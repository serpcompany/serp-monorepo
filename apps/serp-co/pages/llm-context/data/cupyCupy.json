[
  {
    "owner": "cupy",
    "repo": "cupy",
    "content": "TITLE: Defining Elementwise Squared Difference Kernel in CuPy\nDESCRIPTION: Creates an elementwise kernel that computes the squared difference between two inputs (x-y)^2. The kernel accepts float32 inputs and can be called on scalars or arrays with broadcasting support.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nsquared_diff = cp.ElementwiseKernel(\n   'float32 x, float32 y',\n   'float32 z',\n   'z = (x - y) * (x - y)',\n   'squared_diff')\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Stream Context Manager in CuPy\nDESCRIPTION: Demonstrates how to create a CUDA stream and use it as a context manager to control which stream operations are performed on. Within the context, array creation and kernel execution happen on the specified stream.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/cuda_api.rst#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> import numpy as np\n>>>\n>>> a_np = np.arange(10)\n>>> s = cp.cuda.Stream()\n>>> with s:\n...     a_cp = cp.asarray(a_np)  # H2D transfer on stream s\n...     b_cp = cp.sum(a_cp)      # kernel launched on stream s\n...     assert s == cp.cuda.get_current_stream()\n...\n>>> # fall back to the previous stream in use (here the default stream)\n>>> # when going out of the scope of s\n```\n\n----------------------------------------\n\nTITLE: Writing CPU/GPU Agnostic Code with CuPy\nDESCRIPTION: This snippet shows how to write code that can work with both CPU and GPU arrays using cupy.get_array_module function. It includes an example of a CPU/GPU agnostic function that computes softplus.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/basic.rst#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>>> # Stable implementation of log(1 + exp(x))\n>>> def softplus(x):\n...     xp = cp.get_array_module(x)  # 'xp' is a standard usage in the community\n...     print(\"Using:\", xp.__name__)\n...     return xp.maximum(0, x) + xp.log1p(xp.exp(-abs(x)))\n```\n\n----------------------------------------\n\nTITLE: PyTorch-CuPy Data Exchange\nDESCRIPTION: Demonstrates zero-copy data exchange between PyTorch tensors and CuPy arrays using __cuda_array_interface__.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\nimport torch\n\n# Create a PyTorch tensor.\ntx1 = torch.randn(1, 2, 3, 4).cuda()\n\n# Convert it into a CuPy array.\ncx = cupy.from_dlpack(tx1)\n\n# Convert it back to a PyTorch tensor.\ntx2 = torch.from_dlpack(cx)\n```\n\n----------------------------------------\n\nTITLE: JIT Kernel Implementation Example\nDESCRIPTION: Example of using CuPy's JIT decorator to create a raw CUDA kernel from Python code. Implements an elementwise copy operation using a grid-stride loop pattern.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\n@jit.rawkernel()\ndef elementwise_copy(x, y, size):\n    tid = jit.blockIdx.x * jit.blockDim.x + jit.threadIdx.x\n    ntid = jit.gridDim.x * jit.blockDim.x\n    for i in range(tid, size, ntid):\n        y[i] = x[i]\n```\n\n----------------------------------------\n\nTITLE: Basic CuPy Array Operations Example\nDESCRIPTION: Demonstrates basic array creation, reshaping, and computation using CuPy's NumPy-compatible API. Shows how to create an array, reshape it, set its data type, and perform a sum operation along an axis.\nSOURCE: https://github.com/cupy/cupy/blob/main/README.md#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n>>> import cupy as cp\n>>> x = cp.arange(6).reshape(2, 3).astype('f')\n>>> x\narray([[ 0.,  1.,  2.],\n       [ 3.,  4.,  5.]], dtype=float32)\n>>> x.sum(axis=1)\narray([  3.,  12.], dtype=float32)\n```\n\n----------------------------------------\n\nTITLE: Performing Multi-GPU FFT with CuPy\nDESCRIPTION: Shows how to use multiple GPUs for FFT calculations in CuPy. This example demonstrates setting up multi-GPU FFT for a 1D complex-to-complex transform.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/fft.rst#2025-04-19_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nimport cupy as cp\n\ncp.fft.config.use_multi_gpus = True\ncp.fft.config.set_cufft_gpus([0, 1])  # use GPU 0 & 1\n\nshape = (64, 64)  # batch size = 64\ndtype = cp.complex64\na = cp.random.random(shape).astype(dtype)  # reside on GPU 0\n\nb = cp.fft.fft(a)  # computed on GPU 0 & 1, reside on GPU 0\n```\n\n----------------------------------------\n\nTITLE: Initializing CuPy and NumPy Arrays in Python\nDESCRIPTION: This snippet demonstrates how to import CuPy and NumPy, and create arrays using both libraries. It shows the similarity in syntax between CuPy and NumPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/basic.rst#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> import numpy as np\n>>> import cupy as cp\n\n>>> x_gpu = cp.array([1, 2, 3])\n\n>>> x_cpu = np.array([1, 2, 3])\n>>> l2_cpu = np.linalg.norm(x_cpu)\n\n>>> x_gpu = cp.array([1, 2, 3])\n>>> l2_gpu = cp.linalg.norm(x_gpu)\n```\n\n----------------------------------------\n\nTITLE: Memory Pool Statistics and Operations Example\nDESCRIPTION: Demonstrates how to access and manage CuPy memory pools, showing memory allocation, usage tracking, and cleanup operations for both device and pinned memory.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/memory.rst#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\nimport numpy\n\nmempool = cupy.get_default_memory_pool()\npinned_mempool = cupy.get_default_pinned_memory_pool()\n\n# Create an array on CPU.\n# NumPy allocates 400 bytes in CPU (not managed by CuPy memory pool).\na_cpu = numpy.ndarray(100, dtype=numpy.float32)\nprint(a_cpu.nbytes)                      # 400\n\n# You can access statistics of these memory pools.\nprint(mempool.used_bytes())              # 0\nprint(mempool.total_bytes())             # 0\nprint(pinned_mempool.n_free_blocks())    # 0\n\n# Transfer the array from CPU to GPU.\na = cupy.array(a_cpu)\nprint(a.nbytes)                          # 400\nprint(mempool.used_bytes())              # 512\nprint(mempool.total_bytes())             # 512\nprint(pinned_mempool.n_free_blocks())    # 1\n\n# When the array goes out of scope\na = None  # (or `del a`)\nprint(mempool.used_bytes())              # 0\nprint(mempool.total_bytes())             # 512\nprint(pinned_mempool.n_free_blocks())    # 1\n\n# You can clear the memory pool\nmempool.free_all_blocks()\npinned_mempool.free_all_blocks()\nprint(mempool.used_bytes())              # 0\nprint(mempool.total_bytes())             # 0\nprint(pinned_mempool.n_free_blocks())    # 0\n```\n\n----------------------------------------\n\nTITLE: Creating a Raw CUDA Kernel in CuPy\nDESCRIPTION: This snippet demonstrates how to create a raw CUDA kernel using CuPy's RawKernel class. The kernel performs element-wise addition of two float arrays. It also shows how to access and modify kernel attributes.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n>>> add_kernel = cp.RawKernel(r'''\n... extern \"C\" __global__\n... void my_add(const float* x1, const float* x2, float* y) {\n...     int tid = blockDim.x * blockIdx.x + threadIdx.x;\n...     y[tid] = x1[tid] + x2[tid];\n... }\n... ''', 'my_add')\n>>> add_kernel.attributes  # doctest: +SKIP\n{'max_threads_per_block': 1024, 'shared_size_bytes': 0, 'const_size_bytes': 0, 'local_size_bytes': 0, 'num_regs': 10, 'ptx_version': 70, 'binary_version': 70, 'cache_mode_ca': 0, 'max_dynamic_shared_size_bytes': 49152, 'preferred_shared_memory_carveout': -1}\n>>> add_kernel.max_dynamic_shared_size_bytes  # doctest: +SKIP\n49152\n>>> add_kernel.max_dynamic_shared_size_bytes = 50000  # set a new value for the attribute  # doctest: +SKIP\n>>> add_kernel.max_dynamic_shared_size_bytes  # doctest: +SKIP\n50000\n```\n\n----------------------------------------\n\nTITLE: Data Transfer between Host and Device in CuPy\nDESCRIPTION: This snippet demonstrates how to move data between CPU (host) and GPU (device) using cupy.asarray and cupy.asnumpy functions. It also shows how to transfer data between different GPU devices.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/basic.rst#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> x_cpu = np.array([1, 2, 3])\n>>> x_gpu = cp.asarray(x_cpu)  # move the data to the current device.\n\n>>> with cp.cuda.Device(0):\n...     x_gpu_0 = cp.ndarray([1, 2, 3])  # create an array in GPU 0\n>>> with cp.cuda.Device(1):\n...     x_gpu_1 = cp.asarray(x_gpu_0)  # move the array to GPU 1\n\n>>> x_gpu = cp.array([1, 2, 3])  # create an array in the current device\n>>> x_cpu = cp.asnumpy(x_gpu)  # move the array to the host.\n\n>>> x_cpu = x_gpu.get()\n```\n\n----------------------------------------\n\nTITLE: Complex Number Raw CUDA Kernel\nDESCRIPTION: Shows implementation of a raw CUDA kernel that operates on complex-valued arrays. Demonstrates usage of CuPy's complex number support and header inclusion.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_5\n\nLANGUAGE: CUDA\nCODE:\n```\ncomplex_kernel = cp.RawKernel(r'''\n#include <cupy/complex.cuh>\nextern \"C\" __global__\nvoid my_func(const complex<float>* x1, const complex<float>* x2,\n             complex<float>* y, float a) {\n    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    y[tid] = x1[tid] + a * x2[tid];\n}\n''', 'my_func')\n```\n\n----------------------------------------\n\nTITLE: L2 Norm Reduction Kernel\nDESCRIPTION: Defines a reduction kernel that computes the L2 norm along specified axes. Shows implementation of mapping, reduction, and post-mapping expressions.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nl2norm_kernel = cp.ReductionKernel(\n    'T x',  # input params\n    'T y',  # output params\n    'x * x',  # map\n    'a + b',  # reduce\n    'y = sqrt(a)',  # post-reduction map\n    '0',  # identity value\n    'l2norm'  # kernel name\n)\n```\n\n----------------------------------------\n\nTITLE: Raw CUDA Vector Addition Kernel\nDESCRIPTION: Implements a raw CUDA kernel for vector addition using CuPy's RawKernel class. Shows direct CUDA C++ code integration with manual control over grid and block sizes.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_4\n\nLANGUAGE: CUDA\nCODE:\n```\nadd_kernel = cp.RawKernel(r'''\nextern \"C\" __global__\nvoid my_add(const float* x1, const float* x2, float* y) {\n    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    y[tid] = x1[tid] + x2[tid];\n}\n''', 'my_add')\n```\n\n----------------------------------------\n\nTITLE: Custom CUDA Kernels in PyTorch with CuPy\nDESCRIPTION: Implementation of a custom PyTorch autograd function using CuPy RawKernels for logarithm computation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\nimport torch\n\n\ncupy_custom_kernel_fwd = cupy.RawKernel(\n    r\"\"\"\nextern \"C\" __global__\nvoid cupy_custom_kernel_fwd(const float* x, float* y, int size) {\n    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (tid < size)\n        y[tid] = log(x[tid]);\n}\n\"\"\",\n    \"cupy_custom_kernel_fwd\",\n)\n\n\ncupy_custom_kernel_bwd = cupy.RawKernel(\n    r\"\"\"\nextern \"C\" __global__\nvoid cupy_custom_kernel_bwd(const float* x, float* gy, float* gx, int size) {\n    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (tid < size)\n        gx[tid] = gy[tid] / x[tid];\n}\n\"\"\",\n    \"cupy_custom_kernel_bwd\",\n)\n\n\nclass CuPyLog(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.input = x\n        # Enforce contiguous arrays to simplify RawKernel indexing.\n        cupy_x = cupy.ascontiguousarray(cupy.from_dlpack(x.detach()))\n        cupy_y = cupy.empty(cupy_x.shape, dtype=cupy_x.dtype)\n        x_size = cupy_x.size\n        bs = 128\n        cupy_custom_kernel_fwd(\n            (bs,), ((x_size + bs - 1) // bs,), (cupy_x, cupy_y, x_size)\n        )\n        # the ownership of the device memory backing cupy_y is implicitly\n        # transferred to torch_y, so this operation is safe even after\n        # going out of scope of this function.\n        torch_y = torch.from_dlpack(cupy_y)\n        return torch_y\n\n    @staticmethod\n    def backward(ctx, grad_y):\n        # Enforce contiguous arrays to simplify RawKernel indexing.\n        cupy_input = cupy.from_dlpack(ctx.input.detach()).ravel()\n        cupy_grad_y = cupy.from_dlpack(grad_y.detach()).ravel()\n        cupy_grad_x = cupy.zeros(cupy_grad_y.shape, dtype=cupy_grad_y.dtype)\n        gy_size = cupy_grad_y.size\n        bs = 128\n        cupy_custom_kernel_bwd(\n            (bs,),\n            ((gy_size + bs - 1) // bs,),\n            (cupy_input, cupy_grad_y, cupy_grad_x, gy_size),\n        )\n        # the ownership of the device memory backing cupy_grad_x is implicitly\n        # transferred to torch_y, so this operation is safe even after\n        # going out of scope of this function.\n        torch_grad_x = torch.from_dlpack(cupy_grad_x)\n        return torch_grad_x\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Stream.use() Method in CuPy\nDESCRIPTION: Shows how to explicitly set the current CUDA stream using the Stream.use() method. This example demonstrates switching between a custom stream and the default null stream.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/cuda_api.rst#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> s = cp.cuda.Stream()\n>>> s.use()  # any subsequent operations are done on steam s  # doctest: +ELLIPSIS\n<Stream ... (device ...)>\n>>> b_np = cp.asnumpy(b_cp)\n>>> assert s == cp.cuda.get_current_stream()\n>>> cp.cuda.Stream.null.use()  # fall back to the default (null) stream\n<Stream 0 (device -1)>\n>>> assert cp.cuda.Stream.null == cp.cuda.get_current_stream()\n```\n\n----------------------------------------\n\nTITLE: Compiling and Launching Custom CUDA Kernel with CuPy\nDESCRIPTION: Demonstrates how to use cupy.RawKernel to compile and launch a custom CUDA kernel. The kernel is defined in a separate .cu file and can be modified at runtime. The compiled code is cached for efficiency.\nSOURCE: https://github.com/cupy/cupy/blob/main/examples/gemm/README.md#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n# Example code not provided, but would use cupy.RawKernel\n```\n\n----------------------------------------\n\nTITLE: CuPy Array Creation from Existing Data\nDESCRIPTION: Functions for creating arrays from various data sources including buffers, files, and existing arrays. Contains data conversion and loading utilities.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/creation.rst#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\narray\nasarray\nasanyarray\nascontiguousarray\ncopy\nfrombuffer\nfromfile\nfromfunction\nfromiter\nfromstring\nloadtxt\n```\n\n----------------------------------------\n\nTITLE: Numpy-CuPy Interop Example\nDESCRIPTION: Demonstrates NumPy ufunc operations on CuPy arrays using __array_ufunc__ interface. Requires NumPy 1.13 or later.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\nimport numpy\n\narr = cupy.random.randn(1, 2, 3, 4).astype(cupy.float32)\nresult = numpy.sum(arr)\nprint(type(result))  # => <class 'cupy._core.core.ndarray'>\n```\n\n----------------------------------------\n\nTITLE: Benchmarking CuPy Functions with cupyx.profiler\nDESCRIPTION: Example showing how to benchmark a CuPy function using cupyx.profiler.benchmark to measure both CPU and GPU execution times accurately. The function demonstrates timing a simple vector norm calculation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/performance.rst#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom cupyx.profiler import benchmark\n\ndef my_func(a):\n    return cp.sqrt(cp.sum(a**2, axis=-1))\n\na = cp.random.random((256, 1024))\nprint(benchmark(my_func, (a,), n_repeat=20))\n```\n\n----------------------------------------\n\nTITLE: Handling CPU and GPU Arrays in CuPy\nDESCRIPTION: This snippet demonstrates how to handle and operate on both CPU (NumPy) and GPU (CuPy) arrays. It shows the use of cupy.asnumpy and cupy.asarray for data transfer and compatibility.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/basic.rst#2025-04-19_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n>>> x_cpu = np.array([1, 2, 3])\n>>> y_cpu = np.array([4, 5, 6])\n>>> x_cpu + y_cpu\narray([5, 7, 9])\n>>> x_gpu = cp.asarray(x_cpu)\n>>> x_gpu + y_cpu\nTraceback (most recent call last):\n...\nTypeError: Unsupported type <class 'numpy.ndarray'>\n>>> cp.asnumpy(x_gpu) + y_cpu\narray([5, 7, 9])\n>>> cp.asnumpy(x_gpu) + cp.asnumpy(y_cpu)\narray([5, 7, 9])\n>>> x_gpu + cp.asarray(y_cpu)\narray([5, 7, 9])\n>>> cp.asarray(x_gpu) + cp.asarray(y_cpu)\narray([5, 7, 9])\n```\n\n----------------------------------------\n\nTITLE: CuPy Numerical Range Array Creation\nDESCRIPTION: Functions for creating arrays containing numerical sequences and grids. Includes linear, logarithmic and mesh grid generation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/creation.rst#2025-04-19_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\narange\nlinspace\nlogspace\nmeshgrid\nmgrid\nogrid\n```\n\n----------------------------------------\n\nTITLE: Managing Current Device in CuPy\nDESCRIPTION: This snippet shows how to switch between GPU devices using CuPy's Device context manager. It demonstrates creating arrays on different devices.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/basic.rst#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> x_on_gpu0 = cp.array([1, 2, 3, 4, 5])\n\n>>> with cp.cuda.Device(1):\n...    x_on_gpu1 = cp.array([1, 2, 3, 4, 5])\n>>> x_on_gpu0 = cp.array([1, 2, 3, 4, 5])\n\n>>> with cp.cuda.Device(1):\n...    x = cp.array([1, 2, 3, 4, 5])\n>>> x.device\n<CUDA Device 1>\n```\n\n----------------------------------------\n\nTITLE: Importing External CUDA Stream into CuPy\nDESCRIPTION: Illustrates how to use an external CUDA stream (created in PyTorch) with CuPy. It shows the usage of ExternalStream class to switch the current stream in CuPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport torch\n\n# Create a stream on PyTorch.\ns = torch.cuda.Stream()\n\n# Switch the current stream in PyTorch.\nwith torch.cuda.stream(s):\n    # Switch the current stream in CuPy, using the pointer of the stream created in PyTorch.\n    with cupy.cuda.ExternalStream(s.cuda_stream):\n        # This block runs on the same CUDA stream.\n        torch.arange(10, device='cuda')\n        cupy.arange(10)\n```\n\n----------------------------------------\n\nTITLE: CuPy Matrix Building Functions\nDESCRIPTION: Specialized functions for creating matrix structures including diagonal, triangular and Vandermonde matrices.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/creation.rst#2025-04-19_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ndiag\ndiagflat\ntri\ntril\ntriu\nvander\n```\n\n----------------------------------------\n\nTITLE: Defining Custom NumPy Dtype for CUDA Vector Types\nDESCRIPTION: This example shows how to define a custom NumPy dtype that corresponds to CUDA vector types like float3. It demonstrates creating a structured dtype with named fields and accessing its elements.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n>>> import numpy as np\n>>> names = ['x', 'y', 'z']\n>>> types = [np.float32]*3\n>>> float3 = np.dtype({'names': names, 'formats': types})\n>>> arg = np.random.rand(3).astype(np.float32).view(float3)\n>>> print(arg)  # doctest: +SKIP\n[(0.9940819, 0.62873816, 0.8953669)]\n>>> arg['x'] = 42.0\n>>> print(arg)  # doctest: +SKIP\n[(42., 0.62873816, 0.8953669)]\n```\n\n----------------------------------------\n\nTITLE: Manual GPU Event Timing in CuPy\nDESCRIPTION: Demonstrates how to manually measure GPU execution time using CUDA events. Shows the internal implementation approach used by the benchmark utility to accurately time GPU operations.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/performance.rst#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport time\nstart_gpu = cp.cuda.Event()\nend_gpu = cp.cuda.Event()\n\nstart_gpu.record()\nstart_cpu = time.perf_counter()\nout = my_func(a)\nend_cpu = time.perf_counter()\nend_gpu.record()\nend_gpu.synchronize()\nt_gpu = cp.cuda.get_elapsed_time(start_gpu, end_gpu)\nt_cpu = end_cpu - start_cpu\n```\n\n----------------------------------------\n\nTITLE: Running K-means Clustering Demo with Python\nDESCRIPTION: Command to execute the K-means clustering demo script with various optional parameters including GPU ID, number of clusters, data points, maximum iterations, custom kernel usage, and output image specification.\nSOURCE: https://github.com/cupy/cupy/blob/main/examples/kmeans/README.md#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython kmeans.py [--gpu-id GPU_ID] [--n-clusters N_CLUSTERS] [--num NUM]\n                 [--max-iter MAX_ITER] [--use-custom-kernel]\n                 [--output-image OUTPUT_IMAGE]\n```\n\n----------------------------------------\n\nTITLE: Using DLPack Protocol with CuPy and JAX\nDESCRIPTION: Illustrates the usage of DLPack protocol for data exchange between CuPy and JAX. It shows how to convert arrays between the two libraries using from_dlpack() functions.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n>>> import cupy as cp\n>>> import jax.numpy as jnp\n>>> x = jnp.arange(5.0)\n>>> y = cp.from_dlpack(x)\n>>> y\narray([0., 1., 2., 3., 4.], dtype=float32)\n>>> z = jnp.from_dlpack(y)\n>>> z\nArray([0., 1., 2., 3., 4.], dtype=float32)\n```\n\n----------------------------------------\n\nTITLE: Exporting CuPy CUDA Stream\nDESCRIPTION: Shows how to access the CUDA stream pointer created in CuPy for use in other libraries. It demonstrates obtaining the stream pointer and device ID.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ns = cupy.cuda.Stream()\nprint(s.ptr, s.device_id)  # => (93997451352336, 0)\n```\n\n----------------------------------------\n\nTITLE: Raw Argument Vector Addition Kernel\nDESCRIPTION: Creates an elementwise kernel that adds two vectors with manual indexing using the raw argument specifier. Demonstrates reverse indexing of one vector during addition.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nadd_reverse = cp.ElementwiseKernel(\n    'T x, raw T y', 'T z',\n    'z = x + y[_ind.size() - i - 1]',\n    'add_reverse')\n```\n\n----------------------------------------\n\nTITLE: Setting SciPy FFT Backend to CuPy\nDESCRIPTION: Demonstrates how to set cupyx.scipy.fft as the backend for scipy.fft, allowing scipy.fft to work with both numpy and cupy arrays.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_fft.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nscipy.fft.set_backend(cupyx.scipy.fft)\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy Profiling Utilities in Python\nDESCRIPTION: This snippet demonstrates how to import profiling utilities from the cupyx.profiler module. These tools are used for benchmarking, time range profiling, and general profiling of CuPy operations.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/ext.rst#2025-04-19_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nfrom cupyx.profiler import benchmark, time_range, profile\n```\n\n----------------------------------------\n\nTITLE: MPI4Py-CuPy Integration Example\nDESCRIPTION: Shows how to use CuPy arrays with MPI operations through mpi4py. Requires CUDA-aware MPI implementation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\nfrom mpi4py import MPI\n\ncomm = MPI.COMM_WORLD\nsize = comm.Get_size()\n\n# Allreduce\nsendbuf = cupy.arange(10, dtype='i')\nrecvbuf = cupy.empty_like(sendbuf)\ncomm.Allreduce(sendbuf, recvbuf)\nassert cupy.allclose(recvbuf, sendbuf*size)\n```\n\n----------------------------------------\n\nTITLE: In-place FFT with CuPy\nDESCRIPTION: Shows the correct way to perform an in-place FFT using cupyx.scipy.fftpack.fft with the overwrite_x parameter set to True.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_fft.rst#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nx = cupyx.scipy.fftpack.fft(x, ..., overwrite_x=True, ...)\n```\n\n----------------------------------------\n\nTITLE: Enabling Python Slice Copy in CuPy\nDESCRIPTION: Example syntax for copying NumPy array to CuPy array when CUPY_EXPERIMENTAL_SLICE_COPY is enabled.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/environment.rst#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ncupy_ndarray[:] = numpy_ndarray\n```\n\n----------------------------------------\n\nTITLE: Using SciPy FFT Backend with CuPy for One-time Usage\nDESCRIPTION: Demonstrates how to use CuPy's FFT implementation as a backend for SciPy's FFT function using a context manager. This allows for one-time usage of CuPy's FFT while maintaining SciPy's API.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/fft.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport cupy as cp\nimport cupyx.scipy.fft as cufft\nimport scipy.fft\n\na = cp.random.random(100).astype(cp.complex64)\nwith scipy.fft.set_backend(cufft):\n    b = scipy.fft.fft(a)  # equivalent to cufft.fft(a)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Optimized NumPy-CuPy Operations\nDESCRIPTION: Example showing how the configured memory allocators enable efficient operations between NumPy and CuPy arrays without explicit data copying, demonstrating seamless CPU-GPU execution.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/memory.rst#2025-04-19_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# a, b, c are np.ndarray, d is cp.ndarray\na = np.random.random(100)\nb = np.random.random(100)\nc = np.add(a, b)\nd = cp.matmul(cp.asarray(a), cp.asarray(c))\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Device Context Manager Behavior in Python\nDESCRIPTION: Code example showing the change in CuPy device context manager behavior across versions, particularly the reactivation of CUDA current device when exiting a device context manager.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/upgrade.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ndef do_preprocess_cupy():\n    with cupy.cuda.Device(2):\n        # ...\n        pass\n\ntorch.cuda.set_device(1)\ndo_preprocess_cupy()\nprint(torch.cuda.get_device())  # -> ???\n```\n\n----------------------------------------\n\nTITLE: Registering CuPy as Global SciPy FFT Backend\nDESCRIPTION: Shows how to register CuPy's FFT implementation as the global backend for SciPy's FFT functions. This allows using CuPy's FFT through SciPy's API without needing context managers.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/fft.rst#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport cupy as cp\nimport cupyx.scipy.fft as cufft\nimport scipy.fft\nscipy.fft.set_global_backend(cufft)\n\na = cp.random.random(100).astype(cp.complex64)\nb = scipy.fft.fft(a)  # equivalent to cufft.fft(a)\n```\n\n----------------------------------------\n\nTITLE: Numba-CuPy Zero-Copy Conversion\nDESCRIPTION: Demonstrates zero-copy conversion between Numba CUDA arrays and CuPy arrays.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy\nimport numba\nimport cupy\n\nx = numpy.arange(10)  # type: numpy.ndarray\nx_numba = numba.cuda.to_device(x)  # type: numba.cuda.cudadrv.devicearray.DeviceNDArray\nx_cupy = cupy.asarray(x_numba)  # type: cupy.ndarray\n```\n\n----------------------------------------\n\nTITLE: C++ Template Kernel Example\nDESCRIPTION: Demonstration of using C++ templates in CUDA kernels with RawModule. Shows how to multiply array elements by 3 using a templated kernel that works with both float and double types.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_10\n\nLANGUAGE: CUDA\nCODE:\n```\ntemplate<typename T>\n__global__ void fx3(T* arr, int N) {\n    unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid < N) {\n        arr[tid] = arr[tid] * 3;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Illustrating Device Context Manager Changes in Python\nDESCRIPTION: Example demonstrating the behavioral differences in device management between CuPy v9 and v10, specifically regarding device selection after exiting a context manager block.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/upgrade.rst#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ncupy.cuda.Device(1).use()\nwith cupy.cuda.Device(0):\n    pass\ncupy.cuda.Device()  # -> CuPy v10 returns device 0 instead of device 1\n```\n\n----------------------------------------\n\nTITLE: Using FFT Plan Cache in CuPy\nDESCRIPTION: Shows how to use and manage the built-in FFT plan cache in CuPy. The cache is enabled by default and can improve performance by reusing plans.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/fft.rst#2025-04-19_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nimport cupy as cp\n\ncache = cp.fft.config.get_plan_cache()\ncache.show_info()\n\n# Perform a transform, which generates and caches a plan\na = cp.random.random((4, 64, 64))\nout = cp.fft.fftn(a, axes=(1, 2))\ncache.show_info()\n\n# Perform the same transform again, reusing the cached plan\nout = cp.fft.fftn(a, axes=(1, 2))\ncache.show_info()\n\n# Clear the cache\ncache.clear()\ncp.fft.config.show_plan_cache_info()\n```\n\n----------------------------------------\n\nTITLE: Numba-CuPy Integration Example\nDESCRIPTION: Shows how to use CuPy arrays with Numba CUDA JIT compiler using __cuda_array_interface__. Demonstrates array addition kernel.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\nfrom numba import cuda\n\n@cuda.jit\ndef add(x, y, out):\n\tstart = cuda.grid(1)\n\tstride = cuda.gridsize(1)\n\tfor i in range(start, x.shape[0], stride):\n\t\tout[i] = x[i] + y[i]\n\na = cupy.arange(10)\nb = a * 2\nout = cupy.zeros_like(a)\n\nprint(out)  # => [0 0 0 0 0 0 0 0 0 0]\n\nadd[1, 32](a, b, out)\n\nprint(out)  # => [ 0  3  6  9 12 15 18 21 24 27]\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy from Git Repository\nDESCRIPTION: Clones the CuPy repository and installs the latest development version from source.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ git clone --recursive https://github.com/cupy/cupy.git\n$ cd cupy\n$ pip install .\n```\n\n----------------------------------------\n\nTITLE: Configuring CuPy System Memory Allocator\nDESCRIPTION: Sets up CuPy to use system memory allocation through CUDA MemoryPool. This configuration is essential for optimizing memory management in GPU operations.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/memory.rst#2025-04-19_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport cupy as cp\ncp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.memory.malloc_system).malloc)\n```\n\n----------------------------------------\n\nTITLE: CuPy Data Types Reference\nDESCRIPTION: List of supported data types in CuPy's ndarray implementation, including boolean, integer, float, and complex number types.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/overview.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nbool_                  # boolean\nint8, int16, int32, int64    # signed integers\nuint8, uint16, uint32, uint64  # unsigned integers\nfloat16, float32, float64      # floating point\ncomplex64, complex128          # complex numbers\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy with Specific CUDA Version from Conda-Forge\nDESCRIPTION: Forces installation of CuPy with a specific CUDA version (e.g., 11.8) from conda-forge.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ conda install -c conda-forge cupy cuda-version=11.8\n```\n\n----------------------------------------\n\nTITLE: Creating and Using User-Managed FFT Plans with CuPy\nDESCRIPTION: Demonstrates how to create and use user-managed FFT plans in CuPy for performance optimization. The plan can be used explicitly or as a context manager.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/fft.rst#2025-04-19_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nimport cupy as cp\nfrom cupyx.scipy.fft import get_fft_plan\nimport cupyx.scipy.fft\n\na = cp.random.random((4, 64, 64)).astype(cp.complex64)\nplan = get_fft_plan(a, axes=(1, 2), value_type='C2C')  # for batched, C2C, 2D transform\n\n# Using plan explicitly\nout = cupyx.scipy.fft.fft2(a, axes=(1, 2), plan=plan)\n\n# Using plan as context manager\nwith plan:\n    out = cp.fft.fft2(a, axes=(1, 2))\n```\n\n----------------------------------------\n\nTITLE: Importing External GPU Memory into CuPy\nDESCRIPTION: Shows how to create a CuPy array from an external GPU memory pointer. It demonstrates the use of UnownedMemory and MemoryPointer classes to wrap the external memory.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Create a memory chunk from raw pointer and its size.\nmem = cupy.cuda.UnownedMemory(140359025819648, 1024, owner=None)\n\n# Wrap it as a MemoryPointer.\nmemptr = cupy.cuda.MemoryPointer(mem, offset=0)\n\n# Create an ndarray view backed by the memory pointer.\narr = cupy.ndarray((16, 16), dtype=cupy.float32, memptr=memptr)\nassert arr.nbytes <= arr.data.mem.size\n```\n\n----------------------------------------\n\nTITLE: CuPy Sparse Matrix Types\nDESCRIPTION: Available 2-D sparse matrix implementations in CuPy's scipy.sparse compatibility layer.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/overview.rst#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ncsr_matrix    # Compressed Sparse Row matrix\ncoo_matrix    # Coordinate format matrix\ncsc_matrix    # Compressed Sparse Column matrix\ndia_matrix    # Diagonal storage matrix\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy for CUDA 12.x via PyPI\nDESCRIPTION: Installs the CuPy wheel package for CUDA versions 12.x using pip.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install cupy-cuda12x\n```\n\n----------------------------------------\n\nTITLE: Implementing FFT Callbacks with CuPy\nDESCRIPTION: Demonstrates how to use FFT callbacks in CuPy to merge pre- and post-processing kernels with FFT routines. This example shows a load callback that overwrites the input array to 1.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/fft.rst#2025-04-19_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nimport cupy as cp\n\n# a load callback that overwrites the input array to 1\ncode = r'''\n__device__ cufftComplex CB_ConvertInputC(\n    void *dataIn,\n    size_t offset,\n    void *callerInfo,\n    void *sharedPtr)\n{\n    cufftComplex x;\n    x.x = 1.;\n    x.y = 0.;\n    return x;\n}\n__device__ cufftCallbackLoadC d_loadCallbackPtr = CB_ConvertInputC;\n'''\n\na = cp.random.random((64, 128, 128)).astype(cp.complex64)\n\n# this fftn call uses callback\nwith cp.fft.config.set_cufft_callbacks(cb_load=code):\n    b = cp.fft.fftn(a, axes=(1,2))\n\n# this does not use\nc = cp.fft.fftn(cp.ones(shape=a.shape, dtype=cp.complex64), axes=(1,2))\n\n# result agrees\nassert cp.allclose(b, c)\n\n# \"static\" plans are also cached, but are distinct from their no-callback counterparts\ncp.fft.config.get_plan_cache().show_info()\n```\n\n----------------------------------------\n\nTITLE: Stream Ordered Memory Allocation Example\nDESCRIPTION: Shows how to use CuPy's experimental stream ordered memory allocator with custom streams for asynchronous memory operations.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/memory.rst#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\n\n# Use asynchronous stream ordered memory\ncupy.cuda.set_allocator(cupy.cuda.MemoryAsyncPool().malloc)\n\n# Create a custom stream\ns = cupy.cuda.Stream()\n\n# This would allocate memory asynchronously on stream s\nwith s:\n    a = cupy.empty((100,), dtype=cupy.float64)\n```\n\n----------------------------------------\n\nTITLE: Installing CUDA NVCC Compiler in Conda Environment\nDESCRIPTION: Installs the NVIDIA CUDA Compiler (NVCC) in a conda environment for CUDA 12 and above.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ conda install -c conda-forge cuda-nvcc\n```\n\n----------------------------------------\n\nTITLE: Type-Generic Elementwise Kernel Definition\nDESCRIPTION: Demonstrates creating a type-generic version of the squared difference kernel using type placeholders. The kernel automatically determines types based on input/output arguments.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nsquared_diff_generic = cp.ElementwiseKernel(\n    'T x, T y',\n    'T z',\n    '''\n        T diff = x - y;\n        z = diff * diff;\n    ''',\n    'squared_diff_generic')\n```\n\n----------------------------------------\n\nTITLE: Running CuPy Docker Image with GPU Support\nDESCRIPTION: Launches a Docker container with CuPy and GPU support, opening a bash shell.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run --gpus all -it cupy/cupy /bin/bash\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy-specific Functions in Python\nDESCRIPTION: This snippet demonstrates how to import CuPy-specific functions from the cupyx namespace. These functions include mathematical operations, scatter operations, and memory allocation functions.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/ext.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom cupyx import rsqrt, scatter_add, scatter_max, scatter_min, empty_pinned, empty_like_pinned, zeros_pinned, zeros_like_pinned\n```\n\n----------------------------------------\n\nTITLE: Performing Multi-GPU FFT using CuPy's Low-level cuFFT API in Python\nDESCRIPTION: This snippet demonstrates how to use CuPy's low-level cuFFT API to perform a multi-GPU FFT operation. It creates a Plan1d object, executes the FFT on CPU-resident data, and compares the result with NumPy's FFT implementation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/fft.rst#2025-04-19_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport cupy as cp\n\n# no need to touch cp.fft.config, as we are using low-level API\n\nshape = (64, 64)\ndtype = np.complex64\na = np.random.random(shape).astype(dtype)  # reside on CPU\n\nif len(shape) == 1:\n    batch = 1\n    nx = shape[0]\nelif len(shape) == 2:\n    batch = shape[0]\n    nx = shape[1]\n\n# compute via cuFFT\ncufft_type = cp.cuda.cufft.CUFFT_C2C  # single-precision c2c\nplan = cp.cuda.cufft.Plan1d(nx, cufft_type, batch, devices=[0,1])\nout_cp = np.empty_like(a)  # output on CPU\nplan.fft(a, out_cp, cufft.CUFFT_FORWARD)\n\nout_np = numpy.fft.fft(a)  # use NumPy's fft\n# np.fft.fft always returns np.complex128\nif dtype is numpy.complex64:\n    out_np = out_np.astype(dtype)\n\n# check result\nassert np.allclose(out_cp, out_np, rtol=1e-4, atol=1e-7)\n```\n\n----------------------------------------\n\nTITLE: Array Reduction Benchmarking Example\nDESCRIPTION: Code example showing how to benchmark array reduction operations and measure their performance. Demonstrates summing a large 3D array and measuring its execution time.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/performance.rst#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom cupyx.profiler import benchmark\na = cp.random.random((256, 256, 256), dtype=cp.float32)\nprint(benchmark(a.sum, (), n_repeat=100))\n```\n\n----------------------------------------\n\nTITLE: Importing DLPack Utility Function in Python\nDESCRIPTION: This code shows how to import the from_dlpack function from CuPy, which is used to create a cupy.ndarray from a DLPack tensor or any object supporting the DLPack data exchange protocol.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/ext.rst#2025-04-19_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nfrom cupy import from_dlpack\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy Random Module\nDESCRIPTION: This snippet shows how to import the cupy.random module for use in Python code.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/random.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. module:: cupy.random\n```\n\n----------------------------------------\n\nTITLE: Custom Memory Allocator Configuration\nDESCRIPTION: Demonstrates how to configure custom memory allocators using managed memory and stream ordered memory allocation in CuPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/memory.rst#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\n\n# Use managed memory\ncupy.cuda.set_allocator(cupy.cuda.MemoryPool(cupy.cuda.malloc_managed).malloc)\n```\n\n----------------------------------------\n\nTITLE: Implementing Aligned NumPy Allocator\nDESCRIPTION: Creates a custom allocator class for NumPy that aligns with system memory allocation. This setup enables efficient memory sharing between CPU and GPU operations by implementing required memory management functions.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/memory.rst#2025-04-19_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport cupy._core.numpy_allocator as ac\nimport numpy_allocator\nimport ctypes\nlib = ctypes.CDLL(ac.__file__)\nclass my_allocator(metaclass=numpy_allocator.type):\n    _calloc_ = ctypes.addressof(lib._calloc)\n    _malloc_ = ctypes.addressof(lib._malloc)\n    _realloc_ = ctypes.addressof(lib._realloc)\n    _free_ = ctypes.addressof(lib._free)\nmy_allocator.__enter__()\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy Sparse Module\nDESCRIPTION: This snippet shows how to import the cupyx.scipy.sparse module, which is the entry point for CuPy's sparse matrix functionality.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_sparse.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. module:: cupyx.scipy.sparse\n```\n\n----------------------------------------\n\nTITLE: Managing Default Memory Pool in CuPy v4\nDESCRIPTION: Demonstrates how to interact with CuPy's default memory pool, including checking memory usage statistics and freeing cached memory blocks. Shows memory pool behavior when allocating and deallocating arrays.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/upgrade.rst#2025-04-19_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\na = cupy.ndarray(100, dtype=cupy.float32)\nmempool = cupy.get_default_memory_pool()\n\n# For performance, the size of actual allocation may become larger than the requested array size.\nprint(mempool.used_bytes())   # 512\nprint(mempool.total_bytes())  # 512\n\n# Even if the array goes out of scope, its memory block is kept in the pool.\na = None\nprint(mempool.used_bytes())   # 0\nprint(mempool.total_bytes())  # 512\n\n# You can clear the memory block by calling `free_all_blocks`.\nmempool.free_all_blocks()\nprint(mempool.used_bytes())   # 0\nprint(mempool.total_bytes())  # 0\n```\n\n----------------------------------------\n\nTITLE: Including RST Comparison Table\nDESCRIPTION: RST directive to include the comparison table content from an external file containing the actual API mappings.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/comparison.rst#2025-04-19_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. include:: comparison_table.rst.inc\n```\n\n----------------------------------------\n\nTITLE: Importing non-SciPy Compatible Signal API Functions in Python\nDESCRIPTION: This code shows how to import non-SciPy compatible signal processing functions from the cupyx.signal module. These functions are ported from cuSignal and include operations like channelization, convolution, and frequency shifting.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/ext.rst#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nfrom cupyx.signal import channelize_poly, convolve1d3o, pulse_compression, pulse_doppler, cfar_alpha, ca_cfar, freq_shift\n```\n\n----------------------------------------\n\nTITLE: Working with CUDA Events for Timing and Stream Dependencies in CuPy\nDESCRIPTION: Demonstrates creating CUDA events, recording them on streams, timing GPU operations, and establishing dependencies between streams using events. This example shows both manual event creation and creation through the stream.record() method.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/cuda_api.rst#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> e1 = cp.cuda.Event()\n>>> e1.record()\n>>> a_cp = b_cp * a_cp + 8\n>>> e2 = cp.cuda.get_current_stream().record()\n>>>\n>>> # set up a stream order\n>>> s2 = cp.cuda.Stream()\n>>> s2.wait_event(e2)\n>>> with s2:\n...     # the a_cp is guaranteed updated when this copy (on s2) starts\n...     a_np = cp.asnumpy(a_cp)\n>>>\n>>> # timing\n>>> e2.synchronize()\n>>> t = cp.cuda.get_elapsed_time(e1, e2)  # only include the compute time, not the copy time\n```\n\n----------------------------------------\n\nTITLE: Disabling Memory Pools\nDESCRIPTION: Shows how to disable CuPy's default memory pools for both device and pinned memory.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/memory.rst#2025-04-19_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\n\n# Disable memory pool for device memory (GPU)\ncupy.cuda.set_allocator(None)\n\n# Disable memory pool for pinned memory (CPU).\ncupy.cuda.set_pinned_memory_allocator(None)\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy Module for Functional Programming in Python\nDESCRIPTION: This snippet shows the import statement for the CuPy module, which is necessary for using CuPy's functional programming features. It sets up the current module context for the subsequent documentation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/functional.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: cupy\n```\n\n----------------------------------------\n\nTITLE: CuPy Basic Array Creation Functions\nDESCRIPTION: Core functions for creating arrays with ones, zeros, and empty values. Includes functions like empty(), ones(), zeros() and their _like variants.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/creation.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nempty\nempty_like\neye\nidentity\nones\nones_like\nzeros\nzeros_like\nfull\nfull_like\n```\n\n----------------------------------------\n\nTITLE: Creating Packed Structures as NumPy Dtype\nDESCRIPTION: This snippet demonstrates how to create packed structures like vectors or matrices as NumPy dtypes without naming fields. It shows how to define a 5x5 float matrix as a single 100-byte scalar that can be passed to a CUDA kernel.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n>>> import numpy as np\n>>> float5x5 = np.dtype({'names': ['dummy'], 'formats': [(np.float32,(5,5))]})\n>>> arg = np.random.rand(25).astype(np.float32).view(float5x5)\n>>> print(arg.itemsize)\n100\n```\n\n----------------------------------------\n\nTITLE: Module Autosummary for CuPy Distributed Arrays\nDESCRIPTION: Documentation for the cupyx.distributed.array module that provides functionality for creating and manipulating arrays distributed across multiple GPU devices.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/distributed.rst#2025-04-19_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. module:: cupyx.distributed.array\n\n.. autosummary::\n   :toctree: generated/\n\n   distributed_array\n   DistributedArray\n   make_2d_index_map\n   matmul\n```\n\n----------------------------------------\n\nTITLE: Out-of-bounds Index Handling in CuPy\nDESCRIPTION: Illustrates how CuPy handles out-of-bounds indices differently from NumPy, wrapping around instead of raising an error.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/difference.rst#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> x = np.array([0, 1, 2])\n>>> x[[1, 3]] = 10\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nIndexError: index 3 is out of bounds for axis 1 with size 3\n>>> x = cupy.array([0, 1, 2])\n>>> x[[1, 3]] = 10\n>>> x\narray([10, 10,  2])\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy Compressed Sparse Graph Module\nDESCRIPTION: This snippet shows how to import the cupyx.scipy.sparse.csgraph module in Python. This module provides compressed sparse graph routines for CuPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_sparse_csgraph.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. module:: cupyx.scipy.sparse.csgraph\n```\n\n----------------------------------------\n\nTITLE: Upgrading Python Package Management Tools\nDESCRIPTION: Upgrades setuptools and pip to the latest versions before installing CuPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ python -m pip install -U setuptools pip\n```\n\n----------------------------------------\n\nTITLE: Defining Vector Operations Using CUDA RawModule\nDESCRIPTION: Example of creating a RawModule with two CUDA kernels - one for vector addition and one for vector multiplication. Shows how to load CUDA source code and execute the kernels on CuPy arrays.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/kernel.rst#2025-04-19_snippet_9\n\nLANGUAGE: CUDA\nCODE:\n```\nextern \"C\"{\n\n__global__ void test_sum(const float* x1, const float* x2, float* y, \\\n                         unsigned int N)\n{\n    unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (tid < N)\n    {\n        y[tid] = x1[tid] + x2[tid];\n    }\n}\n\n__global__ void test_multiply(const float* x1, const float* x2, float* y, \\\n                              unsigned int N)\n{\n    unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (tid < N)\n    {\n        y[tid] = x1[tid] * x2[tid];\n    }\n}\n\n}\n```\n\n----------------------------------------\n\nTITLE: Duplicate Index Handling in CuPy vs NumPy\nDESCRIPTION: Demonstrates different behaviors when handling duplicate indices in array assignment operations between CuPy and NumPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/difference.rst#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>>> a = cupy.zeros((2,))\n>>> i = cupy.arange(10000) % 2\n>>> v = cupy.arange(10000).astype(np.float32)\n>>> a[i] = v\n>>> a  # doctest: +SKIP\narray([ 9150.,  9151.])\n\n>>> a_cpu = np.zeros((2,))\n>>> i_cpu = np.arange(10000) % 2\n>>> v_cpu = np.arange(10000).astype(np.float32)\n>>> a_cpu[i_cpu] = v_cpu\n>>> a_cpu\narray([9998., 9999.])\n```\n\n----------------------------------------\n\nTITLE: Module Autosummary for CuPy Distributed Communication\nDESCRIPTION: Documentation for the cupyx.distributed module that provides functions for initializing process groups and the NCCL backend for GPU communication.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/distributed.rst#2025-04-19_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. module:: cupyx.distributed\n\n.. autosummary::\n   :toctree: generated/\n\n   init_process_group\n   NCCLBackend\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy from PyPI Source\nDESCRIPTION: Installs the latest stable release of CuPy from source using pip.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install cupy\n```\n\n----------------------------------------\n\nTITLE: Running SGEMM Demo in Python\nDESCRIPTION: Command to run the SGEMM demo script, which calculates matrix multiplication of A (m x k) and B (k x n). It allows specifying GPU ID and matrix dimensions.\nSOURCE: https://github.com/cupy/cupy/blob/main/examples/gemm/README.md#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython sgemm.py [--gpu GPU_ID] [--m m] [--n n] [--k k]\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy Data Type Routines\nDESCRIPTION: This snippet shows how to import the CuPy module for accessing data type routines. It sets up the current module context for the subsequent function references.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/dtype.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: cupy\n```\n\n----------------------------------------\n\nTITLE: Uninstalling CuPy\nDESCRIPTION: Removes CuPy installation using pip.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ pip uninstall cupy\n```\n\n----------------------------------------\n\nTITLE: Random Methods dtype Support in CuPy\nDESCRIPTION: Shows how CuPy's random generator supports dtype argument while NumPy does not, allowing for both float32 and float64 outputs.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/difference.rst#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> np.random.randn(dtype=np.float32)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: randn() got an unexpected keyword argument 'dtype'\n>>> cupy.random.randn(dtype=np.float32)    # doctest: +SKIP\narray(0.10689262300729752, dtype=float32)\n```\n\n----------------------------------------\n\nTITLE: Stream Context Manager Behavior in CuPy v10\nDESCRIPTION: Example showing how stream context management changed in CuPy v10, where the current stream set via use() is not restored when exiting a with block.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/upgrade.rst#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ns1 = cupy.cuda.Stream()\ns2 = cupy.cuda.Stream()\ns3 = cupy.cuda.Stream()\nwith s1:\n    s2.use()\n    with s3:\n        pass\n    cupy.cuda.get_current_stream()  # -> CuPy v10 returns `s1` instead of `s2`.\n```\n\n----------------------------------------\n\nTITLE: Running GMM Demo Script in Python\nDESCRIPTION: Command to run the Gaussian Mixture Model demo script. It allows specifying GPU ID, number of samples, dimensions, maximum iterations, tolerance, and output image path.\nSOURCE: https://github.com/cupy/cupy/blob/main/examples/gmm/README.md#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython gmm.py [--gpu-id GPU_ID] [--num NUM] [--dim DIM] [--max-iter MAX_ITER] [--tol TOL] [--output-image OUTPUT]\n```\n\n----------------------------------------\n\nTITLE: Setting GPU Memory Limits Example\nDESCRIPTION: Shows how to set and configure GPU memory usage limits per device using CuPy's memory pool interface.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/memory.rst#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\n\nmempool = cupy.get_default_memory_pool()\n\nwith cupy.cuda.Device(0):\n    mempool.set_limit(size=1024**3)  # 1 GiB\n\nwith cupy.cuda.Device(1):\n    mempool.set_limit(size=2*1024**3)  # 2 GiB\n```\n\n----------------------------------------\n\nTITLE: Importing Kernel Parameter Optimization Function in Python\nDESCRIPTION: This snippet demonstrates how to import the optimize function from the cupyx.optimizing module. This function is used for automatic optimization of kernel parameters in CuPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/ext.rst#2025-04-19_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nfrom cupyx.optimizing import optimize\n```\n\n----------------------------------------\n\nTITLE: RST Module Documentation for CuPy Statistics\nDESCRIPTION: ReStructuredText documentation defining the statistical functions available in CuPy's statistics module. Includes function references organized by category with autosummary directives.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/statistics.rst#2025-04-19_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\nStatistics\n==========\n\n.. Hint:: `NumPy API Reference: Statistics <https://numpy.org/doc/stable/reference/routines.statistics.html>`_\n\n.. currentmodule:: cupy\n\nOrder statistics\n----------------\n\n.. autosummary::\n   :toctree: generated/\n\n   amin\n   amax\n   nanmin\n   nanmax\n   ptp\n   percentile\n   quantile\n\n\nAverages and variances\n----------------------\n\n.. autosummary::\n   :toctree: generated/\n\n   median\n   average\n   mean\n   std\n   var\n   nanmedian\n   nanmean\n   nanstd\n   nanvar\n\n\nCorrelations\n------------\n\n.. autosummary::\n   :toctree: generated/\n\n   corrcoef\n   correlate\n   cov\n\n\nHistograms\n----------\n\n.. autosummary::\n   :toctree: generated/\n\n   histogram\n   histogram2d\n   histogramdd\n   bincount\n   digitize\n```\n\n----------------------------------------\n\nTITLE: Running GMM Demo in Non-GUI Environment\nDESCRIPTION: Command to run the GMM demo script in environments without matplotlib renderers. It sets the MPLBACKEND environmental variable to 'Agg' to enable matplotlib usage in non-GUI settings.\nSOURCE: https://github.com/cupy/cupy/blob/main/examples/gmm/README.md#2025-04-19_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nMPLBACKEND=Agg python gmm.py ...\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy Array API Module\nDESCRIPTION: Demonstrates how to import the CuPy Array API module. This module provides experimental support for the Python Array API Standard, based on the 2021 version.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/array_api.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport cupy.array_api\n```\n\n----------------------------------------\n\nTITLE: Installing Additional CUDA Libraries for CuPy\nDESCRIPTION: Uses CuPy's installer tool to set up additional CUDA libraries like cuTENSOR.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ python -m cupyx.tools.install_library --cuda 11.x --library cutensor\n```\n\n----------------------------------------\n\nTITLE: Running CuPy ROCm Docker Image with GPU Access\nDESCRIPTION: This command runs the CuPy ROCm Docker image interactively, granting access to GPU devices and adding the user to the video group for proper permissions.\nSOURCE: https://github.com/cupy/cupy/blob/main/docker/rocm/README.md#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --device=/dev/kfd --device=/dev/dri --group-add video cupy/cupy-rocm\n```\n\n----------------------------------------\n\nTITLE: Disabling Default Memory Pool in CuPy v4\nDESCRIPTION: Shows how to disable CuPy's default memory pool by setting custom allocators. This must be done before any other CuPy operations are performed.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/upgrade.rst#2025-04-19_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\ncupy.cuda.set_allocator(None)\ncupy.cuda.set_pinned_memory_allocator(None)\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy for CUDA 11.2-11.8 via PyPI\nDESCRIPTION: Installs the CuPy wheel package for CUDA versions 11.2 to 11.8 using pip.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install cupy-cuda11x\n```\n\n----------------------------------------\n\nTITLE: Running Python Scripts for Custom User Structure Examples\nDESCRIPTION: Command to execute the example Python scripts in the folder. Each script demonstrates different aspects of custom user structures in cupy.RawKernel.\nSOURCE: https://github.com/cupy/cupy/blob/main/examples/custom_struct/README.md#2025-04-19_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\npython3.x example_name.py\n```\n\n----------------------------------------\n\nTITLE: Image Resizing with CuPy using OpenCV Mode\nDESCRIPTION: Demonstrates how to resize an image using CuPy's ndimage affine_transform with OpenCV compatibility mode. The example shows loading an image, creating a transformation matrix for 50% size reduction, and saving the result.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_ndimage.rst#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport cupyx.scipy.ndimage\nimport cupy as cp\nimport cv2\n\nim = cv2.imread('TODO') # pls fill in your image path\n\ntrans_mat = cp.eye(4)\ntrans_mat[0][0] = trans_mat[1][1] = 0.5\n\nsmaller_shape = (im.shape[0] // 2, im.shape[1] // 2, 3)\nsmaller = cp.zeros(smaller_shape) # preallocate memory for resized image\n\ncupyx.scipy.ndimage.affine_transform(im, trans_mat, output_shape=smaller_shape,\n                                    output=smaller, mode='opencv')\n\ncv2.imwrite('smaller.jpg', cp.asnumpy(smaller)) # smaller image saved locally\n```\n\n----------------------------------------\n\nTITLE: Listing CuPy Functional Programming Functions in Python\nDESCRIPTION: This code block lists the main functional programming functions available in CuPy. It includes apply_along_axis, apply_over_axes, vectorize, and piecewise. These functions are documented in detail in the generated documentation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/functional.rst#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. autosummary::\n   :toctree: generated/\n\n   apply_along_axis\n   apply_over_axes\n   vectorize\n   piecewise\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for NumPy-Compatible Routines in reStructuredText\nDESCRIPTION: This snippet defines a table of contents using reStructuredText syntax. It lists various categories of NumPy-compatible routines implemented in CuPy, providing links to detailed documentation for each category.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/routines.rst#2025-04-19_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n   :maxdepth: 2\n\n   creation\n   manipulation\n   binary\n   dtype\n   fft\n   functional\n   indexing\n   io\n   linalg\n   logic\n   math\n   misc\n   pad\n   polynomials\n   random\n   set\n   sorting\n   statistics\n   testing\n   window\n```\n\n----------------------------------------\n\nTITLE: Unstructured Multivariate Interpolation Documentation\nDESCRIPTION: RST autosummary directive listing interpolation classes for unstructured multivariate data\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_interpolate.rst#2025-04-19_snippet_4\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   :toctree: generated/\n\n   LinearNDInterpolator\n   NearestNDInterpolator\n   CloughTocher2DInterpolator\n   RBFInterpolator\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy SciPy Signal Windows Module\nDESCRIPTION: This code snippet shows how to import the cupyx.scipy.signal.windows module in Python. It is used to access various window functions for signal processing in CuPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_signal_windows.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. module:: cupyx.scipy.signal.windows\n```\n\n----------------------------------------\n\nTITLE: Custom CUDA Installation\nDESCRIPTION: Setting CUDA_PATH for non-default CUDA installation directory when installing CuPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n$ CUDA_PATH=/opt/nvidia/cuda pip install cupy\n```\n\n----------------------------------------\n\nTITLE: 1-D Splines Documentation\nDESCRIPTION: RST autosummary directive listing 1-D spline interpolation functions\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_interpolate.rst#2025-04-19_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   :toctree: generated/\n\n   BSpline\n   make_interp_spline\n   make_lsq_spline\n\n   splder\n   splantider\n```\n\n----------------------------------------\n\nTITLE: CuPy Logic Functions RST Documentation\nDESCRIPTION: ReStructuredText documentation listing all available logic functions in CuPy, organized into categories including truth value testing, array contents, array type testing, logic operations, and comparison functions.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/logic.rst#2025-04-19_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\nLogic functions\n===============\n\n.. Hint:: `NumPy API Reference: Logic functions <https://numpy.org/doc/stable/reference/routines.logic.html>`_\n\n.. currentmodule:: cupy\n\nTruth value testing\n-------------------\n\n.. autosummary::\n   :toctree: generated/\n\n   all\n   any\n   union1d\n\n\nArray contents\n--------------\n\n.. autosummary::\n   :toctree: generated/\n\n   isfinite\n   isinf\n   isnan\n   isneginf\n   isposinf\n\n\nArray type testing\n------------------\n\n.. autosummary::\n   :toctree: generated/\n\n   iscomplex\n   iscomplexobj\n   isfortran\n   isreal\n   isrealobj\n   isscalar\n\n\nLogic operations\n----------------\n\n.. autosummary::\n   :toctree: generated/\n\n   logical_and\n   logical_or\n   logical_not\n   logical_xor\n\n\nComparison\n----------\n\n.. autosummary::\n   :toctree: generated/\n\n   allclose\n   isclose\n   array_equal\n   array_equiv\n   greater\n   greater_equal\n   less\n   less_equal\n   equal\n   not_equal\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime Header Configuration Check\nDESCRIPTION: Commands to check and install CUDA runtime headers for CuPy.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_23\n\nLANGUAGE: console\nCODE:\n```\n$ python -c 'import cupy; cupy.show_config()'\n...\nCUDA Extra Include Dirs      : []\n...\nNVRTC Version                : (12, 6)\n...\n$ pip install \"nvidia-cuda-runtime-cu12==12.6.*\"\n...\n$ python -c 'import cupy; cupy.show_config()'\n...\nCUDA Extra Include Dirs      : ['.../site-packages/nvidia/cuda_runtime/include']\n...\n```\n\n----------------------------------------\n\nTITLE: Listing Available Functions in CuPy Compressed Sparse Graph Module\nDESCRIPTION: This code block uses autosummary to generate a list of available functions in the cupyx.scipy.sparse.csgraph module. Currently, it only lists the connected_components function.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_sparse_csgraph.rst#2025-04-19_snippet_1\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. autosummary::\n   :toctree: generated/\n\n   connected_components\n```\n\n----------------------------------------\n\nTITLE: Setting RMM Allocator for CuPy\nDESCRIPTION: Demonstrates how to set the RMM allocator for CuPy. It shows two methods: a basic setup and a more performant option with pool allocation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\nimport rmm\ncupy.cuda.set_allocator(rmm.rmm_cupy_allocator)\n```\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\nimport rmm\nrmm.reinitialize(pool_allocator=True)  # can also set init pool size etc here\ncupy.cuda.set_allocator(rmm.rmm_cupy_allocator)\n```\n\n----------------------------------------\n\nTITLE: CuPy Data Type Casting Functions\nDESCRIPTION: This section lists CuPy functions for data type casting and type-related operations. These functions are used to determine type compatibility, find minimum scalar types, and compute result types for operations.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/dtype.rst#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ncan_cast\nmin_scalar_type\nresult_type\ncommon_type\n```\n\n----------------------------------------\n\nTITLE: Univariate Interpolation Functions Documentation\nDESCRIPTION: RST autosummary directive listing available univariate interpolation functions and classes\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_interpolate.rst#2025-04-19_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   :toctree: generated/\n\n   BarycentricInterpolator\n   KroghInterpolator\n   barycentric_interpolate\n   krogh_interpolate\n   pchip_interpolate\n   CubicHermiteSpline\n   PchipInterpolator\n   Akima1DInterpolator\n   PPoly\n   BPoly\n   CubicSpline\n   interp1d\n```\n\n----------------------------------------\n\nTITLE: Building HTML Documentation\nDESCRIPTION: Commands to generate HTML documentation from the reStructuredText source files.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ cd docs\n$ make html\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architecture for CuPy Build\nDESCRIPTION: Example of setting CUPY_NVCC_GENERATE_CODE environment variable to build CuPy for specific CUDA architecture.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/environment.rst#2025-04-19_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nCUPY_NVCC_GENERATE_CODE=\"arch=compute_60,code=sm_60\"\n```\n\n----------------------------------------\n\nTITLE: Smoothing Splines Documentation\nDESCRIPTION: RST autosummary directive listing smoothing spline interpolation classes\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_interpolate.rst#2025-04-19_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   :toctree: generated/\n\n   UnivariateSpline\n   InterpolatedUnivariateSpline\n   LSQUnivariateSpline\n```\n\n----------------------------------------\n\nTITLE: Installing Documentation Dependencies\nDESCRIPTION: Command to install Sphinx and other requirements for building CuPy documentation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install -r docs/requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Running Python Interpreter in CuPy Docker Container\nDESCRIPTION: Starts a Python interpreter directly in a CuPy Docker container with GPU support.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run --gpus all -it cupy/cupy /usr/bin/python3\n```\n\n----------------------------------------\n\nTITLE: Tensor Product Polynomials Documentation\nDESCRIPTION: RST autosummary directive listing tensor product polynomial interpolation classes\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_interpolate.rst#2025-04-19_snippet_6\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   :toctree: generated/\n\n   NdPPoly\n   NdBSpline\n```\n\n----------------------------------------\n\nTITLE: Installing Testing Dependencies\nDESCRIPTION: Command to install pytest and mock packages required for running CuPy tests.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install pytest mock\n```\n\n----------------------------------------\n\nTITLE: Exporting CuPy Memory Pointer\nDESCRIPTION: Demonstrates how to access the memory pointer of a CuPy array for use in other libraries. It shows how to obtain the pointer address and size of the array.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/interoperability.rst#2025-04-19_snippet_9\n\nLANGUAGE: python\nCODE:\n```\narr = cupy.arange(10)\nprint(arr.data.ptr, arr.nbytes)  # => (140359025819648, 80)\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy from Conda-Forge\nDESCRIPTION: Installs CuPy from the conda-forge channel using conda package manager.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ conda install -c conda-forge cupy\n```\n\n----------------------------------------\n\nTITLE: Verbose CuPy Installation for Troubleshooting\nDESCRIPTION: Installs CuPy with maximum verbosity for debugging installation issues.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install cupy -vvvv\n```\n\n----------------------------------------\n\nTITLE: Building Cython Files for Testing\nDESCRIPTION: Command to build Cython files in place, necessary before running unit tests.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install -e .\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy with Additional CUDA Libraries from Conda-Forge\nDESCRIPTION: Installs CuPy along with cuDNN, cuTENSOR, and NCCL from conda-forge.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ conda install -c conda-forge cupy cudnn cutensor nccl\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy with Environment Variables using Sudo\nDESCRIPTION: Demonstrates how to pass environment variables when installing CuPy with sudo.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo CUDA_PATH=/opt/nvidia/cuda pip install cupy\n```\n\n----------------------------------------\n\nTITLE: Writing Slow Tests with Decorators\nDESCRIPTION: Example of using the slow decorator to mark tests that require significant time to run.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport unittest\nfrom cupy import testing\n\nclass TestMyFunc(unittest.TestCase):\n    ...\n\n    @testing.slow\n    def test_my_slow_func(self):\n        ...\n```\n\n----------------------------------------\n\nTITLE: Building CuPy for ROCm\nDESCRIPTION: Environment setup and installation command for building CuPy with ROCm support.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\n$ export CUPY_INSTALL_USE_HIP=1\n$ export ROCM_HOME=/opt/rocm\n$ export HCC_AMDGPU_TARGET=gfx906\n$ pip install cupy\n```\n\n----------------------------------------\n\nTITLE: Upgrading CuPy\nDESCRIPTION: Upgrades CuPy to the latest version using pip.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install -U cupy\n```\n\n----------------------------------------\n\nTITLE: Running pre-commit Checks on Code\nDESCRIPTION: Command to run pre-commit checks on all files to verify they meet CuPy's coding standards.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pre-commit run -a\n```\n\n----------------------------------------\n\nTITLE: Performing Half-precision FFT using CuPy's Experimental XtPlanNd API in Python\nDESCRIPTION: This code demonstrates the use of CuPy's experimental XtPlanNd API for half-precision FFT. It creates a plan for a 3D FFT, executes it on GPU, and compares the result with a NumPy FFT implementation after necessary type conversions.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/fft.rst#2025-04-19_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport cupy as cp\nimport numpy as np\n\n\nshape = (1024, 256, 256)  # input array shape\nidtype = odtype = edtype = 'E'  # = numpy.complex32 in the future\n\n# store the input/output arrays as fp16 arrays twice as long, as complex32 is not yet available\na = cp.random.random((shape[0], shape[1], 2*shape[2])).astype(cp.float16)\nout = cp.empty_like(a)\n\n# FFT with cuFFT\nplan = cp.cuda.cufft.XtPlanNd(shape[1:],\n                              shape[1:], 1, shape[1]*shape[2], idtype,\n                              shape[1:], 1, shape[1]*shape[2], odtype,\n                              shape[0], edtype,\n                              order='C', last_axis=-1, last_size=None)\n\nplan.fft(a, out, cp.cuda.cufft.CUFFT_FORWARD)\n\n# FFT with NumPy\na_np = cp.asnumpy(a).astype(np.float32)  # upcast\na_np = a_np.view(np.complex64)\nout_np = np.fft.fftn(a_np, axes=(-2,-1))\nout_np = np.ascontiguousarray(out_np).astype(np.complex64)  # downcast\nout_np = out_np.view(np.float32)\nout_np = out_np.astype(np.float16)\n\n# don't worry about accuracy for now, as we probably lost a lot during casting\nprint('ok' if cp.mean(cp.abs(out - cp.asarray(out_np))) < 0.1 else 'not ok')\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy Core Package from Conda-Forge\nDESCRIPTION: Installs the minimal CuPy core package from conda-forge, without CUDA dependencies.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ conda install -c conda-forge cupy-core\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy Pre-release Version\nDESCRIPTION: Installs a pre-release version of CuPy using additional pip options.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install cupy-cuda11x --pre -U -f https://pip.cupy.dev/pre\n```\n\n----------------------------------------\n\nTITLE: Windows Git Symbolic Links Setup\nDESCRIPTION: Git command for enabling symbolic link support on Windows for CuPy development.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ngit config --global core.symlinks true\n```\n\n----------------------------------------\n\nTITLE: Checking Installed CuPy Packages\nDESCRIPTION: Lists installed CuPy packages using pip freeze command.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ pip freeze | grep cupy\n```\n\n----------------------------------------\n\nTITLE: Ubuntu Legacy GCC Setup\nDESCRIPTION: Commands for setting up g++-6 and NVCC on Ubuntu 16.04 for CuPy build.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo add-apt-repository ppa:ubuntu-toolchain-r/test\n$ sudo apt update\n$ sudo apt install g++-6\n$ export NVCC=\"nvcc --compiler-bindir gcc-6\"\n```\n\n----------------------------------------\n\nTITLE: Reinstalling CuPy\nDESCRIPTION: Uninstalls and then reinstalls CuPy, bypassing pip's cache to ensure a fresh installation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n$ pip uninstall cupy\n$ pip install cupy --no-cache-dir\n```\n\n----------------------------------------\n\nTITLE: ROCm Docker Container\nDESCRIPTION: Command to run CuPy ROCm Docker container with GPU access.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run -it --device=/dev/kfd --device=/dev/dri --group-add video cupy/cupy-rocm\n```\n\n----------------------------------------\n\nTITLE: CuPy Academic Citation Format\nDESCRIPTION: BibTeX citation format for the CuPy paper published in the Proceedings of Workshop on Machine Learning Systems at NIPS 2017.\nSOURCE: https://github.com/cupy/cupy/blob/main/README.md#2025-04-19_snippet_1\n\nLANGUAGE: BibTeX\nCODE:\n```\n@inproceedings{cupy_learningsys2017,\n  author       = \"Okuta, Ryosuke and Unno, Yuya and Nishino, Daisuke and Hido, Shohei and Loomis, Crissman\",\n  title        = \"CuPy: A NumPy-Compatible Library for NVIDIA GPU Calculations\",\n  booktitle    = \"Proceedings of Workshop on Machine Learning Systems (LearningSys) in The Thirty-first Annual Conference on Neural Information Processing Systems (NIPS)\",\n  year         = \"2017\",\n  url          = \"http://learningsys.org/nips17/assets/papers/paper_16.pdf\"\n}\n```\n\n----------------------------------------\n\nTITLE: Importing CuPy SciPy Linear Algebra Module\nDESCRIPTION: This snippet shows how to import the cupyx.scipy.linalg module. This module provides GPU-accelerated linear algebra functions similar to those in SciPy's linalg module.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_linalg.rst#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. module:: cupyx.scipy.linalg\n```\n\n----------------------------------------\n\nTITLE: Cloning CuPy Repository on Windows\nDESCRIPTION: Command to clone CuPy repository with recursive flag to include submodules on Windows.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ngit clone --recursive https://github.com/cupy/cupy.git\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for CuPy User Guide in reStructuredText\nDESCRIPTION: This snippet defines the structure of the CuPy user guide using reStructuredText directives. It sets up a table of contents with various sections related to CuPy usage and features.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/index.rst#2025-04-19_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n\n   basic\n   kernel\n   cuda_api\n   fft\n   memory\n   performance\n   interoperability\n   difference\n   compatibility\n```\n\n----------------------------------------\n\nTITLE: Installing CuPy in Editable Mode\nDESCRIPTION: Instructions for installing CuPy in development mode using pip's editable flag. Note that Cython source modifications require reinstallation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install -e .\n```\n\n----------------------------------------\n\nTITLE: Setting GPU Limit for Tests\nDESCRIPTION: Commands to limit the number of GPUs used for testing to avoid failures on systems with fewer GPUs.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ export CUPY_TEST_GPU_LIMIT=1\n$ python -m pytest path/to/gpu/test.py\n```\n\n----------------------------------------\n\nTITLE: Setting up CuPy API Reference Documentation Structure with reStructuredText\nDESCRIPTION: Defines the structure of the CuPy API reference documentation using reStructuredText directives. It includes section references, module specification, and a table of contents pointing to different parts of the API documentation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/index.rst#2025-04-19_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. _cupy_reference:\n\n*************\nAPI Reference\n*************\n\n* :ref:`genindex`\n* :ref:`modindex`\n\n----\n\n.. currentmodule:: cupy\n\n..\n  For NumPy/SciPy-compatible APIs (ndarray, ufunc, routines, scipy),\n  omit the module name prefix in the API list, following the convention in\n  NumPy/SciPy documentation.\n  For CuPy-specific APIs, use fully-qualified names.\n\n.. toctree::\n   :maxdepth: 2\n\n   ndarray\n   ufunc\n   routines\n   scipy\n   ext\n   cuda\n   kernel\n   distributed\n   environment\n   comparison\n   array_api\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests\nDESCRIPTION: Command to run all unit tests using pytest.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ python -m pytest\n```\n\n----------------------------------------\n\nTITLE: Redirecting to scipy_signal Documentation in reStructuredText\nDESCRIPTION: This snippet uses the reStructuredText directive to create a document link that redirects to the scipy_signal documentation page. The :orphan: directive at the beginning indicates that this document should not be included in the table of contents.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/signal.rst#2025-04-19_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n:orphan:\n\nThis document has been moved to :doc:`scipy_signal`.\n```\n\n----------------------------------------\n\nTITLE: Float to Integer Casting Differences in CuPy vs NumPy\nDESCRIPTION: Demonstrates different casting behaviors from float to integer between CuPy and NumPy, particularly for negative floats to unsigned integers and infinity to integers.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/user_guide/difference.rst#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> np.array([-1], dtype=np.float32).astype(np.uint32)\narray([4294967295], dtype=uint32)\n>>> cupy.array([-1], dtype=np.float32).astype(np.uint32)\narray([0], dtype=uint32)\n\n>>> np.array([float('inf')], dtype=np.float32).astype(np.int32)\narray([-2147483648], dtype=int32)\n>>> cupy.array([float('inf')], dtype=np.float32).astype(np.int32)\narray([2147483647], dtype=int32)\n```\n\n----------------------------------------\n\nTITLE: Writing Multi-GPU Tests with Decorators\nDESCRIPTION: Example of using the multi_gpu decorator to create tests that require multiple GPUs.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport unittest\nfrom cupy import testing\n\nclass TestMyFunc(unittest.TestCase):\n    ...\n\n    @testing.multi_gpu(2)  # specify the number of required GPUs here\n    def test_my_two_gpu_func(self):\n        ...\n```\n\n----------------------------------------\n\nTITLE: Running Tests without cuDNN Dependency\nDESCRIPTION: Command to run tests while skipping those that require cuDNN.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ python -m pytest path/to/your/test.py -m='not cudnn'\n```\n\n----------------------------------------\n\nTITLE: Commenting on Include Directory Behavior in CuPy Project (Markdown)\nDESCRIPTION: This snippet describes the behavior of the 'include' directory in the CuPy project. It explains that all files and directories in this location will be copied to both source (sdist) and binary (wheel) distributions, with the exception of hidden items (those starting with a dot). It also refers to 'setup.py' for more detailed information.\nSOURCE: https://github.com/cupy/cupy/blob/main/cupy/_core/include/cupy/README.md#2025-04-19_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# \"include\" directory\n\nAll files and directories in this directory will be copied to the distribution (sdist and wheel).\nNote that items starting with `.` (e.g., `.git`) are excluded.\nSee `setup.py` for details.\n```\n\n----------------------------------------\n\nTITLE: Setting NVCC with ccache\nDESCRIPTION: Command to configure NVCC environment variable to use ccache for faster rebuilds. Requires ccache v3.4 or later.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n$ export NVCC='ccache nvcc'\n```\n\n----------------------------------------\n\nTITLE: Array Class Path Reference in RST\nDESCRIPTION: ReStructuredText directive specifying the current module path for the Array class documentation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/array_api_array.rst#2025-04-19_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: cupy.array_api._array_object\n```\n\n----------------------------------------\n\nTITLE: Limiting CUDA Architecture Targets\nDESCRIPTION: Example of using CUPY_NVCC_GENERATE_CODE to limit build targets to specific architectures (P100 and V100) for faster builds.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n$ export CUPY_NVCC_GENERATE_CODE=arch=compute_60,code=sm_60;arch=compute_70,code=sm_70\n```\n\n----------------------------------------\n\nTITLE: CuPy RST Documentation Structure\nDESCRIPTION: RestructuredText markup defining the documentation structure for deprecated CuPy APIs. Contains sections for DLPack helper, time range functions, timing helper, profiler and device synchronization detection.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/_deprecated.rst#2025-04-19_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n:orphan:\n\n.. This page is to generate documentation for deprecated APIs removed from the\n   public table of contents.\n\nDLPack helper\n-------------\n\n.. autosummary::\n   :toctree: generated/\n\n   cupy.fromDlpack\n\nTime range\n----------\n\n.. autosummary::\n   :toctree: generated/\n\n   cupy.prof.TimeRangeDecorator\n   cupy.prof.time_range\n\nTiming helper\n-------------\n\n.. autosummary::\n   :toctree: generated/\n\n   cupyx.time.repeat\n\nProfiler\n--------\n\n.. autosummary::\n   :toctree: generated/\n\n   cupy.cuda.profile\n   cupy.cuda.profiler.start\n   cupy.cuda.profiler.stop\n\nDevice synchronization detection\n--------------------------------\n\n.. warning::\n\n   These APIs are deprecated in CuPy v10 and will be removed in future releases.\n\n.. autosummary::\n   :toctree: generated/\n\n   cupyx.allow_synchronize\n   cupyx.DeviceSynchronized\n```\n\n----------------------------------------\n\nTITLE: Running K-means Demo in Non-GUI Environment\nDESCRIPTION: Command to run the K-means demo in environments without matplotlib renderers by setting the MPLBACKEND environmental variable to Agg.\nSOURCE: https://github.com/cupy/cupy/blob/main/examples/kmeans/README.md#2025-04-19_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nMPLBACKEND=Agg python kmeans.py ...\n```\n\n----------------------------------------\n\nTITLE: Module Declaration in RST\nDESCRIPTION: ReStructuredText directive declaring the cupyx.scipy.interpolate module documentation\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_interpolate.rst#2025-04-19_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. module:: cupyx.scipy.interpolate\n```\n\n----------------------------------------\n\nTITLE: Running Specific Test Directories\nDESCRIPTION: Commands to run tests from specific directories such as CuPy tests or installation tests.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ python -m pytest tests/cupy_tests     # to just run tests of CuPy\n$ python -m pytest tests/install_tests  # to just run tests of installation modules\n```\n\n----------------------------------------\n\nTITLE: CuPy Class Documentation Template Structure\nDESCRIPTION: A Jinja2 template that defines the structure for CuPy class documentation. It organizes documentation into sections for special methods, ordinary methods, and attributes, using automethod and autoattribute directives to automatically generate API documentation from docstrings.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/_templates/autosummary/class.rst#2025-04-19_snippet_0\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ fullname }}\n{{ underline }}\n\n.. currentmodule:: {{ module }}\n\n.. autoclass:: {{ objname }}\n\n   ..\n      Methods\n\n{% block methods %}\n\n   .. rubric:: Methods\n\n   ..\n      Special methods\n\n{% for item in ('__call__', '__enter__', '__exit__', '__getitem__', '__setitem__', '__len__', '__next__', '__iter__', '__copy__') %}\n{% if item in all_methods or item in all_attributes %}\n   .. automethod:: {{ item }}\n{% endif %}\n{%- endfor %}\n\n   ..\n      Ordinary methods\n\n{% for item in methods %}\n{% if item not in ('__init__',) %}\n   .. automethod:: {{ item }}\n{% endif %}\n{%- endfor %}\n\n   ..\n      Special methods\n\n{% for item in ('__eq__', '__ne__', '__lt__', '__le__', '__gt__', '__ge__', '__nonzero__', '__bool__') %}\n{% if item in all_methods %}\n   .. automethod:: {{ item }}\n{% endif %}\n{%- endfor %}\n{% endblock %}\n\n   ..\n      Attributes\n\n{% block attributes %} {% if attributes %}\n\n   .. rubric:: Attributes\n\n{% for item in attributes %}\n   .. autoattribute:: {{ item }}\n{%- endfor %}\n{% endif %} {% endblock %}\n```\n\n----------------------------------------\n\nTITLE: Structuring Documentation with reStructuredText\nDESCRIPTION: Defines the main documentation structure using reStructuredText directives. Sets up module reference and creates hierarchical documentation sections with table of contents trees (toctree).\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/index.rst#2025-04-19_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. module:: cupy\n\n.. toctree::\n   :maxdepth: 2\n\n   overview\n   install\n   user_guide/index\n   reference/index\n\n.. toctree::\n   :maxdepth: 2\n   :caption: Development\n\n   contribution\n\n.. toctree::\n   :maxdepth: 2\n   :caption: Misc Notes\n\n   upgrade\n   license\n```\n\n----------------------------------------\n\nTITLE: Stream Device Management Example in CuPy\nDESCRIPTION: Example demonstrating stream creation and device handling behavior in CuPy v9 and earlier, where using a stream created on one device while on another device would raise an error.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/upgrade.rst#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport cupy\n\nwith cupy.cuda.Device(0):\n    # Create a stream on device 0.\n    s0 = cupy.cuda.Stream()\n\nwith cupy.cuda.Device(1):\n    with s0:\n        # Try to use the stream on device 1\n        cupy.arange(10)  # -> CUDA_ERROR_INVALID_HANDLE: invalid resource handle\n```\n\n----------------------------------------\n\nTITLE: Defining CuPy Array Padding Function in reStructuredText\nDESCRIPTION: This snippet defines the 'pad' function in the CuPy module using reStructuredText directives. It sets up the current module and creates an autosummary for the 'pad' function, which will generate detailed documentation in a separate file.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/pad.rst#2025-04-19_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. currentmodule:: cupy\n.. autosummary::\n   :toctree: generated/\n\n   pad\n```\n\n----------------------------------------\n\nTITLE: Grid-based Multivariate Interpolation Documentation\nDESCRIPTION: RST autosummary directive listing interpolation functions for grid-based data\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/scipy_interpolate.rst#2025-04-19_snippet_5\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   :toctree: generated/\n\n   interpn\n   RegularGridInterpolator\n```\n\n----------------------------------------\n\nTITLE: Cleaning Cython Generated Files\nDESCRIPTION: Command to clean generated C++ and shared object files when modifying Cython .pxd files.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ git clean -fdx\n```\n\n----------------------------------------\n\nTITLE: Setting cuDNN Environment Variables\nDESCRIPTION: Environment variable configuration for custom cuDNN installation directory.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n$ export CFLAGS=-I/path/to/cudnn/include\n$ export LDFLAGS=-L/path/to/cudnn/lib\n$ export LD_LIBRARY_PATH=/path/to/cudnn/lib:$LD_LIBRARY_PATH\n```\n\n----------------------------------------\n\nTITLE: Installing cuDNN Files\nDESCRIPTION: Commands for copying cuDNN header and library files to the CUDA installation directory.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/install.rst#2025-04-19_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n$ cp /path/to/cudnn.h $CUDA_PATH/include\n$ cp /path/to/libcudnn.so* $CUDA_PATH/lib64\n```\n\n----------------------------------------\n\nTITLE: Installing pre-commit for Code Checking\nDESCRIPTION: Command to install pre-commit tool for checking code compliance with CuPy's coding standards.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install pre-commit\n```\n\n----------------------------------------\n\nTITLE: Installing pre-commit Git Hook\nDESCRIPTION: Command to install pre-commit as a Git hook to automatically check code on commit.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/contribution.rst#2025-04-19_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ pre-commit install\n```\n\n----------------------------------------\n\nTITLE: Defining Baseline API Dependencies for CuPy\nDESCRIPTION: Specifies the versions of NumPy and SciPy that must match the Baseline API version documented in the CuPy Installation Guide. These requirements ensure compatibility with the documented API.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/requirements.txt#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n# These requirements must match with the Baseline API version documented in the Installation Guide.\nnumpy==2.1.*\nscipy==1.14.*\n```\n\n----------------------------------------\n\nTITLE: Array Class Documentation Reference in RST\nDESCRIPTION: ReStructuredText autosummary directive for generating Array class documentation.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/source/reference/array_api_array.rst#2025-04-19_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   :toctree: generated/\n\n   Array\n```\n\n----------------------------------------\n\nTITLE: Specifying Sphinx and Documentation Dependencies for CuPy\nDESCRIPTION: Defines the exact versions of Sphinx, pydata-sphinx-theme, and sphinx-copybutton required for building CuPy documentation. Includes a TODO note about updating pydata-sphinx-theme once a specific issue is resolved.\nSOURCE: https://github.com/cupy/cupy/blob/main/docs/requirements.txt#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nsphinx==5.3.0\n# TODO(kmaehashi): Bump pydata-sphinx-theme when https://github.com/pydata/pydata-sphinx-theme/issues/1161 closed\npydata_sphinx_theme==0.11.0\nsphinx-copybutton==0.5.1\n```"
  }
]