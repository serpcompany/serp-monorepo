[
  {
    "owner": "axiomhq",
    "repo": "docs",
    "content": "TITLE: Configuring OpenTelemetry Tracing for Axiom in .NET\nDESCRIPTION: This snippet shows the tracing.cs file, which sets up OpenTelemetry instrumentation, configures the OTLP exporter for Axiom, and initializes the ASP.NET Core SDK with automatic instrumentation capabilities.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing OpenTelemetry;\nusing OpenTelemetry.Resources;\nusing OpenTelemetry.Trace;\nusing System;\nusing System.Diagnostics;\nusing System.Reflection;\n\n// Class to configure OpenTelemetry tracing\npublic static class TracingConfiguration\n{\n    // Declare an ActivitySource for creating tracing activities\n    private static readonly ActivitySource ActivitySource = new(\"MyCustomActivitySource\");\n\n    // Configure OpenTelemetry with custom settings and instrumentation\n    public static void ConfigureOpenTelemetry()\n    {\n        // Retrieve the service name and version from the executing assembly metadata\n        var serviceName = Assembly.GetExecutingAssembly().GetName().Name ?? \"UnknownService\";\n        var serviceVersion = Assembly.GetExecutingAssembly().GetName().Version?.ToString() ?? \"UnknownVersion\";\n\n        // Set up the tracer provider with various configurations\n        Sdk.CreateTracerProviderBuilder()\n            .SetResourceBuilder(\n                // Set resource attributes including service name and version\n                ResourceBuilder.CreateDefault().AddService(serviceName, serviceVersion: serviceVersion)\n                .AddAttributes(new[] { new KeyValuePair<string, object>(\"environment\", \"development\") }) // Additional attributes\n                .AddTelemetrySdk() // Add telemetry SDK information to the traces\n                .AddEnvironmentVariableDetector()) // Detect resource attributes from environment variables\n            .AddSource(ActivitySource.Name) // Add the ActivitySource defined above\n            .AddAspNetCoreInstrumentation() // Add automatic instrumentation for ASP.NET Core\n            .AddHttpClientInstrumentation() // Add automatic instrumentation for HttpClient requests\n            .AddOtlpExporter(options => // Configure the OTLP exporter\n            {\n                options.Endpoint = new Uri(\"https://api.axiom.co/v1/traces\"); // Set the endpoint for the exporter\n                options.Protocol = OpenTelemetry.Exporter.OtlpExportProtocol.HttpProtobuf; // Set the protocol\n                options.Headers = \"Authorization=Bearer API_TOKEN, X-Axiom-Dataset=DATASET\"; // Update API token and dataset\n            })\n            .Build(); // Build the tracer provider\n    }\n\n    // Method to start a new tracing activity with an optional activity kind\n    public static Activity? StartActivity(string activityName, ActivityKind kind = ActivityKind.Internal)\n    {\n        // Starts and returns a new activity if sampling allows it, otherwise returns null\n        return ActivitySource.StartActivity(activityName, kind);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Core Application Logic with OpenTelemetry in .NET\nDESCRIPTION: This snippet shows the program.cs file, which sets up a simple web server using ASP.NET Core with OpenTelemetry instrumentation. It includes a /rolldice endpoint that demonstrates tracing and logging.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Logging;\nusing System;\nusing System.Globalization;\n\n// Set up the web application builder\nvar builder = WebApplication.CreateBuilder(args);\n// Configure OpenTelemetry for detailed tracing information\nTracingConfiguration.ConfigureOpenTelemetry();\nvar app = builder.Build();\n\n// Map the GET request for '/rolldice/{player?}' to a handler\napp.MapGet(\"/rolldice/{player?}\", (ILogger<Program> logger, string? player) =>\n{\n    // Start a manual tracing activity\n    using var activity = TracingConfiguration.StartActivity(\"HandleRollDice\");\n\n    // Call the RollDice function to get a dice roll result\n    var result = RollDice();\n\n    if (activity != null)\n    {\n        // Add detailed information to the tracing activity for debugging and monitoring\n        activity.SetTag(\"player.name\", player ?? \"anonymous\"); // Tag the player's name, default to 'anonymous' if not provided\n        activity.SetTag(\"dice.rollResult\", result); // Tag the result of the dice roll\n        activity.SetTag(\"operation.success\", true); // Flag the operation as successful\n        activity.SetTag(\"custom.attribute\", \"Additional detail here\"); // Add a custom attribute for potential further detail\n    }\n\n    // Log the dice roll event\n    LogRollDice(logger, player, result);\n\n    // Retur the dice roll result as a string\n    return result.ToString(CultureInfo.InvariantCulture);\n});\n\n// Start the web application\napp.Run();\n\n// Log function to log the result of a dice roll\nvoid LogRollDice(ILogger logger, string? player, int result)\n{\n    // Log message varies based on whether a player's name is provided\n    if (string.IsNullOrEmpty(player))\n    {\n        // Log for an anonymous player\n        logger.LogInformation(\"Anonymous player is rolling the dice: {result}\", result);\n    }\n    else\n    {\n        // Log for a named player\n        logger.LogInformation(\"{player} is rolling the dice: {result}\", player, result);\n    }\n}\n\n// Function to roll a dice and return a random number between 1 and 6\nint RollDice()\n{\n    // Use the shared instance of Random for thread safety\n    return Random.Shared.Next(1, 7);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Tracing in Node.js\nDESCRIPTION: Implementation of OpenTelemetry tracing for Node.js applications. Sets up automatic instrumentation and configures OTLP HTTP exporter to send traces to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/opentelemetry.mdx#2025-04-22_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nconst opentelemetry = require('@opentelemetry/sdk-node');\nconst { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');\nconst { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-proto');\nconst { BatchSpanProcessor } = require('@opentelemetry/sdk-trace-base');\nconst { Resource } = require('@opentelemetry/resources');\nconst { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');\n\n// Initialize OTLP trace exporter with the URL and headers for the Axiom API\nconst traceExporter = new OTLPTraceExporter({\n  url: 'https://api.axiom.co/v1/traces', // Axiom API endpoint for trace data\n  headers: {\n    'Authorization': 'Bearer API_TOKEN', // Replace API_TOKEN with your actual API token\n    'X-Axiom-Dataset': 'DATASET_NAME' // Replace DATASET_NAME with your dataset\n  },\n});\n\n// Define the resource attributes, in this case, setting the service name for the traces\nconst resource = new Resource({\n  [SemanticResourceAttributes.SERVICE_NAME]: 'node traces', // Name for the tracing service\n});\n\n// Create a NodeSDK instance with the configured span processor, resource, and auto-instrumentations\nconst sdk = new opentelemetry.NodeSDK({\n  spanProcessor: new BatchSpanProcessor(traceExporter), // Use BatchSpanProcessor for batching and sending traces\n  resource: resource, // Attach the defined resource to provide additional context\n  instrumentations: [getNodeAutoInstrumentations()], // Automatically instrument common Node.js modules\n});\n\n// Start the OpenTelemetry SDK\nsdk.start();\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Exporter for Axiom in Cloudflare Workers\nDESCRIPTION: Configuration example for exporting OpenTelemetry data to Axiom in a Cloudflare Workers script.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\nconst config = (env) => ({\n  exporter: {\n    url: 'https://api.axiom.co/v1/traces',\n    headers: {\n      'Authorization': `Bearer ${env.AXIOM_API_TOKEN}`,\n      'X-Axiom-Dataset': `${env.AXIOM_DATASET}`\n    },\n  },\n  service: { name: 'axiom-cloudflare-workers' },\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Spans with OpenTelemetry in Node.js\nDESCRIPTION: This code snippet shows how to create and manage spans in a Node.js application using OpenTelemetry. It demonstrates wrapping code blocks with spans, including error handling and span termination.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nconst span = tracer.startSpan('operation_name');\ntry {\n  // Your code here\n  span.end();\n} catch (error) {\n  span.recordException(error);\n  span.end();\n}\n```\n\n----------------------------------------\n\nTITLE: Converting SQL Filtering and Projection to APL\nDESCRIPTION: Demonstrates how to translate a SQL query with column selection and filtering to APL using 'where' and 'project' operators.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT method, status, geo.country\nFROM [Sample-http-logs]\nWHERE resp_header_size_bytes >= 18;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where resp_header_size_bytes >= 18\n| project method, status, ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Configuring Filebeat DaemonSet for Kubernetes Log Ingestion to Axiom\nDESCRIPTION: This YAML configuration sets up a Filebeat DaemonSet to collect logs from Kubernetes containers and send them to Axiom. It includes necessary RBAC permissions, ConfigMap for Filebeat settings, and DaemonSet specification with environment variables for Axiom integration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/kubernetes.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: filebeat\n  namespace: kube-system\n  labels:\n    k8s-app: filebeat\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: filebeat\n  labels:\n    k8s-app: filebeat\nrules:\n  - apiGroups: [''] # \"\" indicates the core API group\n    resources:\n      - namespaces\n      - pods\n      - nodes\n    verbs:\n      - get\n      - watch\n      - list\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: filebeat\nsubjects:\n  - kind: ServiceAccount\n    name: filebeat\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: filebeat\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion: v1\ndata:\n  filebeat.yml: |-\n    filebeat.autodiscover:\n      providers:\n        - type: kubernetes\n          node: ${NODE_NAME}\n          hints.enabled: true\n          hints.default_config:\n            type: container\n            paths:\n              - /var/log/containers/*${data.kubernetes.container.id}.log\n    allow_older_versions: true\n    processors:\n      - add_cloud_metadata:\n    output.elasticsearch:\n      hosts: ['${AXIOM_HOST}/v1/datasets/${AXIOM_DATASET_NAME}/elastic']\n      api_key: 'axiom:${AXIOM_API_TOKEN}'\n    setup.ilm.enabled: false\nkind: ConfigMap\nmetadata:\n  annotations: {}\n  labels:\n    k8s-app: filebeat\n  name: filebeat-config\n  namespace: kube-system\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: filebeat\n  name: filebeat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: filebeat\n  template:\n    metadata:\n      annotations: {}\n      labels:\n        k8s-app: filebeat\n    spec:\n      containers:\n        - args:\n            - -c\n            - /etc/filebeat.yml\n            - -e\n          env:\n            - name: AXIOM_HOST\n              value: https://api.axiom.co:443\n            - name: AXIOM_DATASET_NAME\n              value: my-dataset\n            - name: AXIOM_API_TOKEN\n              value: xaat-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n            - name: NODE_NAME\n              valueFrom:\n                fieldRef:\n                  apiVersion: v1\n                  fieldPath: spec.nodeName\n          image: docker.elastic.co/beats/filebeat-oss:8.11.1\n          imagePullPolicy: IfNotPresent\n          name: filebeat\n          resources:\n            limits:\n              memory: 200Mi\n            requests:\n              cpu: 100m\n              memory: 100Mi\n          securityContext:\n            runAsUser: 0\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          volumeMounts:\n            - mountPath: /etc/filebeat.yml\n              name: config\n              readOnly: true\n              subPath: filebeat.yml\n            - mountPath: /usr/share/filebeat/data\n              name: data\n            - mountPath: /var/lib/docker/containers\n              name: varlibdockercontainers\n              readOnly: true\n            - mountPath: /var/log\n              name: varlog\n              readOnly: true\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      serviceAccount: filebeat\n      serviceAccountName: filebeat\n      terminationGracePeriodSeconds: 30\n      volumes:\n        - configMap:\n            defaultMode: 416\n            name: filebeat-config\n          name: config\n        - hostPath:\n            path: /var/lib/docker/containers\n            type: ''\n          name: varlibdockercontainers\n        - hostPath:\n            path: /var/log\n            type: ''\n          name: varlog\n        - hostPath:\n            path: /var/lib/filebeat-data\n            type: ''\n          name: data\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 1\n    type: RollingUpdate\n```\n\n----------------------------------------\n\nTITLE: Processing S3 Log Files and Sending to Axiom using Python Lambda\nDESCRIPTION: This Lambda function is triggered when a new log file is uploaded to an S3 bucket. It processes the log data based on the file format (CSV, TXT, LOG, NDJSON, or JSONL) and sends it to Axiom using the Axiom API. The function requires environment variables for the Axiom dataset name and API token.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-s3.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport json\nimport boto3\nimport requests\nimport csv\nimport io\nimport ndjson\n\ndef lambda_handler(event, context):\n    # Extract the bucket name and object key from the event\n    bucket = event['Records'][0]['s3']['bucket']['name']\n    key = event['Records'][0]['s3']['object']['key']\n\n    try:\n        # Fetch the log file from S3\n        s3 = boto3.client('s3')\n        obj = s3.get_object(Bucket=bucket, Key=key)\n    except Exception as e:\n        print(f\"Error fetching from S3: {str(e)}\")\n        raise e\n\n    # Read the log data from the S3 object\n    log_data = obj['Body'].read().decode('utf-8')\n\n    # Determine the file format and parse accordingly\n    file_extension = os.path.splitext(key)[1].lower()\n\n    if file_extension == '.csv':\n        csv_data = csv.DictReader(io.StringIO(log_data))\n        json_logs = list(csv_data)\n    elif file_extension == '.txt' or file_extension == '.log':\n        log_lines = log_data.strip().split(\"\\n\")\n        json_logs = [{'message': line} for line in log_lines]\n    elif file_extension == '.ndjson' or file_extension == '.jsonl':\n        json_logs = ndjson.loads(log_data)\n    else:\n        print(f\"Unsupported file format: {file_extension}\")\n        return\n\n    # Prepare Axiom API request\n    dataset_name = os.environ['DATASET_NAME']\n    axiom_api_url = f\"https://api.axiom.co/v1/datasets/{dataset_name}/ingest\"\n    api_token = os.environ['API_TOKEN']\n    axiom_headers = {\n        \"Authorization\": f\"Bearer {api_token}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    # Send logs to Axiom\n    for log in json_logs:\n        try:\n            response = requests.post(axiom_api_url, headers=axiom_headers, json=log)\n            if response.status_code != 200:\n                print(f\"Failed to send log to Axiom: {response.text}\")\n        except Exception as e:\n            print(f\"Error sending to Axiom: {str(e)}. Log: {log}\")\n\n    print(f\"Processed {len(json_logs)} log entries\")\n```\n\n----------------------------------------\n\nTITLE: Defining ECS Task with FireLens for Fluentd\nDESCRIPTION: This JSON snippet shows how to configure an ECS task definition using Fluentd with FireLens. It specifies the log router container using Fluentd and sets up the application container to use the FireLens log driver with forward configuration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-firelens.mdx#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"family\": \"fluentdTaskDefinition\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"log_router\",\n      \"image\": \"YOUR_ECR_REPO_URI:latest\",\n      \"essential\": true,\n      \"memory\": 512,\n      \"cpu\": 256,\n      \"firelensConfiguration\": {\n        \"type\": \"fluentd\",\n        \"options\": {\n          \"config-file-type\": \"file\",\n          \"config-file-value\": \"/path/to/your/fluentd.conf\"\n        }\n      }\n    },\n    {\n      \"name\": \"myApp\",\n      \"image\": \"my-app-image\",\n      \"essential\": true,\n      \"memory\": 512,\n      \"cpu\": 256,\n      \"logConfiguration\": {\n        \"logDriver\": \"awsfirelens\",\n        \"options\": {\n          \"Name\": \"forward\",\n          \"Host\": \"log_router\",\n          \"Port\": \"24224\"\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Vector DaemonSet for Kubernetes Log Ingestion to Axiom\nDESCRIPTION: This YAML configuration sets up a Vector DaemonSet to collect logs from Kubernetes containers and send them to Axiom. It includes RBAC permissions, ConfigMap for Vector settings, and DaemonSet specification with environment variables for Axiom integration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/kubernetes.mdx#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: vector\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: vector\nrules:\n  - apiGroups: [\"\"]\n    resources:\n      - pods\n      - nodes\n      - namespaces\n    verbs:\n      - get\n      - list\n      - watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: vector\nsubjects:\n  - kind: ServiceAccount\n    name: vector\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: vector\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: vector-config\n  namespace: kube-system\ndata:\n  vector.yml: |-\n    sources:\n      kubernetes_logs:\n        type: kubernetes_logs\n        self_node_name: ${VECTOR_SELF_NODE_NAME}\n    sinks:\n      axiom:\n        type: axiom\n        inputs:\n          - kubernetes_logs\n        compression: gzip\n        dataset: ${AXIOM_DATASET_NAME}\n        token: ${AXIOM_API_TOKEN}\n        healthcheck:\n          enabled: true\n          log_level: debug\n        logging:\n          level: debug\n        log_level: debug\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: vector\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: vector\n  template:\n    metadata:\n      labels:\n        name: vector\n    spec:\n      serviceAccountName: vector\n      containers:\n        - name: vector\n          image: timberio/vector:0.37.0-debian\n          args:\n            - --config-dir\n            - /etc/vector/\n          env:\n            - name: AXIOM_HOST\n              value: https://api.axiom.co:443\n            - name: AXIOM_DATASET_NAME\n              value: my-dataset\n            - name: AXIOM_API_TOKEN\n              value: xaat-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n            - name: VECTOR_SELF_NODE_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n          volumeMounts:\n            - name: config\n              mountPath: /etc/vector/vector.yml\n              subPath: vector-config.yml\n            - name: data-dir\n              mountPath: /var/lib/vector\n            - name: var-log\n              mountPath: /var/log\n              readOnly: true\n            - name: var-lib\n              mountPath: /var/lib\n              readOnly: true\n          resources:\n            limits:\n              memory: 500Mi\n            requests:\n              cpu: 200m\n              memory: 100Mi\n          securityContext:\n            runAsUser: 0\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n      volumes:\n        - name: config\n          configMap:\n            name: vector-config\n            items:\n              - key: vector.yml\n                path: vector-config.yml\n        - name: data-dir\n          hostPath:\n            path: /var/lib/vector\n            type: DirectoryOrCreate\n        - name: var-log\n          hostPath:\n            path: /var/log\n        - name: var-lib\n          hostPath:\n            path: /var/lib\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 1\n    type: RollingUpdate\n```\n\n----------------------------------------\n\nTITLE: Converting SQL SELECT with Filter to APL\nDESCRIPTION: Shows how to translate a simple SQL SELECT statement with a WHERE clause into APL syntax using the 'where' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM [Sample-http-logs]\nWHERE method = 'GET';\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where method == 'GET'\n```\n\n----------------------------------------\n\nTITLE: Ingesting and Querying Data with Axiom JS Library\nDESCRIPTION: Example of creating an Axiom client, ingesting data, and performing a query using the JS library.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/ingest.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Axiom } from '@axiomhq/js';\n\nasync function main() {\n    const axiom = new Axiom({\n        token: process.env.AXIOM_TOKEN\n    });\n\n    await axiom.ingest('my-dataset', [{ foo: 'bar' }]);\n\n    const res = await axiom.query(`['my-dataset'] | where foo == 'bar' | limit 100`);\n}\n```\n\n----------------------------------------\n\nTITLE: HTTP Server Implementation with OpenTelemetry\nDESCRIPTION: Complete HTTP server implementation with OpenTelemetry tracing integration, including request handlers and span management for distributed tracing.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_3\n\nLANGUAGE: go\nCODE:\n```\n// main.go\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"math/rand\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/signal\"\n\t\"time\"\n\n    // OpenTelemetry imports for tracing and observability.\n\t\"go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp\"\n\t\"go.opentelemetry.io/otel\"\n\t\"go.opentelemetry.io/otel/trace\"\n)\n\n// main function starts the application and handles run function errors.\nfunc main() {\n\tif err := run(); err != nil {\n\t\tlog.Fatalln(err)\n\t}\n}\n\n// run sets up signal handling, tracer initialization, and starts an HTTP server.\nfunc run() error {\n\t// Creating a context that listens for the interrupt signal from the OS.\n\tctx, stop := signal.NotifyContext(context.Background(), os.Interrupt)\n\tdefer stop()\n\n\t// Initializes tracing and returns a function to shut down OpenTelemetry cleanly.\n\totelShutdown, err := SetupTracer()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer func() {\n\t\tif shutdownErr := otelShutdown(ctx); shutdownErr != nil {\n\t\t\tlog.Printf(\"failed to shutdown OpenTelemetry: %v\", shutdownErr) // Log fatal errors during server shutdown\n\t\t}\n\t}()\n\n\t// Configuring the HTTP server settings.\n\tsrv := &http.Server{\n\t\tAddr:         \":8080\", // Server address\n\t\tBaseContext:  func(_ net.Listener) context.Context { return ctx },\n\t\tReadTimeout:  5 * time.Second, // Server read timeout\n\t\tWriteTimeout: 15 * time.Second, // Server write timeout\n\t\tHandler:      newHTTPHandler(), // HTTP handler\n\t}\n\n\t// Starting the HTTP server in a new goroutine.\n\tgo func() {\n\t\tif err := srv.ListenAndServe(); err != http.ErrServerClosed {\n\t\t\tlog.Fatalf(\"HTTP server ListenAndServe: %v\", err)\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal to gracefully shut down the server with a timeout context.\n\t<-ctx.Done()\n\tshutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cancel() // Ensures cancel function is called on exit\n\tif err := srv.Shutdown(shutdownCtx); err != nil {\n\t\tlog.Fatalf(\"HTTP server Shutdown: %v\", err)  // Log fatal errors during server shutdown\n\t}\n\n\treturn nil\n}\n\n// newHTTPHandler configures the HTTP routes and integrates OpenTelemetry.\nfunc newHTTPHandler() http.Handler {\n\tmux := http.NewServeMux() // HTTP request multiplexer\n\n\t// Wrapping the handler function with OpenTelemetry instrumentation.\n\thandleFunc := func(pattern string, handlerFunc func(http.ResponseWriter, *http.Request)) {\n\t\thandler := otelhttp.WithRouteTag(pattern, http.HandlerFunc(handlerFunc))\n\t\tmux.Handle(pattern, handler) // Associate pattern with handler\n\t}\n\n\t// Registering route handlers with OpenTelemetry instrumentation\n\thandleFunc(\"/rolldice\", rolldice)\n\thandleFunc(\"/roll_with_link\", rollWithLink)\n\n\thandler := otelhttp.NewHandler(mux, \"/\")\n\treturn handler\n}\n\n// rolldice handles the /rolldice route by generating a random dice roll.\nfunc rolldice(w http.ResponseWriter, r *http.Request) {\n\t_, span := otel.Tracer(\"example-tracer\").Start(r.Context(), \"rolldice\")\n\tdefer span.End()\n\n\t// Generating a random dice roll.\n\trandGen := rand.New(rand.NewSource(time.Now().UnixNano()))\n\troll := 1 + randGen.Intn(6)\n\n\t// Writing the dice roll to the response.\n\tfmt.Fprintf(w, \"Rolled a dice: %d\\n\", roll)\n}\n\n// rollWithLink handles the /roll_with_link route by creating a new span with a link to the parent span.\nfunc rollWithLink(w http.ResponseWriter, r *http.Request) {\n\tctx, span := otel.Tracer(\"example-tracer\").Start(r.Context(), \"roll_with_link\")\n\tdefer span.End()\n\n\t/**\n\t * Create a new span for rolldice with a link to the parent span.\n\t * This link helps correlate events that are related but not directly a parent-child relationship.\n\t */\n\trollDiceCtx, rollDiceSpan := otel.Tracer(\"example-tracer\").Start(ctx, \"rolldice\",\n\t\ttrace.WithLinks(trace.Link{\n\t\t\tSpanContext: span.SpanContext(),\n\t\t\tAttributes:  nil,\n\t\t}),\n\t)\n\tdefer rollDiceSpan.End()\n\n\t// Generating a random dice roll linked to the parent context.\n\trandGen := rand.New(rand.NewSource(time.Now().UnixNano()))\n\troll := 1 + randGen.Intn(6)\n\n\t// Writing the linked dice roll to the response.\n\tfmt.Fprintf(w, \"Dice roll result (with link): %d\\n\", roll)\n\n\t// Use the rollDiceCtx if needed.\n\t_ = rollDiceCtx\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry in Django\nDESCRIPTION: Configuration setup for OpenTelemetry in Django, including trace provider setup, OTLP exporter configuration, and Django instrumentation initialization.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# otel_config.py\nfrom opentelemetry import trace\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.instrumentation.django import DjangoInstrumentor\nfrom opentelemetry.sdk.resources import Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\ndef configure_opentelemetry():\n    resource = Resource(attributes={\"service.name\": \"your-django-app\"})\n    trace.set_tracer_provider(TracerProvider(resource=resource))\n    otlp_exporter = OTLPSpanExporter(\n        endpoint=\"https://api.axiom.co/v1/traces\",\n        headers={\"Authorization\": \"Bearer API_TOKEN\", \"X-Axiom-Dataset\": \"DATASET_NAME\"}\n    )\n    span_processor = BatchSpanProcessor(otlp_exporter)\n    trace.get_tracer_provider().add_span_processor(span_processor)\n    DjangoInstrumentor().instrument()\n```\n\n----------------------------------------\n\nTITLE: Flask Application with OpenTelemetry Integration\nDESCRIPTION: Python Flask application demonstrating OpenTelemetry integration with span linking and automatic instrumentation\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-python.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# app.py\n\nfrom flask import Flask\nfrom opentelemetry.instrumentation.flask import FlaskInstrumentor\nfrom opentelemetry import trace\nfrom random import randint\nimport exporter\n\n# Creating a Flask app instance\napp = Flask(__name__)\n\n# Automatically instruments Flask app to enable tracing\nFlaskInstrumentor().instrument_app(app)\n\n# Retrieving a tracer from the custom exporter\ntracer = exporter.service1_tracer\n\n@app.route(\"/rolldice\")\ndef roll_dice(parent_span=None):\n    # Starting a new span for the dice roll. If a parent span is provided, link to its span context.\n    with tracer.start_as_current_span(\"roll_dice_span\",\n          links=[trace.Link(parent_span.get_span_context())] if parent_span else None) as span:\n        # Spans can be created with zero or more Links to other Spans that are related.\n        # Links allow creating connections between different traces\n        return str(roll())\n\n@app.route(\"/roll_with_link\")\ndef roll_with_link():\n    # Starting a new 'parent_span' which may later link to other spans\n    with tracer.start_as_current_span(\"parent_span\") as parent_span:\n        # A common scenario is to correlate one or more traces with the current span.\n        # This can help in tracing and debugging complex interactions across different parts of the app.\n        result = roll_dice(parent_span)\n        return f\"Dice roll result (with link): {result}\"\n\ndef roll():\n    # Function to generate a random number between 1 and 6\n    return randint(1, 6)\n\nif __name__ == \"__main__\":\n    # Starting the Flask server on the specified PORT and enabling debug mode\n    app.run(port=8080, debug=True)\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenTelemetry Tracer in Cloudflare Workers\nDESCRIPTION: Code snippet to initialize an OpenTelemetry tracer in a Cloudflare Workers script.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nimport { trace } from '@opentelemetry/api';\nconst tracer = trace.getTracer('your-service-name');\n```\n\n----------------------------------------\n\nTITLE: APL join example with trace data\nDESCRIPTION: This example shows a practical implementation of a join operation in APL, correlating trace data with log data. It demonstrates joining two datasets on a common trace_id field to connect user activity with performance metrics.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/join-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| join kind=inner ['otel-demo-logs'] on trace_id\n```\n\n----------------------------------------\n\nTITLE: Dependencies in requirements.txt\nDESCRIPTION: List of required Python packages for OpenTelemetry integration to be included in requirements.txt file\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-python.mdx#2025-04-22_snippet_1\n\nLANGUAGE: txt\nCODE:\n```\nopentelemetry-api\nopentelemetry-sdk\nopentelemetry-instrumentation-flask\nopentelemetry-exporter-otlp\nFlask\n```\n\n----------------------------------------\n\nTITLE: Distinct City Count by Server Datacenter\nDESCRIPTION: This query counts the number of distinct cities for each server datacenter in the sample HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize cities = dcount(['geo.city']) by server_datacenter\n```\n\n----------------------------------------\n\nTITLE: Running Python App Commands\nDESCRIPTION: Commands to run the Python application on different operating systems\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-python.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython3 app.py\n```\n\nLANGUAGE: bash\nCODE:\n```\npy -3 app.py\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Collector for Axiom Integration\nDESCRIPTION: This YAML configuration sets up an OpenTelemetry collector to send data to Axiom using an HTTP exporter. It includes settings for compression, endpoint, and required headers for authentication and dataset specification.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/opentelemetry.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nexporters:\n  otlphttp:\n    compression: gzip\n    endpoint: https://api.axiom.co\n    headers:\n      authorization: Bearer API_TOKEN\n      x-axiom-dataset: DATASET_NAME\n\nservice:\n  pipelines:\n    traces:\n      receivers:\n        - otlp\n      processors:\n        - memory_limiter\n        - batch\n      exporters:\n        - otlphttp\n```\n\n----------------------------------------\n\nTITLE: Implementing Express.js Server with OpenTelemetry Tracing\nDESCRIPTION: Core application file that implements a web server using Express.js with OpenTelemetry tracing. Includes endpoints for dice rolling simulation and demonstrates span linking functionality.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n/*app.ts*/\n\n// Importing OpenTelemetry instrumentation for tracing\nimport './instrumentation';\nimport { trace, context } from '@opentelemetry/api';\n\n// Importing Express.js: A minimal and flexible Node.js web app framework\nimport express from 'express';\n\n// Setting up the server port: Use the PORT environment variable or default to 8080\nconst PORT = parseInt(process.env.PORT || '8080');\nconst app = express();\n\n// Get the tracer from the global tracer provider\nconst tracer = trace.getTracer('node-traces');\n\n/**\n * Function to generate a random number between min and max (inclusive).\n * @param min - The minimum number (inclusive).\n * @param max - The maximum number (exclusive).\n * @returns A random number between min and max.\n */\nfunction getRandomNumber(min: number, max: number): number {\n  return Math.floor(Math.random() * (max - min) + min);\n}\n\n// Defining a route handler for '/rolldice' that returns a random dice roll\napp.get('/rolldice', (req, res) => {\n  const span = trace.getSpan(context.active());\n  /**\n   * Spans can be created with zero or more Links to other Spans that are related.\n   * Links allow creating connections between different traces\n   */\n  const rollDiceSpan = tracer.startSpan('roll_dice_span', {\n    links: span ? [{ context: span.spanContext() }] : [],\n  });\n\n  // Set the rollDiceSpan as the currently active span\n  context.with(trace.setSpan(context.active(), rollDiceSpan), () => {\n    const diceRoll = getRandomNumber(1, 6).toString();\n    res.send(diceRoll);\n    rollDiceSpan.end();\n  });\n});\n\n// Defining a route handler for '/roll_with_link' that creates a parent span and calls '/rolldice'\napp.get('/roll_with_link', (req, res) => {\n  /**\n   * A common scenario is to correlate one or more traces with the current span.\n   * This can help in tracing and debugging complex interactions across different parts of the app.\n   */\n  const parentSpan = tracer.startSpan('parent_span');\n\n  // Set the parentSpan as the currently active span\n  context.with(trace.setSpan(context.active(), parentSpan), () => {\n    const diceRoll = getRandomNumber(1, 6).toString();\n    res.send(`Dice roll result (with link): ${diceRoll}`);\n    parentSpan.end();\n  });\n});\n\n// Starting the server on the specified PORT and logging the listening message\napp.listen(PORT, () => {\n  console.log(`Listening for requests on http://localhost:${PORT}`);\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Tracing Exporter in Go\nDESCRIPTION: This code snippet sets up an OpenTelemetry tracing exporter for a Go application. It defines resource attributes, initializes the tracer, and configures the OTLP exporter with appropriate endpoints and headers for sending telemetry data to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_4\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n   \"context\" // For managing request-scoped values, cancellation signals, and deadlines.\n   \"crypto/tls\" // For configuring TLS options, like certificates.\n\n   // OpenTelemetry imports for setting up tracing and exporting telemetry data.\n   \"go.opentelemetry.io/otel\" // Core OpenTelemetry APIs for managing tracers.\n   \"go.opentelemetry.io/otel/attribute\" // For creating and managing trace attributes.\n   \"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp\" // HTTP trace exporter for OpenTelemetry Protocol (OTLP).\n   \"go.opentelemetry.io/otel/propagation\" // For managing context propagation formats.\n   \"go.opentelemetry.io/otel/sdk/resource\" // For defining resources that describe an entity producing telemetry.\n   \"go.opentelemetry.io/otel/sdk/trace\" // For configuring tracing, like sampling and processors.\n   semconv \"go.opentelemetry.io/otel/semconv/v1.24.0\" // Semantic conventions for resource attributes.\n)\n\nconst (\n   serviceName           = \"axiom-go-otel\" // Name of the service for tracing.\n   serviceVersion        = \"0.1.0\" // Version of the service.\n   otlpEndpoint          = \"api.axiom.co\" // OTLP collector endpoint.\n   bearerToken           = \"Bearer API_TOKEN\" // Authorization token.\n   deploymentEnvironment = \"production\" // Deployment environment.\n)\n\nfunc SetupTracer() (func(context.Context) error, error) {\n   ctx := context.Background()\n   return InstallExportPipeline(ctx) // Setup and return the export pipeline for telemetry data.\n}\n\nfunc Resource() *resource.Resource {\n   // Defines resource with service name, version, and environment.\n   return resource.NewWithAttributes(\n       semconv.SchemaURL,\n       semconv.ServiceNameKey.String(serviceName),\n       semconv.ServiceVersionKey.String(serviceVersion),\n       attribute.String(\"environment\", deploymentEnvironment),\n   )\n}\n\nfunc InstallExportPipeline(ctx context.Context) (func(context.Context) error, error) {\n   // Sets up OTLP HTTP exporter with endpoint, headers, and TLS config.\n   exporter, err := otlptracehttp.New(ctx,\n       otlptracehttp.WithEndpoint(otlpEndpoint),\n       otlptracehttp.WithHeaders(map[string]string{\n           \"Authorization\":   bearerToken,\n           \"X-AXIOM-DATASET\": \"DATASET_NAME\",\n       }),\n       otlptracehttp.WithTLSClientConfig(&tls.Config{}),\n   )\n   if err != nil {\n       return nil, err\n   }\n\n   // Configures the tracer provider with the exporter and resource.\n   tracerProvider := trace.NewTracerProvider(\n       trace.WithBatcher(exporter),\n       trace.WithResource(Resource()),\n   )\n   otel.SetTracerProvider(tracerProvider)\n\n   // Sets global propagator to W3C Trace Context and Baggage.\n   otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(\n       propagation.TraceContext{},\n       propagation.Baggage{},\n   ))\n\n   return tracerProvider.Shutdown, nil // Returns a function to shut down the tracer provider.\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Search Operator Syntax in Kusto\nDESCRIPTION: Shows the basic syntax for the search operator in APL, which allows performing full-text searches across datasets with optional case sensitivity.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nsearch [kind=CaseSensitivity] SearchPredicate\n```\n\n----------------------------------------\n\nTITLE: Starting and Stopping Activities for Manual Instrumentation in C#\nDESCRIPTION: Manually start activities (spans) at the beginning of operations you want to trace and stop them when the operations complete. This snippet also demonstrates how to add custom attributes to activities.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nusing var activity = MyActivitySource.StartActivity(\"MyOperationName\");\nactivity?.SetTag(\"key\", \"value\");\n// Perform the operation here\nactivity?.Stop();\n```\n\n----------------------------------------\n\nTITLE: Using Axiom Client for Data Ingestion and Querying\nDESCRIPTION: Demonstrates how to use the Axiom client to ingest events into a dataset and perform queries on the data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/python.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport axiom_py\nimport rfc3339\nfrom datetime import datetime,timedelta\n\nclient = axiom_py.Client()\n\nclient.ingest_events(\n    dataset=\"DATASET_NAME\",\n    events=[\n        {\"foo\": \"bar\"},\n        {\"bar\": \"baz\"},\n    ])\nclient.query(r\"['DATASET_NAME'] | where foo == 'bar' | limit 100\")\n```\n\n----------------------------------------\n\nTITLE: Counting HTTP 500 Errors with Countif\nDESCRIPTION: A log analysis example that counts how many HTTP requests returned a 500 status code to detect server errors.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/countif.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize countif(status == '500')\n```\n\n----------------------------------------\n\nTITLE: Basic APL Query Structure Example\nDESCRIPTION: Shows the basic structure of an APL query with source data reference and operators separated by pipe characters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/introduction.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nDataSource\n| operator ...\n| operator ...\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenTelemetry Configuration in Java\nDESCRIPTION: This code snippet sets up OpenTelemetry with necessary settings, exporters, and span processors. It configures the OTLP gRPC span exporter to send data to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\n// OtelConfiguration.java\npackage com.example;\n\nimport io.opentelemetry.api.OpenTelemetry;\nimport io.opentelemetry.api.trace.Tracer;\nimport io.opentelemetry.context.Scope;\nimport io.opentelemetry.exporter.otlp.trace.OtlpGrpcSpanExporter;\nimport io.opentelemetry.sdk.OpenTelemetrySdk;\nimport io.opentelemetry.sdk.trace.SdkTracerProvider;\nimport io.opentelemetry.sdk.trace.export.BatchSpanProcessor;\n\npublic class OtelConfiguration {\n    public static OpenTelemetry initializeOpenTelemetry() {\n        OtlpGrpcSpanExporter spanExporter = OtlpGrpcSpanExporter.builder()\n            .setEndpoint(\"https://api.axiom.co/v1/traces\")\n            .addHeader(\"Authorization\", \"Bearer API_TOKEN\")\n            .addHeader(\"X-Axiom-Dataset\", \"DATASET_NAME\")\n            .build();\n\n        SdkTracerProvider tracerProvider = SdkTracerProvider.builder()\n            .addSpanProcessor(BatchSpanProcessor.builder(spanExporter).build())\n            .build();\n\n        return OpenTelemetrySdk.builder()\n            .setTracerProvider(tracerProvider)\n            .buildAndRegisterGlobal();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic Instrumentation with OpenTelemetry in Node.js\nDESCRIPTION: This JavaScript snippet demonstrates how to configure automatic instrumentation in a Node.js application using OpenTelemetry. It shows the setup of the NodeSDK with auto-instrumentations, which will automatically generate spans for standard operations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\n// In your instrumentation setup (instrumentation.ts)\nconst { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');\n\nconst sdk = new NodeSDK({\n  // ... other configurations ...\n  instrumentations: [getNodeAutoInstrumentations()]\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Database Tracing with OpenTelemetry\nDESCRIPTION: This code implements a custom cursor wrapper to apply manual tracing to database operations, wrapping database cursor executions with OpenTelemetry spans.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom django.db import connections\nfrom otel_config import tracer\n\nclass TracingCursorWrapper:\n    def __init__(self, cursor):\n        self.cursor = cursor\n    def execute(self, sql, params=None):\n        with tracer.start_as_current_span(\"database_query\") as span:\n            span.set_attribute(\"db.statement\", sql)\n            span.set_attribute(\"db.type\", \"sql\")\n            return self.cursor.execute(sql, params)\n    def __getattr__(self, attr):\n        return getattr(self.cursor, attr)\n\ndef patch_database():\n    for connection in connections.all():\n        connection.cursor_wrapper = TracingCursorWrapper\n\n# settings.py\nfrom db_tracing import patch_database\npatch_database()\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry with Vercel Integration\nDESCRIPTION: Implementation of OpenTelemetry registration using Vercel's OTel package, configuring trace export to Axiom\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nextjs.mdx#2025-04-22_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';\nimport { SimpleSpanProcessor } from '@opentelemetry/sdk-trace-node';\nimport { registerOTel } from '@vercel/otel';\n\nexport function register() {\n  registerOTel({\n    serviceName: 'nextjs-app',\n    spanProcessors: [\n      new SimpleSpanProcessor(\n        new OTLPTraceExporter({\n          url: 'https://api.axiom.co/v1/traces',\n          headers: {\n            Authorization: `Bearer ${process.env.API_TOKEN}`,\n            'X-Axiom-Dataset': `${process.env.DATASET_NAME}`,\n          },\n        })\n      ),\n    ],\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Converting SQL COUNT with HAVING to APL\nDESCRIPTION: Shows how to translate a SQL query with GROUP BY and HAVING clauses to APL using 'summarize', 'count()', and 'where' operators.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT geo.country\nFROM [Sample-http-logs]\nGROUP BY geo.country\nHAVING COUNT(*) > 100;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by ['geo.country']\n| where count_ > 100\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenTelemetry Tracer in Node.js\nDESCRIPTION: This snippet demonstrates how to import and configure a tracer in a Node.js application using OpenTelemetry. It assumes that the OpenTelemetry SDK has already been configured in the instrumentation setup.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n// Assuming OpenTelemetry SDK is already configured\nconst { trace } = require('@opentelemetry/api');\nconst tracer = trace.getTracer('example-tracer');\n```\n\n----------------------------------------\n\nTITLE: Complex APL Query Example with Multiple Operators\nDESCRIPTION: Demonstrates a practical APL query that processes GitHub issue comment events, identifies bot actors, filters data, and creates a time-based summary.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/introduction.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issue-comment-event']\n| extend bot = actor contains \"-bot\" or actor contains \"[bot]\"\n| where bot == true\n| summarize count() by bin_auto(_time), actor\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis with Union and Filtering in APL\nDESCRIPTION: This query combines web and security logs, then filters for requests originating from Germany.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| union ['security-logs']\n| where ['geo.country'] == 'Germany'\n```\n\n----------------------------------------\n\nTITLE: Creating and Managing Spans in Go OpenTelemetry\nDESCRIPTION: This code snippet shows how to create and manage spans in a Go application using OpenTelemetry. It demonstrates starting a span, deferring its end, and performing an operation within the span's context.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_6\n\nLANGUAGE: go\nCODE:\n```\nctx, span := tracer.Start(context.Background(), \"operationName\")\ndefer span.End()\n// Perform the operation here\n```\n\n----------------------------------------\n\nTITLE: Finding HTTP Requests with Longest Durations using Top Operator\nDESCRIPTION: This example query shows how to use the top operator to identify the 5 HTTP requests with the longest durations from a sample HTTP logs dataset in APL. It returns results sorted by request duration in descending order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/top-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| top 5 by req_duration_ms\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry in Cloudflare Workers\nDESCRIPTION: Setup for OpenTelemetry tracing in Cloudflare Workers using the OTel CF Worker package. Configures trace exporting to Axiom with environment-based configuration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/opentelemetry.mdx#2025-04-22_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n// index.ts\nimport { trace } from '@opentelemetry/api';\nimport { instrument, ResolveConfigFn } from '@microlabs/otel-cf-workers';\n\nexport interface Env {\n  AXIOM_API_TOKEN: string,\n  AXIOM_DATASET: string\n}\n\nconst handler = {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n    await fetch('https://cloudflare.com');\n    const greeting = \"Welcome to Axiom Cloudflare instrumentation\";\n    trace.getActiveSpan()?.setAttribute('greeting', greeting);\n    ctx.waitUntil(fetch('https://workers.dev'));\n    return new Response(`${greeting}!`);\n  },\n};\n\nconst config: ResolveConfigFn = (env: Env, _trigger) => {\n  return {\n    exporter: {\n      url: 'https://api.axiom.co/v1/traces',\n      headers: {\n        'Authorization': `Bearer ${env.AXIOM_API_TOKEN}`,\n        'X-Axiom-Dataset': `${env.AXIOM_DATASET}`\n      },\n    },\n    service: { name: 'axiom-cloudflare-workers' },\n  };\n};\n\nexport default instrument(handler, config);\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom client with API token\nDESCRIPTION: Example of creating an Axiom client instance with an API token passed through environment variables.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Axiom } from '@axiomhq/js';\n\nconst axiom = new Axiom({\n  token: process.env.AXIOM_TOKEN,\n});\n```\n\n----------------------------------------\n\nTITLE: Annotating Spans in Go OpenTelemetry\nDESCRIPTION: This code snippet illustrates how to annotate spans with additional information in a Go application using OpenTelemetry. It shows setting attributes and adding events to provide more context about the traced operation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_7\n\nLANGUAGE: go\nCODE:\n```\nspan.SetAttributes(attribute.String(\"key\", \"value\"))\nspan.AddEvent(\"eventName\", trace.WithAttributes(attribute.String(\"key\", \"value\")))\n```\n\n----------------------------------------\n\nTITLE: Querying Flight Data with Node.js\nDESCRIPTION: Example showing how to query a dataset containing flight data using the Axiom Processing Language (APL) with Node.js client\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/query.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Axiom } from '@axiomhq/js';\n\nconst axiom = new Axiom({\n    token: process.env.AXIOM_TOKEN\n});\n\nasync function query() {\n    const aplQuery = \"['flights'] | where altitude > 49000 and flight != '' \";\n\n    const res = await axiom.query(aplQuery);\n    if (!res.matches || res.matches.length === 0) {\n        console.warn('no matches found');\n        return;\n    }\n\n    for (let matched of res.matches) {\n        console.log(matched.data);\n    }\n}\n\nquery();\n```\n\n----------------------------------------\n\nTITLE: Sending Logs to Axiom using PHP and Elastic Bulk API\nDESCRIPTION: PHP code snippet showing how to send log data to Axiom using the Elastic Bulk API. It uses the Guzzle library to make an HTTP POST request with the necessary headers and formatted data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elasticsearch-bulk-api.mdx#2025-04-22_snippet_4\n\nLANGUAGE: php\nCODE:\n```\n<?php\nrequire 'vendor/autoload.php';\n\nuse GuzzleHttp\\Client;\n\n$client = new Client([\n    'base_uri' => 'https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic/_bulk',  // Update with your Axiom host\n    'timeout'  => 2.0,\n]);\n\n// Your Axiom API token\n$AxiomToken = 'API_TOKEN';\n\n// The logs data retrieved from Elasticsearch\n// Note: Replace this with your actual code to retrieve logs from Elasticsearch\n$logs = [\n    [\"@timestamp\" => \"2023-06-06T12:00:00Z\", \"message\" => \"axiom logger\", \"severity\" => \"INFO\"],\n    [\"@timestamp\" => \"2023-06-06T12:00:01Z\", \"message\" => \"axiom logging elasticsearch\", \"severity\" => \"ERROR\"]\n];\n\n$events = array_map(function ($log) {\n    return [\n        '@timestamp' => $log['@timestamp'],\n        'attributes' => $log\n    ];\n}, $logs);\n\n// Create the payload for Axiom\n$payload = [\n    'tags' => [\n        'source' => 'myapplication',\n        'host' => 'myhost'\n    ],\n    'events' => $events\n];\n\ntry {\n    $response = $client->post('', [\n        'headers' => [\n            'Authorization' => 'Bearer ' . $AxiomToken,\n            'Content-Type' => 'application/x-ndjson',\n        ],\n        'json' => $payload,\n    ]);\n    // handle response here\n    $statusCode = $response->getStatusCode();\n    $content = $response->getBody();\n    echo \"Status code: $statusCode \\nContent: $content\";\n} catch (\\Exception $e) {\n    // handle exception here\n    echo \"Error: \" . $e->getMessage();\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Attributes to OpenTelemetry Spans in Ruby\nDESCRIPTION: This snippet demonstrates how to enhance OpenTelemetry spans with custom attributes in a Ruby application. It shows setting a single attribute and adding an event with attributes to provide additional context for tracing.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-ruby.mdx#2025-04-22_snippet_4\n\nLANGUAGE: ruby\nCODE:\n```\nspan.set_attribute(\"user_id\", user.id)\nspan.add_event(\"query_executed\", attributes: { \"query\" => sql_query })\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenTelemetry for Go with Axiom Integration\nDESCRIPTION: This Go code snippet demonstrates how to set up OpenTelemetry tracing in a Go application and configure it to send data to Axiom. It includes setting up the tracer, defining resources, and configuring the OTLP HTTP exporter with the necessary Axiom-specific headers.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/opentelemetry.mdx#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n   \"context\" // For managing request-scoped values, cancellation signals, and deadlines.\n   \"crypto/tls\" // For configuring TLS options, like certificates.\n\n   // OpenTelemetry imports for setting up tracing and exporting telemetry data.\n   \"go.opentelemetry.io/otel\" // Core OpenTelemetry APIs for managing tracers.\n   \"go.opentelemetry.io/otel/attribute\" // For creating and managing trace attributes.\n   \"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp\" // HTTP trace exporter for OpenTelemetry Protocol (OTLP).\n   \"go.opentelemetry.io/otel/propagation\" // For managing context propagation formats.\n   \"go.opentelemetry.io/otel/sdk/resource\" // For defining resources that describe an entity producing telemetry.\n   \"go.opentelemetry.io/otel/sdk/trace\" // For configuring tracing, like sampling and processors.\n   semconv \"go.opentelemetry.io/otel/semconv/v1.24.0\" // Semantic conventions for resource attributes.\n)\n\nconst (\n   serviceName           = \"axiom-go-otel\" // Name of the service for tracing.\n   serviceVersion        = \"0.1.0\" // Version of the service.\n   otlpEndpoint          = \"api.axiom.co\" // OTLP collector endpoint.\n   bearerToken           = \"Bearer API_TOKEN\" // Authorization token.\n   deploymentEnvironment = \"production\" // Deployment environment.\n)\n\nfunc SetupTracer() (func(context.Context) error, error) {\n   ctx := context.Background()\n   return InstallExportPipeline(ctx) // Setup and return the export pipeline for telemetry data.\n}\n\nfunc Resource() *resource.Resource {\n   // Defines resource with service name, version, and environment.\n   return resource.NewWithAttributes(\n       semconv.SchemaURL,\n       semconv.ServiceNameKey.String(serviceName),\n       semconv.ServiceVersionKey.String(serviceVersion),\n       attribute.String(\"environment\", deploymentEnvironment),\n   )\n}\n\nfunc InstallExportPipeline(ctx context.Context) (func(context.Context) error, error) {\n   // Sets up OTLP HTTP exporter with endpoint, headers, and TLS config.\n   exporter, err := otlptracehttp.New(ctx,\n       otlptracehttp.WithEndpoint(otlpEndpoint),\n       otlptracehttp.WithHeaders(map[string]string{\n           \"Authorization\":   bearerToken,\n           \"X-AXIOM-DATASET\": \"DATASET_NAME\",\n       }),\n       otlptracehttp.WithTLSClientConfig(&tls.Config{}),\n   )\n   if err != nil {\n       return nil, err\n   }\n\n   // Configures the tracer provider with the exporter and resource.\n   tracerProvider := trace.NewTracerProvider(\n       trace.WithBatcher(exporter),\n       trace.WithResource(Resource()),\n   )\n   otel.SetTracerProvider(tracerProvider)\n\n   // Sets global propagator to W3C Trace Context and Baggage.\n   otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(\n       propagation.TraceContext{},\n       propagation.Baggage{},\n   ))\n\n   return tracerProvider.Shutdown, nil // Returns a function to shut down the tracer provider.\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing Log Levels Based on HTTP Status Codes in Axiom Next.js Integration\nDESCRIPTION: This code demonstrates how to implement a custom getLogLevelFromStatusCode function to determine appropriate log levels based on HTTP status codes. It maps redirects (300s) to info level, client errors (400s) to warn level, and server errors (500s) to error level.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_19\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger, AxiomJSTransport, LogLevel } from '@axiomhq/logging';\nimport {\n  createAxiomRouteHandler,\n  nextJsFormatters,\n  transformRouteHandlerErrorResult,\n} from '@axiomhq/nextjs';\n\n/* ... your logger setup ... */\n\nconst getLogLevelFromStatusCode = (statusCode: number) => {\n  if (statusCode >= 300 && statusCode < 400) {\n    return LogLevel.info;\n  } else if (statusCode >= 400 && statusCode < 500) {\n    return LogLevel.warn;\n  }\n  return LogLevel.error;\n};\n\nexport const withAxiom = createAxiomRouteHandler(logger, {\n  onError: (error) => {\n    if (error.error instanceof Error) {\n      logger.error(error.error.message, error.error);\n    }\n    const [message, report] = transformRouteHandlerErrorResult(error);\n    report.customField = 'customValue';\n    report.request.searchParams = error.req.nextUrl.searchParams;\n\n    logger.log(getLogLevelFromStatusCode(report.statusCode), message, report);\n    logger.flush();\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Tracing in .NET\nDESCRIPTION: Implementation of OpenTelemetry tracing configuration for .NET applications. Sets up a tracer provider with service information, environment attributes, and configures OTLP HTTP exporter to send traces to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/opentelemetry.mdx#2025-04-22_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nusing OpenTelemetry;\nusing OpenTelemetry.Resources;\nusing OpenTelemetry.Trace;\nusing System;\nusing System.Diagnostics;\nusing System.Reflection;\n\n// Class to configure OpenTelemetry tracing\npublic static class TracingConfiguration\n{\n    // Declares an ActivitySource for creating tracing activities\n    private static readonly ActivitySource ActivitySource = new(\"MyCustomActivitySource\");\n\n    // Configures OpenTelemetry with custom settings and instrumentation\n    public static void ConfigureOpenTelemetry()\n    {\n        // Retrieve the service name and version from the executing assembly metadata\n        var serviceName = Assembly.GetExecutingAssembly().GetName().Name ?? \"UnknownService\";\n        var serviceVersion = Assembly.GetExecutingAssembly().GetName().Version?.ToString() ?? \"UnknownVersion\";\n\n        // Setting up the tracer provider with various configurations\n        Sdk.CreateTracerProviderBuilder()\n            .SetResourceBuilder(\n                // Set resource attributes including service name and version\n                ResourceBuilder.CreateDefault().AddService(serviceName, serviceVersion: serviceVersion)\n                .AddAttributes(new[] { new KeyValuePair<string, object>(\"environment\", \"development\") }) // Additional attributes\n                .AddTelemetrySdk() // Add telemetry SDK information to the traces\n                .AddEnvironmentVariableDetector()) // Detect resource attributes from environment variables\n            .AddSource(ActivitySource.Name) // Add the ActivitySource defined above\n            .AddAspNetCoreInstrumentation() // Add automatic instrumentation for ASP.NET Core\n            .AddHttpClientInstrumentation() // Add automatic instrumentation for HttpClient requests\n            .AddOtlpExporter(options => // Configure the OTLP exporter\n            {\n                options.Endpoint = new Uri(\"https://api.axiom.co/v1/traces\"); // Set the endpoint for the exporter\n                options.Protocol = OpenTelemetry.Exporter.OtlpExportProtocol.HttpProtobuf; // Set the protocol\n                options.Headers = \"Authorization=Bearer API_TOKEN, X-Axiom-Dataset=DATASET_NAME\"; // Update API token and dataset\n            })\n            .Build(); // Build the tracer provider\n    }\n\n    // Method to start a new tracing activity with an optional activity kind\n    public static Activity? StartActivity(string activityName, ActivityKind kind = ActivityKind.Internal)\n    {\n        // Starts and returns a new activity if sampling allows it, otherwise returns null\n        return ActivitySource.StartActivity(activityName, kind);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering HTTP Logs for 404 Status in APL\nDESCRIPTION: Example of using the where operator to filter HTTP logs for status code 404 (Not Found). This is useful for investigating pages that were not found in web applications.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '404'\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Span Duration in OpenTelemetry Traces\nDESCRIPTION: Shows how to use summarize to analyze OpenTelemetry traces by calculating the average span duration for each service.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize avg(duration) by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Sending Logs from React Components using useLogger\nDESCRIPTION: Demonstrates how to use the useLogger hook to send logs from a React component, including on user interactions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/react.mdx#2025-04-22_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nimport { useLogger } from \"@/lib/axiom/client\";\n\nexport default function ClientComponent() {\n  const log = useLogger();\n  log.debug(\"User logged in\", { userId: 42 });\n  const handleClick = () => log.info(\"User logged out\");\n  return (\n    <div>\n      <h1>Logged in</h1>\n      <button onClick={handleClick}>Log out</button>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Server-Side Axiom Logger\nDESCRIPTION: Implementation of server-side logger setup with Axiom transport and Next.js formatters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nimport axiomClient from '@/lib/axiom/axiom';\nimport { Logger, AxiomJSTransport } from '@axiomhq/logging';\nimport { createAxiomRouteHandler, nextJsFormatters } from '@axiomhq/nextjs';\n\nexport const logger = new Logger({\n  transports: [\n    new AxiomJSTransport({ axiom: axiomClient, dataset: process.env.NEXT_PUBLIC_AXIOM_DATASET! }),\n  ],\n  formatters: nextJsFormatters,\n});\n\nexport const withAxiom = createAxiomRouteHandler(logger);\n```\n\n----------------------------------------\n\nTITLE: Manually Instrumenting Django Views\nDESCRIPTION: This code demonstrates how to manually instrument Django views using OpenTelemetry, creating custom spans to trace specific operations within the app.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom django.http import HttpResponse\nfrom otel_config import tracer\n\ndef home_view(request):\n    with tracer.start_as_current_span(\"home_view\") as span:\n        span.set_attribute(\"http.method\", request.method)\n        span.set_attribute(\"http.url\", request.build_absolute_uri())\n        response = HttpResponse(\"Welcome to the home page!\")\n        span.set_attribute(\"http.status_code\", response.status_code)\n        return response\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenTelemetry Dependencies in Maven POM\nDESCRIPTION: This XML snippet shows how to include necessary OpenTelemetry libraries in a Maven pom.xml file for automatic instrumentation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_9\n\nLANGUAGE: xml\nCODE:\n```\n<!-- pom.xml snippet -->\n<dependencies>\n    <dependency>\n        <groupId>io.opentelemetry</groupId>\n        <artifactId>opentelemetry-api</artifactId>\n        <version>{opentelemetry_version}</version>\n    </dependency>\n    <dependency>\n        <groupId>io.opentelemetry</groupId>\n        <artifactId>opentelemetry-sdk</artifactId>\n        <version>{opentelemetry_version}</version>\n    </dependency>\n    <dependency>\n        <groupId>io.opentelemetry.instrumentation</groupId>\n        <artifactId>opentelemetry-instrumentation-httpclient</artifactId>\n        <version>{instrumentation_version}</version>\n    </dependency>\n</dependencies>\n```\n\n----------------------------------------\n\nTITLE: Time-Limited Search in APL\nDESCRIPTION: Performs a search for \"get\" while filtering results by timestamp, returning only events that occurred after September 16, 2022.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search \"get\" and _time > datetime('2022-09-16')\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry for Ruby with Axiom Integration\nDESCRIPTION: This Ruby code snippet shows how to set up OpenTelemetry tracing in a Ruby application and configure it to send data to Axiom. It uses the OTLP over HTTP exporter and includes the necessary Axiom-specific headers for authentication and dataset specification.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/opentelemetry.mdx#2025-04-22_snippet_2\n\nLANGUAGE: ruby\nCODE:\n```\nrequire 'opentelemetry/sdk'\nrequire 'opentelemetry/exporter/otlp'\nrequire 'opentelemetry/instrumentation/all'\n\nOpenTelemetry::SDK.configure do |c|\n  c.service_name = 'ruby-traces' # Set your service name\n\n  c.use_all # or specify individual instrumentation you need\n\n  c.add_span_processor(\n    OpenTelemetry::SDK::Trace::Export::BatchSpanProcessor.new(\n      OpenTelemetry::Exporter::OTLP::Exporter.new(\n        endpoint: 'https://api.axiom.co/v1/traces',\n        headers: {\n          'Authorization' => 'Bearer API_TOKEN',\n          'X-AXIOM-DATASET' => 'DATASET_NAME'\n        }\n      )\n    )\n  )\nend\n```\n\n----------------------------------------\n\nTITLE: Updating Django URL Configuration\nDESCRIPTION: This code updates the urls.py file to include the views, connecting URL paths to the corresponding view functions for proper routing and span creation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom django.urls import path\nfrom .views import roll_dice, home\n\nurlpatterns = [\n    path('', home, name='home'),\n    path('rolldice/', roll_dice, name='roll_dice'),\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic OpenTelemetry Instrumentation in Ruby on Rails\nDESCRIPTION: This code configures automatic OpenTelemetry instrumentation in a Ruby on Rails application. It sets up the SDK with a service name and enables all available instrumentations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-ruby.mdx#2025-04-22_snippet_5\n\nLANGUAGE: ruby\nCODE:\n```\n# In config/initializers/opentelemetry.rb\nOpenTelemetry::SDK.configure do |c|\n  c.service_name = 'ruby-traces'\n  c.use_all  # Automatically use all available instrumentation\nend\n```\n\n----------------------------------------\n\nTITLE: Sending Prometheus Metrics to Axiom with Vector\nDESCRIPTION: A Vector configuration for scraping Prometheus metrics and sending them to Axiom. Uses the prometheus_scrape source type to collect metrics from a Prometheus endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_11\n\nLANGUAGE: toml\nCODE:\n```\n# Define the Prometheus source that scrapes metrics\n[sources.my_prometheus_source]\ntype = \"prometheus_scrape\"  # scrape metrics from a Prometheus endpoint\nendpoints = [\"http://localhost:9090/metrics\"]  # replace with your Prometheus endpoint\n\n# Define Axiom sink where logs will be sent\n[sinks.axiom]\ntype = \"axiom\"  # Axiom type\ninputs = [\"my_prometheus_source\"]  # connect the Axiom sink to your Prometheus source\ndataset = \"DATASET_NAME\"  # replace with the name of your Axiom dataset\ntoken = \"API_TOKEN\"  # replace with your Axiom API token\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Core Dependencies\nDESCRIPTION: Command to install core OpenTelemetry packages without Vercel integration\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nextjs.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @opentelemetry/sdk-node @opentelemetry/exporter-trace-otlp-http @opentelemetry/resources @opentelemetry/semantic-conventions @opentelemetry/sdk-trace-node\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Python SDK\nDESCRIPTION: Different methods to install the Axiom Python SDK using pip package manager across different operating systems.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/python.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython3 -m pip install axiom-py\n```\n\nLANGUAGE: shell\nCODE:\n```\npy -m pip install axiom-py\n```\n\nLANGUAGE: shell\nCODE:\n```\npip3 install axiom-py\n```\n\n----------------------------------------\n\nTITLE: Transforming and Enriching Cloudflare Logpush Data with APL Query in Axiom\nDESCRIPTION: This APL query selects events from a 'cloudflare-logpush' dataset, filters based on QueryName, removes specific fields, and adds a new field for context. It demonstrates data filtering, reduction, and enrichment in Axiom flows.\nSOURCE: https://github.com/axiomhq/docs/blob/main/process-data/flows.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['cloudflare-logpush']\n| where QueryName == \"app.axiom.co.\"\n// Reduce events by dropping unimportant field\n| project-away ['@app']*\n// Enrich events with additional context\n| extend ['@origin'] = \"_axiom\"\n```\n\n----------------------------------------\n\nTITLE: Sending Logs from Loki to Axiom using Python\nDESCRIPTION: This snippet shows how to use the logging_loki library to send logs from Python to Axiom via Loki. It sets up a LokiHandler with the Axiom endpoint URL and custom tags, then configures a logger to use this handler.\nSOURCE: https://github.com/axiomhq/docs/blob/main/endpoints/loki.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nimport logging_loki\n\n# Create a handler\nhandler = logging_loki.LokiHandler(\n    url='$LOKI_ENDPOINT_URL',\n    tags={'app': 'axiom-loki-py-endpoint'},\n    version='1',\n)\n\n# Create a logger\nlogger = logging.getLogger('loki')\n\n# Add the handler to the logger\nlogger.addHandler(handler)\n\n# Log some messages\nlogger.info('Hello, world from Python!')\nlogger.warning('This is a warning')\nlogger.error('This is an error')\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL JOIN and APL lookup implementations\nDESCRIPTION: This snippet shows the equivalence between ANSI SQL's INNER JOIN and APL's lookup operator. The APL implementation is more concise but limited to inner join functionality, whereas SQL offers more flexible join operations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/lookup-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT logs.*, ports.service_name \nFROM logs\nINNER JOIN port_lookup ports ON logs.port = ports.port;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| lookup kind=inner ['port_lookup'] on port\n```\n\n----------------------------------------\n\nTITLE: Annotating Spans with Attributes and Events in Java OpenTelemetry\nDESCRIPTION: This code shows how to annotate spans with attributes and events to provide more context about the operation being performed in OpenTelemetry.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nprivate static void rollDice() {\n    Span span = tracer.spanBuilder(\"rollDice\").startSpan();\n    try (Scope scope = span.makeCurrent()) {\n        int roll = 1 + new Random().nextInt(6);\n        span.setAttribute(\"roll.value\", roll);\n        span.addEvent(\"Dice rolled\");\n        System.out.println(\"Rolled a dice: \" + roll);\n    } finally {\n        span.end();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Annotating Spans with OpenTelemetry in Node.js\nDESCRIPTION: This snippet illustrates how to add metadata and logs to spans in OpenTelemetry for Node.js. It shows setting attributes and adding events to spans for enhanced trace data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nspan.setAttribute('key', 'value');\nspan.addEvent('event name', { eventKey: 'eventValue' });\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Resource Import\nDESCRIPTION: Import for Resource class to define service attributes in OpenTelemetry configuration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.sdk.resources import Resource, SERVICE_NAME\n```\n\n----------------------------------------\n\nTITLE: Counting Successful Requests in Security Logs with APL\nDESCRIPTION: Example of using sum aggregation to count specific HTTP status codes in security logs. This query filters for status code 200 (successful requests) and counts them using sum(1).\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sum.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '200'\n| summarize request_count = sum(1)\n```\n\n----------------------------------------\n\nTITLE: Configuring Metricbeat for System Monitoring\nDESCRIPTION: YAML configuration for Metricbeat to collect system metrics including filesystem, CPU, load, memory, and network statistics and send them to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nsetup.ilm.enabled: false\nmetricbeat.config.modules:\n  path:\n    -$PATH_TO_LOG_FILE\nmetricbeat.modules:\n- module: system\n  metricsets:\n    - filesystem\n    - cpu\n    - load\n    - fsstat\n    - memory\n    - network\noutput.elasticsearch:\n  hosts: [\"https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic\"]\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Configuration Setup\nDESCRIPTION: Configuration class for initializing OpenTelemetry SDK with Axiom exporter settings and resource attributes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npackage com.example;\n\nimport io.opentelemetry.api.OpenTelemetry;\nimport io.opentelemetry.api.common.Attributes;\nimport io.opentelemetry.api.common.AttributeKey;\nimport io.opentelemetry.exporter.otlp.http.trace.OtlpHttpSpanExporter;\nimport io.opentelemetry.sdk.OpenTelemetrySdk;\nimport io.opentelemetry.sdk.resources.Resource;\nimport io.opentelemetry.sdk.trace.SdkTracerProvider;\nimport io.opentelemetry.sdk.trace.export.BatchSpanProcessor;\n\nimport java.util.concurrent.TimeUnit;\n\npublic class OtelConfiguration {\n    private static final String SERVICE_NAME = \"YOUR_SERVICE_NAME\";\n    private static final String SERVICE_VERSION = \"YOUR_SERVICE_VERSION\";\n    private static final String OTLP_ENDPOINT = \"https://api.axiom.co/v1/traces\";\n    private static final String BEARER_TOKEN = \"Bearer API_TOKEN\";\n    private static final String AXIOM_DATASET = \"DATASET_NAME\";\n\n    public static OpenTelemetry initializeOpenTelemetry() {\n        Resource resource = Resource.getDefault()\n                .merge(Resource.create(Attributes.of(\n                        AttributeKey.stringKey(\"service.name\"), SERVICE_NAME,\n                        AttributeKey.stringKey(\"service.version\"), SERVICE_VERSION\n                )));\n\n        OtlpHttpSpanExporter spanExporter = OtlpHttpSpanExporter.builder()\n                .setEndpoint(OTLP_ENDPOINT)\n                .addHeader(\"Authorization\", BEARER_TOKEN)\n                .addHeader(\"X-Axiom-Dataset\", AXIOM_DATASET)\n                .build();\n\n        SdkTracerProvider sdkTracerProvider = SdkTracerProvider.builder()\n                .addSpanProcessor(BatchSpanProcessor.builder(spanExporter)\n                        .setScheduleDelay(100, TimeUnit.MILLISECONDS)\n                        .build())\n                .setResource(resource)\n                .build();\n\n        OpenTelemetrySdk openTelemetry = OpenTelemetrySdk.builder()\n                .setTracerProvider(sdkTracerProvider)\n                .buildAndRegisterGlobal();\n\n        Runtime.getRuntime().addShutdownHook(new Thread(sdkTracerProvider::close));\n\n        return openTelemetry;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenTelemetry Tracer in Go\nDESCRIPTION: This code snippet demonstrates how to initialize an OpenTelemetry tracer in a Go application. It's used to obtain a tracer instance for creating and managing spans in manual instrumentation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_5\n\nLANGUAGE: go\nCODE:\n```\ntracer := otel.Tracer(\"serviceName\")\n```\n\n----------------------------------------\n\nTITLE: Security Logs Analysis with minif in APL\nDESCRIPTION: Example illustrating how to use minif to find the minimum request duration for HTTP requests from a specific country, grouped by HTTP status code.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/minif.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize minif(req_duration_ms, ['geo.country'] == 'US') by status\n```\n\n----------------------------------------\n\nTITLE: Counting HTTP Requests by Method in Log Analysis\nDESCRIPTION: Demonstrates using the summarize operator to count HTTP requests grouped by method in log analysis scenarios.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by method\n```\n\n----------------------------------------\n\nTITLE: Customizing Axiom Reports with onError and onSuccess Functions in Next.js\nDESCRIPTION: This code demonstrates how to customize data sent to Axiom by adding fields to the report object using the onError and onSuccess callbacks in the createAxiomRouteHandler configuration. It also shows how to include request search parameters in the logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger, AxiomJSTransport } from '@axiomhq/logging';\nimport { \n  createAxiomRouteHandler, \n  getLogLevelFromStatusCode, \n  nextJsFormatters, \n  transformRouteHandlerErrorResult, \n  transformRouteHandlerSuccessResult \n} from '@axiomhq/nextjs';\n\n/* ... your logger setup ... */\n\nexport const withAxiom = createAxiomRouteHandler(logger, {\n  onError: (error) => {\n    if (error.error instanceof Error) {\n      logger.error(error.error.message, error.error);\n    }\n    const [message, report] = transformRouteHandlerErrorResult(error);\n    report.customField = \"customValue\";\n    report.request.searchParams = error.req.nextUrl.searchParams;\n\n    logger.log(getLogLevelFromStatusCode(report.statusCode), message, report);\n    logger.flush();\n  },\n  onSuccess: (data) => {\n    const [message, report] = transformRouteHandlerSuccessResult(data);\n    report.customField = \"customValue\";\n    report.request.searchParams = data.req.nextUrl.searchParams;\n\n    logger.info(message, report);\n    logger.flush();\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Serilog Configuration with Axiom HTTP Client in C#\nDESCRIPTION: Complete implementation of Serilog configuration with custom HTTP client for Axiom integration. Includes configuration classes, HTTP client implementation, and example logging operations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_7\n\nLANGUAGE: csharp\nCODE:\n```\nusing Serilog;\nusing Serilog.Formatting.Elasticsearch;\nusing Serilog.Sinks.Http;\nusing System.Net.Http;\nusing System.Net.Http.Headers;\nusing System.IO;\nusing Microsoft.Extensions.Configuration;\n\npublic class AxiomConfig\n{\n    public const string DatasetName = \"DATASET_NAME\";\n    public const string ApiToken = \"API_TOKEN\";\n    public const string ApiUrl = \"https://api.axiom.co/v1/datasets\";\n}\n\npublic class AxiomHttpClient : IHttpClient\n{\n    private readonly HttpClient _httpClient;\n\n    public AxiomHttpClient()\n    {\n        _httpClient = new HttpClient();\n        _httpClient.DefaultRequestHeaders.Authorization = \n            new AuthenticationHeaderValue(\"Bearer\", AxiomConfig.ApiToken);\n    }\n\n    public void Configure(IConfiguration configuration)\n    {\n    }\n\n    public async Task<HttpResponseMessage> PostAsync(string requestUri, Stream contentStream, CancellationToken cancellationToken = default)\n    {\n        var content = new StreamContent(contentStream);\n        content.Headers.Add(\"Content-Type\", \"application/json\");\n        return await _httpClient.PostAsync(requestUri, content, cancellationToken).ConfigureAwait(false);\n    }\n\n    public void Dispose()\n    {\n        _httpClient?.Dispose();\n    }\n}\n\npublic class Program\n{\n    public static async Task Main(string[] args)\n    {\n        Log.Logger = new LoggerConfiguration()\n            .MinimumLevel.Debug()\n            .WriteTo.Console()\n            .WriteTo.Http(\n                requestUri: $\"{AxiomConfig.ApiUrl}/{AxiomConfig.DatasetName}/ingest\",\n                queueLimitBytes: null,\n                textFormatter: new ElasticsearchJsonFormatter(renderMessageTemplate: false, inlineFields: true),\n                httpClient: new AxiomHttpClient()\n            )\n            .CreateLogger();\n\n        try\n        {\n            Log.Information(\"Application started on .NET 8\");\n            await SimulateOperations();\n            Log.Information($\"Runtime version: {Environment.Version}\");\n            Log.Information(\"Application shutting down\");\n        }\n        catch (Exception ex)\n        {\n            Log.Fatal(ex, \"Application terminated unexpectedly\");\n        }\n        finally\n        {\n            await Log.CloseAndFlushAsync();\n        }\n    }\n\n    static async Task SimulateOperations()\n    {\n        Log.Debug(\"Starting operations\");\n        Log.Debug(\"Connecting to database\");\n        await Task.Delay(500);\n        Log.Information(\"Connected to database successfully\");\n        \n        Log.Debug(\"Retrieving user data\");\n        await Task.Delay(1000);\n        Log.Information(\"Retrieved 100 user records\");\n        \n        Log.Debug(\"Updating user preferences\");\n        await Task.Delay(800);\n        Log.Information(\"Updated user preferences successfully\");\n\n        try\n        {\n            Log.Debug(\"Processing payments\");\n            await Task.Delay(1500);\n            throw new Exception(\"Payment gateway unavailable\");\n        }\n        catch (Exception ex)\n        {\n            Log.Error(ex, \"Payment processing failed: {ErrorMessage}\", ex.Message);\n        }\n\n        Log.Debug(\"Sending email notifications\");\n        await Task.Delay(1200);\n        Log.Information(\"Sent 50 email notifications\");\n        \n        Log.Warning(\"Detected high memory usage: {UsagePercentage}%\", 85);\n        await Task.Delay(500);\n        Log.Information(\"Memory usage normalized\");\n        \n        Log.Debug(\"Operations completed\");\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Fluent Bit Configuration\nDESCRIPTION: Complete Fluent Bit configuration for Docker Compose setup, including multiple input sources (CPU, memory, network, disk) and record modification filter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluent-bit.mdx#2025-04-22_snippet_4\n\nLANGUAGE: ini\nCODE:\n```\n[SERVICE]\n    Flush        1\n    Daemon       off\n    Log_Level    debug\n\n[INPUT]\n    Name        cpu\n    Tag         system.cpu\n    Interval_Sec 5\n\n[INPUT]\n    Name        mem\n    Tag         system.mem\n    Interval_Sec 5\n\n[INPUT]\n    Name forward\n    Listen 0.0.0.0\n    port 24224\n\n[INPUT]\n    Name          netif\n    Tag           netif\n    Interval_Sec  1\n    Interval_NSec 0\n    Interface     eth0\n\n[INPUT]\n    Name          disk\n    Tag           disk\n    Interval_Sec  1\n    Interval_NSec 0\n\n[FILTER]\n    Name         record_modifier\n    Match        *\n    Record       hostname ${HOSTNAME}\n\n[OUTPUT]\n    Name        http\n    Match       *\n    Host        api.axiom.co\n    Port        443\n    URI         /v1/datasets/DATASET_NAME/ingest\n    Header      Authorization Bearer API_TOKEN\n    Compress    gzip\n    Format      json\n    JSON_Date_Key _time\n    JSON_Date_Format iso8601\n    TLS         On\n```\n\n----------------------------------------\n\nTITLE: AWS ECS Filter Configuration\nDESCRIPTION: Fluent Bit configuration with AWS ECS grep filter to enrich logs with Amazon ECS metadata. Includes service, input, filter, and output configurations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluent-bit.mdx#2025-04-22_snippet_1\n\nLANGUAGE: ini\nCODE:\n```\n[SERVICE]\n    Flush     5\n    Daemon    off\n    Log_Level debug\n\n[INPUT]\n    Name cpu\n    Tag  cpu\n\n[FILTER]\n    Name  grep\n    Match *\n    Regex ecs_task_arn .*app1.*\n\n[OUTPUT]\n    Name            http\n    Match           *\n    Host            api.axiom.co\n    Port            443\n    URI             /v1/datasets/DATASET_NAME/ingest\n    # Authorization Bearer should be an API token\n    Header Authorization Bearer API_TOKEN\n    compress gzip\n    format json\n    json_date_key _time\n    json_date_format iso8601\n    tls On\n```\n\n----------------------------------------\n\nTITLE: Wrapping HTTP Handlers with OpenTelemetry in Go\nDESCRIPTION: This code snippet demonstrates how to automatically instrument HTTP servers in a Go application by wrapping handlers with OpenTelemetry's instrumentation using otelhttp.NewHandler.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_9\n\nLANGUAGE: go\nCODE:\n```\nhttp.Handle(\"/path\", otelhttp.NewHandler(handler, \"operationName\"))\n```\n\n----------------------------------------\n\nTITLE: Count with a Condition in SQL and APL\nDESCRIPTION: Demonstrates how to count records that meet a specific condition. This example counts HTTP logs where the response header size is greater than 1 byte.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(*) AS HighContentStatus\nFROM  [Sample-http-logs];\nWHERE resp_header_size_bytes  > 1;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where resp_header_size_bytes > 1\n| summarize HighContentStatus = count()\n```\n\n----------------------------------------\n\nTITLE: Implementing Axiom Logger Class\nDESCRIPTION: C# class that handles logging to Axiom using HTTP client, including authentication and error handling.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nusing System;\nusing System.Net.Http;\nusing System.Text;\nusing System.Threading.Tasks;\n\npublic static class AxiomLogger\n{\n    public static async Task LogToAxiom(string message, string logLevel)\n    {\n        // Create an instance of HttpClient to make HTTP requests\n        var client = new HttpClient();\n\n        // Specify the Axiom dataset name and construct the API endpoint URL\n        var datasetName = \"DATASET-NAME\"; // Replace with your actual dataset name\n        var axiomUri = $\"https://api.axiom.co/v1/datasets/{datasetName}/ingest\";\n\n        // Replace with your Axiom API token\n        var apiToken = \"API-TOKEN\"; // Ensure your API token is correct\n\n        // Create an array of log entries, including the timestamp, message, and log level\n        var logEntries = new[]\n        {\n            new\n            {\n                timestamp = DateTime.UtcNow.ToString(\"o\"),\n                message = message,\n                level = logLevel\n            }\n        };\n\n        // Serialize the log entries to JSON format using System.Text.Json.JsonSerializer\n        var content = new StringContent(System.Text.Json.JsonSerializer.Serialize(logEntries), Encoding.UTF8, \"application/json\");\n\n        // Set the authorization header with the Axiom API token\n        client.DefaultRequestHeaders.Authorization = new System.Net.Http.Headers.AuthenticationHeaderValue(\"Bearer\", apiToken);\n\n        // Make a POST request to the Axiom API endpoint with the serialized log entries\n        var response = await client.PostAsync(axiomUri, content);\n\n        // Check the response status code\n        if (!response.IsSuccessStatusCode)\n        {\n            // If the response is not successful, print the error details\n            var responseBody = await response.Content.ReadAsStringAsync();\n            Console.WriteLine($\"Failed to send log: {response.StatusCode}\\n{responseBody}\");\n        }\n        else\n        {\n            // If the response is successful, print \"Log sent successfully.\"\n            Console.WriteLine(\"Log sent successfully.\");\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Integrating Axiom with Structlog\nDESCRIPTION: Demonstrates how to configure structlog to send logs to Axiom using AxiomProcessor.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/python.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom axiom_py import Client\nfrom axiom_py.structlog import AxiomProcessor\n\ndef setup_logger():\n    client = Client()\n\n    structlog.configure(\n        processors=[\n            # ...\n            structlog.processors.add_log_level,\n            structlog.processors.TimeStamper(fmt=\"iso\", key=\"_time\"),\n            AxiomProcessor(client, \"DATASET_NAME\"),\n            # ...\n        ]\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring Exception and Rejection Handling with Winston and Axiom Transport in TypeScript\nDESCRIPTION: Sets up automatic logging of exceptions and rejections using Winston logger with Axiom transport.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/winston.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport winston from 'winston';\nimport { WinstonTransport as AxiomTransport } from '@axiomhq/winston';\nconst axiomTransport = new AxiomTransport({ ... });\nconst logger = winston.createLogger({\n  // 8<----snip----\n  transports: [axiomTransport],\n  exceptionHandlers: [axiomTransport],\n  rejectionHandlers: [axiomTransport],\n  // 8<----snip----\n});\n```\n\n----------------------------------------\n\nTITLE: Importing OpenTelemetry SDK Implementation for Java\nDESCRIPTION: This package is the reference implementation of the OpenTelemetry API for Java. It provides the actual capability behind the API interfaces, including span creation, context propagation, and resource management. It's highly configurable and extensible.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_13\n\nLANGUAGE: Java\nCODE:\n```\nio.opentelemetry:opentelemetry-sdk\n```\n\n----------------------------------------\n\nTITLE: Sample Java App with OpenTelemetry Tracing\nDESCRIPTION: Core application class implementing dice rolling functionality with OpenTelemetry tracing, demonstrating span creation and linking.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npackage com.example;\n\nimport io.opentelemetry.api.OpenTelemetry;\nimport io.opentelemetry.api.trace.Span;\nimport io.opentelemetry.api.trace.Tracer;\nimport io.opentelemetry.context.Scope;\n\nimport java.util.Random;\n\npublic class DiceRollerApp {\n    private static final Tracer tracer;\n\n    static {\n        OpenTelemetry openTelemetry = OtelConfiguration.initializeOpenTelemetry();\n        tracer = openTelemetry.getTracer(DiceRollerApp.class.getName());\n    }\n\n    public static void main(String[] args) {\n        rollDice();\n        rollDiceWithLink();\n    }\n\n    private static void rollDice() {\n        Span span = tracer.spanBuilder(\"rollDice\").startSpan();\n        try (Scope scope = span.makeCurrent()) {\n            int roll = 1 + new Random().nextInt(6);\n            System.out.println(\"Rolled a dice: \" + roll);\n        } finally {\n            span.end();\n        }\n    }\n\n    private static void rollDiceWithLink() {\n        Span parentSpan = tracer.spanBuilder(\"rollWithLink\").startSpan();\n        try (Scope parentScope = parentSpan.makeCurrent()) {\n            Span childSpan = tracer.spanBuilder(\"rolldice\")\n                    .addLink(parentSpan.getSpanContext())\n                    .startSpan();\n            try (Scope childScope = childSpan.makeCurrent()) {\n                int roll = 1 + new Random().nextInt(6);\n                System.out.println(\"Dice roll result (with link): \" + roll);\n            } finally {\n                childSpan.end();\n            }\n        } finally {\n            parentSpan.end();\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Spans in Django Views\nDESCRIPTION: Example of combining automatic instrumentation with custom manual spans in Django views for enhanced trace details.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n# views.py\nfrom opentelemetry import trace\ntracer = trace.get_tracer(__name__)\ndef complex_view(request):\n    with tracer.start_as_current_span(\"complex_operation\"):\n        result = perform_complex_operation()\n    return HttpResponse(result)\n```\n\n----------------------------------------\n\nTITLE: Integrating OpenTelemetry Auto-Instrumentation in Java Main Class\nDESCRIPTION: This snippet shows how to integrate OpenTelemetry auto-instrumentation setup into the main class of a Java application.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\n// Main.java\npackage com.example;\n\npublic class Main {\n    public static void main(String[] args) {\n        AutoInstrumentationSetup.setup();  // Initialize OpenTelemetry auto-instrumentation\n        DiceRollerApp.main(args);          // Start the application logic\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Traces Rate Calculation\nDESCRIPTION: Calculating rate of span duration per second in OpenTelemetry traces.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/rate.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize rate(toint(duration)) by bin(_time, 1s)\n```\n\n----------------------------------------\n\nTITLE: Configuring Winlogbeat with Verification Modes and Processors\nDESCRIPTION: This configuration sets up Winlogbeat to collect Application, Security, and System logs from Windows and send them to Axiom. It includes SSL verification mode settings and processors to add host and cloud metadata to the events.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nwinlogbeat.event_logs:\n  - name: Application\n    ignore_older: 72h\n  - name: Security\n  - name: System\n\noutput.elasticsearch:\n  hosts: ['https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic']\n  # token should be an API token\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n  ssl.verification_mode: \"certificate\"\n\nprocessors:\n  - add_host_metadata: ~\n  - add_cloud_metadata: ~\n\nlogging.level: info\nlogging.to_files: true\nlogging.files:\n  path: C:/ProgramData/winlogbeat/Logs\n  name: winlogbeat\n  keepfiles: 7\n  permissions: 0600\n```\n\n----------------------------------------\n\nTITLE: Querying and Summarizing HTTP Logs with Kusto in Axiom\nDESCRIPTION: This Kusto query retrieves data from the 'sample-http-logs' dataset, calculates the average response body size in bytes, and groups the results by automatically binned time intervals. It demonstrates how to create a non-aggregated view of events for a table chart using Axiom's Advanced Query Language.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/table.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize avg(resp_body_size_bytes) by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Go Dependencies\nDESCRIPTION: Commands for installing required OpenTelemetry packages including the Go SDK, OTLP trace exporter, and instrumentation libraries.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\ngo get go.opentelemetry.io/otel\ngo get go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp\ngo get go.opentelemetry.io/otel/sdk/resource\ngo get go.opentelemetry.io/otel/sdk/trace\ngo get go.opentelemetry.io/otel/semconv/v1.24.0\ngo get go.opentelemetry.io/otel/trace\ngo get go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp\ngo get go.opentelemetry.io/otel/propagation\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenTelemetry Tracing in manage.py\nDESCRIPTION: This code modifies the manage.py file to initialize OpenTelemetry instrumentation for Django when the project is run, automatically tracing all incoming HTTP requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n#!/usr/bin/env python\nimport os\nimport sys\nfrom opentelemetry.instrumentation.django import DjangoInstrumentor\n\ndef main():\n    \"\"\"Run administrative tasks.\"\"\"\n    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'your_project_name.settings')\n\n    # Initialize OpenTelemetry instrumentation\n    DjangoInstrumentor().instrument()\n\n    try:\n        from django.core.management import execute_from_command_line\n    except ImportError as exc:\n        raise ImportError(\n            \"Couldn't import Django. Are you sure it's installed and \"\n            \"available on your PYTHONPATH environment variable? Did you \"\n            \"forget to activate a virtual environment?\"\n        ) from exc\n    execute_from_command_line(sys.argv)\n\nif __name__ == '__main__':\n    main()\n```\n\n----------------------------------------\n\nTITLE: Analyzing OpenTelemetry Traces with make_set_if in APL\nDESCRIPTION: A query example that identifies distinct services that processed spans with durations greater than 1 second, grouped by trace ID using make_set_if.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set-if.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize make_set_if(['service.name'], duration > 1s) by ['trace_id']\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Client in TypeScript\nDESCRIPTION: Create and configure an Axiom client using the JS library in TypeScript.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/ingest.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst client = new Client({\n    token: process.env.AXIOM_TOKEN\n});\n```\n\n----------------------------------------\n\nTITLE: Identifying Unique Users in HTTP Logs using APL\nDESCRIPTION: This query uses the distinct operator to identify unique users who made HTTP requests in a system.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/distinct-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| distinct id\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry for Manual Instrumentation\nDESCRIPTION: This code sets up OpenTelemetry configuration for manual instrumentation in a Django project, including tracer provider and exporter setup.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.resources import Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\ndef configure_opentelemetry():\n    resource = Resource(attributes={\"service.name\": \"your-django-app\"})\n    trace.set_tracer_provider(TracerProvider(resource=resource))\n    otlp_exporter = OTLPSpanExporter(\n        endpoint=\"https://api.axiom.co/v1/traces\",\n        headers={\"Authorization\": \"Bearer API_TOKEN\", \"X-Axiom-Dataset\": \"DATASET_NAME\"}\n    )\n    span_processor = BatchSpanProcessor(otlp_exporter)\n    trace.get_tracer_provider().add_span_processor(span_processor)\n    return trace.get_tracer(__name__)\n\ntracer = configure_opentelemetry()\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenTelemetry for Java with Axiom Integration\nDESCRIPTION: This Java code snippet demonstrates how to set up OpenTelemetry tracing in a Java application and configure it to send data to Axiom. It includes creating a resource, setting up an OTLP/HTTP span exporter, and configuring a BatchSpanProcessor with the necessary Axiom-specific headers.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/opentelemetry.mdx#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npackage com.example;\n\nimport io.opentelemetry.api.OpenTelemetry;\nimport io.opentelemetry.api.common.Attributes;\nimport io.opentelemetry.api.common.AttributeKey;\nimport io.opentelemetry.exporter.otlp.http.trace.OtlpHttpSpanExporter;\nimport io.opentelemetry.sdk.OpenTelemetrySdk;\nimport io.opentelemetry.sdk.resources.Resource;\nimport io.opentelemetry.sdk.trace.SdkTracerProvider;\nimport io.opentelemetry.sdk.trace.export.BatchSpanProcessor;\n\nimport java.util.concurrent.TimeUnit;\n\npublic class OtelConfiguration {\n    // OpenTelemetry configuration\n    private static final String SERVICE_NAME = \"SERVICE_NAME\";\n    private static final String SERVICE_VERSION = \"SERVICE_VERSION\";\n    private static final String OTLP_ENDPOINT = \"https://api.axiom.co/v1/traces\";\n    private static final String BEARER_TOKEN = \"Bearer API_TOKEN\";\n    private static final String AXIOM_DATASET = \"DATASET_NAME\";\n\n    public static OpenTelemetry initializeOpenTelemetry() {\n        // Create a Resource with service name and version\n        Resource resource = Resource.getDefault()\n                .merge(Resource.create(Attributes.of(\n                        AttributeKey.stringKey(\"service.name\"), SERVICE_NAME,\n                        AttributeKey.stringKey(\"service.version\"), SERVICE_VERSION\n                )));\n\n        // Create an OTLP/HTTP span exporter\n        OtlpHttpSpanExporter spanExporter = OtlpHttpSpanExporter.builder()\n                .setEndpoint(OTLP_ENDPOINT)\n                .addHeader(\"Authorization\", BEARER_TOKEN)\n                .addHeader(\"X-Axiom-Dataset\", AXIOM_DATASET)\n                .build();\n\n        // Create a BatchSpanProcessor with the OTLP/HTTP exporter\n        SdkTracerProvider sdkTracerProvider = SdkTracerProvider.builder()\n                .addSpanProcessor(BatchSpanProcessor.builder(spanExporter)\n                        .setScheduleDelay(100, TimeUnit.MILLISECONDS)\n                        .build())\n                .setResource(resource)\n                .build();\n\n        // Build and register the OpenTelemetry SDK\n        OpenTelemetrySdk openTelemetry = OpenTelemetrySdk.builder()\n                .setTracerProvider(sdkTracerProvider)\n                .buildAndRegisterGlobal();\n\n        // Add a shutdown hook to properly close the SDK\n        Runtime.getRuntime().addShutdownHook(new Thread(sdkTracerProvider::close));\n\n        return openTelemetry;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Server Context and Request Tracking to Axiom Logs in Next.js\nDESCRIPTION: This code shows how to add server execution context to Axiom logs using the store configuration option. It demonstrates adding both a randomly generated request_id and extracting a trace_id from request headers to enable request tracking across services.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_21\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger, AxiomJSTransport } from '@axiomhq/logging';\nimport { createAxiomRouteHandler, nextJsFormatters } from '@axiomhq/nextjs';\nimport { NextRequest } from 'next/server';\n\nimport axiomClient from '@/lib/axiom/axiom';\n\nexport const logger = new Logger({\n  transports: [\n    new AxiomJSTransport({ axiom: axiomClient, dataset: process.env.NEXT_PUBLIC_AXIOM_DATASET! }),\n  ],\n  formatters: nextJsFormatters,\n});\n\nexport const withAxiom = createAxiomRouteHandler(logger, {\n  store: (req: NextRequest) => {\n    return {\n      request_id: crypto.randomUUID(),\n      trace_id: req.headers.get('x-trace-id'),\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with sumif in APL\nDESCRIPTION: This example demonstrates how to use sumif to calculate the total request duration for HTTP requests with a 200 status code in a log dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sumif.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize total_req_duration = sumif(req_duration_ms, status == '200')\n```\n\n----------------------------------------\n\nTITLE: HTTP Response Analysis with Time Binning\nDESCRIPTION: Analyzes HTTP 5xx responses over 7 days with daily binning and histogram of response header sizes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_23\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where _time > ago(7d)\n| where req_duration_ms >= 5 and req_duration_ms < 6\n| summarize count(), histogram(resp_header_size_bytes, 20) by bin(_time, 1d)\n| order by _time desc\n```\n\n----------------------------------------\n\nTITLE: Implementing Server Context in Next.js Middleware with Axiom\nDESCRIPTION: Shows how to use runWithServerContext in Next.js middleware to add trace_id from request headers to log fields. This enables consistent request tracking across middleware operations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_23\n\nLANGUAGE: typescript\nCODE:\n```\nimport { runWithServerContext } from '@axiomhq/nextjs';\n\nexport const middleware = (req: NextRequest) => \n  runWithServerContext({ trace_id: req.headers.get('x-trace-id') }, () => {\n    // trace_id will be added to the log fields\n    logger.info(...transformMiddlewareRequest(request));\n\n    // trace_id will also be added to the log fields\n    log.info(\"Hello from middleware\");\n\n    event.waitUntil(logger.flush());\n    return NextResponse.next();\n  });\n```\n\n----------------------------------------\n\nTITLE: Exploring Log Data Schema with getschema in APL\nDESCRIPTION: This snippet demonstrates how to use getschema to explore the schema of log data before running queries. It returns field names, data types, and other metadata for the 'sample-http-logs' dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/getschema-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] | getschema\n```\n\n----------------------------------------\n\nTITLE: Integrating Axiom with Python Logging Module\nDESCRIPTION: Shows how to set up AxiomHandler to integrate with Python's built-in logging module for sending logs to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/python.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport axiom_py\nfrom axiom_py.logging import AxiomHandler\nimport logging\n\ndef setup_logger():\n    client = axiom_py.Client()\n    handler = AxiomHandler(client, \"DATASET_NAME\")\n    logging.getLogger().addHandler(handler)\n```\n\n----------------------------------------\n\nTITLE: Implementing Main Program with Logging\nDESCRIPTION: Main program implementation that demonstrates various logging scenarios and simulated operations with different log levels.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing System;\nusing System.Threading.Tasks;\n\nclass Program\n{\n    static async Task Main(string[] args)\n    {\n        // Log the application startup event with an \"INFO\" log level\n        await AxiomLogger.LogToAxiom(\"Application started\", \"INFO\");\n\n        // Call the SimulateOperations method to simulate various application operations\n        await SimulateOperations();\n\n        // Log the .NET runtime version information with an \"INFO\" log level\n        await AxiomLogger.LogToAxiom($\"CLR version: {Environment.Version}\", \"INFO\");\n\n        // Log the application shutdown event with an \"INFO\" log level\n        await AxiomLogger.LogToAxiom(\"Application shutting down\", \"INFO\");\n    }\n\n    static async Task SimulateOperations()\n    {\n        // Log the start of operations with a \"DEBUG\" log level\n        await AxiomLogger.LogToAxiom(\"Starting operations\", \"DEBUG\");\n\n        // Log the database connection event with a \"DEBUG\" log level\n        await AxiomLogger.LogToAxiom(\"Connecting to database\", \"DEBUG\");\n        await Task.Delay(500); // Simulated delay\n        // Log the successful database connection with an \"INFO\" log level\n        await AxiomLogger.LogToAxiom(\"Connected to database successfully\", \"INFO\");\n\n        // Log the user data retrieval event with a \"DEBUG\" log level\n        await AxiomLogger.LogToAxiom(\"Retrieving user data\", \"DEBUG\");\n        await Task.Delay(1000);\n        // Log the number of retrieved user records with an \"INFO\" log level\n        await AxiomLogger.LogToAxiom(\"Retrieved 100 user records\", \"INFO\");\n\n        // Log the user preference update event with a \"DEBUG\" log level\n        await AxiomLogger.LogToAxiom(\"Updating user preferences\", \"DEBUG\");\n        await Task.Delay(800);\n        // Log the successful user preference update with an \"INFO\" log level\n        await AxiomLogger.LogToAxiom(\"Updated user preferences successfully\", \"INFO\");\n\n        try\n        {\n            // Log the payment processing event with a \"DEBUG\" log level\n            await AxiomLogger.LogToAxiom(\"Processing payments\", \"DEBUG\");\n            await Task.Delay(1500);\n            // Intentionally throw an exception to demonstrate error logging\n            throw new Exception(\"Payment gateway unavailable\");\n        }\n        catch (Exception ex)\n        {\n            // Log the payment processing failure with an \"ERROR\" log level\n            await AxiomLogger.LogToAxiom($\"Payment processing failed: {ex.Message}\", \"ERROR\");\n        }\n\n        // Log the email notification sending event with a \"DEBUG\" log level\n        await AxiomLogger.LogToAxiom(\"Sending email notifications\", \"DEBUG\");\n        await Task.Delay(1200);\n        // Log the number of sent email notifications with an \"INFO\" log level\n        await AxiomLogger.LogToAxiom(\"Sent 50 email notifications\", \"INFO\");\n\n        // Log the high memory usage detection with a \"WARN\" log level\n        await AxiomLogger.LogToAxiom(\"Detected high memory usage\", \"WARN\");\n        await Task.Delay(500);\n        // Log the memory usage normalization with an \"INFO\" log level\n        await AxiomLogger.LogToAxiom(\"Memory usage normalized\", \"INFO\");\n\n        // Log the completion of operations with a \"DEBUG\" log level\n        await AxiomLogger.LogToAxiom(\"Operations completed\", \"DEBUG\");\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Dependencies for .NET\nDESCRIPTION: This snippet shows the command to install necessary NuGet packages for OpenTelemetry integration in a .NET project. It includes packages for OpenTelemetry core, exporters, and instrumentations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package OpenTelemetry --version 1.7.0\ndotnet add package OpenTelemetry.Exporter.Console --version 1.7.0\ndotnet add package OpenTelemetry.Exporter.OpenTelemetryProtocol --version 1.7.0\ndotnet add package OpenTelemetry.Extensions.Hosting --version 1.7.0\ndotnet add package OpenTelemetry.Instrumentation.AspNetCore --version 1.7.1\ndotnet add package OpenTelemetry.Instrumentation.Http --version 1.6.0-rc.1\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Traces Analysis with dcountif\nDESCRIPTION: Example query demonstrating how to count unique trace IDs for a specific service.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcountif.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize dcountif(trace_id, ['service.name'] == 'frontend')\n```\n\n----------------------------------------\n\nTITLE: Laravel Logging Configuration\nDESCRIPTION: Complete logging configuration file (logging.php) that defines various log channels including Axiom integration\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-laravel.mdx#2025-04-22_snippet_1\n\nLANGUAGE: php\nCODE:\n```\n<?php\n\nuse Monolog\\Handler\\NullHandler;\nuse Monolog\\Handler\\StreamHandler;\nuse Monolog\\Handler\\SyslogUdpHandler;\nuse Monolog\\Processor\\PsrLogMessageProcessor;\n\nreturn [\n\n    'default' => env('LOG_CHANNEL', 'stack'),\n\n    'deprecations' => [\n        'channel' => env('LOG_DEPRECATIONS_CHANNEL', 'null'),\n        'trace' => false,\n    ],\n\n    'channels' => [\n        'stack' => [\n            'driver' => 'stack',\n            'channels' => ['single'],\n            'ignore_exceptions' => false,\n        ],\n\n        'single' => [\n            'driver' => 'single',\n            'path' => storage_path('logs/laravel.log'),\n            'level' => env('LOG_LEVEL', 'debug'),\n            'replace_placeholders' => true,\n        ],\n\n        'axiom' => [\n            'driver' => 'monolog',\n            'handler' => App\\Logging\\AxiomHandler::class,\n            'level' => env('LOG_LEVEL', 'debug'),\n            'with' => [\n                'apiToken' => env('AXIOM_API_TOKEN'),\n                'dataset' => env('AXIOM_DATASET'),\n            ],\n        ],\n\n        'daily' => [\n            'driver' => 'daily',\n            'path' => storage_path('logs/laravel.log'),\n            'level' => env('LOG_LEVEL', 'debug'),\n            'days' => 14,\n            'replace_placeholders' => true,\n        ],\n\n        'stderr' => [\n            'driver' => 'monolog',\n            'level' => env('LOG_LEVEL', 'debug'),\n            'handler' => StreamHandler::class,\n            'formatter' => env('LOG_STDERR_FORMATTER'),\n            'with' => [\n                'stream' => 'php://stderr',\n            ],\n            'processors' => [PsrLogMessageProcessor::class],\n        ],\n\n        'syslog' => [\n            'driver' => 'syslog',\n            'level' => env('LOG_LEVEL', 'debug'),\n            'facility' => LOG_USER,\n            'replace_placeholders' => true,\n        ],\n\n        'errorlog' => [\n            'driver' => 'errorlog',\n            'level' => env('LOG_LEVEL', 'debug'),\n            'replace_placeholders' => true,\n        ],\n\n        'null' => [\n            'driver' => 'monolog',\n            'handler' => NullHandler::class,\n        ],\n\n        'emergency' => [\n            'path' => storage_path('logs/laravel.log'),\n        ],\n    ],\n\n];\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry in Django settings.py\nDESCRIPTION: This snippet shows how to add OpenTelemetry Django instrumentation to the project's settings.py file, enabling automatic span creation for HTTP requests handled by Django.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom opentelemetry.instrumentation.django import DjangoInstrumentor\n\nDjangoInstrumentor().instrument()\n\n# Build paths inside the project like this: BASE_DIR / 'subdir'.\nBASE_DIR = Path(__file__).resolve().parent.parent\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenTelemetry in Django Settings\nDESCRIPTION: Integration of OpenTelemetry configuration in Django settings file to enable automatic telemetry data capture.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# settings.py\nfrom otel_config import configure_opentelemetry\nconfigure_opentelemetry()\n```\n\n----------------------------------------\n\nTITLE: Analyzing Security Logs with min Function\nDESCRIPTION: Example of using min function to analyze security logs for minimum request duration by HTTP status code.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/min.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize min(req_duration_ms) by status\n```\n\n----------------------------------------\n\nTITLE: Grouped Status Code Analysis in Sumo Logic and APL\nDESCRIPTION: Queries that categorize HTTP status codes into groups (200s, 300s, etc.) and count occurrences. Sumo Logic uses regex matching, while APL uses case expressions to categorize status codes, methods, and content types.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=Apache/Access\n| timeslice 15m\n| if (status_code matches \"20*\",1,0) as resp_200\n| if (status_code matches \"30*\",1,0) as resp_300\n| if (status_code matches \"40*\",1,0) as resp_400\n| if (status_code matches \"50*\",1,0) as resp_500\n| if (!(status_code matches \"20*\" or status_code matches \"30*\" or status_code matches \"40*\" or status_code matches \"50*\"),1,0) as resp_others\n| count(*), sum(resp_200) as tot_200, sum(resp_300) as tot_300, sum(resp_400) as tot_400, sum(resp_500) as tot_500, sum(resp_others) as tot_others by _timeslice\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend MethodCategory = case(\n   method == \"GET\", \"GET Requests\",\n   method == \"POST\", \"POST Requests\",\n   method == \"PUT\", \"PUT Requests\",\n   method == \"DELETE\", \"DELETE Requests\",\n   \"Other Methods\")\n| extend StatusCodeCategory = case(\n   status startswith \"2\", \"Success\",\n   status startswith \"3\", \"Redirection\",\n   status startswith \"4\", \"Client Error\",\n   status startswith \"5\", \"Server Error\",\n   \"Unknown Status\")\n| extend ContentTypeCategory = case(\n   content_type == \"text/csv\", \"CSV\",\n   content_type == \"application/json\", \"JSON\",\n   content_type == \"text/html\", \"HTML\",\n   \"Other Types\")\n| summarize Count=count() by bin_auto(_time), StatusCodeCategory, MethodCategory, ContentTypeCategory\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Response Body Size Using Axiom Query Language\nDESCRIPTION: Kusto query that summarizes HTTP log data by calculating the average response body size in bytes from the sample-http-logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/statistic.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize avg(resp_body_size_bytes)\n```\n\n----------------------------------------\n\nTITLE: Sending data to Axiom using @axiomhq/js\nDESCRIPTION: Example of ingesting data into Axiom using the @axiomhq/js library.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\naxiom.ingest('DATASET_NAME', [{ foo: 'bar' }]);\nawait axiom.flush();\n```\n\n----------------------------------------\n\nTITLE: Analyzing HTTP Logs with make_set_if in APL\nDESCRIPTION: A query example that uses make_set_if to get distinct cities from which HTTP requests originated, but only for requests exceeding 500ms, grouped by HTTP method.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set-if.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize make_set_if(['geo.city'], req_duration_ms > 500) by ['method']\n```\n\n----------------------------------------\n\nTITLE: Configuring Fluentd with HTTP Output Plugin for Axiom\nDESCRIPTION: This snippet demonstrates how to configure Fluentd to send data to Axiom using the HTTP output plugin. It sets up a forward source and defines a match block for sending data to Axiom's API endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluentd.mdx#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<source>\n  @type forward\n  port 24224\n</source>\n\n<match *.**>\n  @type http\n\n  endpoint https://api.axiom.co/v1/datasets/DATASET_NAME/ingest\n  # Authorization Bearer should be an ingest token\n  headers {\"Authorization\": \"Bearer API_TOKEN\"}\n  json_array false\n  open_timeout 3\n\n  <format>\n    @type json\n  </format>\n\n  <buffer>\n    flush_interval 5s\n  </buffer>\n</match>\n```\n\n----------------------------------------\n\nTITLE: Sending Kubernetes Logs to Axiom with Vector\nDESCRIPTION: A Vector configuration for collecting Kubernetes logs and sending them to Axiom. Includes advanced options for filtering logs by pod name, namespace, and custom labels.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\ntype = \"kubernetes_logs\"\nauto_partial_merge = true\nignore_older_secs = 600\nread_from = \"beginning\"\nself_node_name = \"${VECTOR_SELF_NODE_NAME}\"\nexclude_paths_glob_patterns = [ \"**/exclude/**\" ]\nextra_field_selector = \"metadata.name!=pod-name-to-exclude\"\nextra_label_selector = \"my_custom_label!=my_value\"\nextra_namespace_label_selector = \"my_custom_label!=my_value\"\nmax_read_bytes = 2_048\nmax_line_bytes = 32_768\nfingerprint_lines = 1\nglob_minimum_cooldown_ms = 60_000\ndelay_deletion_ms = 60_000\ndata_dir = \"/var/lib/vector\"\ntimezone = \"local\"\n\n[sinks.axiom]\ntype = \"axiom\"\ninputs = [\"my_source_id\"]\ntoken = \"API_TOKEN\"\ndataset = \"DATASET_NAME\"\n```\n\n----------------------------------------\n\nTITLE: Sending Docker Logs to Axiom with Vector\nDESCRIPTION: A Vector configuration for collecting Docker logs from the Docker socket and forwarding them to Axiom. Requires the docker_logs source type and appropriate permissions to access the Docker socket.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n# Define the Docker logs source\n[sources.docker_logs]\ntype = \"docker_logs\"\ndocker_host = \"unix:///var/run/docker.sock\"\n\n# Define the Axiom sink\n[sinks.axiom]\ntype = \"axiom\"\ninputs = [\"docker_logs\"]\ndataset = \"DATASET_NAME\"\ntoken = \"API_TOKEN\"\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Auto-Instrumentation for Node.js\nDESCRIPTION: This bash command installs the OpenTelemetry auto-instrumentation package for Node.js. This package simplifies the process of adding telemetry data to applications by automatically instrumenting common frameworks and libraries.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @opentelemetry/auto-instrumentations-node\n```\n\n----------------------------------------\n\nTITLE: Analyzing OpenTelemetry Trace Durations with percentiles_arrayif in APL\nDESCRIPTION: This example uses the percentiles_arrayif function to analyze the duration of OpenTelemetry traces for POST requests. It calculates the 50th, 90th, and 99th percentiles of the duration field from the 'otel-demo-traces' dataset, filtering for POST methods.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-arrayif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize percentiles_arrayif(duration, dynamic([50, 90, 99, 99]), ['method'] == \"POST\") by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Traces Analysis with External Data in APL\nDESCRIPTION: Query that uses the externaldata operator to extend OpenTelemetry trace data with human-readable service names from an external source.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/externaldata-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\nlet LookupTable = externaldata (serviceName: string, humanreadableServiceName: string) [\"http://example.com/lookup-table.csv\"] with (format=\"csv\", ignoreFirstRecord=true);\n['otel-demo-traces']\n| lookup kind=leftouter LookupTable on $left.['service.name'] == $right.serviceName\n| project _time, span_id, ['service.name'], humanreadableServiceName\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL Conditional Counting with APL Countif\nDESCRIPTION: This example shows how to count HTTP 500 errors in Splunk SPL compared to the equivalent APL query using countif.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/countif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats count(eval(status=\"500\")) AS error_count\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize countif(status == '500')\n```\n\n----------------------------------------\n\nTITLE: Configuring Filebeat for Axiom Integration\nDESCRIPTION: YAML configuration for setting up Filebeat to ship log data to Axiom. Disables index lifecycle management and configures the Elasticsearch output to point to Axiom's API endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsetup.ilm.enabled: false\nfilebeat.inputs:\n  - type: log\n    # Specify the path of the system log files to be sent to Axiom deployment.\n    paths:\n      - $PATH_TO_LOG_FILE\noutput.elasticsearch:\n  hosts: ['https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic']\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n```\n\n----------------------------------------\n\nTITLE: Analyzing Request Durations in Security Logs with APL Histogram\nDESCRIPTION: Uses the histogram aggregation to analyze the frequency distribution of request durations for HTTP 200 responses in security logs, helping to identify patterns and potential anomalies.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/histogram.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '200'\n| summarize histogram(req_duration_ms, 50) by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Go SDK\nDESCRIPTION: Command to install the Axiom Go SDK package using go get.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/go.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngo get github.com/axiomhq/axiom-go/axiom\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Exporter Configuration\nDESCRIPTION: Configuration for OpenTelemetry exporter to send trace data to Axiom including TracerProvider setup and OTLP exporter configuration\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-python.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.sdk.resources import Resource, SERVICE_NAME\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n\n# Define the service name resource for the tracer.\nresource = Resource(attributes={\n    SERVICE_NAME: \"NAME_OF_SERVICE\" # Replace `NAME_OF_SERVICE` with the name of the service you want to trace.\n})\n\n# Create a TracerProvider with the defined resource for creating tracers.\nprovider = TracerProvider(resource=resource)\n\n# Configure the OTLP/HTTP Span Exporter with Axiom headers and endpoint. Replace `API_TOKEN` with your Axiom API key, and replace `DATASET_NAME` with the name of the Axiom dataset where you want to send data.\notlp_exporter = OTLPSpanExporter(\n    endpoint=\"https://api.axiom.co/v1/traces\",\n    headers={\n        \"Authorization\": \"Bearer API_TOKEN\",\n        \"X-Axiom-Dataset\": \"DATASET_NAME\"\n    }\n)\n\n# Create a BatchSpanProcessor with the OTLP exporter to batch and send trace spans.\nprocessor = BatchSpanProcessor(otlp_exporter)\nprovider.add_span_processor(processor)\n\n# Set the TracerProvider as the global tracer provider.\ntrace.set_tracer_provider(provider)\n\n# Define a tracer for external use in different parts of the app.\nservice1_tracer = trace.get_tracer(\"service1\")\n```\n\n----------------------------------------\n\nTITLE: AWS Lambda Function for IoT Data Processing in Python\nDESCRIPTION: Python Lambda function that processes IoT device data and forwards it to Axiom's API. The function handles authentication, data formatting, and makes HTTP requests to Axiom's ingest endpoint. Requires DATASET_NAME and API_TOKEN environment variables.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-iot-rules.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os  # Import the os module to access environment variables\nimport json  # Import the json module to handle JSON data\nimport requests  # Import the requests module to make HTTP requests\n\ndef lambda_handler(event, context):\n    # Retrieve the dataset name from the environment variable\n    dataset_name = os.environ['DATASET_NAME']\n\n    # Construct the Axiom API URL using the dataset name\n    axiom_api_url = f\"https://api.axiom.co/v1/datasets/{dataset_name}/ingest\"\n\n    # Retrieve the Axiom API token from the environment variable\n    api_token = os.environ['API_TOKEN']\n\n    # Define the headers for the HTTP request to Axiom\n    headers = {\n        \"Authorization\": f\"Bearer {api_token}\",  # Set the Authorization header with the token\n        \"Content-Type\": \"application/json\",  # Specify the content type as JSON\n        \"X-Axiom-Dataset\": dataset_name  # Include the dataset name in the headers\n    }\n\n    # Create the payload for the HTTP request\n    payload = {\n        \"tags\": {\"source\": \"aws-iot\"},  # Add a tag to indicate the source of the data\n        \"events\": [{\"timestamp\": event['timestamp'], \"attributes\": event}]  # Include the event data\n    }\n\n    # Send a POST request to the Axiom API with the headers and payload\n    response = requests.post(axiom_api_url, headers=headers, data=json.dumps(payload))\n\n    # Return the status code and a confirmation message\n    return {\n        'statusCode': response.status_code,  # Return the HTTP status code from the Axiom API response\n        'body': json.dumps('Log sent to Axiom!')  # Return a confirmation message as JSON\n    }\n```\n\n----------------------------------------\n\nTITLE: Using ipv4_compare in APL with Sample Data\nDESCRIPTION: This query extends the sample HTTP logs with two IP addresses and compares them using the ipv4_compare function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-compare.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip1 = '192.168.1.1', ip2 = '192.168.1.10'\n| extend comparison = ipv4_compare(ip1, ip2)\n```\n\n----------------------------------------\n\nTITLE: Filtering HTTP Logs with Where Operator in Splunk SPL and APL\nDESCRIPTION: Comparison between Splunk SPL and APL syntax for filtering logs based on HTTP status code. The examples show how to filter for status code 200 in both query languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nindex=main | where status=\"200\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '200'\n```\n\n----------------------------------------\n\nTITLE: Basic Vector Configuration for File Logs to Axiom\nDESCRIPTION: A basic Vector configuration that reads logs from files and sends them to Axiom using the Axiom sink. Requires specifying a source ID, log file path, sink ID, API token, and dataset name.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.VECTOR_SOURCE_ID]\ntype = \"file\"\ninclude = [\"PATH_TO_LOGS\"]\n\n[sinks.SINK_ID]\ntype = \"axiom\"\ninputs = [\"VECTOR_SOURCE_ID\"]\ntoken = \"API_TOKEN\"\ndataset = \"DATASET_NAME\"\n```\n\n----------------------------------------\n\nTITLE: Identifying Longest Duration Spans in OpenTelemetry Traces\nDESCRIPTION: This example query demonstrates using the top operator to find the 5 spans with the longest durations in OpenTelemetry traces. It helps quickly identify the most time-consuming operations in a distributed tracing system.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/top-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| top 5 by duration\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenTelemetry Tracer in Ruby\nDESCRIPTION: This snippet demonstrates how to initialize an OpenTelemetry tracer in a Ruby application. The tracer is obtained from the global tracer provider and is used to start and manage spans.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-ruby.mdx#2025-04-22_snippet_2\n\nLANGUAGE: ruby\nCODE:\n```\ntracer = OpenTelemetry.tracer_provider.tracer('my-tracer')\n```\n\n----------------------------------------\n\nTITLE: Log analysis example using make_list in APL\nDESCRIPTION: Query demonstrating how to use make_list to collect all URIs accessed by each user in HTTP logs, useful for identifying browsing patterns.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize uris=make_list(uri) by id\n```\n\n----------------------------------------\n\nTITLE: Sample JSON Event Structure for Axiom\nDESCRIPTION: This snippet demonstrates the structure of a typical event sent to Axiom. It includes various fields such as service name, severity, duration, customer ID, tags, and metadata. Events in Axiom follow the JSON specification for supported field types.\nSOURCE: https://github.com/axiomhq/docs/blob/main/getting-started-guide/getting-started.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"service\": \"api-http\",\n  \"severity\": \"error\",\n  \"duration\": 231,\n  \"customer_id\": \"ghj34g32poiu4\",\n  \"tags\": [\"aws-east-1\", \"zone-b\"],\n  \"metadata\": {\n    \"version\": \"3.1.2\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration with Custom Compression Algorithm\nDESCRIPTION: Example Vector configuration file that demonstrates how to set a specific compression algorithm (gzip) when sending data to Axiom. This is useful when upgrading to Vector v0.42.0+ which uses zstd compression by default.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\n# ...\n\n[transforms.migrate]\ntype = \"remap\"\ninputs = [ \"k8s\"]\nfile= 'example.vrl' # See above\n\n[sinks.debug]\ntype = \"axiom\"\ncompression = \"gzip\" # Set the compression algorithm\ninputs = [ \"migrate\" ]\ndataset = \"DATASET_NAME\" # No change\ntoken = \"API_TOKEN\" # No change\n\n[sinks.debug.encoding]\ncodec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Security Logs Analysis with sumif in APL\nDESCRIPTION: This example demonstrates using sumif to calculate the total request duration for failed HTTP requests (non-200 status codes) for security log analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sumif.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize total_req_duration_failed = sumif(req_duration_ms, status != '200')\n```\n\n----------------------------------------\n\nTITLE: Initializing ActivitySource for Manual Instrumentation in C#\nDESCRIPTION: Define an ActivitySource to create activities (spans) for tracing specific operations within your application. This is the first step in manual instrumentation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nprivate static readonly ActivitySource MyActivitySource = new ActivitySource(\"MyActivitySourceName\");\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL distinct count with APL dcount\nDESCRIPTION: Comparison between Splunk SPL's dc function and APL's dcount function for counting distinct values. Splunk uses the stats command with dc() while APL uses the summarize operation with dcount().\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcount.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats dc(user_id) AS distinct_users\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize dcount(id)\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Logger and Exporting Utils in React\nDESCRIPTION: Sets up a Logger instance with Axiom client and exports useLogger and WebVitals components for use in React applications.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/react.mdx#2025-04-22_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\n'use client';\n\nimport { Logger, AxiomJSTransport } from '@axiomhq/logging';\nimport { Axiom } from '@axiomhq/js';\nimport { createUseLogger, createWebVitalsComponent } from '@axiomhq/react';\n\nconst axiomClient = new Axiom({\n  token: process.env.AXIOM_TOKEN!,\n});\n\nexport const logger = new Logger({\n  transports: [\n    new AxiomJSTransport({\n      client: axiomClient,\n      dataset: process.env.AXIOM_DATASET!,\n    }),\n  ],\n});\n\nconst useLogger = createUseLogger(logger);\nconst WebVitals = createWebVitalsComponent(logger);\n\nexport { useLogger, WebVitals };\n```\n\n----------------------------------------\n\nTITLE: Configuring Heartbeat for Multiple Monitor Types\nDESCRIPTION: This configuration sets up Heartbeat with three monitor types: ICMP for ping checks, TCP for port monitoring, and HTTP for website monitoring. It configures the monitors with different intervals and deploys to Axiom for uptime tracking.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n# Disable index lifecycle management (ILM)\nsetup.ilm.enabled: false\nheartbeat.monitors:\n  - type: icmp\n    schedule: '*/5 * * * * * *'\n    hosts: ['myhost']\n    id: my-icmp-service\n    name: My ICMP Service\n  - type: tcp\n    schedule: '@every 5s'\n    hosts: ['myhost:12345']\n    mode: any\n    id: my-tcp-service\n  - type: http\n    schedule: '@every 5s'\n    urls: ['http://example.net']\n    service.name: apm-service-name\n    id: my-http-service\n    name: My HTTP Service\noutput.elasticsearch:\n  hosts: ['https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic']\n  # token should be an API token\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n```\n\n----------------------------------------\n\nTITLE: Counting Events with APL\nDESCRIPTION: Basic APL query that returns the total count of events from the sample-http-logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/explore.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count()\n```\n\n----------------------------------------\n\nTITLE: Basic APL Query Structure\nDESCRIPTION: Shows the fundamental structure of an APL query with dataset selection, filtering, projection, and aggregation operations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| <DatasetName>\n| <FilteringOperation> \n| <ProjectionOperation> \n| <AggregationOperation>\n```\n\n----------------------------------------\n\nTITLE: Service Name Enrichment Example using lookup in APL\nDESCRIPTION: This comprehensive example demonstrates how to use the lookup operator to add human-readable service names to a dataset. It creates a lookup table using datatable and then joins it with OpenTelemetry traces based on service name matching.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/lookup-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\nlet LookupTable=datatable(serviceName:string, humanreadableServiceName:string)[\n\t'frontend', 'Frontend',\n\t'frontendproxy', 'Frontend proxy',\n\t'flagd', 'Flagd',\n\t'productcatalogservice', 'Product catalog',\n\t'loadgenerator', 'Load generator',\n\t'checkoutservice', 'Checkout',\n\t'cartservice', 'Cart',\n\t'recommendationservice', 'Recommendations',\n\t'emailservice', 'Email',\n\t'adservice', 'Ads',\n\t'shippingservice', 'Shipping',\n\t'quoteservice', 'Quote',\n\t'currencyservice', 'Currency',\n\t'paymentservice', 'Payment',\n\t'frauddetectionservice', 'Fraud detection',\n];\n['otel-demo-traces']\n| lookup kind=leftouter LookupTable on $left.['service.name'] == $right.serviceName\n| project _time, span_id, ['service.name'], humanreadableServiceName\n```\n\n----------------------------------------\n\nTITLE: Manually Creating and Managing Spans in Ruby with OpenTelemetry\nDESCRIPTION: This code snippet shows how to manually create and manage spans in a Ruby application using OpenTelemetry. It demonstrates starting a span, handling exceptions, setting span status, and ensuring the span is finished.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-ruby.mdx#2025-04-22_snippet_3\n\nLANGUAGE: ruby\nCODE:\n```\nspan = tracer.start_span('operation_name')\nbegin\n  # Perform operation\nrescue => e\n  span.record_exception(e)\n  span.status = OpenTelemetry::Trace::Status.error(\"Operation failed\")\nensure\n  span.finish\nend\n```\n\n----------------------------------------\n\nTITLE: Calculating 90th percentile of span durations for OpenTelemetry traces\nDESCRIPTION: APL query example that filters for a specific service and calculates the 90th percentile of span durations, helping to analyze service performance.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentile.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| where ['service.name'] == 'checkoutservice'\n| summarize percentile(duration, 90)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Axiom Logger Handler in PHP\nDESCRIPTION: Creates a custom AxiomHandler class that extends Monolog's AbstractProcessingHandler to manage log forwarding to Axiom. Includes cURL initialization, error handling, and JSON formatting of log messages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-laravel.mdx#2025-04-22_snippet_5\n\nLANGUAGE: php\nCODE:\n```\n<?php\n\nnamespace App\\Logging;\n\nuse Monolog\\Handler\\AbstractProcessingHandler;\nuse Monolog\\Logger;\nuse Monolog\\LogRecord;\nuse Monolog\\Formatter\\FormatterInterface;\n\nclass AxiomHandler extends AbstractProcessingHandler\n{\n    private $apiToken;\n    private $dataset;\n\n    public function __construct($level = Logger::DEBUG, bool $bubble = true, $apiToken = null, $dataset = null)\n    {\n        parent::__construct($level, $bubble);\n        $this->apiToken = $apiToken;\n        $this->dataset = $dataset;\n    }\n\n    private function initializeCurl(): \\CurlHandle\n    {\n        $endpoint = \"https://api.axiom.co/v1/datasets/{$this->dataset}/ingest\";\n        $ch = curl_init($endpoint);\n\n        curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\n        curl_setopt($ch, CURLOPT_POST, true);\n        curl_setopt($ch, CURLOPT_HTTPHEADER, [\n            'Authorization: Bearer ' . $this->apiToken,\n            'Content-Type: application/json',\n        ]);\n\n        return $ch;\n    }\n\n    protected function write(LogRecord $record): void\n    {\n        $ch = $this->initializeCurl();\n\n        $data = [\n            'message' => $record->message,\n            'context' => $record->context,\n            'level' => $record->level->getName(),\n            'channel' => $record->channel,\n            'extra' => $record->extra,\n        ];\n\n        $payload = json_encode([$data]);\n\n        curl_setopt($ch, CURLOPT_POSTFIELDS, $payload);\n        curl_exec($ch);\n        if (curl_errno($ch)) {\n            // Optionally log the curl error to PHP error log\n            error_log('Curl error: ' . curl_error($ch));\n        }\n\n        curl_close($ch);\n    }\n\n    protected function getDefaultFormatter(): FormatterInterface\n    {\n        return new \\Monolog\\Formatter\\JsonFormatter();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding OpenTelemetry Dependencies to Gemfile in Ruby\nDESCRIPTION: This snippet shows how to add the necessary OpenTelemetry gems to the Gemfile of a Ruby on Rails application. These gems provide the SDK, exporters, and instrumentations for various Rails components.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-ruby.mdx#2025-04-22_snippet_0\n\nLANGUAGE: ruby\nCODE:\n```\ngem 'opentelemetry-api'\ngem 'opentelemetry-sdk'\ngem 'opentelemetry-exporter-otlp'\ngem 'opentelemetry-instrumentation-rails'\ngem 'opentelemetry-instrumentation-http'\ngem 'opentelemetry-instrumentation-active_record', require: false\ngem 'opentelemetry-instrumentation-all'\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Rust SDK in Cargo.toml\nDESCRIPTION: Add the Axiom Rust SDK dependency to your Cargo.toml file. Replace VERSION with the latest version number from the GitHub Releases page.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/rust.mdx#2025-04-22_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[dependencies]\naxiom-rs = \"VERSION\"\n```\n\n----------------------------------------\n\nTITLE: Creating Span Links in Java OpenTelemetry\nDESCRIPTION: This snippet demonstrates how to create span links in OpenTelemetry, allowing association of spans that aren't in a parent-child relationship.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nprivate static void rollDiceWithLink() {\n    Span parentSpan = tracer.spanBuilder(\"rollWithLink\").startSpan();\n    try (Scope parentScope = parentSpan.makeCurrent()) {\n        Span childSpan = tracer.spanBuilder(\"rolldice\")\n                .addLink(parentSpan.getSpanContext())\n                .startSpan();\n        try (Scope childScope = childSpan.makeCurrent()) {\n            int roll = 1 + new Random().nextInt(6);\n            System.out.println(\"Dice roll result (with link): \" + roll);\n        } finally {\n            childSpan.end();\n        }\n    } finally {\n        parentSpan.end();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Client-Side Axiom Logger\nDESCRIPTION: Setup of client-side logger with React hooks and Web Vitals component integration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\n'use client';\nimport axiomClient from '@/lib/axiom/axiom';\nimport { Logger, AxiomJSTransport } from '@axiomhq/logging';\nimport { createUseLogger, createWebVitalsComponent } from '@axiomhq/react';\nimport { nextJsFormatters } from '@axiomhq/nextjs/client';\n\nexport const logger = new Logger({\n  transports: [\n    new AxiomJSTransport({ axiom: axiomClient, dataset: process.env.NEXT_PUBLIC_AXIOM_DATASET! }),\n  ],\n  formatters: nextJsFormatters,\n});\n\nconst useLogger = createUseLogger(logger);\nconst WebVitals = createWebVitalsComponent(logger);\n\nexport { useLogger, WebVitals };\n```\n\n----------------------------------------\n\nTITLE: Analyzing Response Times by Status Code in Security Logs\nDESCRIPTION: This query uses percentiles_array to calculate the 50th, 95th, and 99th percentiles of request durations for each status code in a sample HTTP log dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-array.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentiles_array(req_duration_ms, 50, 95, 99) by status\n```\n\n----------------------------------------\n\nTITLE: Converting SQL String Functions to APL Parse\nDESCRIPTION: Shows how to convert SQL string manipulation to APL parse operator for extracting duration from URI.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SUBSTRING(uri, CHARINDEX('duration=', uri) + 9, 3) AS req_duration_ms\nFROM sample_http_logs;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| parse uri with * \"duration=\" req_duration_ms:int\n```\n\n----------------------------------------\n\nTITLE: Automatic Instrumentation in Cloudflare Workers\nDESCRIPTION: Example of using automatic instrumentation in a Cloudflare Workers script with the @microlabs/otel-cf-workers package.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nimport { instrument } from '@microlabs/otel-cf-workers';\n\nexport default instrument(yourHandler, yourConfig);\n```\n\n----------------------------------------\n\nTITLE: Status Remapping Using Case Statements\nDESCRIPTION: Implements a remapper for HTTP logs using case statements to categorize data based on duration and size metrics.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_24\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend RemappedStatus = case(req_duration_ms >= 0.57, \"new data\", resp_body_size_bytes >= 1000, \"size bytes\", resp_header_size_bytes == 40, \"header values\", \"doesntmatch\")\n```\n\n----------------------------------------\n\nTITLE: Basic Where Operator Syntax in APL\nDESCRIPTION: The basic syntax of the where operator in APL, which is used to filter rows based on a boolean condition. The operator returns only rows that satisfy the specified condition.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| where condition\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Lambda Extension with AWS Lambda Terraform Module\nDESCRIPTION: This Terraform configuration uses the AWS Lambda Terraform module to set up a Lambda function with the Axiom Lambda Extension. It includes function configuration, environment variables, and the extension layer.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-lambda.mdx#2025-04-22_snippet_3\n\nLANGUAGE: terraform\nCODE:\n```\nmodule \"lambda_function\" {\n  source = \"terraform-aws-modules/lambda/aws\"\n\n  function_name = \"my-lambda1\"\n  description   = \"My awesome lambda function\"\n  handler       = \"index.lambda_handler\"\n  runtime       = \"python3.8\"\n\n  source_path = \"../src/lambda-function1\"\n\n  layers = [\n    \"arn:aws:lambda:AWS_REGION:694952825951:layer:axiom-extension-ARCH:VERSION\"\n  ]\n\n  environment_variables = {\n    AXIOM_TOKEN   = \"API_TOKEN\"\n    AXIOM_DATASET = \"DATASET_NAME\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using make_set for OpenTelemetry Trace Analysis in APL\nDESCRIPTION: Example query using make_set to gather unique service names involved in a trace, grouped by trace ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize make_set(['service.name']) by trace_id\n```\n\n----------------------------------------\n\nTITLE: Sending Virtual Machine Logs to Axiom with Nginx Source Type\nDESCRIPTION: This configuration collects Nginx logs from a virtual machine and sends them to Axiom using the HTTP output plugin. It includes a record transformer to add hostname and service information.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluentd.mdx#2025-04-22_snippet_6\n\nLANGUAGE: xml\nCODE:\n```\n<source>\n  @type tail\n  @id input_tail\n  <parse>\n    @type nginx\n  </parse>\n  path /var/log/nginx/access.log, /var/log/nginx/error.log\n  pos_file /var/log/fluentd/nginx.log.pos\n  tag nginx.logs\n  read_from_head true\n</source>\n\n<filter nginx.logs>\n  @type record_transformer\n  <record>\n    hostname \"#{Socket.gethostname}\"\n    service \"nginx\"\n  </record>\n</filter>\n\n<match nginx.logs>\n  @type http\n  @id out_http_axiom\n  @log_level info\n  endpoint \"#{ENV['AXIOM_URL'] || 'https://api.axiom.co'}\"\n  path \"/v1/datasets/DATASET_NAME/ingest\"\n  ssl_verify \"#{ENV['AXIOM_SSL_VERIFY'] || 'true'}\"\n  <headers>\n    Authorization \"Bearer API_TOKEN\"\n    Content-Type \"application/json\"\n  </headers>\n  <format>\n    @type json\n  </format>\n  <buffer>\n    @type memory\n    flush_mode interval\n    flush_interval 5s\n    chunk_limit_size 5MB\n    retry_forever true\n  </buffer>\n</match>\n```\n\n----------------------------------------\n\nTITLE: Consolidating Security Log Data with array_concat\nDESCRIPTION: Shows how to use array_concat to combine user IDs and geographic information from security logs to detect potential attack patterns.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-concat.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '500'\n| take 50\n| summarize failed_attempts = array_concat(pack_array(id), pack_array(['geo.city']))\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL SELECT with APL Project\nDESCRIPTION: Shows how the SQL SELECT statement is analogous to the project operator in APL, both being used to specify which fields to include in the result set.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT _time, status, uri FROM sample_http_logs;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project _time, status, uri\n```\n\n----------------------------------------\n\nTITLE: Sending Logs to Axiom using Go and Elastic Bulk API\nDESCRIPTION: Go code snippet demonstrating how to send log data to Axiom using the Elastic Bulk API. It includes creating an HTTP request, adding headers, and sending the request.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elasticsearch-bulk-api.mdx#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"net/http\"\n)\n\nfunc main() {\n\tdata := []byte(`{\"index\": {\"_index\": \"myindex\", \"_id\": \"1\"}}\n{\"@timestamp\": \"2023-06-06T12:00:00Z\", \"message\": \"axiom elastic bulk\", \"severity\": \"INFO\"}\n{\"index\": {\"_index\": \"myindex\", \"_id\": \"2\"}}\n{\"@timestamp\": \"2023-06-06T12:00:01Z\", \"message\": \"axiom elastic bulk api\", \"severity\": \"ERROR\"}\n`)\n\n\t// Create a new request using http\n\treq, err := http.NewRequest(\"POST\", \"https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic/_bulk\", bytes.NewBuffer(data))\n\tif err != nil {\n\t\tlog.Fatalf(\"Error creating request: %v\", err)\n\t}\n\n\t// Add authorization header to the request\n\treq.Header.Add(\"Authorization\", \"Bearer API_TOKEN\")\n\treq.Header.Add(\"Content-Type\", \"application/x-ndjson\")\n\n\t// Send request using http.Client\n\tclient := &http.Client{}\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\tlog.Fatalf(\"Error on response: %v\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\t// Read and print the response body\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\tlog.Fatalf(\"Error reading response body: %v\", err)\n\t}\n\tfmt.Printf(\"Response status: %s\\nResponse body: %s\\n\", resp.Status, string(body))\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Tracing in Python\nDESCRIPTION: Setup for OpenTelemetry tracing in Python applications. Configures a TracerProvider with service information and OTLP HTTP exporter to send traces to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/opentelemetry.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.sdk.resources import Resource, SERVICE_NAME\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n\n# Define the service name resource for the tracer.\nresource = Resource(attributes={\n    SERVICE_NAME: \"NAME_OF_SERVICE\" # Replace `NAME_OF_SERVICE` with the name of the service you want to trace.\n})\n\n# Create a TracerProvider with the defined resource for creating tracers.\nprovider = TracerProvider(resource=resource)\n\n# Configure the OTLP/HTTP Span Exporter with Axiom headers and endpoint. Replace `API_TOKEN` with your Axiom API key, and replace `DATASET_NAME` with the name of the Axiom dataset where you want to send data.\notlp_exporter = OTLPSpanExporter(\n    endpoint=\"https://api.axiom.co/v1/traces\",\n    headers={\n        \"Authorization\": \"Bearer API_TOKEN\",\n        \"X-Axiom-Dataset\": \"DATASET_NAME\"\n    }\n)\n\n# Create a BatchSpanProcessor with the OTLP exporter to batch and send trace spans.\nprocessor = BatchSpanProcessor(otlp_exporter)\nprovider.add_span_processor(processor)\n\n# Set the TracerProvider as the global tracer provider.\ntrace.set_tracer_provider(provider)\n\n# Define a tracer for external use in different parts of the app.\nservice1_tracer = trace.get_tracer(\"service1\")\n```\n\n----------------------------------------\n\nTITLE: Detecting Abnormal Patterns in Security Logs with Variance\nDESCRIPTION: Using the variance function on security logs to detect abnormal patterns in request behavior by HTTP status code, which may indicate security threats.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/variance.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize variance(req_duration_ms) by status\n```\n\n----------------------------------------\n\nTITLE: Collecting and Sending Scala Logs to Axiom with Fluentd\nDESCRIPTION: This configuration demonstrates how to collect Scala logs using a multiline parser and send them to Axiom using the HTTP output plugin. It includes buffer settings for efficient log transmission.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluentd.mdx#2025-04-22_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<source>\n  @type tail\n  @id scala_logs\n  <parse>\n    @type multiline\n    format_firstline /^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}/\n    format1 /^(?<time>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}) \\[(?<thread>.*)\\] (?<level>\\w+) (?<class>[\\w\\.$]+) - (?<message>.*)/\n  </parse>\n  path /var/log/scala-app.log\n  pos_file /var/log/fluentd/scala.log.pos\n  read_from_head true\n  tag scala.logs\n</source>\n\n<match scala.logs>\n  @type http\n  endpoint \"#{ENV['FLUENT_HTTP_ENDPOINT'] || 'https://api.axiom.co/v1/datasets/DATASET_NAME/ingest'}\"\n  headers {\"Authorization\": \"Bearer #{ENV['FLUENT_HTTP_TOKEN'] || '<your-token>'}\"}\n  <format>\n    @type json\n  </format>\n\n  <buffer>\n    @type memory\n    flush_mode interval\n    flush_interval 10s\n    chunk_limit_size 5M\n    retry_max_interval 30\n    retry_forever true\n  </buffer>\n</match>\n```\n\n----------------------------------------\n\nTITLE: Generating Time Series Data with Advanced Query Language in Axiom\nDESCRIPTION: This Kusto query summarizes the count of events from the 'sample-http-logs' dataset, grouping them by automatically binned time intervals. It's used to create a time series visualization in Axiom dashboards.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/time-series.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubernetes Resources for Fluent Bit Deployment\nDESCRIPTION: This YAML configuration sets up the necessary Kubernetes resources for deploying Fluent Bit. It includes a ServiceAccount, ClusterRole, ClusterRoleBinding, ConfigMap with Fluent Bit settings, and a DaemonSet definition. The configuration allows Fluent Bit to collect container logs and send them to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/kubernetes.mdx#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: fluent-bit\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: fluent-bit\nrules:\n  - apiGroups: [\"\"]\n    resources:\n      - pods\n      - nodes\n      - namespaces\n    verbs:\n      - get\n      - list\n      - watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: fluent-bit\nsubjects:\n  - kind: ServiceAccount\n    name: fluent-bit\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: fluent-bit\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: fluent-bit-config\n  namespace: kube-system\ndata:\n  fluent-bit.conf: |-\n    [SERVICE]\n        Flush         1\n        Log_Level     debug\n        Daemon        off\n        Parsers_File  parsers.conf\n        HTTP_Server   On\n        HTTP_Listen   0.0.0.0\n        HTTP_Port     2020\n\n    [INPUT]\n        Name              tail\n        Tag               kube.*\n        Path              /var/log/containers/*.log\n        Parser            docker\n        DB                /var/log/flb_kube.db\n        Mem_Buf_Limit     7MB\n        Skip_Long_Lines   On\n        Refresh_Interval  10\n\n    [FILTER]\n        Name                kubernetes\n        Match               kube.*\n        Kube_URL            https://kubernetes.default.svc:443\n        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token\n        Kube_Tag_Prefix     kube.var.log.containers.\n        Merge_Log           On\n        Merge_Log_Key       log_processed\n        K8S-Logging.Parser  On\n        K8S-Logging.Exclude Off\n\n    [OUTPUT]\n        Name            http\n        Match           *\n        Host            api.axiom.co\n        Port            443\n        URI             /v1/datasets/${AXIOM_DATASET_NAME}/ingest\n        Header          Authorization Bearer ${AXIOM_API_TOKEN}\n        Format          json\n        Json_date_key   time\n        Json_date_format iso8601\n        Retry_Limit     False\n        Compress        gzip\n        tls             On\n        tls.verify      Off\n\n  parsers.conf: |-\n    [PARSER]\n        Name        docker\n        Format      json\n        Time_Key    time\n        Time_Format %Y-%m-%dT%H:%M:%S.%L\n        Time_Keep   On\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluent-bit\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: fluent-bit\n  template:\n    metadata:\n      labels:\n        name: fluent-bit\n    spec:\n      serviceAccountName: fluent-bit\n      containers:\n        - name: fluent-bit\n          image: fluent/fluent-bit:1.9.9\n          env:\n            - name: AXIOM_DATASET_NAME\n              value: my-dataset\n            - name: AXIOM_API_TOKEN\n              value: xaat-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n          volumeMounts:\n            - name: config\n              mountPath: /fluent-bit/etc/fluent-bit.conf\n              subPath: fluent-bit.conf\n            - name: config\n              mountPath: /fluent-bit/etc/parsers.conf\n              subPath: parsers.conf\n            - name: varlog\n              mountPath: /var/log\n            - name: varlibdockercontainers\n              mountPath: /var/lib/docker/containers\n              readOnly: true\n      volumes:\n        - name: config\n          configMap:\n            name: fluent-bit-config\n        - name: varlog\n          hostPath:\n            path: /var/log\n        - name: varlibdockercontainers\n          hostPath:\n            path: /var/lib/docker/containers\n      terminationGracePeriodSeconds: 10\n```\n\n----------------------------------------\n\nTITLE: Environment Configuration for Axiom Logging\nDESCRIPTION: Environment variables configuration for Axiom logging integration\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-laravel.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nLOG_CHANNEL=axiom\nAXIOM_API_TOKEN=API_TOKEN\nAXIOM_DATASET=DATASET_NAME\nLOG_LEVEL=debug\nLOG_DEPRECATIONS_CHANNEL=null\n```\n\n----------------------------------------\n\nTITLE: Analyzing HTTP Request Durations with stdev in APL\nDESCRIPTION: This query calculates the standard deviation of request durations in milliseconds from a sample HTTP logs dataset. It demonstrates how to use stdev for log analysis to identify performance variations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdev.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize req_duration_std = stdev(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Calculating Error Rate with APL Query\nDESCRIPTION: APL query to track error rate per minute by extending the dataset with an error flag and calculating the average error rate using time bins.\nSOURCE: https://github.com/axiomhq/docs/blob/main/monitor-data/monitor-examples.mdx#2025-04-22_snippet_0\n\nLANGUAGE: apl\nCODE:\n```\n['sample_dataset']\n| extend is_error = case(['status.code'] == 'ERROR', 1, 0)\n| summarize avg(error) by bin(_time, 1m)\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL GROUP BY with APL Summarize\nDESCRIPTION: Shows how SQL's GROUP BY clause with aggregation functions translates to APL's summarize operator for data grouping and aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT method, COUNT(*) \nFROM sample_http_logs \nGROUP BY method\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by method\n```\n\n----------------------------------------\n\nTITLE: Calculating Request Duration Percentiles for Server Errors with percentiles_arrayif in APL\nDESCRIPTION: This query uses the percentiles_arrayif function to analyze request durations for server errors (status codes starting with 5) in the 'sample-http-logs' dataset. It computes the 50th, 90th, 95th, and 99th percentiles of the req_duration_ms field for these error responses.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-arrayif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentiles_arrayif(req_duration_ms, dynamic([50, 90, 95, 99]), status startswith '5') by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom client with options in Go\nDESCRIPTION: This snippet shows how to configure the underlying Axiom client using SetClientOptions. It sets up the client with a personal token for authentication.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/zap.mdx#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nimport (\n    \"github.com/axiomhq/axiom-go/axiom\"\n    adapter \"github.com/axiomhq/axiom-go/adapters/zap\"\n)\n\n// ...\n\ncore, err := adapter.New(\n    adapter.SetClientOptions(\n        axiom.SetPersonalTokenConfig(\"AXIOM_TOKEN\"),\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Identifying Longest OpenTelemetry Spans\nDESCRIPTION: Query to find the span with the longest duration for each service in OpenTelemetry traces.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-max.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize arg_max(duration, span_id, trace_id) by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Zap adapter with options in Go\nDESCRIPTION: This code demonstrates how to configure the Axiom Zap adapter using options passed to the New function. It sets the dataset name for the logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/zap.mdx#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\ncore, err := adapter.New(\n    adapter.SetDataset(\"DATASET_NAME\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Querying Basic Trace Metrics with Kusto\nDESCRIPTION: Query to calculate the number of requests and average response times for root spans. Includes count, average duration, and percentile calculations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/traces.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| where isnull(parent_span_id)\n| summarize count(),\n            avg(duration),\n            percentiles_array(duration, 95, 99, 99.9)\n  by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Converting SPL eval Command to APL extend\nDESCRIPTION: Comparison between Splunk SPL's eval command and the equivalent extend operation in APL. Both create a new field by multiplying an existing field by 1000.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nindex=myindex\n| eval newField = duration * 1000\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend newField = req_duration_ms * 1000\n```\n\n----------------------------------------\n\nTITLE: Importing OpenTelemetry Contrib for HTTP Instrumentation in Go\nDESCRIPTION: This code snippet shows how to import the OpenTelemetry contrib library for automatic instrumentation of the net/http package in a Go application.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_8\n\nLANGUAGE: go\nCODE:\n```\nimport \"go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp\"\n```\n\n----------------------------------------\n\nTITLE: Serilog Project Configuration in XML\nDESCRIPTION: Project file configuration for Serilog implementation including required package references and project settings.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_8\n\nLANGUAGE: xml\nCODE:\n```\n<Project Sdk=\"Microsoft.NET.Sdk\">\n  <PropertyGroup>\n    <OutputType>Exe</OutputType>\n    <TargetFramework>net8.0</TargetFramework>\n    <ImplicitUsings>enable</ImplicitUsings>\n    <Nullable>enable</Nullable>\n    <AssemblyName>SerilogApp</AssemblyName>\n    <RootNamespace>SerilogApp</RootNamespace>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <PackageReference Include=\"Microsoft.Extensions.Configuration\" Version=\"8.0.0\" />\n    <PackageReference Include=\"Serilog\" Version=\"3.1.1\" />\n    <PackageReference Include=\"Serilog.Formatting.Elasticsearch\" Version=\"10.0.0\" />\n    <PackageReference Include=\"Serilog.Sinks.Console\" Version=\"5.0.1\" />\n    <PackageReference Include=\"Serilog.Sinks.Http\" Version=\"9.0.0\" />\n  </ItemGroup>\n</Project>\n```\n\n----------------------------------------\n\nTITLE: APL join operator syntax\nDESCRIPTION: This snippet demonstrates the basic syntax of the join operator in Axiom Processing Language. It shows how to structure a join operation between two datasets with specified join kind and conditions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/join-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nLeftDataset\n| join kind=KindOfJoin RightDataset on Conditions\n```\n\n----------------------------------------\n\nTITLE: Basic AWS Lambda Function Handler in Python\nDESCRIPTION: Sample Lambda function that processes an event object and returns the value of 'key1'. Includes error handling and logging functionality.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-lambda-dot.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nprint('Loading function')\n\n\ndef lambda_handler(event, context):\n    #print(\"Received event: \" + json.dumps(event, indent=2))\n    print(\"value1 = \" + event['key1'])\n    print(\"value2 = \" + event['key2'])\n    print(\"value3 = \" + event['key3'])\n    return event['key1']  # Echo back the first key value\n    #raise Exception('Something went wrong')\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry SDK for Automatic Instrumentation in C#\nDESCRIPTION: Set up the OpenTelemetry SDK to configure automatic instrumentation in your application. This involves setting up a TracerProvider in your program.cs or startup configuration, which automatically captures telemetry data from supported libraries.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_7\n\nLANGUAGE: csharp\nCODE:\n```\nSdk.CreateTracerProviderBuilder()\n    .AddAspNetCoreInstrumentation()\n    .AddHttpClientInstrumentation()\n    .AddOtlpExporter(options =>\n    {\n        options.Endpoint = new Uri(\"https://api.axiom.co/v1/traces\");\n        // Replace API_TOKEN and DATASET_NAME with your actual API token and dataset name\n        options.Headers = $\"Authorization=Bearer API_TOKEN, X-Axiom-Dataset=DATASET_NAME\";\n    })\n    .Build();\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL Conditional Counting with APL Countif\nDESCRIPTION: This example compares how to count HTTP 500 errors in ANSI SQL using COUNT with CASE versus the equivalent APL query using countif.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/countif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(CASE WHEN status = '500' THEN 1 END) AS error_count\nFROM sample_http_logs\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize countif(status == '500')\n```\n\n----------------------------------------\n\nTITLE: Logging Examples in Next.js with Axiom\nDESCRIPTION: Demonstrates various logging levels and methods using next-axiom in a Next.js application.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nlog.debug(\"Login attempt\", { user: \"j_doe\", status: \"success\" }); // Results in {\"message\": \"Login attempt\", \"fields\": {\"user\": \"j_doe\", \"status\": \"success\"}}\nlog.info(\"Payment completed\", { userID: \"123\", amount: \"25USD\" });\nlog.warn(\"API rate limit exceeded\", {\n  endpoint: \"/users/1\",\n  rateLimitRemaining: 0,\n});\nlog.error(\"System Error\", { code: \"500\", message: \"Internal server error\" });\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Traces Analysis with sumif in APL\nDESCRIPTION: This example shows how to use sumif to sum span durations for a specific service in OpenTelemetry traces dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sumif.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize total_duration = sumif(duration, ['service.name'] == 'frontend')\n```\n\n----------------------------------------\n\nTITLE: Configuring Logrus Adapter with Dataset\nDESCRIPTION: Example of configuring the Logrus adapter with a specific dataset name using the New function and options.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/logrus.mdx#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nhook, err := adapter.New(\n    adapter.SetDataset(\"DATASET_NAME\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Basic Fluent Bit Configuration for Axiom\nDESCRIPTION: Basic configuration for Fluent Bit to send CPU metrics to Axiom. Includes service settings, input configuration for CPU metrics, and output configuration for HTTP transmission to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluent-bit.mdx#2025-04-22_snippet_0\n\nLANGUAGE: ini\nCODE:\n```\n[SERVICE]\n    Flush     5\n    Daemon    off\n    Log_Level debug\n\n[INPUT]\n    Name cpu\n    Tag  cpu\n\n[OUTPUT]\n    Name            http\n    Match           *\n    Host            api.axiom.co\n    Port            443\n    URI             /v1/datasets/DATASET_NAME/ingest\n    # Authorization Bearer should be an API token\n    Header Authorization Bearer API_TOKEN\n    compress gzip\n    format json\n    json_date_key _time\n    json_date_format iso8601\n    tls On\n```\n\n----------------------------------------\n\nTITLE: Complete Axiom Client Usage Example\nDESCRIPTION: Full example demonstrating how to create a client, ingest events, and query data using the Axiom Go SDK.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/go.mdx#2025-04-22_snippet_3\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/axiomhq/axiom-go/axiom\"\n    \"github.com/axiomhq/axiom-go/axiom/ingest\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    client, err := axiom.NewClient()\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    if _, err = client.IngestEvents(ctx, \"my-dataset\", []axiom.Event{\n        {ingest.TimestampField: time.Now(), \"foo\": \"bar\"},\n        {ingest.TimestampField: time.Now(), \"bar\": \"foo\"},\n    }); err != nil {\n        log.Fatal(err)\n    }\n\n    res, err := client.Query(ctx, \"['my-dataset'] | where foo == 'bar' | limit 100\")\n    if err != nil {\n        log.Fatal(err)\n    } else if res.Status.RowsMatched == 0 {\n        log.Fatal(\"No matches found\")\n    }\n\n    rows := res.Tables[0].Rows()\n    if err := rows.Range(ctx, func(_ context.Context, row query.Row) error {\n        _, err := fmt.Println(row)\n        return err\n    }); err != nil {\n        log.Fatal(err)\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Package Configuration for Node.js OpenTelemetry Project\nDESCRIPTION: Package.json configuration file that specifies project dependencies including OpenTelemetry packages, Express.js, and development tools for TypeScript.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"typescript-traces\",\n    \"version\": \"1.0.0\",\n    \"description\": \"\",\n    \"main\": \"app.js\",\n    \"scripts\": {\n        \"build\": \"tsc\",\n        \"start\": \"ts-node app.ts\",\n        \"dev\": \"ts-node-dev --respawn app.ts\"\n    },\n    \"keywords\": [],\n    \"author\": \"\",\n    \"license\": \"ISC\",\n    \"dependencies\": {\n        \"@opentelemetry/api\": \"^1.6.0\",\n        \"@opentelemetry/api-logs\": \"^0.46.0\",\n        \"@opentelemetry/auto-instrumentations-node\": \"^0.39.4\",\n        \"@opentelemetry/exporter-metrics-otlp-http\": \"^0.45.0\",\n        \"@opentelemetry/exporter-metrics-otlp-proto\": \"^0.45.1\",\n        \"@opentelemetry/exporter-trace-otlp-http\": \"^0.45.0\",\n        \"@opentelemetry/sdk-logs\": \"^0.46.0\",\n        \"@opentelemetry/sdk-metrics\": \"^1.20.0\",\n        \"@opentelemetry/sdk-node\": \"^0.45.1\",\n        \"express\": \"^4.18.2\"\n    },\n    \"devDependencies\": {\n        \"@types/express\": \"^4.17.21\",\n        \"@types/node\": \"^16.18.71\",\n        \"ts-node\": \"^10.9.2\",\n        \"ts-node-dev\": \"^2.0.0\",\n        \"tsc-watch\": \"^4.6.2\",\n        \"typescript\": \"^4.9.5\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing JSON Strings in APL\nDESCRIPTION: The parse_json function interprets a string as a JSON value and returns it as a dynamic object. It handles both valid JSON strings and non-JSON strings, returning appropriate results.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_12\n\nLANGUAGE: kusto\nCODE:\n```\nparse_json(json)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['vercel']\n| extend parsed = parse_json('{\"name\":\"vercel\", \"statuscode\":200, \"region\": { \"route\": \"usage streams\", \"number\": 9 }}')\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend parsed = parse_json(creator)\n| where isnotnull( parsed)\n```\n\n----------------------------------------\n\nTITLE: Sending NGINX Metrics to Axiom with Vector\nDESCRIPTION: A Vector configuration for scraping NGINX metrics from a metrics endpoint and forwarding them to Axiom. Requires the nginx_metrics source type configured to point to the NGINX metrics endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_9\n\nLANGUAGE: toml\nCODE:\n```\n[sources.nginx_metrics]\ntype = \"nginx_metrics\" # must be: nginx_metrics\nendpoints = [\"http://localhost/metrics\"] # the endpoint where NGINX metrics are exposed\n\n[sinks.axiom]\ntype = \"axiom\" # must be: axiom\ninputs = [\"nginx_metrics\"] # use the metrics from the NGINX source\ndataset = \"DATASET_NAME\"  # replace with the name of your Axiom dataset\ntoken = \"API_TOKEN\"  # replace with your Axiom API token\n```\n\n----------------------------------------\n\nTITLE: Ingesting Data to Axiom Dataset using cURL\nDESCRIPTION: This curl command demonstrates how to ingest data into an Axiom dataset using the API. It sends a POST request to the ingest endpoint with JSON payload and includes the necessary headers for authentication and content type.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/introduction.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/{dataset_name}/ingest' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -H 'Content-Type: application/json' \\\n  -d '[\n    {\n      \"axiom\": \"logs\"\n    }\n  ]'\n```\n\n----------------------------------------\n\nTITLE: Creating CloudWatch Subscriber Module with Terraform\nDESCRIPTION: Terraform configuration to create a Subscriber module that sets up subscription filters for CloudWatch log groups. References the Forwarder Lambda ARN.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/cloudwatch.mdx#2025-04-22_snippet_1\n\nLANGUAGE: hcl\nCODE:\n```\nmodule \"subscriber\" {\n  source               = \"axiomhq/axiom-cloudwatch-forwarder/aws//modules/subscriber\"\n  prefix               = \"axiom-cloudwatch-forwarder\"\n  forwarder_lambda_arn = module.forwarder.lambda_arn\n  log_groups_prefix    = \"/aws/lambda/\"\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Request Duration Variance in Log Analysis\nDESCRIPTION: An example of using the variance function to measure variability in HTTP request durations, helping identify performance bottlenecks or anomalies.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/variance.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize variance(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Gems for Ruby\nDESCRIPTION: This code snippet lists the essential Ruby gems required for implementing OpenTelemetry in a Ruby application. It includes gems for the core API, SDK, exporters, and various instrumentations for Rails, HTTP, and ActiveRecord.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-ruby.mdx#2025-04-22_snippet_7\n\nLANGUAGE: ruby\nCODE:\n```\ngem 'opentelemetry-api'\ngem 'opentelemetry-sdk'\ngem 'opentelemetry-exporter-otlp'\ngem 'opentelemetry-instrumentation-rails'\ngem 'opentelemetry-instrumentation-http'\ngem 'opentelemetry-instrumentation-active_record', require: false\ngem 'opentelemetry-instrumentation-all'\n```\n\n----------------------------------------\n\nTITLE: Calculating Total Span Duration in OpenTelemetry Traces with APL\nDESCRIPTION: Example of applying sum aggregation to OpenTelemetry trace data to calculate the total span duration. This query sums all duration values in the otel-demo-traces dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sum.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize total_duration = sum(duration)\n```\n\n----------------------------------------\n\nTITLE: Advanced Error Status Code Detection for Next.js with Axiom Logging\nDESCRIPTION: This snippet implements a custom getNextErrorStatusCode function to detect specific Next.js error types like redirect errors and HTTP access fallbacks. It extracts the status code from the error digest and uses it to determine the appropriate log level.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_20\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger, AxiomJSTransport, LogLevel } from '@axiomhq/logging';\nimport {\n  createAxiomRouteHandler,\n  nextJsFormatters,\n  transformRouteHandlerErrorResult,\n} from '@axiomhq/nextjs';\nimport { isRedirectError } from 'next/dist/client/components/redirect-error';\nimport { isHTTPAccessFallbackError } from 'next/dist/client/components/http-access-fallback/http-access-fallback';\n\nimport axiomClient from '@/lib/axiom/axiom';\n\nexport const logger = new Logger({\n  transports: [\n    new AxiomJSTransport({ axiom: axiomClient, dataset: process.env.NEXT_PUBLIC_AXIOM_DATASET! }),\n  ],\n  formatters: nextJsFormatters,\n});\n\nexport const getNextErrorStatusCode = (error: Error & { digest?: string }) => {\n  if (!error.digest) {\n    return 500;\n  }\n\n  if (isRedirectError(error)) {\n    return parseInt(error.digest.split(';')[3]);\n  } else if (isHTTPAccessFallbackError(error)) {\n    return parseInt(error.digest.split(';')[1]);\n  }\n};\n\nconst getLogLevelFromStatusCode = (statusCode: number) => {\n  if (statusCode >= 300 && statusCode < 400) {\n    return LogLevel.info;\n  } else if (statusCode >= 400 && statusCode < 500) {\n    return LogLevel.warn;\n  }\n  return LogLevel.error;\n};\n\nexport const withAxiom = createAxiomRouteHandler(logger, {\n  onError: (error) => {\n    if (error.error instanceof Error) {\n      logger.error(error.error.message, error.error);\n    }\n    const [message, report] = transformRouteHandlerErrorResult(error);\n\n    const statusCode = error.error instanceof Error ? getNextErrorStatusCode(error.error) : 500;\n    report.request.statusCode = statusCode;\n\n    report.customField = 'customValue';\n    report.request.searchParams = error.req.nextUrl.searchParams;\n\n    logger.log(getLogLevelFromStatusCode(report.statusCode), message, report);\n    logger.flush();\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Filtering GitHub Issues by Label Identifier in Kusto\nDESCRIPTION: This query filters GitHub issues by a specific label identifier in the 'github-issues-event' dataset. It extends the result with the labels as a string and filters for labels containing the identifier 'd73a4a'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_29\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend data = tostring(labels)\n| where labels contains \"d73a4a\"\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis with Project in APL\nDESCRIPTION: Shows how to use the project operator to focus on security-relevant fields like timestamp, user ID, and HTTP status from sample logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-operator.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project _time, id, status\n```\n\n----------------------------------------\n\nTITLE: Filtering HTTP Requests by Country in Axiom Dashboard Chart\nDESCRIPTION: This APL query defines a statistic chart that filters HTTP requests based on the selected country. It uses query parameters to reference the country filter and displays the count of requests over time.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/filters.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ndeclare query_parameters (country_filter:string = \"\");\n['sample-http-logs']\n| where isempty(country_filter) or ['geo.country'] == country_filter\n| summarize count() by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Configuring Fluentd for AWS FireLens and Axiom\nDESCRIPTION: This bash snippet contains the Fluentd configuration for forwarding logs to Axiom using AWS FireLens. It defines the input source and output match, including the necessary headers and endpoint for Axiom ingestion.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-firelens.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n<source>\n  @type forward\n  port 24224\n  bind 0.0.0.0\n</source>\n\n<match *>\n  @type http\n  headers {\"Authorization\": \"Bearer API_TOKEN\"}\n  data_type json\n  endpoint https://api.axiom.co/v1/datasets/DATASET_NAME/ingest\n  sourcetype ecs\n</match>\n```\n\n----------------------------------------\n\nTITLE: Filtering in Splunk SPL and APL\nDESCRIPTION: Shows how filtering is performed in Splunk SPL using the 'search' command and in APL using the 'where' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSearch index=\"myIndex\" error \n| stats count\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['myDataset']\n| where fieldName contains \"error\"\n| count \n```\n\n----------------------------------------\n\nTITLE: Querying Axiom Dataset API with cURL\nDESCRIPTION: This cURL command demonstrates how to query a specific dataset in the Axiom API. It includes various query parameters and a complex JSON body for filtering, aggregating, and formatting the data request.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/query.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' \\\n  'https://api.axiom.co/v1/datasets/<dataset_id>/query?saveAsKind=<save_as_kind_query>&streaming-duration=<streaming_duration>&nocache=true' \\\n  -H 'Content-Type: application/json' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -d '{\n  \"aggregations\": [\n    {\n      \"alias\": \"string\",\n      \"argument\": {},\n      \"field\": \"string\",\n      \"op\": \"count\"\n    }\n  ],\n  \"continuationToken\": \"string\",\n  \"cursor\": \"string\",\n  \"endTime\": \"string\",\n  \"filter\": {\n    \"caseSensitive\": true,\n    \"children\": [\n      \"string\"\n    ],\n    \"field\": \"string\",\n    \"op\": \"and\",\n    \"value\": {}\n  },\n  \"groupBy\": [\n    \"string\"\n  ],\n  \"includeCursor\": true,\n  \"limit\": 0,\n  \"order\": [\n    {\n      \"desc\": true,\n      \"field\": \"string\"\n    }\n  ],\n  \"project\": [\n    {\n      \"alias\": \"string\",\n      \"field\": \"string\"\n    }\n  ],\n  \"queryOptions\": {\n    \"against\": \"string\",\n    \"againstStart\": \"string\",\n    \"againstTimestamp\": \"string\",\n    \"caseSensitive\": \"string\",\n    \"containsTimeFilter\": \"string\",\n    \"datasets\": \"string\",\n    \"displayNull\": \"string\",\n    \"editorContent\": \"string\",\n    \"endColumn\": \"string\",\n    \"endLineNumber\": \"string\",\n    \"endTime\": \"string\",\n    \"integrationsFilter\": \"string\",\n    \"openIntervals\": \"string\",\n    \"quickRange\": \"string\",\n    \"resolution\": \"string\",\n    \"startColumn\": \"string\",\n    \"startLineNumber\": \"string\",\n    \"startTime\": \"string\",\n    \"timeSeriesView\": \"string\"\n  },\n  \"resolution\": \"string\",\n  \"startTime\": \"string\",\n  \"virtualFields\": [\n    {\n      \"alias\": \"string\",\n      \"expr\": \"string\"\n    }\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Advanced Summarize with Multiple Aggregations and Filtering\nDESCRIPTION: Demonstrates a complex query that filters GitHub push events, uses summarize with multiple aggregations, time binning, and limits results.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\n['github-push-event']\n| where _time > ago(7d)\n| where repo contains \"axiom\"\n| summarize count(), numCommits=sum(size) by _time=bin(_time, 3h), repo\n| take 100\n```\n\n----------------------------------------\n\nTITLE: Configuring Cloudflare Workers Script with OpenTelemetry\nDESCRIPTION: Example of a Cloudflare Workers script (index.ts) configured to use OpenTelemetry for sending telemetry data to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n// index.ts\nimport { trace } from '@opentelemetry/api';\nimport { instrument, ResolveConfigFn } from '@microlabs/otel-cf-workers';\n\nexport interface Env {\n  AXIOM_API_TOKEN: string,\n  AXIOM_DATASET: string\n}\n\nconst handler = {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n    await fetch('https://cloudflare.com');\n    const greeting = \"Welcome to Axiom Cloudflare instrumentation\";\n    trace.getActiveSpan()?.setAttribute('greeting', greeting);\n    ctx.waitUntil(fetch('https://workers.dev'));\n    return new Response(`${greeting}!`);\n  },\n};\n\nconst config: ResolveConfigFn = (env: Env, _trigger) => {\n  return {\n    exporter: {\n      url: 'https://api.axiom.co/v1/traces',\n      headers: {\n        'Authorization': `Bearer ${env.AXIOM_API_TOKEN}`,\n        'X-Axiom-Dataset': `${env.AXIOM_DATASET}`\n      },\n    },\n    service: { name: 'axiom-cloudflare-workers' },\n  };\n};\n\nexport default instrument(handler, config);\n```\n\n----------------------------------------\n\nTITLE: Using maxif for OpenTelemetry Traces in APL\nDESCRIPTION: This snippet shows how to use the maxif function in APL for analyzing OpenTelemetry traces. It finds the longest span duration for a specific service type.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/maxif.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize maxif(duration, ['service.name'] == \"checkoutservice\" and kind == \"server\")\n```\n\n----------------------------------------\n\nTITLE: Aggregation with GROUP BY and ORDER BY in SQL and APL\nDESCRIPTION: Shows how to group data by a specific field, perform aggregations on groups, and order the results. The example groups HTTP logs by status code, counts occurrences, and sums response header sizes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT status, COUNT(*) AS TotalStatus, SUM(resp_header_size_bytes) AS TotalRequest\nFROM [Sample-http-logs];\nGROUP BY status\nORDER BY TotalSpent DESC;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize TotalStatus = count(), TotalRequest = sum(resp_header_size_bytes) by status\n| order by TotalRequest desc\n```\n\n----------------------------------------\n\nTITLE: Security Log Method Parsing\nDESCRIPTION: Shows how to extract HTTP method and status from security logs using parse operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| parse method with * '/' status\n| project _time, method, status\n```\n\n----------------------------------------\n\nTITLE: Basic Parse Operator Syntax in APL\nDESCRIPTION: Defines the fundamental syntax and parameters for using the parse operator in APL queries. Shows the structure for extracting fields from text data with type specifications.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| parse [kind=simple|regex|relaxed] Expression with [*] StringConstant FieldName [: FieldType] [*] ...\n```\n\n----------------------------------------\n\nTITLE: Sending Virtual Machine Logs to Axiom with Apache Source Type\nDESCRIPTION: This configuration collects Apache-style logs from a virtual machine and sends them to Axiom using the HTTP output plugin. It includes a record transformer to add hostname and service information.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluentd.mdx#2025-04-22_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<source>\n  @type tail\n  @id input_tail\n  <parse>\n    @type apache2\n  </parse>\n  path /var/log/**/*.log\n  pos_file /var/log/fluentd/fluentd.log.pos\n  tag vm.logs\n  read_from_head true\n</source>\n\n<filter vm.logs>\n  @type record_transformer\n  <record>\n    hostname \"#{Socket.gethostname}\"\n    service \"vm_service\"\n  </record>\n</filter>\n\n<match vm.logs>\n  @type http\n  @id out_http_axiom\n  @log_level info\n  endpoint \"#{ENV['AXIOM_URL'] || 'https://api.axiom.co'}\"\n  path \"/v1/datasets/DATASET_NAME/ingest\"\n  ssl_verify \"#{ENV['AXIOM_SSL_VERIFY'] || 'true'}\"\n  <headers>\n    Authorization \"Bearer API_TOKEN\"\n    Content-Type \"application/json\"\n  </headers>\n  <format>\n    @type json\n  </format>\n  <buffer>\n    @type memory\n    flush_mode interval\n    flush_interval 5s\n    chunk_limit_size 5MB\n    retry_forever true\n  </buffer>\n</match>\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Dependencies with Vercel\nDESCRIPTION: Command to install required OpenTelemetry packages including Vercel's OTel integration\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nextjs.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @vercel/otel @opentelemetry/exporter-trace-otlp-http @opentelemetry/sdk-trace-node\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration with Data Transformation\nDESCRIPTION: A Vector configuration that removes a specified field from the data before sending it to Axiom. Uses the remap transform to modify the data stream between the source and sink.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.VECTOR_SOURCE_ID]\ntype = \"file\"\ninclude = [\"PATH_TO_LOGS\"]\n\n[transforms.filter_json_fields]\ntype = \"remap\"\ninputs = [\"VECTOR_SOURCE_ID\"]\nsource = '''\n  . = del(.FIELD_TO_REMOVE)\n'''\n\n[sinks.SINK_ID]\ntype = \"axiom\"\ninputs = [\"filter_json_fields\"]\ntoken = \"API_TOKEN\"\ndataset = \"DATASET_NAME\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Tremor Syslog Client for Axiom Ingestion\nDESCRIPTION: Configuration for sending logs to Axiom's Syslog endpoint using Tremor. Sets up a file connector as data source and a TCP client connector with Syslog codec. Includes TLS configuration and reconnection handling.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/tremor.mdx#2025-04-22_snippet_1\n\nLANGUAGE: troy\nCODE:\n```\ndefine flow client_sink_only\nflow\n  use std::time::nanos;\n  use tremor::pipelines;\n\n  define connector input from file\n  args\n    file = \"in.json\"  # Default input file is 'in.json' in current working directory\n  with\n    codec = \"json\",    # Data is JSON encoded\n    preprocessors = [\"separate\"],    # Data is newline separated\n    config = {\n        \"path\": args.file,\n        \"mode\": \"read\"\n    },\n  end;\n  create connector input;\n\ndefine connector syslog_forwarder from tcp_client\nargs\n  endpoint_hostport,\nwith\n    tls = true,\n    codec = \"syslog\",\n    config = {\n      \"url\": \"#{args.endpoint_hostport}\",\n      \"no_delay\": false,\n      \"buf_size\": 1024,\n    },\n    reconnect = {\n      \"retry\": {\n        \"interval_ms\": 100,\n        \"growth_rate\": 2,\n        \"max_retries\": 3,\n      }\n    }\n end;\n  create connector syslog_forwarder\n  with\n    endpoint_hostport = \"tcp+tls://testsyslog.syslog.axiom.co:6514\"\n  end;\n\n  create pipeline passthrough from pipelines::passthrough;\n\n  connect /connector/input to /pipeline/passthrough;\n  connect /pipeline/passthrough to /connector/syslog_forwarder;\n\nend;\n\ndeploy flow client_sink_only;\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Traces Analysis with minif in APL\nDESCRIPTION: Example demonstrating how to use minif to find the minimum span duration for a specific service in distributed tracing data, grouped by trace_id.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/minif.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize minif(duration, ['service.name'] == 'frontend') by trace_id\n```\n\n----------------------------------------\n\nTITLE: Sending Logs from Loki to Axiom using JavaScript\nDESCRIPTION: This snippet demonstrates how to configure and use Winston with a Loki transport to send logs to Axiom. It initializes a logger with a Loki transport, specifying the Axiom endpoint URL and custom labels.\nSOURCE: https://github.com/axiomhq/docs/blob/main/endpoints/loki.mdx#2025-04-22_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nconst { createLogger, transports, format, } = require(\"winston\");\nconst LokiTransport = require(\"winston-loki\");\n\nlet logger;\n\nconst initializeLogger = () => {\n  if (logger) {\n    return;\n  }\n\n  logger = createLogger({\n    transports: [\n      new LokiTransport({\n        host: \"$LOKI_ENDPOINT_URL\",\n        labels: { app: \"axiom-loki-endpoint\" },\n        json: true,\n        format: format.json(),\n        replaceTimestamp: true,\n        onConnectionError: (err) => console.error(err),\n      }),\n      new transports.Console({\n        format: format.combine(format.simple(), format.colorize()),\n      }),\n    ],\n  });\n};\n\ninitializeLogger()\nlogger.info(\"Starting app...\");\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL join with APL equivalent\nDESCRIPTION: This snippet shows how to translate a standard SQL JOIN query to Axiom Processing Language. It highlights the syntactical differences between SQL's FROM/JOIN/ON structure and APL's pipe-based join operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/join-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM logs\nJOIN traces\nON logs.id = traces.trace_id\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| join kind=inner ['otel-demo-traces'] on id == trace_id\n```\n\n----------------------------------------\n\nTITLE: Generating Heatmap Using Advanced Query Language in Axiom\nDESCRIPTION: This query creates a heatmap visualization from 'http-logs' data. It summarizes the request duration into 15 buckets and bins the time automatically. This is useful for visualizing the distribution of request durations over time.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/heatmap.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['http-logs']\n| summarize histogram(req_duration_ms, 15) by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Axiom CLI Main Usage and Commands\nDESCRIPTION: Complete overview of Axiom CLI commands, usage patterns, and available options.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/cli.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n➜ ~ axiom\nThe power of Axiom on the command-line.\n\nUSAGE\n  axiom <command> <subcommand> [flags]\n\nCORE COMMANDS\n  ingest:      Ingest structured data\n  query:       Query data using APL\n  stream:      Livestream data\n\nMANAGEMENT COMMANDS\n  auth:        Manage authentication state\n  config:      Manage configuration\n  dataset:     Manage datasets\n\nADDITIONAL COMMANDS\n  completion:  Generate shell completion scripts\n  help:        Help about any command\n  version:     Print version\n  web:         Open Axiom in the browser\n\nFLAGS\n  -O, --auth-org-id string   Organization ID to use\n  -T, --auth-token string    Token to use\n  -C, --config string        Path to configuration file to use\n  -D, --deployment string    Deployment to use\n  -h, --help                 Show help for command\n      --no-spinner           Disable the activity indicator\n  -v, --version              Show axiom version\n\nEXAMPLES\n  $ axiom auth login\n  $ axiom version\n  $ cat http-logs.json | axiom ingest http-logs\n\nAUTHENTICATION\n  See 'axiom help credentials' for help and guidance on authentication.\n\nENVIRONMENT VARIABLES\n  See 'axiom help environment' for the list of supported environment variables.\n\nLEARN MORE\n  Use 'axiom <command> <subcommand> --help' for more information about a command.\n  Read the manual at https://axiom.co/reference/cli\n```\n\n----------------------------------------\n\nTITLE: Installing HTTP Client OpenTelemetry Instrumentation Package\nDESCRIPTION: NuGet package reference for adding OpenTelemetry instrumentation to HTTP clients in .NET applications. This package captures telemetry data about outbound HTTP requests including headers, duration, and status.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_9\n\nLANGUAGE: xml\nCODE:\n```\n<PackageReference Include=\"OpenTelemetry.Instrumentation.Http\" Version=\"1.6.0-rc.1\" />\n```\n\n----------------------------------------\n\nTITLE: Sampling HTTP Logs for Quick Analysis in APL\nDESCRIPTION: Example of using the sample operator to analyze 5% of HTTP logs, useful for quickly identifying patterns without processing the entire dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sample-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| sample 0.05\n```\n\n----------------------------------------\n\nTITLE: Querying data from Axiom using @axiomhq/js\nDESCRIPTION: Example of querying data from Axiom using the @axiomhq/js library.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst res = await axiom.query(`['DATASET_NAME'] | where foo == 'bar' | limit 100`);\nconsole.log(res);\n```\n\n----------------------------------------\n\nTITLE: Selecting Distinct Values in SQL\nDESCRIPTION: This snippet demonstrates how to use SELECT DISTINCT in SQL to retrieve unique user IDs from web logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/distinct-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DISTINCT user_id FROM web_logs;\n```\n\n----------------------------------------\n\nTITLE: Conditional Average in Splunk vs APL\nDESCRIPTION: Comparison between Splunk SPL and APL syntax for calculating conditional averages of request duration filtered by status code.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avgif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats avg(req_duration_ms) by id where status = \"200\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize avgif(req_duration_ms, status == \"200\") by id\n```\n\n----------------------------------------\n\nTITLE: Using make_set for Security Log Analysis in APL\nDESCRIPTION: Example query using make_set to collect unique HTTP status codes for each country of origin in security logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize make_set(status) by ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Configuring Journalbeat for Systemd Journal Collection\nDESCRIPTION: This configuration sets up Journalbeat to collect logs from systemd journals. It specifies the journal file paths to monitor and includes filtering options to match specific containers or processes. The collected journal entries are then sent to Axiom for centralized log management.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n# Disable index lifecycle management (ILM)\nsetup.ilm.enabled: false\njournalbeat.inputs:\n- paths:\n  - \"/dev/log\"\n  - \"/var/log/messages/my-journal-file.journal\"\n  seek: head\njournalbeat.inputs:\n- paths: []\n  include_matches:\n    - \"CONTAINER_TAG=redis\"\n    - \"_COMM=redis\"\n    - \"container.image.tag=redis\"\n    - \"process.name=redis\"\noutput.elasticsearch:\n  hosts: ['https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic']\n  # token should be an API token\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n```\n\n----------------------------------------\n\nTITLE: Security Logs Analysis using make_list_if in APL\nDESCRIPTION: This example demonstrates how to use make_list_if for analyzing security logs in APL. It gathers a list of URIs that resulted in a 403 error, grouped by the country of origin.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list-if.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize make_list_if(uri, status == '403') by ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Configuring Fluent Bit for AWS FireLens and Axiom\nDESCRIPTION: This snippet shows the Fluent Bit configuration for forwarding logs to Axiom using AWS FireLens. It defines the input, output, and necessary headers for authentication and data formatting.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-firelens.mdx#2025-04-22_snippet_0\n\nLANGUAGE: ini\nCODE:\n```\n[SERVICE]\n    Log_Level info\n\n[INPUT]\n    Name forward\n    Listen 0.0.0.0\n    Port 24224\n\n[OUTPUT]\n    Name http\n    Match *\n    Host api.axiom.co\n    Port 443\n    URI /v1/datasets/DATASET_NAME/ingest\n    Format json_lines\n    tls On\n    format json\n    json_date_key _time\n    json_date_format iso8601\n    Header Authorization Bearer API_TOKEN\n```\n\n----------------------------------------\n\nTITLE: Collecting and Sending PHP Logs to Axiom with Fluentd\nDESCRIPTION: This configuration sets up Fluentd to collect PHP logs using a multiline parser and send them to Axiom using the OpenSearch output plugin. It includes buffer settings for efficient log transmission.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluentd.mdx#2025-04-22_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<source>\n  @type tail\n  @id php_logs\n  <parse>\n    @type multiline\n    format_firstline /^\\[\\d+-\\w+-\\d+ \\d+:\\d+:\\d+\\]/\n    format1 /^\\[(?<time>\\d+-\\w+-\\d+ \\d+:\\d+:\\d+)\\] (?<message>.*)/\n  </parse>\n  path /var/log/php*.log\n  pos_file /var/log/fluentd/php.log.pos\n  read_from_head true\n  tag php.logs\n</source>\n\n<match php.logs>\n  @type opensearch\n  @id out_os\n  @log_level info\n  include_tag_key true\n  include_timestamp true\n  host \"#{ENV['FLUENT_OPENSEARCH_HOST']  || 'api.axiom.co'}\"\n  port \"#{ENV['FLUENT_OPENSEARCH_PORT'] || '443'}\"\n  path \"#{ENV['FLUENT_OPENSEARCH_PATH']|| '/v1/datasets/DATASET_NAME/elastic'}\"\n  scheme \"#{ENV['FLUENT_OPENSEARCH_SCHEME'] || 'https'}\"\n  ssl_verify \"#{ENV['FLUENT_OPENSEARCH_SSL_VERIFY'] || 'true'}\"\n  ssl_version \"#{ENV['FLUENT_OPENSEARCH_SSL_VERSION'] || 'TLSv1_2'}\"\n  user \"#{ENV['FLUENT_OPENSEARCH_USER'] || 'axiom'}\"\n  password \"#{ENV['FLUENT_OPENSEARCH_PASSWORD'] || 'xaat-xxxxxxxxxx-xxxxxxxxx-xxxxxxx'}\"\n  index_name \"#{ENV['FLUENT_OPENSEARCH_INDEX_NAME'] || 'php-logs'}\"\n\n  <buffer>\n    @type memory\n    flush_mode interval\n    flush_interval 10s\n    chunk_limit_size 5M\n    retry_max_interval 30\n    retry_forever true\n  </buffer>\n</match>\n```\n\n----------------------------------------\n\nTITLE: Creating Spans in Java with OpenTelemetry\nDESCRIPTION: This snippet demonstrates how to create spans in a Java application using OpenTelemetry. It includes initialization of the tracer and creation of spans for different operations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\n// DiceRollerApp.java\npackage com.example;\n\nimport io.opentelemetry.api.OpenTelemetry;\nimport io.opentelemetry.api.trace.Span;\nimport io.opentelemetry.api.trace.Tracer;\nimport io.opentelemetry.context.Scope;\n\npublic class DiceRollerApp {\n    private static final Tracer tracer;\n\n    static {\n        OpenTelemetry openTelemetry = OtelConfiguration.initializeOpenTelemetry();\n        tracer = openTelemetry.getTracer(\"com.example.DiceRollerApp\");\n    }\n\n    public static void main(String[] args) {\n        try (Scope scope = tracer.spanBuilder(\"Main\").startScopedSpan()) {\n            rollDice();\n        }\n    }\n\n    private static void rollDice() {\n        Span span = tracer.spanBuilder(\"rollDice\").startSpan();\n        try (Scope scope = span.makeCurrent()) {\n            // Simulate dice roll\n            int result = new Random().nextInt(6) + 1;\n            System.out.println(\"Rolled a dice: \" + result);\n        } finally {\n            span.end();\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: NLog Configuration in XML\nDESCRIPTION: XML configuration for NLog including HTTP target setup for Axiom integration with buffering and JSON formatting.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_11\n\nLANGUAGE: xml\nCODE:\n```\n<nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n    <extensions>\n        <add assembly=\"NLog.Targets.Http\" />\n    </extensions>\n    <targets>\n        <target xsi:type=\"BufferingWrapper\"\n                name=\"allLogs\"\n                flushTimeout=\"5000\">\n            <target xsi:type=\"HTTP\" \n                    name=\"axiom\"\n                    url=\"https://api.axiom.co/v1/datasets/DATASET_NAME/ingest\"\n                    HttpHeaders=\"Authorization: Bearer API_TOKEN\"\n                    contentType=\"application/json\">\n                <layout xsi:type=\"JsonLayout\" includeAllProperties=\"true\">\n                    <attribute name=\"timestamp\" layout=\"${date:universalTime=true:format=o}\" />\n                    <attribute name=\"level\" layout=\"${level:lowercase=true}\" />\n                    <attribute name=\"message\" layout=\"${message}\" />\n                    <attribute name=\"exception\" layout=\"${exception:format=toString}\" \n                               encode=\"false\" />\n                </layout>\n            </target>\n        </target>\n    </targets>\n    <rules>\n        <logger name=\"*\" minlevel=\"Trace\" writeTo=\"allLogs\" />\n    </rules>\n</nlog>\n```\n\n----------------------------------------\n\nTITLE: Querying HTTP Logs for Scatter Plot Data using Axiom's Advanced Query Language\nDESCRIPTION: This query summarizes HTTP log data to calculate average request duration and response header size for each unique response body size. It's used to generate data for a scatter plot visualization in Axiom dashboards.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/scatter-plot.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize avg(req_duration_ms), avg(resp_header_size_bytes) by resp_body_size_bytes\n```\n\n----------------------------------------\n\nTITLE: Practical iff() Example with Request Duration\nDESCRIPTION: Demonstrates using iff() to categorize request durations into 'numeric' or 'Inactive' based on a condition.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conditional-function.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project Status = iff(req_duration_ms == 1, \"numeric\", \"Inactive\")\n```\n\n----------------------------------------\n\nTITLE: Categorizing Services in OpenTelemetry Traces with extend\nDESCRIPTION: Example query that uses extend with the iff function to categorize services as 'Web' or 'Backend' based on service name in telemetry data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces'] \n| extend service_type = iff(['service.name'] in ('frontend', 'frontendproxy'), 'Web', 'Backend')\n```\n\n----------------------------------------\n\nTITLE: Using maxif for Log Analysis in APL\nDESCRIPTION: This snippet demonstrates how to use the maxif function in APL for log analysis. It finds the maximum request duration for successful HTTP requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/maxif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize maxif(req_duration_ms, status == \"200\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Environment Variables for Fluent Bit\nDESCRIPTION: This YAML snippet shows how to configure the environment variables for Axiom integration in the Fluent Bit DaemonSet. It sets the AXIOM_DATASET_NAME and AXIOM_API_TOKEN variables, which are required for sending logs to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/kubernetes.mdx#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nenv:\n  - name: AXIOM_DATASET_NAME\n    value: DATASET_NAME\n  - name: AXIOM_API_TOKEN\n    value: API_TOKEN\n```\n\n----------------------------------------\n\nTITLE: Adding Server Context to Server Actions with Axiom in Next.js\nDESCRIPTION: Demonstrates how to use runWithServerContext to add a request_id to server actions in Next.js. This wrapper function allows context data to be included with logs generated within the wrapped function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_22\n\nLANGUAGE: typescript\nCODE:\n```\n\"use server\";\nimport { runWithServerContext } from \"@axiomhq/nextjs\";\n\nexport const serverAction = () =>\n  runWithServerContext({ request_id: crypto.randomUUID() }, () => {\n    return \"Hello World\";\n  });\n\n```\n\n----------------------------------------\n\nTITLE: Querying HTTP Status Distribution with Kusto\nDESCRIPTION: Query that aggregates HTTP logs to show the distribution of status codes. Uses the summarize operation to count occurrences grouped by status field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/pie-chart.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['http-logs']\n| summarize count() by status\n```\n\n----------------------------------------\n\nTITLE: Implementing Route Handlers with Axiom in Next.js\nDESCRIPTION: Shows how to wrap route handlers with Axiom logging functionality in a Next.js application.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { withAxiom, AxiomRequest } from \"next-axiom\";\n\nexport const GET = withAxiom((req: AxiomRequest) => {\n  req.log.info(\"Login function called\");\n\n  // You can create intermediate loggers\n  const log = req.log.with({ scope: \"user\" });\n  log.info(\"User logged in\", { userId: 42 });\n\n  return NextResponse.json({ hello: \"world\" });\n});\n```\n\n----------------------------------------\n\nTITLE: Analyzing Request Durations in Web Server Logs with APL Histogram\nDESCRIPTION: Uses the histogram aggregation to analyze the distribution of request durations in web server logs, grouping them into 100 millisecond bins.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/histogram.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize histogram(req_duration_ms, 100) by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Configuring Winlogbeat for Windows Event Collection\nDESCRIPTION: YAML configuration for Winlogbeat to collect Windows Application, System, and Security event logs and send them to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nwinlogbeat.event_logs:\n  - name: Application\n  - name: System\n  - name: Security\nlogging.to_files: true\nlogging.files:\n  path: C:\\ProgramData\\Winlogbeat\\Logs\nlogging.level: info\noutput.elasticsearch:\n  hosts: ['https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic']\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n```\n\n----------------------------------------\n\nTITLE: String Filtering Comparisons in Kusto\nDESCRIPTION: Demonstrates efficient string filtering using direct 'contains' instead of 'matches' regex pattern and shows proper usage of 'search' versus field-specific contains_cs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/performance.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| where message matches \"[Ff]ailed\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| where message contains \"failed\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| search \"foobar\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| where FIELD contains_cs \"foobar\"\n```\n\n----------------------------------------\n\nTITLE: Finding Longest Request Duration in Log Analysis using APL\nDESCRIPTION: This query uses the max function in APL to find the longest request duration from the 'req_duration_ms' field in sample HTTP logs. It's useful for diagnosing performance issues in log analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/max.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize max(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Retrieving First 3 Rows in APL for OpenTelemetry Traces\nDESCRIPTION: This APL query shows how to use the take operator to extract the first 3 spans from an OpenTelemetry traces dataset for analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/take-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces'] \n| take 3\n```\n\n----------------------------------------\n\nTITLE: Ingesting JSON Events via Curl\nDESCRIPTION: Example of sending JSON events to Axiom using curl. This request includes multiple events with different structures.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/ingest.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/{dataset_name}/ingest' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -H 'Content-Type: application/json' \\\n  -d '[\n        {\n          \"time\":\"2025-01-12T00:00:00.000Z\",\n          \"data\":{\"key1\":\"value1\",\"key2\":\"value2\"}\n        },\n        {\n          \"data\":{\"key3\":\"value3\"},\n          \"labels\":{\"key4\":\"value4\"}\n        }\n      ]'\n```\n\n----------------------------------------\n\nTITLE: Configuring Pino Logger with Axiom Transport\nDESCRIPTION: Creates a Pino logger instance with Axiom transport configuration. Requires environment variables AXIOM_DATASET and AXIOM_TOKEN for authentication.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/pino.mdx#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport pino from 'pino';\n\nconst logger = pino(\n  { level: 'info' },\n  pino.transport({\n    target: '@axiomhq/pino',\n    options: {\n      dataset: process.env.AXIOM_DATASET,\n      token: process.env.AXIOM_TOKEN,\n    },\n  }),\n);\n```\n\n----------------------------------------\n\nTITLE: Installing @axiomhq/react Library for React\nDESCRIPTION: Command to install the @axiomhq/react library and its dependencies using npm.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/react.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnpm install --save @axiomhq/logging @axiomhq/react\n```\n\n----------------------------------------\n\nTITLE: Converting IP Address with Netmask in ANSI SQL vs APL\nDESCRIPTION: Comparison of IP address conversion between ANSI SQL's inet_aton with bit manipulation and APL's parse_ipv4_mask function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/parse-ipv4-mask.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT inet_aton('192.168.1.0') & (0xFFFFFFFF << (32 - 24)) AS converted_ip\n```\n\nLANGUAGE: kusto\nCODE:\n```\nprint converted_ip = parse_ipv4_mask(\"192.168.1.0\", 24)\n```\n\n----------------------------------------\n\nTITLE: Counting HTTP Requests from a Specific City\nDESCRIPTION: A security logs example that counts how many HTTP requests originated from New York city, useful for location-based traffic analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/countif.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize countif(['geo.city'] == 'New York')\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Lambda Extension with AWS CLI\nDESCRIPTION: This snippet shows how to add the Axiom Lambda Extension as a layer to an AWS Lambda function using the AWS CLI. It requires replacing placeholders for AWS_REGION, ARCH, and VERSION with appropriate values.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-lambda.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\naws lambda update-function-configuration --function-name my-function \\\n    --layers arn:aws:lambda:AWS_REGION:694952825951:layer:axiom-extension-ARCH:VERSION\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Client with Personal Token\nDESCRIPTION: Example showing how to configure the Axiom client with authentication options using SetClientOptions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/logrus.mdx#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nimport (\n    \"github.com/axiomhq/axiom-go/axiom\"\n    adapter \"github.com/axiomhq/axiom-go/adapters/logrus\"\n)\n\n// ...\n\nhook, err := adapter.New(\n    adapter.SetClientOptions(\n        axiom.SetPersonalTokenConfig(\"AXIOM_TOKEN\"),\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL DISTINCT with APL make_set_if Function\nDESCRIPTION: Demonstrates how ANSI SQL's DISTINCT combined with CASE WHEN can be replaced by APL's make_set_if function for conditional aggregation of distinct values.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set-if.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DISTINCT CASE WHEN condition THEN field END\nFROM table\nGROUP BY another_field\n```\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize make_set_if(field, condition) by another_field\n```\n\n----------------------------------------\n\nTITLE: Importing Axiom Zap adapter in Go\nDESCRIPTION: This snippet shows how to import the Axiom Zap adapter in a Go application. The adapter is imported with an alias to avoid conflicts with the uber-go/zap package.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/zap.mdx#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nimport adapter \"github.com/axiomhq/axiom-go/adapters/zap\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Fluentd with Buffer and Filter Patterns\nDESCRIPTION: This configuration demonstrates how to set up Fluentd with buffer intervals, size limits, and filter patterns. It collects system and Apache logs, excludes specific patterns, and sends the data to Axiom using the OpenSearch output plugin.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluentd.mdx#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<source>\n  @type tail\n  @id system_logs\n  <parse>\n    @type none\n  </parse>\n  path /var/log/*.log\n  pos_file /var/log/fluentd/system.log.pos\n  read_from_head true\n  tag system.logs\n</source>\n\n<source>\n  @type tail\n  @id apache_logs\n  <parse>\n    @type apache2\n  </parse>\n  path /var/log/apache2/*.log\n  pos_file /var/log/fluentd/apache2.log.pos\n  read_from_head true\n  tag apache.logs\n</source>\n\n<filter **>\n  @type grep\n  <exclude>\n    key message\n    pattern /exclude_this_pattern/\n  </exclude>\n</filter>\n\n<match **>\n  @type opensearch\n  @id out_os\n  @log_level info\n  include_tag_key true\n  include_timestamp true\n  host \"#{ENV['FLUENT_OPENSEARCH_HOST']  || 'api.axiom.co'}\"\n  port \"#{ENV['FLUENT_OPENSEARCH_PORT'] || '443'}\"\n  path \"#{ENV['FLUENT_OPENSEARCH_PATH']|| '/v1/datasets/DATASET_NAME/elastic'}\"\n  scheme \"#{ENV['FLUENT_OPENSEARCH_SCHEME'] || 'https'}\"\n  ssl_verify \"#{ENV['FLUENT_OPENSEARCH_SSL_VERIFY'] || 'true'}\"\n  ssl_version \"#{ENV['FLUENT_OPENSEARCH_SSL_VERSION'] || 'TLSv1_2'}\"\n  user \"#{ENV['FLUENT_OPENSEARCH_USER'] || 'axiom'}\"\n  password \"#{ENV['FLUENT_OPENSEARCH_PASSWORD'] || 'xaat-xxxxxxxxxx-xxxxxxxxx-xxxxxxx'}\"\n  index_name \"#{ENV['FLUENT_OPENSEARCH_INDEX_NAME'] || 'fluentd'}\"\n\n  <buffer>\n    @type memory\n    flush_mode interval\n    flush_interval 10s\n    chunk_limit_size 5M\n    retry_max_interval 30\n    retry_forever true\n  </buffer>\n</match>\n```\n\n----------------------------------------\n\nTITLE: Aggregation Operations\nDESCRIPTION: Examples of performing aggregation operations with grouping.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_14\n\nLANGUAGE: splunk\nCODE:\n```\nsearch (Rule=120502.*) | stats count by OSEnv, Audience\n```\n\nLANGUAGE: apl\nCODE:\n```\n['sample-http-logs'] | summarize count() by content_type, status\n```\n\n----------------------------------------\n\nTITLE: Aggregation with HAVING in SQL and APL\nDESCRIPTION: Shows how to filter grouped results based on aggregate values. The SQL example uses HAVING while the APL version uses a where clause after summarize to filter status codes that appear more than 10 times.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSELECT Status\nFROM [Sample-http-logs];\nGROUP BY Status\nHAVING COUNT(*) > 10;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize OrderCount = count() by status\n| where OrderCount > 10\n```\n\n----------------------------------------\n\nTITLE: Creating Axiom CloudWatch Forwarder Module with Terraform\nDESCRIPTION: Terraform configuration to create a Forwarder module that handles forwarding logs from CloudWatch to Axiom. Requires dataset name and API token configuration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/cloudwatch.mdx#2025-04-22_snippet_0\n\nLANGUAGE: hcl\nCODE:\n```\nmodule \"forwarder\" {\n  source           = \"axiomhq/axiom-cloudwatch-forwarder/aws//modules/forwarder\"\n  axiom_dataset    = \"DATASET_NAME\"\n  axiom_token      = \"API_TOKEN\"\n  prefix           = \"axiom-cloudwatch-forwarder\"\n}\n```\n\n----------------------------------------\n\nTITLE: Substring Search Query in Axiom\nDESCRIPTION: Shows how to search for logs containing a specific substring using wildcards. This example searches for any entries containing 'brazil' anywhere in the log.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search \"*brazil*\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Fluentd with OpenSearch Output Plugin for Axiom\nDESCRIPTION: This configuration uses the OpenSearch output plugin to send data to Axiom. It sets up a tail source for Apache logs and defines a match block for sending data to Axiom's OpenSearch-compatible endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluentd.mdx#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<source>\n  @type tail\n  @id input_tail\n  <parse>\n    @type apache2\n  </parse>\n  path /var/log/*.log\n  tag td.logs\n</source>\n\n<match **>\n  @type opensearch\n  @id out_os\n  @log_level info\n  include_tag_key true\n  include_timestamp true\n  host \"#{ENV['FLUENT_OPENSEARCH_HOST']  || 'api.axiom.co'}\"\n  port \"#{ENV['FLUENT_OPENSEARCH_PORT'] || '443'}\"\n  path \"#{ENV['FLUENT_OPENSEARCH_PATH']|| '/v1/datasets/DATASET_NAME/elastic'}\"\n  scheme \"#{ENV['FLUENT_OPENSEARCH_SCHEME'] || 'https'}\"\n  ssl_verify \"#{ENV['FLUENT_OPENSEARCH_SSL_VERIFY'] || 'true'}\"\n  ssl_version \"#{ENV['FLUENT_OPENSEARCH_SSL_VERSION'] || 'TLSv1_2'}\"\n  user \"#{ENV['FLUENT_OPENSEARCH_USER'] || 'axiom'}\"\n  password \"#{ENV['FLUENT_OPENSEARCH_PASSWORD'] || 'xaat-xxxxxxxxxx-xxxxxxxxx-xxxxxxx'}\"\n  index_name \"#{ENV['FLUENT_OPENSEARCH_INDEX_NAME'] || 'fluentd'}\"\n</match>\n```\n\n----------------------------------------\n\nTITLE: Implementing GeoIP Filter in Logstash\nDESCRIPTION: Configuration showing how to use the GeoIP filter plugin to add geographical location information based on IP addresses.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/logstash.mdx#2025-04-22_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\ninput{\n  exec{\n    command => \"axiom\"\n    interval => \"6\"\n  }\n}\n\nfilter {\n  geoip {\n    source => \"ip\"\n  }\n}\n\noutput{\n  opensearch{\n    hosts => [\"https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic\"]\n    user => \"axiom\"\n    password => \"API_TOKEN\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Geolocation Information from IPv4 Address\nDESCRIPTION: Example demonstrating how to filter data based on geolocation attributes obtained from an IPv4 address, such as country, country ISO code, and state.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip_location = geo_info_from_ip_address('20.53.203.50')\n| where ip_location.country == \"Australia\" and ip_location.country_iso == \"AU\" and ip_location.state == \"New South Wales\"\n```\n\n----------------------------------------\n\nTITLE: Aggregation in Splunk SPL and APL\nDESCRIPTION: Illustrates the difference in aggregation between Splunk SPL using the 'stats' command and APL using the 'summarize' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsearch index=\"myIndex\" \n| stats count by status\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['myDataset'] \n| summarize count() by status\n```\n\n----------------------------------------\n\nTITLE: Finding Slowest Services by Operation\nDESCRIPTION: Query to identify the top 5 slowest services by analyzing operation duration averages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/traces.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize count(), avg(duration) by name\n| sort by avg_duration desc\n| limit 5\n```\n\n----------------------------------------\n\nTITLE: Sampling OpenTelemetry Traces for Service Analysis in APL\nDESCRIPTION: Example of filtering traces for a specific service and then sampling 5% of the results to investigate performance metrics across different spans.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sample-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| where ['service.name'] == 'checkoutservice'\n| sample 0.05\n```\n\n----------------------------------------\n\nTITLE: Reordering HTTP Log Fields in APL\nDESCRIPTION: An example that reorders HTTP log fields to prioritize the most relevant ones for log analysis. This query places time, method, status, and other key fields at the beginning for easier analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project-reorder _time, method, status, uri, req_duration_ms, ['geo.city'], ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with Project Operator in APL\nDESCRIPTION: Example query that extracts timestamp, HTTP status code, and request URI from sample HTTP logs using the project operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project _time, status, uri\n```\n\n----------------------------------------\n\nTITLE: Practical Example of has_any_ipv4 in APL\nDESCRIPTION: This snippet provides a practical example of using the has_any_ipv4 function in APL to filter HTTP logs based on specific IP addresses or subnets. It extends the result set with a boolean column indicating whether each log entry matches the specified IP criteria.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-any-ipv4.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend has_ip = has_any_ipv4('192.168.1.1', dynamic(['192.168.1.1', '192.168.0.0/16']))\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL and APL for Average Calculation\nDESCRIPTION: This snippet demonstrates how to calculate average request duration by status in both ANSI SQL and APL, highlighting the syntax differences between the two languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avg.mdx#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT status, AVG(req_duration_ms)\nFROM sample_http_logs\nGROUP BY status\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize avg(req_duration_ms) by status\n```\n\n----------------------------------------\n\nTITLE: Log Analysis Example using make_list_if in APL\nDESCRIPTION: This example demonstrates how to use make_list_if for log analysis in APL. It gathers a list of request durations for successful HTTP requests, grouped by ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list-if.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize make_list_if(req_duration_ms, status == '200') by id\n```\n\n----------------------------------------\n\nTITLE: Monitoring Response Times with APL\nDESCRIPTION: APL query to calculate median response times by route for top-level spans in one-minute intervals, used for anomaly detection in trace data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/monitor-data/monitor-examples.mdx#2025-04-22_snippet_2\n\nLANGUAGE: apl\nCODE:\n```\n['my_traces'] \n| where isempty(parent_span_id)\n| summarize percentile(duration, 50) by ['route'], bin(_time, 1m)\n```\n\n----------------------------------------\n\nTITLE: Initializing Axiom Client with API Token\nDESCRIPTION: Example showing how to initialize the Axiom client using an API token for authentication.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/python.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport axiom_py\n\nclient = axiom_py.Client(\"API_TOKEN\")\n```\n\n----------------------------------------\n\nTITLE: Using Mutate Filter in Logstash\nDESCRIPTION: Example of using the Mutate filter plugin to perform field transformations including renaming, converting, uppercasing, and removing fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/logstash.mdx#2025-04-22_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\ninput{\n  exec{\n    command => \"axiom\"\n    interval => \"1\"\n  }\n}\n\nfilter {\n  mutate {\n    rename => { \"hostname\" => \"host\" }\n    convert => { \"response\" => \"integer\" }\n    uppercase => [ \"method\" ]\n    remove_field => [ \"request\", \"httpversion\" ]\n  }\n}\n\noutput{\n  opensearch{\n    hosts => [\"https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic\"]\n    user => \"axiom\"\n    password => \"API_TOKEN\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using varianceif for HTTP Log Analysis\nDESCRIPTION: Example query demonstrating how to calculate the variance of request durations specifically for successful HTTP requests with status code 200.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/varianceif.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize varianceif(req_duration_ms, status == '200')\n```\n\n----------------------------------------\n\nTITLE: Finding Top HTTP Status Codes with topk in APL\nDESCRIPTION: Query example that demonstrates using topk to identify the 5 most frequent HTTP status codes in log data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/topk.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize topk(status, 5)\n```\n\n----------------------------------------\n\nTITLE: Measuring Span Duration Variance in OpenTelemetry Traces\nDESCRIPTION: Using variance to measure how much span durations differ across service invocations in OpenTelemetry traces for performance optimization.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/variance.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces'] \n| summarize variance(duration)\n```\n\n----------------------------------------\n\nTITLE: Implementing Error Handling with Axiom in Next.js\nDESCRIPTION: Demonstrates how to capture and log errors using Axiom in a Next.js error handling component.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n\"use client\";\n\nimport NavTable from \"@/components/NavTable\";\nimport { LogLevel } from \"@/next-axiom/logger\";\nimport { useLogger } from \"next-axiom\";\nimport { usePathname } from \"next/navigation\";\n\nexport default function ErrorPage({\n  error,\n}: {\n  error: Error & { digest?: string };\n}) {\n  const pathname = usePathname();\n  const log = useLogger({ source: \"error.tsx\" });\n  let status = error.message == \"Invalid URL\" ? 404 : 500;\n\n  log.logHttpRequest(\n    LogLevel.error,\n    error.message,\n    {\n      host: window.location.href,\n      path: pathname,\n      statusCode: status,\n    },\n    {\n      error: error.name,\n      cause: error.cause,\n      stack: error.stack,\n      digest: error.digest,\n    }\n  );\n\n  return (\n    <div className=\"p-8\">\n      Ops! An Error has occurred:{\" \"}\n      <p className=\"text-red-400 px-8 py-2 text-lg\">`{error.message}`</p>\n      <div className=\"w-1/3 mt-8\">\n        <NavTable />\n      </div>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Counting HTTP Requests by Country\nDESCRIPTION: Example of using count for security analysis by grouping HTTP requests by country of origin. This helps identify traffic patterns and potential suspicious activity.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/count.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Adding OpenTelemetry Instrumentation Gems to Ruby on Rails Gemfile\nDESCRIPTION: This snippet shows the necessary gems to include in a Ruby on Rails Gemfile for automatic OpenTelemetry instrumentation of Rails, HTTP, and ActiveRecord components.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-ruby.mdx#2025-04-22_snippet_6\n\nLANGUAGE: ruby\nCODE:\n```\ngem 'opentelemetry-instrumentation-rails'\ngem 'opentelemetry-instrumentation-http'\ngem 'opentelemetry-instrumentation-active_record'\n```\n\n----------------------------------------\n\nTITLE: Sending AWS S3 Logs to Axiom with Vector\nDESCRIPTION: A Vector configuration for reading logs from an AWS S3 bucket and sending them to Axiom. Requires specifying the bucket name, AWS region, and Axiom credentials.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_s3_source]\ntype = \"aws_s3\"\nbucket = \"my-bucket\"  # replace with your bucket name\nregion = \"us-west-2\"  # replace with the AWS region of your bucket\n\n[sinks.axiom]\ntype = \"axiom\"\ninputs = [\"my_s3_source\"]\ndataset = \"DATASET_NAME\"\ntoken = \"API_TOKEN\"\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with avgif\nDESCRIPTION: Example query calculating average request duration for HTTP 200 status codes grouped by city.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avgif.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize avgif(req_duration_ms, status == \"200\") by ['geo.city']\n```\n\n----------------------------------------\n\nTITLE: Querying Map Fields in Axiom using APL (Axiom Processing Language)\nDESCRIPTION: This example demonstrates how to query a map field by filtering traces where the 'http.protocol' property inside the 'attributes.custom' map field equals 'HTTP/1.1'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/map-fields.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| where ['attributes.custom']['http.protocol'] == 'HTTP/1.1'\n```\n\n----------------------------------------\n\nTITLE: Sending data to Axiom using @axiomhq/logging\nDESCRIPTION: Example of sending data to Axiom using the @axiomhq/logging library with multiple transports.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger, AxiomJSTransport, ConsoleTransport } from \"@axiomhq/logging\";\nimport { Axiom } from \"@axiomhq/js\";\n\nconst axiom = new Axiom({\n  token: process.env.AXIOM_TOKEN,\n});\n\nconst logger = new Logger(\n  {\n    transports: [\n      new AxiomJSTransport({ axiom }),\n      new ConsoleTransport(),\n    ],\n  }\n);\n\nlogger.info(\"Hello, world!\");\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL with APL percentileif Syntax\nDESCRIPTION: Demonstrates how to convert a Splunk SPL percentile calculation with conditional filtering to APL's percentileif function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentileif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nstats perc95(req_duration_ms) as p95 where geo.country=\"US\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentileif(req_duration_ms, 95, geo.country == 'US')\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL MIN Function with APL Equivalent\nDESCRIPTION: Demonstrates the MIN function in SQL and its equivalent implementation in APL for finding minimum values grouped by ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/min.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(duration), id FROM sample_http_logs GROUP BY id;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize min(req_duration_ms) by id\n```\n\n----------------------------------------\n\nTITLE: Sending Web Vitals in React App Root\nDESCRIPTION: Shows how to mount the WebVitals component in the root of a React application to capture and send Web Vitals data to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/react.mdx#2025-04-22_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\nimport { WebVitals } from \"@/lib/axiom/client\";\n\nexport default function App({ children }: { children: React.ReactNode }) {\n  return (\n    <main>\n      <WebVitals />\n      {children}\n    </main>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Axiom Provider in Terraform\nDESCRIPTION: This snippet shows how to configure the Axiom provider in a Terraform configuration file. It specifies the required provider and sets up the API token for authentication.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_0\n\nLANGUAGE: hcl\nCODE:\n```\nterraform {\n  required_providers {\n    axiom = {\n      source  = \"axiomhq/axiom\"\n    }\n  }\n}\n\nprovider \"axiom\" {\n  api_token = \"API_TOKEN\"\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating 95th percentile of request durations in log analysis\nDESCRIPTION: APL query example that calculates the 95th percentile of request durations from HTTP logs, useful for analyzing tail-end latencies.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentile.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentile(req_duration_ms, 95)\n```\n\n----------------------------------------\n\nTITLE: Grouping Security Logs by HTTP Status Codes\nDESCRIPTION: Demonstrates using summarize to group security events by HTTP status codes to analyze the distribution of responses.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by status\n```\n\n----------------------------------------\n\nTITLE: Setting Custom Time Range in APL Query for Axiom Dashboard Element\nDESCRIPTION: This snippet demonstrates how to set a custom time range for a dashboard element created with APL by using the 'where' operator to filter events from the last 6 hours.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/create.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| where _time > now(-6h)\n```\n\n----------------------------------------\n\nTITLE: Detecting Requests from Specific IP Ranges in APL\nDESCRIPTION: This snippet shows a use case example of the has_any_ipv4_prefix function to detect requests from specific IP ranges in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-any-ipv4-prefix.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend has_ip_prefix = has_any_ipv4_prefix('192.168.0.1', dynamic(['172.16.', '192.168.']))\n```\n\n----------------------------------------\n\nTITLE: String Operations with Contains Operator\nDESCRIPTION: Queries demonstrating string contains operator for filtering bot names and status codes\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_20\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issue-comment-event']\n| extend bot = actor contains \"-bot\" or actor contains \"[bot]\"\n| where bot == true\n| summarize count() by bin_auto(_time), actor\n| take 20\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend user_status = status contains \"200\" , agent_flow = user_agent contains \"(Windows NT 6.4; AppleWebKit/537.36 Chrome/41.0.2225.0 Safari/537.36\"\n| where user_status == true\n| summarize count() by bin_auto(_time), status\n| take 15\n```\n\n----------------------------------------\n\nTITLE: Analyzing Top Errors by Service and Operation\nDESCRIPTION: Query to list the top 5 errors for each service and operation combination.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/traces.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize topk(['status.message'], 5) by ['service.name'], name\n| limit 5\n```\n\n----------------------------------------\n\nTITLE: Counting Error Messages by Type in APL\nDESCRIPTION: APL query to count error messages grouped by error type in 5-minute intervals, useful for threshold-based monitoring of error frequencies.\nSOURCE: https://github.com/axiomhq/docs/blob/main/monitor-data/monitor-examples.mdx#2025-04-22_snippet_1\n\nLANGUAGE: apl\nCODE:\n```\n['sample_dataset']\n| summarize count() by ['error.message'], bin(_time, 5m)\n```\n\n----------------------------------------\n\nTITLE: Querying HTTP Logs with Percentile Aggregation in Kusto\nDESCRIPTION: This Kusto query retrieves sample HTTP logs, calculates percentiles of request duration, and groups results by status and time bins. It demonstrates the use of summarize, percentiles_array, and bin_auto functions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/explore.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentiles_array(req_duration_ms, 50, 90, 95) by status, bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Importing Axiom Transport for Winston in JavaScript\nDESCRIPTION: Imports the Axiom transport for Winston logger in a JavaScript file.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/winston.mdx#2025-04-22_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport { WinstonTransport as AxiomTransport } from '@axiomhq/winston';\n```\n\n----------------------------------------\n\nTITLE: Dockerizing Java Application with Fluentd\nDESCRIPTION: Dockerfile for building and running the Java application with Fluentd integration. Uses a multi-stage build process to compile the Java application and set up a runtime environment with both Java and Fluentd.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-apache-log4j.mdx#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n# Build stage\nFROM maven:3.8.1-openjdk-11-slim AS build\n\nWORKDIR /usr/src/app\nCOPY pom.xml .\nCOPY src ./src\nCOPY log4j2.xml .\nRUN mvn clean package\n\n# Runtime stage\nFROM openjdk:11-jre-slim\n\nWORKDIR /usr/src/app\n\nRUN apt-get update && \\\n    apt-get install -y --no-install-recommends \\\n    ruby \\\n    ruby-dev \\\n    build-essential && \\\n    gem install fluentd --no-document && \\\n    fluent-gem install fluent-plugin-multi-format-parser && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\nCOPY --from=build /usr/src/app/target/log4j-axiom-test-1.0-SNAPSHOT.jar .\nCOPY fluentd.conf /etc/fluent/fluent.conf\nCOPY log4j2.xml .\n\n# Create startup script\nRUN echo '#!/bin/sh\\n\\\nfluentd -c /etc/fluent/fluent.conf &\\n\\\nsleep 5\\n\\\njava -Dlog4j.configurationFile=log4j2.xml -jar log4j-axiom-test-1.0-SNAPSHOT.jar\\n'\\\n> /usr/src/app/start.sh && chmod +x /usr/src/app/start.sh\n\nEXPOSE 24224\n\nCMD [\"/usr/src/app/start.sh\"]\n```\n\n----------------------------------------\n\nTITLE: Using parse_ipv4 Function in APL\nDESCRIPTION: This snippet demonstrates the syntax and usage of the parse_ipv4 function in APL. It converts the IPv4 address '192.168.1.1' to a long number.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/parse-ipv4.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip_long = parse_ipv4('192.168.1.1')\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis with topk in APL\nDESCRIPTION: Query that identifies the top 5 cities generating the most HTTP requests in security logs using topk aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/topk.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize topk(['geo.city'], 5)\n```\n\n----------------------------------------\n\nTITLE: Querying with Specific Field Projection in Kusto\nDESCRIPTION: This snippet demonstrates how to use the 'project' clause in a Kusto query to specify exactly which fields are needed, reducing unnecessary data retrieval and improving query performance.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/performance.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| where status == 500\n| project timestamp, error_code, user_id\n```\n\n----------------------------------------\n\nTITLE: Creating CloudWatch Listener Module with Terraform\nDESCRIPTION: Terraform configuration to create a Listener module that automatically creates subscription filters for new log groups. References the Forwarder Lambda ARN.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/cloudwatch.mdx#2025-04-22_snippet_2\n\nLANGUAGE: hcl\nCODE:\n```\nmodule \"listener\" {\n  source               = \"axiomhq/axiom-cloudwatch-forwarder/aws//modules/listener\"\n  prefix               = \"axiom-cloudwatch-forwarder\"\n  forwarder_lambda_arn = module.forwarder.lambda_arn\n  log_groups_prefix    = \"/aws/lambda/\"\n}\n```\n\n----------------------------------------\n\nTITLE: Counting OpenTelemetry Traces by Service\nDESCRIPTION: Example of using count to analyze OpenTelemetry traces by grouping on service name. This helps to monitor the distribution of requests across different services.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/count.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize count() by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Configuring Auditbeat for File Integrity Monitoring\nDESCRIPTION: This configuration sets up Auditbeat to monitor file integrity for critical system directories. The file_integrity module will generate events whenever files in the specified paths change, capturing metadata and file hashes which are then sent to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n# Disable index lifecycle management (ILM)\nsetup.ilm.enabled: false\nauditbeat.modules:\n  - module: file_integrity\n    paths:\n      - /usr/bin\n      - /sbin\n      - /usr/sbin\n      - /etc\n      - /bin\n      - /usr/local/sbin\noutput.elasticsearch:\n  hosts: ['https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic']\n  # token should be an API token\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n```\n\n----------------------------------------\n\nTITLE: Sending Logs to Axiom using Python and Elastic Bulk API\nDESCRIPTION: Python code snippet showing how to send log data to Axiom using the Elastic Bulk API. It uses the requests library to make an HTTP POST request with the necessary headers and data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elasticsearch-bulk-api.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nimport json\n\ndata = \"\"\"\n{\"index\": {\"_index\": \"myindex\", \"_id\": \"1\"}}\n{\"@timestamp\": \"2024-01-07T12:00:00Z\", \"message\": \"axiom elastic bulk\", \"severity\": \"INFO\"}\n{\"index\": {\"_index\": \"myindex\", \"_id\": \"2\"}}\n{\"@timestamp\": \"2024-01-07T12:00:01Z\", \"message\": \"Log message 2\", \"severity\": \"ERROR\"}\n\"\"\"\n\n# Replace these with your actual dataset name and API token\ndataset = \"DATASET_NAME\"\napi_token = \"API_TOKEN\"\n\n# The URL for the bulk API\nurl = f'https://api.axiom.co:443/v1/datasets/{dataset}/elastic/_bulk'\n\ntry:\n    response = requests.post(\n        url,\n        data=data,\n        headers={\n            'Content-Type': 'application/x-ndjson',\n            'Authorization': f'Bearer {api_token}'\n        }\n    )\n    response.raise_for_status()\nexcept requests.HTTPError as http_err:\n    print(f'HTTP error occurred: {http_err}')\n    print('Response:', response.text)\nexcept Exception as err:\n    print(f'Other error occurred: {err}')\nelse:\n    print('Success!')\n\n    try:\n        print(response.json())\n    except json.JSONDecodeError:\n        print(response.text)\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Request Duration by Country in APL\nDESCRIPTION: This query calculates the average request duration by country to analyze regional performance trends using security log data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avg.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize avg(req_duration_ms) by ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Counting Distinct User IDs in Log Analysis\nDESCRIPTION: An example query that counts distinct user IDs in a sample HTTP logs dataset. This demonstrates how to use dcount for analyzing unique users accessing a service.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcount.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize dcount(id)\n```\n\n----------------------------------------\n\nTITLE: Finding Top 6 IPs by Number of Hits in Sumo Logic and APL\nDESCRIPTION: Queries to identify the most active source IP addresses based on hit count. The Sumo Logic approach parses IPs directly from logs, while the APL approach extracts IP information from user agent strings and counts occurrences.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache \n| parse \"* -\" as src_ip \n| count by src_ip \n| top 100 src_ip by _count\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend src_ip = extract(\"^(\\\\S+)\", 1, user_agent)\n| summarize _count = count() by src_ip\n| top 6 by _count desc\n```\n\n----------------------------------------\n\nTITLE: Calculating Standard Deviation of Span Durations in OpenTelemetry Traces\nDESCRIPTION: This query computes the standard deviation of span durations in an OpenTelemetry traces dataset. It shows how to use stdev to analyze trace data for identifying inconsistent spans or performance issues.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdev.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize span_duration_std = stdev(duration)\n```\n\n----------------------------------------\n\nTITLE: Finding Most Common HTTP Status Codes in Security Logs\nDESCRIPTION: This example query combines the summarize and top operators to identify the 3 most frequent HTTP status codes in security logs. It first counts occurrences by status code and then uses top to show the highest counts.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/top-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by status\n| top 3 by count_\n```\n\n----------------------------------------\n\nTITLE: Creating Winston Logger Instance with Axiom Transport in JavaScript\nDESCRIPTION: Sets up a Winston logger instance with Axiom transport, configuring log level, format, and default metadata.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/winston.mdx#2025-04-22_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nconst logger = winston.createLogger({\n    level: 'info',\n    format: winston.format.json(),\n    defaultMeta: { service: 'user-service' },\n    transports: [\n        // You can pass an option here. If you don't, the transport is configured automatically\n        // using environment variables like `AXIOM_DATASET` and `AXIOM_TOKEN`\n        new AxiomTransport({\n            dataset: 'DATASET_NAME',\n            token: 'API_TOKEN',\n        }),\n    ],\n});\n```\n\n----------------------------------------\n\nTITLE: Basic Union of Two Datasets in APL\nDESCRIPTION: This snippet demonstrates how to use the union operator to combine data from two datasets: 'sample-http-logs' and 'security-logs'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| union ['security-logs']\n```\n\n----------------------------------------\n\nTITLE: Syntax of the lookup Operator in APL\nDESCRIPTION: This snippet outlines the general syntax of the lookup operator in APL. It shows how to specify the primary dataset, lookup table, kind of lookup, and matching conditions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/lookup-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nPrimaryDataset\n| lookup kind=KindOfLookup LookupTable on Conditions\n```\n\n----------------------------------------\n\nTITLE: Analyzing Top 10 IPs by Bandwidth Usage in Sumo Logic and APL\nDESCRIPTION: Queries to identify source IP addresses consuming the most bandwidth. The Sumo Logic query parses size and IP from logs, while the Axiom APL query uses request duration as a proxy for size and calculates total bandwidth by ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache \n| parse \" 200 * \" as size \n| parse \"* -\" as src_ip \n| sum(size) as total_bytes by src_ip \n| top 10 src_ip by total_bytes\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend size = req_duration_ms\n| summarize total_bytes = sum(size) by ['id']\n| top 10 by total_bytes desc\n```\n\n----------------------------------------\n\nTITLE: Reordering Specific Fields and Using Wildcard for Others\nDESCRIPTION: An example showing how to reorder specific fields while using wildcards to maintain other fields in their original order. This demonstrates placing certain fields at specific positions in the output.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| project-reorder trace_id, *, span_id // orders the trace_id then everything else, then span_id fields \n```\n\n----------------------------------------\n\nTITLE: Executing APL Query via API in JSON\nDESCRIPTION: This snippet demonstrates how to structure a POST request body to execute an Axiom Processing Language (APL) query via the API. It includes the APL query, start time, and end time for the query execution.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/query-hours.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"apl\": \"telegraf | count\",\n  \"startTime\": \"2024-01-11T19:25:00Z\",\n  \"endTime\": \"2024-02-13T19:25:00Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Analysis with Union in APL\nDESCRIPTION: This query combines trace data from different services and filters for errors in the frontend service.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| union ['otel-backend-traces']\n| where ['service.name'] == 'frontend' and status_code == 'error'\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Grafana Plugin via Grafana CLI\nDESCRIPTION: This command installs the Axiom data source plugin for Grafana using the Grafana CLI. It allows users to easily add Axiom as a data source in their Grafana instance.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/grafana.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngrafana-cli plugins install axiomhq-axiom-datasource\n```\n\n----------------------------------------\n\nTITLE: Extracting Geolocation Information from IPv4 Address\nDESCRIPTION: Example showing how to extract geolocation information from an IPv4 address using the geo_info_from_ip_address function and extending the dataset with the result.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip_location = geo_info_from_ip_address('172.217.11.4')\n```\n\n----------------------------------------\n\nTITLE: Histogram Aggregation Syntax in APL\nDESCRIPTION: Demonstrates the basic syntax for using the histogram aggregation function in APL. It takes a numeric field and the number of bins as parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/histogram.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nhistogram(numeric_field, number_of_bins)\n```\n\n----------------------------------------\n\nTITLE: Parsing URLs in APL\nDESCRIPTION: The parse_url function parses an absolute URL string and returns an object containing URL components such as scheme, host, port, path, username, password, query parameters, and fragment.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_13\n\nLANGUAGE: kusto\nCODE:\n```\nparse_url(url)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ParsedURL = parse_url(\"https://www.example.com/path/to/page?query=example\")\n| project \n  Scheme = ParsedURL[\"scheme\"],\n  Host = ParsedURL[\"host\"],\n  Path = ParsedURL[\"path\"],\n  Query = ParsedURL[\"query\"]\n```\n\n----------------------------------------\n\nTITLE: Extracting Service Namespace Prefix in OpenTelemetry Traces\nDESCRIPTION: This query demonstrates using extend-valid to extract the first part of the service namespace from valid namespaces in OpenTelemetry traces.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-valid-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| extend-valid namespace_prefix = extract('^(.*?)-', 1, ['service.namespace'])\n```\n\n----------------------------------------\n\nTITLE: HTTP Body Template Configuration for Cribl\nDESCRIPTION: Body template configuration for forwarding raw log events from Cribl to Axiom via HTTP destination.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/cribl.mdx#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{{_raw}}\n```\n\n----------------------------------------\n\nTITLE: IPv4 Netmask Suffix Function Example in APL\nDESCRIPTION: An example query that uses the ipv4_netmask_suffix function to extract the netmask '24' from the IP address '192.168.1.1/24' when analyzing network traffic logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-netmask-suffix.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend netmask = ipv4_netmask_suffix('192.168.1.1/24')\n```\n\n----------------------------------------\n\nTITLE: Calculating Standard Deviation of Request Durations for POST Methods in Security Logs\nDESCRIPTION: Demonstrates using stdevif to calculate the standard deviation of request durations only for POST HTTP methods, grouped by city. This example shows how to filter by request method when analyzing variability in security logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdevif.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize stdevif(req_duration_ms, method == \"POST\") by ['geo.city']\n```\n\n----------------------------------------\n\nTITLE: Reversing Path Lists in HTTP Logs Analysis\nDESCRIPTION: Uses array_reverse to inspect the sequence of actions in HTTP log entries by reversing the order of URIs accessed by each user. This helps understand the flow of user navigation in reverse chronological order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-reverse.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize paths = make_list(uri) by id\n| project id, reversed_paths = array_reverse(paths)\n```\n\n----------------------------------------\n\nTITLE: Using Axiom Client in Rust\nDESCRIPTION: This snippet demonstrates how to use the Axiom client in Rust. It shows client initialization, dataset creation, data ingestion, querying, and dataset deletion.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/rust.mdx#2025-04-22_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nuse axiom_rs::Client;\nuse serde_json::json;\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    // Build your client by providing a personal token and an org id:\n    let client = Client::builder()\n        .with_token(\"API_TOKEN\")\n        .build()?;\n\n    // Alternatively, auto-configure the client from the environment variable AXIOM_TOKEN:\n    let client = Client::new()?;\n\n    client.datasets().create(\"DATASET_NAME\", \"\").await?;\n\n    client\n        .ingest(\n            \"DATASET_NAME\",\n            vec![json!({\n                \"foo\": \"bar\",\n            })],\n        )\n        .await?;\n\n    let res = client\n        .query(r#\"['DATASET_NAME'] | where foo == \"bar\" | limit 100\"#, None)\n        .await?;\n    println!(\"{:?}\", res);\n\n    client.datasets().delete(\"DATASET_NAME\").await?;\n    Ok(())\n}\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL Timechart to APL Histogram\nDESCRIPTION: Shows how to achieve similar results to Splunk's timechart command using APL's histogram function. This example groups events into time buckets.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/histogram.mdx#2025-04-22_snippet_1\n\nLANGUAGE: splunk\nCODE:\n```\n| stats count by duration | timechart span=10 count\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by histogram(req_duration_ms, 10)\n```\n\n----------------------------------------\n\nTITLE: Configuring Packetbeat for Network Protocol Monitoring\nDESCRIPTION: This configuration sets up Packetbeat to monitor network traffic for various protocols like DNS, HTTP, MySQL, PostgreSQL, Redis, and others. It captures and analyzes network packets in real-time, decodes the application layer protocols, and sends the data to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\n# Disable index lifecycle management (ILM)\nsetup.ilm.enabled: false\npacketbeat.interfaces.auto_promisc_mode: true\npacketbeat.flows:\n  timeout: 30s\n  period: 10s\nprotocols:\n  dns:\n    ports: [53]\n    include_authorities: true\n    include_additionals: true\n  http:\n    ports: [80, 8080, 8081, 5000, 8002]\n  memcache:\n    ports: [11211]\n  mysql:\n    ports: [3306]\n  pgsql:\n    ports: [5432]\n  redis:\n    ports: [6379]\n  thrift:\n    ports: [9090]\n  mongodb:\n    ports: [27017]\noutput.elasticsearch:\n  hosts: ['https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic']\n  # api_key should be your API token\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n```\n\n----------------------------------------\n\nTITLE: Implementing Next.js Middleware for Request Logging\nDESCRIPTION: Middleware configuration to capture and log HTTP traffic in Next.js application.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\nimport { logger } from \"@/lib/axiom/server\";\nimport { transformMiddlewareRequest } from \"@axiomhq/nextjs\";\nimport { NextResponse } from \"next/server\";\nimport type { NextFetchEvent, NextRequest } from \"next/server\";\n\nexport async function middleware(request: NextRequest, event: NextFetchEvent) {\n  logger.info(...transformMiddlewareRequest(request));\n\n  event.waitUntil(logger.flush());\n  return NextResponse.next();\n}\n\nexport const config = {\n  matcher: [\n    \"/((?!api|_next/static|_next/image|favicon.ico|sitemap.xml|robots.txt).*)\",\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Basic Search Query in Axiom\nDESCRIPTION: Demonstrates how to search all logs in a dataset using the wildcard operator. This query returns all rows in the sample-http-logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search *\n```\n\n----------------------------------------\n\nTITLE: Security Logs Sort Example\nDESCRIPTION: Sorting security logs by status code and timestamp for investigating recent failed requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sort-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| sort by status asc, _time desc\n```\n\n----------------------------------------\n\nTITLE: Converting Splunk SPL to APL for Top Results Query\nDESCRIPTION: Comparison between Splunk SPL's top command and APL's topk aggregation for finding the top 5 status codes by method.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/topk.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| top limit=5 status by method\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize topk(status, 5) by method \n```\n\n----------------------------------------\n\nTITLE: Sending Honeycomb Logs Using JavaScript\nDESCRIPTION: Example of sending logs from Honeycomb to Axiom using the libhoney JavaScript library. Requires configuration of writeKey, dataset, and apiHost parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/endpoints/honeycomb.mdx#2025-04-22_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nconst Libhoney = require('libhoney');\nconst hny = new Libhoney({\n  writeKey: '',\n  dataset: '',\n  apiHost: '',\n});\n\nhny.sendNow({ message: 'Welcome to Axiom Endpoints!' });\n```\n\n----------------------------------------\n\nTITLE: Analyzing Security Logs with make_set_if in APL\nDESCRIPTION: A query example that finds HTTP status codes encountered for each city, but only for POST requests, demonstrating conditional set creation in security log analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set-if.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize make_set_if(status, method == 'POST') by ['geo.city']\n```\n\n----------------------------------------\n\nTITLE: Identifying Unique Services in OpenTelemetry Traces using APL\nDESCRIPTION: This query uses the distinct operator to identify all unique services involved in OpenTelemetry traces.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/distinct-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| distinct ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration for Timestamp Field Migration\nDESCRIPTION: Example Vector configuration file that imports a VRL script for field migration from 'timestamp' to '_time'. It defines a transform to apply the migration and configures an Axiom sink for sending the processed data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\n# ...\n\n[transforms.migrate]\ntype = \"remap\"\ninputs = [ \"k8s\"]\nfile= 'example.vrl' # See above\n\n[sinks.debug]\ntype = \"axiom\"\ninputs = [ \"migrate\" ]\ndataset = \"DATASET_NAME\" # No change\ntoken = \"API_TOKEN\" # No change\n\n[sinks.debug.encoding]\ncodec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Converting SQL COUNT with GROUP BY to APL\nDESCRIPTION: Demonstrates how to transform a SQL COUNT with GROUP BY query into APL using the 'summarize' and 'count()' operators.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT Country, COUNT(*)\nFROM [Sample-http-logs]\nGROUP BY method;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by method\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis with percentileif for HTTP Error Codes\nDESCRIPTION: Shows how to calculate the 75th percentile of request durations specifically for HTTP 404 error responses.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentileif.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentileif(req_duration_ms, 75, status == '404')\n```\n\n----------------------------------------\n\nTITLE: Getting Current UTC Time in Axiom Query Language\nDESCRIPTION: The now() function returns the current UTC clock time, optionally offset by a given timespan. It's useful for generating timestamps or comparing against the current time.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_12\n\nLANGUAGE: kusto\nCODE:\n```\nnow([offset])\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project returns_clock_time = now(-5d)\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with project-keep in APL\nDESCRIPTION: Example of using project-keep to analyze HTTP logs by selecting only relevant fields such as timestamp, status, URI, method, and request duration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-keep-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| project-keep _time, status, uri, method, req_duration_ms\n```\n\n----------------------------------------\n\nTITLE: Creating Annotations with GitHub Actions in YAML\nDESCRIPTION: This YAML snippet configures a GitHub Action to create an annotation in Axiom when a deployment occurs. It specifies the Axiom API token, dataset, annotation type, time, and other optional fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/annotate-charts.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n- name: Add annotation in Axiom when a deployment happens\n  uses: axiomhq/annotation-action@v0.1.0\n  with:\n    axiomToken: ${{ secrets.API_TOKEN }}\n    datasets: DATASET_NAME\n    type: \"production-release\"\n    time: \"2024-01-01T00:00:00Z\"                                    # optional, defaults to now\n    endTime: \"2024-01-01T01:00:00Z\"                                 # optional, defaults to null\n    title: \"Production deployment\"                                  # optional\n    description: \"Commit ${{ github.event.head_commit.message }}\"   # optional\n    url: \"https://example.com\"                                      # optional, defaults to job URL\n```\n\n----------------------------------------\n\nTITLE: Filtering OpenTelemetry Traces by Duration in APL\nDESCRIPTION: Example of using the where operator to filter OpenTelemetry traces where duration exceeded 500 milliseconds. This helps identify potentially problematic spans with long durations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| where duration > 500ms\n```\n\n----------------------------------------\n\nTITLE: Ingesting Nested Array JSON Events via Curl\nDESCRIPTION: Example of sending complex nested JSON events to Axiom using curl. This request includes deeply nested arrays and objects.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/ingest.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/{dataset_name}/ingest' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -H 'Content-Type: application/json' \\\n  -d '[\n        {\n        \"axiom\": [{\n            \"logging\":[{\n                \"observability\":[{\n                    \"location\":[{\n                        \"credentials\":[{\n                            \"datasets\":[{\n                                \"first_name\":\"axiom\",\n                                \"last_name\":\"logging\",\n                                \"location\":\"global\"\n                            }],\n                            \"work\":[{\n                                \"details\":\"https://app.axiom.co/\",\n                                \"tutorials\":\"https://www.axiom.co/blog\",\n                                \"changelog\":\"https://www.axiom.co/changelog\",\n                                \"documentation\": \"https://www.axiom.co/docs\"\n                            }]\n                        }],\n                        \"social_media\":[{\n                            \"details\":[{\n                                \"twitter\":\"https://twitter.com/AxiomFM\",\n                                \"linkedin\":\"https://linkedin.com/company/axiomhq\",\n                                \"github\":\"https://github.com/axiomhq\"\n                            }],\n                            \"features\":[{\n                                \"datasets\":\"view logs\",\n                                \"stream\":\"live_tail\",\n                                \"explorer\":\"queries\"\n                            }]\n                        }]\n                    }]\n                }],\n                \"logs\":[{\n                    \"apl\": \"functions\"\n                }]\n            }],\n            \"storage\":[{}]\n        }]}\n      ]'\n```\n\n----------------------------------------\n\nTITLE: Identifying Logs from a Specific User Agent\nDESCRIPTION: This query uses a regex to find logs where the 'user_agent' field contains 'Mozilla/5.0'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_16\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where tostring(user_agent) matches regex \"Mozilla/5.0\"\n```\n\n----------------------------------------\n\nTITLE: Reordering Specific Fields to the Beginning\nDESCRIPTION: An example showing how to reorder specific fields to the beginning of the result set while maintaining the original order of other fields. This demonstrates prioritizing certain fields in the output.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| project-reorder method, status, uri\n```\n\n----------------------------------------\n\nTITLE: Running Axiom Syslog Proxy Binary\nDESCRIPTION: Command to run the Axiom Syslog Proxy after installation\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/syslog-proxy.mdx#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n./axiom-syslog-proxy\n```\n\n----------------------------------------\n\nTITLE: Base64 String Encoding Example in APL\nDESCRIPTION: Demonstrates how to encode a string as base64 using the base64_encode_tostring() function. The example shows both the basic function syntax and a practical usage with the content_type field from sample HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nbase64_encode_tostring(string)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project encoded_base64_string = base64_encode_tostring(content_type)\n```\n\n----------------------------------------\n\nTITLE: Filtering HTTP Logs by Method and Content Type\nDESCRIPTION: This query filters the sample HTTP logs to show only GET requests with application/octet-stream content type.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where method == \"GET\" and content_type == \"application/octet-stream\"\n| project method , content_type\n```\n\n----------------------------------------\n\nTITLE: Converting SQL to APL arg_max Query\nDESCRIPTION: Demonstrates how to convert a complex SQL subquery with JOIN to a simpler APL arg_max aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-max.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nWITH MaxValues AS (\n    SELECT id, MAX(req_duration_ms) as max_duration\n    FROM sample_http_logs\n    GROUP BY id\n)\nSELECT logs.id, logs.uri, MaxValues.max_duration\nFROM sample_http_logs logs\nJOIN MaxValues\nON logs.id = MaxValues.id;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize arg_max(req_duration_ms, id, uri)\n```\n\n----------------------------------------\n\nTITLE: Sorting OpenTelemetry Traces by Span Duration\nDESCRIPTION: This query sorts OpenTelemetry trace data by span duration in descending order to identify the longest-running spans across services.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/order-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| order by duration desc\n```\n\n----------------------------------------\n\nTITLE: Log Analysis Example with dcountif\nDESCRIPTION: Example query showing how to count distinct users with successful HTTP responses.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcountif.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize dcountif(id, status == '200')\n```\n\n----------------------------------------\n\nTITLE: Filtering HTTP Logs with Where Operator in SQL and APL\nDESCRIPTION: Comparison between SQL and APL syntax for filtering logs based on HTTP status code. The examples demonstrate how to filter for status code 200 in both query languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM sample_http_logs WHERE status = '200'\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '200'\n```\n\n----------------------------------------\n\nTITLE: Sending Syslog Logs to Axiom with Vector\nDESCRIPTION: A Vector configuration for collecting Syslog messages and forwarding them to Axiom. Configures a TCP listener on port 6514 with a maximum message length of 102,400 bytes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\ntype=\"syslog\"\naddress=\"0.0.0.0:6514\"\nmax_length=102_400\nmode=\"tcp\"\n\n[sinks.axiom]\ntype=\"axiom\"\ninputs = [ \"my_source_id\" ] # required\ndataset=\"DATASET_NAME\" # replace with the name of your Axiom dataset\ntoken=\"API_TOKEN\" # replace with your Axiom API token\n```\n\n----------------------------------------\n\nTITLE: Comparing ipv4_is_match in APL with LIKE in ANSI SQL\nDESCRIPTION: This snippet shows how the ipv4_is_match function in APL can be used to achieve similar functionality to the LIKE operator in ANSI SQL for IP address matching, albeit with more flexibility and efficiency.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-match.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nip LIKE '192.168.1.0'\n```\n\nLANGUAGE: kusto\nCODE:\n```\nipv4_is_match(ip, \"192.168.1.0\")\n```\n\n----------------------------------------\n\nTITLE: Using ipv4_is_match in APL Query\nDESCRIPTION: This example demonstrates how to use the ipv4_is_match function in an APL query to check if two IP addresses match. It extends the result set with a new column 'is_match' containing the result of the comparison.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-match.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend is_match = ipv4_is_match('203.0.113.112', '203.0.113.112')\n```\n\n----------------------------------------\n\nTITLE: Using bin() Function for Value Grouping in APL\nDESCRIPTION: The bin() function rounds values down to an integer multiple of a given bin size. It's commonly used with the summarize operator to group disorderly values into organized fractions based on a specified bin size.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/rounding-functions.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\nbin(value,roundTo)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nbin(25.73, 4) == 24\n```\n\n----------------------------------------\n\nTITLE: Extracting Visited URLs from Apache Logs in Sumo Logic and APL\nDESCRIPTION: Shows how to extract URLs from GET requests in Apache logs. Sumo Logic filters by source category and parses the URL, while APL filters by method and extracts the URL using regex.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache \n| parse \"GET * \" as url\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where method == \"GET\"\n| project url = extract(@\"(\\w+)\", 1, method)\n```\n\n----------------------------------------\n\nTITLE: Updating Django manage.py for OpenTelemetry\nDESCRIPTION: Modified manage.py script to initialize OpenTelemetry before Django application startup, ensuring proper trace capture.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n#!/usr/bin/env python\nimport os\nimport sys\ndef main():\n    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'your_project.settings')\n    from otel_config import configure_opentelemetry\n    configure_opentelemetry()\n    try:\n        from django.core.management import execute_from_command_line\n    except ImportError as exc:\n        raise ImportError(\"Couldn't import Django.\") from exc\n    execute_from_command_line(sys.argv)\nif __name__ == '__main__':\n    main()\n```\n\n----------------------------------------\n\nTITLE: Using Pino Logger with Axiom\nDESCRIPTION: Example of using the configured Pino logger to send log messages to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/pino.mdx#2025-04-22_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nlogger.info('Hello from Pino!');\n```\n\n----------------------------------------\n\nTITLE: Basic Syntax of topk Aggregation in APL\nDESCRIPTION: The fundamental syntax pattern for the topk function in APL, showing required parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/topk.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ntopk(field, k)\n```\n\n----------------------------------------\n\nTITLE: Finding Top Content Types with topk Function\nDESCRIPTION: Shows how to use the topk aggregation function with summarize to find the top 20 content types in HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize topk(content_type, 20)\n```\n\n----------------------------------------\n\nTITLE: Querying Top GitHub Issue Wranglers with Axiom API using cURL\nDESCRIPTION: This cURL command queries the Axiom API to find the top GitHub issue wranglers for CockroachDB repositories. It uses APL (Axiom Processing Language) to filter and analyze the data, excluding bots and specific users.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/query.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/_apl?format=tabular' \\\n-H 'Authorization: Bearer API_TOKEN' \\\n-H 'Accept: application/json' \\\n-H 'Accept-Encoding: gzip' \\\n-H 'Content-Type: application/json' \\\n-d '{\n      \"apl\": \"[\\\"github-issues-event\\\"] | where actor !endswith \\\"[bot]\\\" and repo startswith \\\"cockroachdb/\\\" and actor !~ \\\"cockroach-teamcity\\\" | summarize topk(actor, 5) by bin_auto(_time), action\",\n      \"startTime\": \"2023-08-15T00:00:00Z\",\n      \"endTime\": \"2023-08-22T00:00:00Z\"\n    }'\n```\n\n----------------------------------------\n\nTITLE: Ingesting CSV Data with Axiom API\nDESCRIPTION: Example of sending CSV data to Axiom's ingest API endpoint using curl. Demonstrates sending data with headers and values in comma-separated format.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/ingest.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/DATASET_NAME/ingest' \\\n      -H 'Authorization: Bearer API_TOKEN' \\\n      -H 'Content-Type: text/csv' \\\n      -d 'user, name\n         foo, bar'\n```\n\n----------------------------------------\n\nTITLE: Parsing Kubernetes Logs with Regex Mode - Query\nDESCRIPTION: Kusto query using parse operator in regex mode to extract pod-related fields using regular expressions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_14\n\nLANGUAGE: kusto\nCODE:\n```\n['PodLogs']\n| parse kind=regex AppName with @\"Log: PodStatusUpdate \\(podName=\" podName: string @\", namespace=\" namespace: string @\", phase=\" phase: string @\", startTime=\" startTime: datetime @\", nodeName=\" nodeName: string @\", hostIP=\" hostIP: string @\", podIP=\" podIP: string @\"\\)\"\n| project podName, namespace, phase, startTime, nodeName, hostIP, podIP\n```\n\n----------------------------------------\n\nTITLE: Creating Test Controller for Axiom Logger\nDESCRIPTION: Implements a TestController with a logTest method that demonstrates various log levels and custom processors for sending test messages to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-laravel.mdx#2025-04-22_snippet_6\n\nLANGUAGE: php\nCODE:\n```\n<?php\n\nnamespace App\\Http\\Controllers;\n\nuse Illuminate\\Http\\Request;\nuse Illuminate\\Support\\Facades\\Log;\nuse Monolog\\Logger;\n\nclass TestController extends Controller\n{\n    public function logTest()\n    {\n\n        $customProcessor = function ($record) {\n\n            $record['extra']['customData'] = 'Additional info';\n\n            $record['extra']['userId'] = auth()->check() ? auth()->user()->id : 'guest';\n\n            return $record;\n        };\n\n        // Get the Monolog instance for the 'axiom' channel and push the custom processor\n        $logger = Log::channel('axiom')->getLogger();\n        if ($logger instanceof Logger) {\n            $logger->pushProcessor($customProcessor);\n        }\n\n        Log::channel('axiom')->debug(\"Checking details.\", ['action' => 'detailCheck', 'status' => 'initiated']);\n        Log::channel('axiom')->info(\"User logged in.\", ['user_id' => 'exampleUserId', 'method' => 'standardLogin']);\n        Log::channel('axiom')->info(\"User tried a feature.\", ['feature' => 'experimentalFeatureX', 'status' => 'trial']);\n        Log::channel('axiom')->warning(\"Feature might not work as expected.\", ['feature' => 'experimentalFeature', 'warning' => 'betaStage']);\n        Log::channel('axiom')->warning(\"Feature failed to load.\", ['feature' => 'featureY', 'error_code' => 500]);\n        Log::channel('axiom')->error(\"Major issue with the app.\", ['system' => 'paymentProcessing', 'error' => 'serviceUnavailable']);\n        Log::channel('axiom')->warning(\"Immediate action needed.\", ['issue' => 'security', 'level' => 'high']);\n        Log::channel('axiom')->error(\"The app is down.\", ['system' => 'entireApplication', 'status' => 'offline']);\n\n        return 'Log messages sent to Axiom';\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Concatenating Arrays in Splunk SPL and APL\nDESCRIPTION: Demonstrates the difference between Splunk's mvappend function and APL's array_concat function for concatenating arrays.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-concat.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval combined_array = mvappend(array1, array2, array3)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| extend combined_array = array_concat(array1, array2, array3)\n```\n\n----------------------------------------\n\nTITLE: Grouping Geolocation Information from IPv4 Address\nDESCRIPTION: Example showing how to group and count data based on geolocation attributes like state, city, latitude, and longitude extracted from an IPv4 address.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip_location = geo_info_from_ip_address('20.53.203.50')\n| summarize Count=count() by ip_location.state, ip_location.city, ip_location.latitude, ip_location.longitude\n```\n\n----------------------------------------\n\nTITLE: Grouping Geolocation Information from IPv6 Address\nDESCRIPTION: Example showing how to group and count data based on geolocation attributes like state, city, latitude, and longitude extracted from an IPv6 address.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_12\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip_location = geo_info_from_ip_address('2a03:2880:f12c:83:face:b00c::25de')\n| summarize Count=count() by ip_location.state, ip_location.city, ip_location.latitude, ip_location.longitude\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with Union and Filtering in APL\nDESCRIPTION: This query combines HTTP logs and security logs, then filters for entries with a status code of 500.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| union ['security-logs']\n| where status == '500'\n```\n\n----------------------------------------\n\nTITLE: Field-Specific Search in APL\nDESCRIPTION: Searches for \"GET\" in the method field OR \"Mozilla\" in the user_agent field, showing how to target specific fields rather than searching across all fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search method:\"GET\" or user_agent :\"Mozilla\"\n```\n\n----------------------------------------\n\nTITLE: Deleting Data Blocks with Axiom API\nDESCRIPTION: This curl command demonstrates how to make a POST request to the Axiom API to delete data blocks. It includes the necessary headers for authentication and content type, as well as a JSON payload specifying the APL query, time range, and commit flag.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/delete-blocks.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v2/datasets/_apl/delete' \\\n-H 'Authorization: Bearer API_TOKEN' \\\n-H 'Content-Type: application/json' \\\n-d  '{\n  \"apl\": \"[\\\"otel-demo-traces\\\"] | where trace_id == \\\"b630e23cfc3a6ac9e57fee13542b3e50\\\"\",\n  \"startTime\": \"now-6h\",\n  \"endTime\": \"now\",\n  \"commit\": false\n  }'\n```\n\n----------------------------------------\n\nTITLE: Retrieving Distinct Actions from Axiom Audit Log in Kusto\nDESCRIPTION: This query retrieves all distinct actions that have occurred in the Axiom organization by querying the axiom-audit dataset and using the distinct operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/audit-log.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['axiom-audit']\n| distinct action\n```\n\n----------------------------------------\n\nTITLE: Sorting HTTP Logs by Request Duration\nDESCRIPTION: This query demonstrates sorting HTTP logs by request duration in descending order to prioritize the longest requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/order-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| order by req_duration_ms desc\n```\n\n----------------------------------------\n\nTITLE: Converting SQL AVG to APL\nDESCRIPTION: Demonstrates how to translate a SQL AVG query to APL using the 'summarize' operator with the 'avg()' function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT AVG(req_duration_ms) AS AverageRequest\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize AverageRequest = avg(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Log Analysis Sort Example\nDESCRIPTION: Sorting HTTP logs by request duration and status code to identify slow requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sort-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| sort by req_duration_ms desc, status asc\n```\n\n----------------------------------------\n\nTITLE: Union with Post-Filtering in APL\nDESCRIPTION: This example combines datasets and then filters the data to only include rows where the 'method' is 'GET'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| union ['github-issues-event']\n| where method == \"GET\"\n```\n\n----------------------------------------\n\nTITLE: Basic Summarize Operator Syntax in APL\nDESCRIPTION: Shows the general syntax for the summarize operator in APL, which allows you to perform data aggregation with optional field naming, aggregation functions, and grouping expressions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| summarize [[Field1 =] AggregationFunction [, ...]] [by [Field2 =] GroupExpression [, ...]]\n```\n\n----------------------------------------\n\nTITLE: Concatenating Array Elements in Splunk SPL vs APL\nDESCRIPTION: Demonstrates the difference between concatenating array elements in Splunk SPL and APL. In Splunk, mvjoin() is used, while APL uses strcat_array() for simplicity.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/strcat-array.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval concatenated=mvjoin(array_field, \", \")\n```\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| extend concatenated = strcat_array(array_field, ', ')\n```\n\n----------------------------------------\n\nTITLE: Finding Logs from a Specific City\nDESCRIPTION: This query uses a regex to find logs where the 'geo.city' field exactly matches 'Camaquã'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_15\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where tostring(['geo.city']) matches regex \"^Camaquã$\"\n```\n\n----------------------------------------\n\nTITLE: Laravel Log Level Examples\nDESCRIPTION: Example code showing how to use different log levels in Laravel\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-laravel.mdx#2025-04-22_snippet_3\n\nLANGUAGE: php\nCODE:\n```\nuse Illuminate\\Support\\Facades\\Log;\n\nLog::debug(\"Checking details.\");\nLog::info(\"User logged in.\");\nLog::notice(\"User tried a feature.\");\nLog::warning(\"Feature might not work as expected.\");\nLog::error(\"Feature failed to load.\");\nLog::critical(\"Major issue with the app.\");\nLog::alert(\"Immediate action needed.\");\nLog::emergency(\"The app is down.\");\n```\n\n----------------------------------------\n\nTITLE: Converting Dynamic to JSON in APL\nDESCRIPTION: The dynamic_to_json() function converts a scalar value of type dynamic to a canonical string representation. It handles various input types including scalars, arrays, and property bags.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\ndynamic_to_json(Expr)\n```\n\n----------------------------------------\n\nTITLE: Using 'where * has' with Aggregations in APL\nDESCRIPTION: Example of using the '* has' pattern with aggregation functions. This query finds the average request duration for events where any field contains 'Japan'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where * has \"Japan\"\n| summarize avg(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Implementing Web Vitals Component in Root Layout\nDESCRIPTION: Integration of Web Vitals tracking component in the Next.js root layout.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_16\n\nLANGUAGE: tsx\nCODE:\n```\nimport { WebVitals } from \"@/lib/axiom/client\";\n\nexport default function RootLayout({\n  children,\n}: Readonly<{\n  children: React.ReactNode;\n}>) {\n  return (\n    <html lang=\"en\">\n      <WebVitals />\n      <body>{children}</body>\n    </html>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Global Term Search Example in APL\nDESCRIPTION: Demonstrates searching for the term \"image\" across all fields in the sample-http-logs dataset, returning all records containing this term.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search \"image\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Project File for OpenTelemetry in .NET\nDESCRIPTION: This snippet shows the content of the dotnet.csproj file, which defines the project's settings, target framework, and package references for OpenTelemetry integration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\n<Project Sdk=\"Microsoft.NET.Sdk.Web\">\n\n  <PropertyGroup>\n    <TargetFramework>net6.0</TargetFramework>\n    <Nullable>enable</Nullable>\n    <ImplicitUsings>enable</ImplicitUsings>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <PackageReference Include=\"OpenTelemetry\" Version=\"1.7.0\" />\n    <PackageReference Include=\"OpenTelemetry.Exporter.Console\" Version=\"1.7.0\" />\n    <PackageReference Include=\"OpenTelemetry.Exporter.OpenTelemetryProtocol\" Version=\"1.7.0\" />\n    <PackageReference Include=\"OpenTelemetry.Extensions.Hosting\" Version=\"1.7.0\" />\n    <PackageReference Include=\"OpenTelemetry.Instrumentation.AspNetCore\" Version=\"1.7.1\" />\n    <PackageReference Include=\"OpenTelemetry.Instrumentation.Http\" Version=\"1.6.0-rc.1\" />\n\n  </ItemGroup>\n\n</Project>\n```\n\n----------------------------------------\n\nTITLE: Case-Insensitive Search in SQL and APL\nDESCRIPTION: Demonstrates how to perform case-insensitive text searches. SQL uses LOWER() with LIKE while APL uses tolower() with contains to find 'GET' methods regardless of case.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nSELECT Status, Method\nFROM \"Sample-http-logs\"\nWHERE LOWER(Method) LIKE 'get'';\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where tolower(method) contains 'GET'\n| project status, method\n```\n\n----------------------------------------\n\nTITLE: Advanced Regex Replacement in APL\nDESCRIPTION: The replace_regex function provides more advanced regex replacement capabilities, including support for backreferences using the $ sign to refer to captured groups.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_16\n\nLANGUAGE: kusto\nCODE:\n```\nreplace_regex(@'^logging', 'axiom', 'logging-data')\n```\n\nLANGUAGE: kusto\nCODE:\n```\nreplace_regex(regex, rewrite, text)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend replaced = replace_regex(@'^logging', 'axiom', 'logging-data')\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project backreferences = replace_regex(@'observability=(.+)', 'axiom=$1', creator)\n```\n\n----------------------------------------\n\nTITLE: Decoding URLs with url_decode Function in Kusto\nDESCRIPTION: Shows how to use the url_decode function to convert an encoded URL into its regular representation. It takes an encoded URL string as an argument.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_33\n\nLANGUAGE: kusto\nCODE:\n```\nurl_decode(encoded url)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project decoded_link = url_decode( \"https://www.axiom.co/\" )\n```\n\n----------------------------------------\n\nTITLE: Converting SQL to APL extend for Field Creation\nDESCRIPTION: Comparison between ANSI SQL's SELECT with expressions and the equivalent extend operation in APL. Both create a new field derived from an existing field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, req_duration_ms, req_duration_ms * 1000 AS newField FROM logs;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend newField = req_duration_ms * 1000\n```\n\n----------------------------------------\n\nTITLE: Splitting Strings in APL\nDESCRIPTION: The split function splits a given string according to a specified delimiter and returns a string array with the resulting substrings. It can optionally return a specific substring if it exists.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_19\n\nLANGUAGE: kusto\nCODE:\n```\nsplit(source, delimiter)\n```\n\n----------------------------------------\n\nTITLE: Using hash_md5() Function in APL\nDESCRIPTION: The hash_md5() function returns an MD5 hash value for the input value encoded as a hex string. The example shows how to apply the function to content_type field from sample-http-logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/hash-functions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nhash_md5(source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project md5_hash_value = hash_md5(content_type)\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"md5_hash_value\": \"b980a9c041dbd33d5893fad65d33284b\"\n}\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL SELECT with APL project-away Operator\nDESCRIPTION: A comparison between SQL's SELECT statement and APL's project-away operator, highlighting how project-away offers a more concise approach when you want to keep many fields but remove a few.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-away-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT _time, req_duration_ms, id, geo.city, geo.country\nFROM sample_http_logs;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| project-away status, uri, method\n```\n\n----------------------------------------\n\nTITLE: Analyzing Span Durations by Service in OpenTelemetry Traces\nDESCRIPTION: This query uses percentiles_array to calculate the 50th, 90th, and 99th percentiles of span durations for each service in an OpenTelemetry trace dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-array.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize percentiles_array(duration, 50, 90, 99) by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Anonymization\nDESCRIPTION: Example showing how to anonymize Kubernetes node names in OpenTelemetry traces using hash-based redaction.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/redact-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| redact replaceHash=true @'.*' on ['resource.k8s.node.name']\n```\n\n----------------------------------------\n\nTITLE: JSON Parsing Query Optimization\nDESCRIPTION: Shows how to query nested data using map fields instead of parse_json() for better performance.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/performance.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| where data_map.someKey == \"someValue\"\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Value using max in APL (SQL Equivalent)\nDESCRIPTION: This snippet demonstrates how to use the max function in APL to find the maximum value of a column. It's equivalent to the ANSI SQL example and shows APL's structured approach.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/max.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize max(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Summarizing HTTP Logs Count by Time Bins\nDESCRIPTION: This query summarizes the count of HTTP log events grouped by automatically determined time bins.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple Substrings with 'where * has' in APL\nDESCRIPTION: Example of using the '* has' pattern with logical operators to find events where any field contains one of multiple substrings ('GET' or 'text').\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| where * has \"GET\" or * has \"text\"\n```\n\n----------------------------------------\n\nTITLE: NLog Project Configuration in XML\nDESCRIPTION: Project file configuration for NLog implementation including required package references.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_13\n\nLANGUAGE: xml\nCODE:\n```\n<Project Sdk=\"Microsoft.NET.Sdk\">\n\n  <PropertyGroup>\n    <OutputType>Exe</OutputType>\n    <TargetFramework>net6.0</TargetFramework>\n    <ImplicitUsings>enable</ImplicitUsings>\n    <Nullable>enable</Nullable>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <PackageReference Include=\"NLog\" Version=\"4.7.12\" />\n    <PackageReference Include=\"NLog.Web.AspNetCore\" Version=\"4.9.3\" />\n    <PackageReference Include=\"NLog.Targets.Http\" Version=\"1.0.4\" />\n  </ItemGroup>\n\n</Project>\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL and APL percentile functions\nDESCRIPTION: Examples comparing ANSI SQL's PERCENTILE_CONT function with APL's percentile function, both calculating the 95th percentile.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentile.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY req_duration_ms) FROM sample_http_logs;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentile(req_duration_ms, 95)\n```\n\n----------------------------------------\n\nTITLE: Equivalent varianceif Implementation in APL for SQL Users\nDESCRIPTION: The APL equivalent of the SQL query, demonstrating how varianceif simplifies conditional variance calculation by combining condition and aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/varianceif.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize varianceif(req_duration_ms, status == '200')\n```\n\n----------------------------------------\n\nTITLE: Using varianceif with OpenTelemetry Trace Data\nDESCRIPTION: Example showing how to calculate variance in span durations specifically for a frontend service in OpenTelemetry trace data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/varianceif.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize varianceif(duration, ['service.name'] == 'frontend')\n```\n\n----------------------------------------\n\nTITLE: Comparing ipv4_is_match in APL with cidrmatch in Splunk SPL\nDESCRIPTION: This snippet demonstrates the similarity between the ipv4_is_match function in APL and the cidrmatch function in Splunk SPL. Both functions check if an IP address falls within a specified CIDR range.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-match.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncidrmatch(\"192.168.1.0/24\", ip)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nipv4_is_match(ip, \"192.168.1.0/24\")\n```\n\n----------------------------------------\n\nTITLE: Sampling Error Logs for Security Analysis in APL\nDESCRIPTION: Example of filtering HTTP logs for 500-level errors and then sampling 3% of the results to quickly spot and investigate potential security issues.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sample-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '500'\n| sample 0.03\n```\n\n----------------------------------------\n\nTITLE: Status Code Analysis with Time Buckets in Sumo Logic and APL\nDESCRIPTION: Queries that analyze status codes across multiple time buckets. Sumo Logic uses 5 evenly distributed buckets, while APL uses fixed 12-minute time bins for CSS content, with additional string parsing.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache*\n| parse \"HTTP/1.1\\\" * * \\\"\" as (status_code, size)\n| timeslice 5 buckets\n| count by _timeslice, status_code\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where content_type startswith 'text/css'\n| extend p=(\"HTTP/1.1\\\" * * \\\"\"), tostring( is_tls)\n| extend status_code= status\n| summarize count() by bin(_time, 12m), status_code\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Service Definition\nDESCRIPTION: Docker Compose configuration for running Fluent Bit as a container. Includes volume mounts for configuration and container logs, plus environment variables.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluent-bit.mdx#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nversion: '3'\n\nservices:\n  fluentbit:\n    image: fluent/fluent-bit:latest\n    container_name: fluent-bit\n    user: root # Required for accessing host log files\n    volumes:\n      - ./fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro\n      - /var/lib/docker/containers:/opt/docker-container-logs:ro\n    environment:\n      - AXIOM_HOSTNAME=axiom\n```\n\n----------------------------------------\n\nTITLE: Reordering Security Log Fields in APL\nDESCRIPTION: An example that reorders fields in a security log to prioritize key fields for investigating HTTP request anomalies. This query reorders fields to focus on HTTP status, request method, and URI for security analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project-reorder _time, status, method, uri, id, ['geo.city'], ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Span Duration by Service in APL\nDESCRIPTION: This query calculates the average span duration for each service to analyze performance across services using OpenTelemetry traces data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avg.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize avg(duration) by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Calculating 99th percentile of request durations for error responses\nDESCRIPTION: APL query example that filters for HTTP 500 status codes and calculates the 99th percentile of request durations, helping to identify outliers in error responses.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentile.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '500'\n| summarize percentile(req_duration_ms, 99)\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Collector Configuration\nDESCRIPTION: YAML configuration for the OpenTelemetry collector defining OTLP receivers and exporters for sending telemetry data to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-lambda-dot.mdx#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n      http:\n\nexporters:\n  otlphttp:\n    compression: gzip\n    endpoint: https://api.axiom.co\n    headers:\n      authorization: Bearer API_TOKEN\n      x-axiom-dataset: DATASET_NAME\n\nservice:\n  pipelines:\n    logs:\n      receivers: [otlp]\n      exporters: [otlphttp]\n    traces:\n      receivers: [otlp]\n      exporters: [otlphttp]\n```\n\n----------------------------------------\n\nTITLE: Default Custom Webhook Template JSON\nDESCRIPTION: Default template structure for Axiom custom webhook notifications showing all available variables and their format.\nSOURCE: https://github.com/axiomhq/docs/blob/main/monitor-data/custom-webhook-notifier.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"action\": \"{{.Action}}\",\n  \"event\": {\n    \"monitorID\": \"{{.MonitorID}}\",\n    \"body\": \"{{.Body}}\",\n    \"description\": \"{{.Description}}\",\n    \"queryEndTime\": \"{{.QueryEndTime}}\",\n    \"queryStartTime\": \"{{.QueryStartTime}}\",\n    \"timestamp\": \"{{.Timestamp}}\",\n    \"title\": \"{{.Title}}\",\n    \"value\": {{.Value}},\n    \"matchedEvent\": {{jsonObject .MatchedEvent}},\n    \"groupKeys\": {{jsonArray .GroupKeys}},\n    \"groupValues\": {{jsonArray .GroupValues}}\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Splunk Rex Command to APL Parse\nDESCRIPTION: Demonstrates how to convert a Splunk rex command to APL parse operator for extracting duration from logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: splunk\nCODE:\n```\nindex=web_logs | rex field=_raw \"duration=(?<duration>\\d+)\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| parse uri with * \"duration=\" req_duration_ms:int\n```\n\n----------------------------------------\n\nTITLE: Checking Private IP Status with ipv4_is_private in APL\nDESCRIPTION: This snippet demonstrates how to use the ipv4_is_private function in APL to determine if an IP address is private. It extends the 'sample-http-logs' dataset with a new column indicating the private status of each client IP.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-private.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend is_private=ipv4_is_private(client_ip)\n```\n\n----------------------------------------\n\nTITLE: Using has_any_ipv4 Function in APL\nDESCRIPTION: This snippet demonstrates the syntax of the has_any_ipv4 function in APL. It shows how to use the function to check if a column contains any IPv4 addresses from a given set of addresses or CIDR ranges.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-any-ipv4.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nhas_any_ipv4(column, ip_list)\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL Stats Command with APL Summarize\nDESCRIPTION: Demonstrates how Splunk SPL's stats command maps to APL's summarize operator for grouping data and applying aggregation functions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nindex=\"sample-http-logs\" | stats count by method\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by method\n```\n\n----------------------------------------\n\nTITLE: Analyzing Request Durations by HTTP Method in APL\nDESCRIPTION: This query uses percentiles_array to calculate the 25th, 50th, and 95th percentiles of request durations for each HTTP method in a sample log dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-array.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentiles_array(req_duration_ms, 25, 50, 95) by method\n```\n\n----------------------------------------\n\nTITLE: Filtering Weekend Days in APL\nDESCRIPTION: This APL query extends the sample-http-logs dataset with the day of the week and filters for Saturday (0) and Sunday (1) using the where operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_21\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend day_of_week = dayofweek(_time)\n| where day_of_week == 1 or day_of_week == 0\n```\n\n----------------------------------------\n\nTITLE: Finding HTTP Status Code Position in Log Analysis\nDESCRIPTION: A query that demonstrates using array_index_of to find the position of a specific HTTP status code within an array of codes in log analysis. The query summarizes status codes into an array and then locates the position of code 500.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-index-of.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| take 50\n| summarize status_array = make_list(status)\n| extend index_500 = array_index_of(status_array, '500')\n```\n\n----------------------------------------\n\nTITLE: Calculated Fields in Splunk SPL and APL\nDESCRIPTION: Shows how to create calculated fields in Splunk SPL using the 'eval' command and in APL using the 'extend' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nsearch index=\"myIndex\" \n| eval newField=field1+field2\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['myDataset'] \n| extend newField = field1 + field2\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Analysis with percentileif\nDESCRIPTION: Demonstrates using percentileif to calculate the 95th percentile of span durations for server spans in a specific service.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentileif.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize percentileif(duration, 95, ['service.name'] == 'frontend' and kind == 'server')\n```\n\n----------------------------------------\n\nTITLE: Implementing Drop Filter in Logstash\nDESCRIPTION: Configuration demonstrating the Drop filter plugin usage to exclude specific events based on conditions. This example drops debug severity syslog events.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/logstash.mdx#2025-04-22_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\ninput {\n  syslog {\n    port => 5140\n    type => syslog\n  }\n}\n\nfilter {\n  if [type] == \"syslog\" and [severity] == \"debug\" {\n    drop { }\n  }\n}\n\noutput{\n  opensearch{\n    hosts => [\"https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic\"]\n    user => \"axiom\"\n    password => \"API_TOKEN\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis with project-keep in APL\nDESCRIPTION: Example of using project-keep for security log analysis by extracting essential fields like timestamp, user ID, HTTP status, URI, and geographical information.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-keep-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| project-keep _time, id, status, uri, ['geo.city'], ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Traces Analysis using make_list_if in APL\nDESCRIPTION: This example shows how to use make_list_if for analyzing OpenTelemetry traces in APL. It aggregates span durations for successful requests to the cartservice, grouped by trace_id.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list-if.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize make_list_if(duration, status_code == '200' and ['service.name'] == 'cartservice') by trace_id\n```\n\n----------------------------------------\n\nTITLE: Limiting Results in SQL vs APL\nDESCRIPTION: Comparison between ANSI SQL's LIMIT clause and APL's limit operator, demonstrating how to restrict results to the top 10 rows in both query languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/limit-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM sample_http_logs LIMIT 10;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| limit 10\n```\n\n----------------------------------------\n\nTITLE: Using Basic Arithmetic Operators in APL\nDESCRIPTION: Examples of basic arithmetic operations like addition, subtraction, multiplication, and division between numerical values and time units in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-operators/numerical-operators.mdx#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`3.19 + 3.19`, `ago(10m) + 10m`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`0.26 - 0.23`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`1s * 5`, `5 * 5`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`10m / 1s`, `4 / 2`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`10 % 3`, `5 % 2`\n```\n\n----------------------------------------\n\nTITLE: Example Usage of array_select_dict in APL\nDESCRIPTION: This snippet demonstrates a practical use case of the array_select_dict function in APL. It extracts a dictionary from an array where the 'service.name' key has the value 'frontend'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-select-dict.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend array = dynamic([{\"service.name\": \"frontend\", \"status_code\": \"200\"}, {\"service.name\": \"backend\", \"status_code\": \"500\"}])\n| project selected = array_select_dict(array, \"service.name\", \"frontend\")\n```\n\n----------------------------------------\n\nTITLE: Ensuring Field Existence in APL\nDESCRIPTION: The ensure_field() function checks for the existence of a field and returns its value or a typed nil if it doesn't exist. It takes a field name and field type as arguments.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nensure_field(field_name, field_type)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend show_field = ensure_field(\"myfield\", typeof(string))\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend newstatus = ensure_field(\"status\", typeof(string))\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend new_field = ensure_field(\"upcoming_field\", typeof(int))\n| where new_field > 100\n```\n\n----------------------------------------\n\nTITLE: Finding Top Repositories with Time Binning\nDESCRIPTION: Demonstrates using topk with summarize to find top repositories in each 24-hour time bin from GitHub push events.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['github-push-event']\n| summarize topk(repo, 20) by bin(_time, 24h)\n```\n\n----------------------------------------\n\nTITLE: Querying Custom Attributes in Axiom Processing Language\nDESCRIPTION: Demonstrates how to query nested custom attributes under the attributes.custom field using APL. This example filters traces where a specific custom attribute is true.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/traces.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces'] \n| where ['attributes.custom']['app.synthetic_request'] == true\n```\n\n----------------------------------------\n\nTITLE: Project with Mixed Field Selection and Expressions in APL\nDESCRIPTION: Demonstrates how to use the project operator with a combination of direct field selections and expressions that can transform the data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| project [FieldName, FieldName[,] = Expression [, ...]\n```\n\n----------------------------------------\n\nTITLE: Filtering Combined Datasets with Union in APL\nDESCRIPTION: Demonstrates how to combine two datasets using union and filter the results based on content_type containing 'a' and city being 'Seattle'. The query joins sample-http-logs with github-pull-request-event data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| union ['github-pull-request-event']\n| where content_type contains \"a\" and ['geo.city']  == \"Seattle\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Rate in SQL vs APL\nDESCRIPTION: Comparison between ANSI SQL and APL for calculating rate of response body size bytes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/rate.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT resp_body_size_bytes, COUNT(*) / TIMESTAMPDIFF(SECOND, MIN(_time), MAX(_time)) AS rate\nFROM http_logs;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize rate(resp_body_size_bytes) by bin(_time, 1s)\n```\n\n----------------------------------------\n\nTITLE: Concatenating Array Elements in ANSI SQL vs APL\nDESCRIPTION: Compares the concatenation of array elements in ANSI SQL using STRING_AGG() with APL's strcat_array(). APL's approach is more direct for array inputs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/strcat-array.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT STRING_AGG(column_name, ', ') AS concatenated FROM table;\n```\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| summarize concatenated = strcat_array(column_name, ', ')\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple Filters in APL Query for Axiom Chart\nDESCRIPTION: This APL query demonstrates how to combine select filters for country and city with a search filter for user_agent. It uses query parameters and handles empty filter values to create a flexible, multi-filtered chart.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/filters.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\ndeclare query_parameters (country_filter:string = \"\",\n                          city_filter:string = \"\",\n                          user_agent_filter:string = \"\");\n['sample-http-logs']\n| where isempty(country_filter) or ['geo.country'] == country_filter\n| where isempty(city_filter) or ['geo.city'] == city_filter\n| where isempty(user_agent_filter) or user_agent contains user_agent_filter\n| summarize count() by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Client\nDESCRIPTION: Example of configuring the Axiom client using a personal token.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/go.mdx#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nclient, err := axiom.NewClient(\n    axiom.SetPersonalTokenConfig(\"AXIOM_TOKEN\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Basic Usage Example of geo_info_from_ip_address\nDESCRIPTION: A simple example showing how to use geo_info_from_ip_address to analyze web log traffic by extending the dataset with geographic information for a specific IP address.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend geo_info = geo_info_from_ip_address('172.217.22.14')\n```\n\n----------------------------------------\n\nTITLE: Single Index Array Splitting in APL\nDESCRIPTION: Demonstrates using array_split with a single index to divide an events array into two parts at index 2, useful for breaking large event arrays into manageable chunks for analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-split.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| where array_length(events) == 3\n| extend split_events = array_split(events, 2)\n```\n\n----------------------------------------\n\nTITLE: Counting Client Service Requests in OpenTelemetry Traces\nDESCRIPTION: An example that counts how many requests were initiated by the client service kind in OpenTelemetry traces data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/countif.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize countif(kind == 'client')\n```\n\n----------------------------------------\n\nTITLE: Using abs() Function in Kusto\nDESCRIPTION: Examples of using the abs() function to calculate absolute values. The function takes a numeric input and returns its absolute value, demonstrating its usage with literals and in a query against sample-http-logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nabs(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nabs(80.5) == 80.5\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project absolute_value = abs(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Multiple Aggregation Functions in SQL and APL\nDESCRIPTION: Demonstrates how to perform multiple aggregations (count, sum, average) in a single query using both SQL and APL. The example calculates total count, sum of request duration, and average duration from sample HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(*) AS TotalDuration, SUM(req_duration_ms) AS TotalDuration, AVG(Price) AS AverageDuration\nFROM  [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize TotalOrders = count(), TotalDuration = sum( req_duration_ms), AverageDuration = avg(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Analyzing OpenTelemetry Traces with min Function\nDESCRIPTION: Example of using min function to analyze OpenTelemetry trace data for minimum span duration by service.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/min.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize min(duration) by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Calculating Standard Deviation of Span Durations for Frontend Service in OpenTelemetry Traces\nDESCRIPTION: Uses stdevif to calculate the standard deviation of span durations specifically for traces from the frontend service, grouped by span kind. This shows how to apply conditional standard deviation in trace analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdevif.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize stdevif(duration, ['service.name'] == \"frontend\") by kind\n```\n\n----------------------------------------\n\nTITLE: Installing ASP.NET Core OpenTelemetry Instrumentation Package\nDESCRIPTION: NuGet package reference for adding OpenTelemetry instrumentation to ASP.NET Core applications. This package automatically collects telemetry data about incoming HTTP requests and responses.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_8\n\nLANGUAGE: xml\nCODE:\n```\n<PackageReference Include=\"OpenTelemetry.Instrumentation.AspNetCore\" Version=\"1.7.1\" />\n```\n\n----------------------------------------\n\nTITLE: Finding Longest Span Duration in OpenTelemetry Traces using APL\nDESCRIPTION: This query uses the max function in APL to find the longest span duration from the 'duration' field in OpenTelemetry traces. It helps identify performance bottlenecks in distributed services.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/max.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize max(duration)\n```\n\n----------------------------------------\n\nTITLE: Creating an Axiom Dataset with Terraform\nDESCRIPTION: This snippet demonstrates how to create a dataset in Axiom using Terraform. It specifies the dataset name and description.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_1\n\nLANGUAGE: hcl\nCODE:\n```\nresource \"axiom_dataset\" \"test_dataset\" {\n  name = \"test_dataset\"\n  description = \"This is a test dataset created by Terraform.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using make_set in Splunk SPL vs APL\nDESCRIPTION: Comparison between Splunk SPL's values function and APL's make_set function for collecting unique values from a column grouped by ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats values(method) by id\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize make_set(method) by id\n```\n\n----------------------------------------\n\nTITLE: Sampling Data with Splunk SPL vs APL\nDESCRIPTION: Comparison of sampling in Splunk SPL and APL, showing how to retrieve a random subset of data rows in both query languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sample-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| sample 10\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| sample 0.1\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL arg_max Usage\nDESCRIPTION: Shows how to translate Splunk SPL max statistics to APL's arg_max aggregation for finding maximum values with associated fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-max.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats max(req_duration_ms) as max_duration by id, uri\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize arg_max(req_duration_ms, id, uri)\n```\n\n----------------------------------------\n\nTITLE: Comparing maxif in APL with Splunk SPL\nDESCRIPTION: This snippet demonstrates how to use the maxif function in APL compared to a similar operation in Splunk SPL. It shows finding the maximum request duration for successful HTTP requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/maxif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: splunk\nCODE:\n```\n| stats max(req_duration_ms) as max_duration where status=\"200\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize maxif(req_duration_ms, status == \"200\")\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with percentileif for HTTP Method Comparison\nDESCRIPTION: Shows how to use percentileif to compare request durations between different HTTP methods (POST vs GET) over time intervals.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentileif.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize post_p90 = percentileif(req_duration_ms, 90, method == \"POST\"), get_p90 = percentileif(req_duration_ms, 90, method == \"GET\") by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Counting Events in Splunk vs APL\nDESCRIPTION: Comparison between Splunk SPL and APL syntax for counting events in a dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/count-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: splunk\nCODE:\n```\nindex=web_logs\n| stats count\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| count\n```\n\n----------------------------------------\n\nTITLE: Formatting JSON Data for Elastic Bulk API\nDESCRIPTION: Example of how to format JSON data for the Elastic Bulk API, including the required '@timestamp' field instead of '_time'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elasticsearch-bulk-api.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"index\": {\"_index\": \"myindex\", \"_id\": \"1\"}}\n{\"@timestamp\": \"2024-01-07T12:00:00Z\", \"message\": \"axiom elastic bulk\", \"severity\": \"INFO\"}\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Analysis with project-away in APL\nDESCRIPTION: Using project-away when analyzing OpenTelemetry traces to remove fields that aren't necessary for specific trace evaluations, such as span IDs and statuses.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-away-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| project-away span_id, status_code\n```\n\n----------------------------------------\n\nTITLE: Concatenating HTTP Log Data in APL\nDESCRIPTION: Uses array_concat to merge URI and method information from HTTP logs into a single array for analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-concat.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| take 50\n| summarize combined_requests = array_concat(pack_array(uri), pack_array(method))\n```\n\n----------------------------------------\n\nTITLE: ID Field Parsing\nDESCRIPTION: Demonstrates parsing composite ID field into region, tenant, and userId components.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| parse id with region '-' tenant '-' userId\n| project region, tenant, userId\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL ORDER BY to APL order\nDESCRIPTION: This example compares the SQL 'ORDER BY' clause with the APL 'order' operator for sorting by timestamp in descending order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/order-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM logs ORDER BY _time DESC;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| order by _time desc\n```\n\n----------------------------------------\n\nTITLE: SQL vs APL IP Range Check Comparison\nDESCRIPTION: Comparison between SQL's BETWEEN clause and APL's ipv4_is_in_range function for checking IP ranges.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-in-range.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CASE\n    WHEN ip_address BETWEEN '192.168.0.0' AND '192.168.0.255' THEN 1\n    ELSE 0\nEND AS in_range\nFROM logs\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend in_range = ipv4_is_in_range(ip_address, '192.168.0.0/24')\n```\n\n----------------------------------------\n\nTITLE: Finding Slowest HTTP Paths by Method\nDESCRIPTION: Example query showing how to find the slowest path for each HTTP method using arg_max.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-max.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize arg_max(req_duration_ms, uri) by method\n```\n\n----------------------------------------\n\nTITLE: Filtering Geolocation Information from IPv6 Address\nDESCRIPTION: Example demonstrating how to filter data based on geolocation attributes obtained from an IPv6 address, such as country, country ISO code, and state.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip_location = geo_info_from_ip_address('2a03:2880:f12c:83:face:b00c::25de')\n| where ip_location.country == \"United States\" and ip_location.country_iso == \"US\" and ip_location.state == \"Florida\"\n```\n\n----------------------------------------\n\nTITLE: Using array_select_dict in APL (SQL Equivalent)\nDESCRIPTION: This snippet shows the APL equivalent of filtering a JSON array using the array_select_dict function. It selects a dictionary from an array where the 'key' has a value of 5.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-select-dict.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n| project selected = array_select_dict(array_column, \"key\", 5)\n```\n\n----------------------------------------\n\nTITLE: Practical Example of array_shift_right in APL\nDESCRIPTION: A query demonstrating how to use array_shift_right to reorganize span events in telemetry data for visualization or debugging.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-right.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| take 50\n| extend shifted_events = array_shift_right(events, 1)\n```\n\n----------------------------------------\n\nTITLE: Analyzing OpenTelemetry Traces with topk in APL\nDESCRIPTION: Query that finds the top five HTTP status codes by service name in OpenTelemetry trace data using topk aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/topk.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize topk(['attributes.http.status_code'], 5) by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Filtering Spans from Trace Data in APL\nDESCRIPTION: This query demonstrates how to use array_slice to filter spans from trace data, analyzing a specific range of events in OpenTelemetry logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-slice.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| where array_length(events) > 4\n| extend sliced_events = array_slice(events, -3, -1)\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Analysis\nDESCRIPTION: Example query calculating average span duration for traces with HTTP 500 status grouped by service name.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avgif.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces'] \n| summarize avgif(duration, status == \"500\") by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Retrieving Distinct Values in Splunk SPL\nDESCRIPTION: This snippet demonstrates how to use the dedup command in Splunk SPL to retrieve distinct values from web logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/distinct-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: splunk\nCODE:\n```\nindex=web_logs\n| dedup user_id\n```\n\n----------------------------------------\n\nTITLE: Security Log URL Redaction\nDESCRIPTION: Example demonstrating partial URL redaction in security logs using capturing groups.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/redact-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| redact replaceToken=\"<REDACTED>\" redactGroups=true @'.*/(.*)' on uri\n```\n\n----------------------------------------\n\nTITLE: Axiom CLI Environment Variables\nDESCRIPTION: List of available environment variables for configuring Axiom CLI.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/cli.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nAXIOM_DEPLOYMENT: The deployment to use. Overwrites the choice loaded\nfrom the configuration file.\n\nAXIOM_ORG_ID: The organization ID of the organization the access\ntoken is valid for.\n\nAXIOM_PAGER, PAGER (in order of precedence): A terminal paging\nprogram to send standard output to, for example, \"less\".\n\nAXIOM_TOKEN: Token The access token to use. Overwrites the choice\nloaded from the configuration file.\n\nAXIOM_URL: The deployment url to use. Overwrites the choice loaded\nfrom the configuration file.\n\nVISUAL, EDITOR (in order of precedence): The editor to use for\nauthoring text.\n\nNO_COLOR: Set to any value to avoid printing ANSI escape sequences\nfor color output.\n\nCLICOLOR: Set to \"0\" to disable printing ANSI colors in output.\n\nCLICOLOR_FORCE: Set to a value other than \"0\" to keep ANSI colors in\noutput even when the output is piped.\n```\n\n----------------------------------------\n\nTITLE: Comparing Count Function: Splunk SPL vs APL\nDESCRIPTION: Comparison of how to count records by status in Splunk SPL and the equivalent syntax in APL. This shows how to translate your existing Splunk queries to APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/count.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats count by status\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by status\n```\n\n----------------------------------------\n\nTITLE: Events Array Example for Single Index Split\nDESCRIPTION: Shows an example of a source events array containing three event objects with timestamp and name properties, before splitting is applied.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-split.mdx#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"timestamp\": 1734033733465219300,\n    \"name\": \"Enqueued\"\n  },\n  {\n    \"name\": \"Sent\",\n    \"timestamp\": 1734033733465228500\n  },\n  {\n    \"timestamp\": 1734033733465455900,\n    \"name\": \"ResponseReceived\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: String Search with indexof()\nDESCRIPTION: Finds the zero-based index of a string within another string with options for start position, length, and occurrence count.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\nindexof( body, ['id'], 2, 1, number ) == \"-1\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\nindexof(source,lookup[,start_index[,length[,occurrence]]])\n\nindexof ()\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project occurrence = indexof( body, ['id'], 23, 5, number )\n```\n\n----------------------------------------\n\nTITLE: Calculating Variance in Splunk SPL vs APL\nDESCRIPTION: A comparison of how to calculate variance in Splunk SPL using the var function and the equivalent approach in APL using the variance function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/variance.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats var(req_duration_ms) as variance\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize variance(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Using dynamic_to_json() Function in APL\nDESCRIPTION: The dynamic_to_json() function converts a dynamic type to a JSON string representation. It takes a dynamic value as input and returns its JSON string equivalent.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\ndynamic_to_json(dynamic)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project conversion_function = dynamic_to_json(dynamic([1,2,3]))\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"conversion_function\": \"[1,2,3]\"\n}\n```\n\n----------------------------------------\n\nTITLE: Counting HTTP Requests by Status Code\nDESCRIPTION: Example of using count to analyze HTTP logs by grouping on status codes. This helps to identify the distribution of successful vs failed requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/count.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by status\n```\n\n----------------------------------------\n\nTITLE: Creating Virtual Fields for Custom Attributes\nDESCRIPTION: Shows how to create a virtual field from a custom attribute to simplify querying. This example creates a virtual field for a User-Agent attribute.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/traces.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| extend useragent = ['attributes.custom']['User-Agent']\n```\n\n----------------------------------------\n\nTITLE: Adding Special Attributes to APL Query Results\nDESCRIPTION: This APL query demonstrates the use of various special field attributes. It adds a tooltip and description to the 'status' field, makes it clickable with a URL, and creates a new field 'resp_body_size_bits' with a specified unit of measurement.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/reference/special-field-attributes.mdx#2025-04-22_snippet_0\n\nLANGUAGE: apl\nCODE:\n```\n['sample-http-logs']\n| extend _status_tooltip = 'The status of the HTTP request is the response code from the server. It shows if an HTTP request has been successfully completed.'\n| extend _status_description = 'This is the status of the HTTP request.'\n| extend _status_url = 'https://developer.mozilla.org/en-US/docs/Web/HTTP/Status'\n| extend resp_body_size_bits = resp_body_size_bytes * 8\n| extend _resp_body_size_bits_unit = 'bits'\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL Array Manipulation\nDESCRIPTION: Demonstrates the difference between Splunk SPL's array manipulation using mvzip and APL's more explicit approach using array_split. Shows equivalent operations in both languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-split.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n| eval split_array = mvzip(array_field, \"2\")\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| extend split_array = array_split(events, 2)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Geo Data in ANSI SQL vs APL\nDESCRIPTION: Comparison between retrieving geographic information from IP addresses in ANSI SQL versus the equivalent operation in APL using geo_info_from_ip_address.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ip_to_location(client_ip) AS geo_info\nFROM sample_http_logs\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend geo_info = geo_info_from_ip_address(client_ip)\n```\n\n----------------------------------------\n\nTITLE: Filtering JSON Array in ANSI SQL\nDESCRIPTION: This snippet demonstrates how to filter a JSON array in ANSI SQL. It's provided as a comparison to the array_select_dict function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-select-dict.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM my_table\nWHERE JSON_CONTAINS(array_column, '{\"key\": 5}')\n```\n\n----------------------------------------\n\nTITLE: Applying Regex to Trim HTTP Log Content Type\nDESCRIPTION: This query uses a regex to trim non-alphabetic characters from the start of the 'content_type' field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_14\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project remove_cutset = trim_start_regex(\"[^a-zA-Z]\", content_type )\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with array_iff in APL\nDESCRIPTION: Example of using array_iff to filter HTTP log data conditionally, selecting request durations based on HTTP status codes and replacing non-matching values with zero.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-iff.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| order by _time desc\n| limit 1000\n| summarize is_ok = make_list(status == '200'), request_duration = make_list(req_duration_ms)\n| project ok_request_duration = array_iff(is_ok, request_duration, 0)\n```\n\n----------------------------------------\n\nTITLE: Using the 'has' Operator in Axiom Processing Language\nDESCRIPTION: Syntax example for the 'has' operator which filters rows based on whether a given term appears within a string field. The operator provides precise term matching rather than substring matching.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-operators/string-operators.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['Dataset'] \n| where Field has (Expression)\n```\n\n----------------------------------------\n\nTITLE: Advanced Log Aggregations with Complex Conditions\nDESCRIPTION: Performs advanced aggregations on HTTP logs with multiple conditions and grouping operations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_25\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend prospect = ['geo.city'] contains \"Okayama\" or uri contains \"/api/v1/messages/back\"\n| extend possibility = server_datacenter contains \"GRU\" or status contains \"301\"\n| summarize count(), topk( user_agent, 6 ) by bin(_time, 10d), ['geo.country']\n| take 4\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis with arg_min\nDESCRIPTION: Query to find lowest status code per country with associated URI.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-min.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize arg_min(toint(status), uri) by ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL join with APL equivalent\nDESCRIPTION: This snippet demonstrates how to convert a Splunk SPL join query to its equivalent in Axiom Processing Language. It shows the difference in syntax between Splunk's join command and APL's join operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/join-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nindex=logs | join type=inner [search index=traces]\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| join kind=inner ['otel-demo-traces'] on id == trace_id\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL and APL sum Aggregations\nDESCRIPTION: Example showing how to compute a sum aggregation in SQL and its equivalent in APL. Both examples calculate the total duration by summing the req_duration_ms field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sum.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SUM(req_duration_ms) AS total_duration\nFROM sample_http_logs\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize total_duration = sum(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Using ipv4_is_private with a Specific IP in APL\nDESCRIPTION: This snippet shows how to use the ipv4_is_private function in APL with a specific IP address ('192.168.0.1'). It demonstrates extending the 'sample-http-logs' dataset with the result of this function call.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-private.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend is_private = ipv4_is_private('192.168.0.1')\n```\n\n----------------------------------------\n\nTITLE: Configuring Fluentd for Log Forwarding\nDESCRIPTION: Fluentd configuration file that sets up log forwarding from Log4j to Axiom. Includes source configuration for receiving logs, filtering for adding tags, and match configuration for forwarding to Axiom's API endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-apache-log4j.mdx#2025-04-22_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<source>\n  @type forward\n  bind 0.0.0.0\n  port 24224\n  <parse>\n    @type multi_format\n    <pattern>\n      format json\n      time_key timeMillis\n      time_type string\n      time_format %Q\n    </pattern>\n  </parse>\n</source>\n\n<filter **>\n  @type record_transformer\n  <record>\n    tag java.log4j\n  </record>\n</filter>\n\n<match **>\n  @type http\n  endpoint https://api.axiom.co/v1/datasets/DATASET_NAME/ingest\n  headers {\"Authorization\":\"Bearer API_TOKEN\"}\n  json_array true\n  <buffer>\n    @type memory\n    flush_interval 5s\n    chunk_limit_size 5m\n    total_limit_size 10m\n  </buffer>\n  <format>\n    @type json\n  </format>\n</match>\n```\n\n----------------------------------------\n\nTITLE: Parsing SQL SELECT with WHERE Clause in APL\nDESCRIPTION: Shows how to use parse_sql() to analyze a SELECT statement with a WHERE clause, filtering customers by subscription status.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\nhn\n| project parse_sql(\"SELECT id, email FROM customers WHERE subscription_status = 'active'\")\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Value using max in APL\nDESCRIPTION: This snippet shows how to use the max function in APL to find the maximum value of a column. It's equivalent to the Splunk SPL example and demonstrates APL's structured flow.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/max.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize max(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Capturing errors with Axiom client\nDESCRIPTION: Example of configuring error handling for the Axiom client.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nlet client = new Axiom({\n  token: '',\n  ...,\n  onError: (err) => {\n    console.error('ERROR:', err);\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Strict Types Set Statement Example\nDESCRIPTION: Demonstrates using the stricttypes option in a query to enforce exact data type declarations. This example shows filtering a dataset where a number field equals 5 with strict type checking enabled.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/query-statement/set-statement.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\nset stricttypes; \n['Dataset'] \n| where number == 5\n```\n\n----------------------------------------\n\nTITLE: Basic arg_max Syntax Example\nDESCRIPTION: Shows the basic syntax for using arg_max aggregation in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-max.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| summarize arg_max(expression, field1[, field2, ...])\n```\n\n----------------------------------------\n\nTITLE: Basic Project Operator Syntax in APL\nDESCRIPTION: Demonstrates the basic syntax of the project operator in APL, showing how to select specific fields from a dataset and optionally apply expressions to transform data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| project FieldName [= Expression] [, ...]\n```\n\n----------------------------------------\n\nTITLE: Reversing Spans in OpenTelemetry Trace Analysis\nDESCRIPTION: Applies array_reverse to analyze trace data by reversing the sequence of span events for each trace. This allows for backtracking service calls and understanding the execution flow in reverse order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-reverse.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize spans = make_list(span_id) by trace_id\n| project trace_id, reversed_spans = array_reverse(spans)\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL stdev with APL stdevif for HTTP Log Analysis\nDESCRIPTION: Demonstrates how to calculate the standard deviation of request durations for HTTP 200 status codes in both Splunk SPL and APL. The APL version uses the stdevif function to combine filtering and aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdevif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats stdev(req_duration_ms) as stdev_req where status=\"200\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize stdevif(req_duration_ms, status == \"200\") by geo.country\n```\n\n----------------------------------------\n\nTITLE: Explicit Case-Insensitive Search in APL\nDESCRIPTION: Explicitly specifies case-insensitive search for \"CSS\", which will match \"css\", \"CSS\", \"Css\" and any other case variations in the logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search kind=case_insensitive \"CSS\"\n```\n\n----------------------------------------\n\nTITLE: Ingesting NDJSON Data with Axiom API\nDESCRIPTION: Example of sending NDJSON (Newline Delimited JSON) data to Axiom's ingest API endpoint using curl. Shows multiple JSON objects separated by newlines.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/ingest.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/DATASET_NAME/ingest' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -H 'Content-Type: application/x-ndjson' \\\n  -d '{\"id\":1,\"name\":\"machala\"}\n  {\"id\":2,\"name\":\"axiom\"}\n  {\"id\":3,\"name\":\"apl\"}\n  {\"index\": {\"_index\": \"products\"}}\n  {\"timestamp\": \"2016-06-06T12:00:00+02:00\", \"attributes\": {\"key1\": \"value1\",\"key2\": \"value2\"}}\n  {\"queryString\": \"count()\"}'\n```\n\n----------------------------------------\n\nTITLE: Converting ANSI SQL to APL for conditional sum\nDESCRIPTION: This code comparison shows how to convert an ANSI SQL query using CASE within SUM to the equivalent APL query using sumif for conditional sum aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sumif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SUM(CASE WHEN status = '200' THEN duration ELSE 0 END) AS total_duration\nFROM http_logs\n```\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize total_duration = sumif(duration, status == '200')\n```\n\n----------------------------------------\n\nTITLE: Using ago() function in Kusto/APL\nDESCRIPTION: The ago() function subtracts a given timespan from the current UTC clock time. It takes an interval to subtract as its argument and returns now() - a_timespan.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nago(6h)\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"date_time_functions\": \"2023-09-11T20:12:39Z\"\n}\n```\n\nLANGUAGE: kusto\nCODE:\n```\nago(3d)\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"date_time_functions\": \"2023-09-09T02:13:29Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Pino Transport Package\nDESCRIPTION: Command to install the Axiom transport package for Pino logger using npm.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/pino.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install @axiomhq/pino\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom CLI using Go\nDESCRIPTION: Install the Axiom CLI tool using Go's package manager. Requires Go version 1.16 or higher.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/cli.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngo install github.com/axiomhq/cli/cmd/axiom@latest\n```\n\n----------------------------------------\n\nTITLE: Counting Rows in SQL vs APL\nDESCRIPTION: Comparison between SQL and APL syntax for counting rows in a table.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/count-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(*) FROM web_logs;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| count\n```\n\n----------------------------------------\n\nTITLE: Calculating Bytes Transferred per Source IP in Sumo Logic and APL\nDESCRIPTION: Shows how to calculate the total number of bytes transferred to each source IP. Sumo Logic parses the source IP and size then uses sum aggregation, while APL extracts values and uses the summarize operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache \n| parse \"* \" as src_IP \n| parse \" 200 * \" as size \n| count, sum(size) by src_IP\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend src_IP = extract(\"^(\\S+)\", 1, uri)\n| extend size = toint(extract(\"200\", 0, status))\n| summarize count(), sum(size) by src_IP\n```\n\n----------------------------------------\n\nTITLE: Creating a Discord Notifier in Axiom with Terraform\nDESCRIPTION: This snippet demonstrates how to create a Discord notifier in Axiom using Terraform. It requires a Discord webhook URL and API token.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_3\n\nLANGUAGE: hcl\nCODE:\n```\nresource \"axiom_notifier\" \"test_discord_notifier\" {\n  name = \"test_discord_notifier\"\n  properties = {\n    discord = {\n      discord_channel = \"DISCORD_CHANNEL\"\n      discord_token = \"DISCORD_TOKEN\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using pair() Function in a Query\nDESCRIPTION: Demonstrates how to use the pair() function within a Kusto query to filter logs by tags containing a specific key-value pair.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/pair-functions.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['logs']\n| where tags contains pair(\"host\", \"mymachine\")\n```\n\n----------------------------------------\n\nTITLE: Capturing Traffic Requests in Next.js Middleware\nDESCRIPTION: Sets up middleware to capture traffic requests and log them using next-axiom in a Next.js app.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger } from 'next-axiom'\nimport { NextResponse } from 'next/server'\nimport type { NextFetchEvent, NextRequest } from 'next/server'\n\nexport async function middleware(request: NextRequest, event: NextFetchEvent) {\n    const logger = new Logger({ source: 'middleware' }); // traffic, request\n    logger.middleware(request)\n\n    event.waitUntil(logger.flush())\n    return NextResponse.next()\n\n// For more information, see Matching Paths below\nexport const config = {\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering HTTP Logs by Country in APL\nDESCRIPTION: Example of using the where operator with a nested field to filter logs based on country. This query filters logs to find requests from users in Germany, useful for security and compliance.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where ['geo.country'] == 'Germany'\n```\n\n----------------------------------------\n\nTITLE: Content Type Parsing\nDESCRIPTION: Example of parsing content type field to extract datatype and format.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| parse content_type with datatype '/' format\n| project datatype, format\n```\n\n----------------------------------------\n\nTITLE: Converting SQL to APL for Top Results Query\nDESCRIPTION: Comparison between ANSI SQL's ORDER BY with LIMIT approach and APL's topk aggregation for finding the top 5 status codes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/topk.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT status, COUNT(*)\nFROM sample_http_logs\nGROUP BY status\nORDER BY COUNT(*) DESC\nLIMIT 5;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize topk(status, 5)\n```\n\n----------------------------------------\n\nTITLE: Extracting IP Addresses with Regex in Sumo Logic and APL\nDESCRIPTION: Shows how to use regular expressions to extract IP addresses from log data in both query languages. Sumo Logic uses parse regex while APL uses the extract function with a regex pattern.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n*| parse regex \"(\\<src_i\\>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip = extract(\"(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\", 1, \"23.45.67.90\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Metricbeat for AWS RDS Monitoring\nDESCRIPTION: YAML configuration for Metricbeat to collect AWS RDS metrics and send them to Axiom. Includes AWS authentication settings and RDS metric collection configuration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nsetup.ilm.enabled: false\nmetricbeat.config.modules:\n  path:\n    -$PATH_TO_LOG_FILE\nmetricbeat.modules:\n- module: aws\n  period: 60s\n  metricsets:\n    - rds\n  access_key_id: '<access_key_id>'\n  secret_access_key: '<secret_access_key>'\n  session_token: '<session_token>'\noutput.elasticsearch:\n  hosts: [\"https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic\"]\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n```\n\n----------------------------------------\n\nTITLE: Parsing SQL GROUP BY Clause in APL\nDESCRIPTION: Demonstrates using parse_sql() to analyze an SQL statement that aggregates order counts by product_id using the GROUP BY clause.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\nhn\n| project parse_sql(\"SELECT product_id, COUNT(*) as order_count FROM orders GROUP BY product_id\")\n```\n\n----------------------------------------\n\nTITLE: Counting Error Status Codes\nDESCRIPTION: Example of counting HTTP error status codes (4xx or 5xx) in a log dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/count-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] |\nwhere status startswith '4' or status startswith '5' |\ncount\n```\n\n----------------------------------------\n\nTITLE: Using datetime_add() function in Kusto/APL\nDESCRIPTION: The datetime_add() function calculates a new datetime from a specified datepart multiplied by a specified amount, added to a specified datetime. It takes period (string), amount (integer), and datetime as arguments.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\ndatetime_add(period,amount,datetime)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project new_datetime = datetime_add( \"month\", 1, datetime(2016-10-06))\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"new_datetime\": \"2016-11-06T00:00:00Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Client with Personal Token\nDESCRIPTION: Example of manually configuring the Axiom client using SetClientOptions with a personal token for authentication.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/apex.mdx#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nimport (\n    \"github.com/axiomhq/axiom-go/axiom\"\n    adapter \"github.com/axiomhq/axiom-go/adapters/apex\"\n)\n\n// ...\n\nhandler, err := adapter.New(\n    adapter.SetClientOptions(\n        axiom.SetPersonalTokenConfig(\"AXIOM_TOKEN\"),\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Parsing Byte Strings in APL\nDESCRIPTION: The parse_bytes function converts a string representation of bytes into a numeric value. It can handle different units (KB, Bytes) and optionally use a specific base (10 or 2).\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\nparse_bytes(bytes_string [, base])\n\nparse_bytes(\"1 KB\") == 1024\n\nparse_bytes(\"1 KB\", 10) == 1000\n\nparse_bytes(\"128 Bytes\") == 128\n\nparse_bytes(\"bad data\") == 0\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend parsed_bytes =  parse_bytes(\"300 KB\", 10)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project parsed_bytes =  parse_bytes(\"300 KB\", 10)\n```\n\n----------------------------------------\n\nTITLE: Security log analysis with make_list in APL\nDESCRIPTION: Query demonstrating how to collect all cities from where users have initiated HTTP requests, useful for geographical analysis or anomaly detection.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize cities=make_list(['geo.city']) by id\n```\n\n----------------------------------------\n\nTITLE: Converting SQL Multiple Aggregations to APL\nDESCRIPTION: Demonstrates how to convert a SQL query with multiple aggregation functions to APL using named aggregations in the 'summarize' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT geo.country,\n       COUNT(*) AS TotalRequests,\n       AVG(req_duration_ms) AS AverageRequest,\n       MIN(req_duration_ms) AS MinRequest,\n       MAX(req_duration_ms) AS MaxRequest\nFROM [Sample-http-logs]\nGROUP BY geo.country;\n```\n\nLANGUAGE: kusto\nCODE:\n```\nUsers\n| summarize TotalRequests = count(),\n            AverageRequest = avg(req_duration_ms),\n            MinRequest = min(req_duration_ms),\n            MaxRequest = max(req_duration_ms) by ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Analysis with Project in APL\nDESCRIPTION: Demonstrates using the project operator to extract service name, span ID, and duration from OpenTelemetry traces for focused analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| project ['service.name'], span_id, duration\n```\n\n----------------------------------------\n\nTITLE: Kubernetes Filter Configuration\nDESCRIPTION: Fluent Bit configuration with Kubernetes filter for enriching logs with Kubernetes metadata. Includes settings for Kubernetes URL and logging parser.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluent-bit.mdx#2025-04-22_snippet_2\n\nLANGUAGE: ini\nCODE:\n```\n[SERVICE]\n    Flush     5\n    Daemon    off\n    Log_Level debug\n\n[INPUT]\n    Name cpu\n    Tag  cpu\n\n[FILTER]\n    Name             kubernetes\n    Match            *\n    Kube_URL         https://kubernetes.default.svc:443\n    Merge_Log        On\n    K8S-Logging.Parser  On\n    K8S-Logging.Exclude On\n\n[OUTPUT]\n    Name            http\n    Match           *\n    Host            api.axiom.co\n    Port            443\n    URI             /v1/datasets/DATASET_NAME/ingest\n    # Authorization Bearer should be an API token\n    Header Authorization Bearer API_TOKEN\n    compress gzip\n    format json\n    json_date_key _time\n    json_date_format iso8601\n    tls On\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL Array Shifting with APL array_shift_left Function\nDESCRIPTION: Shows the difference between SQL's approach to array shifting (requiring custom logic) and APL's built-in array_shift_left function. The SQL example is pseudo-code since standard SQL lacks native array rotation functions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-left.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Pseudo code in SQL\nSELECT ARRAY_SHIFT_LEFT(array_column, shift_amount)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['array_shift_left'](array_column, shift_amount)\n```\n\n----------------------------------------\n\nTITLE: Retrieving First 5 Rows in APL for Log Analysis\nDESCRIPTION: This APL query demonstrates how to use the take operator to retrieve the first 5 rows from a sample HTTP logs dataset for quick analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/take-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| take 5\n```\n\n----------------------------------------\n\nTITLE: Extracting Netmask Suffix in ANSI SQL vs APL\nDESCRIPTION: Comparison of how to extract the netmask suffix from an IP address in ANSI SQL versus using the ipv4_netmask_suffix function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-netmask-suffix.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SUBSTRING(ip, CHARINDEX('/', ip) + 1, LEN(ip)) AS netmask FROM logs;\n```\n\nLANGUAGE: kusto\nCODE:\n```\nextend netmask = ipv4_netmask_suffix(ip)\n```\n\n----------------------------------------\n\nTITLE: Using Wildcards with project-keep in APL for GitHub Events\nDESCRIPTION: Example of using wildcards with the project-keep operator to select related fields from GitHub push events, including size-related fields, repository information, commits, and identifiers.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-keep-operator.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['github-push-event']\n| project-keep size*, repo*, ['commits']*, id*\n```\n\n----------------------------------------\n\nTITLE: Datetime literals and functions in APL\nDESCRIPTION: Examples of datetime literals and functions in APL, including specific date formats and functions to get the current time.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/scalar-data-types.mdx#2025-04-22_snippet_1\n\nLANGUAGE: apl\nCODE:\n```\ndatetime(2019-11-30 23:59:59.9)\ndatetime(2015-12-31)\ndatetime(null)\nnow()\nnow(-timespan)\nago(timespan)\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Analysis with array_iff in APL\nDESCRIPTION: Example of using array_iff with OpenTelemetry trace data to filter spans based on service type, selecting durations for server spans and setting others to zero.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-iff.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| order by _time desc\n| limit 1000\n| summarize is_server = make_list(kind == 'server'), duration_list = make_list(duration)\n| project  server_durations = array_iff(is_server, duration_list, 0)\n```\n\n----------------------------------------\n\nTITLE: Counting URL Visits in Sumo Logic and APL\nDESCRIPTION: Shows how to count the frequency of visits to specific URLs. Sumo Logic filters by source category and counts by URL, while APL extracts the URL and uses the summarize operator to count occurrences.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache \n| parse \"GET * \" as url \n| count by url\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend url = extract(\"^(\\S+)\", 1, method)\n| summarize Count = count() by url\n```\n\n----------------------------------------\n\nTITLE: Categorizing HTTP Status Codes in Security Logs\nDESCRIPTION: Example query that uses extend with the iff function to categorize HTTP status codes as either 'Success' or 'Failure' based on the status code.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| extend status_category = iff(status == '200', 'Success', 'Failure')\n```\n\n----------------------------------------\n\nTITLE: Practical case() Example with HTTP Status Codes\nDESCRIPTION: Shows how to use case() to convert numeric HTTP status codes into human-readable strings.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conditional-function.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] |\nextend status_human_readable = case(\n    status_int == 200,\n    'OK',\n    status_int == 201,\n    'Created',\n    status_int == 301,\n    'Moved Permanently',\n    status_int == 500,\n    'Internal Server Error',\n    'Other'\n)\n```\n\n----------------------------------------\n\nTITLE: Conditional Field Extension in ANSI SQL\nDESCRIPTION: This example demonstrates how to achieve functionality similar to APL's extend-valid in ANSI SQL using a CASE WHEN expression within a SELECT statement.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-valid-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CASE WHEN req_duration_ms IS NOT NULL THEN req_duration_ms + 100 ELSE NULL END AS new_field FROM sample_http_logs;\n```\n\n----------------------------------------\n\nTITLE: Hourly Status Code Analysis for Text Sources in Sumo Logic and APL\nDESCRIPTION: Queries that analyze HTTP status codes in text-related content. Sumo Logic uses parsing and transposition, while APL filters for CSS content types and counts by hour, content type, and status code.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=text*\n| parse \"HTTP/1.1\\\" * * \\\"\" as (status_code, size)\n| timeslice 1h\n| count by _timeslice, status_code\n| transpose row _timeslice column status_code\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where content_type startswith 'text/css'\n| extend status_code= status\n| summarize count() by bin(_time, 1h), content_type, status_code\n```\n\n----------------------------------------\n\nTITLE: Calculating Total Request Duration in HTTP Logs with APL\nDESCRIPTION: Example of using sum aggregation to calculate the total duration of HTTP requests across a dataset. This query sums all req_duration_ms values in the sample-http-logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sum.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize total_duration = sum(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Finding String Index and Binning in HTTP Logs\nDESCRIPTION: This query finds the index of 'content_type' within 'geo.country' and bins the 'resp_header_size_bytes' field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_13\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend based_index =  indexof( ['geo.country'], content_type, 45, 60, resp_body_size_bytes ), specified_time = bin(resp_header_size_bytes, 30)\n```\n\n----------------------------------------\n\nTITLE: Analyzing HTTP Logs with min Function\nDESCRIPTION: Example of using min function to analyze HTTP logs and find minimum request duration by user ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/min.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize min(req_duration_ms) by id\n```\n\n----------------------------------------\n\nTITLE: Creating Request Duration Histogram\nDESCRIPTION: Shows how to use the histogram aggregation function with summarize to create a histogram of request durations with 30 buckets.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/summarize-operator.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize histogram(req_duration_ms, 30)\n```\n\n----------------------------------------\n\nTITLE: Using datetime_part() function in Kusto/APL\nDESCRIPTION: The datetime_part() function extracts the requested date part as an integer value. It takes date (datetime) and part (string) as arguments and returns an integer representing the extracted part.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ndatetime_part(part,datetime)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project new_datetime = datetime_part(\"Day\", datetime(2016-06-26T08:20:03.123456Z))\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"new_datetime\": 26\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Wrangler for Cloudflare Workers\nDESCRIPTION: Configuration for wrangler.toml file, including Cloudflare account details and environment variables for Axiom API token and dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\nname = \"my-axiom-worker\"\ntype = \"javascript\"\naccount_id = \"$YOUR_CLOUDFLARE_ACCOUNT_ID\" # Replace with your actual Cloudflare account ID\nworkers_dev = true\ncompatibility_date = \"2023-03-27\"\ncompatibility_flags = [\"nodejs_compat\"]\nmain = \"index.ts\"\n\n# Define environment variables here\n[vars]\nAXIOM_API_TOKEN = \"API_TOKEN\" # Replace API_TOKEN with your actual Axiom API token\nAXIOM_DATASET = \"DATASET_NAME\" # Replace DATASET_NAME with your actual Axiom dataset name\n```\n\n----------------------------------------\n\nTITLE: Combining HTTP Methods and URLs with strcat_array in APL\nDESCRIPTION: Demonstrates a practical use case of strcat_array by combining HTTP methods and URLs to create a summary of unique request paths in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/strcat-array.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| take 50\n| extend combined_requests = strcat_delim(' ', method, uri)\n| summarize requests_list = make_list(combined_requests)\n| extend paths = strcat_array(requests_list, ', ')\n```\n\n----------------------------------------\n\nTITLE: Checking Array Type in ANSI SQL vs APL\nDESCRIPTION: Compares how to check if a field is an array in ANSI SQL and APL. SQL uses JSON_TYPE function, while APL provides the simpler isarray function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/isarray.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CASE\n         WHEN JSON_TYPE(field) = 'ARRAY' THEN TRUE\n         ELSE FALSE\n       END AS is_array\nFROM dataset_name;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset.name']\n| extend is_array=isarray(field)\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL and APL for IP Address Matching\nDESCRIPTION: This snippet shows how to perform IP address matching in ANSI SQL and the equivalent operation using has_any_ipv4 in APL, demonstrating APL's more concise syntax for this task.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-any-ipv4.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM logs WHERE ip_field = '192.168.1.1' OR ip_field = '192.168.1.2';\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where has_any_ipv4('ip_field', dynamic(['192.168.1.1', '192.168.1.2']))\n```\n\n----------------------------------------\n\nTITLE: has_any_ipv4_prefix Function Syntax in APL\nDESCRIPTION: This snippet demonstrates the syntax of the has_any_ipv4_prefix function in APL, showing its parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-any-ipv4-prefix.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\nhas_any_ipv4_prefix(ip_column, prefixes)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Span Durations in OpenTelemetry Traces with APL Histogram\nDESCRIPTION: Applies the histogram aggregation to analyze the distribution of span durations in OpenTelemetry traces, using 100 bins for grouping.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/histogram.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize histogram(duration, 100) by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with Parse Operator\nDESCRIPTION: Example of using parse operator to extract HTTP request duration from URI field in log analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| parse uri with * 'duration=' req_duration_ms:int\n| project _time, req_duration_ms, uri\n```\n\n----------------------------------------\n\nTITLE: Case-Sensitive Search in APL\nDESCRIPTION: Executes a case-sensitive search for the term \"css\" in the sample-http-logs dataset, demonstrating the use of the kind parameter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search kind=case_sensitive \"css\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Annotations with Axiom API using cURL\nDESCRIPTION: This bash snippet shows how to retrieve information about all annotations in an organization using the Axiom API via a cURL GET request. It includes the API endpoint and authorization header.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/annotate-charts.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'GET' 'https://api.axiom.co/v2/annotations' \\\n  -H 'Authorization: Bearer API_TOKEN'\n```\n\n----------------------------------------\n\nTITLE: Filtering Text Content Types in HTTP Logs using KQL\nDESCRIPTION: Query that counts and filters HTTP log events by content type, focusing on text-based content with more than 10 occurrences. The query groups logs by content_type, filters for text-related entries, and projects the count alongside content type.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-operators/string-operators.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize event_count = count() by content_type\n| where content_type has \"text\"\n| where event_count > 10\n| project event_count, content_type\n```\n\n----------------------------------------\n\nTITLE: Comparing IPv4 Addresses in Splunk SPL\nDESCRIPTION: This snippet shows how to compare two IP addresses in Splunk SPL using a custom evaluation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-compare.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval comparison = if(ip1 < ip2, -1, if(ip1 == ip2, 0, 1))\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Configuration File\nDESCRIPTION: Command to start Vector with a specified configuration file. Vector will read the configuration and begin collecting and forwarding logs according to the defined sources and sinks.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nvector --config /path/to/vector.toml\n```\n\n----------------------------------------\n\nTITLE: APL Use Case Example\nDESCRIPTION: Example query showing how to identify log entries from specific subnets using ipv4_is_in_any_range.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-in-any-range.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| extend is_in_range = ipv4_is_in_any_range('192.168.0.0', dynamic(['192.168.0.0/24', '10.0.0.0/8']))\n```\n\n----------------------------------------\n\nTITLE: Using maxif for Security Logs in APL\nDESCRIPTION: This snippet demonstrates how to use the maxif function in APL for analyzing security logs. It identifies the longest request duration for requests originating from a specific country.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/maxif.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize maxif(req_duration_ms, ['geo.country'] == \"United States\")\n```\n\n----------------------------------------\n\nTITLE: Querying Traces with Span Links\nDESCRIPTION: Shows how to find traces that contain span links by filtering for non-empty link fields using APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/traces.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset'] \n| where isnotempty(links)\n```\n\n----------------------------------------\n\nTITLE: Using Union with Withsource in APL\nDESCRIPTION: Demonstrates how to use union with withsource to combine multiple datasets matching a pattern and count events by source. The query combines all datasets starting with 'github' and tracks their origin.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_13\n\nLANGUAGE: kusto\nCODE:\n```\nunion withsource=dataset github*\n| summarize count() by dataset\n```\n\n----------------------------------------\n\nTITLE: Limiting HTTP Log Entries with Alias\nDESCRIPTION: This query uses the limit operator (alias for take) to return up to 10 rows from the sample HTTP logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| limit 10\n```\n\n----------------------------------------\n\nTITLE: Extracting Numeric Version Numbers in APL\nDESCRIPTION: This APL query extends the sample-http-logs dataset with request duration, converts it to an integer, and filters for specific values (2, 3, or 6).\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_23\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend p= (req_duration_ms)\n| extend number=toint(p)\n| where number in (2,3,6)\n```\n\n----------------------------------------\n\nTITLE: Basic Count Syntax in APL\nDESCRIPTION: The basic syntax for using the count aggregation function in APL. This shows how to count records with optional grouping.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/count.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize count() [by GroupingColumn]\n```\n\n----------------------------------------\n\nTITLE: Creating a Slack Notifier in Axiom with Terraform\nDESCRIPTION: This snippet shows how to create a Slack notifier in Axiom using Terraform. It requires a Slack webhook URL for configuration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_2\n\nLANGUAGE: hcl\nCODE:\n```\nresource \"axiom_notifier\" \"test_slack_notifier\" {\n  name = \"test_slack_notifier\"\n  properties = {\n    slack = {\n      slack_url = \"SLACK_URL\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Taking a Sample of HTTP Log Entries\nDESCRIPTION: This query returns up to 100 rows from the sample HTTP logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| take 100\n```\n\n----------------------------------------\n\nTITLE: Finding Most Recent Event in Security Logs using APL\nDESCRIPTION: This query uses the max function in APL to find the most recent timestamp from the '_time' field in sample HTTP logs. It's useful for monitoring the latest security events in log analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/max.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize max(_time)\n```\n\n----------------------------------------\n\nTITLE: Projecting Geolocation Information from IPv6 Address\nDESCRIPTION: Example showing how to project only the geolocation information from an IPv6 address using the geo_info_from_ip_address function while discarding other columns.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project ip_location=geo_info_from_ip_address('2a03:2880:f12c:83:face:b00c::25de')\n```\n\n----------------------------------------\n\nTITLE: Extracting Hour of Day in Axiom Query Language\nDESCRIPTION: The hourofday() function returns the integer number representing the hour of the day (0-23) from a given datetime. It's useful for time-based analysis and filtering.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\nhourofday(a_date)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project get_specific_hour = hourofday(datetime(2016-06-26T08:20:03.123456Z))\n```\n\n----------------------------------------\n\nTITLE: Syntax for ipv4_compare Function in APL\nDESCRIPTION: This snippet shows the syntax for using the ipv4_compare function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-compare.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\nipv4_compare(ip1, ip2)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Node SDK\nDESCRIPTION: Basic OpenTelemetry setup using Node SDK without Vercel integration\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nextjs.mdx#2025-04-22_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nimport { NodeSDK } from '@opentelemetry/sdk-node';\nimport { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';\nimport { Resource } from '@opentelemetry/resources';\nimport { SEMRESATTRS_SERVICE_NAME } from '@opentelemetry/semantic-conventions';\nimport { SimpleSpanProcessor } from '@opentelemetry/sdk-trace-node';\n\nexport function register() {\n  const sdk = new NodeSDK({\n    resource: new Resource({\n      [SEMRESATTRS_SERVICE_NAME]: 'nextjs-app',\n    }),\n    spanProcessor: new SimpleSpanProcessor(\n      new OTLPTraceExporter({\n        url: 'https://api.axiom.co/v1/traces',\n        headers: {\n          Authorization: `Bearer ${process.env.API_TOKEN}`,\n          'X-Axiom-Dataset': process.env.DATASET_NAME,\n        },\n      })\n    ),\n  });\n\n  sdk.start();\n}\n```\n\n----------------------------------------\n\nTITLE: Union with Filtering and Projection in APL\nDESCRIPTION: This query combines GitHub event logs, filters by actions made by 'github-actions[bot]', and displays key event details.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['github-pull-request-event']\n| union ['github-push-event']\n| where actor == \"github-actions[bot]\"\n| project _time, repo, ['id'], commits, head\n```\n\n----------------------------------------\n\nTITLE: Using has_ipv4_prefix in APL Query\nDESCRIPTION: Example of using has_ipv4_prefix function in an APL query to filter logs for requests from a specific IP range.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-ipv4-prefix.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend has_prefix= has_ipv4_prefix('192.168.0.1', '192.168.')\n```\n\n----------------------------------------\n\nTITLE: APL Array Sum Example Query\nDESCRIPTION: Practical example of using array_sum to calculate total event duration by service name.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-sum.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize event_duration = make_list(duration) by ['service.name']\n| extend total_event_duration = array_sum(event_duration)\n```\n\n----------------------------------------\n\nTITLE: Field Selection with project-keep in APL vs SQL\nDESCRIPTION: Comparison between SQL's SELECT statement and APL's project-keep operator for retrieving specific fields from a dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-keep-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT _time, status, uri FROM sample_http_logs\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| project-keep _time, status, uri\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL sum Aggregations\nDESCRIPTION: Example showing how to compute a sum aggregation in Splunk SPL and its equivalent in APL. Both examples calculate the total duration by summing the req_duration_ms field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sum.mdx#2025-04-22_snippet_0\n\nLANGUAGE: splunk\nCODE:\n```\n| stats sum(req_duration_ms) as total_duration\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize total_duration = sum(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Calculating Multiple Percentiles in ANSI SQL\nDESCRIPTION: This snippet demonstrates how to calculate multiple percentiles in ANSI SQL using PERCENTILE_CONT function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-array.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  service,\n  PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY duration) AS p25,\n  PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY duration) AS p50,\n  PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY duration) AS p95\nFROM traces\nGROUP BY service\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Syslog Proxy via Homebrew\nDESCRIPTION: Commands to install Axiom Syslog Proxy using Homebrew package manager\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/syslog-proxy.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbrew tap axiomhq/tap\nbrew install axiom-syslog-proxy\n```\n\n----------------------------------------\n\nTITLE: Converting Numeric IP to Dotted-Decimal Format Example in APL\nDESCRIPTION: Demonstrates how to use format_ipv4 to convert a numeric IP address to a human-readable format within a query analyzing HTTP logs. The example converts the integer 3232235776 to its dotted-decimal representation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/format-ipv4.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend formatted_ip = format_ipv4(3232235776)\n```\n\n----------------------------------------\n\nTITLE: Extracting Month from DateTime in Axiom Query Language\nDESCRIPTION: The getmonth() function extracts the month number (1-12) from a given datetime value. It's useful for categorizing or filtering data based on months.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend get_specific_month = getmonth(datetime(2020-07-26T08:20))\n```\n\n----------------------------------------\n\nTITLE: Ordered Result Limiting in Splunk and APL\nDESCRIPTION: Demonstrates how to get the first N results ordered by a specific field in both query languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_9\n\nLANGUAGE: splunk\nCODE:\n```\nSample.Logs=\"33009.2\" | sort Event.Sequence | head 20\n```\n\nLANGUAGE: apl\nCODE:\n```\n['sample-http-logs'] | top 20 by method\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis with array_iff in APL\nDESCRIPTION: Example of using array_iff for security log analysis to focus on specific geographic locations, filtering request durations based on the city field in HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-iff.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| limit 1000\n| summarize is_london = make_list(['geo.city'] == \"London\"), request_duration = make_list(req_duration_ms)\n| project london_duration = array_iff(is_london, request_duration, 0)\n```\n\n----------------------------------------\n\nTITLE: APL Sort Basic Syntax\nDESCRIPTION: Basic syntax template for using the sort operator in APL with field specifications and direction parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sort-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| sort by Field1 [asc | desc], Field2 [asc | desc], ...\n```\n\n----------------------------------------\n\nTITLE: Comparing IPv4 Addresses in APL (ANSI SQL Equivalent)\nDESCRIPTION: This snippet demonstrates the APL equivalent of the ANSI SQL comparison using the ipv4_compare function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-compare.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend comparison = ipv4_compare(ip1, ip2)\n```\n\n----------------------------------------\n\nTITLE: minif Syntax in APL\nDESCRIPTION: The basic syntax for using the minif aggregation function in Axiom Processing Language (APL), showing how to find the minimum value of an expression when a condition is met.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/minif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize minif(Expression, Predicate)\n```\n\n----------------------------------------\n\nTITLE: Logging in Client Components with Next.js and Axiom\nDESCRIPTION: Demonstrates how to use the useLogger hook from next-axiom to log from client-side components in Next.js.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n\"use client\";\nimport { useLogger } from \"next-axiom\";\n\nexport default function ClientComponent() {\n  const log = useLogger();\n  log.debug(\"User logged in\", { userId: 42 });\n  return <h1>Logged in</h1>;\n}\n```\n\n----------------------------------------\n\nTITLE: Replacing Strings in HTTP Log Fields\nDESCRIPTION: This query replaces occurrences of 'creator' with 'machala' in the 'method' field of the sample HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend replaced_string = replace_string( \"creator\", \"method\", \"machala\" )\n| project replaced_string\n```\n\n----------------------------------------\n\nTITLE: Sorting Security Logs by Timestamp\nDESCRIPTION: This query analyzes security logs by sorting them by timestamp in descending order to view the most recent logs first.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/order-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| order by _time desc\n```\n\n----------------------------------------\n\nTITLE: URI Endpoint Parsing\nDESCRIPTION: Example of extracting endpoint information from URI using parse operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| parse uri with '/api/v1/' endpoint\n| project endpoint\n```\n\n----------------------------------------\n\nTITLE: Rounding Numbers with round() in Kusto\nDESCRIPTION: The round() function rounds a number to the specified precision. It takes a source value and an optional precision parameter, returning the rounded result.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_20\n\nLANGUAGE: kusto\nCODE:\n```\nround(source [, Precision])\n```\n\nLANGUAGE: kusto\nCODE:\n```\nround(25.563663) == 26\n```\n\n----------------------------------------\n\nTITLE: Retrieving Pi Constant with pi() in Kusto\nDESCRIPTION: The pi() function returns the constant value of Pi (3.1415926...). It takes no arguments and returns the double value of Pi.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_17\n\nLANGUAGE: kusto\nCODE:\n```\npi()\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project pie = pi()\n```\n\n----------------------------------------\n\nTITLE: Case Conversion in SQL and APL\nDESCRIPTION: Demonstrates converting text to uppercase and lowercase. SQL uses UPPER() and LOWER() functions while APL uses toupper() and tolower() to transform content_type and status fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nSELECT UPPER(FirstName) AS UpperFirstName, LOWER(LastName) AS LowerLastName\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project upperFirstName = toupper(content_type), LowerLastNmae = tolower(status)\n```\n\n----------------------------------------\n\nTITLE: Top 10 GitHub Push Events by Maximum Push ID\nDESCRIPTION: This query finds the top 10 GitHub push events with the highest push ID, grouped by size.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['github-push-event']\n| summarize max_if = maxif(push_id, true) by size\n| top 10 by max_if desc\n```\n\n----------------------------------------\n\nTITLE: Projecting Geolocation Information from IPv4 Address\nDESCRIPTION: Example showing how to project only the geolocation information from an IPv4 address using the geo_info_from_ip_address function while discarding other columns.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project ip_location=geo_info_from_ip_address('20.53.203.50')\n```\n\n----------------------------------------\n\nTITLE: Using degrees() Function in Kusto\nDESCRIPTION: Examples of using the degrees() function to convert radians to degrees. The function applies the formula degrees = (180 / PI) * angle_in_radians to perform the conversion.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\ndegrees(a)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ndegrees(3.14) == 179.9087476710785\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project degree_rads = degrees(3.14)\n```\n\n----------------------------------------\n\nTITLE: Summarizing GitHub Push Events by Time\nDESCRIPTION: This query uses the summarize operator to count GitHub push events grouped by automatically binned time intervals.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['github-push-event']\n| summarize count() by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL with APL project-away Operator\nDESCRIPTION: A comparison between Splunk SPL's fields command and APL's project-away operator, both used to remove specified fields from results while returning the remaining ones.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-away-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: splunk\nCODE:\n```\n... | fields - status, uri, method\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| project-away status, uri, method\n```\n\n----------------------------------------\n\nTITLE: Counting Substring Occurrences in Kusto\nDESCRIPTION: Uses countof() function to count the number of times a substring appears within a string. The function takes a search string and text source as arguments.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ncountof(search, text)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project count = countof(\"con\", \"content_type\")\n```\n\n----------------------------------------\n\nTITLE: String Reversal in SQL and APL\nDESCRIPTION: Shows how to reverse the characters in a string. Both SQL and APL provide dedicated functions (REVERSE() and reverse()) to reverse the characters in the method field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nSELECT REVERSE(Method) AS ReversedFirstName\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ReversedFirstName = reverse(method)\n```\n\n----------------------------------------\n\nTITLE: Extracting City Name First Letter in Security Logs\nDESCRIPTION: This example shows how to use extend-valid to extract the first letter of city names from the geo.city field for valid log entries in security logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-valid-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend-valid city_first_letter = extract('^([A-Za-z])', 1, ['geo.city'])\n```\n\n----------------------------------------\n\nTITLE: Calculating End of Week in Axiom Query Language\nDESCRIPTION: The endofweek() function returns the end of the week containing the given date. It considers the end of the week as Saturday at 23:59:59.999999999.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_14\n\nLANGUAGE: kusto\nCODE:\n```\nendofweek(date)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project end_of_the_week = endofweek(datetime(2019-04-18T08:20))\n```\n\n----------------------------------------\n\nTITLE: Using array_shift_left in a Practical Query Example\nDESCRIPTION: Demonstrates a practical use case for array_shift_left by taking trace data and shifting the events array by one position to analyze dependencies in a different sequence.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-left.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| take 50\n| extend shifted_events = array_shift_left(events, 1)\n```\n\n----------------------------------------\n\nTITLE: Limiting Results in Splunk SPL vs APL\nDESCRIPTION: Comparison between Splunk's head command and APL's limit operator, showing how to return the top 10 rows of a dataset in both query languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/limit-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| head 10\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| limit 10\n```\n\n----------------------------------------\n\nTITLE: Using case() Function in APL\nDESCRIPTION: Demonstrates the basic syntax of the case() function which evaluates multiple conditions and returns the first matching result.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conditional-function.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\ncase(condition1, result1, condition2, result2, condition3, result3, ..., nothingMatchedResult)\n```\n\n----------------------------------------\n\nTITLE: Log Analysis Rate Calculation\nDESCRIPTION: Calculating rate of HTTP response sizes per second in log analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/rate.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize rate(resp_body_size_bytes) by bin(_time, 1s)\n```\n\n----------------------------------------\n\nTITLE: Practical Use Case of parse_ipv4_mask with HTTP Logs\nDESCRIPTION: A practical example showing how to use parse_ipv4_mask to analyze HTTP logs and create a masked IP field, useful for subnet-level analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/parse-ipv4-mask.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend masked_ip = parse_ipv4_mask('192.168.0.1', 24)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Schema Information with getschema in APL\nDESCRIPTION: This snippet demonstrates how to use the getschema operator in APL to retrieve schema information for a dataset. It returns field names, data types, and other metadata without requiring any parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/getschema-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| getschema\n```\n\n----------------------------------------\n\nTITLE: String Length Calculation in SQL and APL\nDESCRIPTION: Shows how to calculate the length of string values in a field. SQL uses LEN() function while APL uses strlen() to get the character count of the status field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LEN(Status) AS NameLength\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend NameLength = strlen(status)\n```\n\n----------------------------------------\n\nTITLE: Conditional Average in SQL vs APL\nDESCRIPTION: Comparison between ANSI SQL and APL syntax for calculating conditional averages using CASE statement versus avgif function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avgif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, AVG(CASE WHEN status = '200' THEN req_duration_ms ELSE NULL END) \nFROM sample_http_logs \nGROUP BY id\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize avgif(req_duration_ms, status == \"200\") by id\n```\n\n----------------------------------------\n\nTITLE: Identifying Top 10 Requested Pages in Sumo Logic and APL\nDESCRIPTION: Queries to find the most frequently requested pages by analyzing HTTP GET requests. The Sumo Logic query parses URLs from GET requests, while the Axiom APL query filters for GET method requests and returns the top 10 results.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n* | parse \"GET * \" as url \n| count by url \n| top 10 url by _count\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where method == \"GET\"\n| top 10 by method desc\n```\n\n----------------------------------------\n\nTITLE: Case Conversion Functions in KQL\nDESCRIPTION: Shows toupper and tolower functions for converting strings to upper and lower case respectively.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_27\n\nLANGUAGE: kusto\nCODE:\n```\ntoupper(\"axiom\") == \"AXIOM\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project upper = toupper( body )\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntolower(\"AXIOM\") == \"axiom\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project low = tolower( body )\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Analysis with limit\nDESCRIPTION: A query example demonstrating how to retrieve the first 5 rows from an OpenTelemetry traces dataset to analyze the latest traces.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/limit-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| limit 5\n```\n\n----------------------------------------\n\nTITLE: Finding Service Position in OpenTelemetry Traces\nDESCRIPTION: A query that uses array_index_of to find the position of a specific service.name within an array of service names in OpenTelemetry trace data. It identifies when a particular service appears in the trace chain.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-index-of.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| take 50\n| summarize  service_array = make_list(['service.name'])\n| extend frontend_index = array_index_of(service_array, 'frontend')\n```\n\n----------------------------------------\n\nTITLE: Computing Gamma Function with gamma() in Kusto\nDESCRIPTION: The gamma() function computes the gamma function of x. It takes a real number as input and returns the gamma function value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\ngamma(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ngamma(4) == 6\n```\n\n----------------------------------------\n\nTITLE: Hash Functions Example\nDESCRIPTION: Demonstrates usage of multiple hash functions including MD5, SHA1, SHA256, and SHA512\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_21\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend sha_256 = hash_md5( \"resp_header_size_bytes\" ), sha_1 = hash_sha1( content_type), md5 = hash_md5( method), sha512 = hash_sha512( \"resp_header_size_bytes\" )\n| project sha_256, sha_1, md5, sha512\n```\n\n----------------------------------------\n\nTITLE: Comparing maxif in APL with ANSI SQL\nDESCRIPTION: This snippet compares the use of maxif in APL with a similar query in ANSI SQL. It demonstrates finding the maximum request duration for successful HTTP requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/maxif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MAX(req_duration_ms) \nFROM logs \nWHERE status = '200';\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize maxif(req_duration_ms, status == \"200\")\n```\n\n----------------------------------------\n\nTITLE: Splitting Strings in HTTP Log Fields\nDESCRIPTION: This query splits the string 'method_content_metrics' by underscore and returns the resulting array for the first 20 rows.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project split_str = split(\"method_content_metrics\", \"_\")\n| take 20\n```\n\n----------------------------------------\n\nTITLE: Aggregating Trace Counts by HTTP Method Attribute in Kusto\nDESCRIPTION: This query aggregates trace counts by HTTP method attribute in the 'otel-demo-traces' dataset. It extends the result with the httpFlavor from custom attributes and summarizes the count by the HTTP method attribute.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_30\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| extend httpFlavor = tostring(['attributes.custom'])\n| summarize Count=count() by ['attributes.http.method']\n```\n\n----------------------------------------\n\nTITLE: Extracting Data with Missing Fields in Sumo Logic and APL\nDESCRIPTION: Demonstrates how to extract key parameters when certain fields may be missing. Sumo Logic uses the nodrop option in parse, while APL uses extract functions with conditional extensions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache \n| parse \"* \" as src_IP \n| parse \" 200 * \" as size nodrop \n| parse \"GET * \" as url\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where content_type == \"text/css\"\n| extend src_IP = extract(\"^(\\S+)\", 1, ['id'])\n| extend size = toint(extract(\"(\\w+)\", 1, status))\n| extend url = extract(\"GET\", 0, method)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Null Literals in APL\nDESCRIPTION: This query returns a single row containing null values for various scalar data types in APL. It showcases how null values are represented for different data types using the D(null) syntax.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/null-values.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nprint bool(null), datetime(null), dynamic(null), int(null), long(null), real(null), double(null), time(null)\n```\n\n----------------------------------------\n\nTITLE: Using make_set for HTTP Log Analysis in APL\nDESCRIPTION: Example query using make_set to collect unique HTTP methods used by each user in log data, grouped by user ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize make_set(method) by id\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Dependencies with pip\nDESCRIPTION: Command to install required Python packages including OpenTelemetry SDK, Flask instrumentation, and OTLP exporter\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-python.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install opentelemetry-api opentelemetry-sdk opentelemetry-instrumentation-flask opentelemetry-exporter-otlp Flask\n```\n\n----------------------------------------\n\nTITLE: Using exp() Function in Kusto\nDESCRIPTION: The exp() function calculates the base-e exponential of x (e^x). It takes a real number as input and returns the exponential value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\nexp(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nexp(1) == 2.718281828459045\n```\n\n----------------------------------------\n\nTITLE: Converting IPv4 to Integer in SQL\nDESCRIPTION: This SQL example demonstrates how to convert an IPv4 address to an integer using bitwise operations, as SQL lacks a direct parse_ipv4 equivalent.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/parse-ipv4.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  (CAST(SPLIT_PART(ip, '.', 1) AS INT) << 24) +\n  (CAST(SPLIT_PART(ip, '.', 2) AS INT) << 16) +\n  (CAST(SPLIT_PART(ip, '.', 3) AS INT) << 8) +\n  CAST(SPLIT_PART(ip, '.', 4) AS INT) AS ip_int\nFROM logs;\n```\n\n----------------------------------------\n\nTITLE: Finding Highest Status Codes by Country\nDESCRIPTION: Query to identify the highest HTTP status code for each country in log data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-max.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize arg_max(toint(status), uri) by ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Split String Function in KQL\nDESCRIPTION: Demonstrates the split function that separates a string into an array using a delimiter. Shows splitting 'axiom_observability_monitoring' into array elements.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_20\n\nLANGUAGE: kusto\nCODE:\n```\nsplit(source, delimiter)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nproject split_str = split(\"axiom_observability_monitoring\", \"_\")\n```\n\n----------------------------------------\n\nTITLE: Substring Extraction in SQL and APL\nDESCRIPTION: Shows how to extract a portion of a string. Both SQL and APL extract the first 10 characters from the content_type field, with a slight difference in indexing (SQL starts at 1, APL at 0).\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SUBSTRING(content_type, 1, 10) AS ShortDescription\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ShortDescription = substring(content_type, 0, 10)\n```\n\n----------------------------------------\n\nTITLE: Extracting Nested Payment Amount from Custom Attributes in Kusto\nDESCRIPTION: This query extracts a nested payment amount from the custom attributes map field in the 'otel-demo-traces' dataset. It extends the result with the amount, filters for non-null amounts, and projects relevant fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_28\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| extend amount = ['attributes.custom']['app.payment.amount']\n| where isnotnull( amount)\n| project _time, trace_id, name, amount, ['attributes.custom']\n```\n\n----------------------------------------\n\nTITLE: Syntax for distinct Operator in APL\nDESCRIPTION: This snippet shows the general syntax for using the distinct operator in APL, allowing for multiple field names.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/distinct-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n| distinct FieldName1 [, FieldName2, ...]\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL mvfind with APL array_index_of\nDESCRIPTION: Comparison between Splunk SPL's mvfind function and APL's array_index_of function. Both retrieve the position of an element within an array, but APL uses zero-based indexing while SPL uses one-based indexing.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-index-of.mdx#2025-04-22_snippet_1\n\nLANGUAGE: splunk\nCODE:\n```\n| eval index=mvfind(array, \"value\")\n```\n\nLANGUAGE: kusto\nCODE:\n```\nlet index = array_index_of(array, 'value')\n```\n\n----------------------------------------\n\nTITLE: Multiple Indices Array Splitting in APL\nDESCRIPTION: Shows how to use array_split with multiple indices to divide an events array into three parts at indices 1 and 2, useful for dividing traces into fixed-size segments.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-split.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| where array_length(events) == 3\n| extend split_events = array_split(events, dynamic([1,2]))\n```\n\n----------------------------------------\n\nTITLE: Counting Pages by Source IP in Sumo Logic and APL\nDESCRIPTION: Demonstrates how to count pages associated with each source IP. Sumo Logic parses the source IP and counts by it, while APL extracts the source IP and uses summarize to count by source IP.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache \n| parse \"* -\" as src_ip \n| count by src_ip\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend src_ip = extract(\".*\", 0,  ['id'])\n| summarize Count = count() by src_ip\n```\n\n----------------------------------------\n\nTITLE: String Comparison Function in KQL\nDESCRIPTION: Shows the strcmp function that compares two strings and returns -1, 0, or 1 based on their lexicographical comparison.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_23\n\nLANGUAGE: kusto\nCODE:\n```\nstrcmp(string1, string2)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend cmp = strcmp( body, repo )\n```\n\nLANGUAGE: kusto\nCODE:\n```\nproject cmp = strcmp( \"axiom\", \"observability\")\n```\n\n----------------------------------------\n\nTITLE: Using minif in APL vs ANSI SQL\nDESCRIPTION: Comparison between ANSI SQL's MIN with CASE statement and the equivalent APL minif function for conditional minimum aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/minif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(CASE WHEN status = '200' THEN req_duration_ms ELSE NULL END) as min_duration\nFROM sample_http_logs\nGROUP BY id;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize minif(req_duration_ms, status == \"200\") by id\n```\n\n----------------------------------------\n\nTITLE: Finding Unique HTTP Status Codes in Security Logs using APL\nDESCRIPTION: This query uses the distinct operator to find unique HTTP status codes from security logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/distinct-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| distinct status\n```\n\n----------------------------------------\n\nTITLE: Logical NOT Operation with not() in Kusto\nDESCRIPTION: The not() function reverses the value of its boolean argument. It takes a boolean expression as input and returns the opposite logical value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_16\n\nLANGUAGE: kusto\nCODE:\n```\nnot(expr)\n```\n\n----------------------------------------\n\nTITLE: Trimming String Start with trim_start Function in Kusto\nDESCRIPTION: Illustrates the usage of trim_start function to remove specified characters from the beginning of a string. It takes a source string as an argument.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_31\n\nLANGUAGE: kusto\nCODE:\n```\ntrim_start(source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project remove_cutset = trim_start( \"github\", repo)\n```\n\n----------------------------------------\n\nTITLE: Comparing make_list_if in APL with Splunk SPL\nDESCRIPTION: This snippet compares the make_list_if function in APL with its equivalent in Splunk SPL. It demonstrates how to create conditional lists in both query languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list-if.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats list(field) as field_list by condition\n```\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize make_list_if(field, condition)\n```\n\n----------------------------------------\n\nTITLE: Selecting Fields in Splunk SPL and APL\nDESCRIPTION: Illustrates how to select specific fields in Splunk SPL using the 'fields' command and in APL using the 'project', 'project-away', or 'project-keep' operators.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nindex=main sourcetype=mySourceType\n| fields status, responseTime\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['myDataset'] \n| extend newName = oldName\n| project-away oldName\n```\n\n----------------------------------------\n\nTITLE: Conditional Global Term Search in APL\nDESCRIPTION: Shows a search that finds records containing \"jpeg\" AND either \"GET\" OR \"true\" in any field, demonstrating boolean operators with the search operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search \"jpeg\" and (\"GET\" or \"true\")\n```\n\n----------------------------------------\n\nTITLE: Syntax of pack_array Function in APL\nDESCRIPTION: This snippet shows the syntax of the pack_array function in APL. It takes multiple values as parameters and returns an array containing these values.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/pack-array.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\npack_array(value1, value2, ..., valueN)\n```\n\n----------------------------------------\n\nTITLE: Parsing JSON from HTTP Logs\nDESCRIPTION: This query extracts and parses JSON elements from the 'config_jsonified_metrics' field in the sample HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project parsed_json = parse_json( \"config_jsonified_metrics\")\n```\n\n----------------------------------------\n\nTITLE: Computing Standard Deviation in ANSI SQL and APL\nDESCRIPTION: This snippet shows how to calculate standard deviation in ANSI SQL and its equivalent in APL. It computes the standard deviation of a 'duration' field from a dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdev.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT STDDEV(duration) AS duration_std FROM dataset;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset']\n| summarize duration_std = stdev(duration)\n```\n\n----------------------------------------\n\nTITLE: AWS ADOT Lambda Layer ARN Configuration\nDESCRIPTION: ARN template for adding the ADOT Lambda layer to a function, requiring region, architecture, and version specification.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-lambda-dot.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\narn:aws:lambda:AWS_REGION:901920570463:layer:aws-otel-python-ARCH-VERSION\n```\n\n----------------------------------------\n\nTITLE: Creating New .NET Console Project\nDESCRIPTION: Command to create a new .NET console application named AxiomLogs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet new console -n AxiomLogs\n```\n\n----------------------------------------\n\nTITLE: Setting Axiom Environment Variables for AWS Lambda\nDESCRIPTION: This code snippet demonstrates how to set the required environment variables for the Axiom Lambda Extension. It includes the Axiom API token and dataset name.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-lambda.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nAXIOM_TOKEN: API_TOKEN\nAXIOM_DATASET: DATASET_NAME\n```\n\n----------------------------------------\n\nTITLE: Syntax for percentiles_array Function in APL\nDESCRIPTION: This snippet shows the syntax for using the percentiles_array function in APL, including the field and percentile parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-array.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\npercentiles_array(Field, Percentile1, Percentile2, ...)\n```\n\n----------------------------------------\n\nTITLE: Incident.io Integration Template JSON\nDESCRIPTION: Custom template formatted specifically for incident.io integration using monitor ID as deduplication key.\nSOURCE: https://github.com/axiomhq/docs/blob/main/monitor-data/custom-webhook-notifier.mdx#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"title\": \"{{.Title}}\",\n  \"description\": \"{{.Body}}\",\n  \"deduplication_key\": \"{{.MonitorID}}\",\n  \"status\": \"{{ if eq .Action \\\"Open\\\" }}firing{{ else }}resolved{{ end }}\",\n  \"metadata\": {\n    \"description\": \"{{.Description}}\",\n    \"value\": {{.Value}}\n  },\n  \"source_url\": \"https://app.axiom.co/{your-org-id-here}/monitors/{{.MonitorID}}\"\n}\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Analysis with arg_min\nDESCRIPTION: Query to find shortest duration spans per service with associated details.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-min.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize arg_min(duration, trace_id, span_id, kind) by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Counting Regex Matches in Kusto\nDESCRIPTION: Uses countof_regex() to count occurrences of patterns matching a regular expression within a string source.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\ncountof_regex(regex, text)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project count = countof_regex(\"c.n\", \"content_type\")\n```\n\n----------------------------------------\n\nTITLE: Filtering Windows NT User Agents\nDESCRIPTION: Query to find logs where user agent contains Windows NT version using regex pattern matching\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_18\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where tostring(user_agent) matches regex @\"Windows NT [\\d\\.]+\"\n```\n\n----------------------------------------\n\nTITLE: Normalizing HTTP Methods in Log Analysis\nDESCRIPTION: This example shows how to use extend-valid to normalize HTTP request methods by converting them to uppercase for valid entries in a log analysis scenario.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-valid-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend-valid upper_method = toupper(method)\n```\n\n----------------------------------------\n\nTITLE: APL arg_min Basic Syntax\nDESCRIPTION: Basic syntax example for using arg_min aggregation in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-min.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| summarize arg_min(expression, field1, ..., fieldN)\n```\n\n----------------------------------------\n\nTITLE: NGINX Configuration for Metrics Exposure\nDESCRIPTION: NGINX server configuration to expose metrics via the stub_status module. This creates an endpoint that Vector can scrape to collect NGINX metrics.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nlocation /metrics {\n  stub_status;\n  allow 127.0.0.1; # only allow requests from localhost\n  deny all; # deny all other hosts\n}\n```\n\n----------------------------------------\n\nTITLE: Using acos() Function in Kusto\nDESCRIPTION: Examples of using the acos() function to calculate arc cosine values. The function returns the angle whose cosine is the specified number, with a practical example showing the arc cosine of -1.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\nacos(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nacos(-1) == 3.141592653589793\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Client Instance\nDESCRIPTION: Setup of the main Axiom client instance with API token configuration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Axiom } from '@axiomhq/js';\n\nconst axiomClient = new Axiom({\n  token: process.env.NEXT_PUBLIC_AXIOM_TOKEN!,\n});\n\nexport default axiomClient;\n```\n\n----------------------------------------\n\nTITLE: String Repetition Function in KQL\nDESCRIPTION: Shows usage of strrep function to repeat a string a specified number of times with an optional delimiter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_25\n\nLANGUAGE: kusto\nCODE:\n```\nstrrep(value,multiplier,[delimiter])\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend repeat_string = strrep( repo, 5, \"::\" )\n```\n\nLANGUAGE: kusto\nCODE:\n```\nproject repeat_string = strrep( \"axiom\", 3, \"::\" )\n```\n\n----------------------------------------\n\nTITLE: Parsing HTTP Logs with Relaxed Mode - Query\nDESCRIPTION: Kusto query demonstrating the parse operator in relaxed mode to extract method, URL, status, and response time from HTTP request logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\n['HttpRequestLogs']\n| parse kind=relaxed log with method \" \" url \" \" status:int \" \" responseTime\n| project method, url, status, responseTime\n```\n\n----------------------------------------\n\nTITLE: Practical Example of array_rotate_left with Trace Data\nDESCRIPTION: Example query showing how to use array_rotate_left to rotate the events array in trace data by one position.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-left.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| extend rotated_sequence = array_rotate_left(events, 1)\n```\n\n----------------------------------------\n\nTITLE: Verifying Finite Values in Kusto\nDESCRIPTION: Demonstrates the usage of the isfinite() function to check if a given number is finite. The function returns true for finite numbers and false for infinite or NaN values.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_27\n\nLANGUAGE: kusto\nCODE:\n```\nisfinite(number)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nisfinite(25.563663) == true\n```\n\n----------------------------------------\n\nTITLE: Syntax of array_select_dict Function in APL\nDESCRIPTION: This snippet shows the syntax of the array_select_dict function in APL. It takes an array of dictionaries, a key, and a value as parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-select-dict.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\narray_select_dict(array, key, value)\n```\n\n----------------------------------------\n\nTITLE: URL Formatting with format_url()\nDESCRIPTION: Formats a dynamic object containing URL components into a properly formatted URL string. Supports scheme, host, path, port, fragment, user, and password components.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project formatted_url = format_url(dynamic({\"scheme\": \"https\", \"host\": \"github.com\", \"path\": \"/axiomhq/next-axiom\"})\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project formatted_url = format_url(dynamic({\"scheme\": \"https\", \"host\": \"github.com\", \"path\": \"/axiomhq/next-axiom\", \"port\": 443, \"fragment\": \"axiom\",\"user\": \"axiom\", \"password\": \"apl\"}))\n```\n\n----------------------------------------\n\nTITLE: Slicing Arrays in APL (Equivalent to ANSI SQL)\nDESCRIPTION: This snippet shows the APL equivalent of the ANSI SQL array slicing operation using the array_slice function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-slice.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\nT | extend sliced_array = array_slice(my_array, 1, 3)\n```\n\n----------------------------------------\n\nTITLE: Union with Aggregation in APL\nDESCRIPTION: This example combines datasets and summarizes the data, counting occurrences of each combination of 'content_type' and 'actor'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| union ['github-pull-request-event']\n| summarize Count = count() by content_type, actor\n```\n\n----------------------------------------\n\nTITLE: Slicing Arrays in APL (Equivalent to Splunk SPL)\nDESCRIPTION: This snippet shows the APL equivalent of the Splunk SPL array slicing operation using the array_slice function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-slice.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\nT | extend sliced_array = array_slice(my_array, 1, 3)\n```\n\n----------------------------------------\n\nTITLE: Converting Splunk SPL to APL for conditional sum\nDESCRIPTION: This code comparison shows how to convert a Splunk SPL query that uses stats with a where clause to the equivalent APL query using sumif for conditional sum aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sumif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats sum(duration) as total_duration where status=\"200\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize total_duration = sumif(duration, status == '200')\n```\n\n----------------------------------------\n\nTITLE: Consolidating Span Data with pack_array in APL\nDESCRIPTION: This example demonstrates how to use pack_array to create a summary of span data in a trace. It combines service name, kind, and duration into a single array field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/pack-array.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| extend span_summary = pack_array(['service.name'], kind, duration)\n```\n\n----------------------------------------\n\nTITLE: Next.js Configuration\nDESCRIPTION: Next.js configuration file with instrumentation and webpack settings\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nextjs.mdx#2025-04-22_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nmodule.exports = {\n  experimental: {\n    instrumentationHook: true,\n  },\n  webpack: (config, { isServer }) => {\n    if (!isServer) {\n      config.resolve.fallback = {\n        tls: false,\n      };\n    }\n    return config;\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Using hash_sha512() Function with Content Type Field in APL\nDESCRIPTION: Another example of the hash_sha512() function that demonstrates applying it to the content_type field from sample-http-logs, producing a different hash output.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/hash-functions.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project sha512_hash_value = hash_sha512(content_type)\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"sha512_hash_value\": \"95c6eacdd41170b129c3c287cfe088d4fafea34e371422b94eb78b9653a89d4132af33ef39dd6b3d80e18c33b21ae167ec9e9c2d820860689c647ffb725498c4\"\n}\n```\n\n----------------------------------------\n\nTITLE: APL Top Operator Syntax\nDESCRIPTION: This snippet shows the formal syntax for using the top operator in APL. It demonstrates how to specify the number of rows to return and the expression to sort by, with an optional parameter for ascending or descending order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/top-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| top N by Expression [asc | desc]\n```\n\n----------------------------------------\n\nTITLE: Formatting Parsed SQL Query in APL\nDESCRIPTION: Demonstrates how to use format_sql() to convert a parsed SQL model back into a formatted SQL string.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\nhn\n| extend parsed = parse_sql(\"SELECT * FROM db\")\n| project formatted_sql = format_sql(parsed)\n```\n\n----------------------------------------\n\nTITLE: Computing Square Root with sqrt() in Kusto\nDESCRIPTION: The sqrt() function calculates the square root of a number. It takes a real number as input and returns its square root.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_23\n\nLANGUAGE: kusto\nCODE:\n```\nsqrt(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nsqrt(25.563663) == 5.0560521160288685\n```\n\n----------------------------------------\n\nTITLE: Converting to DateTime in APL\nDESCRIPTION: The todatetime() function converts input to a datetime scalar. If conversion is successful, it returns a datetime value; otherwise, it returns false.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ntodatetime(Expr)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntodatetime(\"2022-11-13\")\n```\n\n----------------------------------------\n\nTITLE: Parsing URL Query Strings in APL\nDESCRIPTION: The parse_urlquery function returns a dynamic object containing the query parameters from a URL query string. It extracts key-value pairs from the query string.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_14\n\nLANGUAGE: kusto\nCODE:\n```\nparse_urlquery(\"a1=b1&a2=b2&a3=b3\")\n```\n\nLANGUAGE: kusto\nCODE:\n```\nparse_urlquery(query)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project parsed = parse_urlquery(\"https://play.axiom.co/axiom-play-qf1k/query?qid=fUKgiQgLjKE-rd7wjy\")\n```\n\n----------------------------------------\n\nTITLE: Checking CIDR Matches in Splunk SPL vs. has_ipv4_prefix in APL\nDESCRIPTION: Comparison between Splunk SPL's cidrmatch function and APL's has_ipv4_prefix function for checking IP address prefixes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-ipv4-prefix.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval is_match = if(cidrmatch(\"192.168.0.0/24\", ip), true, false)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where has_ipv4_prefix(uri, \"192.168.0\")\n```\n\n----------------------------------------\n\nTITLE: Querying HTTP Logs with Axiom Advanced Query Language\nDESCRIPTION: A Kusto query that projects specific fields (method, status, and content_type) from the sample-http-logs dataset for log stream visualization.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/log-stream.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project method, status, content_type\n```\n\n----------------------------------------\n\nTITLE: APL Query Examples using cURL\nDESCRIPTION: Collection of cURL commands demonstrating various APL queries for different use cases\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/query.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/_apl?format=tabular' \\\n-H 'Authorization: Bearer API_TOKEN' \\\n-H 'Accept: application/json' \\\n-H 'Accept-Encoding: gzip' \\\n-H 'Content-Type: application/json' \\\n-d '{\n      \"apl\": \"[\\\"sample-http-logs\\\"] | summarize percentile(todouble(req_duration_ms), 95) by server_datacenter\",\n      \"startTime\": \"2023-08-15T00:00:00Z\",\n      \"endTime\": \"2023-08-22T00:00:00Z\"\n    }'\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Dependencies for Django\nDESCRIPTION: This command installs the necessary Python packages for integrating OpenTelemetry with Django, including the OTLP exporter and Django instrumentation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install django opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp-proto-http opentelemetry-instrumentation-django\n```\n\n----------------------------------------\n\nTITLE: Computing Base-10 Exponential in Kusto\nDESCRIPTION: Shows how to use the exp10() function to calculate the base-10 exponential of a given value. The function takes a real number as the exponent and returns 10 raised to that power.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_25\n\nLANGUAGE: kusto\nCODE:\n```\nexp10(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nexp10(25.563663) == 36,615,333,994,520,800,000,000,000\n```\n\n----------------------------------------\n\nTITLE: Counting Unique Trace IDs in OpenTelemetry Data\nDESCRIPTION: An example query that counts distinct trace IDs in OpenTelemetry trace data. This helps determine how many unique traces are being captured in the telemetry system.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcount.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize dcount(trace_id)\n```\n\n----------------------------------------\n\nTITLE: has_ipv4 Example in APL\nDESCRIPTION: Demonstrates a practical use case of the has_ipv4 function for identifying requests from a specific IP address in HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-ipv4.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend has_ip = has_ipv4('Requests from: 192.168.1.1, 10.1.1.115.', '192.168.1.1')\n```\n\n----------------------------------------\n\nTITLE: Syntax for ipv4_is_match Function in APL\nDESCRIPTION: This snippet shows the syntax for the ipv4_is_match function in APL. It takes two IP addresses as strings and an optional prefix length as parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-match.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nipv4_is_match(ipaddress1, ipaddress2, prefix)\n```\n\n----------------------------------------\n\nTITLE: Implementing Log4j Logger with Multiple Event Types in Java\nDESCRIPTION: A comprehensive Java application demonstrating Log4j implementation with multiple loggers for different purposes (security, performance, general logging). Features include dynamic log level configuration, thread context management, and simulation of various logging scenarios including user activity, database operations, security events, and performance metrics.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-apache-log4j.mdx#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npackage com.example;\n\nimport org.apache.logging.log4j.LogManager;\nimport org.apache.logging.log4j.Logger;\nimport org.apache.logging.log4j.ThreadContext;\nimport org.apache.logging.log4j.core.config.Configurator;\nimport org.apache.logging.log4j.Level;\n\nimport java.util.Random;\n\npublic class App {\n    // Define loggers for different purposes\n    private static final Logger logger = LogManager.getLogger(App.class);\n    private static final Logger securityLogger = LogManager.getLogger(\"SecurityLogger\");\n    private static final Logger performanceLogger = LogManager.getLogger(\"PerformanceLogger\");\n\n    public static void main(String[] args) {\n        // Configure logging levels programmatically\n        configureLogging();\n\n        Random random = new Random();\n\n        // Infinite loop to continuously generate log events\n        while (true) {\n            try {\n                // Simulate various logging scenarios\n                simulateUserActivity(random);\n                simulateDatabaseOperations(random);\n                simulateSecurityEvents(random);\n                simulatePerformanceMetrics(random);\n\n                // Simulate a critical error with 10% probability\n                if (random.nextInt(10) == 0) {\n                    throw new RuntimeException(\"Simulated critical error\");\n                }\n\n                Thread.sleep(1000);  // Sleep for 1 second\n            } catch (InterruptedException e) {\n                logger.warn(\"Sleep interrupted\", e);\n            } catch (Exception e) {\n                logger.error(\"Critical error occurred\", e);\n            } finally {\n                // Clear thread context after each iteration\n                ThreadContext.clearAll();\n            }\n        }\n    }\n\n    private static void configureLogging() {\n        // Set root logger level to DEBUG\n        Configurator.setRootLevel(Level.DEBUG);\n\n        // Set custom logger levels\n        Configurator.setLevel(\"SecurityLogger\", Level.INFO);\n        Configurator.setLevel(\"PerformanceLogger\", Level.TRACE);\n    }\n\n    // Simulate user activities and log them\n    private static void simulateUserActivity(Random random) {\n        String[] users = {\"Alice\", \"Bob\", \"Charlie\", \"David\"};\n        String[] actions = {\"login\", \"logout\", \"view_profile\", \"update_settings\"};\n\n        String user = users[random.nextInt(users.length)];\n        String action = actions[random.nextInt(actions.length)];\n\n        // Add user and action to thread context\n        ThreadContext.put(\"user\", user);\n        ThreadContext.put(\"action\", action);\n\n        // Log different user actions with appropriate levels\n        switch (action) {\n            case \"login\":\n                logger.info(\"User logged in successfully\");\n                break;\n            case \"logout\":\n                logger.info(\"User logged out\");\n                break;\n            case \"view_profile\":\n                logger.debug(\"User viewed their profile\");\n                break;\n            case \"update_settings\":\n                logger.info(\"User updated their settings\");\n                break;\n        }\n    }\n\n    // Simulate database operations and log them\n    private static void simulateDatabaseOperations(Random random) {\n        String[] operations = {\"select\", \"insert\", \"update\", \"delete\"};\n        String operation = operations[random.nextInt(operations.length)];\n        long duration = random.nextInt(1000);\n\n        // Add operation and duration to thread context\n        ThreadContext.put(\"operation\", operation);\n        ThreadContext.put(\"duration\", String.valueOf(duration));\n\n        // Log slow database operations as warnings\n        if (duration > 500) {\n            logger.warn(\"Slow database operation detected\");\n        } else {\n            logger.debug(\"Database operation completed\");\n        }\n\n        // Simulate database connection loss with 5% probability\n        if (random.nextInt(20) == 0) {\n            logger.error(\"Database connection lost\", new SQLException(\"Connection timed out\"));\n        }\n    }\n\n    // Simulate security events and log them\n    private static void simulateSecurityEvents(Random random) {\n        String[] events = {\"failed_login\", \"password_change\", \"role_change\", \"suspicious_activity\"};\n        String event = events[random.nextInt(events.length)];\n\n        ThreadContext.put(\"security_event\", event);\n\n        // Log different security events with appropriate levels\n        switch (event) {\n            case \"failed_login\":\n                securityLogger.warn(\"Failed login attempt\");\n                break;\n            case \"password_change\":\n                securityLogger.info(\"User changed their password\");\n                break;\n            case \"role_change\":\n                securityLogger.info(\"User role was modified\");\n                break;\n            case \"suspicious_activity\":\n                securityLogger.error(\"Suspicious activity detected\", new SecurityException(\"Potential breach attempt\"));\n                break;\n        }\n    }\n\n    // Simulate performance metrics and log them\n    private static void simulatePerformanceMetrics(Random random) {\n        String[] metrics = {\"cpu_usage\", \"memory_usage\", \"disk_io\", \"network_latency\"};\n        String metric = metrics[random.nextInt(metrics.length)];\n        double value = random.nextDouble() * 100;\n\n        // Add metric and value to thread context\n        ThreadContext.put(\"metric\", metric);\n        ThreadContext.put(\"value\", String.format(\"%.2f\", value));\n\n        // Log high resource usage as warnings\n        if (value > 80) {\n            performanceLogger.warn(\"High resource usage detected\");\n        } else {\n            performanceLogger.trace(\"Performance metric recorded\");\n        }\n    }\n\n    // Custom exception classes for simulating errors\n    private static class SQLException extends Exception {\n        public SQLException(String message) {\n            super(message);\n        }\n    }\n\n    private static class SecurityException extends Exception {\n        public SecurityException(String message) {\n            super(message);\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Dynamic type literals in APL\nDESCRIPTION: Examples of dynamic type literals in APL, which can hold values of various types including primitives, arrays, and property bags.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/scalar-data-types.mdx#2025-04-22_snippet_2\n\nLANGUAGE: apl\nCODE:\n```\ndynamic(null)\ndynamic(6)\ndynamic([3, 4, \"bye\"])\ndynamic({\"a\":1, \"b\":{\"a\":2}})\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL fieldsummary with APL getschema\nDESCRIPTION: This snippet compares the Splunk SPL fieldsummary command with the APL getschema operator. While fieldsummary provides additional summary statistics, getschema focuses specifically on returning field names and types.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/getschema-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n| fieldsummary\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| getschema\n```\n\n----------------------------------------\n\nTITLE: Concatenating Strings with Delimiter in HTTP Logs\nDESCRIPTION: This query concatenates the 'geo.city' and 'resp_body_size_bytes' fields with a colon delimiter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_12\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project strcat = strcat_delim(\":\", ['geo.city'], resp_body_size_bytes)\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL and APL Array Operations\nDESCRIPTION: Contrasts ANSI SQL's lack of built-in array splitting functions with APL's native array_split capability, showing how array operations are handled differently in each language.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-split.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- SQL typically requires custom functions or JSON manipulation.\nSELECT * FROM dataset WHERE JSON_ARRAY_LENGTH(array_field) > 0;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| extend split_array = array_split(events, 2)\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL INFORMATION_SCHEMA with APL getschema\nDESCRIPTION: This snippet compares retrieving schema information using ANSI SQL INFORMATION_SCHEMA queries with the APL getschema operator. APL's approach is more straightforward and doesn't require system views.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/getschema-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COLUMN_NAME, DATA_TYPE FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'sample_http_logs';\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| getschema\n```\n\n----------------------------------------\n\nTITLE: Combining Span and Trace IDs in OpenTelemetry Traces\nDESCRIPTION: Demonstrates using array_concat to join span IDs and trace IDs from OpenTelemetry trace data for comprehensive analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-concat.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| take 50\n| summarize combined_ids = array_concat(pack_array(span_id), pack_array(trace_id))\n```\n\n----------------------------------------\n\nTITLE: Using Wildcards with Project-Reorder to Sort All Fields\nDESCRIPTION: An example showing how to use wildcards with project-reorder to sort all fields in ascending order. This query demonstrates the flexibility of wildcard patterns in APL field ordering.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| project-reorder * asc\n```\n\n----------------------------------------\n\nTITLE: Using bin_auto() Function with Time Data in APL\nDESCRIPTION: The bin_auto() function rounds values down to a fixed-size bin and is specifically designed to be used with the summarize operator on the _time column. It automatically determines appropriate bin sizes based on query properties.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/rounding-functions.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize count() by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Result of Single Index Array Split Operation\nDESCRIPTION: Displays the result of splitting the events array at index 2, showing how the original array is divided into two subarrays - one with the first two elements and one with the third element.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-split.mdx#2025-04-22_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n[\n  [\n    {\n      \"timestamp\": 1734033733465219300,\n      \"name\": \"Enqueued\"\n    },\n    {\n      \"name\": \"Sent\",\n      \"timestamp\": 1734033733465228500\n    }\n  ],\n  [\n    {\n      \"timestamp\": 1734033733465455900,\n      \"name\": \"ResponseReceived\"\n    }\n  ]\n]\n```\n\n----------------------------------------\n\nTITLE: Reordering with Wildcards and Sorting in Descending Order\nDESCRIPTION: An example showing how to reorder fields using wildcards and sort in descending order. This query demonstrates using patterns to match multiple fields and apply specific sorting.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['github-push-event'] \n| project-reorder repo*, num_commits, push_id, ref, size, ['id'], size_large desc \n```\n\n----------------------------------------\n\nTITLE: Basic APL min Function Syntax\nDESCRIPTION: Shows the basic syntax for using the min aggregation function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/min.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize min(Expression)\n```\n\n----------------------------------------\n\nTITLE: Installing Serilog Packages\nDESCRIPTION: Commands to install Serilog and its required extensions for the alternative logging implementation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Serilog\ndotnet add package Serilog.Sinks.Console\ndotnet add package Serilog.Sinks.Http\ndotnet add package Serilog.Formatting.Elasticsearch\ndotnet add package Microsoft.Extensions.Configuration\n```\n\n----------------------------------------\n\nTITLE: Calculating Start of Year in Axiom Query Language\nDESCRIPTION: The startofyear() function returns the start of the year containing the given date. It sets the month to January, day to 1st, and time to 00:00:00, useful for yearly aggregations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_19\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project yearStart = startofyear(datetime(2019-04-03))\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project yearStart = startofyear(datetime(2019-10-09 01:00:00.0000000))\n```\n\n----------------------------------------\n\nTITLE: Multiple Terms Search Query in Axiom\nDESCRIPTION: Illustrates how to search for multiple independent terms using the OR operator. This query finds logs containing either 'GET' or 'covina' in any field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_12\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search \"GET\" or \"covina\"\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL ARRAY_AGG with APL make_list\nDESCRIPTION: Example showing how to use ARRAY_AGG in SQL compared to make_list in APL to aggregate URI values by ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ARRAY_AGG(uri) AS uris FROM sample_http_logs GROUP BY id;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize uris=make_list(uri) by id\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL COUNT DISTINCT with APL dcount\nDESCRIPTION: Comparison between SQL's COUNT DISTINCT and APL's dcount function. SQL uses COUNT(DISTINCT column) while APL uses the summarize operation with dcount().\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcount.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(DISTINCT user_id) AS distinct_users\nFROM sample_http_logs\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize dcount(id)\n```\n\n----------------------------------------\n\nTITLE: Array_iff Syntax in APL\nDESCRIPTION: The basic syntax for the array_iff function in Axiom Processing Language, showing the function call with its three required parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-iff.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\narray_iff(condition_array, array1, array2)\n```\n\n----------------------------------------\n\nTITLE: Creating a User in Axiom with Terraform\nDESCRIPTION: This snippet shows how to create a user in Axiom using Terraform. It specifies the user's name, email, and role.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_6\n\nLANGUAGE: hcl\nCODE:\n```\nresource \"axiom_user\" \"test_user\" {\n  name  = \"test_user\"\n  email = \"test@abc.com\"\n  role  = \"user\"\n}\n```\n\n----------------------------------------\n\nTITLE: APL Expression Examples\nDESCRIPTION: Examples demonstrating various APL expressions and operators for virtual fields, including array access, closures, and filters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/virtual-fields.mdx#2025-04-22_snippet_0\n\nLANGUAGE: apl\nCODE:\n```\nall(comments, {.Size < 280})\n```\n\nLANGUAGE: apl\nCODE:\n```\none(repos, {.private})\n```\n\nLANGUAGE: apl\nCODE:\n```\nmap(0..9, {# / 2})\n```\n\nLANGUAGE: apl\nCODE:\n```\nfilter(comments, {len(.body) > 280})\n```\n\nLANGUAGE: apl\nCODE:\n```\nnot (\"us-east-1\" contains \"us\")\n```\n\nLANGUAGE: apl\nCODE:\n```\nmetadata.region in [\"us-east-1\", \"us-east-2\"]\n```\n\nLANGUAGE: apl\nCODE:\n```\nmyArray[1:5] == [2, 3, 4] myArray[3:] == [4, 5] myArray[:4] == [1, 2, 3] myArray[:] == myArray\n```\n\n----------------------------------------\n\nTITLE: Determining Sign of a Number with sign() in Kusto\nDESCRIPTION: The sign() function returns the sign of a numeric expression. It takes a real number as input and returns +1 for positive, 0 for zero, and -1 for negative values.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_21\n\nLANGUAGE: kusto\nCODE:\n```\nsign(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nsign(25.563663) == 1\n```\n\n----------------------------------------\n\nTITLE: Counting Unique Values After Union in APL\nDESCRIPTION: Shows how to combine two datasets and count unique values for geo.city and repo fields. The query uses dcount to calculate distinct counts from the combined sample-http-logs and github-push-event data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_12\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| union ['github-push-event']\n| summarize UniqueNames = dcount(['geo.city']), UniqueData = dcount(repo)\n```\n\n----------------------------------------\n\nTITLE: APL IPv4 Range Check Function Syntax\nDESCRIPTION: Basic syntax example of the ipv4_is_in_range function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-in-range.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nipv4_is_in_range(ip: string, range: string)\n```\n\n----------------------------------------\n\nTITLE: Extracting Geolocation Information from IPv6 Address\nDESCRIPTION: Example showing how to extract geolocation information from an IPv6 address using the geo_info_from_ip_address function and extending the dataset with the result.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip_location = geo_info_from_ip_address('2607:f8b0:4005:805::200e')\n```\n\n----------------------------------------\n\nTITLE: Using varianceif for Geolocation-based Analysis in Security Logs\nDESCRIPTION: Example showing how to calculate the variance in request durations specifically for requests originating from the United States.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/varianceif.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize varianceif(req_duration_ms, ['geo.country'] == 'United States')\n```\n\n----------------------------------------\n\nTITLE: Using parse_pair() Function in Kusto\nDESCRIPTION: Parses a string to form a pair with a custom separator. This example extracts key and value from a string.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/pair-functions.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nparse_pair(\"key.value\", \".\")\n```\n\n----------------------------------------\n\nTITLE: Parsing and Formatting Complex SQL Query in APL\nDESCRIPTION: Shows the process of parsing a more complex SQL query with multiple clauses and then formatting it back into a SQL string.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\nhn \n| extend parsed = parse_sql(\"SELECT name, registration_date FROM users ORDER BY registration_date DESC\")\n| project format_sql(parsed)\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis with project-away in APL\nDESCRIPTION: Using project-away in security log analysis to exclude unnecessary fields such as HTTP method or URI and focus on user behavior patterns and request durations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-away-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project-away method, uri\n```\n\n----------------------------------------\n\nTITLE: Building and Running Application Commands\nDESCRIPTION: Series of Maven and Java commands to build and run the instrumented application.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmvn clean\n```\n\nLANGUAGE: bash\nCODE:\n```\nmvn compile\n```\n\nLANGUAGE: bash\nCODE:\n```\nmvn package\n```\n\nLANGUAGE: bash\nCODE:\n```\njava -jar target/axiom-otel-java-1.0-SNAPSHOT.jar\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Parsing\nDESCRIPTION: Demonstrates parsing service names from OpenTelemetry trace IDs using the parse operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| parse trace_id with * '-' ['service.name']\n| project _time, ['service.name'], trace_id\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL min Function with APL Equivalent\nDESCRIPTION: Shows how to use min function in Splunk SPL and its equivalent in APL for finding minimum values grouped by ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/min.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats min(duration) by id\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize min(req_duration_ms) by id\n```\n\n----------------------------------------\n\nTITLE: Installing NLog Packages via .NET CLI\nDESCRIPTION: Commands for installing NLog and related packages using the .NET CLI.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package NLog\ndotnet add package NLog.Web.AspNetCore\ndotnet add package NLog.Targets.Http\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL Table Command with APL Project\nDESCRIPTION: Compares Splunk's table command with the equivalent project operator in APL. Both commands select specific fields from the dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n| table _time, status, uri\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project _time, status, uri\n```\n\n----------------------------------------\n\nTITLE: Computing Average HTTP Response Size in Sumo Logic and APL\nDESCRIPTION: Calculates the average size of successful HTTP responses. Sumo Logic filters by source category and uses avg function, while APL extracts numeric values and uses the summarize operator with avg function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache \n| parse \" 200 * \" as size \n| avg(size)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend number = todouble(extract(\"\\d+(\\.\\d+)?\", 0, status))\n| summarize Average = avg(number)\n```\n\n----------------------------------------\n\nTITLE: Creating Dependent City Filter Based on Country Selection in Axiom\nDESCRIPTION: This APL query defines a dependent filter for cities based on the selected country. It uses query parameters to reference the country filter and retrieves distinct city values for the chosen country.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/filters.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\ndeclare query_parameters (country_filter:string = \"\");\n['sample-http-logs'] \n| where isnotempty(['geo.country']) and isnotempty(['geo.city'])\n| where ['geo.country'] == country_filter\n| summarize count() by ['geo.city']\n| project key = ['geo.city'], value = ['geo.city']\n| sort by key asc\n```\n\n----------------------------------------\n\nTITLE: Using dayofweek() function in Kusto/APL\nDESCRIPTION: The dayofweek() function returns the integer number of days since the preceding Sunday, as a timespan. It takes a_date (datetime) as an argument and returns the timespan since midnight of the preceding Sunday.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\ndayofweek(a_date)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project day_of_the_week = dayofweek(datetime(2019-05-18))\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"day_of_the_week\": 6\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Standard Deviation of Request Durations for Successful HTTP Requests\nDESCRIPTION: Calculates the standard deviation of request durations only for HTTP requests with a 200 status code, grouped by country. This demonstrates using stdevif for conditional aggregation in log analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdevif.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize stdevif(req_duration_ms, status == '200') by ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Calculating Variance in SQL vs APL\nDESCRIPTION: A comparison of how to calculate variance in ANSI SQL using VAR_POP and the equivalent approach in APL using the variance function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/variance.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VAR_POP(req_duration_ms) FROM sample_http_logs;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize variance(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Field Selection with project-keep in APL vs Splunk SPL\nDESCRIPTION: Comparison between Splunk SPL's table command and APL's project-keep operator for selecting specific fields from a dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-keep-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: splunk\nCODE:\n```\nindex=main | table _time, status, uri\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| project-keep _time, status, uri\n```\n\n----------------------------------------\n\nTITLE: APL Sort with Project\nDESCRIPTION: Example of combining project and sort operators while maintaining required fields for sorting.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sort-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: apl\nCODE:\n```\n['sample-http-logs']\n| project status, _time\n| sort by _time desc\n```\n\n----------------------------------------\n\nTITLE: Basic Searching in Splunk SPL and APL\nDESCRIPTION: Demonstrates the difference in basic searching between Splunk SPL and APL. Splunk uses the 'search' command, while APL specifies the dataset name followed by a filter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsearch index=\"myIndex\" error\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['myDatasaet']\n| where FieldName contains \"error\"\n```\n\n----------------------------------------\n\nTITLE: Using asin() Function in Kusto\nDESCRIPTION: Example of using the asin() function to calculate arc sine values. The function returns the angle whose sine is the specified number, demonstrated with a query against sample-http-logs calculating the arc sine of -1.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nasin(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project inverse_sin_angle = asin(-1)\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with Redact\nDESCRIPTION: Example of using redact to sanitize HTTP logs by obfuscating geographical data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/redact-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| redact replaceToken=\"x\" @'.*' on ['geo.city'], ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Time Frames in Splunk SPL and APL\nDESCRIPTION: Demonstrates how to specify time frames in Splunk SPL using the 'earliest' and 'latest' parameters, and in APL using the 'where' operator with time functions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsearch index=\"myIndex\" earliest=-1d@d latest=now\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['myDataset']\n| where _time >= ago(1d) and _time <= now()\n```\n\n----------------------------------------\n\nTITLE: Timespan literals in APL\nDESCRIPTION: Examples of timespan literals in APL, showing different time interval representations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/scalar-data-types.mdx#2025-04-22_snippet_7\n\nLANGUAGE: apl\nCODE:\n```\n2d\n1.5h\n30m\n10s\ntimespan(15s)\n0.1s\ntimespan(2d)\n```\n\n----------------------------------------\n\nTITLE: Initializing Go Module\nDESCRIPTION: Command to initialize a new Go module for the project, creating a go.mod file for dependency management.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngo mod init <module-name>\n```\n\n----------------------------------------\n\nTITLE: Creating a Monitor in Axiom with Terraform\nDESCRIPTION: This snippet demonstrates how to create a monitor in Axiom using Terraform. It includes various configuration options for different monitor types and alert conditions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_5\n\nLANGUAGE: hcl\nCODE:\n```\nresource \"axiom_monitor\" \"test_monitor\" {\n  depends_on       = [axiom_dataset.test_dataset, axiom_notifier.test_slack_notifier]\n\n  type             = \"Threshold\"\n\n  name             = \"test_monitor\"\n  description      = \"This is a test monitor created by Terraform.\"\n  apl_query        = \"['test_dataset'] | summarize count() by bin_auto(_time)\"\n  interval_minutes = 5\n  \n  operator         = \"Above\"\n\n  range_minutes    = 5\n\n  threshold        = 1\n\n  notifier_ids = [\n    axiom_notifier.test_slack_notifier.id\n  ]\n  alert_on_no_data = false\n  notify_by_group  = false\n}\n```\n\n----------------------------------------\n\nTITLE: Computing Log of Gamma Function with loggamma() in Kusto\nDESCRIPTION: The loggamma() function computes the natural logarithm of the absolute value of the gamma function of x. It takes a real number as input and returns the log-gamma value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_15\n\nLANGUAGE: kusto\nCODE:\n```\nloggamma(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nloggamma(16) == 27.89927138384089\n```\n\n----------------------------------------\n\nTITLE: Using Comparison Operators in APL\nDESCRIPTION: Examples of comparison operations between numerical values and time units in APL, including less than, greater than, equals, not equals, and equality with collections.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-operators/numerical-operators.mdx#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n`1 < 2`, `1 <= 1`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`0.23 > 0.22`, `10min > 1sec`, `now() > ago(1d)`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`3 == 3`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`2 != 1`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`5 <= 6`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`7 >= 6`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`\"abc\" in (\"123\", \"345\", \"abc\")`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`\"bca\" !in (\"123\", \"345\", \"abc\")`\n```\n\n----------------------------------------\n\nTITLE: Using Clone Filter in Logstash\nDESCRIPTION: Example showing how to use the Clone filter plugin to create copies of events in the pipeline.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/logstash.mdx#2025-04-22_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\ninput {\n  syslog {\n    port => 5140\n    type => syslog\n  }\n}\n\nfilter {\n  clone {\n    clones => [\"cloned_event\"]\n  }\n}\n\noutput{\n  opensearch{\n    hosts => [\"https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic\"]\n    user => \"axiom\"\n    password => \"API_TOKEN\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Concatenating Arrays in ANSI SQL and APL\nDESCRIPTION: Shows how to concatenate arrays using UNION in ANSI SQL and the equivalent operation using array_concat in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-concat.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT array1 UNION ALL array2 UNION ALL array3\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| extend combined_array = array_concat(array1, array2, array3)\n```\n\n----------------------------------------\n\nTITLE: Creating and Managing Spans in Cloudflare Workers\nDESCRIPTION: Example of manually creating and managing spans in a Cloudflare Workers script for tracing operations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nconst span = tracer.startSpan('operationName');\ntry {\n  // Your operation code here\n} finally {\n  span.end();\n}\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL with APL percentileif Syntax\nDESCRIPTION: Shows how to convert an ANSI SQL percentile calculation with WHERE clause to APL's percentileif function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentileif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY req_duration_ms)\nFROM sample_http_logs\nWHERE geo_country = 'US'\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentileif(req_duration_ms, 95, geo.country == 'US')\n```\n\n----------------------------------------\n\nTITLE: Defining format_ipv4 Function Syntax in APL\nDESCRIPTION: Shows the basic syntax for the format_ipv4 function in APL, which accepts a numeric IPv4 address parameter and returns the dotted-decimal string representation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/format-ipv4.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nformat_ipv4(ipv4address)\n```\n\n----------------------------------------\n\nTITLE: Formatting Bytes with format_bytes()\nDESCRIPTION: Formats numeric byte values into human-readable strings with customizable precision, units and base. Supports both base-2 and base-10 unit prefixes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\nformat_bytes( 4000, number, \"['id']\", num_comments ) == \"3.9062500000000 KB\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\nformat_bytes(1024) == \"1 KB\"\n\nformat_bytes(8000000, 2, \"MB\", 10) == \"8.00 MB\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project formated_bytes =  format_bytes( 4783549035, number, \"['id']\", num_comments  )\n```\n\n----------------------------------------\n\nTITLE: Building and Running Node.js Application in Production\nDESCRIPTION: Commands to build TypeScript files and start the application in production mode.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\nnpm start\n```\n\n----------------------------------------\n\nTITLE: Rotating Arrays in Splunk SPL vs APL\nDESCRIPTION: Comparison between Splunk SPL approach to rotating array elements and the APL equivalent using array_rotate_left function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-left.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval rotated_array = mvindex(array, 1) . \",\" . mvindex(array, 0)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nprint rotated_array = array_rotate_left(dynamic([1,2,3,4]), 1)\n```\n\n----------------------------------------\n\nTITLE: Example Employee Lookup Table in CSV Format\nDESCRIPTION: A sample CSV format lookup table containing employee information that can be used with the externaldata operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/externaldata-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: csv\nCODE:\n```\nemployeeID, email, name, location\n00001, tifa@acme.com, Tifa Lockhart, US\n00002, barret@acme.com, Barret Wallace, Europe\n00003, cid@acme.com, Cid Highwind, Europe\n```\n\n----------------------------------------\n\nTITLE: Converting IPv4 to Integer in Splunk SPL\nDESCRIPTION: This snippet demonstrates how to convert an IPv4 address to an integer in Splunk SPL, as there's no direct equivalent to APL's parse_ipv4 function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/parse-ipv4.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval ip_int = tonumber(replace(ip, \"\\\\.\" , \"\"))\n```\n\n----------------------------------------\n\nTITLE: Using dayofyear() function in Kusto/APL\nDESCRIPTION: The dayofyear() function returns the integer representing the day number of the given year. It takes a_date (datetime) as an argument and returns the day number of the given year.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\ndayofyear(a_date)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project day_of_the_year = dayofyear(datetime(2020-07-20))\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"day_of_the_year\": 202\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Year from DateTime in Axiom Query Language\nDESCRIPTION: The getyear() function returns the year part of the datetime argument. It's commonly used for grouping or filtering data by year.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\ngetyear(datetime())\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project get_specific_year = getyear(datetime(2020-07-26))\n```\n\n----------------------------------------\n\nTITLE: Trimming String End with trim_end Function in Kusto\nDESCRIPTION: Demonstrates the usage of trim_end function to remove specified characters from the end of a string. It takes a source string and a cutset string as arguments.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_29\n\nLANGUAGE: kusto\nCODE:\n```\ntrim_end(source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend remove_cutset = trim_end(@\"[^\\w]+\", body)\n```\n\n----------------------------------------\n\nTITLE: Sample Operator Syntax in APL\nDESCRIPTION: The basic syntax of the APL sample operator which takes a ProportionOfRows parameter to randomly select that fraction of rows from the input dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sample-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| sample ProportionOfRows\n```\n\n----------------------------------------\n\nTITLE: Paginating Query Results with Cursor in Axiom API (Current Endpoint)\nDESCRIPTION: This snippet shows how to make a POST request to the current Axiom API endpoint for running queries with pagination. It uses a cursor to retrieve the next page of results, along with specifying the query, time range, and output format.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/pagination.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/_apl?format=tabular' \\\n-H 'Authorization: Bearer API_TOKEN' \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"apl\": \"dataset | sort by _time desc | limit 100\",\n    \"startTime\": \"2024-01-01T00:00:00.000Z\",\n    \"endTime\": \"2024-01-31T23:59:59.999Z\",\n    \"cursor\": \"0d3wo7v7e1oii-075a8c41710018b9-0000ecc5\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Parsing HTTP Logs with Relaxed Mode - Input Example\nDESCRIPTION: Example of HTTP request log entries that will be parsed using relaxed mode, showing different HTTP methods, URLs, status codes, and response times.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nGET /home 200 123ms\nPOST /login 500 nonValidResponseTime\nPUT /api/data 201 456ms\nDELETE /user/123 404 nonValidResponseTime\n```\n\n----------------------------------------\n\nTITLE: Using String Equality and Set Membership Operators in Kusto\nDESCRIPTION: Examples of string equality and set membership operators including exact match comparisons and checking if a value exists within a set of values. These operators include ==, !=, =~, !~, in, !in, in~, and !in~.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-operators/string-operators.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n\"get\" == \"get\"\n\"get\" != \"GET\"\n\"get\" =~ \"GET\"\n\"get\" !~ \"put\"\n\"get\" in (\"get\", \"put\", \"delete\")\n```\n\n----------------------------------------\n\nTITLE: Sorting in Splunk SPL and APL\nDESCRIPTION: Shows how sorting is performed in Splunk SPL using the 'sort' command and in APL using the 'sort by' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsearch index=\"myIndex\" \n| sort - content_type\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['myDataset'] \n| sort by countent_type desc\n```\n\n----------------------------------------\n\nTITLE: APL avgif Basic Syntax\nDESCRIPTION: Basic syntax example for the avgif aggregation function in APL showing the required parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avgif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize avgif(expr, predicate) by grouping_field\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for Retrieving Current User in Axiom\nDESCRIPTION: YAML specification for the GET /user endpoint in Axiom's API. This endpoint retrieves details of the currently authenticated user. The specification includes the API version and the endpoint path.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/getCurrentUser.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: \"v2 get /user\"\n```\n\n----------------------------------------\n\nTITLE: Basic syntax of make_list function in APL\nDESCRIPTION: The syntax for using the make_list aggregation function in APL, which takes a column parameter and returns a dynamic array.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nmake_list(column)\n```\n\n----------------------------------------\n\nTITLE: Counting Total Events in Sample HTTP Logs\nDESCRIPTION: This query counts the total number of events in the sample HTTP logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| count\n```\n\n----------------------------------------\n\nTITLE: Extracting All Regex Matches in Kusto\nDESCRIPTION: Uses extract_all() to retrieve all substrings matching a regular expression from a source string, with options to select specific capture groups. Returns results as a dynamic array.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\nextract_all(regex, [captureGroups,] source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project extract_match =  extract_all(@\"(\\w)(\\w+)(\\w)\", dynamic([1,3]), content_type)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nextract_all(@\"(\\w)(\\w+)(\\w)\", dynamic([1,3]), content_type) == [[\"t\", \"t\"],[\"c\",\"v\"]]\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project extract_match = extract_all(@\"(\\w)(\\w+)(\\w)\", pack_array(), content_type)\n```\n\n----------------------------------------\n\nTITLE: String Replacement in SQL and APL\nDESCRIPTION: Shows how to replace occurrences of one substring with another. Both SQL and APL versions replace 'old' with 'new' in the status field, with slightly different function syntax.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nSELECT REPLACE(StaTUS, 'old', 'new') AS UpdatedStatus\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend UpdatedStatus = replace('old', 'new', status)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenSearch Output in Logstash\nDESCRIPTION: Basic Logstash configuration that sends data to Axiom using OpenSearch output. It executes a date command at 1-second intervals and forwards the output to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/logstash.mdx#2025-04-22_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\ninput{\n  exec{\n    command => \"date\"\n    interval => \"1\"\n  }\n}\noutput{\n  opensearch{\n    hosts => [\"https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic\"]\n    user => \"axiom\"\n    password => \"API_TOKEN\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example JSON Output for Shifted Events Array\nDESCRIPTION: Displays the result of applying array_shift_left to the events array, showing how the elements are rotated left with the last element becoming null.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-left.mdx#2025-04-22_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"attributes\": null,\n    \"name\": \"Sent\",\n    \"timestamp\": 1734001111273925400\n  },\n  {\n    \"name\": \"ResponseReceived\",\n    \"timestamp\": 1734001111274167300,\n    \"attributes\": null\n  },\n  null\n]\n```\n\n----------------------------------------\n\nTITLE: Lambda Environment Variables for ADOT\nDESCRIPTION: Required environment variables for enabling ADOT auto-instrumentation and specifying the collector configuration file location.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-lambda-dot.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nAWS_LAMBDA_EXEC_WRAPPER: /opt/otel-instrument\nOPENTELEMETRY_COLLECTOR_CONFIG_FILE: /var/task/collector.yaml\n```\n\n----------------------------------------\n\nTITLE: Importing Axiom Package\nDESCRIPTION: Import statement for the Axiom Go package.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/go.mdx#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nimport \"github.com/axiomhq/axiom-go/axiom\"\n```\n\n----------------------------------------\n\nTITLE: Accessing an Existing Dataset in Axiom with Terraform\nDESCRIPTION: This snippet demonstrates how to access an existing dataset in Axiom using Terraform. It requires the dataset ID obtained from the Axiom API.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_7\n\nLANGUAGE: hcl\nCODE:\n```\ndata \"axiom_dataset\" \"test_dataset\" {\n  id = \"DATASET_ID\"\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing and Formatting Simple SELECT Statement in Kusto\nDESCRIPTION: This snippet demonstrates how to parse a simple SELECT statement and reformat it using parse_sql and format_sql functions. It retrieves user IDs and usernames from the user_accounts table where the active status is 1.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\nhn \n| extend parsed = parse_sql(\"SELECT user_id, username FROM user_accounts WHERE active = 1\")\n| project formatted_sql = format_sql(parsed)\n```\n\n----------------------------------------\n\nTITLE: Conditional Field Extension in Splunk SPL\nDESCRIPTION: This snippet shows how to achieve similar functionality to APL's extend-valid in Splunk SPL using the eval function with conditional logic.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-valid-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n| eval new_field = if(isnotnull(field), field + 1, null())\n```\n\n----------------------------------------\n\nTITLE: Union with Ordering in APL\nDESCRIPTION: This example performs a union operation and then orders the result by the 'type' field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| union hn\n| order by type\n```\n\n----------------------------------------\n\nTITLE: IP Range Check in SQL vs APL\nDESCRIPTION: Comparison between SQL's BETWEEN operator and APL's ipv4_is_in_any_range function for checking IP ranges.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-in-any-range.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *,\n  CASE WHEN ip_address BETWEEN '192.168.0.0' AND '192.168.0.255' THEN 1 ELSE 0 END AS is_in_range\nFROM dataset;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset'] \n| extend is_in_range = ipv4_is_in_any_range(ip_address, dynamic(['192.168.0.0/24', '10.0.0.0/8']))\n```\n\n----------------------------------------\n\nTITLE: Django Instrumentor Import\nDESCRIPTION: Import for DjangoInstrumentor to enable automatic instrumentation in Django applications.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.instrumentation.django import DjangoInstrumentor\n```\n\n----------------------------------------\n\nTITLE: String Concatenation with strcat in KQL\nDESCRIPTION: Shows usage of strcat function to concatenate multiple arguments into a single string. Can handle 1-64 arguments with automatic string conversion.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_21\n\nLANGUAGE: kusto\nCODE:\n```\nstrcat(argument1, argument2[, argumentN])\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project stract_con = strcat( ['milestone.creator'], number )\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project stract_con = strcat( 'axiom', number )\n```\n\n----------------------------------------\n\nTITLE: Next Page Request Example for Run Query\nDESCRIPTION: Example showing how to request the next page of results using timestamp-based pagination for the Run Query endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/pagination.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/_apl?format=tabular' \\\n-H 'Authorization: Bearer API_TOKEN' \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"apl\": \"dataset | sort by _time desc | limit 100\",\n    \"startTime\": \"2024-11-30T00:00:00.000Z\",\n    \"endTime\": \"2024-11-30T22:59:59.999Z\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: WASM Filter Configuration\nDESCRIPTION: Fluent Bit configuration using WebAssembly (WASM) based filters. Includes path configuration for WASM filter file and public token settings.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/fluent-bit.mdx#2025-04-22_snippet_3\n\nLANGUAGE: ini\nCODE:\n```\n[SERVICE]\n    Flush     5\n    Daemon    off\n    Log_Level debug\n\n[INPUT]\n    Name cpu\n    Tag  cpu\n\n[FILTER]\n    Name         wasm\n    Match        *\n    Path         /path/to/wasm/filter.wasm\n    public_token xxxxxxxxxxx\n\n[OUTPUT]\n    Name            http\n    Match           *\n    Host            api.axiom.co\n    Port            443\n    URI             /v1/datasets/DATASET_NAME/ingest\n     # Authorization Bearer should be an API token\n    Header Authorization Bearer API_TOKEN\n    compress gzip\n    format json\n    json_date_key _time\n    json_date_format iso8601\n    tls On\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL GROUP BY to APL Histogram\nDESCRIPTION: Demonstrates how to achieve a histogram-like result in SQL using GROUP BY and range calculations, compared to APL's simpler histogram function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/histogram.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(*), FLOOR(req_duration_ms/10)*10 as duration_bin\nFROM sample_http_logs\nGROUP BY duration_bin\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by histogram(req_duration_ms, 10)\n```\n\n----------------------------------------\n\nTITLE: Parsing Basic SQL SELECT Query in APL\nDESCRIPTION: Demonstrates using parse_sql() to analyze a simple SELECT statement that retrieves all columns from a table named 'db'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nhn\n| project parse_sql(\"select * from db\")\n```\n\n----------------------------------------\n\nTITLE: Alternative Search Operator Syntax in Kusto\nDESCRIPTION: Shows an alternative but identical syntax for the search operator in APL, reinforcing the basic structure with optional case sensitivity parameter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\nsearch [kind=CaseSensitivity] SearchPredicate\n```\n\n----------------------------------------\n\nTITLE: Get Dataset Field Endpoint Path\nDESCRIPTION: OpenAPI endpoint path specification for retrieving a single field from a dataset. Uses dataset ID and field ID as path parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/getFieldForDataset.mdx#2025-04-22_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\nv2 get /datasets/{id}/fields/{fieldId}\n```\n\n----------------------------------------\n\nTITLE: Converting SQL STDDEV to APL\nDESCRIPTION: Demonstrates how to translate a SQL standard deviation query to APL using the 'stdev()' function in a 'summarize' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT STDDEV(req_duration_ms) AS StdDevRequest\nFROM  [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize StdDevRequest = stdev(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Example JSON Output for Original Events Array\nDESCRIPTION: Shows a sample of the original events array containing three events (Enqueued, Sent, ResponseReceived) with their timestamps and attributes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-left.mdx#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"name\": \"Enqueued\",\n    \"timestamp\": 1734001111273917000,\n    \"attributes\": null\n  },\n  {\n    \"attributes\": null,\n    \"name\": \"Sent\",\n    \"timestamp\": 1734001111273925400\n  },\n  {\n    \"name\": \"ResponseReceived\",\n    \"timestamp\": 1734001111274167300,\n    \"attributes\": null\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: String Length Function in KQL\nDESCRIPTION: Demonstrates the strlen function that returns the length of a string in characters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_24\n\nLANGUAGE: kusto\nCODE:\n```\nstrlen(source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nproject str_len =  strlen(\"axiom\")\n```\n\n----------------------------------------\n\nTITLE: Paginating Query Results with Cursor in Axiom API (Legacy Endpoint)\nDESCRIPTION: This snippet demonstrates how to make a POST request to the legacy Axiom API endpoint for running queries with pagination. It uses a cursor to fetch the next page of results, along with specifying the dataset, time range, limit, and sort order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/pagination.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/{dataset_id}/query' \\\n-H 'Authorization: Bearer API_TOKEN' \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"startTime\": \"2024-01-01T00:00:00.000Z\",\n    \"endTime\": \"2024-01-31T23:59:59.999Z\",\n    \"limit\": 100,\n    \"order\": [{ \"field\": \"_time\", \"desc\": true }],\n    \"cursor\": \"0d3wo7v7e1oii-075a8c41710018b9-0000ecc5\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Renaming Fields in Splunk SPL and APL\nDESCRIPTION: Demonstrates how to rename fields in Splunk SPL using the 'rename' command and in APL using the 'extend' and 'project' operators.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nindex=\"myIndex\" sourcetype=\"mySourceType\"\n| rename oldFieldName AS newFieldName\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['myDataset']\n| where method == \"GET\"\n| extend new_field_name = content_type\n| project-away content_type\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL and APL for IPv4 Detection\nDESCRIPTION: Shows how to check for the presence of an IPv4 address in text using ANSI SQL pattern matching compared to the equivalent approach in Axiom Processing Language (APL).\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-ipv4.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CASE WHEN column_text LIKE '%192.168.1.1%' THEN TRUE ELSE FALSE END AS result\nFROM log_table;\n```\n\nLANGUAGE: kusto\nCODE:\n```\nprint result=has_ipv4('05:04:54 192.168.1.1 GET /favicon.ico 404', '192.168.1.1')\n```\n\n----------------------------------------\n\nTITLE: Using floor() Function in APL\nDESCRIPTION: The floor() function calculates the largest integer less than or equal to the specified numeric expression. It takes a real number and returns the floor integer value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/rounding-functions.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\nfloor(number)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nfloor(25.73) == 25\n```\n\n----------------------------------------\n\nTITLE: Sample Webhook Response JSON\nDESCRIPTION: Example of an actual webhook POST request body when a threshold monitor is triggered.\nSOURCE: https://github.com/axiomhq/docs/blob/main/monitor-data/custom-webhook-notifier.mdx#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"action\": \"Open\",\n  \"event\": {\n    \"monitorID\": \"CabI3w142069etTgd0\",\n    \"body\": \"Current value of 57347 is above or equal to the threshold value of 0\",\n    \"description\": \"\",\n    \"queryEndTime\": \"2024-06-28 14:55:57.631364493 +0000 UTC\",\n    \"queryStartTime\": \"2024-06-28 14:45:57.631364493 +0000 UTC\",\n    \"timestamp\": \"2024-06-28 14:55:57 +0000 UTC\",\n    \"title\": \"Axiom Monitor Test Triggered\",\n    \"value\": 57347,\n    \"matchedEvent\": null,\n    \"groupKeys\": null,\n    \"groupValues\": null\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Objects in Array using Splunk SPL\nDESCRIPTION: This snippet demonstrates how to filter objects in an array based on conditions in Splunk SPL. It's provided as a comparison to the array_select_dict function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-select-dict.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval selected = mvfilter(array, 'key' == 5)\n```\n\n----------------------------------------\n\nTITLE: Installing WebApi Client Package\nDESCRIPTION: Command to install Microsoft.AspNet.WebApi.Client package for making HTTP requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Microsoft.AspNet.WebApi.Client\n```\n\n----------------------------------------\n\nTITLE: Calculating Start of Month in Axiom Query Language\nDESCRIPTION: The startofmonth() function returns the start of the month containing the given date. It sets the day to the 1st and the time to 00:00:00, useful for monthly aggregations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_17\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project start_of_the_month =  startofmonth(datetime(2020-08-01))\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['hackernews']\n| extend start_of_the_month = startofmonth(datetime(2020-08-01))\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL values function with APL make_list\nDESCRIPTION: Example showing how to use the values function in Splunk SPL compared to make_list in APL to collect URI values by user.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nindex=logs | stats values(uri) by user\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize uris=make_list(uri) by id\n```\n\n----------------------------------------\n\nTITLE: Timeslice and Status Code Analysis in Sumo Logic and APL\nDESCRIPTION: Queries that analyze HTTP status codes in hourly time intervals. The Sumo Logic query parses status codes from Apache logs and counts by hour, while the APL query focuses on POST requests and bins results by hour.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache*\n| parse \"HTTP/1.1\\\" * * \\\"\" as (status_code, size)\n| timeslice 1h\n| count by _timeslice, status_code\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend status_code = extract(\"^(\\\\S+)\", 1, method)\n| where status_code == \"POST\"\n| summarize count() by status_code, bin(_time, 1h)\n```\n\n----------------------------------------\n\nTITLE: Simple Field Selection with Project in APL\nDESCRIPTION: Shows the simplest form of the project operator where you list the field names you want to include in the result set without any transformations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n| project FieldName, FieldName, FieldName, ...\n```\n\n----------------------------------------\n\nTITLE: Removing Fields with project-away in APL (Basic Syntax)\nDESCRIPTION: The basic syntax for the project-away operator which allows you to exclude specific fields from your query results. This operator is useful when you want to return all fields except a few specific ones.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-away-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| project-away FieldName1, FieldName2, ...\n```\n\n----------------------------------------\n\nTITLE: Auto-Instrumenting Java Application with OpenTelemetry\nDESCRIPTION: This Java code demonstrates how to set up automatic instrumentation for a Java application using OpenTelemetry, specifically for HTTP client instrumentation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\n// AutoInstrumentationSetup.java\npackage com.example;\n\nimport io.opentelemetry.instrumentation.httpclient.HttpClientInstrumentation;\nimport io.opentelemetry.api.OpenTelemetry;\n\npublic class AutoInstrumentationSetup {\n    public static void setup() {\n        OpenTelemetry openTelemetry = OtelConfiguration.initializeOpenTelemetry();\n        HttpClientInstrumentation.instrument(openTelemetry);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Coalescing Values in Kusto\nDESCRIPTION: Demonstrates using coalesce() function to evaluate a list of expressions and return the first non-null (or non-empty for strings) expression. Useful for fallback values.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project coalesced = coalesce(content_type, ['geo.city'], method)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['http-logs']\n| project req_duration_ms, server_datacenter, predicate = coalesce(content_type, method, status)\n```\n\n----------------------------------------\n\nTITLE: Cursor-based Pagination Response Format\nDESCRIPTION: Example JSON response showing the format of cursor-based pagination, including status metadata and cursor information.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/pagination.mdx#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"status\": {\n    \"rowsMatched\": 2500,\n    \"minCursor\": \"0d3wo7v7e1oii-075a8c41710018b9-0000ecc5\",\n    \"maxCursor\": \"0d3wo7v7e1oii-075a8c41710018b9-0000faa3\"\n  },\n  \"matches\": [\n    // ... events ...\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Type conversion functions in APL\nDESCRIPTION: List of commonly used type conversion functions in APL for converting values between different scalar data types.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/scalar-data-types.mdx#2025-04-22_snippet_8\n\nLANGUAGE: apl\nCODE:\n```\ntobool()\ntodatetime()\ntodouble() or toreal()\ntostring()\ntotimespan()\ntolong()\ntoint()\n```\n\n----------------------------------------\n\nTITLE: Using make_set in SQL vs APL\nDESCRIPTION: Comparison between SQL's ARRAY_AGG(DISTINCT) function and APL's make_set function for aggregating unique values from a column grouped by ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, ARRAY_AGG(DISTINCT method) \nFROM sample_http_logs \nGROUP BY id;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize make_set(method) by id\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL array conditional selection\nDESCRIPTION: Comparison between Splunk SPL's conditional array manipulation and APL's array_iff function, showing how to conditionally select elements from arrays based on a condition.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-iff.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\neval selected_array=if(condition, array1, array2)\n```\n\nLANGUAGE: kusto\nCODE:\n```\narray_iff(condition_array, array1, array2)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Success and Error Transformers for Axiom Logging in Next.js\nDESCRIPTION: This code shows how to create custom transformSuccessResult and transformRouteHandlerErrorResult functions that format the data sent to Axiom. These custom transformers define the structure of request logs while still allowing for additional custom fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger, AxiomJSTransport } from '@axiomhq/logging';\nimport { \n  createAxiomRouteHandler, \n  getLogLevelFromStatusCode, \n  nextJsFormatters, \n  transformRouteHandlerErrorResult, \n  transformRouteHandlerSuccessResult \n} from '@axiomhq/nextjs';\n\n/* ... your logger setup ... */\n\nexport const transformSuccessResult = (\n  data: SuccessData\n): [message: string, report: Record<string, any>] => {\n  const report = {\n    request: {\n      type: \"request\",\n      method: data.req.method,\n      url: data.req.url,\n      statusCode: data.res.status,\n      durationMs: data.end - data.start,\n      path: new URL(data.req.url).pathname,\n      endTime: data.end,\n      startTime: data.start,\n    },\n  };\n\n  return [\n    `${data.req.method} ${report.request.path} ${\n      report.request.statusCode\n    } in ${report.request.endTime - report.request.startTime}ms`,\n    report,\n  ];\n};\n\nexport const transformRouteHandlerErrorResult = (data: ErrorData): [message: string, report: Record<string, any>] => {\n  const statusCode = data.error instanceof Error ? getNextErrorStatusCode(data.error) : 500;\n\n  const report = {\n    request: {\n      startTime: new Date().getTime(),\n      endTime: new Date().getTime(),\n      path: data.req.nextUrl.pathname ?? new URL(data.req.url).pathname,\n      method: data.req.method,\n      host: data.req.headers.get('host'),\n      userAgent: data.req.headers.get('user-agent'),\n      scheme: data.req.url.split('://')[0],\n      ip: data.req.headers.get('x-forwarded-for'),\n      region: getRegion(data.req),\n      statusCode: statusCode,\n    },\n  };\n\n  return [\n    `${data.req.method} ${report.request.path} ${report.request.statusCode} in ${report.request.endTime - report.request.startTime}ms`,\n    report,\n  ];\n};\n\nexport const withAxiom = createAxiomRouteHandler(logger, {\n  onError: (error) => {\n    if (error.error instanceof Error) {\n      logger.error(error.error.message, error.error);\n    }\n    const [message, report] = transformRouteHandlerErrorResult(error);\n    report.customField = \"customValue\";\n    report.request.searchParams = error.req.nextUrl.searchParams;\n\n    logger.log(getLogLevelFromStatusCode(report.statusCode), message, report);\n    logger.flush();\n  },\n  onSuccess: (data) => {\n    const [message, report] = transformRouteHandlerSuccessResult(data);\n    report.customField = \"customValue\";\n    report.request.searchParams = data.req.nextUrl.searchParams;\n\n    logger.info(message, report);\n    logger.flush();\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Sample Flight Data Response\nDESCRIPTION: Example JSON response showing flight data structure returned from the API\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/query.mdx#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"aircraft\": null,\n  \"altitude\": 123600,\n  \"category\": null,\n  \"flight\": \"BCI96D  \",\n  \"hex\": \"407241\",\n  \"lat\": 50.951285,\n  \"lon\": -1.347961,\n  \"messages\": 13325,\n  \"mlat\": [ \"lat\", \"lon\", \"track\", \"speed\", \"vert_rate\" ],\n  \"now\": null,\n  \"nucp\": 0,\n  \"rssi\": -13.3,\n  \"seen\": 3.6,\n  \"seen_pos\": 19.7,\n  \"speed\": 260,\n  \"squawk\": \"6014\",\n  \"tisb\": [],\n  \"track\": 197,\n  \"type\": null,\n  \"vert_rate\": 64\n}\n```\n\n----------------------------------------\n\nTITLE: Syntax for make_set_if Function in APL\nDESCRIPTION: Shows the syntax for the make_set_if function in APL which allows specifying a column to aggregate, a predicate condition, and an optional maximum size parameter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set-if.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nmake_set_if(column, predicate, [max_size])\n```\n\n----------------------------------------\n\nTITLE: Using array_index_of Function in APL (Basic Syntax)\nDESCRIPTION: The syntax for the array_index_of function in APL. This function returns the zero-based index of a specified value in an array, with optional parameters for start index, length, and occurrence.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-index-of.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\narray_index_of(array, lookup_value, [start], [length], [occurrence])\n```\n\n----------------------------------------\n\nTITLE: Converting to Boolean in APL\nDESCRIPTION: The tobool() function converts input to boolean (signed 8-bit) representation. If conversion is successful, it returns a boolean value; otherwise, it returns false.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\ntobool(Expr)\n\ntoboolean(Expr) (alias)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntobool(\"true\") == true\n```\n\n----------------------------------------\n\nTITLE: NLog Implementation in C#\nDESCRIPTION: C# implementation using NLog for logging with example operations and error handling.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_12\n\nLANGUAGE: csharp\nCODE:\n```\nusing NLog;\nusing NLog.Web;\n\nvar logger = NLogBuilder.ConfigureNLog(\"nlog.config\").GetCurrentClassLogger();\n\nclass Program\n{\n    static async Task Main(string[] args)\n    {\n        logger.Info(\"Application started\");\n        await SimulateOperations();\n        logger.Info($\"CLR version: {Environment.Version}\");\n        logger.Info(\"Application shutting down\");\n    }\n\n    static async Task SimulateOperations()\n    {\n        logger.Debug(\"Starting operations\");\n        logger.Debug(\"Connecting to database\");\n        await Task.Delay(500); // Simulated delay\n        logger.Info(\"Connected to database successfully\");\n        logger.Debug(\"Retrieving user data\");\n        await Task.Delay(1000);\n        logger.Info(\"Retrieved 100 user records\");\n        logger.Debug(\"Updating user preferences\");\n        await Task.Delay(800);\n        logger.Info(\"Updated user preferences successfully\");\n\n        try\n        {\n            logger.Debug(\"Processing payments\");\n            await Task.Delay(1500);\n            throw new Exception(\"Payment gateway unavailable\");\n        }\n        catch (Exception ex)\n        {\n            logger.Error($\"Payment processing failed: {ex.Message}\");\n        }\n\n        logger.Debug(\"Sending email notifications\");\n        await Task.Delay(1200);\n        logger.Info(\"Sent 50 email notifications\");\n        logger.Warn(\"Detected high memory usage\");\n        await Task.Delay(500);\n        logger.Info(\"Memory usage normalized\");\n        logger.Debug(\"Operations completed\");\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: TypeScript Configuration\nDESCRIPTION: TypeScript compiler options for Next.js and OpenTelemetry compatibility\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nextjs.mdx#2025-04-22_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"compilerOptions\": {\n    \"lib\": [\"dom\", \"dom.iterable\", \"esnext\"],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"strict\": true,\n    \"noEmit\": true,\n    \"esModuleInterop\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"bundler\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"jsx\": \"preserve\",\n    \"incremental\": true,\n    \"plugins\": [\n      {\n        \"name\": \"next\"\n      }\n    ],\n    \"paths\": {\n      \"@/*\": [\"./src/*\"]\n    }\n  },\n  \"include\": [\"next-env.d.ts\", \"**/*.ts\", \"**/*.tsx\", \".next/types/**/*.ts\"],\n  \"exclude\": [\"node_modules\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Django App\nDESCRIPTION: This command creates a new Django app within the project using the manage.py script.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython manage.py startapp your_app_name\n```\n\n----------------------------------------\n\nTITLE: Left and Right Trimming in SQL and APL\nDESCRIPTION: Shows how to remove whitespace from the beginning and end of strings. SQL uses LTRIM() and RTRIM() while APL uses trim_start() and trim_end() to remove spaces from content_type field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LTRIM(content_type) AS LeftTrimmedFirstName, RTRIM(content_type) AS RightTrimmedLastName\nFROM  [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend LeftTrimmedFirstName = trim_start(' ', content_type), RightTrimmedLastName = trim_end(' ', content_type)\n```\n\n----------------------------------------\n\nTITLE: Building and Running .NET Application\nDESCRIPTION: Commands for building and running the .NET application with logging configuration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ndotnet build\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Array Rotation in SQL vs APL\nDESCRIPTION: Comparison between SQL approach and APL for rotating array elements, showing the more concise approach in APL with array_rotate_left.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-left.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT array_column[2], array_column[3], array_column[0], array_column[1] FROM table\n```\n\nLANGUAGE: kusto\nCODE:\n```\nprint rotated_array = array_rotate_left(dynamic([1,2,3,4]), 2)\n```\n\n----------------------------------------\n\nTITLE: Configuring Log4j XML Settings\nDESCRIPTION: Log4j XML configuration that sets up Socket and Console appenders. The Socket appender forwards logs to Fluentd in JSON format, while the Console appender prints logs to standard output.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-apache-log4j.mdx#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"WARN\">\n  <Appenders>\n    <Socket name=\"Socket\" host=\"127.0.0.1\" port=\"24224\" protocol=\"TCP\">\n      <JsonLayout complete=\"false\" compact=\"true\" eventEol=\"true\" properties=\"true\" includeTimeMillis=\"true\"/>\n    </Socket>\n    <Console name=\"Console\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\"/>\n    </Console>\n  </Appenders>\n  <Loggers>\n    <Root level=\"info\">\n      <AppenderRef ref=\"Socket\"/>\n      <AppenderRef ref=\"Console\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n\n----------------------------------------\n\nTITLE: Updating Notifier Configuration using Axiom API (YAML)\nDESCRIPTION: This YAML snippet defines the OpenAPI specification for updating an existing notifier in Axiom. It specifies the HTTP method (PUT) and the endpoint path (/notifiers/{id}) for the update operation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/updateNotifier.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: \"v2 put /notifiers/{id}\"\n```\n\n----------------------------------------\n\nTITLE: Basic extend Operator Syntax in APL\nDESCRIPTION: The basic syntax for the extend operator in APL, which creates a new field based on an expression.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| extend NewField = Expression\n```\n\n----------------------------------------\n\nTITLE: Extending Fields with Valid Data in APL\nDESCRIPTION: This snippet demonstrates the basic syntax of the extend-valid operator in APL. It extends fields with new calculated values based on validity conditions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-valid-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| extend-valid FieldName1 = Expression1, FieldName2 = Expression2, FieldName3 = ...\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Tracer in exporter.py\nDESCRIPTION: This code sets up the OpenTelemetry tracing provider and exporter, configuring how and where trace data is sent, including the service name, API token, and dataset name for Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.sdk.resources import Resource, SERVICE_NAME\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n\n# Define the service name resource\nresource = Resource(attributes={\n    SERVICE_NAME: \"your-service-name\"  # Replace with your actual service name\n})\n\n# Create a TracerProvider with the defined resource\nprovider = TracerProvider(resource=resource)\n\n# Configure the OTLP/HTTP Span Exporter with necessary headers and endpoint\notlp_exporter = OTLPSpanExporter(\n    endpoint=\"https://api.axiom.co/v1/traces\",\n    headers={\n        \"Authorization\": \"Bearer API_TOKEN\",  # Replace with your actual API token\n        \"X-Axiom-Dataset\": \"DATASET_NAME\"    # Replace with your dataset name\n    }\n)\n\n# Create a BatchSpanProcessor with the OTLP exporter\nprocessor = BatchSpanProcessor(otlp_exporter)\nprovider.add_span_processor(processor)\n\n# Set the TracerProvider as the global tracer provider\ntrace.set_tracer_provider(provider)\n\n# Define a tracer for external use\ntracer = trace.get_tracer(\"your-service-name\")\n```\n\n----------------------------------------\n\nTITLE: Creating Rake Task for Logging in Ruby\nDESCRIPTION: This Rake task sends a test log to Axiom when invoked. It demonstrates how to create a custom Rake task that uses the AxiomLogger to send logs, which can be useful for testing or scheduled logging tasks.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-ruby-on-rails.mdx#2025-04-22_snippet_3\n\nLANGUAGE: ruby\nCODE:\n```\n# lib/tasks/log.rake\nnamespace :log do\n  desc \"Send a test log to Axiom\"\n  task send_test_log: :environment do\n    log_data = { message: \"Hello, Axiom from Rake!\", level: \"info\", service: \"rake_task\" }\n    AxiomLogger.send_log(log_data)\n    puts \"Test log sent to Axiom.\"\n  end\nend\n```\n\n----------------------------------------\n\nTITLE: Converting IPv4 to Long in APL\nDESCRIPTION: This snippet shows the APL equivalent of converting an IPv4 address to a long number using the parse_ipv4 function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/parse-ipv4.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ip_long = parse_ipv4(uri)\n```\n\n----------------------------------------\n\nTITLE: Using array_select_dict in APL\nDESCRIPTION: This snippet shows the equivalent operation of filtering objects in an array using the array_select_dict function in APL. It selects a dictionary from an array where the 'key' has a value of 5.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-select-dict.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n| project selected = array_select_dict(array, \"key\", 5)\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Value using max in Splunk SPL\nDESCRIPTION: This snippet demonstrates how to use the max function in Splunk SPL to find the maximum value of a field. It's used as a comparison to the APL equivalent.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/max.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats max(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Reordering Fields in Splunk SPL vs APL\nDESCRIPTION: Comparison between Splunk SPL's table command and APL's project-reorder operator for field reordering. The Splunk example shows how to reorder fields using the table command, while the APL equivalent demonstrates the same functionality using project-reorder.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: splunk\nCODE:\n```\n| table FieldA, FieldB, FieldC\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset.name']\n| project-reorder FieldA, FieldB, FieldC\n```\n\n----------------------------------------\n\nTITLE: Logging in Server Components with Next.js and Axiom\nDESCRIPTION: Shows how to use the Logger class from next-axiom to log from server-side components in Next.js.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger } from \"next-axiom\";\n\nexport default async function ServerComponent() {\n  const log = new Logger();\n  log.info(\"User logged in\", { userId: 42 });\n\n  // ...\n\n  await log.flush();\n  return <h1>Logged in</h1>;\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Access Settings Component in MDX\nDESCRIPTION: MDX import statement for including the access-to-datasets component in the documentation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/settings.mdx#2025-04-22_snippet_0\n\nLANGUAGE: mdx\nCODE:\n```\nimport AccessToDatasets from \"/snippets/access-to-datasets.mdx\"\n```\n\n----------------------------------------\n\nTITLE: Converting SQL VARIANCE to APL\nDESCRIPTION: Shows how to translate a SQL variance query to APL using the 'variance()' function in a 'summarize' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VAR(req_duration_ms) AS VarRequest\nFROM  [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize VarRequest = variance(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Conditional Filtering for Client Errors in Sumo Logic and APL\nDESCRIPTION: Queries demonstrating conditional filtering. Sumo Logic finds all 400-level client errors, while the APL example filters for CSS content with 200 status codes. Both use parsing to extract relevant fields for filtering.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache*\n| parse \"HTTP/1.1\\\" * * \\\"\" as (status_code, size)\n| where status_code matches \"40*\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where content_type startswith 'text/css'\n| extend p = (\"HTTP/1.1\\\" * * \\\"\")\n| where status == \"200\"\n```\n\n----------------------------------------\n\nTITLE: Checking for Integer Values in Kusto\nDESCRIPTION: Illustrates the use of the isint() function to determine if a given value is an integer. The function returns true for positive or negative integers, and false otherwise.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_26\n\nLANGUAGE: kusto\nCODE:\n```\nisint(expression)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nisint(resp_body_size_bytes) == true\n```\n\nLANGUAGE: kusto\nCODE:\n```\nisint(25.563663) == false\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML configuration block defining metadata for the documentation page including title, description, sidebar title and relevant tags.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/tokens.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: 'Authenticate API requests with tokens'\ndescription: 'Learn how you can authenticate your requests to the Axiom API with tokens.'\nsidebarTitle: Tokens\ntags:\n    ['axiom documentation', 'documentation', 'axiom', 'token', 'authenticate']\n---\n```\n\n----------------------------------------\n\nTITLE: Converting Request Duration from Milliseconds to Seconds in Log Analysis\nDESCRIPTION: Example query that uses extend to compute request duration in seconds from milliseconds in HTTP logs data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/extend-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| extend duration_sec = req_duration_ms / 1000\n```\n\n----------------------------------------\n\nTITLE: Converting to String in APL\nDESCRIPTION: The tostring() function converts input to a string representation. If the input is non-null, it returns a string representation; if null, it returns an empty string.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\ntostring(Expr)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntostring(axiom) == \"axiom\"\n```\n\n----------------------------------------\n\nTITLE: TypeScript Configuration for Node.js Project\nDESCRIPTION: TypeScript compiler configuration file that specifies compilation options for the Node.js project.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"compilerOptions\": {\n    \"target\": \"es2016\",\n    \"module\": \"commonjs\",\n    \"esModuleInterop\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"strict\": true,\n    \"skipLibCheck\": true\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Trimming String Start with Regular Expression using trim_start_regex Function in Kusto\nDESCRIPTION: Demonstrates how to use trim_start_regex function to remove leading matches of a specified regular expression from a string. It takes a regex and a source string as arguments.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_32\n\nLANGUAGE: kusto\nCODE:\n```\ntrim_start_regex(regex, source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project remove_cutset = trim_start_regex( \"github\", repo)\n```\n\n----------------------------------------\n\nTITLE: Reordering Fields in SQL vs APL\nDESCRIPTION: Comparison between SQL's SELECT statement and APL's project-reorder operator for field reordering. The SQL example shows field order in a SELECT statement, while the APL equivalent demonstrates the same functionality using project-reorder.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT FieldA, FieldB, FieldC FROM dataset;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| project-reorder FieldA, FieldB, FieldC\n```\n\n----------------------------------------\n\nTITLE: Basic Syntax for array_shift_right Function in APL\nDESCRIPTION: The syntax definition for using the array_shift_right function in Axiom Processing Language.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-right.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\narray_shift_right(array: array) : array\n```\n\n----------------------------------------\n\nTITLE: Using iff() Function in APL\nDESCRIPTION: Shows the basic syntax of the iff() function which evaluates a condition and returns one of two values based on the result.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conditional-function.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\niff(predicate, ifTrue, ifFalse)\n```\n\n----------------------------------------\n\nTITLE: Modifying Annotations with Axiom API using cURL\nDESCRIPTION: This bash snippet demonstrates how to modify an existing annotation using the Axiom API via a cURL PUT request. It includes the API endpoint, authorization header, and JSON payload with the fields to be updated.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/annotate-charts.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'PUT' 'https://api.axiom.co/v2/annotations/ANNOTATION_ID' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"endTime\": \"2024-03-18T08:49:28.382Z\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Running Cloudflare Workers App in Development Mode\nDESCRIPTION: Command to start a local development server for the Cloudflare Workers app.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm run start\n```\n\n----------------------------------------\n\nTITLE: Parsing and Formatting Complex Query with INNER JOIN in Kusto\nDESCRIPTION: This example parses and reformats a more complex SQL statement involving an INNER JOIN between orders and customers tables. It selects order IDs and customer names for orders placed after January 1, 2023.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_12\n\nLANGUAGE: kusto\nCODE:\n```\nhn \n| extend parsed = parse_sql(\"SELECT orders.order_id, customers.name FROM orders INNER JOIN customers ON orders.customer_id = customers.id WHERE orders.order_date > '2023-01-01'\")\n| project formatted_sql = format_sql(parsed)\n```\n\n----------------------------------------\n\nTITLE: Reversing an Array in APL (Basic Example)\nDESCRIPTION: Demonstrates the basic usage of array_reverse function in APL to reverse the order of elements in an array. The example creates a simple numeric array and applies the function to reverse it.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-reverse.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nlet arr = dynamic([1, 2, 3, 4, 5]);\nprint reversed_arr = array_reverse(arr)\n```\n\n----------------------------------------\n\nTITLE: Configuring AxiomJSTransport for @axiomhq/logging\nDESCRIPTION: Example of configuring the AxiomJSTransport for the @axiomhq/logging library.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Axiom } from \"@axiomhq/js\";\nimport { AxiomJSTransport } from \"@axiomhq/logging\";\n\nconst axiom = new Axiom({\n  token: process.env.AXIOM_TOKEN,\n});\n\nconst transport = new AxiomJSTransport({\n  axiom,\n  dataset: process.env.AXIOM_DATASET,\n  logLevel: \"warn\",\n});\n```\n\n----------------------------------------\n\nTITLE: Sending Logs from Splunk to Axiom using Golang\nDESCRIPTION: This snippet illustrates how to send logs from Splunk to Axiom using Golang. It creates a new Splunk client and demonstrates logging with and without a timestamp.\nSOURCE: https://github.com/axiomhq/docs/blob/main/endpoints/splunk.mdx#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport \"github.com/docker/docker/daemon/logger/splunk\"\n\nfunc main() {\n\n\t// Create new Splunk client\n\tsplunk := splunk.NewClient(\n\t\tnil,\n\t\t\"https://{$AXIOM_SPLUNK_ENDPOINT}:8088/services/collector\",\n\t\t\"{your-token}\",\n\t\t\"{your-source}\",\n\t\t\"{your-sourcetype}\",\n\t\t\"{your-index}\"\n\t)\n\n\terr := splunk.Log(\n\t\tinterface{\"msg\": \"axiom endpoints\", \"msg2\": \"endpoints\"}\n\t)\n\tif err != nil {\n        \treturn err\n        }\n\n\terr = splunk.LogWithTime(\n\t\ttime.Now(),\n\t\tinterface{\"msg\": \"axiom endpoints\", \"msg2\": \"endpoints\"}\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n```\n\n----------------------------------------\n\nTITLE: Parsing SQL Query with Index Hints in APL\nDESCRIPTION: Shows how to parse an SQL query that uses index hints to specify a particular index for query execution.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\nhn \n| project parse_sql(\"SELECT * FROM users USE INDEX (index_name) WHERE user_id = 101\")\n```\n\n----------------------------------------\n\nTITLE: APL sum Aggregation Syntax\nDESCRIPTION: The syntax for using the sum aggregation function in APL. It shows how to summarize data by calculating the sum of a numeric field with an optional column renaming.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sum.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize [<new_column_name> =] sum(<numeric_field>)\n```\n\n----------------------------------------\n\nTITLE: Run Query API Request with Timestamp Pagination\nDESCRIPTION: Example of making a paginated query request to Axiom's Run Query endpoint using timestamp-based pagination with sort and limit operators.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/pagination.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/_apl?format=tabular' \\\n-H 'Authorization: Bearer API_TOKEN' \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"apl\": \"dataset | sort by _time desc | limit 100\",\n    \"startTime\": \"2024-11-30T00:00:00.000Z\",\n    \"endTime\": \"2024-11-30T23:59:59.999Z\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Retrieving External Data with SQL and APL Comparison\nDESCRIPTION: Comparison between SQL's OPENROWSET and APL's externaldata approach for accessing external data stored in cloud storage.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/externaldata-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM OPENROWSET(BULK 'https://storage.example.com/data.csv', FORMAT = 'CSV') AS data;\n```\n\nLANGUAGE: kusto\nCODE:\n```\nexternaldata (id:string, timestamp:datetime) [\"https://storage.example.com/data.csv\"] with (format=\"csv\")\n```\n\n----------------------------------------\n\nTITLE: Creating a custom formatter for @axiomhq/logging\nDESCRIPTION: Example of creating and using a custom formatter with the @axiomhq/logging library.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Logger, LogEvent } from \"@axiomhq/logging\";\n\nconst myCustomFormatter = (event: LogEvent) => {\n  const upperCaseKeys = {\n    ...event,\n    fields: Object.fromEntries(\n      Object.entries(event.fields).map(([key, value]) => [key.toUpperCase(), value])\n    ),\n  };\n\n  return upperCaseKeys;\n};\n\nconst logger = new Logger({\n  formatters: [myCustomFormatter],\n});\n\nlogger.info(\"Hello, world!\");\n```\n\n----------------------------------------\n\nTITLE: Testing AxiomLogger in Rails Initializer\nDESCRIPTION: This initializer file tests the AxiomLogger by sending various types of logs (info, warn, error, debug) to Axiom after the Rails application initializes. It demonstrates how to use the AxiomLogger with different log levels and data structures.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-ruby-on-rails.mdx#2025-04-22_snippet_2\n\nLANGUAGE: ruby\nCODE:\n```\n# config/initializers/axiom_logger_test.rb\nRails.application.config.after_initialize do\n  puts \"Sending test logs to Axiom using Ruby on Rails Faraday...\"\n\n  # Info logs\n  AxiomLogger.send_log({ message: \"Application started successfully\", level: \"info\", service: \"initializer\" })\n  AxiomLogger.send_log({ message: \"User authentication successful\", level: \"info\", service: \"auth\" })\n  AxiomLogger.send_log({ message: \"Data fetched from external API\", level: \"info\", service: \"external_api\" })\n  AxiomLogger.send_log({ message: \"Email notification sent\", level: \"info\", service: \"email\" })\n\n  # Warn logs\n  AxiomLogger.send_log({ message: \"API request took longer than expected\", level: \"warn\", service: \"external_api\", duration: 1500 })\n  AxiomLogger.send_log({ message: \"User authentication token expiring soon\", level: \"warn\", service: \"auth\", user_id: 123 })\n  AxiomLogger.send_log({ message: \"Low disk space warning\", level: \"warn\", service: \"system\", disk_usage: \"85%\" })\n  AxiomLogger.send_log({ message: \"Non-critical configuration issue detected\", level: \"warn\", service: \"config\" })\n\n  # Error logs\n  AxiomLogger.send_log({ message: \"Database connection error\", level: \"error\", service: \"database\", error: \"Timeout\" })\n  AxiomLogger.send_log({ message: \"Failed to process payment\", level: \"error\", service: \"payment\", user_id: 456, error: \"Invalid card\" })\n  AxiomLogger.send_log({ message: \"Unhandled exception occurred\", level: \"error\", service: \"application\", exception: \"NoMethodError\" })\n  AxiomLogger.send_log({ message: \"Third-party API returned an error\", level: \"error\", service: \"integration\", status_code: 500 })\n\n  # Debug logs\n  AxiomLogger.send_log({ message: \"Request parameters\", level: \"debug\", service: \"api\", params: { page: 1, limit: 20 } })\n  AxiomLogger.send_log({ message: \"Response headers\", level: \"debug\", service: \"api\", headers: { \"Content-Type\" => \"application/json\" } })\n  AxiomLogger.send_log({ message: \"User object details\", level: \"debug\", service: \"user\", user: { id: 789, name: \"Axiom Observability\", email: \"support@axiom.co\" } })\n  AxiomLogger.send_log({ message: \"Cache hit for key\", level: \"debug\", service: \"cache\", key: \"popular_products\" })\nend\n```\n\n----------------------------------------\n\nTITLE: Extracting Netmask Suffix in Splunk SPL vs APL\nDESCRIPTION: Comparison of how to extract the netmask suffix from an IP address in Splunk SPL versus using the ipv4_netmask_suffix function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-netmask-suffix.mdx#2025-04-22_snippet_0\n\nLANGUAGE: spl\nCODE:\n```\neval netmask = replace(ip, \"^.*?/\", \"\")\n```\n\nLANGUAGE: kusto\nCODE:\n```\nextend netmask = ipv4_netmask_suffix(ip)\n```\n\n----------------------------------------\n\nTITLE: Extracting Regex Matches in Kusto\nDESCRIPTION: Uses extract() function to retrieve the first substring matching a regular expression pattern from a source string, with support for capturing groups.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\nextract(regex, captureGroup, source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project extract_sub =  extract(\"^.{2,2}(.{4,4})\", 1, content_type)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nextract(\"x=([0-9.]+)\", 1, \"axiom x=65.6|po\") == \"65.6\"\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL with APL Array Rotation\nDESCRIPTION: Demonstrates the difference between Splunk's mvindex and APL's array_rotate_right function for array rotation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-right.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval rotated_array=mvindex(array, -3)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| extend rotated_array = array_rotate_right(array, 3)\n```\n\n----------------------------------------\n\nTITLE: Syntax for strcat_array Function in APL\nDESCRIPTION: Defines the syntax for using the strcat_array function in APL, which takes an array and an optional delimiter as parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/strcat-array.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nstrcat_array(array, delimiter)\n```\n\n----------------------------------------\n\nTITLE: Converting to Hexadecimal in APL\nDESCRIPTION: The tohex() function converts an integer or long value to a hexadecimal string. If conversion is successful, it returns a string value; otherwise, it returns false.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\ntohex(value)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntohex(-546) == 'fffffffffffffdde'\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntohex(546) == '222'\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Apex Adapter with Dataset\nDESCRIPTION: Configuration of the Apex adapter using the New function with dataset option to specify the target dataset name.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/apex.mdx#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nhandler, err := adapter.New(\n    adapter.SetDataset(\"DATASET_NAME\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Using datetime_diff() function in Kusto/APL\nDESCRIPTION: The datetime_diff() function calculates calendarian difference between two datetime values. It takes period (string), datetime_1 and datetime_2 as arguments and returns an integer representing periods in datetime_1 - datetime_2.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\ndatetime_diff(period,datetime_1,datetime_2)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project new_datetime = datetime_diff(\"week\", datetime(2019-06-26T08:20:03.123456Z), datetime(2014-06-26T08:19:03.123456Z))\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"new_datetime\": 260\n}\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project new_datetime = datetime_diff(\"week\", datetime(2015-11-08), datetime(2014-11-08))\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"new_datetime\": 52\n}\n```\n\n----------------------------------------\n\nTITLE: Example Output of Original and Shifted Arrays in JSON\nDESCRIPTION: Sample JSON output showing the original events array and the same array after applying the array_shift_right function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-right.mdx#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"name\": \"Enqueued\",\n    \"timestamp\": 1734001215487927300,\n    \"attributes\": null\n  },\n  {\n    \"attributes\": null,\n    \"name\": \"Sent\",\n    \"timestamp\": 1734001215487937000\n  },\n  {\n    \"timestamp\": 1734001215488191000,\n    \"attributes\": null,\n    \"name\": \"ResponseReceived\"\n  }\n]\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n  null,\n  {\n    \"timestamp\": 1734001215487927300,\n    \"attributes\": null,\n    \"name\": \"Enqueued\"\n  },\n  {\n    \"attributes\": null,\n    \"name\": \"Sent\",\n    \"timestamp\": 1734001215487937000\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Detecting Private IPs in ANSI SQL\nDESCRIPTION: This snippet demonstrates how to identify private IP addresses in ANSI SQL using CASE statements and LIKE operators. It's provided as a comparison to the APL approach.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-private.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ip, \n       CASE \n         WHEN ip LIKE '10.%' OR ip LIKE '172.16.%' OR ip LIKE '192.168.%' THEN 'true'\n         ELSE 'false'\n       END AS is_private\nFROM logs;\n```\n\n----------------------------------------\n\nTITLE: Syntax of the limit Operator in APL\nDESCRIPTION: The formal syntax for the limit operator in APL. This operator takes a non-negative integer parameter N to specify the maximum number of rows to return.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/limit-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| limit [N]\n```\n\n----------------------------------------\n\nTITLE: Creating Typed Virtual Fields\nDESCRIPTION: Demonstrates how to create a typed virtual field by converting a custom attribute to a specific type using the tostring function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/traces.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n| extend deployment_id = tostring(['attributes.custom']['deployment_id'])\n```\n\n----------------------------------------\n\nTITLE: Using parse_pair() Function in a Query\nDESCRIPTION: Shows how to use parse_pair() in a Kusto query to access the key from the first element of a tags array.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/pair-functions.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['logs']\n| where parse_pair(tags[0]).key == \"host\"\n```\n\n----------------------------------------\n\nTITLE: Shifting Arrays in ANSI SQL vs APL\nDESCRIPTION: Comparison between ANSI SQL approach and APL's array_shift_right function for shifting array elements to the right.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-right.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nWITH shifted AS (\n  SELECT\n    array_column[ARRAY_LENGTH(array_column)] AS first_element,\n    array_column[1:ARRAY_LENGTH(array_column)-1] AS rest_of_elements\n  FROM table\n)\nSELECT ARRAY_APPEND(first_element, rest_of_elements) AS shifted_array\nFROM shifted\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset.name']\n| extend shifted_array = array_shift_right(array)\n```\n\n----------------------------------------\n\nTITLE: Creating AxiomLogger Service in Ruby\nDESCRIPTION: This code creates an AxiomLogger service that sends log data to Axiom using Faraday. It sets up the connection, wraps the log data, and sends a POST request to the Axiom API. It also handles the response and logs any errors.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-ruby-on-rails.mdx#2025-04-22_snippet_1\n\nLANGUAGE: ruby\nCODE:\n```\n# app/services/axiom_logger.rb\nrequire 'faraday'\nrequire 'json'\n\nclass AxiomLogger\n  def self.send_log(log_data)\n    dataset_name = \"DATASET_NAME\"\n    axiom_ingest_api_url = \"https://api.axiom.co/v1/datasets/DATASET_NAME/ingest\"\n    ingest_token = \"API_TOKEN\"\n\n    conn = Faraday.new(url: axiom_ingest_api_url) do |faraday|\n      faraday.request :url_encoded\n      faraday.adapter Faraday.default_adapter\n    end\n\n    wrapped_log_data = [log_data]\n\n    response = conn.post do |req|\n      req.headers['Content-Type'] = 'application/json'\n      req.headers['Authorization'] = \"Bearer #{ingest_token}\"\n      req.body = wrapped_log_data.to_json\n    end\n\n    puts \"AxiomLogger Response status: #{response.status}, body: #{response.body}\"\n\n    if response.status != 200\n      Rails.logger.error \"Failed to send log to Axiom: #{response.body}\"\n    end\n  end\nend\n```\n\n----------------------------------------\n\nTITLE: Configuring Winlogbeat with Ignore Older Option\nDESCRIPTION: YAML configuration for Winlogbeat with ignore_older option to specify how far back to read events.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nwinlogbeat.event_logs:\n  - name: Application\n    ignore_older: 72h\n\noutput.elasticsearch:\n  hosts: ['https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic']\n  protocol: \"https\"\n  ssl.verification_mode: \"full\"\n  api_key: 'axiom:API_TOKEN'\n  allow_older_versions: true\n```\n\n----------------------------------------\n\nTITLE: String Trimming in SQL and APL\nDESCRIPTION: Demonstrates removing whitespace from both ends of a string. SQL uses TRIM() while APL uses trim() to remove spaces from the content_type field in HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TRIM(content_type) AS TrimmedFirstName\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend TrimmedFirstName = trim(' ', content_type)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Distinct Values in APL\nDESCRIPTION: This snippet shows the equivalent APL query to retrieve distinct user IDs from sample HTTP logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/distinct-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| distinct id\n```\n\n----------------------------------------\n\nTITLE: Next Page Request Example for Legacy Query\nDESCRIPTION: Example showing how to request the next page of results using timestamp-based pagination for the Legacy Query endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/pagination.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/{dataset_id}/query' \\\n-H 'Authorization: Bearer API_TOKEN' \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"startTime\": \"2024-11-30T00:00:00.000Z\",\n    \"endTime\": \"2024-11-30T22:59:59.999Z\",\n    \"limit\": 100,\n    \"order\": [{ \"field\": \"_time\", \"desc\": true }]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Parsing SQL JOIN Operation in APL\nDESCRIPTION: Illustrates parsing an SQL statement that performs a JOIN operation between 'orders' and 'customers' tables to match orders with customer names.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nhn\n| project parse_sql(\"SELECT orders.id, customers.name FROM orders JOIN customers ON orders.customer_id = customers.id\")\n```\n\n----------------------------------------\n\nTITLE: Sending Logs to Axiom using JavaScript and Elastic Bulk API\nDESCRIPTION: JavaScript code snippet demonstrating how to send log data to Axiom using the Elastic Bulk API. It uses the axios library to make an HTTP POST request with the required headers and data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elasticsearch-bulk-api.mdx#2025-04-22_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nconst axios = require('axios');\n\n// Axiom elastic API URL\nconst AxiomApiUrl = 'https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic/_bulk';\n\n// Your Axiom API token\nconst AxiomToken = 'API_TOKEN';\n\n// The logs data retrieved from Elasticsearch\nconst logs = [\n    {\"index\": {\"_index\": \"myindex\", \"_id\": \"1\"}},\n    {\"@timestamp\": \"2023-06-06T12:00:00Z\", \"message\": \"axiom logging\", \"severity\": \"INFO\"},\n    {\"index\": {\"_index\": \"myindex\", \"_id\": \"2\"}},\n    {\"@timestamp\": \"2023-06-06T12:00:01Z\", \"message\": \"axiom log data\", \"severity\": \"ERROR\"}\n];\n\n// Convert the logs to a single string with newline separators\nconst data = logs.map(log => JSON.stringify(log)).join('\\n') + '\\n';\n\naxios.post(AxiomApiUrl, data, {\n    headers: {\n        'Content-Type': 'application/x-ndjson',\n        'Authorization': `Bearer ${AxiomToken}`\n    }\n})\n.then((response) => {\n    console.log('Response Status:', response.status);\n    console.log('Response Data:', response.data);\n})\n.catch((error) => {\n    console.error('Error:', error.response ? error.response.data : error.message);\n});\n```\n\n----------------------------------------\n\nTITLE: Comparing Array Sum in Splunk SPL vs APL\nDESCRIPTION: Example showing how to sum array elements in Splunk SPL compared to APL syntax.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-sum.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval total_duration = mvsum(duration_array)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset.name']\n| extend total_duration = array_sum(duration_array)\n```\n\n----------------------------------------\n\nTITLE: Syntax for array_concat Function in APL\nDESCRIPTION: Demonstrates the syntax for using the array_concat function in APL, including multiple array parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-concat.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\narray_concat(array1, array2, ...)\n```\n\n----------------------------------------\n\nTITLE: APL array_rotate_left Syntax\nDESCRIPTION: The syntax for using the array_rotate_left function in APL, which takes an array and the number of positions to rotate left.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-left.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\narray_rotate_left(array, positions)\n```\n\n----------------------------------------\n\nTITLE: Comparing make_list_if in APL with ANSI SQL\nDESCRIPTION: This snippet compares the make_list_if function in APL with its equivalent in ANSI SQL. It shows how to perform conditional aggregation in both query languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list-if.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ARRAY_AGG(CASE WHEN condition THEN field END) FROM table\n```\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize make_list_if(field, condition)\n```\n\n----------------------------------------\n\nTITLE: Calculating Base-10 Logarithm with log10() in Kusto\nDESCRIPTION: The log10() function calculates the common logarithm (base-10) of x. It takes a real number greater than 0 as input and returns the logarithm value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_13\n\nLANGUAGE: kusto\nCODE:\n```\nlog10(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nlog10(4) == 0.6020599913279624\n```\n\n----------------------------------------\n\nTITLE: AWS IoT Rule SQL Query\nDESCRIPTION: SQL statement for AWS IoT rule that captures all messages from the 'iot/topic' MQTT topic. This rule should be configured to trigger the Lambda function for processing incoming IoT messages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-iot-rules.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM 'iot/topic'\n```\n\n----------------------------------------\n\nTITLE: IP Prefix Matching in ANSI SQL vs. APL\nDESCRIPTION: Comparison between ANSI SQL's LIKE operator and APL's has_ipv4_prefix function for checking IP address prefixes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-ipv4-prefix.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM sample_http_logs\nWHERE ip LIKE '192.168.0%'\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where has_ipv4_prefix(uri, \"192.168.0\")\n```\n\n----------------------------------------\n\nTITLE: Raw string literals in APL\nDESCRIPTION: Examples of raw string literals in APL where backslash characters do not denote escape sequences, useful for regex patterns.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/scalar-data-types.mdx#2025-04-22_snippet_6\n\nLANGUAGE: apl\nCODE:\n```\n@\"This is a raw string literal\"\n@'This is a raw string literal'\n```\n\nLANGUAGE: apl\nCODE:\n```\n@\"^[\\d]+$\"\n```\n\n----------------------------------------\n\nTITLE: Building Axiom Documentation Locally with Mintlify\nDESCRIPTION: Command to build and serve the Axiom documentation locally using Mintlify for development and preview.\nSOURCE: https://github.com/axiomhq/docs/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run mintlify dev\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Value using MAX in ANSI SQL\nDESCRIPTION: This snippet illustrates how to use the MAX function in ANSI SQL to find the maximum value of a column. It's used as a comparison to the APL equivalent.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/max.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MAX(req_duration_ms) FROM sample_http_logs;\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Axiom Integration\nDESCRIPTION: Environment variable configuration for Axiom API token and dataset name\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nextjs.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nAPI_TOKEN=xaat-123\nDATASET_NAME=my-dataset\n```\n\n----------------------------------------\n\nTITLE: Project-Reorder Syntax in APL\nDESCRIPTION: The syntax for the project-reorder operator in APL showing how to specify fields and optional sort orders. Includes parameters for field names and sort direction options including asc, desc, granny-asc, and granny-desc.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| project-reorder Field1 [asc | desc | granny-asc | granny-desc], Field2 [asc | desc | granny-asc | granny-desc], ...\n```\n\n----------------------------------------\n\nTITLE: Explicit Case-Sensitive Search in APL\nDESCRIPTION: Explicitly uses case-sensitive search to find the exact term \"text\" in the sample-http-logs dataset, matching only records with this exact case.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search kind=case_sensitive \"text\"\n```\n\n----------------------------------------\n\nTITLE: Using isbool() Function in APL\nDESCRIPTION: The isbool() function checks if an expression value is a boolean type. It returns true if the expression is a boolean, and false otherwise.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\nisbool(expression)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nisbool(\"pow\") == false\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"conversion_function\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Error Handling with Winston and Axiom Transport in TypeScript\nDESCRIPTION: Sets up error handling for Winston logger with Axiom transport, using the errors formatter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/winston.mdx#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport winston from 'winston';\nimport { WinstonTransport as AxiomTransport } from '@axiomhq/winston';\nconst { combine, errors, stack } = winston.format;\nconst axiomTransport = new AxiomTransport({ ... });\nconst logger = winston.createLogger({\n  // 8<----snip----\n  format: combine(errors({ stack: true }), json()),\n  // 8<----snip----\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Project File\nDESCRIPTION: Project configuration file (csproj) with required package references and project settings.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<Project Sdk=\"Microsoft.NET.Sdk\">\n\n  <PropertyGroup>\n    <OutputType>Exe</OutputType>\n    <TargetFramework>net6.0</TargetFramework>\n    <ImplicitUsings>enable</ImplicitUsings>\n    <Nullable>enable</Nullable>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <PackageReference Include=\"Microsoft.AspNet.WebApi.Client\" Version=\"6.0.0\" />\n  </ItemGroup>\n\n</Project>\n```\n\n----------------------------------------\n\nTITLE: Converting to Long Integer in APL\nDESCRIPTION: The tolong() function converts input to a long (signed 64-bit) number representation. If conversion is successful, it returns a long number; otherwise, it returns false.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\ntolong(Expr)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntolong(\"241\") == 241\n```\n\n----------------------------------------\n\nTITLE: Basic Syntax for stdevif Aggregation Function in APL\nDESCRIPTION: Shows the basic syntax of the stdevif function in APL, which calculates the standard deviation of values from a column that meet a specified condition.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdevif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize stdevif(column, condition)\n```\n\n----------------------------------------\n\nTITLE: Limiting Results with APL\nDESCRIPTION: APL query that returns a random subset of 1000 rows from the sample-http-logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/explore.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| limit 1000\n```\n\n----------------------------------------\n\nTITLE: Parsing Nested SQL Queries in APL\nDESCRIPTION: Shows how to parse a nested SQL query where the inner query selects user_id from orders based on purchase_date, and the outer query selects names from users based on those IDs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\nhn\n| project parse_sql(\"SELECT name FROM users WHERE id IN (SELECT user_id FROM orders WHERE purchase_date > '2022-01-01')\")\n```\n\n----------------------------------------\n\nTITLE: Sending Logs from Splunk to Axiom using JavaScript\nDESCRIPTION: This snippet demonstrates how to send logs from Splunk to Axiom using JavaScript. It uses the 'splunk-logging' package to create a Splunk logger and send a payload to the Axiom endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/endpoints/splunk.mdx#2025-04-22_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nvar SplunkLogger = require('splunk-logging').Logger;\n\nvar config = {\n  token: '$SPLUNK_TOKEN',\n  url: '$AXIOM_ENDPOINT_URL',\n};\n\nvar Logger = new SplunkLogger({\n  token: config.token,\n  url: config.url,\n  host: '$AXIOM_ENDPOINT_URL',\n});\n\nvar payload = {\n  // Message can be anything; doesn't have to be an object\n  message: {\n    temperature: '70F',\n    chickenCount: 500,\n  },\n};\n\nconsole.log('Sending payload', payload);\nLogger.send(payload, function (err, resp, body) {\n  // If successful, body will be { text: 'Success', code: 0 }\n  console.log('Response from Splunk', body);\n});\n```\n\n----------------------------------------\n\nTITLE: Quoting Identifiers in APL Queries\nDESCRIPTION: Demonstrates how to quote identifiers in APL queries when they contain special characters or match reserved keywords. Quoted identifiers are enclosed in quotation marks and square brackets.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/entities/entity-names.mdx#2025-04-22_snippet_0\n\nLANGUAGE: APL\nCODE:\n```\n['my-field']\n```\n\n----------------------------------------\n\nTITLE: Basic Log Analysis with limit Operator\nDESCRIPTION: A query example showing how to retrieve the first 5 rows from a sample HTTP logs dataset, useful for viewing the most recent log entries.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/limit-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| limit 5\n```\n\n----------------------------------------\n\nTITLE: Long type literals in APL\nDESCRIPTION: Examples of long type literals in APL, showing positive, negative, and null representations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/scalar-data-types.mdx#2025-04-22_snippet_4\n\nLANGUAGE: apl\nCODE:\n```\nlong(11)\nlong(-3)\nlong(null)\n```\n\n----------------------------------------\n\nTITLE: Calculating Power with pow() in Kusto\nDESCRIPTION: The pow() function raises a base value to an exponent. It takes two arguments: the base and the exponent, and returns the result of base^exponent.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_18\n\nLANGUAGE: kusto\nCODE:\n```\npow(base, exponent )\n```\n\nLANGUAGE: kusto\nCODE:\n```\npow(2, 6) == 64\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL Distinct Counting\nDESCRIPTION: Example showing how to count distinct values conditionally in Splunk SPL versus APL syntax.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcountif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats dc(eval(status=\"200\")) AS distinct_successful_users\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize dcountif(id, status == '200')\n```\n\n----------------------------------------\n\nTITLE: Creating Axiom Annotation via API Call\nDESCRIPTION: API request example showing how to create an annotation in Axiom using cURL. The request includes timestamp, type, affected datasets, title, description, and a reference URL. Requires an Axiom API token for authentication.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/annotate-charts.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v2/annotations' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"time\": \"2024-03-18T08:39:28.382Z\",\n    \"type\": \"deploy\",\n    \"datasets\": [\"my-dataset\"],\n    \"title\": \"Production deployment\",\n    \"description\": \"Deploy new feature to the sales form\",\n    \"url\": \"https://example.com\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Importing Axiom Apex Adapter in Go\nDESCRIPTION: Import statement for the Axiom Go SDK's Apex adapter package, imported as 'adapter' to avoid conflicts with apex/log package.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/apex.mdx#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nimport adapter \"github.com/axiomhq/axiom-go/adapters/apex\"\n```\n\n----------------------------------------\n\nTITLE: Rotated Sequence JSON Example\nDESCRIPTION: Example JSON output showing the rotated array after applying array_rotate_left, with elements shifted one position to the left.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-left.mdx#2025-04-22_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"timestamp\": 1733997117722911700,\n    \"name\": \"Sent\"\n  },\n  {\n    \"name\": \"ResponseReceived\",\n    \"timestamp\": 1733997117723591400\n  },\n  {\n    \"timestamp\": 1733997117722909000,\n    \"name\": \"Enqueued\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Basic Syntax for percentileif Function in APL\nDESCRIPTION: Illustrates the basic syntax for using the percentileif aggregation function in APL, showing the required parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentileif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize percentileif(Field, Percentile, Predicate)\n```\n\n----------------------------------------\n\nTITLE: Computing Variance with Conditions in ANSI SQL\nDESCRIPTION: Example showing how to calculate conditional variance in ANSI SQL using a CASE statement to apply filtering logic before computing variance.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/varianceif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VARIANCE(CASE WHEN status = '200' THEN req_duration_ms END) \nFROM sample_http_logs;\n```\n\n----------------------------------------\n\nTITLE: Extracting Array Elements in Splunk SPL\nDESCRIPTION: This snippet demonstrates how to extract elements from an array using the mvindex function in Splunk SPL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-slice.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval sliced_array=mvindex(my_array, 1, 3)\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Lambda Extension with Terraform\nDESCRIPTION: This Terraform configuration demonstrates how to add the Axiom Lambda Extension to an AWS Lambda function. It includes setting up the function, environment variables, and the extension layer.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-lambda.mdx#2025-04-22_snippet_2\n\nLANGUAGE: terraform\nCODE:\n```\nresource \"aws_lambda_function\" \"test_lambda\" {\n  filename      = \"lambda_function_payload.zip\"\n  function_name = \"lambda_function_name\"\n  role          = aws_iam_role.iam_for_lambda.arn\n  handler       = \"index.test\"\n  runtime       = \"nodejs14.x\"\n\n  ephemeral_storage {\n    size = 10240 # Min 512 MB and the Max 10240 MB\n  }\n\n  environment {\n    variables = {\n      AXIOM_TOKEN   = \"API_TOKEN\"\n      AXIOM_DATASET = \"DATASET_NAME\"\n    }\n  }\n\n  layers = [\n    \"arn:aws:lambda:AWS_REGION:694952825951:layer:axiom-extension-ARCH:VERSION\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using ceiling() Function in APL\nDESCRIPTION: The ceiling() function calculates the smallest integer greater than or equal to a specified numeric expression. It takes a real number as input and returns the ceiling integer value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/rounding-functions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nceiling(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nceiling(25.43) == 26\n```\n\n----------------------------------------\n\nTITLE: Next.js Root Layout Configuration\nDESCRIPTION: Implementation of the root layout component with OpenTelemetry registration\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nextjs.mdx#2025-04-22_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nimport { register } from '../../instrumentation';\n\nregister();\n\nexport default function RootLayout({ children }: Readonly<{ children: React.ReactNode }>) {\n  return (\n    <html lang=\"en\">\n      <body>{children}</body>\n    </html>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Running Axiom Loki Proxy\nDESCRIPTION: Command to run the Axiom Loki Proxy locally.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/loki-multiplexer.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./axiom-loki-proxy\n```\n\n----------------------------------------\n\nTITLE: Get RBAC Group Endpoint Specification\nDESCRIPTION: OpenAPI specification for retrieving group details via GET request. Endpoint path includes group ID parameter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/getGroupById.mdx#2025-04-22_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\nv2 get /rbac/groups/{id}\n```\n\n----------------------------------------\n\nTITLE: JSON Event Structure Example\nDESCRIPTION: Example showing how Axiom flattens nested JSON events using dot notation for field names\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/datasets.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"foo\": { \"bar\": \"baz\" }}\n```\n\n----------------------------------------\n\nTITLE: Reversing Security Event Sequences in HTTP Logs\nDESCRIPTION: Demonstrates using array_reverse on security logs to examine blocked access attempts in reverse order. This helps identify unusual access patterns or the progression of unauthorized access attempts by users.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-reverse.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '403'\n| summarize blocked_uris = make_list(uri) by id\n| project id, reversed_blocked_uris = array_reverse(blocked_uris)\n```\n\n----------------------------------------\n\nTITLE: Checking IP Range in Splunk vs APL\nDESCRIPTION: Comparison between Splunk's cidrmatch and APL's ipv4_is_in_any_range function for checking if an IP address belongs to a range.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-in-any-range.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval is_in_range = cidrmatch(\"192.168.0.0/24\", ip_address)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset'] \n| extend is_in_range = ipv4_is_in_any_range(ip_address, dynamic(['192.168.0.0/24', '10.0.0.0/8']))\n```\n\n----------------------------------------\n\nTITLE: Configuring Tremor HTTP Client for Axiom Ingestion\nDESCRIPTION: Configuration for sending logs to Axiom's HTTP endpoint using Tremor. Sets up a file connector as data source and an HTTP client connector to send data to Axiom's API. Includes JSON codec and authentication configuration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/tremor.mdx#2025-04-22_snippet_0\n\nLANGUAGE: troy\nCODE:\n```\ndefine flow client_sink_only\nflow\n  use std::time::nanos;\n  use tremor::pipelines;\n\n  define connector input from file\n  args\n    file = \"in.json\"  # Default input file is 'in.json' in current working directory\n  with\n    codec = \"json\",   # Data is JSON encoded\n    preprocessors = [\"separate\"],   # Data is newline separated\n    config = {\n        \"path\": args.file,\n        \"mode\": \"read\"\n    },\n  end;\n  create connector input;\n\n  define connector http_client from http_client\n  args\n    dataset,\n    token\n  with\n    config = {\n      \"url\": \"https://api.axiom.co/v1/datasets/#{args.dataset}/ingest\",\n      \"tls\": true,\n      \"method\": \"POST\",\n      \"headers\": {\n        \"Authorization\": \"Bearer #{args.token}\"\n      },\n      \"timeout\": nanos::from_seconds(10),\n      \"mime_mapping\": {\n        \"*/*\": {\"name\": \"json\"},\n      }\n    }\n  end;\n  create connector http_client\n  with\n    dataset = \"DATASET_NAME\",\n    token = \"API_TOKEN\"\n  end;\n\n  create pipeline passthrough from pipelines::passthrough;\n\n  connect /connector/input to /pipeline/passthrough;\n  connect /pipeline/passthrough to /connector/http_client;\n\nend;\n\ndeploy flow client_sink_only;\n```\n\n----------------------------------------\n\nTITLE: Sending Logs from Splunk to Axiom using Python\nDESCRIPTION: This snippet shows how to send logs from Splunk to Axiom using Python. It uses the 'splunk_handler' package to create a Splunk handler and send a warning log message to the Axiom endpoint.\nSOURCE: https://github.com/axiomhq/docs/blob/main/endpoints/splunk.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom splunk_handler import SplunkHandler\nsplunk = SplunkHandler(\n        host=\"$AXIOM_SPLUNK_ENDPOINT_URL\",\n        port='8088',\n        token='',\n        index='main'\n    )\n\nlogging.getLogger('').addHandler(splunk)\n\nlogging.warning('Axiom endpoints!')\n```\n\n----------------------------------------\n\nTITLE: Converting ANSI SQL TOP Clause to APL Top Operator\nDESCRIPTION: This snippet shows how to translate an ANSI SQL query using the TOP clause to its APL equivalent. The SQL example selects the top 5 records ordered by request duration, while the APL version achieves the same result using the top operator in a pipeline.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/top-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TOP 5 req_duration_ms FROM sample_http_logs ORDER BY req_duration_ms DESC\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| top 5 by req_duration_ms\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL STDDEV with APL stdevif for HTTP Log Analysis\nDESCRIPTION: Shows how to calculate standard deviation with filtering in both ANSI SQL (using CASE WHEN) and APL (using stdevif). The example filters for HTTP 200 status codes when calculating the standard deviation of request durations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdevif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT STDDEV(CASE WHEN status = '200' THEN req_duration_ms END)\nFROM sample_http_logs\nGROUP BY geo.country;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize stdevif(req_duration_ms, status == \"200\") by geo.country\n```\n\n----------------------------------------\n\nTITLE: Calculating Base-2 Logarithm with log2() in Kusto\nDESCRIPTION: The log2() function calculates the base-2 logarithm of x. It takes a real number greater than 0 as input and returns the logarithm value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_14\n\nLANGUAGE: kusto\nCODE:\n```\nlog2(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nlog2(6) == 2.584962500721156\n```\n\n----------------------------------------\n\nTITLE: Converting IP Address with Netmask in Splunk SPL vs APL\nDESCRIPTION: Comparison of IP address conversion between Splunk SPL's cidrmatch function and APL's parse_ipv4_mask function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/parse-ipv4-mask.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval converted_ip = cidrmatch(\"192.168.1.0/24\", ip)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nprint converted_ip = parse_ipv4_mask(\"192.168.1.0\", 24)\n```\n\n----------------------------------------\n\nTITLE: Accessing an Existing User in Axiom with Terraform\nDESCRIPTION: This snippet shows how to access an existing user in Axiom using Terraform. It requires the user ID obtained from the Axiom API.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_10\n\nLANGUAGE: hcl\nCODE:\n```\ndata \"axiom_user\" \"test_user\" {\n  id = \"USER_ID\"\n}\n```\n\n----------------------------------------\n\nTITLE: Converting to Real/Double in APL\nDESCRIPTION: The todouble() and toreal() functions (synonyms) convert input to a value of type real. If conversion is successful, it returns a real value; otherwise, it returns false.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\ntoreal(Expr)\ntodouble(Expr)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntoreal(\"1567\") == 1567\n```\n\n----------------------------------------\n\nTITLE: Running Axiom CLI using Docker\nDESCRIPTION: Pull and run the Axiom CLI Docker image from DockerHub.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/cli.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull axiomhq/cli\ndocker run axiomhq/cli\n```\n\n----------------------------------------\n\nTITLE: Axiom CLI Help Commands\nDESCRIPTION: Commands for accessing help documentation within Axiom CLI.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/cli.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\naxiom help\naxiom help auth\naxiom help auth status\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL percentile functions\nDESCRIPTION: Examples showing how to calculate the 95th percentile in Splunk SPL and the equivalent syntax in Axiom Processing Language (APL).\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentile.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats perc95(req_duration_ms)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentile(req_duration_ms, 95)\n```\n\n----------------------------------------\n\nTITLE: Basic Syntax for array_split Function in APL\nDESCRIPTION: Defines the fundamental syntax for the array_split function in APL, showing the function name followed by the array parameter and the index parameter enclosed in parentheses.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-split.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\narray_split(array, index)\n```\n\n----------------------------------------\n\nTITLE: Using Regular Expression Matching Operators in Kusto\nDESCRIPTION: Examples of regular expression matching operators for testing if a string matches or doesn't match a specified pattern using regex syntax.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-operators/string-operators.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n\"parentSpanId\" matches regex \"p.*Id\" // True\n\"parentSpanId\" !matches regex \"x.*z\" // True\n```\n\n----------------------------------------\n\nTITLE: Configuring Next.js with Axiom\nDESCRIPTION: Wraps the Next.js configuration with Axiom using the withAxiom function in next.config.ts.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst { withAxiom } = require(\"next-axiom\");\n\nmodule.exports = withAxiom({\n  // Your existing configuration.\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Loki Proxy via Homebrew\nDESCRIPTION: Commands to install and update Axiom Loki Proxy using Homebrew package manager.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/loki-multiplexer.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbrew tap axiomhq/tap\nbrew install axiom-loki-proxy\nbrew update\nbrew upgrade axiom-loki-proxy\n```\n\n----------------------------------------\n\nTITLE: Comparing Array Sum in SQL vs APL\nDESCRIPTION: Example showing how to sum array elements in ANSI SQL compared to APL syntax.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-sum.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SUM(value) AS total_duration\nFROM UNNEST(duration_array) AS value;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset.name']\n| extend total_duration = array_sum(duration_array)\n```\n\n----------------------------------------\n\nTITLE: Using toint() Function in APL\nDESCRIPTION: The toint() function converts input values to signed 64-bit integer representation. If conversion is successful, it returns the integer value; otherwise, it returns null.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\ntoint(value)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| project toint(\"456\") == 456\n```\n\n----------------------------------------\n\nTITLE: Comparing ANSI SQL with APL array_index_of\nDESCRIPTION: Comparison between ANSI SQL array position functions and APL's array_index_of. SQL typically uses a combination of array and search functions where supported, while APL provides a dedicated function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-index-of.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT POSITION('value' IN ARRAY[...])\n```\n\nLANGUAGE: kusto\nCODE:\n```\nlet index = array_index_of(array, 'value')\n```\n\n----------------------------------------\n\nTITLE: Creating CloudWatch Unsubscriber Module with Terraform\nDESCRIPTION: Terraform configuration to create an Unsubscriber module that removes subscription filters from specified log groups.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/cloudwatch.mdx#2025-04-22_snippet_4\n\nLANGUAGE: hcl\nCODE:\n```\nmodule \"unsubscriber\" {\n  source           = \"axiomhq/axiom-cloudwatch-forwarder/aws//modules/unsubscriber\"\n  prefix           = \"axiom-cloudwatch-forwarder\"\n  forwarder_lambda_arn = module.forwarder.lambda_arn\n  log_groups_prefix    = \"/aws/lambda/\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using hash_sha512() Function with Status Field in APL\nDESCRIPTION: The hash_sha512() function returns a SHA512 hash value for the input value encoded as a hex string. This example shows applying the function to the status field from sample-http-logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/hash-functions.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\nhash_sha512(source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project sha512_hash_value = hash_sha512(status)\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"sha512_hash_value\": \"0878a61b503dd5a9fe9ea3545d6d3bd41c3b50a47f3594cb8bbab3e47558d68fc8fcc409cd0831e91afc4e609ef9da84e0696c50354ad86b25f2609efef6a834\"\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Set Statement Syntax in Kusto\nDESCRIPTION: Shows the basic syntax for using the set statement to configure query options. The OptionName parameter specifies which option to set, and OptionValue defines the value for that option.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/query-statement/set-statement.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\nset OptionName=OptionValue\n```\n\n----------------------------------------\n\nTITLE: Setting Default Value for Event Field in Kusto\nDESCRIPTION: This query sets a default value for the status field in the 'sample-http-logs' dataset. It uses the 'case' function to check if the status is not null and not empty, then uses the content_type, otherwise defaults to 'info'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_27\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project status = case(\n    isnotnull(status) and status != \"\", content_type, // use the contenttype if it's not null and not an empty string\n    \"info\" // default value\n  )\n```\n\n----------------------------------------\n\nTITLE: String literals in APL\nDESCRIPTION: Examples of string literals in APL, demonstrating double-quoted and single-quoted strings with escape sequences.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/scalar-data-types.mdx#2025-04-22_snippet_5\n\nLANGUAGE: apl\nCODE:\n```\n\"This is a string literal. Single quote characters (') don't require escaping. Double quote characters (\\\") are escaped by a backslash (\\\\)\"\n```\n\nLANGUAGE: apl\nCODE:\n```\n'Another string literal. Single quote characters (\\'') require escaping by a backslash (\\\\). Double quote characters (\") do not require escaping.'\n```\n\n----------------------------------------\n\nTITLE: has_ipv4_prefix Syntax in APL\nDESCRIPTION: The syntax for using the has_ipv4_prefix function in APL to check if an IPv4 address starts with a specific prefix.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-ipv4-prefix.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nhas_ipv4_prefix(column_name, prefix)\n```\n\n----------------------------------------\n\nTITLE: Parsing CSV Strings with parse_csv Function in Kusto\nDESCRIPTION: Shows how to use the parse_csv function to split a given string representing a single record of comma-separated values into a string array. It takes a CSV string as an argument.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_36\n\nLANGUAGE: kusto\nCODE:\n```\nparse_csv(\"axiom,logging,observability\") ==  [ \"axiom\", \"logging\", \"observability\" ]\n```\n\nLANGUAGE: kusto\nCODE:\n```\nparse_csv(\"axiom, processing, language\")  == [ \"axiom\", \"processing\", \"language\" ]\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project parse_csv(\"github, body, repo\")\n```\n\n----------------------------------------\n\nTITLE: APL Array Rotate Right Function Syntax\nDESCRIPTION: Shows the basic syntax for the array_rotate_right function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-right.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\narray_rotate_right(array, count)\n```\n\n----------------------------------------\n\nTITLE: Rate Limit Error Response in JSON\nDESCRIPTION: Example JSON response returned when a user exceeds their rate limit, resulting in a 429 Too Many Requests status code.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/api-limits.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"message\": \"rate limit exceeded\",\n}\n```\n\n----------------------------------------\n\nTITLE: Running Django Development Server\nDESCRIPTION: This command starts the Django development server, allowing interaction with the app and sending of collected traces to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npython3 manage.py runserver\n```\n\n----------------------------------------\n\nTITLE: Parsing Kubernetes Logs with Regex Mode - Output\nDESCRIPTION: JSON output showing the parsed Kubernetes pod information with extracted fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_15\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"podName\": \"nginx-pod\",\n  \"namespace\": \"default\",\n  \"phase\": \"Running\",\n  \"startTime\": \"2023-05-14 08:30:00\",\n  \"nodeName\": \"node-1\",\n  \"hostIP\": \"192.168.1.1\",\n  \"podIP\": \"10.1.1.1\"\n}\n```\n\n----------------------------------------\n\nTITLE: Splunk vs APL Data Redaction Comparison\nDESCRIPTION: Comparison between Splunk SPL and APL approaches for data sanitization using regex patterns.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/redact-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval sanitized_field=replace(field, \"regex_pattern\", \"*\")\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| redact 'regex_pattern' on field\n```\n\n----------------------------------------\n\nTITLE: Adding Web Vitals Tracking in Next.js\nDESCRIPTION: Integrates the AxiomWebVitals component into the root layout to track Web Vitals in a Next.js app.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AxiomWebVitals } from \"next-axiom\";\n\nexport default function RootLayout() {\n  return (\n    <html>\n      ...\n      <AxiomWebVitals />\n      <div>...</div>\n    </html>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Running Axiom Syslog Proxy via Docker\nDESCRIPTION: Docker command to run Axiom Syslog Proxy with required environment variables and port mappings\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/syslog-proxy.mdx#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ndocker run -p601:601/tcp -p514:514/udp  \\\n  -e=AXIOM_TOKEN=API_TOKEN     \\\n  -e=AXIOM_DATASET=DATASET_NAME \\\n  axiomhq/axiom-syslog-proxy\n```\n\n----------------------------------------\n\nTITLE: SQL vs APL Array Rotation Comparison\nDESCRIPTION: Shows how APL handles array rotation compared to SQL, which lacks direct array rotation functionality.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-right.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- No direct ANSI SQL equivalent for array rotation\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| extend rotated_array = array_rotate_right(array_column, 3)\n```\n\n----------------------------------------\n\nTITLE: Extracting Month of Year in Axiom Query Language\nDESCRIPTION: The monthofyear() function returns the integer number representing the month of the year (1-12) for a given date. It's useful for month-based grouping or filtering.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_15\n\nLANGUAGE: kusto\nCODE:\n```\nmonthofyear(datetime(\"2018-11-21\"))\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project month_of_the_year = monthofyear(datetime(2018-11-11))\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL sort to APL order\nDESCRIPTION: This example compares the Splunk SPL 'sort' operator with the APL 'order' operator for sorting by timestamp in descending order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/order-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: splunk\nCODE:\n```\n| sort - _time\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| order by _time desc\n```\n\n----------------------------------------\n\nTITLE: Running Axiom Loki Proxy with Docker\nDESCRIPTION: Docker command to run Axiom Loki Proxy with specified port and API token.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/loki-multiplexer.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p8080:8080/tcp \\\n  -e=AXIOM_TOKEN=<YOUR_AXIOM_TOKEN> \\\n  axiomhq/axiom-loki-proxy\n```\n\n----------------------------------------\n\nTITLE: Syntax for make_list_if Function in APL\nDESCRIPTION: This snippet demonstrates the syntax for using the make_list_if function in APL. It shows how to apply the function with an expression and a condition in a summarize operation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list-if.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize make_list_if(expression, condition)\n```\n\n----------------------------------------\n\nTITLE: Advanced Rate Calculation with Two Summarize Statements\nDESCRIPTION: Example of calculating average rate over one minute per hour using two summarize statements.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/rate.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize respBodyRate = rate(resp_body_size_bytes) by bin(_time, 1m)\n| summarize avg(respBodyRate) by bin(_time, 1h)\n```\n\n----------------------------------------\n\nTITLE: Counting OpenTelemetry Traces\nDESCRIPTION: Example of counting traces in an OpenTelemetry dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/count-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces'] |\ncount\n```\n\n----------------------------------------\n\nTITLE: Testing Syslog Configuration\nDESCRIPTION: Commands to test the Axiom Syslog Proxy configuration by sending test messages via TCP and UDP\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/syslog-proxy.mdx#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\necho -n \"tcp message\" | nc -w1 localhost 601\necho -n \"udp message\" | nc -u -w1 localhost 514\n```\n\n----------------------------------------\n\nTITLE: Calculating Start of Day in Axiom Query Language\nDESCRIPTION: The startofday() function returns the start of the day containing the given date. It sets the time to 00:00:00, which is useful for daily aggregations or comparisons.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_16\n\nLANGUAGE: kusto\nCODE:\n```\nstartofday(datetime(2020-08-31))\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project start_of_the_day = startofday(datetime(2018-11-11))\n```\n\n----------------------------------------\n\nTITLE: Checking IP Prefix Match in ANSI SQL\nDESCRIPTION: This snippet shows how to check if an IP address starts with certain prefixes using LIKE clauses in ANSI SQL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-any-ipv4-prefix.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM logs\nWHERE ip LIKE '10.%' OR ip LIKE '192.168.%';\n```\n\n----------------------------------------\n\nTITLE: Accessing an Existing Notifier in Axiom with Terraform\nDESCRIPTION: This snippet shows how to access an existing notifier in Axiom using Terraform. It requires the notifier ID obtained from the Axiom API.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_8\n\nLANGUAGE: hcl\nCODE:\n```\ndata \"axiom_dataset\" \"test_slack_notifier\" {\n  id = \"NOTIFIER_ID\"\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Weekend Days in Sumo Logic\nDESCRIPTION: This Sumo Logic query parses the day of the week from logs and filters for Saturday and Sunday using the where operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n* | parse \"day=*:\" as day_of_week\n| where day_of_week in (\"Saturday\",\"Sunday\")\n```\n\n----------------------------------------\n\nTITLE: Syntax for project-keep Operator in APL\nDESCRIPTION: The basic syntax for using the project-keep operator in APL queries to select specific fields to retain.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-keep-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| project-keep FieldName1, FieldName2, ...\n```\n\n----------------------------------------\n\nTITLE: APL parse_ipv4_mask Function Syntax\nDESCRIPTION: The syntax definition for the parse_ipv4_mask function in APL, showing function name and parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/parse-ipv4-mask.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nparse_ipv4_mask(ip, prefix)\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL Array Rotation with APL array_shift_left Function\nDESCRIPTION: Demonstrates how to rotate array elements in Splunk SPL versus using the more concise array_shift_left function in APL. The Splunk example uses mvindex while APL provides a dedicated function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-left.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval rotated_array = mvindex(array, 1) . mvindex(array, 0)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['array_shift_left'](array, 1)\n```\n\n----------------------------------------\n\nTITLE: Installing @axiomhq/logging via npm\nDESCRIPTION: Command to install the @axiomhq/logging library using npm package manager.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nnpm install @axiomhq/logging\n```\n\n----------------------------------------\n\nTITLE: Converting SQL SUM to APL\nDESCRIPTION: Shows how to translate a SQL SUM query to APL using the 'summarize' operator with the 'sum()' function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SUM(resp_body_size_bytes) AS TotalBytes\nFROM  [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize TotalBytes = sum(resp_body_size_bytes)\n```\n\n----------------------------------------\n\nTITLE: Library Dependencies for OpenTelemetry in Cloudflare Workers\nDESCRIPTION: List of essential NPM packages required for implementing OpenTelemetry tracing in Cloudflare Workers. Includes packages for worker instrumentation, core telemetry APIs, OTLP exporters, and resource definitions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n@microlabs/otel-cf-workers\n@opentelemetry/api\n@opentelemetry/exporter-trace-otlp-http\n@opentelemetry/otlp-exporter-base\n@opentelemetry/otlp-transformer\n@opentelemetry/resources\n```\n\n----------------------------------------\n\nTITLE: Running Node.js Application in Development Mode\nDESCRIPTION: Command to start the application in development mode with auto-reload functionality.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Virtual Fields Usage Examples\nDESCRIPTION: Demonstrates how to avoid unnecessary string casting operations in queries for better performance.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/performance.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| extend str_user_id = tostring(mixed_user_id)\n| where str_user_id contains \"123\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| where mixed_user_id contains \"123\"\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Array Rotation Example\nDESCRIPTION: Practical example of using array_rotate_right with OpenTelemetry trace data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-right.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| extend rotated_sequence = array_rotate_right(events, 1)\n```\n\n----------------------------------------\n\nTITLE: Sort Clause Comparison - SQL vs APL\nDESCRIPTION: Shows the difference between SQL ORDER BY clause and APL sort operator syntax for ordering results.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sort-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM sample_http_logs\nORDER BY _time DESC, status ASC\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| sort by _time desc, status asc\n```\n\n----------------------------------------\n\nTITLE: Configuring Axiom Authentication Variables in Cloudflare Worker\nDESCRIPTION: Configuration snippet for setting up authentication variables in a Cloudflare Worker to connect with Axiom. Requires setting the dataset name and API token for authentication.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/cloudflare-workers.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconst axiomDataset = \"DATASET_NAME\"\nconst axiomToken = \"API_TOKEN\"\n```\n\n----------------------------------------\n\nTITLE: Creating an Email Notifier in Axiom with Terraform\nDESCRIPTION: This snippet shows how to create an email notifier in Axiom using Terraform. It allows specifying multiple email addresses for notifications.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_4\n\nLANGUAGE: hcl\nCODE:\n```\nresource \"axiom_notifier\" \"test_email_notifier\" {\n  name = \"test_email_notifier\"\n  properties = {\n    email= {\n      emails = [\"EMAIL1\",\"EMAIL2\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Counting Browser Hits in Sumo Logic\nDESCRIPTION: This Sumo Logic query extracts browser information from Apache access logs and counts hits for IE, Firefox, Safari, and Chrome browsers.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=Apache/Access\n| extract \"\\\"[A-Z]+ \\S+ HTTP/[\\d\\.]+\\\" \\S+ \\S+ \\S+ \\\"(?<agent>[^\\\"]+?)\\\"\"\n| if (agent matches \"*MSIE*\",1,0) as ie\n| if (agent matches \"*Firefox*\",1,0) as firefox\n| if (agent matches \"*Safari*\",1,0) as safari\n| if (agent matches \"*Chrome*\",1,0) as chrome\n| sum(ie) as ie, sum(firefox) as firefox, sum(safari) as safari, sum(chrome) as chrome\n```\n\n----------------------------------------\n\nTITLE: Retrieving First 10 Rows in APL\nDESCRIPTION: This snippet demonstrates how to use the take operator in APL to retrieve the first 10 rows from a sample dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/take-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| take 10\n```\n\n----------------------------------------\n\nTITLE: Creating a custom Transport for @axiomhq/logging\nDESCRIPTION: Example of creating a custom Transport by implementing the Transport interface.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Transport } from \"@axiomhq/logging\";\n\nclass MyTransport implements Transport {\n  log(log: Transport['log']) {\n    console.log(log);\n  }\n\n  flush() {\n    console.log(\"Flushing logs\");\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Multiple Percentiles in Splunk SPL\nDESCRIPTION: This snippet demonstrates how to calculate multiple percentiles in Splunk SPL using the perc function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-array.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n... | stats perc95(duration), perc50(duration), perc25(duration) by service\n```\n\n----------------------------------------\n\nTITLE: Accessing an Existing Monitor in Axiom with Terraform\nDESCRIPTION: This snippet demonstrates how to access an existing monitor in Axiom using Terraform. It requires the monitor ID obtained from the Axiom API.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/terraform.mdx#2025-04-22_snippet_9\n\nLANGUAGE: hcl\nCODE:\n```\ndata \"axiom_monitor\" \"test_monitor\" {\n  id = \"MONITOR_ID\"\n}\n```\n\n----------------------------------------\n\nTITLE: Decoding Base64 String in Kusto\nDESCRIPTION: Demonstrates using base64_decode_tostring() to decode a base64-encoded string into its UTF-8 representation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\nbase64_decode_tostring(string)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project decoded_base64_string = base64_decode_tostring(\"VGhpcyBpcyBhbiBlbmNvZGVkIG1lc3NhZ2Uu\")\n```\n\n----------------------------------------\n\nTITLE: Delimited String Concatenation in KQL\nDESCRIPTION: Demonstrates strcat_delim function for concatenating strings with a specified delimiter. Handles 2-64 arguments with automatic string conversion.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_22\n\nLANGUAGE: kusto\nCODE:\n```\nstrcat_delim(delimiter, argument1, argument2[ , argumentN])\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project strcat = strcat_delim(\":\", actor, creator)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nproject strcat = strcat_delim(\":\", \"axiom\", \"monitoring\")\n```\n\n----------------------------------------\n\nTITLE: Extracting Array Elements in ANSI SQL\nDESCRIPTION: This snippet demonstrates how to extract elements from an array using JSON functions in ANSI SQL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-slice.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_EXTRACT(my_array, '$[1:3]') AS sliced_array FROM my_table\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL and APL array conditional selection\nDESCRIPTION: Comparison between ANSI SQL's CASE statement approach for conditional array selection and APL's array_iff function, demonstrating the simplified syntax in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-iff.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCASE WHEN condition THEN array1 ELSE array2 END\n```\n\nLANGUAGE: kusto\nCODE:\n```\narray_iff(condition_array, array1, array2)\n```\n\n----------------------------------------\n\nTITLE: Adding Axiom Lambda Extension Layer in AWS Lambda UI\nDESCRIPTION: This snippet provides the ARN (Amazon Resource Name) to add the Axiom Lambda Extension as a layer in the AWS Lambda function UI. It requires replacing placeholders for AWS_REGION, ARCH, and VERSION.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-lambda.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\narn:aws:lambda:AWS_REGION:694952825951:layer:axiom-extension-ARCH:VERSION\n```\n\n----------------------------------------\n\nTITLE: Explaining IP-prefix Notation in APL\nDESCRIPTION: This section explains how IP-prefix notation works in APL, showing how to use the slash character to define IP addresses with subnet masks. It explains that the number after the slash indicates the number of contiguous bits in the netmask.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nIP-prefix notation\n\nYou can define IP addresses with IP-prefix notation using a slash (`/`) character. The IP address to the left of the slash is the base IP address. The number (1 to 32) to the right of the slash is the number of contiguous bits in the netmask. For example, `192.168.2.0/24` has an associated net/subnetmask containing 24 contiguous bits or `255.255.255.0` in dotted decimal format.\n```\n\n----------------------------------------\n\nTITLE: Defining ECS Task with FireLens for Fluent Bit\nDESCRIPTION: This JSON snippet demonstrates how to include FireLens configuration within an ECS task definition. It specifies the log router container using Fluent Bit and configures the application container to use the FireLens log driver.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-firelens.mdx#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"family\": \"myTaskDefinition\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"log_router\",\n      \"image\": \"amazon/aws-for-fluent-bit:latest\",\n      \"essential\": true,\n      \"firelensConfiguration\": {\n        \"type\": \"fluentbit\",\n        \"options\": {\n          \"config-file-type\": \"file\",\n          \"config-file-value\": \"/fluent-bit/etc/fluent-bit.conf\"\n        }\n      }\n    },\n    {\n      \"name\": \"myApp\",\n      \"image\": \"my-app-image\",\n      \"logConfiguration\": {\n        \"logDriver\": \"awsfirelens\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving First 10 Rows in Splunk SPL\nDESCRIPTION: This snippet shows how to retrieve the first 10 rows of data using the head command in Splunk SPL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/take-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| head 10\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Loki Proxy via Go\nDESCRIPTION: Command to install Axiom Loki Proxy using Go's package manager.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/loki-multiplexer.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngo get -u github.com/axiomhq/axiom-loki-proxy/cmd/axiom-loki-proxy\n```\n\n----------------------------------------\n\nTITLE: Checking for Infinite Values with isinf() in Kusto\nDESCRIPTION: The isinf() function checks if the input is an infinite value (positive or negative). It returns true for infinite values and false otherwise.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\nisinf(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nisinf(45.56) == false\n```\n\n----------------------------------------\n\nTITLE: Default Case-Insensitive Search in APL\nDESCRIPTION: Explicitly specifies the default search behavior (case-insensitive) when searching for \"INDIA\" in the sample-http-logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/search-operator.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| search kind=default \"INDIA\"\n```\n\n----------------------------------------\n\nTITLE: Using Wrangler Directly for Cloudflare Workers\nDESCRIPTION: Commands to directly use Wrangler for local development and deployment of Cloudflare Workers app.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nwrangler dev\n```\n\nLANGUAGE: bash\nCODE:\n```\nwrangler deploy\n```\n\n----------------------------------------\n\nTITLE: Sending Honeycomb Logs Using Golang\nDESCRIPTION: Example of sending structured logs from Honeycomb to Axiom using the libhoney-go library. Shows how to initialize the client, create events with multiple fields, and properly close the connection.\nSOURCE: https://github.com/axiomhq/docs/blob/main/endpoints/honeycomb.mdx#2025-04-22_snippet_2\n\nLANGUAGE: golang\nCODE:\n```\npackage main\n\nimport (\n\t\"github.com/honeycombio/libhoney-go\"\n)\n\nfunc main() {\n\tlibhoney.Init(libhoney.Config{\n\t\tWriteKey: \"\",\n\t\tDataset:  \"\",\n\t\tAPIHost:  \"\",\n\t})\n\n\tdefer libhoney.Close() // Flush any pending calls to Honeycomb\n\n\tvar ev = libhoney.NewEvent()\n\tev.Add(map[string]interface{}{\n\t\t\"duration_ms\":    155.67,\n\t\t\"method\":         \"post\",\n\t\t\"hostname\":       \"endpoints\",\n\t\t\"payload_length\": 43,\n\t})\n\tev.Send()\n}\n```\n\n----------------------------------------\n\nTITLE: Security Logs Analysis with dcountif\nDESCRIPTION: Example query showing how to count unique cities with forbidden access attempts.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcountif.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize dcountif(['geo.city'], status == '403')\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry OTLP Exporter Import\nDESCRIPTION: Import for OTLPSpanExporter to enable sending trace data to OTLP-compatible backends.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Syslog Proxy via Go\nDESCRIPTION: Command to install Axiom Syslog Proxy using Go package manager\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/syslog-proxy.mdx#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngo install github.com/axiomhq/axiom-syslog-proxy/cmd/axiom-syslog-proxy@latest\n```\n\n----------------------------------------\n\nTITLE: Configuring ProxyTransport for @axiomhq/logging\nDESCRIPTION: Example of configuring the ProxyTransport for the @axiomhq/logging library.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ProxyTransport } from \"@axiomhq/logging\";\n\nconst transport = new ProxyTransport({\n  url: \"/proxy\",\n  logLevel: \"warn\",\n  autoFlush: { durationMs: 1000 },\n});\n```\n\n----------------------------------------\n\nTITLE: Checking for NaN Values with isnan() in Kusto\nDESCRIPTION: The isnan() function checks if the input is a Not-a-Number (NaN) value. It returns true for NaN values and false otherwise.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\nisnan(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nisnan(45.56) == false\n```\n\n----------------------------------------\n\nTITLE: Using bool literals in APL\nDESCRIPTION: Examples of boolean literals in APL, including true/false values and null representations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/scalar-data-types.mdx#2025-04-22_snippet_0\n\nLANGUAGE: apl\nCODE:\n```\ntrue and bool(true)\nfalse and bool(false)\nnull and bool(null)\n```\n\n----------------------------------------\n\nTITLE: Example CloudWatch Log Group Structure\nDESCRIPTION: Example showing the structure of CloudWatch log group names for different AWS services including Lambda, EKS, and RDS.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/cloudwatch.mdx#2025-04-22_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\n/aws/lambda/function-foo\n/aws/lambda/function-bar\n/aws/eks/cluster/cluster-1\n/aws/rds/instance-baz\n```\n\n----------------------------------------\n\nTITLE: Trimming String End with Regular Expression using trim_end_regex Function in Kusto\nDESCRIPTION: Shows how to use trim_end_regex function to remove trailing matches of a specified regular expression from a string. It takes a regex and a source string as arguments.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_30\n\nLANGUAGE: kusto\nCODE:\n```\ntrim_end_regex(regex, source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project remove_cutset_regex = trim_end_regex( \"^github\", creator )\n```\n\n----------------------------------------\n\nTITLE: Calculating Base-2 Exponential with exp2() in Kusto\nDESCRIPTION: The exp2() function calculates the base-2 exponential of x (2^x). It takes a real number as input and returns the exponential value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\nexp2(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| project base_2_exponential_value = exp2(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Left and Right String Extraction in SQL and APL\nDESCRIPTION: Demonstrates extracting characters from the beginning and end of strings. SQL uses LEFT() and RIGHT() functions, while APL implements this with substring() and string length calculations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LEFT(content_type, 3) AS LeftTitle, RIGHT(content_type, 3) AS RightTitle\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend LeftTitle = substring(content_type, 0, 3), RightTitle = substring(content_type, strlen(content_type) - 3, 3)\n```\n\n----------------------------------------\n\nTITLE: Limiting Results in SQL\nDESCRIPTION: This SQL example shows how to limit the number of rows returned to 10 using the LIMIT clause.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/take-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM sample_http_logs LIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Basic Count Operation in APL\nDESCRIPTION: Simple count operator syntax demonstration in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/count-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| count\n```\n\n----------------------------------------\n\nTITLE: Ingesting CSV Events via Curl\nDESCRIPTION: Example of sending CSV formatted events to Axiom using curl. This request includes a simple CSV payload with headers.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/ingest.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/{dataset_name}/ingest' \\\n      -H 'Authorization: Bearer API_TOKEN' \\\n      -H 'Content-Type: text/csv' \\\n      -d 'user, name\n         foo, bar'\n```\n\n----------------------------------------\n\nTITLE: Running Vale Style Check on a Single Documentation File\nDESCRIPTION: Command to check the writing style of a specific MDX file using Vale style guide.\nSOURCE: https://github.com/axiomhq/docs/blob/main/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nvale example.mdx\n```\n\n----------------------------------------\n\nTITLE: Calculating End of Month in Axiom Query Language\nDESCRIPTION: The endofmonth() function returns the end of the month containing the given date. It sets the date to the last day of the month and the time to the last moment of the day.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_13\n\nLANGUAGE: kusto\nCODE:\n```\nendofmonth(date)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project end_of_the_month = endofmonth(datetime(2016-06-26T08:20))\n```\n\n----------------------------------------\n\nTITLE: Syntax of make_set in APL\nDESCRIPTION: The basic syntax for the make_set aggregation function in APL, showing required and optional parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nmake_set(column, [limit])\n```\n\n----------------------------------------\n\nTITLE: Parsing SQL INSERT with ON DUPLICATE KEY UPDATE in APL\nDESCRIPTION: Demonstrates parsing an SQL INSERT statement that includes an ON DUPLICATE KEY UPDATE clause for handling duplicate entries.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\nhn \n| project parse_sql(\"INSERT INTO settings (user_id, setting, value) VALUES (1, 'theme', 'dark') ON DUPLICATE KEY UPDATE value='dark'\")\n```\n\n----------------------------------------\n\nTITLE: Maven Project Configuration\nDESCRIPTION: Maven POM file defining project structure, dependencies, and build configuration for OpenTelemetry integration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>com.example</groupId>\n  <artifactId>axiom-otel-java</artifactId>\n  <version>1.0-SNAPSHOT</version>\n\n  <properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <maven.compiler.source>11</maven.compiler.source>\n    <maven.compiler.target>11</maven.compiler.target>\n    <opentelemetry.version>1.18.0</opentelemetry.version>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupId>io.opentelemetry</groupId>\n      <artifactId>opentelemetry-api</artifactId>\n      <version>${opentelemetry.version}</version>\n    </dependency>\n    <dependency>\n      <groupId>io.opentelemetry</groupId>\n      <artifactId>opentelemetry-sdk</artifactId>\n      <version>${opentelemetry.version}</version>\n    </dependency>\n    <dependency>\n      <groupId>io.opentelemetry</groupId>\n      <artifactId>opentelemetry-exporter-otlp</artifactId>\n      <version>${opentelemetry.version}</version>\n    </dependency>\n    <dependency>\n      <groupId>io.grpc</groupId>\n      <artifactId>grpc-netty-shaded</artifactId>\n      <version>1.42.1</version>\n    </dependency>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>4.13.2</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n\n  <build>\n    <plugins>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-compiler-plugin</artifactId>\n        <version>3.8.1</version>\n        <configuration>\n          <source>11</source>\n          <target>11</target>\n        </configuration>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-surefire-plugin</artifactId>\n        <version>3.0.0-M5</version>\n        <configuration>\n          <testFailureIgnore>true</testFailureIgnore>\n        </configuration>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-shade-plugin</artifactId>\n        <version>3.2.4</version>\n        <executions>\n          <execution>\n            <phase>package</phase>\n            <goals>\n              <goal>shade</goal>\n            </goals>\n            <configuration>\n              <transformers>\n                <transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\">\n                  <mainClass>com.example.DiceRollerApp</mainClass>\n                </transformer>\n              </transformers>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n    </plugins>\n  </build>\n</project>\n```\n\n----------------------------------------\n\nTITLE: Shifting Arrays in Splunk SPL vs APL\nDESCRIPTION: Comparison between Splunk SPL approach and APL's array_shift_right function for shifting array elements to the right.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-right.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval shifted_array=mvappend(mvindex(array,-1),mvindex(array,0,len(array)-1))\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset.name']\n| extend shifted_array = array_shift_right(array)\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with External Data in APL\nDESCRIPTION: Query that demonstrates using externaldata operator to cross-reference employee IDs from access logs with information from an external lookup table.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/externaldata-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\nlet employees = externaldata (employeeID: string, email: string, name: string, location: string) [\"http://example.com/lookup-table.csv\"] with (format=\"csv\", skipFirstRow=true);\naccessLogs\n| where severity == \"high\"\n| lookup employees on employeeID\n| project _time, severity, employeeID, email, name\n```\n\n----------------------------------------\n\nTITLE: Sample Metrics Event Data Structure in JSON\nDESCRIPTION: Example of how metrics data is structured in Axiom, showing a GPU utilization event with various metadata fields including job ID, timestamp, and metric values.\nSOURCE: https://github.com/axiomhq/docs/blob/main/getting-started-guide/observability.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"job_id\": \"train_123\",\n  \"user_name\": \"acme\",\n  \"timestamp\": \"2024-10-08T15:30:00Z\",\n  \"node_host\": \"worker-01\",\n  \"metric_name\": \"gpu_utilization\",\n  \"metric_value\": 87.5,\n  \"training_type\": \"image_classification\"\n}\n```\n\n----------------------------------------\n\nTITLE: Legacy Query API Request with Timestamp Pagination\nDESCRIPTION: Example of making a paginated query request to Axiom's Legacy Query endpoint using timestamp-based pagination with order and limit parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/pagination.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/{dataset_id}/query' \\\n-H 'Authorization: Bearer API_TOKEN' \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"startTime\": \"2024-11-30T00:00:00.000Z\",\n    \"endTime\": \"2024-11-30T23:59:59.999Z\",\n    \"limit\": 100,\n    \"order\": [{ \"field\": \"_time\", \"desc\": true }]\n  }'\n```\n\n----------------------------------------\n\nTITLE: API Route Implementation\nDESCRIPTION: Example API route implementation with a random dice roll function\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nextjs.mdx#2025-04-22_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nimport { NextResponse } from 'next/server';\n\nfunction getRandomNumber(min: number, max: number): number {\n  return Math.floor(Math.random() * (max - min) + min);\n}\n\nexport async function GET() {\n  const diceRoll = getRandomNumber(1, 6);\n  return NextResponse.json(diceRoll.toString());\n}\n```\n\n----------------------------------------\n\nTITLE: Axiom API Endpoint Definition for Creating Annotations\nDESCRIPTION: YAML frontmatter defining the API endpoint for creating annotations in Axiom's API v2.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/createAnnotation.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: Create annotation\nopenapi: \"v2 post /annotations\"\n---\n```\n\n----------------------------------------\n\nTITLE: Syntax for array_slice Function in APL\nDESCRIPTION: This snippet shows the syntax for using the array_slice function in APL, including its parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-slice.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\narray_slice(array, start, end)\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Core Trace Import\nDESCRIPTION: Basic import for OpenTelemetry trace functionality in Django applications.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies from requirements.txt\nDESCRIPTION: Command to install dependencies listed in requirements.txt file\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-python.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Using Wildcards with project-away for HTTP Logs in APL\nDESCRIPTION: An example of using wildcards with the project-away operator to exclude multiple fields that match a pattern, such as all fields starting with 'status', 'user', 'is', and any field under the 'geo.' namespace.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-away-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project-away status*, user*, is*,  ['geo.']*\n```\n\n----------------------------------------\n\nTITLE: Importing OpenTelemetry SDK Common Utilities for Java\nDESCRIPTION: This package provides common capabilities used across different parts of the OpenTelemetry SDK. It includes utilities for working with attributes, resources, and other shared concepts, ensuring consistency and simplifying implementation of cross-cutting concerns.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_17\n\nLANGUAGE: Java\nCODE:\n```\nio.opentelemetry:opentelemetry-sdk-common\n```\n\n----------------------------------------\n\nTITLE: Integer literals in APL\nDESCRIPTION: Examples of integer literals in APL, including null representation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/data-types/scalar-data-types.mdx#2025-04-22_snippet_3\n\nLANGUAGE: apl\nCODE:\n```\nint(null)\n```\n\n----------------------------------------\n\nTITLE: Sending Honeycomb Logs Using Python\nDESCRIPTION: Implementation of sending logs from Honeycomb to Axiom using the libhoney Python library. Demonstrates adding fields to events and sending them to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/endpoints/honeycomb.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport libhoney\nlibhoney.init(writekey=\"\", dataset=\"\", api_host=\"\")\n\nevent = libhoney.new_event()\nevent.add_field(\"foo\", \"bar\")\nevent.add({\"message\": \"Welcome, to Axiom Endpoints!\"})\nevent.send()\n```\n\n----------------------------------------\n\nTITLE: Laravel Log Output Format\nDESCRIPTION: Example of how log messages appear in the output\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-laravel.mdx#2025-04-22_snippet_4\n\nLANGUAGE: php\nCODE:\n```\n[2023-09-01 00:00:00] local.DEBUG: Checking details.\n[2023-09-01 00:00:00] local.INFO: User logged in.\n[2023-09-01 00:00:00] local.NOTICE: User tried a feature.\n[2023-09-01 00:00:00] local.WARNING: Feature might not work as expected.\n[2023-09-01 00:00:00] local.ERROR: Feature failed to load.\n[2023-09-01 00:00:00] local.CRITICAL: Major issue with the app.\n[2023-09-01 00:00:00] local.ALERT: Immediate action needed.\n[2023-09-01 00:00:00] local.EMERGENCY: The app is down.\n```\n\n----------------------------------------\n\nTITLE: Calculating End of Day in Axiom Query Language\nDESCRIPTION: The endofday() function returns the end of the day containing the given date. It sets the time to the last moment of the day (23:59:59.999999999).\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\nendofday(date)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project end_of_day_series = endofday(datetime(2016-06-26T08:20:03.123456Z))\n```\n\n----------------------------------------\n\nTITLE: Basic varianceif Syntax in APL\nDESCRIPTION: The formal syntax for the varianceif function in APL, showing the required summarize operation with expression and predicate parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/varianceif.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize varianceif(Expr, Predicate)\n```\n\n----------------------------------------\n\nTITLE: Basic Example of parse_ipv4_mask in APL\nDESCRIPTION: A simple example demonstrating how to use the parse_ipv4_mask function with a localhost IP and subnet mask of 24.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/parse-ipv4-mask.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\nprint parse_ipv4_mask(\"127.0.0.1\", 24)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies from requirements.txt\nDESCRIPTION: This command installs the Python packages listed in the requirements.txt file.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Calculating Natural Logarithm with log() in Kusto\nDESCRIPTION: The log() function calculates the natural logarithm (base-e) of x. It takes a real number greater than 0 as input and returns the logarithm value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_12\n\nLANGUAGE: kusto\nCODE:\n```\nlog(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nlog(1) == 0\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL for Average Calculation\nDESCRIPTION: This snippet shows how to calculate average request duration by status in both Splunk SPL and APL, demonstrating the syntax differences between the two languages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avg.mdx#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n| stats avg(req_duration_ms) by status\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize avg(req_duration_ms) by status\n```\n\n----------------------------------------\n\nTITLE: Setting Axiom Log Level in Next.js\nDESCRIPTION: Example of setting the log level for Axiom in a Next.js application using an environment variable.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nexport NEXT_PUBLIC_AXIOM_LOG_LEVEL=info\n```\n\n----------------------------------------\n\nTITLE: Replacing Regex Matches in APL\nDESCRIPTION: The replace function replaces all regex matches in a string with another string. It supports capture groups and backreferences for more complex replacements.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_15\n\nLANGUAGE: kusto\nCODE:\n```\nreplace(regex, rewrite, source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project content_type, Comment = replace(\"[html]\", \"[censored]\", method)\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven Dependencies for Log4j\nDESCRIPTION: Maven POM configuration that includes Log4j core, API, and SLF4J implementation dependencies, along with Jackson for JSON support. Also configures the Maven Shade plugin for creating an executable JAR.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-apache-log4j.mdx#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>com.example</groupId>\n  <artifactId>log4j-axiom-test</artifactId>\n  <packaging>jar</packaging>\n  <version>1.0-SNAPSHOT</version>\n  <name>log4j-axiom-test</name>\n  <url>http://maven.apache.org</url>\n\n  <properties>\n    <maven.compiler.source>11</maven.compiler.source>\n    <maven.compiler.target>11</maven.compiler.target>\n    <log4j.version>2.19.0</log4j.version>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>4.12</version>\n      <scope>test</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.apache.logging.log4j</groupId>\n      <artifactId>log4j-core</artifactId>\n      <version>${log4j.version}</version>\n    </dependency>\n    <dependency>\n      <groupId>org.apache.logging.log4j</groupId>\n      <artifactId>log4j-api</artifactId>\n      <version>${log4j.version}</version>\n    </dependency>\n    <dependency>\n      <groupId>org.apache.logging.log4j</groupId>\n      <artifactId>log4j-slf4j2-impl</artifactId>\n      <version>${log4j.version}</version>\n    </dependency>\n    <dependency>\n      <groupId>com.fasterxml.jackson.core</groupId>\n      <artifactId>jackson-databind</artifactId>\n      <version>2.13.0</version>\n    </dependency>\n  </dependencies>\n\n  <build>\n    <plugins>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-shade-plugin</artifactId>\n        <version>3.2.4</version>\n        <executions>\n          <execution>\n            <phase>package</phase>\n            <goals>\n              <goal>shade</goal>\n            </goals>\n            <configuration>\n              <transformers>\n                <transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\">\n                  <mainClass>com.example.App</mainClass>\n                </transformer>\n              </transformers>\n              <createDependencyReducedPom>false</createDependencyReducedPom>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n    </plugins>\n  </build>\n</project>\n```\n\n----------------------------------------\n\nTITLE: Creating a New Django Project\nDESCRIPTION: This command creates a new Django project using the django-admin tool.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndjango-admin startproject your_project_name\n```\n\n----------------------------------------\n\nTITLE: Running Vale Style Check on All Documentation Files\nDESCRIPTION: Command to check the writing style of all files in the current directory and subdirectories using Vale.\nSOURCE: https://github.com/axiomhq/docs/blob/main/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nvale .\n```\n\n----------------------------------------\n\nTITLE: Tracer Import for Views\nDESCRIPTION: Import statement for accessing the tracer instance in Django views for custom span creation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nfrom .exporter import tracer\n```\n\n----------------------------------------\n\nTITLE: Calculating Tangent in Kusto\nDESCRIPTION: Demonstrates the usage of the tan() function to calculate the tangent of a given value. The function takes a real number as input and returns the tangent of that number.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_24\n\nLANGUAGE: kusto\nCODE:\n```\ntan(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntan(25.563663) == 0.4597371460602336\n```\n\n----------------------------------------\n\nTITLE: Installing Node.js Dependencies\nDESCRIPTION: Command to install all required Node.js packages specified in package.json.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Identifying Status Code Position in Security Logs\nDESCRIPTION: A security-focused query using array_index_of to identify the index of a particular error or status code within an array of status codes. This helps in pinpointing where specific error conditions occur in the data sequence.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-index-of.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| take 50\n| summarize status_array = make_list(status)\n| extend index_500 = array_index_of(status_array, '500')\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Syslog Proxy from GitHub\nDESCRIPTION: Commands to clone and install Axiom Syslog Proxy from GitHub source\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/syslog-proxy.mdx#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/axiomhq/axiom-syslog-proxy.git\ncd axiom-syslog-proxy\nmake install\n```\n\n----------------------------------------\n\nTITLE: Syntax of isarray Function in APL\nDESCRIPTION: Shows the syntax for using the isarray function in APL. It takes a single parameter 'value' and returns a boolean.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/isarray.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nisarray(value)\n```\n\n----------------------------------------\n\nTITLE: API Endpoint Definition for Token Listing\nDESCRIPTION: OpenAPI specification for the GET /tokens endpoint that retrieves all API tokens. This endpoint requires authentication and returns a list of token objects.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/getTokens.mdx#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ntitle: List all API tokens\nopenapi: \"v2 get /tokens\"\n```\n\n----------------------------------------\n\nTITLE: Creating Arrays with pack_array in APL (ANSI SQL Comparison)\nDESCRIPTION: This snippet shows how to use pack_array in APL to create an array, compared to using ARRAY in ANSI SQL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/pack-array.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ARRAY[value1, value2, value3] AS array_field;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| extend array_field = pack_array(value1, value2, value3)\n```\n\n----------------------------------------\n\nTITLE: Example JSON Log File Structure for S3 Upload\nDESCRIPTION: This JSON structure represents a sample log file that can be uploaded to the S3 bucket. The Lambda function will process this file and send the data to Axiom. The log entries can include timestamps, data fields, attributes, and tags.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/aws-s3.mdx#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n[\n   {\n     \"_time\":\"2021-02-04T03:11:23.222Z\",\n     \"data\":{\"key1\":\"value1\",\"key2\":\"value2\"}\n   },\n   {\n     \"data\":{\"key3\":\"value3\"},\n     \"attributes\":{\"key4\":\"value4\"}\n   },\n   {\n     \"tags\": {\n       \"server\": \"aws\",\n       \"source\": \"wordpress\"\n     }\n   }\n ]\n```\n\n----------------------------------------\n\nTITLE: Percentile function syntax in APL\nDESCRIPTION: The basic syntax of the percentile function in Axiom Processing Language, showing how to specify the column and percentile value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentile.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\npercentile(column, percentile)\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Django Dependencies\nDESCRIPTION: Command to install required Python packages for OpenTelemetry integration with Django including API, SDK, OTLP exporter, and Django instrumentation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\npip install django opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp-proto-http opentelemetry-instrumentation-django\n```\n\n----------------------------------------\n\nTITLE: Installing @axiomhq/js via npm\nDESCRIPTION: Command to install the @axiomhq/js library using npm package manager.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install @axiomhq/js\n```\n\n----------------------------------------\n\nTITLE: Implementing Grok Filter in Logstash\nDESCRIPTION: Configuration showing how to use the Grok filter plugin to parse unstructured log data into structured format. Includes date parsing and field mutation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/logstash.mdx#2025-04-22_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\ninput{\n  exec{\n    command => \"axiom\"\n    interval => \"1\"\n  }\n}\n\nfilter {\n  grok {\n    match => { \"message\" => \"%{COMBINEDAPACHELOG}\" }\n  }\n\n  date {\n    match => [ \"timestamp\" , \"dd/MMM/yyyy:HH:mm:ss Z\" ]\n  }\n\n  mutate {\n    add_field => { \"foo\" => \"Hello Axiom, from Logstash\" }\n    remove_field => [ \"axiom\", \"logging\" ]\n  }\n}\n\noutput{\n  opensearch{\n    hosts => [\"https://api.axiom.co:443/v1/datasets/DATASET_NAME/elastic\"]\n    user => \"axiom\"\n    password => \"API_TOKEN\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extending Logger in Next.js with Axiom\nDESCRIPTION: Shows how to extend the Axiom logger with additional context in a Next.js application.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst logger = useLogger().with({ userId: 42 });\nlogger.info(\"Hi\"); // will ingest { ..., \"message\": \"Hi\", \"fields\" { \"userId\": 42 }}\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry BatchSpanProcessor Import\nDESCRIPTION: Import for BatchSpanProcessor to handle span batch processing before export.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n```\n\n----------------------------------------\n\nTITLE: Unquoted Identifier in APL Queries\nDESCRIPTION: Shows an example of an unquoted identifier in APL queries. Identifiers that don't contain special characters or match reserved keywords can be used without quotes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/entities/entity-names.mdx#2025-04-22_snippet_1\n\nLANGUAGE: APL\nCODE:\n```\nmyfield\n```\n\n----------------------------------------\n\nTITLE: Comparing IPv4 Addresses in ANSI SQL\nDESCRIPTION: This snippet shows how to compare two IP addresses in ANSI SQL using a CASE statement.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-compare.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CASE \n  WHEN ip1 < ip2 THEN -1\n  WHEN ip1 = ip2 THEN 0\n  ELSE 1\nEND AS comparison\nFROM ips;\n```\n\n----------------------------------------\n\nTITLE: has_ipv4 Syntax in APL\nDESCRIPTION: Specifies the syntax for the has_ipv4 function in Axiom Processing Language, showing the required parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-ipv4.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nhas_ipv4(source, ip_address)\n```\n\n----------------------------------------\n\nTITLE: Comparing IPv4 Addresses in APL\nDESCRIPTION: This snippet demonstrates the equivalent operation in APL using the ipv4_compare function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-compare.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n| extend comparison = ipv4_compare(ip1, ip2)\n```\n\n----------------------------------------\n\nTITLE: Managing Winlogbeat Service\nDESCRIPTION: PowerShell commands for validating configuration and managing the Winlogbeat service.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nPS C:\\Program Files\\Winlogbeat> .\\winlogbeat.exe test config -c .\\winlogbeat.yml -e\n\nPS C:\\Program Files\\Winlogbeat> Start-Service winlogbeat\n\nPS C:\\Program Files\\Winlogbeat> services.msc\n\nPS C:\\Program Files\\Winlogbeat> Stop-Service winlogbeat\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom CLI from source\nDESCRIPTION: Clone and build the Axiom CLI from source code using Git and Make.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/cli.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/axiomhq/cli.git\ncd cli\nmake install # Build and install binary into $GOPATH\n```\n\n----------------------------------------\n\nTITLE: Configuring Markdown Frontmatter for Axiom Tour Page\nDESCRIPTION: YAML frontmatter configuration for the Axiom tour documentation page, defining the title, description, icon, and external URL for the interactive demo.\nSOURCE: https://github.com/axiomhq/docs/blob/main/getting-started-guide/axiom-tour.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: \"Axiom tour\"\ndescription: \"Interactive demonstration of Axiom and its features\"\nicon: plane-departure\nurl: \"https://axiom.navattic.com/d8e0yrj\"\n---\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Delete Starred Query Endpoint\nDESCRIPTION: OpenAPI specification for the DELETE endpoint to remove a starred query by its ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/deleteStarred.mdx#2025-04-22_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\ndelete /apl-starred-queries/{id}\n```\n\n----------------------------------------\n\nTITLE: Reversing Strings in APL\nDESCRIPTION: The reverse function reverses the order of characters in a string. It takes a single string argument and returns the reversed string.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_18\n\nLANGUAGE: kusto\nCODE:\n```\nreverse(value)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nproject reversed = reverse(\"axiom\")\n```\n\n----------------------------------------\n\nTITLE: Deleting Annotations with Axiom API using cURL\nDESCRIPTION: This bash snippet shows how to delete an existing annotation using the Axiom API via a cURL DELETE request. It includes the API endpoint and authorization header.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/annotate-charts.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'DELETE' 'https://api.axiom.co/v2/annotations/ANNOTATION_ID' \\\n  -H 'Authorization: Bearer API_TOKEN' \n```\n\n----------------------------------------\n\nTITLE: Result Formatting and Column Selection\nDESCRIPTION: Shows how to select specific columns to include or exclude in the results.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_12\n\nLANGUAGE: splunk\nCODE:\n```\nEvent.Rule=330009.2 | table rule, state\n```\n\nLANGUAGE: apl\nCODE:\n```\n['sample-http-logs'] | project status, method\n```\n\n----------------------------------------\n\nTITLE: Adding Heroku Log Drain for Axiom Ingestion\nDESCRIPTION: This command configures a Heroku log drain to send logs to Axiom. It requires replacing placeholders for the API token, dataset name, and Heroku application name.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/heroku-log-drains.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nheroku drains:add https://axiom:API_TOKEN@api.axiom.co/v1/datasets/DATASET_NAME/ingest -a HEROKU_APPLICATION_NAME\n```\n\n----------------------------------------\n\nTITLE: Importing Axiom Logrus Adapter\nDESCRIPTION: Import statement for the Axiom Go SDK's Logrus adapter package.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/logrus.mdx#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nimport adapter \"github.com/axiomhq/axiom-go/adapters/logrus\"\n```\n\n----------------------------------------\n\nTITLE: Truncating Decimals in Kusto\nDESCRIPTION: Demonstrates using floor and ceiling functions to round decimal values in log data fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_22\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project floor_value = floor(resp_body_size_bytes), ceiling_value = ceiling(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Node.js Library\nDESCRIPTION: Command to install the official Axiom Node.js library using npm\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/query.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install @axiomhq/js\n```\n\n----------------------------------------\n\nTITLE: Filtering Records with Array Field in APL\nDESCRIPTION: Demonstrates how to use isarray function to filter records where the 'events' field contains an array. It also uses make_list to create an array from events.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/isarray.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| take 50\n| summarize events_array = make_list(events)\n| extend is_array = isarray(events_array)\n```\n\n----------------------------------------\n\nTITLE: Extracting Numeric Version Numbers in Sumo Logic\nDESCRIPTION: This Sumo Logic query parses version numbers, converts them to numeric format, and filters for specific values (2, 3, or 6).\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n* | parse \"Version=*.\" as number | num(number)\n| where number in (2,3,6)\n```\n\n----------------------------------------\n\nTITLE: Checking IP Prefix Match in Splunk SPL\nDESCRIPTION: This snippet demonstrates how to check if an IP address matches certain prefixes in Splunk SPL using pattern matching.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-any-ipv4-prefix.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval is_in_range=if(match(ip, \"10.*\") OR match(ip, \"192.168.*\"), 1, 0)\n```\n\n----------------------------------------\n\nTITLE: Navigating to Project Directory\nDESCRIPTION: This command changes the current directory to the newly created Django project directory.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd your_project_name\n```\n\n----------------------------------------\n\nTITLE: Update RBAC Group - OpenAPI v2 Endpoint Definition\nDESCRIPTION: API endpoint specification for updating an existing RBAC group. The endpoint uses PUT method and requires the group ID as a path parameter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/updateGroup.mdx#2025-04-22_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\nput /rbac/groups/{id}\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image for Log4j-Axiom Integration\nDESCRIPTION: This command builds a Docker image named 'log4j-axiom-test' from the Dockerfile in the current directory. It sets up the environment for running Log4j with Axiom integration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-apache-log4j.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t log4j-axiom-test .\n```\n\n----------------------------------------\n\nTITLE: Checking for Broken Links in Axiom Documentation\nDESCRIPTION: Command to validate and identify broken links within the Axiom documentation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm run mintlify broken-links\n```\n\n----------------------------------------\n\nTITLE: Creating Cloudflare Workers Project Directory\nDESCRIPTION: Commands to create a new directory for the Cloudflare Workers project and initialize it using Wrangler.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir my-axiom-worker && cd my-axiom-worker\n```\n\nLANGUAGE: bash\nCODE:\n```\nwrangler init --type=\"javascript\"\n```\n\n----------------------------------------\n\nTITLE: Building and Running the Application\nDESCRIPTION: Commands to build and run the .NET application.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-dotnet.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndotnet build\n\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry TracerProvider Import\nDESCRIPTION: Import statement for TracerProvider to configure tracing behavior in Django applications.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.sdk.trace import TracerProvider\n```\n\n----------------------------------------\n\nTITLE: APL Function Syntax Example\nDESCRIPTION: Basic syntax demonstration of the ipv4_is_in_any_range function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-in-any-range.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nipv4_is_in_any_range(ip_address: string, ranges: dynamic)\n```\n\n----------------------------------------\n\nTITLE: HTTP Header Configuration for Cribl-Axiom Integration\nDESCRIPTION: Example JSON header configuration for setting up HTTP destination in Cribl LogStream to forward logs to Axiom. Includes content type and authorization settings.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/cribl.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"Content-Type\": \"application/json\",\n  \"Authorization\": \"Bearer $API_Token\"\n}\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL and APL Distinct Counting\nDESCRIPTION: Example demonstrating conditional distinct counting in ANSI SQL versus APL syntax.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcountif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(DISTINCT CASE WHEN status = '200' THEN user_id END) AS distinct_successful_users\nFROM sample_http_logs\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize dcountif(id, status == '200')\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom JS Library with npm\nDESCRIPTION: Install the official Axiom Javascript library using npm.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/ingest.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install @axiomhq/js\n```\n\n----------------------------------------\n\nTITLE: Configuring ConsoleTransport for @axiomhq/logging\nDESCRIPTION: Example of configuring the ConsoleTransport for the @axiomhq/logging library.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ConsoleTransport } from \"@axiomhq/logging\";\n\nconst transport = new ConsoleTransport({\n  logLevel: \"warn\",\n  prettyPrint: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Parsing and Formatting SQL with Aggregation Functions in Kusto\nDESCRIPTION: This snippet focuses on parsing and reformatting an SQL statement that performs aggregation. It selects product IDs and counts of total sales from a sales table, grouping by product_id and having a condition on the count.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_13\n\nLANGUAGE: kusto\nCODE:\n```\nhn \n| extend parsed = parse_sql(\"SELECT product_id, COUNT(*) as total_sales FROM sales GROUP BY product_id HAVING COUNT(*) > 100\")\n| project formatted_sql = format_sql(parsed)\n```\n\n----------------------------------------\n\nTITLE: Parsing Kubernetes Logs with Regex Mode - Input Example\nDESCRIPTION: Example of a Kubernetes pod log entry containing pod status information to be parsed using regex mode.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nLog: PodStatusUpdate (podName=nginx-pod, namespace=default, phase=Running, startTime=2023-05-14 08:30:00, nodeName=node-1, hostIP=192.168.1.1, podIP=10.1.1.1)\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Definition for Token Deletion Endpoint\nDESCRIPTION: OpenAPI v2 specification defining the DELETE endpoint for removing API tokens by their ID. The endpoint path pattern is '/tokens/{id}'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/deleteToken.mdx#2025-04-22_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\nv2 delete /tokens/{id}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Notifier API Specification in YAML\nDESCRIPTION: YAML specification for the GET /notifiers/{id} endpoint. It defines the path parameters, responses, and security requirements for retrieving a specific notifier.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/getNotifier.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: 3.0.0\ninfo:\n  title: Retrieve notifier\n  version: 1.0.0\npaths:\n  /notifiers/{id}:\n    get:\n      summary: Retrieve a notifier\n      description: Retrieve a notifier by its ID.\n      parameters:\n        - name: id\n          in: path\n          required: true\n          schema:\n            type: string\n      responses:\n        '200':\n          description: Successful response\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Notifier'\n        '404':\n          description: Notifier not found\n      security:\n        - bearerAuth: []\ncomponents:\n  schemas:\n    Notifier:\n      type: object\n      # Define the Notifier schema here\n  securitySchemes:\n    bearerAuth:\n      type: http\n      scheme: bearer\n```\n\n----------------------------------------\n\nTITLE: Starting Laravel Development Server\nDESCRIPTION: Command to launch the Laravel development server for testing the Axiom logger implementation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-laravel.mdx#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nphp artisan serve\n```\n\n----------------------------------------\n\nTITLE: Reinstalling Mintlify Dependencies for Troubleshooting\nDESCRIPTION: Command to reinstall Mintlify dependencies when encountering build failures in the documentation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpm run mintlify install\n```\n\n----------------------------------------\n\nTITLE: Syntax for array_length Function in APL\nDESCRIPTION: The basic syntax for using the array_length function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-length.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\narray_length(array_expression)\n```\n\n----------------------------------------\n\nTITLE: JSON Response Structure for Axiom API Query\nDESCRIPTION: This JSON structure represents the response format for a successful Axiom API query. It includes buckets with series and totals, field metadata, matched data, and query status information.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/query.mdx#2025-04-22_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"buckets\": {\n    \"series\": [\n      {\n        \"endTime\": \"2022-07-26T03:00:48.925Z\",\n        \"groups\": [\n          {\n            \"aggregations\": [\n              {\n                \"op\": \"string\",\n                \"value\": {}\n              }\n            ],\n            \"group\": {\n              \"additionalProp1\": {},\n              \"additionalProp2\": {},\n              \"additionalProp3\": {}\n            },\n            \"id\": 0\n          }\n        ],\n        \"startTime\": \"2022-07-26T03:00:48.925Z\"\n      }\n    ],\n    \"totals\": [\n      {\n        \"aggregations\": [\n          {\n            \"op\": \"string\",\n            \"value\": {}\n          }\n        ],\n        \"group\": {\n          \"additionalProp1\": {},\n          \"additionalProp2\": {},\n          \"additionalProp3\": {}\n        },\n        \"id\": 0\n      }\n    ]\n  },\n  \"fieldsMeta\": [\n    {\n      \"description\": \"string\",\n      \"hidden\": true,\n      \"name\": \"string\",\n      \"type\": \"string\",\n      \"unit\": \"string\"\n    }\n  ],\n  \"matches\": [\n    {\n      \"_rowId\": \"string\",\n      \"_sysTime\": \"2022-07-26T03:00:48.925Z\",\n      \"_time\": \"2022-07-26T03:00:48.925Z\",\n      \"data\": {\n        \"additionalProp1\": {},\n        \"additionalProp2\": {},\n        \"additionalProp3\": {}\n      }\n    }\n  ],\n  \"status\": {\n    \"blocksExamined\": 0,\n    \"cacheStatus\": 0,\n    \"continuationToken\": \"string\",\n    \"elapsedTime\": 0,\n    \"isEstimate\": true,\n    \"isPartial\": true,\n    \"maxBlockTime\": \"2022-07-26T03:00:48.925Z\",\n    \"messages\": [\n      {\n        \"code\": \"string\",\n        \"count\": 0,\n        \"msg\": \"string\",\n        \"priority\": \"string\"\n      }\n    ],\n    \"minBlockTime\": \"2022-07-26T03:00:48.925Z\",\n    \"numGroups\": 0,\n    \"rowsExamined\": 0,\n    \"rowsMatched\": 0\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Array Operations with Concatenation and Sum\nDESCRIPTION: Demonstrates array_concat and array_sum functions on dynamic arrays\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_19\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend concatenate = array_concat( dynamic([5,4,3,87,45,2,3,45]))\n| project concatenate\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend summary_array=dynamic([1,2,3,4])\n| project summary_array=array_sum(summary_array)\n```\n\n----------------------------------------\n\nTITLE: Splunk vs APL IP Range Check Comparison\nDESCRIPTION: Comparison between Splunk's cidrmatch and APL's ipv4_is_in_range function for checking IP ranges.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-in-range.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval in_range = cidrmatch(\"192.168.0.0/24\", ip_address)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend in_range = ipv4_is_in_range(ip_address, '192.168.0.0/24')\n```\n\n----------------------------------------\n\nTITLE: Syncing Vale Style Packages for Documentation\nDESCRIPTION: Command to synchronize Vale style packages used for ensuring consistent documentation style.\nSOURCE: https://github.com/axiomhq/docs/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nvale sync\n```\n\n----------------------------------------\n\nTITLE: Checking Array Type in Splunk SPL vs APL\nDESCRIPTION: Compares how to check if a field is an array in Splunk SPL and APL. Splunk uses a manual approach with mvcount, while APL provides the isarray function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/isarray.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval is_array=if(isnotnull(mvcount(field)), \"true\", \"false\")\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset.name']\n| extend is_array=isarray(field)\n```\n\n----------------------------------------\n\nTITLE: Parsing HTTP Logs with Relaxed Mode - Output\nDESCRIPTION: JSON output showing the parsed results with extracted fields from HTTP request logs, including null values for invalid response times.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"method\": \"GET\",\n    \"url\": \"/home\",\n    \"status\": 200,\n    \"responseTime\": \"123ms\"\n  },\n  {\n    \"method\": \"POST\",\n    \"url\": \"/login\",\n    \"status\": 500,\n    \"responseTime\": null\n  },\n  {\n    \"method\": \"PUT\",\n    \"url\": \"/api/data\",\n    \"status\": 201,\n    \"responseTime\": \"456ms\"\n  },\n  {\n    \"method\": \"DELETE\",\n    \"url\": \"/user/123\",\n    \"status\": 404,\n    \"responseTime\": null\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Restarting NGINX After Configuration Change\nDESCRIPTION: Command to restart the NGINX service after updating its configuration to enable metrics exposure. This applies the configuration changes without requiring a full server restart.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl restart nginx\n```\n\n----------------------------------------\n\nTITLE: Inserting Inline SVG Icon in Markdown\nDESCRIPTION: This code snippet demonstrates how to insert an inline SVG icon within markdown text. It's used to display an 'Add element' icon in the instructions for creating a note.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/note.mdx#2025-04-22_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n<img src=\"/doc-assets/icons/plus.svg\" className=\"inline-icon\" alt=\"Add element\" />\n```\n\n----------------------------------------\n\nTITLE: Computing Variance with Conditions in Splunk SPL\nDESCRIPTION: Example showing how to calculate conditional variance in Splunk SPL by using the eval function to filter data before applying the var aggregation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/varianceif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval filtered_var=if(status==\"200\",req_duration_ms,null())\n| stats var(filtered_var)\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom SDK for Winston in Node.js\nDESCRIPTION: Installs the Axiom SDK for Winston using npm package manager.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/winston.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install @axiomhq/winston\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Specification for Listing Datasets in Axiom\nDESCRIPTION: YAML-formatted OpenAPI v2 specification for the GET /datasets endpoint. This endpoint retrieves a list of all datasets in an Axiom project.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/getDatasets.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nopenapi: \"v2 get /datasets\"\n```\n\n----------------------------------------\n\nTITLE: Syntax for array_shift_left Function in APL\nDESCRIPTION: Shows the basic syntax for using the array_shift_left function in APL, which takes an array parameter and a shift amount parameter to rotate elements to the left.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-shift-left.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['array_shift_left'](array, shift_amount)\n```\n\n----------------------------------------\n\nTITLE: Installing Node Dependencies for Axiom Documentation\nDESCRIPTION: Command to install Node.js dependencies required for the Axiom documentation repository.\nSOURCE: https://github.com/axiomhq/docs/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm i\n```\n\n----------------------------------------\n\nTITLE: OpenAPI Endpoint Specification for Legacy Dataset Query\nDESCRIPTION: OpenAPI specification for the legacy dataset query endpoint that allows querying data from a specific dataset via POST request.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/queryDataset.mdx#2025-04-22_snippet_0\n\nLANGUAGE: openapi\nCODE:\n```\nv1 post /datasets/{dataset_name}/query\n```\n\n----------------------------------------\n\nTITLE: Installing Winlogbeat Service\nDESCRIPTION: PowerShell command to install Winlogbeat as a Windows service.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/elastic-beats.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nPS C:\\Users\\Administrator> cd C:\\Program Files\\Winlogbeat\n\nPS C:\\Program Files\\Winlogbeat> .\\install-service-winlogbeat.ps1\n```\n\n----------------------------------------\n\nTITLE: Creating New Laravel Project\nDESCRIPTION: Command to create a new Laravel project using Composer package manager\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-laravel.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncomposer create-project --prefer-dist laravel/laravel laravel-axiom-logger\n```\n\n----------------------------------------\n\nTITLE: Counting Array Length in ANSI SQL\nDESCRIPTION: Example showing how to count array elements using CARDINALITY function in SQL databases that support arrays.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-length.mdx#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CARDINALITY(array_field) AS array_size\nFROM sample_table\n```\n\n----------------------------------------\n\nTITLE: Sampling Data with SQL vs APL\nDESCRIPTION: Comparison of sampling in ANSI SQL using TABLESAMPLE and APL's sample operator, showing how to retrieve a random subset of data rows.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sample-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM table TABLESAMPLE (10 ROWS);\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| sample 0.1\n```\n\n----------------------------------------\n\nTITLE: Retrieving First 10 Rows in APL for Security Logs\nDESCRIPTION: This APL query demonstrates how to use the take operator to sample the first 10 entries from a security log dataset for quick investigation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/take-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| take 10\n```\n\n----------------------------------------\n\nTITLE: Basic Axiom CLI command\nDESCRIPTION: Check version and basic commands of Axiom CLI.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/cli.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\naxiom\n```\n\n----------------------------------------\n\nTITLE: Pulling Axiom Loki Proxy Docker Image\nDESCRIPTION: Command to pull the latest Axiom Loki Proxy Docker image.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/loki-multiplexer.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull axiomhq/axiom-loki-proxy:latest\n```\n\n----------------------------------------\n\nTITLE: Markdown Table of Pricing-Based Limits\nDESCRIPTION: A detailed markdown table showing the various limits and features available across different pricing tiers (Personal, Team, and Enterprise)\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/field-restrictions.mdx#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n|                        | Personal                    | Team                                                                         | Enterprise |\n| ---------------------- | --------------------------- | ---------------------------------------------------------------------------- | ---------- |\n| Ingest (included)      | 500 GB / month              | 1 TB / month                                                                 | Custom     |\n| Ingest (maximum)       | 500 GB / month              | 50 TB / month                                                                | Custom     |\n| Query-hours (included) | 10 GB-hours / month         | 100 GB-hours / month                                                         | Custom     |\n| Retention              | 30 days                     | 95 days                                                                      | Custom     |\n| Datasets               | 2                           | 20                                                                           | Custom     |\n| Fields per dataset     | 256                         | 1024                                                                         | Custom     |\n| Monitors               | 3                           | 50                                                                           | Custom     |\n| Notifiers              | Email, Discord              | Email, Discord, Opsgenie,<br/>PagerDuty, Slack, Webhook,<br/>Microsoft Teams | Custom     |\n| Endpoints              | 1 (Honeycomb, Loki, Splunk) | 5 (Honeycomb, Loki, Splunk, Syslog)                                          | Custom     |\n```\n\n----------------------------------------\n\nTITLE: Result of Multiple Indices Array Split Operation\nDESCRIPTION: Shows the result of splitting the events array at indices 1 and 2, creating three separate subarrays each containing a single event object from the original array.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-split.mdx#2025-04-22_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n[\n  [\n    {\n      \"timestamp\": 1734034755085206000,\n      \"attributes\": null,\n      \"name\": \"Enqueued\"\n    }\n  ],\n  [\n    {\n      \"timestamp\": 1734034755085215500,\n      \"attributes\": null,\n      \"name\": \"Sent\"\n    }\n  ],\n  [\n    {\n      \"attributes\": null,\n      \"name\": \"ResponseReceived\",\n      \"timestamp\": 1734034755085424000\n    }\n  ]\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Maven Project for Log4j Integration\nDESCRIPTION: Creates a new Maven project using the quickstart archetype with group ID com.example and artifact ID log4j-axiom-test.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-apache-log4j.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmvn archetype:generate -DgroupId=com.example -DartifactId=log4j-axiom-test -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false\n\ncd log4j-axiom-test\n```\n\n----------------------------------------\n\nTITLE: Original Events Array JSON Example\nDESCRIPTION: Example JSON output showing the original events array before rotation, containing timestamped trace events.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-rotate-left.mdx#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"name\": \"Enqueued\",\n    \"timestamp\": 1733997117722909000\n  },\n  {\n    \"timestamp\": 1733997117722911700,\n    \"name\": \"Sent\"\n  },\n  {\n    \"name\": \"ResponseReceived\",\n    \"timestamp\": 1733997117723591400\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring package.json for Cloudflare Workers\nDESCRIPTION: Configuration for package.json file, including dependencies required for OpenTelemetry and Cloudflare Workers.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"my-axiom-worker\",\n    \"version\": \"1.0.0\",\n    \"description\": \"A template for kick-starting a Cloudflare Workers project\",\n    \"main\": \"index.ts\",\n    \"scripts\": {\n      \"start\": \"wrangler dev\",\n      \"deploy\": \"wrangler publish\"\n    },\n    \"dependencies\": {\n      \"@microlabs/otel-cf-workers\": \"^1.0.0-rc.20\",\n      \"@opentelemetry/api\": \"^1.6.0\",\n      \"@opentelemetry/core\": \"^1.17.1\",\n      \"@opentelemetry/exporter-trace-otlp-http\": \"^0.43.0\",\n      \"@opentelemetry/otlp-exporter-base\": \"^0.43.0\",\n      \"@opentelemetry/otlp-transformer\": \"^0.43.0\",\n      \"@opentelemetry/resources\": \"^1.17.1\",\n      \"@opentelemetry/sdk-trace-base\": \"^1.17.1\",\n      \"@opentelemetry/semantic-conventions\": \"^1.17.1\",\n      \"deepmerge\": \"^4.3.1\",\n      \"husky\": \"^8.0.3\",\n      \"lint-staged\": \"^15.0.2\",\n      \"ts-checked-fsm\": \"^1.1.0\"\n    },\n    \"devDependencies\": {\n      \"@changesets/cli\": \"^2.26.2\",\n      \"@cloudflare/workers-types\": \"^4.20231016.0\",\n      \"prettier\": \"^3.0.3\",\n      \"rimraf\": \"^4.4.1\",\n      \"typescript\": \"^5.2.2\",\n      \"wrangler\": \"2.13.0\"\n    },\n    \"private\": true\n  }\n```\n\n----------------------------------------\n\nTITLE: Limiting Query Results in Splunk and APL\nDESCRIPTION: Examples showing how to limit the number of returned results using head/take operations in both Splunk and APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_8\n\nLANGUAGE: splunk\nCODE:\n```\nSample.Logs=330009.2 | head 100\n```\n\nLANGUAGE: apl\nCODE:\n```\n['sample-htto-logs'] | limit 100\n```\n\n----------------------------------------\n\nTITLE: Variance Function Syntax in APL\nDESCRIPTION: The syntax for using the variance aggregation function in APL, which calculates the variance of a numeric expression across records.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/variance.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize variance(Expression)\n```\n\n----------------------------------------\n\nTITLE: Counting HTTP Requests in APL\nDESCRIPTION: Example of counting total HTTP requests in a log dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/count-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| count\n```\n\n----------------------------------------\n\nTITLE: Importing MDX Component for Ingest Data Limits\nDESCRIPTION: Imports a reusable MDX component that contains information about data ingestion limits\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/field-restrictions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nimport IngestDataLimits from \"/snippets/ingest-data-limits.mdx\"\n```\n\n----------------------------------------\n\nTITLE: Installing next-axiom in Next.js\nDESCRIPTION: Command to install the next-axiom library in a Next.js project using npm.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install --save next-axiom\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Instrumentation\nDESCRIPTION: Sets up OpenTelemetry instrumentation including OTLP exporters for traces and initializes the Node SDK with automatic instrumentation capabilities.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-nodejs.mdx#2025-04-22_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n/*instrumentation.ts*/\n\n// Importing necessary OpenTelemetry packages including the core SDK, auto-instrumentations, OTLP trace exporter, and batch span processor\nimport { NodeSDK } from '@opentelemetry/sdk-node';\nimport { getNodeAutoInstrumentations } from '@opentelemetry/auto-instrumentations-node';\nimport { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-proto';\nimport { BatchSpanProcessor } from '@opentelemetry/sdk-trace-base';\nimport { Resource } from '@opentelemetry/resources';\nimport { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';\n\n// Initialize OTLP trace exporter with the endpoint URL and headers\nconst traceExporter = new OTLPTraceExporter({\n  url: 'https://api.axiom.co/v1/traces',\n  headers: {\n    'Authorization': 'Bearer API_TOKEN',\n    'X-Axiom-Dataset': 'DATASET_NAME'\n  },\n});\n\n// Creating a resource to identify your service in traces\nconst resource = new Resource({\n  [SemanticResourceAttributes.SERVICE_NAME]: 'node traces',\n});\n\n// Configuring the OpenTelemetry Node SDK\nconst sdk = new NodeSDK({\n  // Adding a BatchSpanProcessor to batch and send traces\n  spanProcessor: new BatchSpanProcessor(traceExporter),\n\n  // Registering the resource to the SDK\n  resource: resource,\n\n  // Adding auto-instrumentations to automatically collect trace data\n  instrumentations: [getNodeAutoInstrumentations()],\n});\n\n// Starting the OpenTelemetry SDK to begin collecting telemetry data\nsdk.start();\n```\n\n----------------------------------------\n\nTITLE: Basic 'where * has' Usage in APL\nDESCRIPTION: Example of using the '* has' pattern to search for a specific substring across all fields in a dataset. This query finds events where any field contains 'GET'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| where * has \"GET\"\n```\n\n----------------------------------------\n\nTITLE: Importing Prerequisites Component in Markdown\nDESCRIPTION: This code snippet imports a Prerequisites component from a separate MDX file. It's likely used to include common prerequisite information across multiple documentation pages.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/note.mdx#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nimport Prerequisites from \"/snippets/dashboard-minimal-prerequisites.mdx\"\n```\n\n----------------------------------------\n\nTITLE: Calculating End of Year in Axiom Query Language\nDESCRIPTION: The endofyear() function returns a datetime representing the end of the year for the given date value. It is used to find the last moment of the year containing the input date.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\nendofyear(date)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend end_of_the_year = endofyear(datetime(2016-06-26T08:20))\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAPI Endpoint for Deleting User from Organization\nDESCRIPTION: This YAML snippet specifies the OpenAPI definition for the endpoint to delete a user from an organization. It uses the DELETE HTTP method and includes a path parameter for the user ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/endpoints/removeUserFromOrg.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntitle: Delete user from org\nopenapi: \"v2 delete /users/{id}\"\n```\n\n----------------------------------------\n\nTITLE: String Trimming Functions in KQL\nDESCRIPTION: Demonstrates trim and trim_regex functions for removing leading and trailing characters or patterns from strings.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_28\n\nLANGUAGE: kusto\nCODE:\n```\ntrim(source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend remove_leading_matches = trim( \"locked\", repo)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nproject remove_leading_matches = trim( \"axiom\", \"observability\")\n```\n\nLANGUAGE: kusto\nCODE:\n```\ntrim_regex(regex, source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend remove_trailing_match_regex = trim_regex( \"^github\", action )\n```\n\n----------------------------------------\n\nTITLE: Searching Map Fields in Trace Data\nDESCRIPTION: Demonstrates how to search through nested map fields in OpenTelemetry trace data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_26\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| where isnotnull( ['attributes.custom'])\n| extend extra = tostring(['attributes.custom'])\n| search extra:\"0PUK6V6EV0\"\n| project _time, trace_id, name, ['attributes.custom']\n```\n\n----------------------------------------\n\nTITLE: Calculating Sine with sin() in Kusto\nDESCRIPTION: The sin() function calculates the sine of an angle in radians. It takes a real number as input and returns the sine value.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_22\n\nLANGUAGE: kusto\nCODE:\n```\nsin(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nsin(25.563663) == 0.41770848373492825\n```\n\n----------------------------------------\n\nTITLE: Using atan() Function in Kusto\nDESCRIPTION: Examples of using the atan() function to calculate arc tangent values. The function returns the angle whose tangent is the specified number, with a calculation and a practical query example.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\natan(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\natan(-1) == -0.7853981633974483\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project inverse_tan_angle = atan(-1)\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis\nDESCRIPTION: Example query calculating average request duration for failed HTTP requests grouped by country.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avgif.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| summarize avgif(req_duration_ms, toint(status) >= 400) by ['geo.country']\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Exporter in Ruby on Rails\nDESCRIPTION: This code configures the OpenTelemetry SDK and OTLP exporter in a Ruby on Rails application. It sets up the service name, enables all instrumentations, and configures the exporter to send data to Axiom with the specified API token and dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-ruby.mdx#2025-04-22_snippet_1\n\nLANGUAGE: ruby\nCODE:\n```\nrequire 'opentelemetry/sdk'\nrequire 'opentelemetry/exporter/otlp'\nrequire 'opentelemetry/instrumentation/all'\n\nOpenTelemetry::SDK.configure do |c|\n  c.service_name = 'ruby-traces' # Set your service name\n\n  c.use_all # Or specify individual instrumentation you need\n\n  c.add_span_processor(\n    OpenTelemetry::SDK::Trace::Export::BatchSpanProcessor.new(\n      OpenTelemetry::Exporter::OTLP::Exporter.new(\n        endpoint: 'https://api.axiom.co/v1/traces',\n        headers: {\n          'Authorization' => 'Bearer API_TOKEN',\n          'X-AXIOM-DATASET' => 'DATASET_NAME'\n        }\n      )\n    )\n  )\nend\n```\n\n----------------------------------------\n\nTITLE: Identifying Private IPs in Splunk SPL\nDESCRIPTION: This snippet shows how to check for private IP addresses in Splunk SPL using CIDR matching functions. It's provided as a comparison to the APL approach.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-private.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\neval is_private=if(cidrmatch(\"10.0.0.0/8\", ip) OR cidrmatch(\"172.16.0.0/12\", ip) OR cidrmatch(\"192.168.0.0/16\", ip), 1, 0)\n```\n\n----------------------------------------\n\nTITLE: Using String Subsequence Matching Operators in Kusto\nDESCRIPTION: Examples of string subsequence matching operators for testing if a string contains, starts with, or ends with another string. Includes both case-sensitive and case-insensitive variants of these operators.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-operators/string-operators.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n\"parentSpanId\" contains \"Span\" // True\n\"parentSpanId\" !contains \"xyz\" // True\n\"parentSpanId\" startswith \"parent\" // True\n\"parentSpanId\" endswith \"Id\" // True\n\"parentSpanId\" contains_cs \"Span\" // True if parentSpanId is \"parentSpanId\", False if parentSpanId is \"parentspanid\" or \"PARENTSPANID\"\n\"parentSpanId\" startswith_cs \"parent\" // True if parentSpanId is \"parentSpanId\", False if parentSpanId is \"ParentSpanId\" or \"PARENTSPANID\"\n\"parentSpanId\" endswith_cs \"Id\" // True if parentSpanId is \"parentSpanId\", False if parentSpanId is \"parentspanid\" or \"PARENTSPANID\"\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL values with APL make_set_if Function\nDESCRIPTION: Shows how the Splunk SPL values function with a where condition compares to the APL make_set_if function for creating distinct sets based on conditions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-set-if.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats values(field) by another_field where condition\n```\n\nLANGUAGE: kusto\nCODE:\n```\nsummarize make_set_if(field, condition) by another_field\n```\n\n----------------------------------------\n\nTITLE: Sending Kafka Logs to Axiom with Vector\nDESCRIPTION: A Vector configuration for consuming logs from Kafka topics and sending them to Axiom. Requires specifying Kafka bootstrap servers, consumer group ID, and topics to consume from.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_kafka_source]\ntype = \"kafka\" # must be: kafka\nbootstrap_servers = \"10.14.22.123:9092\" # your Kafka bootstrap servers\ngroup_id = \"my_group_id\" # your Kafka consumer group ID\ntopics = [\"my_topic\"] # the Kafka topics to consume from\nauto_offset_reset = \"earliest\" # start reading from the beginning\n\n[sinks.axiom]\ntype = \"axiom\"\ninputs = [\"my_kafka_source\"]  # connect the Axiom sink to your Kafka source\ndataset = \"DATASET_NAME\"  # replace with the name of your Axiom dataset\ntoken = \"API_TOKEN\"  # replace with your Axiom API token\n```\n\n----------------------------------------\n\nTITLE: Counting Browser Hits in APL\nDESCRIPTION: This APL query counts hits for IE, Firefox, Safari, and Chrome browsers using the sample-http-logs dataset. It uses case statements to identify browsers and summarizes the counts.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_19\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend ie = case(tolower(user_agent) contains \"msie\", 1, 0)\n| extend firefox = case(tolower(user_agent) contains \"firefox\", 1, 0)\n| extend safari = case(tolower(user_agent) contains \"safari\", 1, 0)\n| extend chrome = case(tolower(user_agent) contains \"chrome\", 1, 0)\n| summarize data = sum(ie), lima = sum(firefox), lo = sum(safari), ce = sum(chrome)\n```\n\n----------------------------------------\n\nTITLE: Importing OpenTelemetry Libraries in Python\nDESCRIPTION: Essential library imports for OpenTelemetry implementation including trace management, span processing, and OTLP export functionality. These imports provide the foundation for creating and managing trace data, configuring tracing behavior, and exporting telemetry data to backend systems.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-python.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.sdk.resources import Resource, SERVICE_NAME\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n```\n\n----------------------------------------\n\nTITLE: Creating Annotations using Axiom API with cURL\nDESCRIPTION: This bash snippet demonstrates how to create an annotation using the Axiom API via a cURL POST request. It includes the API endpoint, authorization header, and JSON payload with annotation details.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/annotate-charts.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v2/annotations' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"time\": \"2024-03-18T08:39:28.382Z\",\n    \"type\": \"deploy\",\n    \"datasets\": [\"DATASET_NAME\"],\n    \"title\": \"Production deployment\",\n    \"description\": \"Deploy new feature to the sales form\",\n    \"url\": \"https://example.com\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Calculating Request Duration Percentiles with percentiles_arrayif in APL\nDESCRIPTION: This snippet demonstrates how to use the percentiles_arrayif function to calculate multiple percentiles of request durations for HTTP status 200 responses. It filters the 'sample-http-logs' dataset and computes the 50th, 90th, 95th, and 99th percentiles of the req_duration_ms field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-arrayif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize percentiles_arrayif(req_duration_ms, dynamic([50, 90, 95, 99]), status == '200') by bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Calculating Rate in Splunk vs APL\nDESCRIPTION: Comparison between Splunk SPL and APL for calculating rate of response body size bytes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/rate.mdx#2025-04-22_snippet_0\n\nLANGUAGE: splunk\nCODE:\n```\n| timechart per_second count by resp_body_size_bytes\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize rate(resp_body_size_bytes) by bin(_time, 1s)\n```\n\n----------------------------------------\n\nTITLE: Ingesting Mixed JSON Events via Curl\nDESCRIPTION: Example of sending JSON events with mixed data types (objects, strings, and arrays) to Axiom using curl.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/ingest.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/{dataset_name}/ingest' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -H 'Content-Type: application/json' \\\n  -d '[{ \"axiom\": {\n    \"logging\": {\n        \"observability\": [\n            { \"apl\": 23, \"function\": \"tostring\" },\n            { \"apl\": 24, \"operator\": \"summarize\" }\n        ],\n        \"axiom\": [\n            { \"stream\": \"livetail\", \"datasets\": [4, 0, 16], \"logging\": \"observability\", \"metrics\": 8, \"dashboard\": 10, \"alerting\": \"kubernetes\" }\n        ]\n    },\n    \"apl\": {\n        \"reference\":\n            [[80, 12], [30, 40]]\n    }\n  }\n}]'\n```\n\n----------------------------------------\n\nTITLE: Ingesting JSON Data with Axiom API\nDESCRIPTION: Example of sending JSON data to Axiom's ingest API endpoint using curl. Demonstrates sending multiple events with timestamps, data fields, attributes, and tags.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/ingest.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X 'POST' 'https://api.axiom.co/v1/datasets/DATASET_NAME/ingest' \\\n  -H 'Authorization: Bearer API_TOKEN' \\\n  -H 'Content-Type: application/json' \\\n  -d '[\n        {\n          \"_time\":\"2021-02-04T03:11:23.222Z\",\n          \"data\":{\"key1\":\"value1\",\"key2\":\"value2\"}\n        },\n        {\n          \"data\":{\"key3\":\"value3\"},\n          \"attributes\":{\"key4\":\"value4\"}\n        },\n        {\n          \"tags\": {\n            \"server\": \"aws\",\n            \"source\": \"wordpress\"\n          }\n        }\n      ]'\n```\n\n----------------------------------------\n\nTITLE: Example Response from Axiom API for Data Block Deletion\nDESCRIPTION: This JSON response shows the result of a dry run deletion request. It includes information about the number of rows matched and deleted, as well as the timestamp range of the affected events.\nSOURCE: https://github.com/axiomhq/docs/blob/main/restapi/delete-blocks.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n{\n    \"dryRun\": true,\n    \"firstMatchedEvent\": \"2024-08-25 00:18:19 +0000 UTC\",\n    \"lastMatchedEvent\": \"2024-08-25 00:18:19 +0000 UTC\",\n    \"rowsDeleted\": 10249,\n    \"rowsMatched\": 1\n}\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL Top Operation with APL Equivalent\nDESCRIPTION: This snippet demonstrates how to convert a Splunk SPL query using the 'top' operator to its APL equivalent. The Splunk example retrieves the top 5 records by request duration, while the APL equivalent achieves the same result with a slightly different syntax.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/top-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nindex=\"sample_http_logs\" | top limit=5 req_duration_ms\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| top 5 by req_duration_ms\n```\n\n----------------------------------------\n\nTITLE: Union with Field Removal in APL\nDESCRIPTION: This example removes specific fields from the datasets before combining them using the union operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| union ['github-push-event']\n| project-away content_type, commits\n```\n\n----------------------------------------\n\nTITLE: Reordering Pages by Load Frequency in Sumo Logic and APL\nDESCRIPTION: Shows how to count pages, then sort them by frequency of access. Sumo Logic counts by URL and sorts by count, while APL extracts data, counts by URL and source IP, then orders by count in descending order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache \n| parse \"* \" as src_ip \n| parse \"GET * \" as url \n| count by url \n| sort by _count\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend src_ip = extract(\".*\", 0, ['id'])\n| extend url = extract(\"(GET)\", 1, method)\n| where isnotnull(url)\n| summarize _count = count() by url, src_ip\n| order by _count desc\n```\n\n----------------------------------------\n\nTITLE: Migrating Timestamp Field in Vector VRL\nDESCRIPTION: VRL script to migrate from the legacy 'timestamp' field to the '_time' field required by newer Vector versions. It sets the '_time' field explicitly with the value from 'timestamp' and then removes the original timestamp field to avoid duplication.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/vector.mdx#2025-04-22_snippet_12\n\nLANGUAGE: vrl\nCODE:\n```\n# Set time explicitly rather than allowing Axiom to default to the current time\n. = set!(value: ., path: [\"_time\"],  data: .timestamp)\n\n# Remove the original value as it is effectively a duplicate\ndel(.timestamp)\n```\n\n----------------------------------------\n\nTITLE: Events Array Example for Multiple Indices Split\nDESCRIPTION: Provides an example of a source events array with three event objects that includes additional attributes field, before splitting with multiple indices is applied.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-split.mdx#2025-04-22_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"attributes\": null,\n    \"name\": \"Enqueued\",\n    \"timestamp\": 1734034755085206000\n  },\n  {\n    \"name\": \"Sent\",\n    \"timestamp\": 1734034755085215500,\n    \"attributes\": null\n  },\n  {\n    \"attributes\": null,\n    \"name\": \"ResponseReceived\",\n    \"timestamp\": 1734034755085424000\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Extracting Multiple Fields from Apache Traffic in Sumo Logic and APL\nDESCRIPTION: Demonstrates extracting source IP addresses, message sizes, and URLs from Apache logs in both query languages. This shows how to parse multiple pieces of information from the same log entry.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n_sourceCategory=apache\n| parse \"* \" as src_IP\n| parse \" 200 * \" as size\n| parse \"GET * \" as url\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend src_IP = extract(\"^(\\S+)\", 0, uri)\n| extend size = extract(\"^(\\S+)\", 1, status)\n| extend url = extract(\"^(\\S+)\", 1, method)\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL lookup implementations\nDESCRIPTION: This snippet demonstrates the difference between Splunk SPL's lookup command and APL's lookup operator. While Splunk's lookup command enriches event data with fields from an external lookup table, APL's lookup operator only performs an inner join.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/lookup-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nindex=web_logs | lookup port_lookup port AS client_port OUTPUT service_name\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| lookup kind=inner ['port_lookup'] on port\n```\n\n----------------------------------------\n\nTITLE: Basic Union of GitHub Event Logs in APL\nDESCRIPTION: This example combines all rows from 'github-push-event' and 'github-pull-request-event' without any transformation or filtering.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['github-push-event']\n| union ['github-pull-request-event']\n```\n\n----------------------------------------\n\nTITLE: Analyzing HTTP Response Times by Status Code using stdev in APL\nDESCRIPTION: This query calculates the standard deviation of request durations grouped by HTTP status code. It demonstrates how to use stdev in security log analysis to identify patterns related to response times across different status codes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdev.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize resp_time_std = stdev(req_duration_ms) by status\n```\n\n----------------------------------------\n\nTITLE: Importing OpenTelemetry Protocol (OTLP) Exporter for Java\nDESCRIPTION: This exporter sends telemetry data using the OpenTelemetry Protocol (OTLP). It allows Java applications to send collected traces, metrics, and logs to any backend supporting OTLP, ensuring broad compatibility and standardized data transmission.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_14\n\nLANGUAGE: Java\nCODE:\n```\nio.opentelemetry:opentelemetry-exporter-otlp\n```\n\n----------------------------------------\n\nTITLE: Adding Faraday and dotenv-rails to Gemfile in Ruby\nDESCRIPTION: This snippet shows how to add the Faraday and dotenv-rails gems to the Gemfile of a Ruby on Rails application. These gems are required for making HTTP requests and managing environment variables respectively.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-ruby-on-rails.mdx#2025-04-22_snippet_0\n\nLANGUAGE: ruby\nCODE:\n```\ngem 'faraday'\ngem 'dotenv-rails', groups: [:development, :test]\n```\n\n----------------------------------------\n\nTITLE: Querying Distinct Countries for Select Filter in Axiom\nDESCRIPTION: This APL query retrieves distinct country values from the 'sample-http-logs' dataset, projecting them as both key and value for a select filter, and sorts them alphabetically.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/filters.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| distinct ['geo.country']\n| project key=['geo.country'] , value=['geo.country']\n| sort by key asc\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Attributes to Activities in C#\nDESCRIPTION: Enhance activities with custom attributes to provide additional context, making it easier to analyze telemetry data. This snippet shows how to add user ID and operation details as custom attributes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-dotnet.mdx#2025-04-22_snippet_6\n\nLANGUAGE: csharp\nCODE:\n```\nactivity?.SetTag(\"UserId\", userId);\nactivity?.SetTag(\"OperationDetail\", \"Detail about the operation\");\n```\n\n----------------------------------------\n\nTITLE: Running Docker Container for Log4j-Axiom Integration\nDESCRIPTION: This command runs the 'log4j-axiom-test' container, mapping port 24224 from the container to the host. It starts both Fluentd and the Java application for sending logs to Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-apache-log4j.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 24224:24224 log4j-axiom-test\n```\n\n----------------------------------------\n\nTITLE: Advanced Chaining with 'where * has' and Summarize in APL\nDESCRIPTION: Example of chaining the '* has' pattern with summarize operator. This query filters data where any field contains 'GET' and 'css', then summarizes by method, content_type, and server_datacenter.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_9\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where * has \"GET\" and * has \"css\"\n| summarize Count=count() by method, content_type, server_datacenter\n```\n\n----------------------------------------\n\nTITLE: Using cos() Function in Kusto\nDESCRIPTION: Examples of using the cos() function to calculate cosine values. The function takes an angle in radians and returns its cosine value, with a practical query example.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\ncos(x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\ncos(-1) == 0.5403023058681398\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project cosine_function = cos(-1)\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL for IP Address Matching\nDESCRIPTION: This snippet demonstrates how to use the cidrmatch function in Splunk SPL and the equivalent has_any_ipv4 function in APL to match IP addresses against a CIDR range.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-any-ipv4.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| where cidrmatch(\"192.168.1.0/24\", ip_field)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where has_any_ipv4('ip_field', dynamic(['192.168.1.0/24']))\n```\n\n----------------------------------------\n\nTITLE: Excluding Specific Fields in Kusto Query\nDESCRIPTION: This example shows how to use the 'project-away' clause in a Kusto query to exclude specific large fields while keeping most others, which can be useful for optimizing queries on datasets with many fields.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/performance.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| project-away debug_payload, large_object_field\n```\n\n----------------------------------------\n\nTITLE: Importing OpenTelemetry SDK Auto-configuration Extension for Java\nDESCRIPTION: This extension provides auto-configuration capabilities for the OpenTelemetry SDK. It allows configuration using environment variables or system properties, simplifying setup and deployment in various environments, particularly for containerized or cloud applications.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_15\n\nLANGUAGE: Java\nCODE:\n```\nio.opentelemetry:opentelemetry-sdk-extension-autoconfigure\n```\n\n----------------------------------------\n\nTITLE: Security Log Analysis with Filtering and limit\nDESCRIPTION: A query that combines filtering with the limit operator to analyze the 5 most recent unauthorized access attempts (HTTP status 401) from a logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/limit-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where status == '401'\n| limit 5\n```\n\n----------------------------------------\n\nTITLE: Using OpenTelemetry Tracer in Django Views\nDESCRIPTION: This code demonstrates how to use the OpenTelemetry tracer in Django views, creating spans to capture the execution of individual request handlers.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom django.http import HttpResponse\nfrom .exporter import tracer  # Import the tracer\n\ndef roll_dice(request):\n    with tracer.start_as_current_span(\"roll_dice_span\"):\n        # Your logic here\n        return HttpResponse(\"Dice rolled!\")\n\ndef home(request):\n    with tracer.start_as_current_span(\"home_span\"):\n        return HttpResponse(\"Welcome to the homepage!\")\n```\n\n----------------------------------------\n\nTITLE: Counting Occurrences of a Specific Value in SQL and APL\nDESCRIPTION: Demonstrates how to count occurrences of records with a specific field value. This example counts HTTP requests with the 'text/csv' content type.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSELECT content_type, COUNT(*) AS RequestCount\nFROM  [Sample-http-logs];\nWHERE content_type = 'text/csv';\n```\n\nLANGUAGE: kusto\nCODE:\n```\n ['sample-http-logs'];\n| where content_type == 'text/csv'\n| summarize RequestCount = count()\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL for IPv4 Detection\nDESCRIPTION: Demonstrates how to detect IPv4 addresses in text using Splunk Search Processing Language (SPL) compared to the equivalent approach in Axiom Processing Language (APL).\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-ipv4.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nsearch sourcetype=access_combined | eval isPresent=match(_raw, \"192\\.168\\.1\\.1\")\n```\n\nLANGUAGE: kusto\nCODE:\n```\nprint result=has_ipv4('05:04:54 192.168.1.1 GET /favicon.ico 404', '192.168.1.1')\n```\n\n----------------------------------------\n\nTITLE: Importing OpenTelemetry SDK Tracing Package for Java\nDESCRIPTION: This package focuses on tracing capability within the OpenTelemetry SDK. It includes important classes like SdkTracerProvider for creating and managing tracers, and BatchSpanProcessor for efficient batch processing and exporting of spans.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_16\n\nLANGUAGE: Java\nCODE:\n```\nio.opentelemetry:opentelemetry-sdk-trace\n```\n\n----------------------------------------\n\nTITLE: Parsing Fields from Text in Sumo Logic and APL\nDESCRIPTION: Demonstrates how to extract 'from' and 'to' fields from raw events in both Sumo Logic and APL. Sumo Logic uses parse operator while APL uses the extend and extract functions.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sumologic-to-apl.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n* | parse \"From: * To: *\" as (from, to)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend (method) == extract(\"From: (.*?) To: (.*)\", 1, method)\n```\n\n----------------------------------------\n\nTITLE: Summarizing Data with Time Bins in APL\nDESCRIPTION: Complex APL query that aggregates average request duration by city and time bins, filtering for the last 2 days with 4-hour intervals.\nSOURCE: https://github.com/axiomhq/docs/blob/main/query-data/explore.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where _time > ago(2d)\n| summarize avg(req_duration_ms) by _time=bin(_time, 4h), ['geo.city']\n```\n\n----------------------------------------\n\nTITLE: Case-Insensitive 'where * has' in APL\nDESCRIPTION: Example demonstrating case-insensitivity of the 'has' operator. This query finds events where any field contains 'mexico' (case-insensitive) and calculates the average request duration.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_11\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where * has \"mexico\"\n| summarize avg(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Converting SQL MIN and MAX to APL\nDESCRIPTION: Shows how to translate a SQL query with MIN and MAX functions to APL using 'min()' and 'max()' functions in a 'summarize' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(req_duration_ms) AS MinRequest, MAX(req_duration_ms) AS MaxRequest\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize MinRequest = min(req_duration_ms), MaxRequest = max(req_duration_ms)\n```\n\n----------------------------------------\n\nTITLE: Using Wildcards with project-away for GitHub Push Events in APL\nDESCRIPTION: An example of using wildcards with the project-away operator to exclude multiple fields that match a pattern in GitHub push event data, specifically removing fields related to push events, repositories, and commits.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-away-operator.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['github-push-event']\n| project-away push*, repo*, ['commits']*\n```\n\n----------------------------------------\n\nTITLE: Importing OpenTelemetry Core API for Java\nDESCRIPTION: This library provides the core OpenTelemetry API for Java, defining interfaces and classes for manual app instrumentation. It includes fundamental classes like Tracer, Span, and Context for creating and managing traces.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_12\n\nLANGUAGE: Java\nCODE:\n```\nio.opentelemetry:opentelemetry-api\n```\n\n----------------------------------------\n\nTITLE: Sample Output from geo_info_from_ip_address Function\nDESCRIPTION: Example of the JSON output returned by the geo_info_from_ip_address function, showing geographic attributes like country, state, city, coordinates, and time zone.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"state\": \"\",\n  \"longitude\": -97.822,\n  \"latitude\": 37.751,\n  \"country_iso\": \"US\",\n  \"country\": \"United States\",\n  \"city\": \"\",\n  \"time_zone\": \"America/Chicago\"\n}\n```\n\n----------------------------------------\n\nTITLE: Reordering OpenTelemetry Trace Fields in APL\nDESCRIPTION: An example that reorders OpenTelemetry trace fields to prioritize service and status information. This query emphasizes service-related fields like service.name and status_code at the start of the output.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-reorder-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| project-reorder _time, ['service.name'], kind, status_code, trace_id, span_id, duration\n```\n\n----------------------------------------\n\nTITLE: Combining 'where * has' with Field-Specific Conditions in APL\nDESCRIPTION: Example of using the '* has' pattern with field-specific conditions. This query finds events where any field contains 'css' and the req_duration_ms field equals 1.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/where-operator.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs'] \n| where * has \"css\" and req_duration_ms == 1\n```\n\n----------------------------------------\n\nTITLE: Service Name Lookup Table in CSV Format\nDESCRIPTION: A sample CSV lookup table mapping service names to human-readable service names for OpenTelemetry traces.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/externaldata-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: csv\nCODE:\n```\nserviceName,humanreadableServiceName\nfrontend,Frontend\nfrontendproxy,Frontendproxy\nflagd,Flagd\nproductcatalogservice,Productcatalog\nloadgenerator,Loadgenerator\ncheckoutservice,Checkout\ncartservice,Cart\nrecommendationservice,Recommendations\nemailservice,Email\nadservice,Ads\nshippingservice,Shipping\nquoteservice,Quote\ncurrencyservice,Currency\npaymentservice,Payment\nfrauddetectionservice,Frauddetection\n```\n\n----------------------------------------\n\nTITLE: Sorting with order Operator in APL\nDESCRIPTION: This snippet demonstrates the basic syntax for using the order operator in APL. It allows sorting by one or more fields in ascending or descending order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/order-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n| order by FieldName [asc | desc], FieldName [asc | desc]\n```\n\n----------------------------------------\n\nTITLE: Counting Distinct Cities in Security Logs\nDESCRIPTION: An example query that counts distinct cities from geolocation data in HTTP logs. This helps analyze the geographic distribution of traffic in security logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcount.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize dcount(['geo.city'])\n```\n\n----------------------------------------\n\nTITLE: Calculating Standard Deviation in Splunk SPL and APL\nDESCRIPTION: This snippet compares the syntax for calculating standard deviation in Splunk SPL and APL. It demonstrates how to compute the standard deviation of a 'duration' field and assign it to 'duration_std'.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdev.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats stdev(duration) as duration_std\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['dataset']\n| summarize duration_std = stdev(duration)\n```\n\n----------------------------------------\n\nTITLE: Log Analysis Example with minif in APL\nDESCRIPTION: Example showing how to use minif to find the minimum request duration for successful HTTP requests, grouped by city in a log analysis scenario.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/minif.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize minif(req_duration_ms, status == '200') by ['geo.city']\n```\n\n----------------------------------------\n\nTITLE: Using Wildcards with project-keep in APL for HTTP Logs\nDESCRIPTION: Example of using wildcards with the project-keep operator to select multiple fields with similar prefixes in HTTP logs, such as response fields, content fields, and geographical information.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-keep-operator.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project-keep resp*, content*,  ['geo.']*\n```\n\n----------------------------------------\n\nTITLE: Extending Results with New Fields\nDESCRIPTION: Shows how to add new calculated fields to the result set using conditional logic.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_10\n\nLANGUAGE: splunk\nCODE:\n```\nSample.Logs=330009.2 | eval state= if(Data.Exception = \"0\", \"success\", \"error\")\n```\n\nLANGUAGE: apl\nCODE:\n```\n['sample-http-logs'] | extend Grade = iff(req_duration_ms >= 80, \"A\", \"B\")\n```\n\n----------------------------------------\n\nTITLE: Using minif in APL vs Splunk SPL\nDESCRIPTION: Comparison between Splunk SPL's min with where condition and the equivalent APL minif function for finding minimum request duration for successful HTTP requests.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/minif.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats min(req_duration_ms) as min_duration where status=\"200\"\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize minif(req_duration_ms, status == \"200\") by id\n```\n\n----------------------------------------\n\nTITLE: String Concatenation in SQL and APL\nDESCRIPTION: Demonstrates string concatenation techniques. SQL uses CONCAT() while APL uses strcat() to join content_type and method fields with a space in between.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONCAT(content_type, ' ', method) AS FullLength\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend FullLength = strcat(content_type, ' ', method)\n```\n\n----------------------------------------\n\nTITLE: Calculating Start of Week in Axiom Query Language\nDESCRIPTION: The startofweek() function returns the start of the week containing the given date. It considers Sunday as the start of the week and sets the time to 00:00:00.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_18\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend start_of_the_week =  startofweek(datetime(2020-08-01))\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['hackernews']\n| extend start_of_the_week = startofweek(datetime(2020-08-01))\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend start_of_the_week = startofweek(datetime(2018-06-11T00:00:00Z))\n```\n\n----------------------------------------\n\nTITLE: Encoding URLs with url_encode Function in Kusto\nDESCRIPTION: Illustrates the usage of url_encode function to convert characters of an input URL into a format that can be transmitted over the Internet. It takes a URL string as an argument.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_34\n\nLANGUAGE: kusto\nCODE:\n```\nurl_encode(url)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project encoded_url = url_encode( \"https://www.axiom.co/\" )\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Trace Analysis with project-keep in APL\nDESCRIPTION: Example of using project-keep to analyze OpenTelemetry traces by focusing on key tracing details like timestamps, trace IDs, service names, and durations.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-keep-operator.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces'] \n| project-keep _time, trace_id, span_id, ['service.name'], duration\n```\n\n----------------------------------------\n\nTITLE: Replacing Substrings in APL\nDESCRIPTION: The replace_string function replaces all occurrences of a substring with another string. It's useful for simple string replacements without regex complexity.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_17\n\nLANGUAGE: kusto\nCODE:\n```\nreplace_string(\"github\", \"axiom\", \"The project is hosted on github\")\n```\n\nLANGUAGE: kusto\nCODE:\n```\nreplace_string(lookup, rewrite, text)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend replaced_string = replace_string(\"The project is hosted on github\", \"github\", \"axiom\")\n| project replaced_string\n```\n\n----------------------------------------\n\nTITLE: Using Term Matching Operators in Kusto\nDESCRIPTION: Examples of term matching operators (has and has_cs) which test if a string contains a whole term, with both case-sensitive and case-insensitive options.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-operators/string-operators.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n\"content type\" has \"type\" // True\n\"content type\" has_cs \"Type\" // False\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-value Fields with pack_array in APL (Splunk SPL Comparison)\nDESCRIPTION: This snippet demonstrates how to use pack_array in APL to create an array field, compared to using mvappend in Splunk SPL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/pack-array.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval array_field = mvappend(value1, value2, value3)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| extend array_field = pack_array(value1, value2, value3)\n```\n\n----------------------------------------\n\nTITLE: Comparing Count Function: SQL vs APL\nDESCRIPTION: Comparison of how to count records by status in SQL and the equivalent syntax in APL. This demonstrates how to translate your SQL queries to APL format.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/count.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT status, COUNT(*)\nFROM sample_http_logs\nGROUP BY status\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize count() by status\n```\n\n----------------------------------------\n\nTITLE: Field Renaming Operations\nDESCRIPTION: Examples of renaming fields in the result set using different operators.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_11\n\nLANGUAGE: splunk\nCODE:\n```\nSample.Logs=330009.2 | rename Date.Exception as execption\n```\n\nLANGUAGE: apl\nCODE:\n```\n['sample-http-logs'] | project updated_status = status\n```\n\n----------------------------------------\n\nTITLE: Syntax for stdev Function in APL\nDESCRIPTION: This snippet demonstrates the basic syntax for using the stdev function in APL. It shows how to apply the function to a numeric field to calculate its standard deviation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/stdev.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nstdev(numeric_field)\n```\n\n----------------------------------------\n\nTITLE: Using hash_sha256() Function in APL\nDESCRIPTION: The hash_sha256() function returns a SHA256 hash value for the input value encoded as a hex string. The example shows applying the function to content_type field from sample-http-logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/hash-functions.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nhash_sha256(source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project sha256_hash_value = hash_sha256(content_type)\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"sha256_hash_value\": \"bb4770ff4ac5b7d2be41a088cb27d8bcaad53b574b6f27941e8e48e9e10fc25a\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using hash_sha1() Function in APL\nDESCRIPTION: The hash_sha1() function returns a SHA1 hash value for the input value encoded as a hex string. The example demonstrates applying the function to content_type field from sample-http-logs.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/hash-functions.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\nhash_sha1(source)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project sha1_hash_value = hash_sha1(content_type)\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"sha1_hash_value\": \"9f9af029585ba014e07cd3910ca976cf56160616\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using array_length with OpenTelemetry Traces in APL\nDESCRIPTION: A practical example of using array_length to filter spans with more than 2 events in OpenTelemetry trace data.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-length.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| take 50\n| extend event_count = array_length(events)\n| where event_count > 2\n```\n\n----------------------------------------\n\nTITLE: Rendering Prerequisites Component in Markdown\nDESCRIPTION: This code snippet renders the imported Prerequisites component within the markdown document. It's used to display prerequisite information for creating note dashboard elements.\nSOURCE: https://github.com/axiomhq/docs/blob/main/dashboard-elements/note.mdx#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n<Prerequisites />\n```\n\n----------------------------------------\n\nTITLE: Querying Axiom Audit Log in Kusto\nDESCRIPTION: This snippet demonstrates how to query the axiom-audit dataset to display raw audit log data in a table using Kusto Query Language (KQL).\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/audit-log.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['axiom-audit']\n```\n\n----------------------------------------\n\nTITLE: Converting Degrees to Radians with radians() in Kusto\nDESCRIPTION: The radians() function converts an angle value from degrees to radians. It takes a real number representing degrees as input and returns the corresponding value in radians.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_19\n\nLANGUAGE: kusto\nCODE:\n```\nradians(a)\n```\n\nLANGUAGE: kusto\nCODE:\n```\nradians(60) == 1.0471975511965976\n```\n\n----------------------------------------\n\nTITLE: Converting SQL COUNT DISTINCT to APL\nDESCRIPTION: Shows how to translate a SQL COUNT DISTINCT query to APL using the 'dcount()' function in a 'summarize' operator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(DISTINCT method) AS UniqueMethods\nFROM [Sample-http-logs];\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize UniqueMethods = dcount(method)\n```\n\n----------------------------------------\n\nTITLE: Counting Array Length in APL (Equivalent to Splunk)\nDESCRIPTION: The APL equivalent of Splunk's mvcount function, using array_length to count elements in an array field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-length.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend array_size = array_length(array_field)\n```\n\n----------------------------------------\n\nTITLE: Counting Array Length in APL (Equivalent to SQL)\nDESCRIPTION: The APL equivalent of SQL's CARDINALITY function, using array_length to count elements in an array field.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-length.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend array_size = array_length(array_field)\n```\n\n----------------------------------------\n\nTITLE: Comparing Splunk SPL and APL arg_min Usage\nDESCRIPTION: Example showing how to find minimum duration records in Splunk SPL versus APL's arg_min approach.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-min.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| stats min(req_duration_ms) as minDuration by id\n| where req_duration_ms=minDuration\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize arg_min(req_duration_ms, id, uri)\n```\n\n----------------------------------------\n\nTITLE: Counting Array Length in Splunk SPL\nDESCRIPTION: Example showing how to count elements in a multivalue field using Splunk's mvcount function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-length.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval array_size = mvcount(array_field)\n```\n\n----------------------------------------\n\nTITLE: Listing OpenTelemetry Dependencies in requirements.txt\nDESCRIPTION: This snippet shows the content of a requirements.txt file listing the necessary OpenTelemetry packages for a Django project.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-django.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndjango\nopentelemetry-api\nopentelemetry-sdk\nopentelemetry-exporter-otlp-proto-http\nopentelemetry-instrumentation-django\n```\n\n----------------------------------------\n\nTITLE: Filtering HTTP Logs by Response Body Size Range\nDESCRIPTION: Query to find logs where response body size is between 4000 and 5000 bytes\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_17\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where toint(resp_body_size_bytes) >= 4000 and toint(resp_body_size_bytes) <= 5000\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with project-away in APL\nDESCRIPTION: An example of using project-away in log analysis to exclude unnecessary fields and focus on relevant information like timestamp, request duration, and user information.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/project-away-operator.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project-away status, uri, method\n```\n\n----------------------------------------\n\nTITLE: Converting SQL TOP N with ORDER BY to APL\nDESCRIPTION: Shows how to convert a SQL TOP and ORDER BY query to APL using 'top' and 'project' operators.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/migrating-from-sql-to-apl.mdx#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TOP 10 Status, Method\nFROM [Sample-http-logs]\nORDER BY Method DESC;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| top 10 by method desc\n| project status, method\n```\n\n----------------------------------------\n\nTITLE: Querying Average GPU Utilization with Kusto\nDESCRIPTION: Kusto query example demonstrating how to compute average GPU utilization across nodes using time-based binning and aggregation in Axiom.\nSOURCE: https://github.com/axiomhq/docs/blob/main/getting-started-guide/observability.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| summarize avg(metric_value) by node_host, bin_auto(_time)\n```\n\n----------------------------------------\n\nTITLE: Union with Source Field in APL\nDESCRIPTION: This example shows the syntax for using the union operator with the 'withsource' parameter to add a field specifying the source dataset for each row.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/union-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\nT1 | union [withsource=FieldName] [T2], [T3], ...\n```\n\n----------------------------------------\n\nTITLE: Using dayofmonth() function in Kusto/APL\nDESCRIPTION: The dayofmonth() function returns the integer representing the day number of the given month. It takes a_date (datetime) as an argument and returns the day number of the given month.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/datetime-functions.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\ndayofmonth(a_date)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project day_of_the_month = dayofmonth(datetime(2017-11-30))\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"day_of_the_month\": 30\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Dependencies for Next.js\nDESCRIPTION: Command to install required Axiom packages including core JS, logging, Next.js integration, and React components.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/nextjs.mdx#2025-04-22_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\nnpm install --save @axiomhq/js @axiomhq/logging @axiomhq/nextjs @axiomhq/react\n```\n\n----------------------------------------\n\nTITLE: Checking IP Prefix Match in APL\nDESCRIPTION: This snippet shows the equivalent operation in APL using the has_any_ipv4_prefix function, which simplifies checking multiple IP prefixes.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/has-any-ipv4-prefix.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| where has_any_ipv4_prefix(uri, dynamic(['10.', '192.168.']))\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Request Duration by Status in APL\nDESCRIPTION: This query calculates the average request duration for HTTP requests, grouped by status using the 'avg' aggregation function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/avg.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize avg(req_duration_ms) by status\n```\n\n----------------------------------------\n\nTITLE: Syntax Definition for array_reverse Function\nDESCRIPTION: Defines the syntax for the array_reverse function in APL, which takes an array expression as input and returns the array with elements in reverse order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-reverse.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\narray_reverse(array_expression)\n```\n\n----------------------------------------\n\nTITLE: Equivalent varianceif Implementation in APL\nDESCRIPTION: The APL equivalent of the Splunk query, showing how varianceif combines filtering and aggregation in a single, more concise function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/varianceif.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize varianceif(req_duration_ms, status == '200')\n```\n\n----------------------------------------\n\nTITLE: Retrieving Geo Data in Splunk SPL vs APL\nDESCRIPTION: Comparison between retrieving geographic information from IP addresses in Splunk SPL versus the equivalent operation in APL using geo_info_from_ip_address.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| eval geo_info = iplocation(client_ip)\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend geo_info = geo_info_from_ip_address(client_ip)\n```\n\n----------------------------------------\n\nTITLE: Creating annotations with @axiomhq/js\nDESCRIPTION: Example of creating an annotation using the @axiomhq/js library.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/javascript.mdx#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { annotations } from '@axiomhq/js';\n\nconst client = new annotations.Service({ token: process.env.AXIOM_TOKEN });\n\nawait annotations.create({\n  type: 'deployment',\n  datasets: ['DATASET_NAME'],\n  title: 'New deployment',\n  description: 'Deployed version 1.0.0',\n})\n```\n\n----------------------------------------\n\nTITLE: Using pair() Function in Kusto\nDESCRIPTION: Creates a pair from a key and value with an optional separator. This example shows simple usage with a custom separator.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/pair-functions.mdx#2025-04-22_snippet_0\n\nLANGUAGE: kusto\nCODE:\n```\npair(\"key\", \"value\", \".\")\n```\n\n----------------------------------------\n\nTITLE: Column Exclusion Operations\nDESCRIPTION: Demonstrates how to exclude specific columns from the result set.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_13\n\nLANGUAGE: splunk\nCODE:\n```\nSample.Logs=330009.2 | fields - quota, hightest_seller\n```\n\nLANGUAGE: apl\nCODE:\n```\n['sample-http-logs'] | project-away method, status\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry trace analysis using make_list in APL\nDESCRIPTION: Query showing how to collect all service names involved in OpenTelemetry traces grouped by trace ID.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/make-list.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize services=make_list(['service.name']) by trace_id\n```\n\n----------------------------------------\n\nTITLE: Configuring Route for Logger Testing\nDESCRIPTION: Adds a web route to access the TestController's logTest method for testing the Axiom logger implementation.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/send-logs-from-laravel.mdx#2025-04-22_snippet_7\n\nLANGUAGE: php\nCODE:\n```\n<?php\n\nuse App\\Http\\Controllers\\TestController;\n\nRoute::get('/test-log', [TestController::class, 'logTest']);\n```\n\n----------------------------------------\n\nTITLE: APL IPv4 Range Check Example Query\nDESCRIPTION: Example query demonstrating how to use ipv4_is_in_range to check if an IP address is within a specific subnet.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-is-in-range.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| extend in_range = ipv4_is_in_range('192.168.1.0', '192.168.1.0/24')\n```\n\n----------------------------------------\n\nTITLE: Using atan2() Function in Kusto\nDESCRIPTION: Examples of using the atan2() function to calculate the angle between the positive x-axis and a point. The function takes x and y coordinates and returns the angle in radians.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/mathematical-functions.mdx#2025-04-22_snippet_4\n\nLANGUAGE: kusto\nCODE:\n```\natan2(y,x)\n```\n\nLANGUAGE: kusto\nCODE:\n```\natan2(-1, 1) == -0.7853981633974483\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project angle_in_rads = atan2(-1, 1)\n```\n\n----------------------------------------\n\nTITLE: Logging with Winston and Axiom Transport in JavaScript\nDESCRIPTION: Demonstrates how to use the configured Winston logger to log an info message.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/winston.mdx#2025-04-22_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nlogger.log({\n    level: 'info',\n    message: 'Logger successfully setup',\n});\n```\n\n----------------------------------------\n\nTITLE: Filter Ordering Optimization\nDESCRIPTION: Shows how to order filter conditions for optimal query performance by placing more selective filters first.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/performance.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\ndataset\n| where user_id == 1234\n| where log_level == \"ERROR\"\n```\n\n----------------------------------------\n\nTITLE: Substring Extraction in KQL\nDESCRIPTION: Demonstrates the substring function for extracting a portion of a string using start index and length parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_26\n\nLANGUAGE: kusto\nCODE:\n```\nsubstring(source, startingIndex [, length])\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| extend extract_string = substring( repo, 4, 5 )\n```\n\nLANGUAGE: kusto\nCODE:\n```\nproject extract_string = substring( \"axiom\", 4, 5 )\n```\n\n----------------------------------------\n\nTITLE: Parsing SQL Query with JSON Functions in APL\nDESCRIPTION: Illustrates parsing an SQL query that uses JSON functions to extract data from a JSON column.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_8\n\nLANGUAGE: kusto\nCODE:\n```\nhn \n| project parse_sql(\"SELECT JSON_EXTRACT(user_info, '$.age') AS age FROM users WHERE user_id = 101\")\n```\n\n----------------------------------------\n\nTITLE: dcount Function Syntax in APL\nDESCRIPTION: The basic syntax for the dcount aggregation function in Axiom Processing Language, which counts distinct values in a specified column.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcount.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ndcount(column_name)\n```\n\n----------------------------------------\n\nTITLE: Manual OpenTelemetry Instrumentation Example\nDESCRIPTION: Code examples showing how to manually instrument Python code with OpenTelemetry spans and attributes\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-python.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport exporter\ntracer = exporter.service1_tracer\n```\n\nLANGUAGE: python\nCODE:\n```\nwith tracer.start_as_current_span(\"operation_name\"):\n```\n\nLANGUAGE: python\nCODE:\n```\nwith tracer.start_as_current_span(\"operation_name\") as span:\n    span.set_attribute(\"key\", \"value\")\n```\n\n----------------------------------------\n\nTITLE: Sort Command Comparison - Splunk vs APL\nDESCRIPTION: Demonstrates the difference between Splunk SPL sort command and APL sort operator syntax for ordering by time and status.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sort-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: splunk\nCODE:\n```\n| sort - _time, status\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| sort by _time desc, status asc\n```\n\n----------------------------------------\n\nTITLE: Parsing SQL ORDER BY Clause in APL\nDESCRIPTION: Demonstrates parsing an SQL statement that orders users by registration_date in descending order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/sql-functions.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\nhn\n| project parse_sql(\"SELECT name, registration_date FROM users ORDER BY registration_date DESC\")\n```\n\n----------------------------------------\n\nTITLE: Sumif Syntax in APL\nDESCRIPTION: This snippet shows the syntax of the sumif aggregation function in APL, which takes a numeric expression and a condition as parameters.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/sumif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nsumif(numeric_expression, condition)\n```\n\n----------------------------------------\n\nTITLE: Retrieving External Data with Splunk and APL Comparison\nDESCRIPTION: Comparison between Splunk's inputlookup and APL's externaldata approach for retrieving data from external sources.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/externaldata-operator.mdx#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n| inputlookup external_data.csv\n```\n\nLANGUAGE: kusto\nCODE:\n```\nexternaldata (id:string, timestamp:datetime) [\"https://storage.example.com/data.csv\"] with (format=\"csv\")\n```\n\n----------------------------------------\n\nTITLE: Creating Maven Project Structure\nDESCRIPTION: Maven command to generate a new Java project with standard directory structure.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-java.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmvn archetype:generate -DgroupId=com.example -DartifactId=MyProject -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false\n```\n\n----------------------------------------\n\nTITLE: Basic Syntax for externaldata Operator in APL\nDESCRIPTION: The fundamental syntax for using the externaldata operator in APL to retrieve and define schema for external data sources.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/externaldata-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nexternaldata (FieldName1:FieldType1, FieldName2:FieldType2, ...) [\"URL1\", \"URL2\", ...] [with (format = \"FormatType\", ignoreFirstRecord=false)]\n```\n\n----------------------------------------\n\nTITLE: Calculating Multiple Percentiles in APL\nDESCRIPTION: This snippet shows the equivalent APL query for calculating multiple percentiles using the percentiles_array function.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/percentiles-array.mdx#2025-04-22_snippet_1\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| summarize percentiles_array(duration, 25, 50, 95) by ['service.name']\n```\n\n----------------------------------------\n\nTITLE: Annotating Spans in Cloudflare Workers\nDESCRIPTION: Example of adding metadata to spans in a Cloudflare Workers script for additional context in tracing.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nspan.setAttribute('key', 'value');\nspan.addEvent('eventName', { 'eventAttribute': 'value' });\n```\n\n----------------------------------------\n\nTITLE: Security Logs Rate Calculation\nDESCRIPTION: Calculating rate of HTTP request duration per second for security monitoring.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/rate.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize rate(req_duration_ms) by bin(_time, 1s)\n```\n\n----------------------------------------\n\nTITLE: Converting to TimeSpan in APL\nDESCRIPTION: The totimespan() function converts input to a timespan scalar. If conversion is successful, it returns a timespan value; otherwise, it returns false.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/conversion-functions.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\ntotimespan(Expr)\n```\n\n----------------------------------------\n\nTITLE: Log Analysis with arg_min\nDESCRIPTION: Query to identify paths with shortest duration per HTTP method.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-min.mdx#2025-04-22_snippet_3\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize arg_min(req_duration_ms, uri) by method\n```\n\n----------------------------------------\n\nTITLE: Null/Empty Checking Functions\nDESCRIPTION: Collection of functions for checking null and empty values including isempty(), isnotempty(), isnotnull(), and isnull().\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_10\n\nLANGUAGE: kusto\nCODE:\n```\nisempty(\"\") == true\n```\n\nLANGUAGE: kusto\nCODE:\n```\nisnotempty(\"\") == false\n```\n\nLANGUAGE: kusto\nCODE:\n```\nisnotnull( num_comments ) == true\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['github-issues-event']\n| project is_null = isnull(creator)\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Traces Sort Example\nDESCRIPTION: Sorting OpenTelemetry traces by span duration and service name for performance analysis.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/sort-operator.mdx#2025-04-22_snippet_5\n\nLANGUAGE: kusto\nCODE:\n```\n['otel-demo-traces']\n| sort by duration desc, ['service.name'] asc\n```\n\n----------------------------------------\n\nTITLE: SQL vs APL Data Redaction Comparison\nDESCRIPTION: Comparison between ANSI SQL and APL approaches for data obfuscation using regex patterns.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/redact-operator.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT REGEXP_REPLACE(field, 'regex_pattern', '*') AS sanitized_field FROM table;\n```\n\nLANGUAGE: kusto\nCODE:\n```\n| redact 'regex_pattern' on field\n```\n\n----------------------------------------\n\nTITLE: Automatic OpenTelemetry Instrumentation Example\nDESCRIPTION: Code examples showing how to automatically instrument Python frameworks with OpenTelemetry\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-python.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npip install opentelemetry-instrumentation-flask\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.instrumentation.flask import FlaskInstrumentor\n# This assumes `app` is your Flask app.\nFlaskInstrumentor().instrument_app(app)\n```\n\n----------------------------------------\n\nTITLE: APL Redact Operator Syntax\nDESCRIPTION: Basic syntax for the redact operator showing supported parameters and usage.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/redact-operator.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\n| redact [replaceToken=\"*\"] [replaceHash=false] [redactGroups=false] <regex>, (<regex>) [on Field]\n```\n\n----------------------------------------\n\nTITLE: Managing Go Dependencies\nDESCRIPTION: Command to tidy up project dependencies, ensuring go.mod and go.sum files are up to date.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-go.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngo mod tidy\n```\n\n----------------------------------------\n\nTITLE: Sorting Operations\nDESCRIPTION: Shows how to sort results in ascending and descending order.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/guides/splunk-cheat-sheet.mdx#2025-04-22_snippet_15\n\nLANGUAGE: splunk\nCODE:\n```\nSample.logs=120103 | sort Data.Hresult | reverse\n```\n\nLANGUAGE: apl\nCODE:\n```\n['sample-http-logs'] | order by status desc\n```\n\n----------------------------------------\n\nTITLE: Comparing SQL and APL arg_min Implementation\nDESCRIPTION: Demonstrates how to achieve arg_min functionality in SQL versus APL's simpler approach.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/arg-min.mdx#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, uri\nFROM sample_http_logs\nWHERE req_duration_ms = (\n    SELECT MIN(req_duration_ms)\n    FROM sample_http_logs\n);\n```\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| summarize arg_min(req_duration_ms, id, uri)\n```\n\n----------------------------------------\n\nTITLE: User Agent Parsing\nDESCRIPTION: Complex example of parsing user agent string to extract OS information.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tabular-operators/parse-operator.mdx#2025-04-22_snippet_7\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| parse user_agent with * '(' os_name ' ' os_version ';' * ')' *\n| project os_name, os_version\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom CLI using Homebrew\nDESCRIPTION: Install and update the Axiom CLI using Homebrew package manager on macOS.\nSOURCE: https://github.com/axiomhq/docs/blob/main/reference/cli.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbrew tap axiomhq/tap\nbrew install axiom\n```\n\n----------------------------------------\n\nTITLE: Deploying Cloudflare Workers App to Production\nDESCRIPTION: Command to deploy the Cloudflare Workers app to the production environment.\nSOURCE: https://github.com/axiomhq/docs/blob/main/guides/opentelemetry-cloudflare-workers.mdx#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpm run deploy\n```\n\n----------------------------------------\n\nTITLE: APL dcountif Function Syntax\nDESCRIPTION: Basic syntax for the dcountif function in APL showing parameter structure.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/dcountif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ndcountif(column_name, condition)\n```\n\n----------------------------------------\n\nTITLE: Installing Axiom Loki Proxy from Source\nDESCRIPTION: Commands to clone the repository and build Axiom Loki Proxy from source code.\nSOURCE: https://github.com/axiomhq/docs/blob/main/send-data/loki-multiplexer.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/axiomhq/axiom-loki-proxy.git\ncd axiom-loki-proxy\nmake build\n```\n\n----------------------------------------\n\nTITLE: Basic Rate Function Syntax\nDESCRIPTION: Basic syntax for the rate function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/rate.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nrate(field)\n```\n\n----------------------------------------\n\nTITLE: Determining Runtime Type with gettype Function in Kusto\nDESCRIPTION: Demonstrates the gettype function which returns the runtime type of its single argument. It can be used with various data types including strings, numbers, booleans, and complex types.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/string-functions.mdx#2025-04-22_snippet_35\n\nLANGUAGE: kusto\nCODE:\n```\ngettype(\"lima\")\ngettype(2222)\ngettype(5==5)\ngettype(now())\ngettype(parse_json('67'))\ngettype(parse_json(' \"polish\" '))\ngettype(parse_json(' {\"axiom\":1234} '))\ngettype(parse_json(' [6, 7, 8] '))\ngettype(456.98)\ngettype(parse_json(''))\n```\n\n----------------------------------------\n\nTITLE: IPv4 Netmask Suffix Function Syntax in APL\nDESCRIPTION: The syntax for using the ipv4_netmask_suffix function in APL to extract the netmask suffix from an IPv4 address.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/ipv4-netmask-suffix.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\nipv4_netmask_suffix(ipv4address)\n```\n\n----------------------------------------\n\nTITLE: Syntax for geo_info_from_ip_address Function in APL\nDESCRIPTION: The basic syntax for using the geo_info_from_ip_address function in APL to retrieve geographic information from an IP address.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/ip-functions/geo-info-from-ip-address.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ngeo_info_from_ip_address(ip_address)\n```\n\n----------------------------------------\n\nTITLE: APL Array Sum Basic Syntax\nDESCRIPTION: Basic syntax demonstration of the array_sum function in APL.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/scalar-functions/array-functions/array-sum.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\narray_sum(array_expression)\n```\n\n----------------------------------------\n\nTITLE: Projecting Specific Columns from HTTP Logs\nDESCRIPTION: This query selects a subset of columns from the sample HTTP logs dataset.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/tutorial.mdx#2025-04-22_snippet_6\n\nLANGUAGE: kusto\nCODE:\n```\n['sample-http-logs']\n| project content_type, ['geo.country'], method, resp_body_size_bytes, resp_header_size_bytes\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable for Docker Installation\nDESCRIPTION: This snippet shows how to set the environment variable GF_INSTALL_PLUGINS to include the Axiom data source plugin when installing via Docker. This allows the plugin to be automatically installed when the Docker container is created.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apps/grafana.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nGF_INSTALL_PLUGINS=\"axiomhq-axiom-datasource\"\n```\n\n----------------------------------------\n\nTITLE: Countif Function Syntax in APL\nDESCRIPTION: The basic syntax for the countif aggregation function in Axiom Processing Language.\nSOURCE: https://github.com/axiomhq/docs/blob/main/apl/aggregation-function/countif.mdx#2025-04-22_snippet_2\n\nLANGUAGE: kusto\nCODE:\n```\ncountif(condition)\n```"
  }
]