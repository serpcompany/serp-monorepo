[
  {
    "owner": "mistralai",
    "repo": "client-python",
    "content": "TITLE: Classifying Text with Mistral API in Python\nDESCRIPTION: This snippet demonstrates text classification using the Mistral API. It initializes the Mistral client and calls the classify method with a specified model and input text.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/classifiers/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.classifiers.classify(model=\"Altima\", inputs=\"<value>\")\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Non-Streaming Chat with MistralAI Client (Old Implementation)\nDESCRIPTION: Example of using the old MistralClient for non-streaming chat completions. This code initializes the client, creates a message, and prints the response content.\nSOURCE: https://github.com/mistralai/client-python/blob/main/MIGRATION.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai.client import MistralClient\nfrom mistralai.models.chat_completion import ChatMessage\n\napi_key = os.environ[\"MISTRAL_API_KEY\"]\nmodel = \"mistral-large-latest\"\n\nclient = MistralClient(api_key=api_key)\n\nmessages = [\n    ChatMessage(role=\"user\", content=\"What is the best French cheese?\")\n]\n\n# No streaming\nchat_response = client.chat(\n    model=model,\n    messages=messages,\n)\n\nprint(chat_response.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Synchronous Chat Completion Example\nDESCRIPTION: Example showing how to use the Mistral SDK for synchronous chat completions\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.chat.complete(model=\"mistral-small-latest\", messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ])\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Regular Chat Completion with MistralAI Azure Client\nDESCRIPTION: Example showing how to make a regular (non-streaming) chat completion request using MistralAI's Azure client. Initializes the client with Azure credentials and sends a simple query about French painters.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/sdks/chat/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nimport os\n\ns = MistralAzure(\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.complete(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"azureai\")\n\nif res is not None:\n    # handle response\n    pass\n```\n\n----------------------------------------\n\nTITLE: Synchronous Agent Completion Example\nDESCRIPTION: Example showing how to use agent completions with the Mistral SDK synchronously\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.agents.complete(messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], agent_id=\"<id>\")\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Streaming Events with Mistral AI Python Client\nDESCRIPTION: Example showing how to stream chat completions using server-sent events. The code demonstrates using the chat.stream() method within a context manager and iterating over the event stream.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.chat.stream(model=\"mistral-small-latest\", messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ])\n\n    with res as event_stream:\n        for event in event_stream:\n            # handle event\n            print(event, flush=True)\n```\n\n----------------------------------------\n\nTITLE: Streaming FIM Completion with Python Mistral AI Client\nDESCRIPTION: This snippet demonstrates how to use the Mistral AI client to stream FIM completions. It initializes the client, sets up the request parameters, and processes the streamed events.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/sdks/fim/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP\nimport os\n\ns = MistralGCP()\n\n\nres = s.fim.stream(prompt=\"def\", model=\"codestral-2405\", suffix=\"return a+b\")\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Moderating Chat with Mistral API in Python\nDESCRIPTION: This snippet shows how to use the Mistral API for chat moderation. It initializes the Mistral client and calls the moderate_chat method with complex chat input structures including different roles and content types.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/classifiers/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.classifiers.moderate_chat(inputs=[\n        [\n            {\n                \"content\": [\n\n                ],\n                \"role\": \"system\",\n            },\n            {\n                \"content\": \"<value>\",\n                \"role\": \"tool\",\n            },\n        ],\n        [\n            {\n                \"prefix\": False,\n                \"role\": \"assistant\",\n            },\n            {\n                \"content\": \"<value>\",\n                \"role\": \"user\",\n            },\n            {\n                \"prefix\": False,\n                \"role\": \"assistant\",\n            },\n        ],\n        [\n            {\n                \"content\": \"<value>\",\n                \"role\": \"system\",\n            },\n            {\n                \"content\": [\n                    {\n                        \"image_url\": \"https://fatherly-colon.name\",\n                        \"type\": \"image_url\",\n                    },\n                ],\n                \"role\": \"user\",\n            },\n            {\n                \"content\": \"<value>\",\n                \"role\": \"user\",\n            },\n        ],\n    ], model=\"Model Y\")\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: File Upload with Mistral AI Python Client\nDESCRIPTION: Example showing how to upload files using streams to avoid memory issues with large files. The code demonstrates using the files.upload() method with a file stream.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.files.upload(file={\n        \"file_name\": \"example.file\",\n        \"content\": open(\"example.file\", \"rb\"),\n    })\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Performing Chat Completion with Mistral API in Python\nDESCRIPTION: This snippet demonstrates how to use the Mistral Python client to perform a chat completion. It initializes the Mistral client with an API key from environment variables and sends a user message to generate a response about the best French painter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/chat/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.chat.complete(model=\"mistral-small-latest\", messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ])\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Completion with MistralAI Azure Client\nDESCRIPTION: Example demonstrating how to stream chat completions using MistralAI's Azure client. Sets up the client with Azure credentials and streams responses for a simple query about French painters. Handles the response as a stream of events.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/sdks/chat/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nimport os\n\ns = MistralAzure(\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.stream(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"azureai\")\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Agent Completion Example\nDESCRIPTION: Example showing how to use agent completions with the Mistral SDK asynchronously\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom mistralai import Mistral\nimport os\n\nasync def main():\n\n    async with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n\n        res = await mistral.agents.complete_async(messages=[\n            {\n                \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n                \"role\": \"user\",\n            },\n        ], agent_id=\"<id>\")\n\n        # Handle response\n        print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Authenticating Mistral SDK with API Key in Python\nDESCRIPTION: Demonstrates how to authenticate with the Mistral API using an API key. The example shows how to initialize the SDK client with the API key stored in an environment variable.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.list()\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Responses with Mistral AI Python Client\nDESCRIPTION: This code snippet demonstrates how to use the stream method of the Mistral AI Python client to receive chat responses token by token as they become available. It initializes the client with an API key from environment variables and sends a simple user query about French painters.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/chat/README.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.chat.stream(model=\"mistral-small-latest\", messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ])\n\n    with res as event_stream:\n        for event in event_stream:\n            # handle event\n            print(event, flush=True)\n```\n\n----------------------------------------\n\nTITLE: Initializing HTTP Client with Custom Headers in Python\nDESCRIPTION: This snippet demonstrates how to initialize the MistralAzure client with a custom HTTP client using httpx. It sets a custom header for every request made by the SDK. Dependencies include the httpx library and the mistralai_azure module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nimport httpx\n\nhttp_client = httpx.Client(headers={\"x-custom-header\": \"someValue\"})\ns = MistralAzure(client=http_client)\n```\n\n----------------------------------------\n\nTITLE: Non-Streaming Chat with MistralAI Client (New Implementation)\nDESCRIPTION: Updated example using the new Mistral client for non-streaming chat completions. Shows both dictionary-style message creation and the new message classes approach.\nSOURCE: https://github.com/mistralai/client-python/blob/main/MIGRATION.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom mistralai import Mistral, UserMessage\n\napi_key = os.environ[\"MISTRAL_API_KEY\"]\nmodel = \"mistral-large-latest\"\n\nclient = Mistral(api_key=api_key)\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"What is the best French cheese?\",\n    },\n]\n# Or using the new message classes\n# messages = [\n#     UserMessage(content=\"What is the best French cheese?\"),\n# ]\n\nchat_response = client.chat.complete(\n    model=model,\n    messages=messages,\n)\n\nprint(chat_response.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Starting a Fine-Tuning Job - MistralAI Python\nDESCRIPTION: This code snippet demonstrates how to request the start of a validated fine-tuning job using the MistralAI Python client. It initializes the Mistral client with an API key and then calls the `fine_tuning.jobs.start()` method with the job ID to initiate the job. The response is then printed to the console.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/jobs/README.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.fine_tuning.jobs.start(job_id=\"0bf0f9e6-c3e5-4d61-aac8-0e36dcac0dfc\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Processing OCR with Mistral AI Python Client\nDESCRIPTION: Example demonstrating how to use the Mistral AI client to perform OCR processing on a document. The code initializes the client with an API key and processes a document specified by URL.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/ocr/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.ocr.process(model=\"Focus\", document={\n        \"document_url\": \"https://dutiful-horst.org\",\n        \"type\": \"document_url\",\n    })\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Chat Completion Example\nDESCRIPTION: Example showing how to use the Mistral SDK for asynchronous chat completions\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom mistralai import Mistral\nimport os\n\nasync def main():\n\n    async with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n\n        res = await mistral.chat.complete_async(model=\"mistral-small-latest\", messages=[\n            {\n                \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n                \"role\": \"user\",\n            },\n        ])\n\n        # Handle response\n        print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Synchronous Embedding Creation Example\nDESCRIPTION: Example showing how to create embeddings using the Mistral SDK synchronously\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.embeddings.create(model=\"mistral-embed\", inputs=[\n        \"Embed this sentence.\",\n        \"As well as this one.\",\n    ])\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Chat Completion Example\nDESCRIPTION: Example demonstrating asynchronous chat completions using asyncio with the Mistral GCP client\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Asynchronous Example\nimport asyncio\nfrom mistralai_gcp import MistralGCP\nimport os\n\nasync def main():\n    s = MistralGCP(\n        api_key=os.getenv(\"API_KEY\", \"\"),\n    )\n    res = await s.chat.complete_async(messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], model=\"mistral-small-latest\")\n    if res is not None:\n        # handle response\n        pass\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Completion with Mistral AI Python Client\nDESCRIPTION: This snippet demonstrates how to use the stream method of the Chat Completion API to get streaming responses from the Mistral AI model. It sets up the client, sends a message, and prints each event in the response stream.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/sdks/chat/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP\nimport os\n\ns = MistralGCP()\n\n\nres = s.chat.stream(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"mistral-small-latest\")\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Completion with Mistral AI Python Client\nDESCRIPTION: This code snippet demonstrates how to use the stream method of the Mistral AI Python client to receive streaming responses for chat completions. It sets up the client, sends a message, and processes the streaming events.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/agents/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.agents.stream(messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], agent_id=\"<id>\")\n\n    with res as event_stream:\n        for event in event_stream:\n            # handle event\n            print(event, flush=True)\n```\n\n----------------------------------------\n\nTITLE: Formatting Messages for Chat Completion in Python\nDESCRIPTION: Example of how to structure the 'messages' parameter for a chat completion request. It shows a list containing a single message dictionary with 'role' and 'content' keys.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/chat/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n[\n    {\n        \"role\": \"user\",\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\"\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring Global Retries\nDESCRIPTION: Example showing how to configure retries globally for all API calls. The code demonstrates setting a custom retry configuration when initializing the SDK client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nfrom mistralai.utils import BackoffStrategy, RetryConfig\nimport os\n\n\nwith Mistral(\n    retry_config=RetryConfig(\"backoff\", BackoffStrategy(1, 50, 1.1, 100), False),\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.list()\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Creating Embeddings with Mistral AI Python Client\nDESCRIPTION: Example showing how to generate embeddings using the Mistral AI client. The code demonstrates initializing the client with an API key and creating embeddings for multiple text inputs using the mistral-embed model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/embeddings/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.embeddings.create(model=\"mistral-embed\", inputs=[\n        \"Embed this sentence.\",\n        \"As well as this one.\",\n    ])\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Initializing Custom HTTP Client with Headers in Python\nDESCRIPTION: This snippet illustrates how to create an instance of the MistralGCP client using a custom httpx.Client with specific headers. It demonstrates the necessary imports and the header setting for all requests made by the SDK client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP\nimport httpx\n\nhttp_client = httpx.Client(headers={\"x-custom-header\": \"someValue\"})\ns = MistralGCP(client=http_client)\n```\n\n----------------------------------------\n\nTITLE: Creating Asynchronous Chat Completions with Mistral AI GCP Python SDK\nDESCRIPTION: Example demonstrating asynchronous chat completion requests using asyncio with the Mistral GCP client. Shows how to set up an async function, initialize the client with an API key, and handle the response asynchronously.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/USAGE.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Asynchronous Example\nimport asyncio\nfrom mistralai_gcp import MistralGCP\nimport os\n\nasync def main():\n    s = MistralGCP(\n        api_key=os.getenv(\"API_KEY\", \"\"),\n    )\n    res = await s.chat.complete_async(messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], model=\"mistral-small-latest\")\n    if res is not None:\n        # handle response\n        pass\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Creating Synchronous Chat Completions with Mistral AI Python SDK\nDESCRIPTION: This example demonstrates how to create synchronous chat completions using the Mistral AI Python client. It initializes the client with an API key from environment variables and makes a request to the 'mistral-small-latest' model with a user message.\nSOURCE: https://github.com/mistralai/client-python/blob/main/USAGE.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Synchronous Example\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.chat.complete(model=\"mistral-small-latest\", messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ])\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Creating Synchronous Embedding Requests with Mistral AI Python SDK\nDESCRIPTION: This example demonstrates how to create synchronous embedding requests using the Mistral AI Python client. It initializes the client with an API key and uses the mistral-embed model to generate embeddings for multiple text inputs.\nSOURCE: https://github.com/mistralai/client-python/blob/main/USAGE.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Synchronous Example\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.embeddings.create(model=\"mistral-embed\", inputs=[\n        \"Embed this sentence.\",\n        \"As well as this one.\",\n    ])\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Uploading Files with MistralAI Python Client\nDESCRIPTION: Example showing how to upload a file using the MistralAI client. Files can be up to 512MB in size, with .jsonl being the only supported format for fine-tuning. Uses environment variable for API key authentication.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/files/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.files.upload(file={\n        \"file_name\": \"example.file\",\n        \"content\": open(\"example.file\", \"rb\"),\n    })\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Authenticating SDK Client with API Key in Python\nDESCRIPTION: This snippet explains how to authenticate the MistralAzure SDK client with an API key. It demonstrates how to initialize the client by setting the api_key and azure_endpoint using environment variables. Requires access to the os library to fetch environment variable values.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nimport os\n\ns = MistralAzure(\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.stream(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"azureai\")\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Error Handling Example\nDESCRIPTION: Example showing how to handle errors and exceptions when making API calls. The code demonstrates catching and handling specific exception types like HTTPValidationError and SDKError.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral, models\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n    res = None\n    try:\n\n        res = mistral.models.list()\n\n        # Handle response\n        print(res)\n\n    except models.HTTPValidationError as e:\n        # handle e.data: models.HTTPValidationErrorData\n        raise(e)\n    except models.SDKError as e:\n        # handle exception\n        raise(e)\n```\n\n----------------------------------------\n\nTITLE: Creating Asynchronous Chat Completions with Mistral AI Python SDK\nDESCRIPTION: This example shows how to create asynchronous chat completions using the Mistral AI Python client. It initializes the client with an API key from environment variables inside an async context manager and uses the complete_async method with asyncio.\nSOURCE: https://github.com/mistralai/client-python/blob/main/USAGE.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Asynchronous Example\nimport asyncio\nfrom mistralai import Mistral\nimport os\n\nasync def main():\n\n    async with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n\n        res = await mistral.chat.complete_async(model=\"mistral-small-latest\", messages=[\n            {\n                \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n                \"role\": \"user\",\n            },\n        ])\n\n        # Handle response\n        print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Listing Models with Mistral Python Client\nDESCRIPTION: This snippet demonstrates how to list all models available to the user using the Mistral Python client. It initializes the client with an API key and calls the list method on the models object.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/models/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.list()\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: API Authentication with API Key in Python SDK\nDESCRIPTION: This snippet illustrates how to configure the SDK client for API authentication using an api_key. It shows the initialization of MistralGCP and demonstrates handling an event stream response while querying the chat API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP\nimport os\n\ns = MistralGCP()\n\nres = s.chat.stream(\n    messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], \n    model=\"mistral-small-latest\"\n)\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Deleting a Fine-Tuned Model with Mistral Python Client\nDESCRIPTION: This snippet demonstrates how to delete a fine-tuned model using the Mistral Python client. It initializes the client with an API key and calls the delete method on the models object, passing a model ID as a parameter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/models/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.delete(model_id=\"ft:open-mistral-7b:587a6b29:20240514:7e773925\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Creating Synchronous Chat Completions with Mistral AI Azure Client in Python\nDESCRIPTION: This snippet demonstrates how to initialize the MistralAzure client and make a synchronous chat completion request. It uses environment variables for API key and endpoint, and sends a user message asking about the best French painter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/USAGE.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Synchronous Example\nfrom mistralai_azure import MistralAzure\nimport os\n\ns = MistralAzure(\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.complete(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"azureai\")\n\nif res is not None:\n    # handle response\n    pass\n```\n\n----------------------------------------\n\nTITLE: Creating Synchronous Chat Completions with Mistral AI GCP Python SDK\nDESCRIPTION: Example showing how to initialize the Mistral GCP client and make synchronous chat completion requests. This snippet demonstrates basic usage with a simple user message requesting information about French painters.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/USAGE.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Synchronous Example\nfrom mistralai_gcp import MistralGCP\nimport os\n\ns = MistralGCP()\n\n\nres = s.chat.complete(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"mistral-small-latest\")\n\nif res is not None:\n    # handle response\n    pass\n```\n\n----------------------------------------\n\nTITLE: Retrieving Model Information with Mistral Python Client\nDESCRIPTION: This snippet shows how to retrieve information about a specific model using the Mistral Python client. It initializes the client with an API key and calls the retrieve method on the models object, passing a model ID as a parameter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/models/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.retrieve(model_id=\"ft:open-mistral-7b:587a6b29:20240514:7e773925\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Custom Logic Wrapper for Async HTTP Client in Python\nDESCRIPTION: This snippet showcases wrapping an async HTTP client with additional logic, such as adding a custom header to requests. It uses classes from the httpx library and requires the mistralai_azure.httpclient module. The send method is overridden to insert a client-level header.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nfrom mistralai_azure.httpclient import AsyncHttpClient\nimport httpx\n\nclass CustomClient(AsyncHttpClient):\n    client: AsyncHttpClient\n\n    def __init__(self, client: AsyncHttpClient):\n        self.client = client\n\n    async def send(\n        self,\n        request: httpx.Request,\n        *,\n        stream: bool = False,\n        auth: Union[\n            httpx._types.AuthTypes, httpx._client.UseClientDefault, None\n        ] = httpx.USE_CLIENT_DEFAULT,\n        follow_redirects: Union[\n            bool, httpx._client.UseClientDefault\n        ] = httpx.USE_CLIENT_DEFAULT,\n    ) -> httpx.Response:\n        request.headers[\"Client-Level-Header\"] = \"added by client\"\n\n        return await self.client.send(\n            request, stream=stream, auth=auth, follow_redirects=follow_redirects\n        )\n\n    def build_request(\n        self,\n        method: str,\n        url: httpx._types.URLTypes,\n        *,\n        content: Optional[httpx._types.RequestContent] = None,\n        data: Optional[httpx._types.RequestData] = None,\n        files: Optional[httpx._types.RequestFiles] = None,\n        json: Optional[Any] = None,\n        params: Optional[httpx._types.QueryParamTypes] = None,\n        headers: Optional[httpx._types.HeaderTypes] = None,\n        cookies: Optional[httpx._types.CookieTypes] = None,\n        timeout: Union[\n            httpx._types.TimeoutTypes, httpx._client.UseClientDefault\n        ] = httpx.USE_CLIENT_DEFAULT,\n        extensions: Optional[httpx._types.RequestExtensions] = None,\n    ) -> httpx.Request:\n        return self.client.build_request(\n            method,\n            url,\n            content=content,\n            data=data,\n            files=files,\n            json=json,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            timeout=timeout,\n            extensions=extensions,\n        )\n\ns = MistralAzure(async_client=CustomClient(httpx.AsyncClient()))\n```\n\n----------------------------------------\n\nTITLE: Creating Asynchronous Chat Completions with Mistral AI Azure Client in Python\nDESCRIPTION: This snippet shows how to use the MistralAzure client for asynchronous chat completion requests. It utilizes asyncio for asynchronous execution and follows a similar pattern to the synchronous example, but uses the complete_async method.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/USAGE.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Asynchronous Example\nimport asyncio\nfrom mistralai_azure import MistralAzure\nimport os\n\nasync def main():\n    s = MistralAzure(\n        azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n        azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n    )\n    res = await s.chat.complete_async(messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], model=\"azureai\")\n    if res is not None:\n        # handle response\n        pass\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Creating Asynchronous Embedding Requests with Mistral AI Python SDK\nDESCRIPTION: This example shows how to create asynchronous embedding requests using the Mistral AI Python client. It initializes the client with an API key inside an async context manager and uses the create_async method with asyncio to generate embeddings for multiple text inputs.\nSOURCE: https://github.com/mistralai/client-python/blob/main/USAGE.md#2025-04-17_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Asynchronous Example\nimport asyncio\nfrom mistralai import Mistral\nimport os\n\nasync def main():\n\n    async with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n\n        res = await mistral.embeddings.create_async(model=\"mistral-embed\", inputs=[\n            \"Embed this sentence.\",\n            \"As well as this one.\",\n        ])\n\n        # Handle response\n        print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Synchronous Chat Completion Example\nDESCRIPTION: Example showing how to create synchronous chat completions using the Mistral GCP client\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Synchronous Example\nfrom mistralai_gcp import MistralGCP\nimport os\n)\n\n\nres = s.chat.complete(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"mistral-small-latest\")\n\nif res is not None:\n    # handle response\n    pass\n```\n\n----------------------------------------\n\nTITLE: Creating Asynchronous Agent Completions with Mistral AI Python SDK\nDESCRIPTION: This example shows how to create asynchronous agent completions using the Mistral AI Python client. It initializes the client with an API key inside an async context manager and uses the complete_async method with asyncio to make a request to a specific agent.\nSOURCE: https://github.com/mistralai/client-python/blob/main/USAGE.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Asynchronous Example\nimport asyncio\nfrom mistralai import Mistral\nimport os\n\nasync def main():\n\n    async with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n\n        res = await mistral.agents.complete_async(messages=[\n            {\n                \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n                \"role\": \"user\",\n            },\n        ], agent_id=\"<id>\")\n\n        # Handle response\n        print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Initializing Mistral SDK with Custom HTTP Client in Python\nDESCRIPTION: Demonstrates how to initialize the Mistral SDK with a custom HTTP client that includes a custom header for every request. This example uses the httpx library to create a client with a specific header.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport httpx\n\nhttp_client = httpx.Client(headers={\"x-custom-header\": \"someValue\"})\ns = Mistral(client=http_client)\n```\n\n----------------------------------------\n\nTITLE: Creating Chat Completion with Mistral AI Python Client\nDESCRIPTION: This snippet shows how to use the complete method of the Chat Completion API to get a full response from the Mistral AI model. It sets up the client, sends a message, and handles the response.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/sdks/chat/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP\nimport os\n\ns = MistralGCP()\n\n\nres = s.chat.complete(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"mistral-small-latest\")\n\nif res is not None:\n    # handle response\n    pass\n```\n\n----------------------------------------\n\nTITLE: Uploading Files Asynchronously with Mistral AI Python SDK\nDESCRIPTION: This example shows how to upload a file asynchronously using the Mistral AI Python client. It initializes the client with an API key inside an async context manager and uses the upload_async method with asyncio to upload a local file.\nSOURCE: https://github.com/mistralai/client-python/blob/main/USAGE.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Asynchronous Example\nimport asyncio\nfrom mistralai import Mistral\nimport os\n\nasync def main():\n\n    async with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n\n        res = await mistral.files.upload_async(file={\n            \"file_name\": \"example.file\",\n            \"content\": open(\"example.file\", \"rb\"),\n        })\n\n        # Handle response\n        print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Getting Signed URLs with Mistral API\nDESCRIPTION: Example demonstrating how to get a signed URL for file access using the Mistral Python client. Requires API key authentication and file ID, with optional expiry parameter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/files/README.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.files.get_signed_url(file_id=\"<id>\")\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Async Chat with MistralAI Client (New Implementation)\nDESCRIPTION: Updated example using the new unified Mistral client for asynchronous streaming chat completions. Shows proper async function structure with asyncio and the new method naming conventions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/MIGRATION.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport os\n\nfrom mistralai import Mistral, UserMessage\n\n\nasync def main():\n    client = Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    )\n\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": \"What is the best French cheese?\",\n        },\n    ]\n    # Or using the new message classes\n    # messages = [\n    #     UserMessage(\n    #         content=\"What is the best French cheese?\",\n    #     ),\n    # ]\n    async_response = await client.chat.stream_async(\n        messages=messages,\n        model=\"mistral-large-latest\",\n    )\n\n    async for chunk in async_response:\n        print(chunk.data.choices[0].delta.content)\n\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Getting Fine-Tuning Job Details - MistralAI Python\nDESCRIPTION: This code snippet demonstrates how to retrieve details of a fine-tuning job using the MistralAI Python client. It initializes the Mistral client with an API key and then calls the `fine_tuning.jobs.get()` method with the job ID to retrieve the job details. The retrieved job details are then printed to the console.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/jobs/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.fine_tuning.jobs.get(job_id=\"b888f774-3e7c-4135-a18c-6b985523c4bc\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Moderating Text with Mistral API in Python\nDESCRIPTION: This snippet demonstrates how to use the Mistral API to moderate text inputs. It initializes the Mistral client with an API key and calls the moderate method with a specified model and input text.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/classifiers/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.classifiers.moderate(model=\"V90\", inputs=[\n        \"<value>\",\n    ])\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Error Handling Example\nDESCRIPTION: Example demonstrating proper error handling for API calls including HTTP validation errors\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP, models\nimport os\n\ns = MistralGCP()\n\nres = None\ntry:\n    res = s.chat.complete(\n        messages=[\n            {\n                \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n                \"role\": \"user\",\n            },\n        ],\n        model=\"mistral-small-latest\"\n    )\n\nexcept models.HTTPValidationError as e:\n    # handle exception\n    raise(e)\nexcept models.SDKError as e:\n    # handle exception\n    raise(e)\n\nif res is not None:\n    # handle response\n    pass\n```\n\n----------------------------------------\n\nTITLE: Retrieving File Information with Mistral API\nDESCRIPTION: Example showing how to retrieve information about a specific file using the Mistral Python client. Requires API key authentication and file ID parameter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/files/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.files.retrieve(file_id=\"<id>\")\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Performing FIM Completion with Mistral AI Python Client\nDESCRIPTION: This code snippet demonstrates how to use the Mistral AI Python client to perform a Fill-in-the-Middle (FIM) completion. It initializes the Mistral client with an API key from an environment variable and makes a completion request using the 'codestral-2405' model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/fim/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.fim.complete(model=\"codestral-2405\", prompt=\"def\", suffix=\"return a+b\")\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Defining API Response and Error Types in Markdown\nDESCRIPTION: This snippet defines the response type and possible error types for an API endpoint. It includes the return type and details about HTTP errors that may occur.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/agents/README.md#2025-04-17_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n### Response\n\n**[Union[eventstreaming.EventStream[models.CompletionEvent], eventstreaming.EventStreamAsync[models.CompletionEvent]]](../../models/.md)**\n\n### Errors\n\n| Error Type                 | Status Code                | Content Type               |\n| -------------------------- | -------------------------- | -------------------------- |\n| models.HTTPValidationError | 422                        | application/json           |\n| models.SDKError            | 4XX, 5XX                   | \\*/\\*                      |\n```\n\n----------------------------------------\n\nTITLE: Classifying Chat with Mistral API in Python\nDESCRIPTION: This snippet shows how to use the Mistral API for chat classification. It initializes the Mistral client and calls the classify_chat method with a specified model and chat input structure.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/classifiers/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.classifiers.classify_chat(model=\"Fortwo\", inputs=[\n        {\n            \"messages\": [\n                {\n                    \"content\": \"<value>\",\n                    \"role\": \"tool\",\n                },\n            ],\n        },\n        {\n            \"messages\": [\n\n            ],\n        },\n    ])\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Managing Mistral SDK Resources with Context Manager in Python\nDESCRIPTION: Shows how to use the Mistral SDK with a context manager for proper resource management. This approach ensures that HTTP connections and other resources are properly closed and freed up after use.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\ndef main():\n\n    with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n        # Rest of application here...\n\n\n# Or when using async:\nasync def amain():\n\n    async with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n        # Rest of application here...\n```\n\n----------------------------------------\n\nTITLE: Making Agent Completion Request with Mistral AI Python Client\nDESCRIPTION: Demonstrates how to use the Mistral AI Python client to make an agent completion request. The example shows initialization of the client with an API key and sending a simple prompt to get a response from a specific agent.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/agents/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.agents.complete(messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], agent_id=\"<id>\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Setting Up Mistral API Key in Bash Environment\nDESCRIPTION: Instructions for setting up the Mistral API key as an environment variable in a zsh shell\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# set Mistral API Key (using zsh for example)\n$ echo 'export MISTRAL_API_KEY=[your_key_here]' >> ~/.zshenv\n\n# reload the environment (or just quit and open a new terminal)\n$ source ~/.zshenv\n```\n\n----------------------------------------\n\nTITLE: Defining AgentsCompletionRequest Class in Python for Mistral AI Client\nDESCRIPTION: This code snippet defines the AgentsCompletionRequest class with various attributes for configuring agent-based completion requests. It includes parameters for the model, messages, tools, temperature, max tokens, top p, stream, safe mode, and random seed.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass AgentsCompletionRequest:\n    model: str\n    messages: List[Message]\n    tools: Optional[List[Tool]] = None\n    temperature: Optional[float] = None\n    max_tokens: Optional[int] = None\n    top_p: Optional[float] = None\n    stream: Optional[bool] = None\n    safe_mode: Optional[bool] = None\n    random_seed: Optional[int] = None\n```\n\n----------------------------------------\n\nTITLE: Listing Fine Tuning Jobs with MistralAI Python Client\nDESCRIPTION: Example of how to list fine-tuning jobs for your organization and user using the MistralAI Python client. The code demonstrates initializing the client with an API key from environment variables and making a request to list jobs.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/jobs/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.fine_tuning.jobs.list()\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Google Cloud Integration Example\nDESCRIPTION: Example showing how to use Mistral with Google Cloud integration\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom mistralai_gcp import MistralGoogleCloud\n\nclient = MistralGoogleCloud()\n\n\nasync def main() -> None:\n    res = await client.chat.complete_async(\n        model= \"mistral-small-2402\",\n        messages= [\n            {\n                \"content\": \"Hello there!\",\n                \"role\": \"user\"\n            }\n        ]\n    )\n    print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Markdown Parameter Documentation for MistralAI Python Client\nDESCRIPTION: Markdown table documenting the optional parameters for the Mistral AI Python client, including top_p, max_tokens, stream, stop, and random_seed parameters. Each parameter includes its type definition and detailed description of its purpose and behavior.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/chat/README.md#2025-04-17_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| `top_p` | *Optional[float]* | :heavy_minus_sign: | Nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both. |\n| `max_tokens` | *OptionalNullable[int]* | :heavy_minus_sign: | The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length. |\n| `stream` | *Optional[bool]* | :heavy_minus_sign: | Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON. |\n| `stop` | [Optional[models.Stop]](../../models/stop.md) | :heavy_minus_sign: | Stop generation if this token is detected. Or if one of these tokens is detected when providing an array |\n| `random_seed` | *OptionalNullable[int]* | :heavy_minus_sign: | The seed to use for random sampling. If set, different calls will generate deterministic results. |\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionJobOut Class in Python for Mistral AI Client\nDESCRIPTION: This code snippet defines the CompletionJobOut class, which is a data structure for holding the results of a completion job. It uses Pydantic for data validation and serialization.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completionjobout.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# CompletionJobOut\n```\n\n----------------------------------------\n\nTITLE: Asynchronous File Upload Example\nDESCRIPTION: Example showing how to upload files using the Mistral SDK asynchronously\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom mistralai import Mistral\nimport os\n\nasync def main():\n\n    async with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n\n        res = await mistral.files.upload_async(file={\n            \"file_name\": \"example.file\",\n            \"content\": open(\"example.file\", \"rb\"),\n        })\n\n        # Handle response\n        print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Async HTTP Client for Mistral SDK in Python\nDESCRIPTION: Shows how to create a custom asynchronous HTTP client that wraps the default client and adds custom logic. This example adds a custom header to every request and demonstrates how to implement the required methods.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nfrom mistralai.httpclient import AsyncHttpClient\nimport httpx\n\nclass CustomClient(AsyncHttpClient):\n    client: AsyncHttpClient\n\n    def __init__(self, client: AsyncHttpClient):\n        self.client = client\n\n    async def send(\n        self,\n        request: httpx.Request,\n        *,\n        stream: bool = False,\n        auth: Union[\n            httpx._types.AuthTypes, httpx._client.UseClientDefault, None\n        ] = httpx.USE_CLIENT_DEFAULT,\n        follow_redirects: Union[\n            bool, httpx._client.UseClientDefault\n        ] = httpx.USE_CLIENT_DEFAULT,\n    ) -> httpx.Response:\n        request.headers[\"Client-Level-Header\"] = \"added by client\"\n\n        return await self.client.send(\n            request, stream=stream, auth=auth, follow_redirects=follow_redirects\n        )\n\n    def build_request(\n        self,\n        method: str,\n        url: httpx._types.URLTypes,\n        *,\n        content: Optional[httpx._types.RequestContent] = None,\n        data: Optional[httpx._types.RequestData] = None,\n        files: Optional[httpx._types.RequestFiles] = None,\n        json: Optional[Any] = None,\n        params: Optional[httpx._types.QueryParamTypes] = None,\n        headers: Optional[httpx._types.HeaderTypes] = None,\n        cookies: Optional[httpx._types.CookieTypes] = None,\n        timeout: Union[\n            httpx._types.TimeoutTypes, httpx._client.UseClientDefault\n        ] = httpx.USE_CLIENT_DEFAULT,\n        extensions: Optional[httpx._types.RequestExtensions] = None,\n    ) -> httpx.Request:\n        return self.client.build_request(\n            method,\n            url,\n            content=content,\n            data=data,\n            files=files,\n            json=json,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            timeout=timeout,\n            extensions=extensions,\n        )\n\ns = Mistral(async_client=CustomClient(httpx.AsyncClient()))\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat with MistralAI Client (New Implementation)\nDESCRIPTION: Updated example using the new Mistral client for streaming chat completions. Shows the new method naming and response structure changes, including the updated path to access content.\nSOURCE: https://github.com/mistralai/client-python/blob/main/MIGRATION.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom mistralai import Mistral, UserMessage\n\napi_key = os.environ[\"MISTRAL_API_KEY\"]\nmodel = \"mistral-large-latest\"\n\nclient = Mistral(api_key=api_key)\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"What is the best French cheese?\",\n    },\n]\n# Or using the new message classes\n# messages = [\n#     UserMessage(content=\"What is the best French cheese?\"),\n# ]\n\nstream_response = client.chat.stream(\n    model=model,\n    messages=messages,\n)\n\nfor chunk in stream_response:\n    print(chunk.data.choices[0].delta.content)\n```\n\n----------------------------------------\n\nTITLE: Defining API Endpoints for Mistral AI Python Client\nDESCRIPTION: This code snippet defines constant values for various API endpoints used in the Mistral AI Python client. It includes endpoints for chat completions, embeddings, FIM completions, and moderation services.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/apiendpoint.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                       | Value                      |\n| -------------------------- | -------------------------- |\n| `ROOT_V1_CHAT_COMPLETIONS` | /v1/chat/completions       |\n| `ROOT_V1_EMBEDDINGS`       | /v1/embeddings             |\n| `ROOT_V1_FIM_COMPLETIONS`  | /v1/fim/completions        |\n| `ROOT_V1_MODERATIONS`      | /v1/moderations            |\n| `ROOT_V1_CHAT_MODERATIONS` | /v1/chat/moderations       |\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Chat Completion with Mistral Azure\nDESCRIPTION: Example demonstrating asynchronous chat completions using asyncio with the MistralAzure client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Asynchronous Example\nimport asyncio\nfrom mistralai_azure import MistralAzure\nimport os\n\nasync def main():\n    s = MistralAzure(\n        azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n        azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n    )\n    res = await s.chat.complete_async(\n        messages=[\n            {\n                \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n                \"role\": \"user\",\n            },\n        ], \n        model=\"azureai\"\n    )\n    if res is not None:\n        # handle response\n        pass\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Server-Sent Event Streaming with Mistral Azure\nDESCRIPTION: Example showing how to handle server-sent event streaming for chat completions using a generator pattern.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nimport os\n\ns = MistralAzure(\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.stream(\n    messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], \n    model=\"azureai\"\n)\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Code Completion Prompt in Python\nDESCRIPTION: This snippet shows an example of a prompt for code completion. It's a simple Python function definition start, which would be completed by the AI model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/fim/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef\n```\n\n----------------------------------------\n\nTITLE: Synchronous Chat Completion with Mistral Azure\nDESCRIPTION: Example showing how to create synchronous chat completions using the MistralAzure client with authentication via environment variables.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Synchronous Example\nfrom mistralai_azure import MistralAzure\nimport os\n\ns = MistralAzure(\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.complete(\n    messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], \n    model=\"azureai\"\n)\n\nif res is not None:\n    # handle response\n    pass\n```\n\n----------------------------------------\n\nTITLE: Archiving a Fine-Tuned Model with Mistral Python Client\nDESCRIPTION: This snippet demonstrates how to archive a fine-tuned model using the Mistral Python client. It initializes the client with an API key and calls the archive method on the models object, passing a model ID as a parameter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/models/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.archive(model_id=\"ft:open-mistral-7b:587a6b29:20240514:7e773925\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Function Fields Documentation Table in Markdown\nDESCRIPTION: Markdown table documenting the required and optional fields for function parameters, including their types and requirements. The table covers name (string), parameters (dictionary), description (optional string), and strict (optional boolean) fields.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/function.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `name`             | *str*              | :heavy_check_mark: | N/A                |\n| `parameters`       | Dict[str, *Any*]   | :heavy_check_mark: | N/A                |\n| `description`      | *Optional[str]*    | :heavy_minus_sign: | N/A                |\n| `strict`           | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Enabling Debug Logging for Mistral SDK in Python\nDESCRIPTION: Demonstrates how to enable debug logging for the Mistral SDK. This example shows how to set up a custom logger and pass it to the SDK instance for detailed request and response logging.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG)\ns = Mistral(debug_logger=logging.getLogger(\"mistralai\"))\n```\n\n----------------------------------------\n\nTITLE: Async Chat with MistralAI Client (Old Implementation)\nDESCRIPTION: Example of using the old MistralAsyncClient for asynchronous streaming chat completions. Demonstrates the async client instantiation and response handling.\nSOURCE: https://github.com/mistralai/client-python/blob/main/MIGRATION.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai.async_client import MistralAsyncClient\nfrom mistralai.models.chat_completion import ChatMessage\n\napi_key = os.environ[\"MISTRAL_API_KEY\"]\nmodel = \"mistral-large-latest\"\n\nclient = MistralAsyncClient(api_key=api_key)\n\nmessages = [\n    ChatMessage(role=\"user\", content=\"What is the best French cheese?\")\n]\n\n# With async\nasync_response = client.chat_stream(model=model, messages=messages)\n\nasync for chunk in async_response:\n    print(chunk.choices[0].delta.content)\n```\n\n----------------------------------------\n\nTITLE: BaseModelCard Field Specifications - Markdown Table\nDESCRIPTION: Markdown table defining the field specifications for BaseModelCard including field names, data types, requirement status, and descriptions. Documents critical model attributes like ID, capabilities, object type, creation timestamp, ownership, and various model parameters.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/basemodelcard.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                | Type                                                                 | Required                                                             | Description                                                          |\n| -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| `id`                                                                 | *str*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `capabilities`                                                       | [models.ModelCapabilities](../models/modelcapabilities.md)           | :heavy_check_mark:                                                   | N/A                                                                  |\n| `object`                                                             | *Optional[str]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `created`                                                            | *Optional[int]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `owned_by`                                                           | *Optional[str]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `name`                                                               | *OptionalNullable[str]*                                              | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `description`                                                        | *OptionalNullable[str]*                                              | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `max_context_length`                                                 | *Optional[int]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `aliases`                                                            | List[*str*]                                                          | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `deprecation`                                                        | [date](https://docs.python.org/3/library/datetime.html#date-objects) | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `default_model_temperature`                                          | *OptionalNullable[float]*                                            | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `type`                                                               | [Optional[models.Type]](../models/type.md)                           | :heavy_minus_sign:                                                   | N/A                                                                  |\n```\n\n----------------------------------------\n\nTITLE: Uploading Files Synchronously with Mistral AI Python SDK\nDESCRIPTION: This example demonstrates how to upload a file synchronously using the Mistral AI Python client. It initializes the client with an API key and uploads a file by specifying a file name and binary content from a local file.\nSOURCE: https://github.com/mistralai/client-python/blob/main/USAGE.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Synchronous Example\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.files.upload(file={\n        \"file_name\": \"example.file\",\n        \"content\": open(\"example.file\", \"rb\"),\n    })\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Creating a Batch Job with Mistral AI Python Client\nDESCRIPTION: This snippet shows how to create a new batch job using the Mistral AI Python client. It uses the create() method of the batch.jobs module, specifying input files, endpoint, and model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/mistraljobs/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.batch.jobs.create(input_files=[\n        \"a621cf02-1cd9-4cf5-8403-315211a509a3\",\n    ], endpoint=\"/v1/fim/completions\", model=\"2\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Example Message Structure for Mistral AI API in JSON\nDESCRIPTION: Demonstrates the structure of a message object to be passed as a parameter to the Mistral AI API. It includes the 'role' and 'content' fields for a user prompt.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/agents/README.md#2025-04-17_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"role\": \"user\",\n    \"content\": \"Who is the best French painter? Answer in one short sentence.\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Defining Function Class Fields in Python\nDESCRIPTION: This code snippet defines the fields of the Function class. It includes required fields 'name' and 'parameters', and optional fields 'description' and 'strict'. The types and requirements for each field are specified.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/function.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Function\n\n\n## Fields\n\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `name`             | *str*              | :heavy_check_mark: | N/A                |\n| `parameters`       | Dict[str, *Any*]   | :heavy_check_mark: | N/A                |\n| `description`      | *Optional[str]*    | :heavy_minus_sign: | N/A                |\n| `strict`           | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Synchronous File Upload Example\nDESCRIPTION: Example showing how to upload files using the Mistral SDK synchronously\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.files.upload(file={\n        \"file_name\": \"example.file\",\n        \"content\": open(\"example.file\", \"rb\"),\n    })\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Using Custom Method in Python Client\nDESCRIPTION: Example of how to use the custom method in the Mistral AI Python client after implementation and installation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/src/mistralai/extra/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom mistralai import Mistral\n\napi_key = os.environ[\"MISTRAL_API_KEY\"]\nclient = Mistral(api_key=api_key)\n\nclient.chat.my_custom_method(param=\"test\")\n```\n\n----------------------------------------\n\nTITLE: Mistral AI Chat Completion Parameters Documentation in Markdown\nDESCRIPTION: Markdown table documenting the configuration parameters for Mistral AI chat completion requests. Includes top_p for nucleus sampling, max_tokens for output length control, stream for response streaming, stop for generation control, and random_seed for deterministic outputs.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| `top_p` | *Optional[float]* | :heavy_minus_sign: | Nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both. |\n| `max_tokens` | *OptionalNullable[int]* | :heavy_minus_sign: | The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length. |\n| `stream` | *Optional[bool]* | :heavy_minus_sign: | Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON. |\n| `stop` | [Optional[models.ChatCompletionRequestStop]](../models/chatcompletionrequeststop.md) | :heavy_minus_sign: | Stop generation if this token is detected. Or if one of these tokens is detected when providing an array |\n| `random_seed` | *OptionalNullable[int]* | :heavy_minus_sign: | The seed to use for random sampling. If set, different calls will generate deterministic results. |\n```\n\n----------------------------------------\n\nTITLE: Defining AgentsCompletionStreamRequest Class in Python\nDESCRIPTION: This class definition for AgentsCompletionStreamRequest inherits from BaseModel. It includes various fields such as model, messages, tools, tool_choice, temperature, max_tokens, top_p, stop, stream, safe_mode, random_seed, and response_format.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass AgentsCompletionStreamRequest(BaseModel):\n    model: str\n    messages: List[ChatMessage]\n    tools: Optional[List[ChatCompletionTool]] = None\n    tool_choice: Optional[ChatCompletionToolChoice] = None\n    temperature: Optional[float] = None\n    max_tokens: Optional[int] = None\n    top_p: Optional[float] = None\n    stop: Optional[Union[str, List[str]]] = None\n    stream: Optional[bool] = True\n    safe_mode: Optional[bool] = None\n    random_seed: Optional[int] = None\n    response_format: Optional[ChatCompletionResponseFormat] = None\n```\n\n----------------------------------------\n\nTITLE: Listing Batch Jobs with Mistral AI Python Client\nDESCRIPTION: This snippet demonstrates how to retrieve a list of batch jobs for your organization and user using the Mistral AI Python client. It uses the list() method of the batch.jobs module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/mistraljobs/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.batch.jobs.list()\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Installing Mistral AI SDK\nDESCRIPTION: Instructions for installing the Mistral AI Python package using pip or poetry package managers.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install mistralai\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry add mistralai\n```\n\n----------------------------------------\n\nTITLE: Defining Tools for AI Function Calling\nDESCRIPTION: Optional list of tools or functions that can be used by the AI model during response generation. Enables advanced interaction and function calling capabilities.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntools: List[models.Tool] = []\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Embedding Creation Example\nDESCRIPTION: Example showing how to create embeddings using the Mistral SDK asynchronously\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom mistralai import Mistral\nimport os\n\nasync def main():\n\n    async with Mistral(\n        api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n    ) as mistral:\n\n        res = await mistral.embeddings.create_async(model=\"mistral-embed\", inputs=[\n            \"Embed this sentence.\",\n            \"As well as this one.\",\n        ])\n\n        # Handle response\n        print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Canceling a Batch Job with Mistral AI Python Client\nDESCRIPTION: This snippet shows how to request the cancellation of a batch job using the Mistral AI Python client. It uses the cancel() method of the batch.jobs module, specifying the job ID to be canceled.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/mistraljobs/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.batch.jobs.cancel(job_id=\"0f713502-9233-41c6-9ebd-c570b7edb496\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Tool Fields Documentation Table in Markdown\nDESCRIPTION: Markdown table documenting the fields of the Tool class, including function and type fields with their respective types and requirements.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/tool.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                | Type                                                 | Required                                             | Description                                          |\n| ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- |\n| `function`                                           | [models.Function](../models/function.md)             | :heavy_check_mark:                                   | N/A                                                  |\n| `type`                                               | [Optional[models.ToolTypes]](../models/tooltypes.md) | :heavy_minus_sign:                                   | N/A                                                  |\n```\n\n----------------------------------------\n\nTITLE: Downloading Files with Mistral API\nDESCRIPTION: Example showing how to download a file using the Mistral Python client. Requires API key authentication and file ID of the file to be downloaded.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/files/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.files.download(file_id=\"<id>\")\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Defining Chat Completion Stream Request Fields in Markdown\nDESCRIPTION: A markdown table defining the fields for a chat completion stream request, including the model, messages, and temperature. It specifies the type, requirement, description, and example for each field.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description | Example |\n| ----- | ---- | -------- | ----------- | ------- |\n| `model` | *str* | :heavy_check_mark: | ID of the model to use. You can use the [List Available Models](/api/#tag/models/operation/list_models_v1_models_get) API to see all of your available models, or see our [Model overview](/models) for model descriptions. | mistral-small-latest |\n| `messages` | List[[models.ChatCompletionStreamRequestMessages](../models/chatcompletionstreamrequestmessages.md)] | :heavy_check_mark: | The prompt(s) to generate completions for, encoded as a list of dict with role and content. | [<br/>{<br/>\"role\": \"user\",<br/>\"content\": \"Who is the best French painter? Answer in one short sentence.\"<br/>}<br/>] |\n| `temperature` | *OptionalNullable[float]* | :heavy_minus_sign: | What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value. | |\n```\n\n----------------------------------------\n\nTITLE: Defining FIMCompletionResponse Fields in Markdown\nDESCRIPTION: This snippet outlines the fields of the FIMCompletionResponse class using a markdown table. It includes field names, types, requirements, descriptions, and examples for each field.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/fimcompletionresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            | Example                                                                |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `id`                                                                   | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | cmpl-e5cc70bb28c444948073e77776eb30ef                                  |\n| `object`                                                               | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | chat.completion                                                        |\n| `model`                                                                | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | codestral-latest                                                       |\n| `usage`                                                                | [models.UsageInfo](../models/usageinfo.md)                             | :heavy_check_mark:                                                     | N/A                                                                    |                                                                        |\n| `created`                                                              | *Optional[int]*                                                        | :heavy_minus_sign:                                                     | N/A                                                                    | 1702256327                                                             |\n| `choices`                                                              | List[[models.ChatCompletionChoice](../models/chatcompletionchoice.md)] | :heavy_minus_sign:                                                     | N/A                                                                    |                                                                        |\n```\n\n----------------------------------------\n\nTITLE: Mistral AI Parameters Table in Markdown\nDESCRIPTION: Markdown table documenting the optional parameters for Mistral AI API requests, including n (number of completions), prediction, parallel_tool_calls, and safe_prompt parameters with their types and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionrequest.md#2025-04-17_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| `n` | *OptionalNullable[int]* | :heavy_minus_sign: | Number of completions to return for each request, input tokens are only billed once. |\n| `prediction` | [Optional[models.Prediction]](../models/prediction.md) | :heavy_minus_sign: | N/A |\n| `parallel_tool_calls` | *Optional[bool]* | :heavy_minus_sign: | N/A |\n| `safe_prompt` | *Optional[bool]* | :heavy_minus_sign: | Whether to inject a safety prompt before all conversations. |\n```\n\n----------------------------------------\n\nTITLE: Unarchiving a Fine-Tuned Model with Mistral AI Python Client\nDESCRIPTION: This snippet demonstrates how to use the Mistral AI Python client to unarchive a previously archived fine-tuned model. It requires the Mistral API key and the model ID as input.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/models/README.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.unarchive(model_id=\"ft:open-mistral-7b:587a6b29:20240514:7e773925\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Cancelling a Fine-Tuning Job - MistralAI Python\nDESCRIPTION: This code snippet demonstrates how to request the cancellation of a fine-tuning job using the MistralAI Python client. It initializes the Mistral client with an API key and then calls the `fine_tuning.jobs.cancel()` method with the job ID to request cancellation. The response after attempting the cancellation is then printed to the console.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/jobs/README.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.fine_tuning.jobs.cancel(job_id=\"0f713502-9233-41c6-9ebd-c570b7edb496\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Response Format in Mistral AI Chat Completion\nDESCRIPTION: Optional parameter to specify the desired response format for the AI model. Allows customization of output structure and type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nresponse_format: Optional[models.ResponseFormat] = None\n```\n\n----------------------------------------\n\nTITLE: Defining ToolCall Model Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ToolCall model, including their types, whether they are required, and any additional description. It includes fields for function, id, type, and index.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/toolcall.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                | Type                                                 | Required                                             | Description                                          |\n| ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- |\n| `function`                                           | [models.FunctionCall](../models/functioncall.md)     | :heavy_check_mark:                                   | N/A                                                  |\n| `id`                                                 | *Optional[str]*                                      | :heavy_minus_sign:                                   | N/A                                                  |\n| `type`                                               | [Optional[models.ToolTypes]](../models/tooltypes.md) | :heavy_minus_sign:                                   | N/A                                                  |\n| `index`                                              | *Optional[int]*                                      | :heavy_minus_sign:                                   | N/A                                                  |\n```\n\n----------------------------------------\n\nTITLE: Listing Files with MistralAI Python Client\nDESCRIPTION: Example demonstrating how to retrieve a list of files belonging to the user's organization using the MistralAI client. Uses environment variable for API key authentication.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/files/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.files.list()\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Defining API Request Fields in Markdown\nDESCRIPTION: A markdown table defining the fields for API requests in the Mistral AI Python client. It includes the field names, types, requirements, descriptions, and examples for 'model', 'prompt', and 'temperature' parameters.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/fimcompletionrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description | Example |\n| ----- | ---- | -------- | ----------- | ------- |\n| `model` | *str* | :heavy_check_mark: | ID of the model to use. Only compatible for now with:<br/>  - `codestral-2405`<br/>  - `codestral-latest` | codestral-2405 |\n| `prompt` | *str* | :heavy_check_mark: | The text/code to complete. | def |\n| `temperature` | *OptionalNullable[float]* | :heavy_minus_sign: | What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value. | |\n```\n\n----------------------------------------\n\nTITLE: Parameter Table Definition in Markdown\nDESCRIPTION: Markdown table defining optional training parameters for the Mistral AI client including epochs, sequence length, and fill-in-the-middle ratio with their types and configurations.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completiontrainingparametersin.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| `epochs` | *OptionalNullable[float]* | :heavy_minus_sign: | N/A |\n| `seq_len` | *OptionalNullable[int]* | :heavy_minus_sign: | N/A |\n| `fim_ratio` | *OptionalNullable[float]* | :heavy_minus_sign: | N/A |\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionStreamRequest Class in Python for Mistral AI Client\nDESCRIPTION: This code snippet defines the ChatCompletionStreamRequest class, which inherits from BaseModel. It specifies the structure and types of parameters used for streaming chat completion requests in the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass ChatCompletionStreamRequest(BaseModel):\n    model: str\n    messages: List[ChatMessage]\n    temperature: Optional[float] = None\n    max_tokens: Optional[int] = None\n    top_p: Optional[float] = None\n    random_seed: Optional[int] = None\n    safe_mode: Optional[bool] = None\n    stream: Literal[True] = True\n```\n\n----------------------------------------\n\nTITLE: Error Handling Example\nDESCRIPTION: Example demonstrating proper error handling for API calls using try-except blocks for specific error types.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure, models\nimport os\n\ns = MistralAzure(\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\nres = None\ntry:\n    res = s.chat.complete(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"azureai\")\n\nexcept models.HTTPValidationError as e:\n    # handle exception\n    raise(e)\nexcept models.SDKError as e:\n    # handle exception\n    raise(e)\n\nif res is not None:\n    # handle response\n    pass\n```\n\n----------------------------------------\n\nTITLE: Defining an AssistantMessage in MistralAI Python Client\nDESCRIPTION: Demonstrates how to define an AssistantMessage object for use in an instruction request. AssistantMessages represent responses from the AI assistant in a conversation history.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequestinputsmessages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Installing GCP Authentication\nDESCRIPTION: Command to authenticate with Google Cloud Platform locally\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngcloud auth application-default login\n```\n\n----------------------------------------\n\nTITLE: Defining Chat Completion API Fields in Markdown\nDESCRIPTION: A markdown table defining the fields for the chat completion API, including their types, requirements, descriptions, and examples. It covers the 'model', 'messages', and 'temperature' parameters.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description | Example |\n| ----- | ---- | -------- | ----------- | ------- |\n| `model` | *str* | :heavy_check_mark: | ID of the model to use. You can use the [List Available Models](/api/#tag/models/operation/list_models_v1_models_get) API to see all of your available models, or see our [Model overview](/models) for model descriptions. | mistral-small-latest |\n| `messages` | List[[models.Messages](../models/messages.md)] | :heavy_check_mark: | The prompt(s) to generate completions for, encoded as a list of dict with role and content. | [{\"role\": \"user\",\"content\": \"Who is the best French painter? Answer in one short sentence.\"}] |\n| `temperature` | *OptionalNullable[float]* | :heavy_minus_sign: | What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value. | |\n```\n\n----------------------------------------\n\nTITLE: Creating Synchronous Agent Completions with Mistral AI Python SDK\nDESCRIPTION: This example demonstrates how to create synchronous agent completions using the Mistral AI Python client. It initializes the client with an API key and makes a request to a specific agent identified by its ID with a user message.\nSOURCE: https://github.com/mistralai/client-python/blob/main/USAGE.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Synchronous Example\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.agents.complete(messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], agent_id=\"<id>\")\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Markdown Table Definition of Mistral AI Client Fields\nDESCRIPTION: A markdown table that defines the fields used for model fine-tuning, including their types, requirements, and descriptions. The table covers model name, hyperparameters, training files, validation files, and suffix configuration.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobin.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description |\n| --- | --- | --- | --- |\n| `model` | *str* | :heavy_check_mark: | The name of the model to fine-tune. |\n| `hyperparameters` | [models.Hyperparameters](../models/hyperparameters.md) | :heavy_check_mark: | N/A |\n| `training_files` | List[[models.TrainingFile](../models/trainingfile.md)] | :heavy_minus_sign: | N/A |\n| `validation_files` | List[*str*] | :heavy_minus_sign: | A list containing the IDs of uploaded files that contain validation data. If you provide these files, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in `checkpoints` when getting the status of a running fine-tuning job. The same data should not be present in both train and validation files. |\n| `suffix` | *OptionalNullable[str]* | :heavy_minus_sign: | A string that will be added to your fine-tuning model name. For example, a suffix of \"my-great-model\" would produce a model name like `ft:open-mistral-7b:my-great-model:xxx...` |\n```\n\n----------------------------------------\n\nTITLE: Defining FIMCompletionResponse Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the FIMCompletionResponse model, including their types, requirements, and examples. It covers key properties such as id, object, model, usage, created, and choices.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/fimcompletionresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            | Example                                                                |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `id`                                                                   | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | cmpl-e5cc70bb28c444948073e77776eb30ef                                  |\n| `object`                                                               | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | chat.completion                                                        |\n| `model`                                                                | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | codestral-latest                                                       |\n| `usage`                                                                | [models.UsageInfo](../models/usageinfo.md)                             | :heavy_check_mark:                                                     | N/A                                                                    |                                                                        |\n| `created`                                                              | *Optional[int]*                                                        | :heavy_minus_sign:                                                     | N/A                                                                    | 1702256327                                                             |\n| `choices`                                                              | List[[models.ChatCompletionChoice](../models/chatcompletionchoice.md)] | :heavy_minus_sign:                                                     | N/A                                                                    |                                                                        |\n```\n\n----------------------------------------\n\nTITLE: Deleting Files with Mistral API\nDESCRIPTION: Example demonstrating how to delete a file using the Mistral Python client. Requires API key authentication and file ID of the file to be deleted.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/files/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.files.delete(file_id=\"<id>\")\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Defining BatchJobOut Class Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the BatchJobOut class, including their types, whether they are required, and placeholders for descriptions. It covers essential job information, status details, and various metrics related to the batch processing.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/batchjobout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                | Type                                                                 | Required                                                             | Description                                                          |\n| -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| `id`                                                                 | *str*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `input_files`                                                        | List[*str*]                                                          | :heavy_check_mark:                                                   | N/A                                                                  |\n| `endpoint`                                                           | *str*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `model`                                                              | *str*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `errors`                                                             | List[[models.BatchError](../models/batcherror.md)]                   | :heavy_check_mark:                                                   | N/A                                                                  |\n| `status`                                                             | [models.BatchJobStatus](../models/batchjobstatus.md)                 | :heavy_check_mark:                                                   | N/A                                                                  |\n| `created_at`                                                         | *int*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `total_requests`                                                     | *int*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `completed_requests`                                                 | *int*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `succeeded_requests`                                                 | *int*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `failed_requests`                                                    | *int*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `object`                                                             | [Optional[models.BatchJobOutObject]](../models/batchjoboutobject.md) | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `metadata`                                                           | Dict[str, *Any*]                                                     | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `output_file`                                                        | *OptionalNullable[str]*                                              | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `error_file`                                                         | *OptionalNullable[str]*                                              | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `started_at`                                                         | *OptionalNullable[int]*                                              | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `completed_at`                                                       | *OptionalNullable[int]*                                              | :heavy_minus_sign:                                                   | N/A                                                                  |\n```\n\n----------------------------------------\n\nTITLE: Markdown Table Schema Definition for WandbIntegrationOut\nDESCRIPTION: Markdown table defining the fields, types, requirements and descriptions for WandbIntegrationOut configuration. Includes project name, integration type, display name, run name and URL fields.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/wandbintegrationout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                            | Type                                                                             | Required                                                                         | Description                                                                      |\n| -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- |\n| `project`                                                                        | *str*                                                                            | :heavy_check_mark:                                                               | The name of the project that the new run will be created under.                  |\n| `type`                                                                           | [Optional[models.WandbIntegrationOutType]](../models/wandbintegrationouttype.md) | :heavy_minus_sign:                                                               | N/A                                                                              |\n| `name`                                                                           | *OptionalNullable[str]*                                                          | :heavy_minus_sign:                                                               | A display name to set for the run. If not set, will use the job ID as the name.  |\n| `run_name`                                                                       | *OptionalNullable[str]*                                                          | :heavy_minus_sign:                                                               | N/A                                                                              |\n| `url`                                                                            | *OptionalNullable[str]*                                                          | :heavy_minus_sign:                                                               | N/A                                                                              |\n```\n\n----------------------------------------\n\nTITLE: Retry Configuration for Single API Call\nDESCRIPTION: Example of configuring retry strategy for a single API call using RetryConfig and BackoffStrategy.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nfrom mistralazure.utils import BackoffStrategy, RetryConfig\nimport os\n\ns = MistralAzure(\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.stream(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"azureai\",\n    RetryConfig(\"backoff\", BackoffStrategy(1, 50, 1.1, 100), False))\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Defining a ToolMessage in MistralAI Python Client\nDESCRIPTION: Demonstrates how to define a ToolMessage object for use in an instruction request. ToolMessages represent responses from external tools or functions that have been called during a conversation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequestinputsmessages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: OCRResponse Fields Definition Table\nDESCRIPTION: Markdown table defining the fields, types, requirements and descriptions for the OCRResponse model. Includes three main fields: pages (list of OCR page objects), model (string identifier), and usage_info (OCR usage statistics).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ocrresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                    | Type                                                     | Required                                                 | Description                                              |\n| -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- |\n| `pages`                                                  | List[[models.OCRPageObject](../models/ocrpageobject.md)] | :heavy_check_mark:                                       | List of OCR info for pages.                              |\n| `model`                                                  | *str*                                                    | :heavy_check_mark:                                       | The model used to generate the OCR.                      |\n| `usage_info`                                             | [models.OCRUsageInfo](../models/ocrusageinfo.md)         | :heavy_check_mark:                                       | N/A                                                      |\n```\n\n----------------------------------------\n\nTITLE: Creating Fine Tuning Job with MistralAI Python Client\nDESCRIPTION: Example of how to create a new fine-tuning job using the MistralAI Python client. The code shows setting up the client and creating a job with a specified model and hyperparameters.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/jobs/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.fine_tuning.jobs.create(model=\"Fiesta\", hyperparameters={\n        \"learning_rate\": 0.0001,\n    })\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Defining ClassificationResponse Fields in Markdown\nDESCRIPTION: This markdown table defines the structure of a ClassificationResponse object, specifying field names, types, requirements, descriptions, and examples.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classificationresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                         | Type                                                                                          | Required                                                                                      | Description                                                                                   | Example                                                                                       |\n| --------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- |\n| `id`                                                                                          | *str*                                                                                         | :heavy_check_mark:                                                                            | N/A                                                                                           | mod-e5cc70bb28c444948073e77776eb30ef                                                          |\n| `model`                                                                                       | *str*                                                                                         | :heavy_check_mark:                                                                            | N/A                                                                                           |                                                                                               |\n| `results`                                                                                     | List[Dict[str, [models.ClassificationTargetResult](../models/classificationtargetresult.md)]] | :heavy_check_mark:                                                                            | N/A                                                                                           |                                                                                               |\n```\n\n----------------------------------------\n\nTITLE: Defining Number of Completions Parameter for API Requests\nDESCRIPTION: This snippet defines the `n` parameter, which is an optional integer specifying the number of completions to return for each request. The implementation notes that input tokens are billed only once per request, emphasizing efficiency in token usage.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n| `n`                                                                                                                                                                                                                                                                                                                                                                                                   | *OptionalNullable[int]*                                                                                                                                                                                                                                                                                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | Number of completions to return for each request, input tokens are only billed once.                                                                                                                                                                                                                                                                                                                  |\n```\n\n----------------------------------------\n\nTITLE: Configuring Retries for Single API Call\nDESCRIPTION: Example showing how to configure retries for a single API call using RetryConfig. The code demonstrates setting a custom backoff strategy for the models.list() method.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nfrom mistralai.utils import BackoffStrategy, RetryConfig\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.list(,\n        RetryConfig(\"backoff\", BackoffStrategy(1, 50, 1.1, 100), False))\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Defining ClassificationRequest Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ClassificationRequest model, including their types, requirements, and descriptions. It specifies two required fields: 'model' and 'inputs'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classificationrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                          | Type                                                                           | Required                                                                       | Description                                                                    |\n| ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------ |\n| `model`                                                                        | *str*                                                                          | :heavy_check_mark:                                                             | ID of the model to use.                                                        |\n| `inputs`                                                                       | [models.ClassificationRequestInputs](../models/classificationrequestinputs.md) | :heavy_check_mark:                                                             | Text to classify.                                                              |\n```\n\n----------------------------------------\n\nTITLE: Defining Fine-Tuning Parameters in Markdown\nDESCRIPTION: This markdown table defines the parameters used for fine-tuning models with the Mistral AI Python client. It includes the parameter names, types, requirements, and descriptions for model, hyperparameters, training files, validation files, and suffix.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/jobs/README.md#2025-04-17_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| Parameter | Type | Required | Description |\n| --------- | ---- | -------- | ----------- |\n| `model` | *str* | :heavy_check_mark: | The name of the model to fine-tune. |\n| `hyperparameters` | [models.Hyperparameters](../../models/hyperparameters.md) | :heavy_check_mark: | N/A |\n| `training_files` | List[[models.TrainingFile](../../models/trainingfile.md)] | :heavy_minus_sign: | N/A |\n| `validation_files` | List[*str*] | :heavy_minus_sign: | A list containing the IDs of uploaded files that contain validation data. If you provide these files, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in `checkpoints` when getting the status of a running fine-tuning job. The same data should not be present in both train and validation files. |\n| `suffix` | *OptionalNullable[str]* | :heavy_minus_sign: | A string that will be added to your fine-tuning model name. For example, a suffix of \"my-great-model\" would produce a model name like `ft:open-mistral-7b:my-great-model:xxx...` |\n```\n\n----------------------------------------\n\nTITLE: Formatting Chat Completion Request in Markdown\nDESCRIPTION: This markdown table defines the fields for a chat completion API request. It includes details on the model, messages, and temperature parameters, specifying their types, requirements, descriptions, and examples.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description | Example |\n| ----- | ---- | -------- | ----------- | ------- |\n| `model` | *str* | :heavy_check_mark: | ID of the model to use. You can use the [List Available Models](/api/#tag/models/operation/list_models_v1_models_get) API to see all of your available models, or see our [Model overview](/models) for model descriptions. | mistral-small-latest |\n| `messages` | List[[models.ChatCompletionRequestMessages](../models/chatcompletionrequestmessages.md)] | :heavy_check_mark: | The prompt(s) to generate completions for, encoded as a list of dict with role and content. | [<br/>{<br/>\"role\": \"user\",<br/>\"content\": \"Who is the best French painter? Answer in one short sentence.\"<br/>}<br/>] |\n| `temperature` | *OptionalNullable[float]* | :heavy_minus_sign: | What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value. | |\n```\n\n----------------------------------------\n\nTITLE: Server-Sent Event Streaming Example\nDESCRIPTION: Example showing how to handle server-sent event streaming for chat completions\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP\nimport os\n\ns = MistralGCP()\n\n\nres = s.chat.stream(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"mistral-small-latest\")\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionRequest Class in Python for Mistral AI Client\nDESCRIPTION: This code snippet defines the ChatCompletionRequest class with various attributes for configuring a chat completion request. It uses Pydantic for data validation and includes parameters such as model, messages, temperature, max_tokens, and others.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel, Field\n\nfrom .chat_completion_message import ChatCompletionMessage\n\n\nclass ChatCompletionRequest(BaseModel):\n    model: str\n    messages: List[ChatCompletionMessage]\n    temperature: Optional[float] = Field(None, ge=0, le=1)\n    max_tokens: Optional[int] = None\n    top_p: Optional[float] = Field(None, ge=0, le=1)\n    stream: Optional[bool] = False\n    safe_prompt: Optional[bool] = False\n    random_seed: Optional[int] = None\n```\n\n----------------------------------------\n\nTITLE: RetrieveFileOut Model Fields Table\nDESCRIPTION: Markdown table documenting the fields, types, requirements, and descriptions for the RetrieveFileOut data model. Includes essential file properties and metadata fields.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/retrievefileout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                          | Type                                           | Required                                       | Description                                    | Example                                        |\n| ---------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- |\n| `id`                                           | *str*                                          | :heavy_check_mark:                             | The unique identifier of the file.             | 497f6eca-6276-4993-bfeb-53cbbbba6f09           |\n| `object`                                       | *str*                                          | :heavy_check_mark:                             | The object type, which is always \"file\".       | file                                           |\n| `size_bytes`                                   | *int*                                          | :heavy_check_mark:                             | The size of the file, in bytes.                | 13000                                          |\n| `created_at`                                   | *int*                                          | :heavy_check_mark:                             | The UNIX timestamp (in seconds) of the event.  | 1716963433                                     |\n| `filename`                                     | *str*                                          | :heavy_check_mark:                             | The name of the uploaded file.                 | files_upload.jsonl                             |\n| `purpose`                                      | [models.FilePurpose](../models/filepurpose.md) | :heavy_check_mark:                             | N/A                                            |                                                |\n| `sample_type`                                  | [models.SampleType](../models/sampletype.md)   | :heavy_check_mark:                             | N/A                                            |                                                |\n| `source`                                       | [models.Source](../models/source.md)           | :heavy_check_mark:                             | N/A                                            |                                                |\n| `deleted`                                      | *bool*                                         | :heavy_check_mark:                             | N/A                                            |                                                |\n| `num_lines`                                    | *OptionalNullable[int]*                        | :heavy_minus_sign:                             | N/A                                            |                                                |\n```\n\n----------------------------------------\n\nTITLE: Updating a Fine-Tuned Model with Mistral Python Client\nDESCRIPTION: This snippet shows how to update a model's name or description using the Mistral Python client. It initializes the client with an API key and calls the update method on the models object, passing a model ID as a parameter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/models/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.update(model_id=\"ft:open-mistral-7b:587a6b29:20240514:7e773925\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Field Definitions Table in Markdown\nDESCRIPTION: A markdown table defining the structure of the UploadFileOut model, including field names, types, requirements, descriptions and examples.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/uploadfileout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                          | Type                                           | Required                                       | Description                                    | Example                                        |\n| ---------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- |\n| `id`                                           | *str*                                          | :heavy_check_mark:                             | The unique identifier of the file.             | 497f6eca-6276-4993-bfeb-53cbbbba6f09           |\n| `object`                                       | *str*                                          | :heavy_check_mark:                             | The object type, which is always \"file\".       | file                                           |\n| `size_bytes`                                   | *int*                                          | :heavy_check_mark:                             | The size of the file, in bytes.                | 13000                                          |\n| `created_at`                                   | *int*                                          | :heavy_check_mark:                             | The UNIX timestamp (in seconds) of the event.  | 1716963433                                     |\n| `filename`                                     | *str*                                          | :heavy_check_mark:                             | The name of the uploaded file.                 | files_upload.jsonl                             |\n| `purpose`                                      | [models.FilePurpose](../models/filepurpose.md) | :heavy_check_mark:                             | N/A                                            |                                                |\n| `sample_type`                                  | [models.SampleType](../models/sampletype.md)   | :heavy_check_mark:                             | N/A                                            |                                                |\n| `source`                                       | [models.Source](../models/source.md)           | :heavy_check_mark:                             | N/A                                            |                                                |\n| `num_lines`                                    | *OptionalNullable[int]*                        | :heavy_minus_sign:                             | N/A                                            |                                                |\n```\n\n----------------------------------------\n\nTITLE: DeltaMessage Fields Definition Table - Markdown\nDESCRIPTION: Markdown table defining the fields, types, requirements and descriptions for the DeltaMessage model structure.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/deltamessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                    | Type                                                     | Required                                                 | Description                                              |\n| -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- |\n| `role`                                                   | *OptionalNullable[str]*                                  | :heavy_minus_sign:                                       | N/A                                                      |\n| `content`                                                | [OptionalNullable[models.Content]](../models/content.md) | :heavy_minus_sign:                                       | N/A                                                      |\n| `tool_calls`                                             | List[[models.ToolCall](../models/toolcall.md)]           | :heavy_minus_sign:                                       | N/A                                                      |\n```\n\n----------------------------------------\n\nTITLE: Retry Configuration Example\nDESCRIPTION: Examples showing how to configure retry strategies for API calls both per-operation and globally\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP\nfrom mistralgcp.utils import BackoffStrategy, RetryConfig\nimport os\n\ns = MistralGCP()\n\n\nres = s.chat.stream(\n    messages=[\n        {\n            \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n            \"role\": \"user\",\n        },\n    ], \n    model=\"mistral-small-latest\",\n    retries=RetryConfig(\n        \"backoff\",\n        BackoffStrategy(1, 50, 1.1, 100),\n        False\n    )\n)\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: TextChunk Field Specifications Table\nDESCRIPTION: Markdown table defining the fields, types, requirements and descriptions for the TextChunk model. Contains two fields: text (required string) and type (optional Type model).\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/textchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                      | Type                                       | Required                                   | Description                                |\n| ------------------------------------------ | ------------------------------------------ | ------------------------------------------ | ------------------------------------------ |\n| `text`                                     | *str*                                      | :heavy_check_mark:                         | N/A                                        |\n| `type`                                     | [Optional[models.Type]](../models/type.md) | :heavy_minus_sign:                         | N/A                                        |\n```\n\n----------------------------------------\n\nTITLE: Defining Fine-Tuning Job Parameters in Markdown\nDESCRIPTION: This markdown table outlines various parameters for configuring a fine-tuning job, including their types and descriptions. It covers integrations, auto-start settings, invalid sample handling, job type, repositories, classifier targets, and retry configuration.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/jobs/README.md#2025-04-17_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n| `integrations`                                                                                                                                                                                                                                                                                                                                                    | List[[models.JobInIntegrations](../../models/jobinintegrations.md)]                                                                                                                                                                                                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | A list of integrations to enable for your fine-tuning job.                                                                                                                                                                                                                                                                                                        |\n| `auto_start`                                                                                                                                                                                                                                                                                                                                                      | *Optional[bool]*                                                                                                                                                                                                                                                                                                                                                  | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | This field will be required in a future release.                                                                                                                                                                                                                                                                                                                  |\n| `invalid_sample_skip_percentage`                                                                                                                                                                                                                                                                                                                                  | *Optional[float]*                                                                                                                                                                                                                                                                                                                                                 | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | N/A                                                                                                                                                                                                                                                                                                                                                               |\n| `job_type`                                                                                                                                                                                                                                                                                                                                                        | [OptionalNullable[models.FineTuneableModelType]](../../models/finetuneablemodeltype.md)                                                                                                                                                                                                                                                                           | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | N/A                                                                                                                                                                                                                                                                                                                                                               |\n| `repositories`                                                                                                                                                                                                                                                                                                                                                    | List[[models.JobInRepositories](../../models/jobinrepositories.md)]                                                                                                                                                                                                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | N/A                                                                                                                                                                                                                                                                                                                                                               |\n| `classifier_targets`                                                                                                                                                                                                                                                                                                                                              | List[[models.ClassifierTargetIn](../../models/classifiertargetin.md)]                                                                                                                                                                                                                                                                                             | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | N/A                                                                                                                                                                                                                                                                                                                                                               |\n| `retries`                                                                                                                                                                                                                                                                                                                                                         | [Optional[utils.RetryConfig]](../../models/utils/retryconfig.md)                                                                                                                                                                                                                                                                                                  | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | Configuration to override the default retry behavior of the client.                                                                                                                                                                                                                                                                                               |\n```\n\n----------------------------------------\n\nTITLE: Declaring AssistantMessage Type in Python\nDESCRIPTION: Example of declaring an AssistantMessage type variable for Mistral AI client\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/messages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining EmbeddingRequest Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the EmbeddingRequest class, including 'model' and 'inputs'. It specifies their types, whether they are required, and provides descriptions and examples.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/embeddingrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                | Type                                                                 | Required                                                             | Description                                                          | Example                                                              |\n| -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| `model`                                                              | *str*                                                                | :heavy_check_mark:                                                   | ID of the model to use.                                              | mistral-embed                                                        |\n| `inputs`                                                             | [models.EmbeddingRequestInputs](../models/embeddingrequestinputs.md) | :heavy_check_mark:                                                   | Text to embed.                                                       | [<br/>\"Embed this sentence.\",<br/>\"As well as this one.\"<br/>]       |\n```\n\n----------------------------------------\n\nTITLE: Using ContentChunk List in Mistral AI Python Client\nDESCRIPTION: Example of using a list of ContentChunk objects as content in the Mistral AI Python client. This format allows for structured content with additional metadata.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/content.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: JobsOut Model Fields Definition Table\nDESCRIPTION: Markdown table defining the fields, types, requirements and descriptions for the JobsOut model structure.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                        | Type                                                         | Required                                                     | Description                                                  |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| `total`                                                      | *int*                                                        | :heavy_check_mark:                                           | N/A                                                          |\n| `data`                                                       | List[[models.JobsOutData](../models/jobsoutdata.md)]         | :heavy_minus_sign:                                           | N/A                                                          |\n| `object`                                                     | [Optional[models.JobsOutObject]](../models/jobsoutobject.md) | :heavy_minus_sign:                                           | N/A                                                          |\n```\n\n----------------------------------------\n\nTITLE: Non-Streaming FIM Completion with Python Mistral AI Client\nDESCRIPTION: This snippet shows how to perform a non-streaming FIM completion using the Mistral AI client. It sets up the client, specifies the completion parameters, and handles the response.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/sdks/fim/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP\nimport os\n\ns = MistralGCP()\n\n\nres = s.fim.complete(prompt=\"def\", model=\"codestral-2405\", suffix=\"return a+b\")\n\nif res is not None:\n    # handle response\n    pass\n```\n\n----------------------------------------\n\nTITLE: Defining FTModelCard Fields in Markdown\nDESCRIPTION: This code snippet defines the fields of the FTModelCard class using a markdown table. It includes field names, types, whether they are required, and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ftmodelcard.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                | Type                                                                 | Required                                                             | Description                                                          |\n| -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| `id`                                                                 | *str*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `capabilities`                                                       | [models.ModelCapabilities](../models/modelcapabilities.md)           | :heavy_check_mark:                                                   | N/A                                                                  |\n| `job`                                                                | *str*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `root`                                                               | *str*                                                                | :heavy_check_mark:                                                   | N/A                                                                  |\n| `object`                                                             | *Optional[str]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `created`                                                            | *Optional[int]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `owned_by`                                                           | *Optional[str]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `name`                                                               | *OptionalNullable[str]*                                              | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `description`                                                        | *OptionalNullable[str]*                                              | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `max_context_length`                                                 | *Optional[int]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `aliases`                                                            | List[*str*]                                                          | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `deprecation`                                                        | [date](https://docs.python.org/3/library/datetime.html#date-objects) | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `default_model_temperature`                                          | *OptionalNullable[float]*                                            | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `type`                                                               | [Optional[models.FTModelCardType]](../models/ftmodelcardtype.md)     | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `archived`                                                           | *Optional[bool]*                                                     | :heavy_minus_sign:                                                   | N/A                                                                  |\n```\n\n----------------------------------------\n\nTITLE: FunctionCall Fields Documentation in Markdown\nDESCRIPTION: Markdown table documenting the required fields for the FunctionCall class. It specifies two required fields: 'name' as a string type and 'arguments' as a custom Arguments model type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/functioncall.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                      | Type                                       | Required                                   | Description                                |\n| ------------------------------------------ | ------------------------------------------ | ------------------------------------------ | ------------------------------------------ |\n| `name`                                     | *str*                                      | :heavy_check_mark:                         | N/A                                        |\n| `arguments`                                | [models.Arguments](../models/arguments.md) | :heavy_check_mark:                         | N/A                                        |\n```\n\n----------------------------------------\n\nTITLE: Global Retry Configuration\nDESCRIPTION: Example of setting a global retry strategy for all operations that support retries.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nfrom mistralazure.utils import BackoffStrategy, RetryConfig\nimport os\n\ns = MistralAzure(\n    retry_config=RetryConfig(\"backoff\", BackoffStrategy(1, 50, 1.1, 100), False),\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.stream(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"azureai\")\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Azure AI Integration Example\nDESCRIPTION: Example showing how to use Mistral with Azure AI integration\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport os\n\nfrom mistralai_azure import MistralAzure\n\nclient = MistralAzure(\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\nasync def main() -> None:\n    res = await client.chat.complete_async( \n        max_tokens= 100,\n        temperature= 0.5,\n        messages= [\n            {\n                \"content\": \"Hello there!\",\n                \"role\": \"user\"\n            }\n        ]\n    )\n    print(res)\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Setting Mistral API Key as environment variable\nDESCRIPTION: This bash command adds the Mistral API Key to the zsh environment file. Replace [your_key_here] with your actual API key.\nSOURCE: https://github.com/mistralai/client-python/blob/main/OLD-README.md#2025-04-17_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\necho 'export MISTRAL_API_KEY=[your_key_here]' >> ~/.zshenv\n```\n\n----------------------------------------\n\nTITLE: Declaring UserMessage Type in Python\nDESCRIPTION: Example of declaring a UserMessage type variable for Mistral AI client\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/messages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: SystemMessage Fields Documentation Table\nDESCRIPTION: Markdown table documenting the fields of the SystemMessage class, including their types, requirements, and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/systemmessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                            | Type                                                             | Required                                                         | Description                                                      |\n| ---------------------------------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------- |\n| `content`                                                        | [models.SystemMessageContent](../models/systemmessagecontent.md) | :heavy_check_mark:                                               | N/A                                                              |\n| `role`                                                           | [Optional[models.Role]](../models/role.md)                       | :heavy_minus_sign:                                               | N/A                                                              |\n```\n\n----------------------------------------\n\nTITLE: Streaming FIM Completion with Mistral AI Python Client\nDESCRIPTION: This code snippet demonstrates how to use the streaming functionality of the FIM completion API. It initializes the Mistral client, sends a request with a prompt and suffix, and processes the streamed response events.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/fim/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.fim.stream(model=\"codestral-2405\", prompt=\"def\", suffix=\"return a+b\")\n\n    with res as event_stream:\n        for event in event_stream:\n            # handle event\n            print(event, flush=True)\n\n```\n\n----------------------------------------\n\nTITLE: Markdown table defining WandB integration fields\nDESCRIPTION: Structured documentation of configuration fields for WandB integration, including project name, API key, integration type, display name, and run name parameters. Each field is defined with its type, requirement status, and description.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/wandbintegration.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                           | Type                                                                            | Required                                                                        | Description                                                                     |\n| ------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |\n| `project`                                                                       | *str*                                                                           | :heavy_check_mark:                                                              | The name of the project that the new run will be created under.                 |\n| `api_key`                                                                       | *str*                                                                           | :heavy_check_mark:                                                              | The WandB API key to use for authentication.                                    |\n| `type`                                                                          | [Optional[models.WandbIntegrationType]](../models/wandbintegrationtype.md)      | :heavy_minus_sign:                                                              | N/A                                                                             |\n| `name`                                                                          | *OptionalNullable[str]*                                                         | :heavy_minus_sign:                                                              | A display name to set for the run. If not set, will use the job ID as the name. |\n| `run_name`                                                                      | *OptionalNullable[str]*                                                         | :heavy_minus_sign:                                                              | N/A                                                                             |\n```\n\n----------------------------------------\n\nTITLE: User Message Structure Schema\nDESCRIPTION: Markdown table defining the fields, types, and requirements for the UserMessage model. Contains two main fields: content (required) of type UserMessageContent and role (optional) of type UserMessageRole.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/usermessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `content`                                                              | [Nullable[models.UserMessageContent]](../models/usermessagecontent.md) | :heavy_check_mark:                                                     | N/A                                                                    |\n| `role`                                                                 | [Optional[models.UserMessageRole]](../models/usermessagerole.md)       | :heavy_minus_sign:                                                     | N/A                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Installing Mistral SDK with Package Managers\nDESCRIPTION: Commands for installing the Mistral SDK using either pip or poetry package managers\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install mistralai\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry add mistralai\n```\n\n----------------------------------------\n\nTITLE: Defining ResponseFormat Fields in Markdown\nDESCRIPTION: This snippet outlines the fields of the ResponseFormat class in a markdown table. It specifies the field names, their types, whether they are required, and provides descriptions for each field.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/responseformat.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                                                                                                                                                                                                                              | Type                                                                                                                                                                                                                                                                                               | Required                                                                                                                                                                                                                                                                                           | Description                                                                                                                                                                                                                                                                                        |\n| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `type`                                                                                                                                                                                                                                                                                             | [Optional[models.ResponseFormats]](../models/responseformats.md)                                                                                                                                                                                                                                   | :heavy_minus_sign:                                                                                                                                                                                                                                                                                 | An object specifying the format that the model must output. Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is in JSON. When using JSON mode you MUST also instruct the model to produce JSON yourself with a system or a user message. |\n| `json_schema`                                                                                                                                                                                                                                                                                      | [OptionalNullable[models.JSONSchema]](../models/jsonschema.md)                                                                                                                                                                                                                                     | :heavy_minus_sign:                                                                                                                                                                                                                                                                                 | N/A                                                                                                                                                                                                                                                                                                |\n```\n\n----------------------------------------\n\nTITLE: Defining AssistantMessage Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the AssistantMessage class. It includes the field names, their types, whether they are required, and descriptions for each field.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/assistantmessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                                                                                                                                  | Type                                                                                                                                                                                                   | Required                                                                                                                                                                                               | Description                                                                                                                                                                                            |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| `content`                                                                                                                                                                                              | [OptionalNullable[models.AssistantMessageContent]](../models/assistantmessagecontent.md)                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                     | N/A                                                                                                                                                                                                    |\n| `tool_calls`                                                                                                                                                                                           | List[[models.ToolCall](../models/toolcall.md)]                                                                                                                                                         | :heavy_minus_sign:                                                                                                                                                                                     | N/A                                                                                                                                                                                                    |\n| `prefix`                                                                                                                                                                                               | *Optional[bool]*                                                                                                                                                                                       | :heavy_minus_sign:                                                                                                                                                                                     | Set this to `true` when adding an assistant message as prefix to condition the model response. The role of the prefix message is to force the model to start its answer by the content of the message. |\n| `role`                                                                                                                                                                                                 | [Optional[models.AssistantMessageRole]](../models/assistantmessagerole.md)                                                                                                                             | :heavy_minus_sign:                                                                                                                                                                                     | N/A                                                                                                                                                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Defining Single String Input for Classification in Python\nDESCRIPTION: This snippet demonstrates how to define a single string input for text classification using the ClassificationRequestInputs type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classificationrequestinputs.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining retries Parameter in Python Client\nDESCRIPTION: Defines the 'retries' parameter as an optional configuration object that allows users to customize the retry behavior of the client when faced with transient errors. This parameter can help make the client more resilient in the face of network or service issues.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/fim/README.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n| `retries`                                                                                                                                                                                                                                                                                                                                                                                             | [Optional[utils.RetryConfig]](../../models/utils/retryconfig.md)                                                                                                                                                                                                                                                                                                                                      | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | Configuration to override the default retry behavior of the client.                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                       |\n```\n\n----------------------------------------\n\nTITLE: Using UserMessage in Mistral AI Python Client\nDESCRIPTION: Example of using the UserMessage type from the models module in Mistral AI Python client. This message type represents user inputs in a conversation with the assistant.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequestmessages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining AssistantMessage Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the AssistantMessage model, including their types, whether they are required, and descriptions. It covers content, tool_calls, prefix, and role fields.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/assistantmessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                                                                                                                                  | Type                                                                                                                                                                                                   | Required                                                                                                                                                                                               | Description                                                                                                                                                                                            |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| `content`                                                                                                                                                                                              | [OptionalNullable[models.AssistantMessageContent]](../models/assistantmessagecontent.md)                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                     | N/A                                                                                                                                                                                                    |\n| `tool_calls`                                                                                                                                                                                           | List[[models.ToolCall](../models/toolcall.md)]                                                                                                                                                         | :heavy_minus_sign:                                                                                                                                                                                     | N/A                                                                                                                                                                                                    |\n| `prefix`                                                                                                                                                                                               | *Optional[bool]*                                                                                                                                                                                       | :heavy_minus_sign:                                                                                                                                                                                     | Set this to `true` when adding an assistant message as prefix to condition the model response. The role of the prefix message is to force the model to start its answer by the content of the message. |\n| `role`                                                                                                                                                                                                 | [Optional[models.AssistantMessageRole]](../models/assistantmessagerole.md)                                                                                                                             | :heavy_minus_sign:                                                                                                                                                                                     | N/A                                                                                                                                                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Defining Fine-Tuning Job Details Schema in Markdown\nDESCRIPTION: This snippet outlines the structure of fine-tuning job details, including repositories, events, and checkpoints. It specifies the data types, models, and descriptions for each component.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completiondetailedjobout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| `repositories`                                                                                                                     | List[[models.CompletionDetailedJobOutRepositories](../models/completiondetailedjoboutrepositories.md)]                             | :heavy_minus_sign:                                                                                                                 | N/A                                                                                                                                |\n| `events`                                                                                                                           | List[[models.EventOut](../models/eventout.md)]                                                                                     | :heavy_minus_sign:                                                                                                                 | Event items are created every time the status of a fine-tuning job changes. The timestamped list of all events is accessible here. |\n| `checkpoints`                                                                                                                      | List[[models.CheckpointOut](../models/checkpointout.md)]                                                                           | :heavy_minus_sign:                                                                                                                 | N/A                                                                                                                                |\n```\n\n----------------------------------------\n\nTITLE: Tool Selection Strategy in Chat Completion\nDESCRIPTION: Optional parameter to define how tools are selected and used during the AI response generation process. Provides fine-grained control over tool utilization.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequest.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntool_choice: Optional[models.ChatCompletionRequestToolChoice] = None\n```\n\n----------------------------------------\n\nTITLE: Defining ResponseFormat Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ResponseFormat class, including their types, requirements, and descriptions. It covers the 'type' field for specifying output format and the 'json_schema' field.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/responseformat.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                                                                                                                                                                                                                              | Type                                                                                                                                                                                                                                                                                               | Required                                                                                                                                                                                                                                                                                           | Description                                                                                                                                                                                                                                                                                        |\n| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `type`                                                                                                                                                                                                                                                                                             | [Optional[models.ResponseFormats]](../models/responseformats.md)                                                                                                                                                                                                                                   | :heavy_minus_sign:                                                                                                                                                                                                                                                                                 | An object specifying the format that the model must output. Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is in JSON. When using JSON mode you MUST also instruct the model to produce JSON yourself with a system or a user message. |\n| `json_schema`                                                                                                                                                                                                                                                                                      | [OptionalNullable[models.JSONSchema]](../models/jsonschema.md)                                                                                                                                                                                                                                     | :heavy_minus_sign:                                                                                                                                                                                                                                                                                 | N/A                                                                                                                                                                                                                                                                                                |\n```\n\n----------------------------------------\n\nTITLE: Defining ImageURL Fields in Markdown Table\nDESCRIPTION: A markdown table describing the fields of the ImageURL class. It specifies the field names, types, whether they are required, and provides space for descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/imageurl.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                   | Type                    | Required                | Description             |\n| ----------------------- | ----------------------- | ----------------------- | ----------------------- |\n| `url`                   | *str*                   | :heavy_check_mark:      | N/A                     |\n| `detail`                | *OptionalNullable[str]* | :heavy_minus_sign:      | N/A                     |\n```\n\n----------------------------------------\n\nTITLE: Message Formatting Example in JSON for Mistral AI API\nDESCRIPTION: Example of how to format the messages parameter as a JSON array containing a user role and content. This shows the structure required when making a chat completion request to the Mistral AI API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n[\n{\n\"role\": \"user\",\n\"content\": \"Who is the best French painter? Answer in one short sentence.\"\n}\n]\n```\n\n----------------------------------------\n\nTITLE: User Message Example in Mistral AI Chat API (Markdown)\nDESCRIPTION: Example of a properly formatted user message in JSON format for the Mistral AI chat completion API. This demonstrates how to structure the 'messages' parameter with a role and content.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/sdks/chat/README.md#2025-04-17_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n\"role\": \"user\",\n\"content\": \"Who is the best French painter? Answer in one short sentence.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Markdown Table of Mistral API Parameters\nDESCRIPTION: Table documenting API parameters for chat completion requests, including response_format, tools, tool_choice, presence_penalty and frequency_penalty with their types and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| `response_format` | [Optional[models.ResponseFormat]](../models/responseformat.md) | :heavy_minus_sign: | N/A | |\n| `tools` | List[[models.Tool](../models/tool.md)] | :heavy_minus_sign: | N/A | |\n| `tool_choice` | [Optional[models.ChatCompletionRequestToolChoice]](../models/chatcompletionrequesttoolchoice.md) | :heavy_minus_sign: | N/A | |\n| `presence_penalty` | *Optional[float]* | :heavy_minus_sign: | presence_penalty determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative. | |\n| `frequency_penalty` | *Optional[float]* | :heavy_minus_sign: | frequency_penalty penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition. | |\n```\n\n----------------------------------------\n\nTITLE: User Message Type Declaration\nDESCRIPTION: Declaration of the UserMessage type used for messages from the human user in the conversation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequestmessages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining API Request Fields in Markdown Table\nDESCRIPTION: A markdown table that defines the fields used in API requests for the Mistral AI Python client. It includes the field names, types, requirements, descriptions, and examples for 'model', 'prompt', and 'temperature' parameters.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/fimcompletionrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description | Example |\n| ----- | ---- | -------- | ----------- | ------- |\n| `model` | *str* | :heavy_check_mark: | ID of the model to use. Only compatible for now with:<br/>  - `codestral-2405`<br/>  - `codestral-latest` | codestral-2405 |\n| `prompt` | *str* | :heavy_check_mark: | The text/code to complete. | def |\n| `temperature` | *OptionalNullable[float]* | :heavy_minus_sign: | What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value. | |\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionChoice Model Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ChatCompletionChoice model, including their types, requirements, and examples. It specifies three fields: index, message, and finish_reason.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                    | Type                                                     | Required                                                 | Description                                              | Example                                                  |\n| -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- |\n| `index`                                                  | *int*                                                    | :heavy_check_mark:                                       | N/A                                                      | 0                                                        |\n| `message`                                                | [models.AssistantMessage](../models/assistantmessage.md) | :heavy_check_mark:                                       | N/A                                                      |                                                          |\n| `finish_reason`                                          | [models.FinishReason](../models/finishreason.md)         | :heavy_check_mark:                                       | N/A                                                      | stop                                                     |\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat with MistralAI Client (Old Implementation)\nDESCRIPTION: Example of the old MistralClient implementation for streaming chat completions. The code sets up the client and iterates through response chunks to print content as it arrives.\nSOURCE: https://github.com/mistralai/client-python/blob/main/MIGRATION.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai.client import MistralClient\nfrom mistralai.models.chat_completion import ChatMessage\n\napi_key = os.environ[\"MISTRAL_API_KEY\"]\nmodel = \"mistral-large-latest\"\n\nclient = MistralClient(api_key=api_key)\n\nmessages = [\n    ChatMessage(role=\"user\", content=\"What is the best French cheese?\")\n]\n\n# With streaming\nstream_response = client.chat_stream(model=model, messages=messages)\n\nfor chunk in stream_response:\n    print(chunk.choices[0].delta.content)\n```\n\n----------------------------------------\n\nTITLE: Defining Fine-Tuning Job Details Schema in Markdown\nDESCRIPTION: This markdown table defines the schema for fine-tuning job details, including field names, types, requirements, descriptions, and examples. It covers various aspects of a fine-tuning job such as duration, cost, and token usage.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/legacyjobmetadataout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## Fields\n\n| Field                                                                                                                                                                                                                           | Type                                                                                                                                                                                                                            | Required                                                                                                                                                                                                                        | Description                                                                                                                                                                                                                     | Example                                                                                                                                                                                                                         |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `details`                                                                                                                                                                                                                       | *str*                                                                                                                                                                                                                           | :heavy_check_mark:                                                                                                                                                                                                              | N/A                                                                                                                                                                                                                             |                                                                                                                                                                                                                                 |\n| `expected_duration_seconds`                                                                                                                                                                                                     | *OptionalNullable[int]*                                                                                                                                                                                                         | :heavy_minus_sign:                                                                                                                                                                                                              | The approximated time (in seconds) for the fine-tuning process to complete.                                                                                                                                                     | 220                                                                                                                                                                                                                             |\n| `cost`                                                                                                                                                                                                                          | *OptionalNullable[float]*                                                                                                                                                                                                       | :heavy_minus_sign:                                                                                                                                                                                                              | The cost of the fine-tuning job.                                                                                                                                                                                                | 10                                                                                                                                                                                                                              |\n| `cost_currency`                                                                                                                                                                                                                 | *OptionalNullable[str]*                                                                                                                                                                                                         | :heavy_minus_sign:                                                                                                                                                                                                              | The currency used for the fine-tuning job cost.                                                                                                                                                                                 | EUR                                                                                                                                                                                                                             |\n| `train_tokens_per_step`                                                                                                                                                                                                         | *OptionalNullable[int]*                                                                                                                                                                                                         | :heavy_minus_sign:                                                                                                                                                                                                              | The number of tokens consumed by one training step.                                                                                                                                                                             | 131072                                                                                                                                                                                                                          |\n| `train_tokens`                                                                                                                                                                                                                  | *OptionalNullable[int]*                                                                                                                                                                                                         | :heavy_minus_sign:                                                                                                                                                                                                              | The total number of tokens used during the fine-tuning process.                                                                                                                                                                 | 1310720                                                                                                                                                                                                                         |\n```\n\n----------------------------------------\n\nTITLE: Fine-Tuning Job Request Parameters Table in Markdown\nDESCRIPTION: Markdown table documenting the available request parameters for fine-tuning job queries, including field names, types, requirements, and descriptions. Parameters include pagination controls, model filtering, date ranges, and various other filtering options.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuninggetfinetuningjobsrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                              | Type                                                                                               | Required                                                                                           | Description                                                                                        |\n| -------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |\n| `page`                                                                                             | *Optional[int]*                                                                                    | :heavy_minus_sign:                                                                                 | The page number of the results to be returned.                                                     |\n| `page_size`                                                                                        | *Optional[int]*                                                                                    | :heavy_minus_sign:                                                                                 | The number of items to return per page.                                                            |\n| `model`                                                                                            | *OptionalNullable[str]*                                                                            | :heavy_minus_sign:                                                                                 | The model name used for fine-tuning to filter on. When set, the other results are not displayed.   |\n| `created_after`                                                                                    | [date](https://docs.python.org/3/library/datetime.html#date-objects)                               | :heavy_minus_sign:                                                                                 | The date/time to filter on. When set, the results for previous creation times are not displayed.   |\n| `created_before`                                                                                   | [date](https://docs.python.org/3/library/datetime.html#date-objects)                               | :heavy_minus_sign:                                                                                 | N/A                                                                                                |\n| `created_by_me`                                                                                    | *Optional[bool]*                                                                                   | :heavy_minus_sign:                                                                                 | When set, only return results for jobs created by the API caller. Other results are not displayed. |\n| `status`                                                                                           | [OptionalNullable[models.QueryParamStatus]](../models/queryparamstatus.md)                         | :heavy_minus_sign:                                                                                 | The current job state to filter on. When set, the other results are not displayed.                 |\n| `wandb_project`                                                                                    | *OptionalNullable[str]*                                                                            | :heavy_minus_sign:                                                                                 | The Weights and Biases project to filter on. When set, the other results are not displayed.        |\n| `wandb_name`                                                                                       | *OptionalNullable[str]*                                                                            | :heavy_minus_sign:                                                                                 | The Weight and Biases run name to filter on. When set, the other results are not displayed.        |\n| `suffix`                                                                                           | *OptionalNullable[str]*                                                                            | :heavy_minus_sign:                                                                                 | The model suffix to filter on. When set, the other results are not displayed.                      |\n```\n\n----------------------------------------\n\nTITLE: Managing Presence Penalty for Text Diversity\nDESCRIPTION: Controls the model's tendency to introduce new words and phrases. Higher values encourage more diverse and creative text generation by penalizing repeated word usage.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequest.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npresence_penalty: Optional[float] = None\n```\n\n----------------------------------------\n\nTITLE: Defining ReferenceChunk Model Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ReferenceChunk model. It specifies the field names, their types, whether they are required, and provides a description for each field.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/referencechunk.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `reference_ids`                                                        | List[*int*]                                                            | :heavy_check_mark:                                                     | N/A                                                                    |\n| `type`                                                                 | [Optional[models.ReferenceChunkType]](../models/referencechunktype.md) | :heavy_minus_sign:                                                     | N/A                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Configuring Response Format in Mistral AI Client\nDESCRIPTION: Optional parameter to specify the desired response format for chat completions. Allows customization of output structure and content type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequest.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nresponse_format: Optional[models.ResponseFormat] = None\n```\n\n----------------------------------------\n\nTITLE: Defining API Parameters in Markdown Table\nDESCRIPTION: This markdown table defines various optional parameters for the MistralAI Python client API. It includes details on response format, tools, tool choice, presence penalty, and frequency penalty. Each row describes a parameter, its type, optionality, and purpose.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequest.md#2025-04-17_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| `response_format` | [Optional[models.ResponseFormat]](../models/responseformat.md) | :heavy_minus_sign: | N/A |\n| `tools` | List[[models.Tool](../models/tool.md)] | :heavy_minus_sign: | N/A |\n| `tool_choice` | [Optional[models.ChatCompletionRequestToolChoice]](../models/chatcompletionrequesttoolchoice.md) | :heavy_minus_sign: | N/A |\n| `presence_penalty` | *Optional[float]* | :heavy_minus_sign: | presence_penalty determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative. |\n| `frequency_penalty` | *Optional[float]* | :heavy_minus_sign: | frequency_penalty penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition. |\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionChunk Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the CompletionChunk class, including their types, whether they are required, and brief descriptions. It covers essential properties like id, model, choices, as well as optional fields like object, created, and usage.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/completionchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                      | Type                                                                                       | Required                                                                                   | Description                                                                                |\n| ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ |\n| `id`                                                                                       | *str*                                                                                      | :heavy_check_mark:                                                                         | N/A                                                                                        |\n| `model`                                                                                    | *str*                                                                                      | :heavy_check_mark:                                                                         | N/A                                                                                        |\n| `choices`                                                                                  | List[[models.CompletionResponseStreamChoice](../models/completionresponsestreamchoice.md)] | :heavy_check_mark:                                                                         | N/A                                                                                        |\n| `object`                                                                                   | *Optional[str]*                                                                            | :heavy_minus_sign:                                                                         | N/A                                                                                        |\n| `created`                                                                                  | *Optional[int]*                                                                            | :heavy_minus_sign:                                                                         | N/A                                                                                        |\n| `usage`                                                                                    | [Optional[models.UsageInfo]](../models/usageinfo.md)                                       | :heavy_minus_sign:                                                                         | N/A                                                                                        |\n```\n\n----------------------------------------\n\nTITLE: Defining Parallel Tool Calls Parameter for API Requests\nDESCRIPTION: This snippet defines the `parallel_tool_calls` parameter, an optional boolean that may control whether API requests allow for parallel execution of tool calls. The context of its usage is not fully specified, indicating it may be conditional based on specific use cases.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n| `parallel_tool_calls`                                                                                                                                                                                                                                                                                                                                                                                 | *Optional[bool]*                                                                                                                                                                                                                                                                                                                                                                                      | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | N/A                                                                                                                                                                                                                                                                                                                                                                                                   |\n```\n\n----------------------------------------\n\nTITLE: Defining UsageInfo Fields in Markdown Table\nDESCRIPTION: This snippet outlines the fields of the UsageInfo structure using a markdown table. It specifies three integer fields: prompt_tokens, completion_tokens, and total_tokens, all of which are required.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/usageinfo.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field               | Type                | Required            | Description         | Example             |\n| ------------------- | ------------------- | ------------------- | ------------------- | ------------------- |\n| `prompt_tokens`     | *int*               | :heavy_check_mark:  | N/A                 | 16                  |\n| `completion_tokens` | *int*               | :heavy_check_mark:  | N/A                 | 34                  |\n| `total_tokens`      | *int*               | :heavy_check_mark:  | N/A                 | 50                  |\n```\n\n----------------------------------------\n\nTITLE: FileSignedURL Class Definition in Markdown Table\nDESCRIPTION: A markdown table defining the FileSignedURL class with its field 'url' of string type that is required. The table shows the field name, type, requirement status, and description column (which is empty).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/filesignedurl.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `url`              | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining Chat Completion Request Messages in Markdown\nDESCRIPTION: This snippet demonstrates the structure of the 'messages' field in a chat completion request. It shows how to format a user message as a list containing a dictionary with 'role' and 'content' keys.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[\\n{\\n\"role\": \"user\",\\n\"content\": \"Who is the best French painter? Answer in one short sentence.\"\\n}\\n]\n```\n\n----------------------------------------\n\nTITLE: FunctionCall Fields Table in Markdown\nDESCRIPTION: Table documentation showing the required fields for the FunctionCall model, including their types and requirements. The model consists of a name field of type string and an arguments field of type Arguments model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/functioncall.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                      | Type                                       | Required                                   | Description                                |\n| ------------------------------------------ | ------------------------------------------ | ------------------------------------------ | ------------------------------------------ |\n| `name`                                     | *str*                                      | :heavy_check_mark:                         | N/A                                        |\n| `arguments`                                | [models.Arguments](../models/arguments.md) | :heavy_check_mark:                         | N/A                                        |\n```\n\n----------------------------------------\n\nTITLE: Server Selection by Name\nDESCRIPTION: Example showing how to override the default server by specifying a named server configuration.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nimport os\n\ns = MistralAzure(\n    server=\"prod\",\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.stream(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"azureai\")\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Defining UserMessageContent as List of ContentChunk Objects in Python\nDESCRIPTION: This snippet demonstrates how to define UserMessageContent as a List of ContentChunk objects from the models module. The actual list of ContentChunk objects would be assigned to the 'value' variable.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/usermessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: JSONSchema Fields Table Definition\nDESCRIPTION: Markdown table defining the required fields and their types for JSONSchema implementation. Includes name (string), schema_definition (dictionary), optional description (nullable string), and optional strict boolean flag.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/jsonschema.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                   | Type                    | Required                | Description             |\n| ----------------------- | ----------------------- | ----------------------- | ----------------------- |\n| `name`                  | *str*                   | :heavy_check_mark:      | N/A                     |\n| `schema_definition`     | Dict[str, *Any*]        | :heavy_check_mark:      | N/A                     |\n| `description`           | *OptionalNullable[str]* | :heavy_minus_sign:      | N/A                     |\n| `strict`                | *Optional[bool]*        | :heavy_minus_sign:      | N/A                     |\n```\n\n----------------------------------------\n\nTITLE: Response Format Fields Documentation Table\nDESCRIPTION: Markdown table documenting the fields of the ResponseFormat class including their types, requirements and descriptions. Focuses on the type and json_schema fields where type can be used to enable JSON mode output.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/responseformat.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description |\n| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `type` | [Optional[models.ResponseFormats]](../models/responseformats.md) | :heavy_minus_sign: | An object specifying the format that the model must output. Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is in JSON. When using JSON mode you MUST also instruct the model to produce JSON yourself with a system or a user message. |\n| `json_schema` | [OptionalNullable[models.JSONSchema]](../models/jsonschema.md) | :heavy_minus_sign: | N/A |\n```\n\n----------------------------------------\n\nTITLE: Initializing AssistantMessage in Mistral AI Python Client\nDESCRIPTION: Creates an instance of AssistantMessage from the models module. This type is used to represent messages generated by the AI assistant.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/messages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: FinishReason Enum Value Definitions in Markdown\nDESCRIPTION: A markdown table listing all possible FinishReason values used by the Mistral AI Python client. These values indicate why a model generation stopped, such as reaching a stop token, length limit, model context limit, encountering an error, or completing tool calls.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/finishreason.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name           | Value          |\n| -------------- | -------------- |\n| `STOP`         | stop           |\n| `LENGTH`       | length         |\n| `MODEL_LENGTH` | model_length   |\n| `ERROR`        | error          |\n| `TOOL_CALLS`   | tool_calls     |\n```\n\n----------------------------------------\n\nTITLE: Defining OCRUsageInfo Class Fields in Markdown\nDESCRIPTION: Defines the fields of the OCRUsageInfo class using a markdown table. It specifies two fields: pages_processed (an integer) and doc_size_bytes (an optional nullable integer).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ocrusageinfo.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                     | Type                      | Required                  | Description               |\n| ------------------------- | ------------------------- | ------------------------- | ------------------------- |\n| `pages_processed`         | *int*                     | :heavy_check_mark:        | Number of pages processed |\n| `doc_size_bytes`          | *OptionalNullable[int]*   | :heavy_minus_sign:        | Document size in bytes    |\n```\n\n----------------------------------------\n\nTITLE: Defining suffix Parameter in Python Client\nDESCRIPTION: Defines the 'suffix' parameter as an optional string that adds context to the model's prompt completion. When both 'prompt' and 'suffix' are provided, the model generates output between them; otherwise, it only uses the 'prompt'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/fim/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n| `suffix`                                                                                                                                                                                                                                                                                                                                                                                              | *OptionalNullable[str]*                                                                                                                                                                                                                                                                                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | Optional text/code that adds more context for the model. When given a `prompt` and a `suffix` the model will fill what is between them. When `suffix` is not provided, the model will simply execute completion starting with `prompt`.                                                                                                                                                               | return a+b                                                                                                                                                                                                                                                                                                                                                                                            |\n```\n\n----------------------------------------\n\nTITLE: SystemMessage Field Definitions in Markdown\nDESCRIPTION: Defines the structure of the SystemMessage class with two fields: content (required) and role (optional). The content field uses SystemMessageContent type while role uses an optional Role type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/systemmessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                            | Type                                                             | Required                                                         | Description                                                      |\n| ---------------------------------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------- |\n| `content`                                                        | [models.SystemMessageContent](../models/systemmessagecontent.md) | :heavy_check_mark:                                               | N/A                                                              |\n| `role`                                                           | [Optional[models.Role]](../models/role.md)                       | :heavy_minus_sign:                                               | N/A                                                              |\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionRequestStop with List of Strings in Python\nDESCRIPTION: This snippet demonstrates how to define a ChatCompletionRequestStop object using a list of strings. Generation will stop if any of the tokens in the list are detected during the process.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequeststop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionChoice Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ChatCompletionChoice model. It includes the field names, their types, whether they are required, and example values where applicable.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                    | Type                                                                                     | Required                                                                                 | Description                                                                              | Example                                                                                  |\n| ---------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- |\n| `index`                                                                                  | *int*                                                                                    | :heavy_check_mark:                                                                       | N/A                                                                                      | 0                                                                                        |\n| `message`                                                                                | [models.AssistantMessage](../models/assistantmessage.md)                                 | :heavy_check_mark:                                                                       | N/A                                                                                      |                                                                                          |\n| `finish_reason`                                                                          | [models.ChatCompletionChoiceFinishReason](../models/chatcompletionchoicefinishreason.md) | :heavy_check_mark:                                                                       | N/A                                                                                      | stop                                                                                     |\n```\n\n----------------------------------------\n\nTITLE: BackoffStrategy Fields Documentation in Markdown\nDESCRIPTION: Markdown table specifying the configuration options for exponential backoff strategy, including intervals, exponent, and maximum elapsed time.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/utils/retryconfig.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Name               | Type      | Description                               | Example  |\n| ------------------ | --------- | ----------------------------------------- | -------- |\n| `initial_interval` | `*int*`   | The initial interval in milliseconds.     | `500`    |\n| `max_interval`     | `*int*`   | The maximum interval in milliseconds.     | `60000`  |\n| `exponent`         | `*float*` | The exponent to use for the backoff.      | `1.5`    |\n| `max_elapsed_time` | `*int*`   | The maximum elapsed time in milliseconds. | `300000` |\n```\n\n----------------------------------------\n\nTITLE: Initializing List of ContentChunk for AssistantMessageContent in Python\nDESCRIPTION: This code shows how to initialize a list of ContentChunk objects for AssistantMessageContent. The actual ContentChunk objects should be provided in place of the comment.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/assistantmessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: ToolChoice Fields Definition Table\nDESCRIPTION: Markdown table defining the fields of the ToolChoice type, including the function field which is required and references FunctionName model, and an optional type field that references ToolTypes model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/toolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                        | Type                                                                         | Required                                                                     | Description                                                                  |\n| ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |\n| `function`                                                                   | [models.FunctionName](../models/functionname.md)                             | :heavy_check_mark:                                                           | this restriction of `Function` is used to select a specific function to call |\n| `type`                                                                       | [Optional[models.ToolTypes]](../models/tooltypes.md)                         | :heavy_minus_sign:                                                           | N/A                                                                          |\n```\n\n----------------------------------------\n\nTITLE: Defining MetricOut Fields Schema\nDESCRIPTION: Markdown table defining the field structure for MetricOut class. Specifies three optional float fields: train_loss, valid_loss, and valid_mean_token_accuracy, used to track model training metrics.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/metricout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                       | Type                        | Required                    | Description                 |\n| --------------------------- | --------------------------- | --------------------------- | --------------------------- |\n| `train_loss`                | *OptionalNullable[float]*   | :heavy_minus_sign:          | N/A                         |\n| `valid_loss`                | *OptionalNullable[float]*   | :heavy_minus_sign:          | N/A                         |\n| `valid_mean_token_accuracy` | *OptionalNullable[float]*   | :heavy_minus_sign:          | N/A                         |\n```\n\n----------------------------------------\n\nTITLE: Defining multiple stop tokens with List[str] in AgentsCompletionRequestStop\nDESCRIPTION: Shows how to define multiple stop tokens using a list of strings for AgentsCompletionRequestStop. When any of these tokens are detected in the generated text, the generation process will stop.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionrequeststop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining AssistantMessage Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the AssistantMessage model using a markdown table. It includes field names, types, requirement status, and descriptions for content, tool_calls, prefix, and role.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/assistantmessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                                                                                                                                  | Type                                                                                                                                                                                                   | Required                                                                                                                                                                                               | Description                                                                                                                                                                                            |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| `content`                                                                                                                                                                                              | [OptionalNullable[models.AssistantMessageContent]](../models/assistantmessagecontent.md)                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                     | N/A                                                                                                                                                                                                    |\n| `tool_calls`                                                                                                                                                                                           | List[[models.ToolCall](../models/toolcall.md)]                                                                                                                                                         | :heavy_minus_sign:                                                                                                                                                                                     | N/A                                                                                                                                                                                                    |\n| `prefix`                                                                                                                                                                                               | *Optional[bool]*                                                                                                                                                                                       | :heavy_minus_sign:                                                                                                                                                                                     | Set this to `true` when adding an assistant message as prefix to condition the model response. The role of the prefix message is to force the model to start its answer by the content of the message. |\n| `role`                                                                                                                                                                                                 | [Optional[models.AssistantMessageRole]](../models/assistantmessagerole.md)                                                                                                                             | :heavy_minus_sign:                                                                                                                                                                                     | N/A                                                                                                                                                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Setting Multiple Token Stops in FIMCompletionStreamRequest\nDESCRIPTION: Shows how to provide multiple stop tokens as a list of strings. Generation will terminate if any of these tokens are detected in the output stream.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/fimcompletionstreamrequeststop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Server Selection by Name\nDESCRIPTION: Example showing how to select a specific server by name when initializing the SDK client. The code demonstrates using the 'eu' server option.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    server=\"eu\",\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.list()\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: ToolChoiceEnum Values Table in Markdown\nDESCRIPTION: A markdown table defining the four possible values for the ToolChoiceEnum: AUTO, NONE, ANY, and REQUIRED. Each entry maps an enum name to its corresponding string value.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/toolchoiceenum.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name       | Value      |\n| ---------- | ---------- |\n| `AUTO`     | auto       |\n| `NONE`     | none       |\n| `ANY`      | any        |\n| `REQUIRED` | required   |\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies using poetry\nDESCRIPTION: This command uses poetry to set up a virtual environment and install all project dependencies specified in the pyproject.toml file.\nSOURCE: https://github.com/mistralai/client-python/blob/main/OLD-README.md#2025-04-17_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Content Chunk List Type Definition - Python\nDESCRIPTION: Defines a list of ContentChunk models that can be used as tool message content. Uses the models module to specify the ContentChunk type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/toolmessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Batch Jobs Request Parameters Table\nDESCRIPTION: Markdown table defining the request parameters for batch jobs API including their types, requirements and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesbatchgetbatchjobsrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                | Type                                                                 | Required                                                             | Description                                                          |\n| -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| `page`                                                               | *Optional[int]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `page_size`                                                          | *Optional[int]*                                                      | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `model`                                                              | *OptionalNullable[str]*                                              | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `metadata`                                                           | Dict[str, *Any*]                                                     | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `created_after`                                                      | [date](https://docs.python.org/3/library/datetime.html#date-objects) | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `created_by_me`                                                      | *Optional[bool]*                                                     | :heavy_minus_sign:                                                   | N/A                                                                  |\n| `status`                                                             | List[[models.BatchJobStatus](../models/batchjobstatus.md)]           | :heavy_minus_sign:                                                   | N/A                                                                  |\n```\n\n----------------------------------------\n\nTITLE: Defining List of ContentChunk Type for AssistantMessageContent in Python\nDESCRIPTION: Defines a list of ContentChunk objects as a supported type for AssistantMessageContent. This allows for more complex, structured content to be used in messages.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/assistantmessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing SystemMessage in Mistral AI Python Client\nDESCRIPTION: Creates an instance of SystemMessage from the models module. This type is typically used for system-level messages or instructions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/messages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: OCRImageObject Field Definitions - Markdown Table\nDESCRIPTION: Table defining the fields, types, requirements and descriptions for the OCRImageObject class. Includes coordinates for image positioning, image ID and optional base64 image data.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ocrimageobject.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                      | Type                                                       | Required                                                   | Description                                                |\n| ---------------------------------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------- |\n| `id`                                                       | *str*                                                      | :heavy_check_mark:                                         | Image ID for extracted image in a page                     |\n| `top_left_x`                                               | *Nullable[int]*                                            | :heavy_check_mark:                                         | X coordinate of top-left corner of the extracted image     |\n| `top_left_y`                                               | *Nullable[int]*                                            | :heavy_check_mark:                                         | Y coordinate of top-left corner of the extracted image     |\n| `bottom_right_x`                                           | *Nullable[int]*                                            | :heavy_check_mark:                                         | X coordinate of bottom-right corner of the extracted image |\n| `bottom_right_y`                                           | *Nullable[int]*                                            | :heavy_check_mark:                                         | Y coordinate of bottom-right corner of the extracted image |\n| `image_base64`                                             | *OptionalNullable[str]*                                    | :heavy_minus_sign:                                         | Base64 string of the extracted image                       |\n```\n\n----------------------------------------\n\nTITLE: Defining FinishReason Enum Values\nDESCRIPTION: Enumeration of standard finish reasons for AI model interactions, indicating why a model response has terminated\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/finishreason.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nSTOP = \"stop\"\nLENGTH = \"length\"\nERROR = \"error\"\nTOOL_CALLS = \"tool_calls\"\n```\n\n----------------------------------------\n\nTITLE: Defining FIMCompletionStreamRequestStop with Single String in Python\nDESCRIPTION: Demonstrates how to define a FIMCompletionStreamRequestStop using a single string value. This will stop the generation if the specified token is detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/fimcompletionstreamrequeststop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: ValidationError Fields Structure\nDESCRIPTION: Markdown table defining the required fields for the ValidationError class. Includes loc (list of location objects), msg (string message), and type (string type identifier).\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/validationerror.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                | Type                                 | Required                             | Description                          |\n| ------------------------------------ | ------------------------------------ | ------------------------------------ | ------------------------------------ |\n| `loc`                                | List[[models.Loc](../models/loc.md)] | :heavy_check_mark:                   | N/A                                  |\n| `msg`                                | *str*                                | :heavy_check_mark:                   | N/A                                  |\n| `type`                               | *str*                                | :heavy_check_mark:                   | N/A                                  |\n```\n\n----------------------------------------\n\nTITLE: FunctionName Field Definition in Markdown\nDESCRIPTION: Defines the required 'name' field of type string that specifies which function should be called. This is a mandatory parameter marked with a heavy checkmark.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/functionname.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `name`             | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionResponseStreamChoice Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the CompletionResponseStreamChoice structure. It includes the field names, their types, whether they are required, and provides space for descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/completionresponsestreamchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                      | Type                                                       | Required                                                   | Description                                                |\n| ---------------------------------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------- |\n| `index`                                                    | *int*                                                      | :heavy_check_mark:                                         | N/A                                                        |\n| `delta`                                                    | [models.DeltaMessage](../models/deltamessage.md)           | :heavy_check_mark:                                         | N/A                                                        |\n| `finish_reason`                                            | [Nullable[models.FinishReason]](../models/finishreason.md) | :heavy_check_mark:                                         | N/A                                                        |\n```\n\n----------------------------------------\n\nTITLE: Response Format Values Table\nDESCRIPTION: Defines the available format types that can be specified for model outputs, including TEXT, JSON_OBJECT, and JSON_SCHEMA values.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/responseformats.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name          | Value         |\n| ------------- | ------------- |\n| `TEXT`        | text          |\n| `JSON_OBJECT` | json_object   |\n| `JSON_SCHEMA` | json_schema   |\n```\n\n----------------------------------------\n\nTITLE: Defining String Type for UserMessageContent in Python\nDESCRIPTION: This snippet shows how to define a string value for UserMessageContent. It uses type hinting to specify that the 'value' variable is of type 'str'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/usermessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Constant Values for MistralAI Python Client\nDESCRIPTION: This code snippet defines constant values used throughout the MistralAI Python client. It includes values for fine-tuning (FINE_TUNE), batch processing (BATCH), and optical character recognition (OCR).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/filepurpose.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nFINE_TUNE = 'fine-tune'\nBATCH = 'batch'\nOCR = 'ocr'\n```\n\n----------------------------------------\n\nTITLE: UnarchiveFTModelOut Fields Table in Markdown\nDESCRIPTION: A markdown table defining the structure of UnarchiveFTModelOut, including field names, types, requirements, and descriptions. The structure contains an ID field, an object field referencing UnarchiveFTModelOutObject, and an archived boolean flag.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/unarchiveftmodelout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field     | Type                                     | Required           | Description |\n| --------- | ---------------------------------------- | ------------------ | ----------- |\n| `id`      | *str*                                    | :heavy_check_mark: | N/A         |\n| `object`  | [Optional[models.UnarchiveFTModelOutObject]] | :heavy_minus_sign: | N/A         |\n| `archived`| *Optional[bool]*                         | :heavy_minus_sign: | N/A         |\n```\n\n----------------------------------------\n\nTITLE: Initializing FIMCompletionRequestStop with List of Strings in Python\nDESCRIPTION: This snippet demonstrates initializing FIMCompletionRequestStop with a list of strings. The generation will stop if any of the provided tokens are detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/fimcompletionrequeststop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining DeltaMessage Fields in Markdown\nDESCRIPTION: This markdown table outlines the fields of the DeltaMessage class, including their types, whether they're required, and a placeholder for descriptions. It covers 'role', 'content', and 'tool_calls' fields.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/deltamessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                    | Type                                                     | Required                                                 | Description                                              |\n| -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- |\n| `role`                                                   | *OptionalNullable[str]*                                  | :heavy_minus_sign:                                       | N/A                                                      |\n| `content`                                                | [OptionalNullable[models.Content]](../models/content.md) | :heavy_minus_sign:                                       | N/A                                                      |\n| `tool_calls`                                             | List[[models.ToolCall](../models/toolcall.md)]           | :heavy_minus_sign:                                       | N/A                                                      |\n```\n\n----------------------------------------\n\nTITLE: Defining Single Stop Token in Python\nDESCRIPTION: This snippet shows how to define a single stop token as a string for the ChatCompletionStreamRequestStop class.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequeststop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Installing Mistral GCP Dependencies\nDESCRIPTION: Command to install the Mistral AI Python client with GCP-specific dependencies\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install mistralai[gcp]\n```\n\n----------------------------------------\n\nTITLE: ToolMessage Model Fields Definition - Markdown\nDESCRIPTION: Table defining the fields of the ToolMessage model, including their types, requirements, and descriptions. The model consists of content (required), tool_call_id (optional), name (optional), and role (optional) fields.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/toolmessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `content`                                                              | [Nullable[models.ToolMessageContent]](../models/toolmessagecontent.md) | :heavy_check_mark:                                                     | N/A                                                                    |\n| `tool_call_id`                                                         | *OptionalNullable[str]*                                                | :heavy_minus_sign:                                                     | N/A                                                                    |\n| `name`                                                                 | *OptionalNullable[str]*                                                | :heavy_minus_sign:                                                     | N/A                                                                    |\n| `role`                                                                 | [Optional[models.ToolMessageRole]](../models/toolmessagerole.md)       | :heavy_minus_sign:                                                     | N/A                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Initializing AssistantMessage in Python for Mistral AI Chat Completion\nDESCRIPTION: Creates an instance of AssistantMessage for use in chat completion requests. The specific values for initialization are not provided in the snippet.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequestmessages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: String Value Type in SystemMessageContent\nDESCRIPTION: Demonstrates the string value type definition for SystemMessageContent. Uses Python's type hinting to specify a string value.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/systemmessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining SystemMessage Type in Python\nDESCRIPTION: Type definition for SystemMessage class which represents system-level messages or instructions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/two.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing UserMessage in Mistral AI Python Client\nDESCRIPTION: Example of creating a UserMessage object in the Mistral AI Python client. UserMessage represents input or queries provided by the user to the AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/messages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Stop Tokens in Python for MistralAI Client\nDESCRIPTION: Shows how to configure multiple stop tokens using a list of strings. Text generation will stop if any of the specified tokens in the list are detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/stop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Multiple Stop Tokens Configuration in Python\nDESCRIPTION: Defines a list of string stop tokens configuration for FIM completion requests. The value parameter expects an array of strings, where detection of any token in the list will trigger the completion to stop.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/fimcompletionrequeststop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Tool Class Fields in Markdown\nDESCRIPTION: This markdown table defines the structure of the Tool class. It specifies two fields: 'function' of type models.Function which is required, and 'type' of type Optional[models.ToolTypes] which is optional.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/tool.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                | Type                                                 | Required                                             | Description                                          |\n| ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- |\n| `function`                                           | [models.Function](../models/function.md)             | :heavy_check_mark:                                   | N/A                                                  |\n| `type`                                               | [Optional[models.ToolTypes]](../models/tooltypes.md) | :heavy_minus_sign:                                   | N/A                                                  |\n```\n\n----------------------------------------\n\nTITLE: Defining Single String Stop Token in Python\nDESCRIPTION: Implementation of a single string stop token for stream completion requests. Uses a string value to define when the generation should stop.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequeststop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ModerationObject Fields in Markdown\nDESCRIPTION: This snippet defines the fields of a ModerationObject using a markdown table. It specifies two fields: 'categories' and 'category_scores', along with their types, requirements, and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/moderationobject.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                        | Type                         | Required                     | Description                  |\n| ---------------------------- | ---------------------------- | ---------------------------- | ---------------------------- |\n| `categories`                 | Dict[str, *bool*]            | :heavy_minus_sign:           | Moderation result thresholds |\n| `category_scores`            | Dict[str, *float*]           | :heavy_minus_sign:           | Moderation result            |\n```\n\n----------------------------------------\n\nTITLE: Initializing SystemMessage in Python for Mistral AI Chat Completion\nDESCRIPTION: Creates an instance of SystemMessage for use in chat completion requests. The specific values for initialization are not provided in the snippet.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequestmessages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionRequestStop as List of Strings in Python\nDESCRIPTION: Specifies multiple tokens as a list of strings to stop generation if any are detected. The value is of type List[str].\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequeststop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Security Fields Table in Markdown\nDESCRIPTION: Markdown table documenting the security fields available in the client, specifically the optional api_key field of type string.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/security.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `api_key`          | *Optional[str]*    | :heavy_minus_sign: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining Tool Message Type - Python\nDESCRIPTION: Example of declaring a ToolMessage type variable for agent completions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionrequestmessages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Example Messages Format for Mistral AI Agent Request in Markdown\nDESCRIPTION: Example showing the format for the messages field in a Mistral AI agent completion request. The messages parameter takes a list of dictionaries with role and content fields.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n[<br/>{<br/>\"role\": \"user\",<br/>\"content\": \"Who is the best French painter? Answer in one short sentence.\"<br/>}<br/>]\n```\n\n----------------------------------------\n\nTITLE: Defining a UserMessage in MistralAI Python Client\nDESCRIPTION: Demonstrates how to define a UserMessage object for use in an instruction request. UserMessages represent inputs from the user in a conversation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequestinputsmessages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionEvent Structure in Markdown\nDESCRIPTION: This markdown table defines the structure of a CompletionEvent, specifying its single field 'data', its type, requirement status, and description. The 'data' field is of type CompletionChunk and is marked as required.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/completionevent.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                  | Type                                                   | Required                                               | Description                                            |\n| ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ |\n| `data`                                                 | [models.CompletionChunk](../models/completionchunk.md) | :heavy_check_mark:                                     | N/A                                                    |\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionRequestStop with Single String in Python\nDESCRIPTION: This snippet shows how to define a ChatCompletionRequestStop object using a single string value. The stop token is specified as a string, and generation will halt if this token is detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequeststop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Getting Batch Job Details with Mistral AI Python Client\nDESCRIPTION: This snippet demonstrates how to retrieve details of a specific batch job using its UUID with the Mistral AI Python client. It uses the get() method of the batch.jobs module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/mistraljobs/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.batch.jobs.get(job_id=\"b888f774-3e7c-4135-a18c-6b985523c4bc\")\n\n    # Handle response\n    print(res)\n\n```\n\n----------------------------------------\n\nTITLE: Defining Optional Parameters for Mistral AI Python Client API\nDESCRIPTION: This markdown table defines optional parameters for the Mistral AI Python client API, including their types and descriptions. It covers response_format, tools, tool_choice, presence_penalty, and frequency_penalty.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/chat/README.md#2025-04-17_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n| `response_format`                                                                                                                                                                                                                                                                                                                                                                                     | [Optional[models.ResponseFormat]](../../models/responseformat.md)                                                                                                                                                                                                                                                                                                                                     | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | N/A                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                       |\n| `tools`                                                                                                                                                                                                                                                                                                                                                                                               | List[[models.Tool](../../models/tool.md)]                                                                                                                                                                                                                                                                                                                                                             | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | N/A                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                       |\n| `tool_choice`                                                                                                                                                                                                                                                                                                                                                                                         | [Optional[models.ChatCompletionRequestToolChoice]](../../models/chatcompletionrequesttoolchoice.md)                                                                                                                                                                                                                                                                                                   | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | N/A                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                       |\n| `presence_penalty`                                                                                                                                                                                                                                                                                                                                                                                    | *Optional[float]*                                                                                                                                                                                                                                                                                                                                                                                     | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | presence_penalty determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative.                                                                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                       |\n| `frequency_penalty`                                                                                                                                                                                                                                                                                                                                                                                   | *Optional[float]*                                                                                                                                                                                                                                                                                                                                                                                     | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | frequency_penalty penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition.                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                       |\n```\n\n----------------------------------------\n\nTITLE: Initializing ToolMessage in Python\nDESCRIPTION: Shows the type hint for creating a ToolMessage instance in the models module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequestmessages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Core MistralAI Client Constants\nDESCRIPTION: Defines three core constant values used in the MistralAI Python client: UPLOAD for upload operations, REPOSITORY for repository references, and MISTRAL for the main service identifier.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/source.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name         | Value        |\n| ------------ | ------------ |\n| `UPLOAD`     | upload       |\n| `REPOSITORY` | repository   |\n| `MISTRAL`    | mistral      |\n```\n\n----------------------------------------\n\nTITLE: Mistral AI Client Parameters Table\nDESCRIPTION: A markdown table defining the available parameters for Mistral AI client configuration, including validation files, object types, fine-tuning settings, and integration options. Each parameter includes its type and description.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completionjobout.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| `validation_files` | List[*str*] | :heavy_minus_sign: | A list containing the IDs of uploaded files that contain validation data. |\n| `object` | [Optional[models.Object]](../models/object.md) | :heavy_minus_sign: | The object type of the fine-tuning job. |\n| `fine_tuned_model` | *OptionalNullable[str]* | :heavy_minus_sign: | The name of the fine-tuned model that is being created. The value will be `null` if the fine-tuning job is still running. |\n| `suffix` | *OptionalNullable[str]* | :heavy_minus_sign: | Optional text/code that adds more context for the model. When given a `prompt` and a `suffix` the model will fill what is between them. When `suffix` is not provided, the model will simply execute completion starting with `prompt`. |\n| `integrations` | List[[models.Integrations](../models/integrations.md)] | :heavy_minus_sign: | A list of integrations enabled for your fine-tuning job. |\n| `trained_tokens` | *OptionalNullable[int]* | :heavy_minus_sign: | Total number of tokens trained. |\n| `metadata` | [OptionalNullable[models.JobMetadataOut]](../models/jobmetadataout.md) | :heavy_minus_sign: | N/A |\n| `job_type` | [Optional[models.JobType]](../models/jobtype.md) | :heavy_minus_sign: | The type of job (`FT` for fine-tuning). |\n| `repositories` | List[[models.Repositories](../models/repositories.md)] | :heavy_minus_sign: | N/A |\n```\n\n----------------------------------------\n\nTITLE: Initializing SystemMessage in Mistral AI Python Client\nDESCRIPTION: Example of creating a SystemMessage object in the Mistral AI Python client. SystemMessage typically represents instructions or context provided to the AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/messages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using SystemMessage in Mistral AI Python Client\nDESCRIPTION: Example of using the SystemMessage type from the models module in Mistral AI Python client. This message type typically contains instructions or context information for the model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequestmessages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining a SystemMessage in MistralAI Python Client\nDESCRIPTION: Demonstrates how to define a SystemMessage object for use in an instruction request. SystemMessages provide overall instructions or context that guide the model's behavior.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequestinputsmessages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Prediction Object Fields in Markdown Table\nDESCRIPTION: This markdown table defines the structure of a Prediction object. It specifies two fields: 'type' and 'content', both of which are optional. The 'type' field is constrained to the literal value 'content'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/prediction.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                          | Type                           | Required                       | Description                    |\n| ------------------------------ | ------------------------------ | ------------------------------ | ------------------------------ |\n| `type`                         | *Optional[Literal[\"content\"]]* | :heavy_minus_sign:             | N/A                            |\n| `content`                      | *Optional[str]*                | :heavy_minus_sign:             | N/A                            |\n```\n\n----------------------------------------\n\nTITLE: Initializing ImageURLChunk in Mistral AI Python Client\nDESCRIPTION: This snippet demonstrates how to create an instance of the ImageURLChunk class from the models module. It's used to represent image content in the Mistral AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/contentchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ImageURLChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: FinishReason Enum Values Table in Markdown\nDESCRIPTION: Markdown table defining the enumeration values and their corresponding string representations for different completion states in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/finishreason.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name         | Value        |\n| ------------ | ------------ |\n| `STOP`       | stop         |\n| `LENGTH`     | length       |\n| `ERROR`      | error        |\n| `TOOL_CALLS` | tool_calls   |\n```\n\n----------------------------------------\n\nTITLE: Defining String User Message Content in Python\nDESCRIPTION: Demonstrates how to define user message content as a string value in Python. This is a simple way to represent textual content.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/usermessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Declaring Dict[str, Any] Argument in Python for Mistral AI Client\nDESCRIPTION: This snippet demonstrates how to declare a variable of type Dict[str, Any], which is a dictionary with string keys and values of any type. This is commonly used for flexible data structures in the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/arguments.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: Dict[str, Any] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining List of Strings Input for Embedding Requests in Python\nDESCRIPTION: Shows how to define a list of strings as input for an embedding request. This format is used when you need to embed multiple pieces of text at once.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/embeddingrequestinputs.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining models.ToolChoiceEnum in Python for ChatCompletionRequestToolChoice\nDESCRIPTION: This snippet shows the declaration of a value of type models.ToolChoiceEnum for use in ChatCompletionRequestToolChoice. The specific enum values are not included in the snippet.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequesttoolchoice.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoiceEnum = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Declaring List of TextChunk Objects for SystemMessageContent in Python\nDESCRIPTION: This snippet demonstrates how to declare a list of TextChunk objects for the SystemMessageContent class. It uses type hinting to specify that the 'value' variable is a List of models.TextChunk objects.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/systemmessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.TextChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing UserMessage Type in Python\nDESCRIPTION: Demonstrates the type annotation for a UserMessage object in the models module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequestmessages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Multiple Stop Tokens in Python\nDESCRIPTION: This snippet demonstrates how to define multiple stop tokens as a list of strings for the ChatCompletionStreamRequestStop class.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequeststop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing SystemMessage in Mistral AI Python Client\nDESCRIPTION: Creates an instance of the SystemMessage type. This message type might be used for system-level communications or instructions within the AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/one.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining min_tokens Parameter in Python Client\nDESCRIPTION: Defines the 'min_tokens' parameter as an optional integer specifying the minimum number of tokens the model should generate in its completion. This parameter helps ensure that the output meets a certain length requirement.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/fim/README.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n| `min_tokens`                                                                                                                                                                                                                                                                                                                                                                                          | *OptionalNullable[int]*                                                                                                                                                                                                                                                                                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | The minimum number of tokens to generate in the completion.                                                                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                       |\n```\n\n----------------------------------------\n\nTITLE: Using models.ToolChoiceEnum Type with AgentsCompletionStreamRequestToolChoice\nDESCRIPTION: Shows how to use the models.ToolChoiceEnum type with the AgentsCompletionStreamRequestToolChoice class. This enum type likely provides predefined options for tool choice configurations.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequesttoolchoice.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoiceEnum = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining List of ContentChunks for UserMessageContent in Python\nDESCRIPTION: This snippet demonstrates how to define a list of ContentChunk objects for UserMessageContent. It uses type hinting to specify that the 'value' variable is a List of models.ContentChunk objects.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/usermessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Declaring str Argument in Python for Mistral AI Client\nDESCRIPTION: This snippet shows the declaration of a variable of type str, which represents a string in Python. Strings are frequently used for text-based inputs and outputs in the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/arguments.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using ToolMessage in Mistral AI Python Client\nDESCRIPTION: Example of using the ToolMessage type from the models module in Mistral AI Python client. This message type is used for tool-related communications or function calls within the conversation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequestmessages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing ToolMessage in Mistral AI Python Client\nDESCRIPTION: Example of creating a ToolMessage object in the Mistral AI Python client. ToolMessage might represent messages related to specific tools or functionalities within the AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/messages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Content Chunk List Declaration\nDESCRIPTION: Defines how to declare a list of content chunks for assistant messages using the models.ContentChunk type\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/assistantmessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ToolMessage Type in Python\nDESCRIPTION: Type definition for ToolMessage class which represents messages from integrated tools or functions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/two.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Multiple Stop Tokens in Python\nDESCRIPTION: Implementation of multiple stop tokens using a list of strings. Allows defining multiple tokens that can trigger generation stop when any of them is detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequeststop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using AssistantMessage in Mistral AI Python Client\nDESCRIPTION: Example of using the AssistantMessage type from the models module in Mistral AI Python client. This message type represents responses from the assistant in a conversation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequestmessages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ImageURL Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ImageURL structure. It specifies the field names, their types, whether they are required, and provides space for descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/imageurl.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                   | Type                    | Required                | Description             |\n| ----------------------- | ----------------------- | ----------------------- | ----------------------- |\n| `url`                   | *str*                   | :heavy_check_mark:      | N/A                     |\n| `detail`                | *OptionalNullable[str]* | :heavy_minus_sign:      | N/A                     |\n```\n\n----------------------------------------\n\nTITLE: Defining FunctionCall Model Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the FunctionCall model. It specifies two required fields: 'name' of type string, and 'arguments' which is a reference to the Arguments model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/functioncall.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                      | Type                                       | Required                                   | Description                                |\n| ------------------------------------------ | ------------------------------------------ | ------------------------------------------ | ------------------------------------------ |\n| `name`                                     | *str*                                      | :heavy_check_mark:                         | N/A                                        |\n| `arguments`                                | [models.Arguments](../models/arguments.md) | :heavy_check_mark:                         | N/A                                        |\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionChoiceFinishReason Constants in Markdown Table\nDESCRIPTION: Markdown table defining the constant values for different chat completion finish reasons including STOP, LENGTH, MODEL_LENGTH, ERROR, and TOOL_CALLS.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionchoicefinishreason.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name           | Value          |\n| -------------- | -------------- |\n| `STOP`         | stop           |\n| `LENGTH`       | length         |\n| `MODEL_LENGTH` | model_length   |\n| `ERROR`        | error          |\n| `TOOL_CALLS`   | tool_calls     |\n```\n\n----------------------------------------\n\nTITLE: BatchJobsOut Model Fields Structure\nDESCRIPTION: Markdown table defining the fields, types, requirements and descriptions for the BatchJobsOut model. Contains three fields: total (required integer), data (optional list of BatchJobOut objects), and object (optional BatchJobsOutObject).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/batchjobsout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field     | Type      | Required  | Description |\n| --------- | --------- | --------- | ----------- |\n| `total`   | *int*     | :heavy_check_mark: | N/A |\n| `data`    | List[[models.BatchJobOut](../models/batchjobout.md)] | :heavy_minus_sign: | N/A |\n| `object`  | [Optional[models.BatchJobsOutObject]](../models/batchjobsoutobject.md) | :heavy_minus_sign: | N/A |\n```\n\n----------------------------------------\n\nTITLE: Defining ToolChoice Type for ChatCompletionStreamRequest in Python\nDESCRIPTION: This snippet demonstrates how to define a value of type models.ToolChoice for use in a ChatCompletionStreamRequest. The actual values to be used are not provided in the snippet.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequesttoolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoice = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing SystemMessage in Python\nDESCRIPTION: Shows the type hint for creating a SystemMessage instance in the models module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequestmessages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ToolMessage Fields in Markdown Table\nDESCRIPTION: This markdown table defines the fields of the ToolMessage class, including their types, requirements, and descriptions. It specifies four fields: content, tool_call_id, name, and role, each with different data types and requirement levels.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/toolmessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `content`                                                              | [Nullable[models.ToolMessageContent]](../models/toolmessagecontent.md) | :heavy_check_mark:                                                     | N/A                                                                    |\n| `tool_call_id`                                                         | *OptionalNullable[str]*                                                | :heavy_minus_sign:                                                     | N/A                                                                    |\n| `name`                                                                 | *OptionalNullable[str]*                                                | :heavy_minus_sign:                                                     | N/A                                                                    |\n| `role`                                                                 | [Optional[models.ToolMessageRole]](../models/toolmessagerole.md)       | :heavy_minus_sign:                                                     | N/A                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Defining FTClassifierLossFunction Enum in Python\nDESCRIPTION: Enumerates the loss function types for fine-tuned classifiers. It includes SINGLE_CLASS for binary classification tasks and MULTI_CLASS for multi-label classification tasks.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ftclassifierlossfunction.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# FTClassifierLossFunction\n\n\n## Values\n\n| Name           | Value          |\n| -------------- | -------------- |\n| `SINGLE_CLASS` | single_class   |\n| `MULTI_CLASS`  | multi_class    |\n```\n\n----------------------------------------\n\nTITLE: Initializing UserMessage in Mistral AI Python Client\nDESCRIPTION: Creates an instance of UserMessage from the models module. This type represents messages input by the user in the conversation with the AI.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/messages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionResponse Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the ChatCompletionResponse class using a markdown table. It includes field names, types, requirements, descriptions, and examples for each attribute of the response object.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            | Example                                                                |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `id`                                                                   | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | cmpl-e5cc70bb28c444948073e77776eb30ef                                  |\n| `object`                                                               | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | chat.completion                                                        |\n| `model`                                                                | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | mistral-small-latest                                                   |\n| `usage`                                                                | [models.UsageInfo](../models/usageinfo.md)                             | :heavy_check_mark:                                                     | N/A                                                                    |                                                                        |\n| `created`                                                              | *Optional[int]*                                                        | :heavy_minus_sign:                                                     | N/A                                                                    | 1702256327                                                             |\n| `choices`                                                              | List[[models.ChatCompletionChoice](../models/chatcompletionchoice.md)] | :heavy_minus_sign:                                                     | N/A                                                                    |                                                                        |\n```\n\n----------------------------------------\n\nTITLE: Defining List of Content Chunks for User Message in Python\nDESCRIPTION: Shows how to define user message content as a list of ContentChunk objects. This allows for more structured and potentially multi-modal content representation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/usermessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing ToolMessage in Mistral AI Python Client\nDESCRIPTION: Creates an instance of ToolMessage from the models module. This type might be used for messages related to specific tools or functionalities within the AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/messages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Controlling Frequency Penalty for Text Generation\nDESCRIPTION: Optional floating-point parameter that reduces repetition of frequently occurring words to enhance output diversity and reduce redundancy in generated text.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrequency_penalty: Optional[float] = None\n```\n\n----------------------------------------\n\nTITLE: Defining Messages for Agents Completion Request in Markdown\nDESCRIPTION: This snippet demonstrates how to structure the 'messages' parameter for an agents completion request. It shows a JSON-like format within a markdown table cell, representing a list containing a single message object with 'role' and 'content' properties.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n[<br/>{<br/>\"role\": \"user\",<br/>\"content\": \"Who is the best French painter? Answer in one short sentence.\"<br/>}<br/>]\n```\n\n----------------------------------------\n\nTITLE: JSON Schema Field Specifications in Markdown\nDESCRIPTION: Defines four fields for JSON Schema: name (required string), schema_definition (required dictionary), description (optional nullable string), and strict (optional boolean).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jsonschema.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                   | Type                    | Required                | Description             |\n| ----------------------- | ----------------------- | ----------------------- | ----------------------- |\n| `name`                  | *str*                   | :heavy_check_mark:      | N/A                     |\n| `schema_definition`     | Dict[str, *Any*]        | :heavy_check_mark:      | N/A                     |\n| `description`           | *OptionalNullable[str]* | :heavy_minus_sign:      | N/A                     |\n| `strict`                | *Optional[bool]*        | :heavy_minus_sign:      | N/A                     |\n```\n\n----------------------------------------\n\nTITLE: Tool Message Type Declaration\nDESCRIPTION: Declaration of the ToolMessage type used for messages from tools or functions that can be called during the conversation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequestmessages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ToolMessage Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ToolMessage class. It includes four fields: content, tool_call_id, name, and role. Each field is described with its type, requirement status, and a placeholder for description.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/toolmessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `content`                                                              | [Nullable[models.ToolMessageContent]](../models/toolmessagecontent.md) | :heavy_check_mark:                                                     | N/A                                                                    |\n| `tool_call_id`                                                         | *OptionalNullable[str]*                                                | :heavy_minus_sign:                                                     | N/A                                                                    |\n| `name`                                                                 | *OptionalNullable[str]*                                                | :heavy_minus_sign:                                                     | N/A                                                                    |\n| `role`                                                                 | [Optional[models.ToolMessageRole]](../models/toolmessagerole.md)       | :heavy_minus_sign:                                                     | N/A                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Defining FineTuneableModelType Enum Values in Markdown Table\nDESCRIPTION: A markdown table that defines the possible values for the FineTuneableModelType enumeration. It includes two types: COMPLETION with a value of 'completion' and CLASSIFIER with a value of 'classifier'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/finetuneablemodeltype.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name         | Value        |\n| ------------ | ------------ |\n| `COMPLETION` | completion   |\n| `CLASSIFIER` | classifier   |\n```\n\n----------------------------------------\n\nTITLE: Defining User Message Type - Python\nDESCRIPTION: Example of declaring a UserMessage type variable for agent completions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionrequestmessages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionFTModelOut Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the CompletionFTModelOut class using a markdown table. It includes field names, types, whether they are required, and leaves space for descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completionftmodelout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                  | Type                                                                                   | Required                                                                               | Description                                                                            |\n| -------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |\n| `id`                                                                                   | *str*                                                                                  | :heavy_check_mark:                                                                     | N/A                                                                                    |\n| `created`                                                                              | *int*                                                                                  | :heavy_check_mark:                                                                     | N/A                                                                                    |\n| `owned_by`                                                                             | *str*                                                                                  | :heavy_check_mark:                                                                     | N/A                                                                                    |\n| `root`                                                                                 | *str*                                                                                  | :heavy_check_mark:                                                                     | N/A                                                                                    |\n| `archived`                                                                             | *bool*                                                                                 | :heavy_check_mark:                                                                     | N/A                                                                                    |\n| `capabilities`                                                                         | [models.FTModelCapabilitiesOut](../models/ftmodelcapabilitiesout.md)                   | :heavy_check_mark:                                                                     | N/A                                                                                    |\n| `job`                                                                                  | *str*                                                                                  | :heavy_check_mark:                                                                     | N/A                                                                                    |\n| `object`                                                                               | [Optional[models.CompletionFTModelOutObject]](../models/completionftmodeloutobject.md) | :heavy_minus_sign:                                                                     | N/A                                                                                    |\n| `name`                                                                                 | *OptionalNullable[str]*                                                                | :heavy_minus_sign:                                                                     | N/A                                                                                    |\n| `description`                                                                          | *OptionalNullable[str]*                                                                | :heavy_minus_sign:                                                                     | N/A                                                                                    |\n| `max_context_length`                                                                   | *Optional[int]*                                                                        | :heavy_minus_sign:                                                                     | N/A                                                                                    |\n| `aliases`                                                                              | List[*str*]                                                                            | :heavy_minus_sign:                                                                     | N/A                                                                                    |\n| `model_type`                                                                           | [Optional[models.ModelType]](../models/modeltype.md)                                   | :heavy_minus_sign:                                                                     | N/A                                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Using models.ToolChoice Type\nDESCRIPTION: Example showing the type annotation for using the models.ToolChoice value in chat completion requests.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionrequesttoolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoice = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Controlling Frequency Penalty for Repetition Reduction\nDESCRIPTION: Manages the model's propensity to repeat words based on their frequency in the generated text. Higher values reduce repetition and promote lexical variety.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequest.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrequency_penalty: Optional[float] = None\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionTrainingParametersIn in Python for Mistral AI\nDESCRIPTION: This snippet demonstrates how to define a variable of type CompletionTrainingParametersIn from the models module. It's used to set hyperparameters for completion training tasks.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/hyperparameters.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.CompletionTrainingParametersIn = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using models.ToolChoiceEnum Type\nDESCRIPTION: Example showing the type annotation for using the models.ToolChoiceEnum value in chat completion requests.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionrequesttoolchoice.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoiceEnum = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining UserMessage Fields in Markdown\nDESCRIPTION: This markdown table outlines the fields of the UserMessage class, specifying their types, requirements, and descriptions. It includes two fields: 'content' and 'role', both with specific model types and requirement indicators.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/usermessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `content`                                                              | [Nullable[models.UserMessageContent]](../models/usermessagecontent.md) | :heavy_check_mark:                                                     | N/A                                                                    |\n| `role`                                                                 | [Optional[models.UserMessageRole]](../models/usermessagerole.md)       | :heavy_minus_sign:                                                     | N/A                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionChoiceFinishReason Enum Values in Markdown\nDESCRIPTION: This snippet defines the possible values for the ChatCompletionChoiceFinishReason enum using a markdown table. It includes five different finish reasons: STOP, LENGTH, MODEL_LENGTH, ERROR, and TOOL_CALLS.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionchoicefinishreason.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name           | Value          |\n| -------------- | -------------- |\n| `STOP`         | stop           |\n| `LENGTH`       | length         |\n| `MODEL_LENGTH` | model_length   |\n| `ERROR`        | error          |\n| `TOOL_CALLS`   | tool_calls     |\n```\n\n----------------------------------------\n\nTITLE: Text Chunks List Type Declaration for SystemMessageContent\nDESCRIPTION: Defines a list of TextChunk models as a value type for system message content. Used when the system message needs to be structured as multiple text segments.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/systemmessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.TextChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: ChatCompletionResponse Fields Documentation\nDESCRIPTION: Markdown table documenting the fields of the ChatCompletionResponse structure including their types, requirements, and examples.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            | Example                                                                |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `id`                                                                   | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | cmpl-e5cc70bb28c444948073e77776eb30ef                                  |\n| `object`                                                               | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | chat.completion                                                        |\n| `model`                                                                | *str*                                                                  | :heavy_check_mark:                                                     | N/A                                                                    | mistral-small-latest                                                   |\n| `usage`                                                                | [models.UsageInfo](../models/usageinfo.md)                             | :heavy_check_mark:                                                     | N/A                                                                    |                                                                        |\n| `created`                                                              | *Optional[int]*                                                        | :heavy_minus_sign:                                                     | N/A                                                                    | 1702256327                                                             |\n| `choices`                                                              | List[[models.ChatCompletionChoice](../models/chatcompletionchoice.md)] | :heavy_minus_sign:                                                     | N/A                                                                    |                                                                        |\n```\n\n----------------------------------------\n\nTITLE: Initializing Classifier Detailed Job Output Type - Python\nDESCRIPTION: Defines the type annotation for a classifier detailed job output response from the fine-tuning API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningstartfinetuningjobresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ClassifierDetailedJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using models.ToolChoice Type in ChatCompletionStreamRequest\nDESCRIPTION: Shows how to define a variable of type models.ToolChoice that can be used with the ChatCompletionStreamRequest in the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequesttoolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoice = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Tool Message Role Constants - Markdown\nDESCRIPTION: Markdown table defining the TOOL constant with value 'tool' used for tool message roles in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/toolmessagerole.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name   | Value  |\n| ------ | ------ |\n| `TOOL` | tool   |\n```\n\n----------------------------------------\n\nTITLE: Defining TextChunk Fields Table in Markdown\nDESCRIPTION: Markdown table documenting the fields of the TextChunk data structure. Includes information about text and type fields with their respective types and requirements.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/textchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                        | Type                                                         | Required                                                     | Description                                                  |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| `text`                                                       | *str*                                                        | :heavy_check_mark:                                           | N/A                                                          |\n| `type`                                                       | [Optional[models.TextChunkType]](../models/textchunktype.md) | :heavy_minus_sign:                                           | N/A                                                          |\n```\n\n----------------------------------------\n\nTITLE: Defining Response Format Values in Markdown\nDESCRIPTION: This snippet defines a table of response format values using Markdown syntax. It specifies three formats: TEXT, JSON_OBJECT, and JSON_SCHEMA, along with their corresponding string values.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/responseformats.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name          | Value         |\n| ------------- | ------------- |\n| `TEXT`        | text          |\n| `JSON_OBJECT` | json_object   |\n| `JSON_SCHEMA` | json_schema   |\n```\n\n----------------------------------------\n\nTITLE: Formatting Chat Messages for Mistral AI API\nDESCRIPTION: Example JSON structure for the 'messages' parameter in a chat completion request. This shows how to format a user message with content that will be processed by the model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/chat/README.md#2025-04-17_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n[\n{\n\"role\": \"user\",\n\"content\": \"Who is the best French painter? Answer in one short sentence.\"\n}\n]\n```\n\n----------------------------------------\n\nTITLE: Defining ValidationError Fields in Markdown\nDESCRIPTION: This markdown table outlines the structure of a ValidationError object, specifying the required fields, their types, and whether they are mandatory. It includes loc (location), msg (message), and type fields.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/validationerror.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                | Type                                 | Required                             | Description                          |\n| ------------------------------------ | ------------------------------------ | ------------------------------------ | ------------------------------------ |\n| `loc`                                | List[[models.Loc](../models/loc.md)] | :heavy_check_mark:                   | N/A                                  |\n| `msg`                                | *str*                                | :heavy_check_mark:                   | N/A                                  |\n| `type`                               | *str*                                | :heavy_check_mark:                   | N/A                                  |\n```\n\n----------------------------------------\n\nTITLE: Using models.ToolChoice Type with AgentsCompletionStreamRequestToolChoice\nDESCRIPTION: Demonstrates how to use the models.ToolChoice type with the AgentsCompletionStreamRequestToolChoice class. This type allows configuring tool choice behavior for agent completions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequesttoolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoice = /* values here */\n```\n\n----------------------------------------\n\nTITLE: UserMessage Field Definitions in Markdown\nDESCRIPTION: Markdown table defining the required fields for UserMessage objects, including content and role properties with their respective types and requirements.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/usermessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `content`                                                              | [Nullable[models.UserMessageContent]](../models/usermessagecontent.md) | :heavy_check_mark:                                                     | N/A                                                                    |\n| `role`                                                                 | [Optional[models.UserMessageRole]](../models/usermessagerole.md)       | :heavy_minus_sign:                                                     | N/A                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Defining Assistant Message Type - Python\nDESCRIPTION: Example of declaring an AssistantMessage type variable for agent completions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionrequestmessages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using InstructRequestInputs Model in Python\nDESCRIPTION: Example showing the type annotation for using the InstructRequestInputs model class for making instruction requests. The InstructRequestInputs is a structured input format for the Mistral AI API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/inputs.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.InstructRequestInputs = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing AssistantMessage Type in Python\nDESCRIPTION: Demonstrates the type annotation for an AssistantMessage object in the models module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequestmessages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ToolChoiceEnum Values in Markdown\nDESCRIPTION: This snippet defines the possible values for the ToolChoiceEnum using a markdown table. It includes four options: AUTO, NONE, ANY, and REQUIRED, along with their corresponding string values.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/toolchoiceenum.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name       | Value      |\n| ---------- | ---------- |\n| `AUTO`     | auto       |\n| `NONE`     | none       |\n| `ANY`      | any        |\n| `REQUIRED` | required   |\n```\n\n----------------------------------------\n\nTITLE: Defining ToolMessageRole Constant in Python\nDESCRIPTION: This code snippet defines a constant 'TOOL' with the value 'tool', likely used to identify or categorize messages in a system that involves tool-based interactions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/toolmessagerole.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nTOOL = 'tool'\n```\n\n----------------------------------------\n\nTITLE: Declaring TextChunk in Mistral AI Python Client\nDESCRIPTION: Example of declaring a TextChunk type variable for handling text content in Mistral AI.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/contentchunk.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.TextChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Declaring Dict[str, Any] Argument in Python for Mistral AI Client\nDESCRIPTION: This snippet shows how to declare a variable of type Dict[str, Any], which is a dictionary with string keys and values of any type. This is commonly used for flexible data structures in the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/arguments.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: Dict[str, Any] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ImageURLChunk Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the ImageURLChunk class using a markdown table. It specifies the field names, types, requirements, and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/imageurlchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                | Type                                                                 | Required                                                             | Description                                                          |\n| -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| `image_url`                                                          | [models.ImageURLChunkImageURL](../models/imageurlchunkimageurl.md)   | :heavy_check_mark:                                                   | N/A                                                                  |\n| `type`                                                               | [Optional[models.ImageURLChunkType]](../models/imageurlchunktype.md) | :heavy_minus_sign:                                                   | N/A                                                                  |\n```\n\n----------------------------------------\n\nTITLE: Defining AssistantMessage Type in Python\nDESCRIPTION: Type definition for AssistantMessage class which represents messages from the AI assistant.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/two.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using List of InstructRequest Objects in Python\nDESCRIPTION: Example showing the type annotation for using a List of InstructRequest objects for making batch instruction requests. This format allows sending multiple instruction requests in a single API call.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/inputs.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.InstructRequest] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining FIMCompletionRequest Class in Python for Mistral AI Client\nDESCRIPTION: This code snippet defines the FIMCompletionRequest class, which inherits from BaseModel. It includes class attributes for model, prompt, and options, with type hints and default values.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/fimcompletionrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass FIMCompletionRequest(BaseModel):\n    model: str\n    prompt: str\n    options: Optional[FIMCompletionOptions] = None\n```\n\n----------------------------------------\n\nTITLE: Initializing SystemMessage Type in Python\nDESCRIPTION: Demonstrates the type annotation for a SystemMessage object in the models module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequestmessages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining System Role in Markdown Table\nDESCRIPTION: This markdown table defines the 'SYSTEM' role with its corresponding value. It's likely used for role-based operations or permissions within the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/role.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name     | Value    |\n| -------- | -------- |\n| `SYSTEM` | system   |\n```\n\n----------------------------------------\n\nTITLE: ToolChoice Field Definition Table\nDESCRIPTION: Markdown table defining the fields of the ToolChoice class, including function and type properties with their requirements and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/toolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field      | Type                                                 | Required           | Description                                                  |\n| ---------- | ---------------------------------------------------- | ------------------ | ------------------------------------------------------------ |\n| `function` | [models.FunctionName](../models/functionname.md)       | :heavy_check_mark: | this restriction of `Function` is used to select a specific function to call |\n| `type`     | [Optional[models.ToolTypes]](../models/tooltypes.md)   | :heavy_minus_sign: | N/A                                                          |\n```\n\n----------------------------------------\n\nTITLE: Defining String Type for AssistantMessageContent in Python\nDESCRIPTION: Specifies the string type as a supported value for AssistantMessageContent. This allows for simple text-based content to be used as the message content.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/assistantmessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Declaring SystemMessage Type in Python\nDESCRIPTION: Example of declaring a SystemMessage type variable for Mistral AI client\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/messages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Predictions Parameter for API Requests\nDESCRIPTION: This snippet defines the `prediction` parameter, expected to be an optional list of Prediction models. It serves to specify the type of predictions that can be returned from the API, and it's not applicable in certain contexts.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n| `prediction`                                                                                                                                                                                                                                                                                                                                                                                          | [Optional[models.Prediction]](../models/prediction.md)                                                                                                                                                                                                                                                                                                                                                | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | N/A                                                                                                                                                                                                                                                                                                                                                                                                   |\n```\n\n----------------------------------------\n\nTITLE: Using models.ImageURL Type with ImageURLChunkImageURL\nDESCRIPTION: Demonstrates the usage of models.ImageURL type with ImageURLChunkImageURL class or module. The value is expected to be an instance of the models.ImageURL class.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/imageurlchunkimageurl.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ImageURL = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ImageURLChunkType Enum in Python\nDESCRIPTION: This code snippet defines an enumeration class called ImageURLChunkType with a single value IMAGE_URL. The enum value is assigned the string 'image_url'. This enum can be used to specify the type of image URL chunks in related code.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/imageurlchunktype.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# ImageURLChunkType\n\n\n## Values\n\n| Name        | Value       |\n| ----------- | ----------- |\n| `IMAGE_URL` | image_url   |\n```\n\n----------------------------------------\n\nTITLE: Defining UserMessage Type in Python\nDESCRIPTION: Type definition for UserMessage class which represents messages from the user.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/two.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining List of Strings Input for Classification in Python\nDESCRIPTION: This snippet shows how to define a list of strings as input for text classification using the ClassificationRequestInputs type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classificationrequestinputs.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ClassifierJobOut Model Type\nDESCRIPTION: Example showing the type annotation for a ClassifierJobOut model value from the models package.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsoutdata.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ClassifierJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing AssistantMessage in Mistral AI Python Client\nDESCRIPTION: Creates an instance of the AssistantMessage type. This message type is likely used to represent responses or messages from the AI assistant.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/one.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: OCR Request Model Field Definitions in Markdown\nDESCRIPTION: Markdown table defining the fields, types, requirements and descriptions for the OCR Request model. Includes parameters for model selection, document processing, page selection, and image handling options.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ocrrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                | Type                     | Required            | Description                                                                                                   |\n| -------------------- | ------------------------ | ------------------- | ------------------------------------------------------------------------------------------------------------- |\n| `model`              | *Nullable[str]*          | :heavy_check_mark:  | N/A                                                                                                           |\n| `document`           | [models.Document]        | :heavy_check_mark:  | Document to run OCR on                                                                                        |\n| `id`                 | *Optional[str]*          | :heavy_minus_sign:  | N/A                                                                                                           |\n| `pages`              | List[*int*]              | :heavy_minus_sign:  | Specific pages user wants to process in various formats: single number, range, or list of both. Starts from 0 |\n| `include_image_base64`| *OptionalNullable[bool]* | :heavy_minus_sign:  | Include image URLs in response                                                                                |\n| `image_limit`        | *OptionalNullable[int]*  | :heavy_minus_sign:  | Max images to extract                                                                                         |\n| `image_min_size`     | *OptionalNullable[int]*  | :heavy_minus_sign:  | Minimum height and width of image to extract                                                                  |\n```\n\n----------------------------------------\n\nTITLE: String Content Type Declaration\nDESCRIPTION: Defines how to declare a string content value for assistant messages\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/assistantmessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining String Type for ToolMessageContent in Python\nDESCRIPTION: Specifies the string data type for ToolMessageContent values. This allows for simple text content to be used as a tool message.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/toolmessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining UsageInfo Fields in Markdown\nDESCRIPTION: Defines the structure of the UsageInfo class using a markdown table. It specifies three required integer fields: prompt_tokens, completion_tokens, and total_tokens, each with an example value.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/usageinfo.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field               | Type                | Required            | Description         | Example             |\n| ------------------- | ------------------- | ------------------- | ------------------- | ------------------- |\n| `prompt_tokens`     | *int*               | :heavy_check_mark:  | N/A                 | 16                  |\n| `completion_tokens` | *int*               | :heavy_check_mark:  | N/A                 | 34                  |\n| `total_tokens`      | *int*               | :heavy_check_mark:  | N/A                 | 50                  |\n```\n\n----------------------------------------\n\nTITLE: System Message Type Declaration\nDESCRIPTION: Declaration of the SystemMessage type used for system-level instructions or context in the conversation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequestmessages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining String Input for Embedding Requests in Python\nDESCRIPTION: Shows how to define a single string as input for an embedding request. This format is used when you need to embed a single piece of text.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/embeddingrequestinputs.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Setting String Token Stop in FIMCompletionStreamRequest\nDESCRIPTION: Demonstrates how to define a single string token to stop text generation when detected. This is used with the FIMCompletionStreamRequest to control when the generation should terminate.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/fimcompletionstreamrequeststop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Assistant Message Type Declaration\nDESCRIPTION: Declaration of the AssistantMessage type used for messages from the AI assistant in the conversation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequestmessages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: String Value Type Definition - Python\nDESCRIPTION: Defines a string type value that can be used as tool message content.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/toolmessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionResponseStreamChoice Fields in Markdown\nDESCRIPTION: This markdown table describes the fields of the CompletionResponseStreamChoice model, including their types, requirements, and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/completionresponsestreamchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                      | Type                                                       | Required                                                   | Description                                                |\n| ---------------------------------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------- |\n| `index`                                                    | *int*                                                      | :heavy_check_mark:                                         | N/A                                                        |\n| `delta`                                                    | [models.DeltaMessage](../models/deltamessage.md)           | :heavy_check_mark:                                         | N/A                                                        |\n| `finish_reason`                                            | [Nullable[models.FinishReason]](../models/finishreason.md) | :heavy_check_mark:                                         | N/A                                                        |\n```\n\n----------------------------------------\n\nTITLE: Initializing String Type for AssistantMessageContent in Python\nDESCRIPTION: This snippet demonstrates how to initialize a string type value for AssistantMessageContent. The actual values should be provided in place of the comment.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/assistantmessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Function Class Fields in Markdown\nDESCRIPTION: This snippet outlines the fields of the Function class using a markdown table. It specifies the field names, their types, whether they are required, and provides placeholders for descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/function.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `name`             | *str*              | :heavy_check_mark: | N/A                |\n| `parameters`       | Dict[str, *Any*]   | :heavy_check_mark: | N/A                |\n| `description`      | *Optional[str]*    | :heavy_minus_sign: | N/A                |\n| `strict`           | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Managing Presence Penalty for Text Diversity\nDESCRIPTION: Optional floating-point parameter that penalizes word repetition to encourage more diverse and creative text generation. Higher values promote broader vocabulary usage.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npresence_penalty: Optional[float] = None\n```\n\n----------------------------------------\n\nTITLE: Defining Single Stop Token in Python\nDESCRIPTION: Shows how to define a single string stop token that will halt generation when detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/stop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Chat Completion Parameters in Markdown\nDESCRIPTION: This markdown table defines the fields used for chat completion requests in the Mistral AI Python client. It includes the model, prompt, and temperature parameters, along with their types, requirements, descriptions, and examples.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/fimcompletionstreamrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description | Example |\n| ----- | ---- | -------- | ----------- | ------- |\n| `model` | *str* | :heavy_check_mark: | ID of the model to use. Only compatible for now with:<br/>  - `codestral-2405`<br/>  - `codestral-latest` | codestral-2405 |\n| `prompt` | *str* | :heavy_check_mark: | The text/code to complete. | def |\n| `temperature` | *OptionalNullable[float]* | :heavy_minus_sign: | What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value. | |\n```\n\n----------------------------------------\n\nTITLE: Initializing ToolMessage Type in Python\nDESCRIPTION: Demonstrates the type annotation for a ToolMessage object in the models module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequestmessages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining UserMessageContent as String in Python\nDESCRIPTION: This snippet shows how to define UserMessageContent as a string type in Python. The actual values would be assigned to the 'value' variable.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/usermessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining a single stop token with str in AgentsCompletionRequestStop\nDESCRIPTION: Shows how to define a single stop token using a string value for AgentsCompletionRequestStop. When this token is detected in the generated text, the generation process will stop.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionrequeststop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Model Capabilities Fields Table in Markdown\nDESCRIPTION: Markdown table defining the fields, types, requirements, and descriptions for model capabilities. Each field is defined as an optional boolean type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/modelcapabilities.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `completion_chat`  | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n| `completion_fim`   | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n| `function_calling` | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n| `fine_tuning`      | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n| `vision`           | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining TextChunk Class with Fields in Python\nDESCRIPTION: This code snippet defines the TextChunk class with two fields: text (a required string) and type (an optional Type object). The fields are documented in a table format, specifying their types, requirements, and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/textchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# TextChunk\n\n\n## Fields\n\n| Field                                      | Type                                       | Required                                   | Description                                |\n| ------------------------------------------ | ------------------------------------------ | ------------------------------------------ | ------------------------------------------ |\n| `text`                                     | *str*                                      | :heavy_check_mark:                         | N/A                                        |\n| `type`                                     | [Optional[models.Type]](../models/type.md) | :heavy_minus_sign:                         | N/A                                        |\n```\n\n----------------------------------------\n\nTITLE: String Type Declaration for SystemMessageContent\nDESCRIPTION: Defines a string type value for system message content. Used for simple text-based system messages.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/systemmessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing UserMessage in Python\nDESCRIPTION: Shows the type hint for creating a UserMessage instance in the models module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequestmessages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining String Type in Python for Mistral AI Client\nDESCRIPTION: Demonstrates how to declare a variable of type string (str) in Python, which is a supported type in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/loc.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: ModelList Field Definitions in Markdown\nDESCRIPTION: Markdown table defining the fields of the ModelList class, including their types, requirements, and descriptions. Contains two fields: object (Optional[str]) and data (List[models.Data]).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/modellist.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                  | Type                                   | Required                               | Description                            |\n| -------------------------------------- | -------------------------------------- | -------------------------------------- | -------------------------------------- |\n| `object`                               | *Optional[str]*                        | :heavy_minus_sign:                     | N/A                                    |\n| `data`                                 | List[[models.Data](../models/data.md)] | :heavy_minus_sign:                     | N/A                                    |\n```\n\n----------------------------------------\n\nTITLE: Initializing ToolMessage in Python for Mistral AI Chat Completion\nDESCRIPTION: Creates an instance of ToolMessage for use in chat completion requests. The specific values for initialization are not provided in the snippet.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequestmessages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining models.ImageURL in Python\nDESCRIPTION: This snippet demonstrates how to declare a variable of type models.ImageURL. The actual value assignment is not shown and should be replaced with appropriate data.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/imageurlchunkimageurl.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ImageURL = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Single String Stop Token Configuration in Python\nDESCRIPTION: Defines a single string stop token configuration for FIM completion requests. The value parameter expects a string that will trigger the completion to stop when detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/fimcompletionrequeststop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionEvent Structure in Markdown\nDESCRIPTION: This markdown table defines the structure of the CompletionEvent class. It specifies a single field named 'data' of type CompletionChunk, which is required for the event.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completionevent.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                  | Type                                                   | Required                                               | Description                                            |\n| ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ |\n| `data`                                                 | [models.CompletionChunk](../models/completionchunk.md) | :heavy_check_mark:                                     | N/A                                                    |\n```\n\n----------------------------------------\n\nTITLE: FTModelCapabilitiesOut Schema Fields\nDESCRIPTION: Markdown table defining the fields, types, requirements and descriptions for the FTModelCapabilitiesOut data structure. Each field is an optional boolean indicating support for specific model capabilities.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ftmodelcapabilitiesout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `completion_chat`  | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n| `completion_fim`   | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n| `function_calling` | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n| `fine_tuning`      | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n| `classification`   | *Optional[bool]*   | :heavy_minus_sign: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionChunk Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the CompletionChunk model using a markdown table. It includes field names, types, requirements, and descriptions for each component of the completion chunk response.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completionchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                      | Type                                                                                       | Required                                                                                   | Description                                                                                |\n| ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ |\n| `id`                                                                                       | *str*                                                                                      | :heavy_check_mark:                                                                         | N/A                                                                                        |\n| `model`                                                                                    | *str*                                                                                      | :heavy_check_mark:                                                                         | N/A                                                                                        |\n| `choices`                                                                                  | List[[models.CompletionResponseStreamChoice](../models/completionresponsestreamchoice.md)] | :heavy_check_mark:                                                                         | N/A                                                                                        |\n| `object`                                                                                   | *Optional[str]*                                                                            | :heavy_minus_sign:                                                                         | N/A                                                                                        |\n| `created`                                                                                  | *Optional[int]*                                                                            | :heavy_minus_sign:                                                                         | N/A                                                                                        |\n| `usage`                                                                                    | [Optional[models.UsageInfo]](../models/usageinfo.md)                                       | :heavy_minus_sign:                                                                         | N/A                                                                                        |\n```\n\n----------------------------------------\n\nTITLE: Defining List of ContentChunk Models for ToolMessageContent in Python\nDESCRIPTION: Defines a list of ContentChunk models as a valid type for ToolMessageContent. This allows for more complex, structured content to be used in tool messages.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/toolmessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ToolCall Fields in Markdown\nDESCRIPTION: Documents the fields available in the ToolCall class including function, id, type, and index properties. Shows the required fields and their respective data types.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/toolcall.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                | Type                                                 | Required                                             | Description                                          |\n| ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- |\n| `function`                                           | [models.FunctionCall](../models/functioncall.md)     | :heavy_check_mark:                                   | N/A                                                  |\n| `id`                                                 | *Optional[str]*                                      | :heavy_minus_sign:                                   | N/A                                                  |\n| `type`                                               | [Optional[models.ToolTypes]](../models/tooltypes.md) | :heavy_minus_sign:                                   | N/A                                                  |\n| `index`                                              | *Optional[int]*                                      | :heavy_minus_sign:                                   | N/A                                                  |\n```\n\n----------------------------------------\n\nTITLE: Specifying Tool Choice Strategy\nDESCRIPTION: Optional parameter to control how and which tools are selected by the AI model during response generation. Provides fine-grained control over tool usage.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntool_choice: Optional[models.ChatCompletionStreamRequestToolChoice] = None\n```\n\n----------------------------------------\n\nTITLE: Defining Integer Type in Python for Mistral AI Client\nDESCRIPTION: Shows the declaration of an integer (int) type variable in Python, another supported type in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/loc.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: int = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Chat Moderation Request Fields Table\nDESCRIPTION: Markdown table documenting the required fields for chat moderation requests, including inputs object for classification and model string specification.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatmoderationrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                          | Type                                                                           | Required                                                                       | Description                                                                    |\n| ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------ |\n| `inputs`                                                                       | [models.ChatModerationRequestInputs](../models/chatmoderationrequestinputs.md) | :heavy_check_mark:                                                             | Chat to classify                                                               |\n| `model`                                                                        | *str*                                                                          | :heavy_check_mark:                                                             | N/A                                                                            |\n```\n\n----------------------------------------\n\nTITLE: Defining Nested List of Model.Two Objects for Chat Moderation in Python\nDESCRIPTION: Shows how to define a variable that holds a nested list of model.Two objects for use in chat moderation requests. This more complex structure allows for multi-dimensional chat content organization.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatmoderationrequestinputs.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[List[models.Two]] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using String Type with ImageURLChunkImageURL\nDESCRIPTION: Demonstrates the usage of string type with ImageURLChunkImageURL class or module. The value is expected to be a string, likely representing an image URL.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/imageurlchunkimageurl.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining List of ContentChunk Objects in MistralAI Python Client\nDESCRIPTION: Shows the syntax for defining a list of ContentChunk objects as a content value in the MistralAI Python client. The actual list of ContentChunk objects should be assigned where the comment is placed.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/content.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining HTTPValidationError Model Structure in Markdown\nDESCRIPTION: This markdown table defines the structure of the HTTPValidationError model. It specifies a single field 'detail' which is a list of ValidationError objects. The field is not marked as required.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/httpvalidationerror.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                        | Type                                                         | Required                                                     | Description                                                  |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| `detail`                                                     | List[[models.ValidationError](../models/validationerror.md)] | :heavy_minus_sign:                                           | N/A                                                          |\n```\n\n----------------------------------------\n\nTITLE: Defining Prediction Class Fields in Markdown\nDESCRIPTION: This markdown table outlines the fields of the Prediction class, including their types, whether they are required, and descriptions. The class has two optional fields: 'type' and 'content'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/prediction.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                          | Type                           | Required                       | Description                    |\n| ------------------------------ | ------------------------------ | ------------------------------ | ------------------------------ |\n| `type`                         | *Optional[Literal[\"content\"]]* | :heavy_minus_sign:             | N/A                            |\n| `content`                      | *Optional[str]*                | :heavy_minus_sign:             | N/A                            |\n```\n\n----------------------------------------\n\nTITLE: TextChunk List Type in SystemMessageContent\nDESCRIPTION: Shows the type definition for a list of TextChunk models in SystemMessageContent. Uses Python's type hinting with the List type from typing module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/systemmessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.TextChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Specifying WandbIntegrationOut Model Type in Python\nDESCRIPTION: Example of typing a variable as WandbIntegrationOut model from the models package. This code demonstrates how to declare a variable with the WandbIntegrationOut type, which is used for Weights & Biases integration with Mistral AI's completion jobs.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completiondetailedjoboutintegrations.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.WandbIntegrationOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining List of Model.One Objects for Chat Moderation in Python\nDESCRIPTION: Shows how to define a variable that holds a list of model.One objects for use in chat moderation requests. The list structure is used to pass chat content for classification.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatmoderationrequestinputs.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.One] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing GithubRepositoryOut Model in Python\nDESCRIPTION: This snippet demonstrates how to initialize a GithubRepositoryOut model object. The GithubRepositoryOut is likely used to represent output data for a GitHub repository in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/repositories.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.GithubRepositoryOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining String Location Type in Python\nDESCRIPTION: This snippet demonstrates how to define a location value as a string type in Python. The actual value would be assigned where the comment is placed.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/loc.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Multiple Stop Tokens Configuration\nDESCRIPTION: Defines multiple stop tokens as a list of strings. Generation will stop if any of these tokens are detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/stop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining String Content in MistralAI Python Client\nDESCRIPTION: Demonstrates how to define a string content value in the MistralAI Python client. The actual value should be assigned where the comment is placed.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/content.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining UsageInfo Fields in Markdown Table\nDESCRIPTION: This markdown table defines the fields of the UsageInfo class, including their types, whether they are required, and example values. It covers prompt_tokens, completion_tokens, and total_tokens.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/usageinfo.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field               | Type                | Required            | Description         | Example             |\n| ------------------- | ------------------- | ------------------- | ------------------- | ------------------- |\n| `prompt_tokens`     | *int*               | :heavy_check_mark:  | N/A                 | 16                  |\n| `completion_tokens` | *int*               | :heavy_check_mark:  | N/A                 | 34                  |\n| `total_tokens`      | *int*               | :heavy_check_mark:  | N/A                 | 50                  |\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionDetailedJobOutStatus Enum Values in Markdown\nDESCRIPTION: This markdown table defines the possible values for the CompletionDetailedJobOutStatus enum. It includes statuses such as queued, running, failed, and success, among others, representing different stages and outcomes of a completion detailed job.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completiondetailedjoboutstatus.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                     | Value                    |\n| ------------------------ | ------------------------ |\n| `QUEUED`                 | QUEUED                   |\n| `STARTED`                | STARTED                  |\n| `VALIDATING`             | VALIDATING               |\n| `VALIDATED`              | VALIDATED                |\n| `RUNNING`                | RUNNING                  |\n| `FAILED_VALIDATION`      | FAILED_VALIDATION        |\n| `FAILED`                 | FAILED                   |\n| `SUCCESS`                | SUCCESS                  |\n| `CANCELLED`              | CANCELLED                |\n| `CANCELLATION_REQUESTED` | CANCELLATION_REQUESTED   |\n```\n\n----------------------------------------\n\nTITLE: Defining models.ToolChoice in Python for ChatCompletionRequestToolChoice\nDESCRIPTION: This snippet demonstrates how to define a value of type models.ToolChoice for use in ChatCompletionRequestToolChoice. The actual values are not provided in the snippet.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequesttoolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoice = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionChunk Fields in Markdown\nDESCRIPTION: Specifies the fields, types, requirements, and descriptions for the CompletionChunk model using a markdown table. Includes both required and optional fields, with references to other model types.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/completionchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                      | Type                                                                                       | Required                                                                                   | Description                                                                                |\n| ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------ |\n| `id`                                                                                       | *str*                                                                                      | :heavy_check_mark:                                                                         | N/A                                                                                        |\n| `model`                                                                                    | *str*                                                                                      | :heavy_check_mark:                                                                         | N/A                                                                                        |\n| `choices`                                                                                  | List[[models.CompletionResponseStreamChoice](../models/completionresponsestreamchoice.md)] | :heavy_check_mark:                                                                         | N/A                                                                                        |\n| `object`                                                                                   | *Optional[str]*                                                                            | :heavy_minus_sign:                                                                         | N/A                                                                                        |\n| `created`                                                                                  | *Optional[int]*                                                                            | :heavy_minus_sign:                                                                         | N/A                                                                                        |\n| `usage`                                                                                    | [Optional[models.UsageInfo]](../models/usageinfo.md)                                       | :heavy_minus_sign:                                                                         | N/A                                                                                        |\n```\n\n----------------------------------------\n\nTITLE: Defining TrainingFile Class Fields in Python\nDESCRIPTION: This code snippet defines the fields for the TrainingFile class. It specifies two fields: file_id as a required string, and weight as an optional float. The information is presented in a table format, indicating the field names, types, whether they are required, and a description (which is not provided in this case).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/trainingfile.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `file_id`          | *str*              | :heavy_check_mark: | N/A                |\n| `weight`           | *Optional[float]*  | :heavy_minus_sign: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining Role Enum in Python for Mistral AI Client\nDESCRIPTION: This code snippet defines an Enum class named Role with a single value SYSTEM. It's likely used to categorize message types in a conversation model, with SYSTEM potentially representing messages or instructions from the system itself.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/role.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# Role\n\n\n## Values\n\n| Name     | Value    |\n| -------- | -------- |\n| `SYSTEM` | system   |\n```\n\n----------------------------------------\n\nTITLE: Fine-tuning Job Request Fields Table in Markdown\nDESCRIPTION: Markdown table defining the request fields for starting a fine-tuning job. Contains a single required string field 'job_id'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningstartfinetuningjobrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `job_id`           | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining WandbIntegrationType Enum in Python\nDESCRIPTION: This code snippet defines an enum called WandbIntegrationType with a single value 'WANDB' corresponding to the string 'wandb'. This enum is likely used for specifying integration types related to Weights & Biases (wandb) in the project.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/wandbintegrationtype.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# WandbIntegrationType\n\n\n## Values\n\n| Name    | Value   |\n| ------- | ------- |\n| `WANDB` | wandb   |\n```\n\n----------------------------------------\n\nTITLE: Defining ToolTypes Enumeration in Python\nDESCRIPTION: This code snippet defines the ToolTypes enumeration with a single value 'FUNCTION'. It is likely used to specify the type of tool in the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/tooltypes.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# ToolTypes\n\n\n## Values\n\n| Name       | Value      |\n| ---------- | ---------- |\n| `FUNCTION` | function   |\n```\n\n----------------------------------------\n\nTITLE: Content Chunk List Type Definition in Tool Message Content\nDESCRIPTION: Shows the type annotation for a list of content chunks in tool message content. Demonstrates how to declare a variable as a list of ContentChunk model objects.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/toolmessagecontent.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using WandbIntegration Model in Python\nDESCRIPTION: Example of using the WandbIntegration model from the models package in the mistralai/client-python project. This snippet shows the syntax for declaring a WandbIntegration value.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobinintegrations.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.WandbIntegration = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ListFilesOut Class Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the ListFilesOut class using a markdown table. It specifies the field names, types, whether they are required, and provides descriptions where available.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/listfilesout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                              | Type                                               | Required                                           | Description                                        |\n| -------------------------------------------------- | -------------------------------------------------- | -------------------------------------------------- | -------------------------------------------------- |\n| `data`                                             | List[[models.FileSchema](../models/fileschema.md)] | :heavy_check_mark:                                 | N/A                                                |\n| `object`                                           | *str*                                              | :heavy_check_mark:                                 | N/A                                                |\n| `total`                                            | *int*                                              | :heavy_check_mark:                                 | N/A                                                |\n```\n\n----------------------------------------\n\nTITLE: Defining ToolChoice Value Type\nDESCRIPTION: Demonstrates type annotation for a variable using the models.ToolChoice type in the Mistral AI client\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequesttoolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoice = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ToolChoiceEnum Values in Markdown\nDESCRIPTION: This code snippet defines the possible values for the ToolChoiceEnum class using a markdown table. It lists four options: AUTO, NONE, ANY, and REQUIRED, along with their corresponding string values.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/toolchoiceenum.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name       | Value      |\n| ---------- | ---------- |\n| `AUTO`     | auto       |\n| `NONE`     | none       |\n| `ANY`      | any        |\n| `REQUIRED` | required   |\n```\n\n----------------------------------------\n\nTITLE: Defining UserMessageRole Enum in Markdown\nDESCRIPTION: This code snippet defines the UserMessageRole enum using a markdown table. It specifies a single value 'USER' with the corresponding string value 'user'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/usermessagerole.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name   | Value  |\n| ------ | ------ |\n| `USER` | user   |\n```\n\n----------------------------------------\n\nTITLE: Defining Classifier Job Output Type\nDESCRIPTION: Type definition for classifier detailed job output response when canceling a fine-tuning job.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningcancelfinetuningjobresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ClassifierDetailedJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining AssistantMessageRole Enum in Python\nDESCRIPTION: This code snippet defines an enumeration called AssistantMessageRole with a single value ASSISTANT set to 'assistant'. This enum is likely used to represent the role of an AI assistant in message exchanges within the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/assistantmessagerole.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# AssistantMessageRole\n\n\n## Values\n\n| Name        | Value       |\n| ----------- | ----------- |\n| `ASSISTANT` | assistant   |\n```\n\n----------------------------------------\n\nTITLE: Defining Job Type Enumeration Value\nDESCRIPTION: Defines the COMPLETION job type value constant used for specifying job operations in the Mistral AI API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobtype.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name         | Value        |\n| ------------ | ------------ |\n| `COMPLETION` | completion   |\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Code Region in Python SDK\nDESCRIPTION: Shows how to add a custom code region in the SDK files, including imports and a custom method implementation within a class.\nSOURCE: https://github.com/mistralai/client-python/blob/main/src/mistralai/extra/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# region imports\nfrom typing import Type\nfrom mistralai.extra import my_custom_function\n# endregion imports\n\nclass Chat(BaseSDK):\n    r\"\"\"Chat Completion API.\"\"\"\n\n    # region sdk-class-body\n    def my_custom_method(self, param: str) -> Type[some_type]:\n        output = my_custom_function(param1)\n        return output\n    # endregion sdk-class-body\n```\n\n----------------------------------------\n\nTITLE: Using models.ToolChoice Type\nDESCRIPTION: Demonstrates usage of the models.ToolChoice type for tool choice requests in chat completion streams.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionstreamrequesttoolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoice = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing WandbIntegration Model Output Type\nDESCRIPTION: Example showing the type annotation for a WandbIntegration output value using the models module. This demonstrates how to properly type WandbIntegration responses in the client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/integrations.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.WandbIntegrationOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining FunctionName Class Fields in Markdown\nDESCRIPTION: This markdown table defines the fields for the FunctionName class. It specifies a single required field 'name' of type string.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/functionname.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `name`             | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining ToolChoiceEnum Value Type\nDESCRIPTION: Demonstrates type annotation for a variable using the models.ToolChoiceEnum type in the Mistral AI client\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequesttoolchoice.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoiceEnum = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Mistral AI Python Client API Parameters in Markdown\nDESCRIPTION: This markdown table defines various parameters for the Mistral AI Python client API. It includes parameters for controlling randomness, response format, tool selection, and output characteristics like diversity and repetition.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequest.md#2025-04-17_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| `random_seed`                                                                                                                                                                                                                                                               | *OptionalNullable[int]*                                                                                                                                                                                                                                                     | :heavy_minus_sign:                                                                                                                                                                                                                                                          | The seed to use for random sampling. If set, different calls will generate deterministic results.                                                                                                                                                                           |                                                                                                                                                                                                                                                                             |\n| `response_format`                                                                                                                                                                                                                                                           | [Optional[models.ResponseFormat]](../models/responseformat.md)                                                                                                                                                                                                              | :heavy_minus_sign:                                                                                                                                                                                                                                                          | N/A                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                             |\n| `tools`                                                                                                                                                                                                                                                                     | List[[models.Tool](../models/tool.md)]                                                                                                                                                                                                                                      | :heavy_minus_sign:                                                                                                                                                                                                                                                          | N/A                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                             |\n| `tool_choice`                                                                                                                                                                                                                                                               | [Optional[models.AgentsCompletionStreamRequestToolChoice]](../models/agentscompletionstreamrequesttoolchoice.md)                                                                                                                                                            | :heavy_minus_sign:                                                                                                                                                                                                                                                          | N/A                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                             |\n| `presence_penalty`                                                                                                                                                                                                                                                          | *Optional[float]*                                                                                                                                                                                                                                                           | :heavy_minus_sign:                                                                                                                                                                                                                                                          | presence_penalty determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative.                                       |                                                                                                                                                                                                                                                                             |\n| `frequency_penalty`                                                                                                                                                                                                                                                         | *Optional[float]*                                                                                                                                                                                                                                                           | :heavy_minus_sign:                                                                                                                                                                                                                                                          | frequency_penalty penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition. |                                                                                                                                                                                                                                                                             |\n| `n`                                                                                                                                                                                                                                                                         | *OptionalNullable[int]*                                                                                                                                                                                                                                                     | :heavy_minus_sign:                                                                                                                                                                                                                                                          | Number of completions to return for each request, input tokens are only billed once.                                                                                                                                                                                        |                                                                                                                                                                                                                                                                             |\n```\n\n----------------------------------------\n\nTITLE: Model Schema Definition - Training Parameters\nDESCRIPTION: Schema definition for training-related parameters including tokens, epochs, and training steps. Documents data types and example values for each field in the model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/legacyjobmetadataout.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| `data_tokens` | *OptionalNullable[int]* | :heavy_minus_sign: | The total number of tokens in the training dataset. | 305375 |\n| `estimated_start_time` | *OptionalNullable[int]* | :heavy_minus_sign: | N/A | |\n| `deprecated` | *Optional[bool]* | :heavy_minus_sign: | N/A | |\n| `epochs` | *OptionalNullable[float]* | :heavy_minus_sign: | The number of complete passes through the entire training dataset. | 4.2922 |\n| `training_steps` | *OptionalNullable[int]* | :heavy_minus_sign: | The number of training steps to perform. A training step refers to a single update of the model weights during the fine-tuning process. This update is typically calculated using a batch of samples from the training dataset. | 10 |\n| `object` | [Optional[models.LegacyJobMetadataOutObject]](../models/legacyjobmetadataoutobject.md) | :heavy_minus_sign: | N/A | |\n```\n\n----------------------------------------\n\nTITLE: User Message Role Value Table\nDESCRIPTION: Markdown table defining the UserMessageRole enumeration value mapping USER to 'user' string literal.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/usermessagerole.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name   | Value  |\n| ------ | ------ |\n| `USER` | user   |\n```\n\n----------------------------------------\n\nTITLE: Initializing Completion Detailed Job Output Type - Python\nDESCRIPTION: Defines the type annotation for a completion detailed job output response from the fine-tuning API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningstartfinetuningjobresponse.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.CompletionDetailedJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Tool Message Role Constants - Markdown Table\nDESCRIPTION: Defines the TOOL constant with value 'tool' used to identify tool message roles in the messaging system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/toolmessagerole.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name   | Value  |\n| ------ | ------ |\n| `TOOL` | tool   |\n```\n\n----------------------------------------\n\nTITLE: WANDB Integration Type Enumeration Values\nDESCRIPTION: Defines the enumeration value for WANDB integration output type. The only defined value is 'WANDB' which maps to the string literal 'wandb'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/wandbintegrationouttype.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name    | Value   |\n| ------- | ------- |\n| `WANDB` | wandb   |\n```\n\n----------------------------------------\n\nTITLE: API Parameter Types in Markdown Table\nDESCRIPTION: Defines parameter types for job_type, events and checkpoints fields with their respective model references and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierdetailedjobout.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| `job_type` | [Optional[models.ClassifierDetailedJobOutJobType]](../models/classifierdetailedjoboutjobtype.md) | :heavy_minus_sign: | N/A |\n| `events` | List[[models.EventOut](../models/eventout.md)] | :heavy_minus_sign: | Event items are created every time the status of a fine-tuning job changes. The timestamped list of all events is accessible here. |\n| `checkpoints` | List[[models.CheckpointOut](../models/checkpointout.md)] | :heavy_minus_sign: | N/A |\n```\n\n----------------------------------------\n\nTITLE: Defining OCRPageDimensions Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the OCRPageDimensions class using a markdown table. It specifies three required integer fields: dpi (dots per inch), height (in pixels), and width (in pixels).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ocrpagedimensions.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                           | Type                            | Required                        | Description                     |\n| ------------------------------- | ------------------------------- | ------------------------------- | ------------------------------- |\n| `dpi`                           | *int*                           | :heavy_check_mark:              | Dots per inch of the page-image |\n| `height`                        | *int*                           | :heavy_check_mark:              | Height of the image in pixels   |\n| `width`                         | *int*                           | :heavy_check_mark:              | Width of the image in pixels    |\n```\n\n----------------------------------------\n\nTITLE: Defining ToolTypes Enumeration in Python for Mistral AI Client\nDESCRIPTION: This code snippet defines an enumeration called ToolTypes with a single value 'FUNCTION'. It is likely used to categorize or identify different types of tools or functionalities within the Mistral AI Python client library.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/tooltypes.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nFUNCTION = function\n```\n\n----------------------------------------\n\nTITLE: JobsAPIRoutesBatchGetBatchJobRequest Fields Table in Markdown\nDESCRIPTION: Markdown table defining the fields for JobsAPIRoutesBatchGetBatchJobRequest model. Contains a single required field 'job_id' of type string.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesbatchgetbatchjobrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `job_id`           | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Security Fields Documentation Table in Markdown\nDESCRIPTION: Markdown table documenting the security configuration fields, specifically the required api_key field of type string.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/security.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `api_key`          | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining ClassifierTrainingParametersIn in Python for Mistral AI\nDESCRIPTION: This code shows the declaration of a ClassifierTrainingParametersIn variable from the models module. It's used to configure hyperparameters for classifier training tasks.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/hyperparameters.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ClassifierTrainingParametersIn = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ClassifierFTModelOutObject Constants in Markdown\nDESCRIPTION: Defines the constant MODEL with a string value of 'model' using a markdown table format. This appears to be part of a client Python library for Mistral AI.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierftmodeloutobject.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name    | Value   |\n| ------- | ------- |\n| `MODEL` | model   |\n```\n\n----------------------------------------\n\nTITLE: Initializing models.Response1 in Python\nDESCRIPTION: Creates an instance of the models.Response1 class. This class is likely used to represent a response from the Jobs API for creating a fine-tuning job.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningcreatefinetuningjobresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.Response1 = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining FIMCompletionStreamRequest Class in Python\nDESCRIPTION: This code defines the FIMCompletionStreamRequest class with various attributes for handling streaming completion requests. It includes fields for model, prompt, options, and other parameters relevant to the completion process.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/fimcompletionstreamrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# FIMCompletionStreamRequest\n```\n\n----------------------------------------\n\nTITLE: Server URL Override\nDESCRIPTION: Example showing how to override the server URL globally when initializing the SDK client. The code demonstrates setting a custom server URL.\nSOURCE: https://github.com/mistralai/client-python/blob/main/README.md#2025-04-17_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai import Mistral\nimport os\n\n\nwith Mistral(\n    server_url=\"https://api.mistral.ai\",\n    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\"),\n) as mistral:\n\n    res = mistral.models.list()\n\n    # Handle response\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: OCRPageObject Field Definitions in Markdown\nDESCRIPTION: Markdown table defining the fields, types, requirements and descriptions for the OCRPageObject class. Includes index, markdown content, images list, and page dimensions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ocrpageobject.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                | Type                                                                 | Required                                                             | Description                                                          |\n| -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| `index`                                                              | *int*                                                                | :heavy_check_mark:                                                   | The page index in a pdf document starting from 0                     |\n| `markdown`                                                           | *str*                                                                | :heavy_check_mark:                                                   | The markdown string response of the page                             |\n| `images`                                                             | List[[models.OCRImageObject]](../models/ocrimageobject.md)]           | :heavy_check_mark:                                                   | List of all extracted images in the page                             |\n| `dimensions`                                                         | [Nullable[models.OCRPageDimensions]](../models/ocrpagedimensions.md) | :heavy_check_mark:                                                   | The dimensions of the PDF Page's screenshot image                    |\n```\n\n----------------------------------------\n\nTITLE: Defining FTModelCardType Constants in Markdown Table\nDESCRIPTION: A markdown table that defines the FTModelCardType constants, specifically the FINE_TUNED constant with a value of 'fine-tuned'. This appears to be used to categorize model cards in the Mistral AI client library.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/ftmodelcardtype.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name         | Value        |\n| ------------ | ------------ |\n| `FINE_TUNED` | fine-tuned   |\n```\n\n----------------------------------------\n\nTITLE: Defining System Message Type - Python\nDESCRIPTION: Example of declaring a SystemMessage type variable for agent completions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionrequestmessages.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.SystemMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: EventOut Model Fields Definition\nDESCRIPTION: Documents the fields of the EventOut model including name (string), created_at (unix timestamp), and an optional data dictionary. Name and created_at are required fields while data is optional.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/eventout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                         | Type                                          | Required                                      | Description                                   |\n| --------------------------------------------- | --------------------------------------------- | --------------------------------------------- | --------------------------------------------- |\n| `name`                                        | *str*                                         | :heavy_check_mark:                            | The name of the event.                        |\n| `created_at`                                  | *int*                                         | :heavy_check_mark:                            | The UNIX timestamp (in seconds) of the event. |\n| `data`                                        | Dict[str, *Any*]                              | :heavy_minus_sign:                            | N/A                                           |\n```\n\n----------------------------------------\n\nTITLE: Defining Completion Fine-Tuned Model Output Type\nDESCRIPTION: Type definition for completion fine-tuned model output response using models.CompletionFTModelOut.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningupdatefinetunedmodelresponse.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.CompletionFTModelOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining InstructRequestInputs Structure in Markdown\nDESCRIPTION: Markdown table documenting the structure of the InstructRequestInputs class, showing that it requires a list of InstructRequestInputsMessages objects as its only field.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequestinputs.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                    | Type                                                                                     | Required                                                                                 | Description                                                                              |\n| ---------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- |\n| `messages`                                                                               | List[[models.InstructRequestInputsMessages](../models/instructrequestinputsmessages.md)] | :heavy_check_mark:                                                                       | N/A                                                                                      |\n```\n\n----------------------------------------\n\nTITLE: Defining WandbIntegrationOut Model in Python\nDESCRIPTION: This code snippet defines a value of type models.WandbIntegrationOut. It's likely part of a larger class or type definition for ClassifierDetailedJobOutIntegrations.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierdetailedjoboutintegrations.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.WandbIntegrationOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining BatchJobsOutObject Enum Value\nDESCRIPTION: Defines a single enum value LIST for batch job output types. This enum is used to specify the output format for batch processing jobs.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/batchjobsoutobject.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nLIST = list\n```\n\n----------------------------------------\n\nTITLE: Markdown Table of Request Parameters\nDESCRIPTION: Defines the fields, types, requirements and examples for unarchiving a fine-tuned model. The table shows that model_id is a required string parameter that identifies the specific model to be unarchived.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningunarchivefinetunedmodelrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                         | Type                                          | Required                                      | Description                                   | Example                                       |\n| --------------------------------------------- | --------------------------------------------- | --------------------------------------------- | --------------------------------------------- | --------------------------------------------- |\n| `model_id`                                    | *str*                                         | :heavy_check_mark:                            | The ID of the model to unarchive.             | ft:open-mistral-7b:587a6b29:20240514:7e773925 |\n```\n\n----------------------------------------\n\nTITLE: Server URL Override\nDESCRIPTION: Example demonstrating how to override the default server URL globally for the SDK client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/README.md#2025-04-17_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_azure import MistralAzure\nimport os\n\ns = MistralAzure(\n    server_url=\"https://api.mistral.ai\",\n    azure_api_key=os.getenv(\"AZURE_API_KEY\", \"\"),\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\", \"\")\n)\n\n\nres = s.chat.stream(messages=[\n    {\n        \"content\": \"Who is the best French painter? Answer in one short sentence.\",\n        \"role\": \"user\",\n    },\n], model=\"azureai\")\n\nif res is not None:\n    for event in res:\n        # handle event\n        print(event)\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionJobOut Model Type\nDESCRIPTION: Example showing the type annotation for a CompletionJobOut model value from the models package.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsoutdata.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.CompletionJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining InstructRequest Fields in Markdown\nDESCRIPTION: This markdown table defines the 'messages' field of the InstructRequest class. It specifies the field type, whether it's required, and provides a description.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/instructrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                        | Type                                                                         | Required                                                                     | Description                                                                  |\n| ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |\n| `messages`                                                                   | List[[models.InstructRequestMessages](../models/instructrequestmessages.md)] | :heavy_check_mark:                                                           | N/A                                                                          |\n```\n\n----------------------------------------\n\nTITLE: Initializing DocumentURLChunk Model in Python\nDESCRIPTION: Example showing the type annotation for a DocumentURLChunk model value. Used for processing documents via URL in OCR operations.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/document.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.DocumentURLChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ChatCompletionRequestStop as String in Python\nDESCRIPTION: Specifies a single token as a string to stop generation if detected. The value is of type str.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionrequeststop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining JobsAPIRoutesFineTuningArchiveFineTunedModelRequest Fields in Markdown\nDESCRIPTION: This snippet defines the fields for the JobsAPIRoutesFineTuningArchiveFineTunedModelRequest object. It specifies the 'model_id' field as a required string, used to identify the model to be archived.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningarchivefinetunedmodelrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                         | Type                                          | Required                                      | Description                                   | Example                                       |\n| --------------------------------------------- | --------------------------------------------- | --------------------------------------------- | --------------------------------------------- | --------------------------------------------- |\n| `model_id`                                    | *str*                                         | :heavy_check_mark:                            | The ID of the model to archive.               | ft:open-mistral-7b:587a6b29:20240514:7e773925 |\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionResponseStreamChoiceFinishReason Enum Values in Markdown\nDESCRIPTION: This table defines the possible values for the CompletionResponseStreamChoiceFinishReason enumeration in the Mistral AI Python client. It includes four finish reasons: STOP (normal completion), LENGTH (response reached maximum length), ERROR (an error occurred), and TOOL_CALLS (completion ended due to tool calls).\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completionresponsestreamchoicefinishreason.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name         | Value        |\n| ------------ | ------------ |\n| `STOP`       | stop         |\n| `LENGTH`     | length       |\n| `ERROR`      | error        |\n| `TOOL_CALLS` | tool_calls   |\n```\n\n----------------------------------------\n\nTITLE: Single String Stop Token Configuration\nDESCRIPTION: Defines a single stop token as a string value to halt text generation when this token is detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/stop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Uploading Files with Custom Filename in Bash\nDESCRIPTION: Example of how to upload a file with a custom filename in a bash request. This shows the syntax for specifying both the file path and a custom filename in the request.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/filesapiroutesuploadfilemultipartbodyparams.md#2025-04-17_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nfile=@path/to/your/file.jsonl;filename=custom_name.jsonl\n```\n\n----------------------------------------\n\nTITLE: Initializing ToolMessage in Mistral AI Python Client\nDESCRIPTION: Creates an instance of the ToolMessage type. This message type could be used for messages related to specific tools or functionalities within the AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/one.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ModelType Enumeration in Python\nDESCRIPTION: This code snippet defines an enumeration called ModelType with a single value COMPLETION. It uses a class-based approach to define the enumeration, which is common in Python for creating constants or enums.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/modeltype.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass ModelType:\n    COMPLETION = \"completion\"\n```\n\n----------------------------------------\n\nTITLE: Defining Classifier Job Response Type\nDESCRIPTION: Type definition for classifier detailed job output response from the fine-tuning API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuninggetfinetuningjobresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ClassifierDetailedJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: API Request Field Documentation in Markdown\nDESCRIPTION: Documents the required fields for retrieving a fine-tuning job, specifying the job_id parameter as a required string value used to identify the specific fine-tuning job to analyze.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuninggetfinetuningjobrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                         | Type                          | Required                      | Description                   |\n| ----------------------------- | ----------------------------- | ----------------------------- | ----------------------------- |\n| `job_id`                      | *str*                         | :heavy_check_mark:            | The ID of the job to analyse. |\n```\n\n----------------------------------------\n\nTITLE: Initializing ImageURLChunk in Python for Mistral AI Client\nDESCRIPTION: This snippet demonstrates how to create an instance of the ImageURLChunk class from the models module. It's used to represent image content in the Mistral AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/contentchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ImageURLChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining BackoffStrategy Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the BackoffStrategy class using a markdown table. It includes the field names, types, descriptions, and examples for initial_interval, max_interval, exponent, and max_elapsed_time.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/utils/retryconfig.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Name               | Type      | Description                               | Example  |\n| ------------------ | --------- | ----------------------------------------- | -------- |\n| `initial_interval` | `*int*`   | The initial interval in milliseconds.     | `500`    |\n| `max_interval`     | `*int*`   | The maximum interval in milliseconds.     | `60000`  |\n| `exponent`         | `*float*` | The exponent to use for the backoff.      | `1.5`    |\n| `max_elapsed_time` | `*int*`   | The maximum elapsed time in milliseconds. | `300000` |\n```\n\n----------------------------------------\n\nTITLE: Defining Classifier Fine-Tuned Model Output Type\nDESCRIPTION: Type definition for classifier fine-tuned model output response using models.ClassifierFTModelOut.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningupdatefinetunedmodelresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ClassifierFTModelOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ClassifierJobOutJobType Enum in Python\nDESCRIPTION: This enum defines the possible job types for classifier jobs in the Mistral AI platform. Currently, it only includes the 'CLASSIFIER' type with a value of 'classifier'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierjoboutjobtype.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n| Name         | Value        |\n| ------------ | ------------ |\n| `CLASSIFIER` | classifier   |\n```\n\n----------------------------------------\n\nTITLE: Defining SampleType Enum in Markdown Table\nDESCRIPTION: This snippet presents a Markdown table that defines the SampleType enum. It lists the enum names and their corresponding string values, which are likely used in a machine learning or data processing context.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/sampletype.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name            | Value           |\n| --------------- | --------------- |\n| `PRETRAIN`      | pretrain        |\n| `INSTRUCT`      | instruct        |\n| `BATCH_REQUEST` | batch_request   |\n| `BATCH_RESULT`  | batch_result    |\n| `BATCH_ERROR`   | batch_error     |\n```\n\n----------------------------------------\n\nTITLE: Defining str for ImageURL in Python\nDESCRIPTION: This snippet shows the declaration of a string variable that can be used to represent an image URL. The specific value assignment is not provided and should be replaced with an actual URL string.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/imageurlchunkimageurl.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Building SDK with Custom Code in Bash\nDESCRIPTION: Command to build the SDK with custom code, removing existing distribution, building with poetry, and installing the new wheel file.\nSOURCE: https://github.com/mistralai/client-python/blob/main/src/mistralai/extra/README.md#2025-04-17_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nrm -rf dist; poetry build; python3 -m pip install ~/client-python/dist/mistralai-1.4.1-py3-none-any.whl --force-reinstall\n```\n\n----------------------------------------\n\nTITLE: Initializing UserMessage in Mistral AI Python Client\nDESCRIPTION: Creates an instance of the UserMessage type. This message type is likely used to represent input or messages from the user interacting with the AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/one.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: FilesAPIRoutesDownloadFileRequest Field Documentation in Markdown\nDESCRIPTION: A markdown table documenting the required field for the FilesAPIRoutesDownloadFileRequest class. The file_id field is of type string and is marked as required for making file download requests in the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/filesapiroutesdownloadfilerequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `file_id`          | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining Completion Job Output Type\nDESCRIPTION: Type definition for completion detailed job output response when canceling a fine-tuning job.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningcancelfinetuningjobresponse.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.CompletionDetailedJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using GithubRepositoryOut Model in CompletionDetailedJobOutRepositories\nDESCRIPTION: Example code showing how to use the GithubRepositoryOut model with CompletionDetailedJobOutRepositories. The code demonstrates the value assignment pattern with this model type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completiondetailedjoboutrepositories.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.GithubRepositoryOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Installing Mistral Python Client via pip\nDESCRIPTION: This command installs the Mistral Python client package using pip, the Python package installer.\nSOURCE: https://github.com/mistralai/client-python/blob/main/OLD-README.md#2025-04-17_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install mistralai\n```\n\n----------------------------------------\n\nTITLE: Defining BASE Constant for MistralAI Model Type in Python\nDESCRIPTION: Declares a constant value 'BASE' with the string value 'base' to represent the base model type in the MistralAI Python client. This constant can be used to specify model types when making API calls or configuring the client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/type.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nBASE = \"base\"\n```\n\n----------------------------------------\n\nTITLE: Defining BaseModelCard Type in Python for Model Retrieval Response\nDESCRIPTION: This code snippet defines a possible value for the 'value' attribute of the response class. It specifies that the value can be of type models.BaseModelCard, which likely represents the basic information of a model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/retrievemodelv1modelsmodelidgetresponseretrievemodelv1modelsmodelidget.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.BaseModelCard = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Running example script using poetry run\nDESCRIPTION: These commands navigate to the examples directory and run a Python script using poetry run, which executes the script within the project's virtual environment.\nSOURCE: https://github.com/mistralai/client-python/blob/main/OLD-README.md#2025-04-17_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd examples\npoetry run python chat_no_streaming.py\n```\n\n----------------------------------------\n\nTITLE: Declaring ToolMessage Type in Python\nDESCRIPTION: Example of declaring a ToolMessage type variable for Mistral AI client\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/messages.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Declaring str Argument in Python for Mistral AI Client\nDESCRIPTION: This snippet demonstrates the declaration of a variable of type str, which represents a string in Python. String arguments are frequently used in the Mistral AI client for various text-based inputs.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/arguments.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining SystemMessage Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the SystemMessage class. It includes the field names, their types, whether they are required, and a description column (which is empty in this case).\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/systemmessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                            | Type                                                             | Required                                                         | Description                                                      |\n| ---------------------------------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------- |\n| `content`                                                        | [models.SystemMessageContent](../models/systemmessagecontent.md) | :heavy_check_mark:                                               | N/A                                                              |\n| `role`                                                           | [Optional[models.Role]](../models/role.md)                       | :heavy_minus_sign:                                               | N/A                                                              |\n```\n\n----------------------------------------\n\nTITLE: Model Retrieval Request Fields Documentation in Markdown\nDESCRIPTION: Documents the required fields for making a model retrieval request, specifically the model_id parameter which must be provided as a string to identify the target model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/retrievemodelv1modelsmodelidgetrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                         | Type                                          | Required                                      | Description                                   | Example                                       |\n| --------------------------------------------- | --------------------------------------------- | --------------------------------------------- | --------------------------------------------- | --------------------------------------------- |\n| `model_id`                                    | *str*                                         | :heavy_check_mark:                            | The ID of the model to retrieve.              | ft:open-mistral-7b:587a6b29:20240514:7e773925 |\n```\n\n----------------------------------------\n\nTITLE: Using WandbIntegrationOut with ClassifierJobOutIntegrations in Python\nDESCRIPTION: Example of how to use WandbIntegrationOut with ClassifierJobOutIntegrations. The WandbIntegrationOut is a supported type for ClassifierJobOutIntegrations, allowing integration with Weights & Biases for classifier job outputs.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierjoboutintegrations.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.WandbIntegrationOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining BackoffStrategy Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the BackoffStrategy class using a Markdown table. It includes the field names, types, descriptions, and examples for configuring exponential backoff.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/utils/retryconfig.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Name               | Type      | Description                               | Example  |\n| ------------------ | --------- | ----------------------------------------- | -------- |\n| `initial_interval` | `*int*`   | The initial interval in milliseconds.     | `500`    |\n| `max_interval`     | `*int*`   | The maximum interval in milliseconds.     | `60000`  |\n| `exponent`         | `*float*` | The exponent to use for the backoff.      | `1.5`    |\n| `max_elapsed_time` | `*int*`   | The maximum elapsed time in milliseconds. | `300000` |\n```\n\n----------------------------------------\n\nTITLE: Defining Completion Job Response Type\nDESCRIPTION: Type definition for completion detailed job output response from the fine-tuning API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuninggetfinetuningjobresponse.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.CompletionDetailedJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining FineTuning Class for MistralAI Python Client\nDESCRIPTION: This code snippet defines the FineTuning class, which is likely used to manage fine-tuning operations in the MistralAI Python client. The class is decorated with @attrs.define, suggesting it uses the attrs library for class creation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/finetuning/README.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n@attrs.define\nclass FineTuning:\n```\n\n----------------------------------------\n\nTITLE: Example Agent Completion Request Message in JSON\nDESCRIPTION: Demonstrates the structure of a message in the 'messages' parameter for an agent completion request. It shows a user role with a content asking about the best French painter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/agents/README.md#2025-04-17_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"role\": \"user\",\n    \"content\": \"Who is the best French painter? Answer in one short sentence.\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Collecting Environment Information using Node.js\nDESCRIPTION: Command to gather system environment information using the envinfo NPM package for issue reporting purposes.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/CONTRIBUTING.md#2025-04-17_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx envinfo\n```\n\n----------------------------------------\n\nTITLE: Example Parameter Usage in Python\nDESCRIPTION: Example showing the code completion model parameter, demonstrating the basic format of a function definition prompt.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/fim/README.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef\n```\n\n----------------------------------------\n\nTITLE: Instantiating ReferenceChunk in Mistral AI Python Client\nDESCRIPTION: This snippet illustrates the creation of a ReferenceChunk instance from the models module. ReferenceChunk probably represents referential or linked content within the Mistral AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/contentchunk.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ReferenceChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining JobsAPIRoutesFineTuningUpdateFineTunedModelRequest Fields in Markdown\nDESCRIPTION: This markdown table outlines the fields required for updating a fine-tuned model. It includes the model_id as a string and update_ft_model_in as an UpdateFTModelIn object, both of which are mandatory for the request.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningupdatefinetunedmodelrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                  | Type                                                   | Required                                               | Description                                            | Example                                                |\n| ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ |\n| `model_id`                                             | *str*                                                  | :heavy_check_mark:                                     | The ID of the model to update.                         | ft:open-mistral-7b:587a6b29:20240514:7e773925          |\n| `update_ft_model_in`                                   | [models.UpdateFTModelIn](../models/updateftmodelin.md) | :heavy_check_mark:                                     | N/A                                                    |                                                        |\n```\n\n----------------------------------------\n\nTITLE: Defining Jobs Output Object Values\nDESCRIPTION: Enumerates the possible values for Jobs API output objects, defining LIST as a constant value.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsoutobject.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name   | Value  |\n| ------ | ------ |\n| `LIST` | list   |\n```\n\n----------------------------------------\n\nTITLE: Initializing AssistantMessage in Mistral AI Python Client\nDESCRIPTION: Example of creating an AssistantMessage object in the Mistral AI Python client. AssistantMessage represents a message generated by the AI assistant.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/messages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ClassifierDetailedJobOutObject Enum in Python\nDESCRIPTION: This code snippet defines an enum called ClassifierDetailedJobOutObject with a single value 'JOB'. It uses a simple key-value pair structure to represent the enum.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierdetailedjoboutobject.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nClassifierDetailedJobOutObject:\n    JOB = \"job\"\n```\n\n----------------------------------------\n\nTITLE: Defining FTModelCard Type in Python for Model Retrieval Response\nDESCRIPTION: This code snippet defines another possible value for the 'value' attribute of the response class. It specifies that the value can be of type models.FTModelCard, which likely represents information for a fine-tuned model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/retrievemodelv1modelsmodelidgetresponseretrievemodelv1modelsmodelidget.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.FTModelCard = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Installing poetry for dependency management\nDESCRIPTION: This command installs poetry, a dependency and virtual environment manager for Python projects.\nSOURCE: https://github.com/mistralai/client-python/blob/main/OLD-README.md#2025-04-17_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install poetry\n```\n\n----------------------------------------\n\nTITLE: Defining BatchJobOutObject Enumeration Values in Markdown\nDESCRIPTION: A markdown table that documents the available values in the BatchJobOutObject enumeration, showing that the name 'BATCH' corresponds to the value 'batch'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/batchjoboutobject.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name    | Value   |\n| ------- | ------- |\n| `BATCH` | batch   |\n```\n\n----------------------------------------\n\nTITLE: Field Specifications Table in Markdown\nDESCRIPTION: A markdown table defining the fields, types, requirements, and descriptions for classifier job outputs. Includes both required fields like id, model, status and optional fields like validation_files and metadata.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierdetailedjobout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                                                                              | Type                                                                                                                               | Required                                                                                                                           | Description                                                                                                                        |\n| ---------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |\n| `id`                                                                                                                               | *str*                                                                                                                              | :heavy_check_mark:                                                                                                                 | N/A                                                                                                                                |\n| `auto_start`                                                                                                                       | *bool*                                                                                                                             | :heavy_check_mark:                                                                                                                 | N/A                                                                                                                                |\n| `model`                                                                                                                            | *str*                                                                                                                              | :heavy_check_mark:                                                                                                                 | The name of the model to fine-tune.                                                                                                |\n| `status`                                                                                                                           | [models.ClassifierDetailedJobOutStatus](../models/classifierdetailedjoboutstatus.md)                                               | :heavy_check_mark:                                                                                                                 | N/A                                                                                                                                |\n| `created_at`                                                                                                                       | *int*                                                                                                                              | :heavy_check_mark:                                                                                                                 | N/A                                                                                                                                |\n| `modified_at`                                                                                                                      | *int*                                                                                                                              | :heavy_check_mark:                                                                                                                 | N/A                                                                                                                                |\n| `training_files`                                                                                                                   | List[*str*]                                                                                                                        | :heavy_check_mark:                                                                                                                 | N/A                                                                                                                                |\n| `hyperparameters`                                                                                                                  | [models.ClassifierTrainingParameters](../models/classifiertrainingparameters.md)                                                   | :heavy_check_mark:                                                                                                                 | N/A                                                                                                                                |\n| `classifier_targets`                                                                                                               | List[[models.ClassifierTargetOut](../models/classifiertargetout.md)]                                                               | :heavy_check_mark:                                                                                                                 | N/A                                                                                                                                |\n| `validation_files`                                                                                                                 | List[*str*]                                                                                                                        | :heavy_minus_sign:                                                                                                                 | N/A                                                                                                                                |\n| `object`                                                                                                                           | [Optional[models.ClassifierDetailedJobOutObject]](../models/classifierdetailedjoboutobject.md)                                     | :heavy_minus_sign:                                                                                                                 | N/A                                                                                                                                |\n| `fine_tuned_model`                                                                                                                 | *OptionalNullable[str]*                                                                                                            | :heavy_minus_sign:                                                                                                                 | N/A                                                                                                                                |\n| `suffix`                                                                                                                           | *OptionalNullable[str]*                                                                                                            | :heavy_minus_sign:                                                                                                                 | N/A                                                                                                                                |\n| `integrations`                                                                                                                     | List[[models.ClassifierDetailedJobOutIntegrations](../models/classifierdetailedjoboutintegrations.md)]                             | :heavy_minus_sign:                                                                                                                 | N/A                                                                                                                                |\n| `trained_tokens`                                                                                                                   | *OptionalNullable[int]*                                                                                                            | :heavy_minus_sign:                                                                                                                 | N/A                                                                                                                                |\n| `metadata`                                                                                                                         | [OptionalNullable[models.JobMetadataOut]](../models/jobmetadataout.md)                                                             | :heavy_minus_sign:                                                                                                                 | N/A                                                                                                                                |\n```\n\n----------------------------------------\n\nTITLE: Defining JobsAPIRoutesFineTuningCancelFineTuningJobRequest Class Fields in Markdown\nDESCRIPTION: This markdown table defines the fields for the JobsAPIRoutesFineTuningCancelFineTuningJobRequest class. It specifies the 'job_id' field, which is a required string parameter used to identify the fine-tuning job that should be canceled.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningcancelfinetuningjobrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                        | Type                         | Required                     | Description                  |\n| ---------------------------- | ---------------------------- | ---------------------------- | ---------------------------- |\n| `job_id`                     | *str*                        | :heavy_check_mark:           | The ID of the job to cancel. |\n```\n\n----------------------------------------\n\nTITLE: Declaring str type in Python\nDESCRIPTION: This snippet shows the declaration of a variable of type str. The specific value assignment is not provided.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/imageurlchunkimageurl.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing GithubRepositoryIn Model in Python\nDESCRIPTION: This snippet demonstrates how to create an instance of the GithubRepositoryIn model. This model appears to be used for specifying GitHub repository information as input to certain operations in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobinrepositories.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.GithubRepositoryIn = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionFTModelOutObject Enum in Python\nDESCRIPTION: This code snippet defines an enum called CompletionFTModelOutObject with a single value 'MODEL' set to 'model'. This enum is likely used for specifying model output options in a completion or fine-tuning context.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completionftmodeloutobject.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# CompletionFTModelOutObject\n\n\n## Values\n\n| Name    | Value   |\n| ------- | ------- |\n| `MODEL` | model   |\n```\n\n----------------------------------------\n\nTITLE: System Role Value Definition in Markdown Table\nDESCRIPTION: Defines the system role constant SYSTEM with value 'system' using a markdown table format. This constant is likely used to identify system messages in chat conversations.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/role.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name     | Value    |\n| -------- | -------- |\n| `SYSTEM` | system   |\n```\n\n----------------------------------------\n\nTITLE: Initializing ClassifierJobOut Model in Python\nDESCRIPTION: This snippet demonstrates how to initialize a ClassifierJobOut model from the Mistral AI Python client. It uses the models module to create an instance of ClassifierJobOut.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/response1.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ClassifierJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Batch Operations Section Headers in Markdown\nDESCRIPTION: Basic markdown structure defining sections for batch operations documentation, including overview and available operations sections.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/batch/README.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Batch\n(*batch*)\n\n## Overview\n\n### Available Operations\n```\n\n----------------------------------------\n\nTITLE: Defining UnarchiveFTModelOutObject Enum in Python\nDESCRIPTION: This code snippet defines an enum class 'UnarchiveFTModelOutObject' with a single value 'MODEL'. It is likely used to represent the output of unarchiving a fine-tuned model.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/unarchiveftmodeloutobject.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# UnarchiveFTModelOutObject\n\n\n## Values\n\n| Name    | Value   |\n| ------- | ------- |\n| `MODEL` | model   |\n```\n\n----------------------------------------\n\nTITLE: Defining UpdateFTModelIn Class Fields in Markdown\nDESCRIPTION: This markdown table defines the fields for the UpdateFTModelIn class. It specifies two optional fields: 'name' and 'description', both of type OptionalNullable[str].\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/updateftmodelin.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                   | Type                    | Required                | Description             |\n| ----------------------- | ----------------------- | ----------------------- | ----------------------- |\n| `name`                  | *OptionalNullable[str]* | :heavy_minus_sign:      | N/A                     |\n| `description`           | *OptionalNullable[str]* | :heavy_minus_sign:      | N/A                     |\n```\n\n----------------------------------------\n\nTITLE: Defining ImageURLChunk Model Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the ImageURLChunk model using a markdown table. It specifies the field names, types, requirements, and descriptions for 'image_url' and 'type' fields.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/imageurlchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                | Type                                                                 | Required                                                             | Description                                                          |\n| -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- |\n| `image_url`                                                          | [models.ImageURLChunkImageURL](../models/imageurlchunkimageurl.md)   | :heavy_check_mark:                                                   | N/A                                                                  |\n| `type`                                                               | [Optional[models.ImageURLChunkType]](../models/imageurlchunktype.md) | :heavy_minus_sign:                                                   | N/A                                                                  |\n```\n\n----------------------------------------\n\nTITLE: Defining TextChunkType Enumeration in Python\nDESCRIPTION: This code snippet defines an enumeration called TextChunkType with a single value 'TEXT' that corresponds to the string 'text'. This enumeration is likely used to specify the type of text chunks in a larger system or API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/textchunktype.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# TextChunkType\n\n\n## Values\n\n| Name   | Value  |\n| ------ | ------ |\n| `TEXT` | text   |\n```\n\n----------------------------------------\n\nTITLE: Defining ToolCall Fields in Markdown Table\nDESCRIPTION: This markdown table defines the fields of the ToolCall model, including their types, requirements, and descriptions. It covers the function, id, type, and index fields, specifying their data types and whether they are required or optional.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/toolcall.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                | Type                                                 | Required                                             | Description                                          |\n| ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- |\n| `function`                                           | [models.FunctionCall](../models/functioncall.md)     | :heavy_check_mark:                                   | N/A                                                  |\n| `id`                                                 | *Optional[str]*                                      | :heavy_minus_sign:                                   | N/A                                                  |\n| `type`                                               | [Optional[models.ToolTypes]](../models/tooltypes.md) | :heavy_minus_sign:                                   | N/A                                                  |\n| `index`                                              | *Optional[int]*                                      | :heavy_minus_sign:                                   | N/A                                                  |\n```\n\n----------------------------------------\n\nTITLE: Defining ReferenceChunkType Enum in Python\nDESCRIPTION: This code snippet defines an enum called ReferenceChunkType with a single value 'REFERENCE'. The enum is likely used to specify the type of chunk in a reference system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/referencechunktype.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# ReferenceChunkType\n\n\n## Values\n\n| Name        | Value       |\n| ----------- | ----------- |\n| `REFERENCE` | reference   |\n```\n\n----------------------------------------\n\nTITLE: Defining ReferenceChunk Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ReferenceChunk model. It specifies two fields: 'reference_ids' as a required list of integers, and 'type' as an optional ReferenceChunkType.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/referencechunk.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                  | Type                                                                   | Required                                                               | Description                                                            |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| `reference_ids`                                                        | List[*int*]                                                            | :heavy_check_mark:                                                     | N/A                                                                    |\n| `type`                                                                 | [Optional[models.ReferenceChunkType]](../models/referencechunktype.md) | :heavy_minus_sign:                                                     | N/A                                                                    |\n```\n\n----------------------------------------\n\nTITLE: Initializing ImageURLChunk Model in Python\nDESCRIPTION: Example showing the type annotation for an ImageURLChunk model value. Used for processing images via URL in OCR operations.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/document.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ImageURLChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Integer Location Type in Python\nDESCRIPTION: This snippet shows how to define a location value as an integer type in Python. The specific integer value would be assigned in place of the comment.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/loc.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: int = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Declaring models.ImageURL in Python\nDESCRIPTION: This snippet demonstrates how to declare a variable of type models.ImageURL. The actual value assignment is not shown.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/imageurlchunkimageurl.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ImageURL = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Tool Object Fields in Markdown\nDESCRIPTION: This markdown table defines the structure of a Tool object with two fields: 'function' and 'type'. The 'function' field is required and of type 'models.Function', while the 'type' field is optional and of type 'models.ToolTypes'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/tool.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                | Type                                                 | Required                                             | Description                                          |\n| ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- |\n| `function`                                           | [models.Function](../models/function.md)             | :heavy_check_mark:                                   | N/A                                                  |\n| `type`                                               | [Optional[models.ToolTypes]](../models/tooltypes.md) | :heavy_minus_sign:                                   | N/A                                                  |\n```\n\n----------------------------------------\n\nTITLE: Integer Type Declaration in Python\nDESCRIPTION: Demonstrates the type annotation for integer values in Python using type hints.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/loc.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: int = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ImageURLChunk Structure\nDESCRIPTION: Example structure of an ImageURLChunk object showing base64 encoded image URL format. The structure contains two main fields: image_url (required) and type (optional).\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/imageurlchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"type\":\"image_url\",\"image_url\":{\"url\":\"data:image/png;base64,iVBORw0\n```\n\n----------------------------------------\n\nTITLE: Using FTModelCard Model Type\nDESCRIPTION: Example showing the type annotation for FTModelCard (Fine-Tuned Model Card) values in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/data.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.FTModelCard = /* values here */\n```\n\n----------------------------------------\n\nTITLE: RetryConfig Fields Documentation in Markdown\nDESCRIPTION: Markdown table defining the fields available in RetryConfig including strategy type, backoff configuration, and connection error retry settings.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/utils/retryconfig.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                      | Type                                | Description                             | Example   |\n| ------------------------- | ----------------------------------- | --------------------------------------- | --------- |\n| `strategy`                | `*str*`                             | The retry strategy to use.              | `backoff` |\n| `backoff`                 | [BackoffStrategy](#backoffstrategy) | Configuration for the backoff strategy. |           |\n| `retry_connection_errors` | `*bool*`                            | Whether to retry on connection errors.  | `true`    |\n```\n\n----------------------------------------\n\nTITLE: Reloading the environment\nDESCRIPTION: This command reloads the zsh environment to apply the newly added API key variable.\nSOURCE: https://github.com/mistralai/client-python/blob/main/OLD-README.md#2025-04-17_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsource ~/.zshenv\n```\n\n----------------------------------------\n\nTITLE: Response Format Values Table\nDESCRIPTION: A markdown table defining the available response format constants and their corresponding values. Includes TEXT, JSON_OBJECT, and JSON_SCHEMA format types.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/responseformats.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name          | Value         |\n| ------------- | ------------- |\n| `TEXT`        | text          |\n| `JSON_OBJECT` | json_object   |\n| `JSON_SCHEMA` | json_schema   |\n```\n\n----------------------------------------\n\nTITLE: Using BaseModelCard Model Type\nDESCRIPTION: Example showing the type annotation for BaseModelCard model values in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/data.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.BaseModelCard = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining Fine-Tuning Job Status Values in Markdown\nDESCRIPTION: This code snippet defines a table of status values for fine-tuning jobs. It includes various stages such as queued, started, running, and different completion states like success, failure, and cancellation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/status.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                     | Value                    |\n| ------------------------ | ------------------------ |\n| `QUEUED`                 | QUEUED                   |\n| `STARTED`                | STARTED                  |\n| `VALIDATING`             | VALIDATING               |\n| `VALIDATED`              | VALIDATED                |\n| `RUNNING`                | RUNNING                  |\n| `FAILED_VALIDATION`      | FAILED_VALIDATION        |\n| `FAILED`                 | FAILED                   |\n| `SUCCESS`                | SUCCESS                  |\n| `CANCELLED`              | CANCELLED                |\n| `CANCELLATION_REQUESTED` | CANCELLATION_REQUESTED   |\n```\n\n----------------------------------------\n\nTITLE: Defining API Fields in Markdown Table\nDESCRIPTION: This markdown table defines the fields used in the Mistral AI Python client API, including their types, requirements, descriptions, and examples.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/fimcompletionstreamrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description | Example |\n| ----- | ---- | -------- | ----------- | ------- |\n| `model` | *str* | :heavy_check_mark: | ID of the model to use. Only compatible for now with:<br/>  - `codestral-2405`<br/>  - `codestral-latest` | codestral-2405 |\n| `prompt` | *str* | :heavy_check_mark: | The text/code to complete. | def |\n| `temperature` | *OptionalNullable[float]* | :heavy_minus_sign: | What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value. | |\n```\n\n----------------------------------------\n\nTITLE: Declaring DocumentURLChunk in Mistral AI Python Client\nDESCRIPTION: Example of declaring a DocumentURLChunk type variable for handling document URL content in Mistral AI.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/contentchunk.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.DocumentURLChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining JSONSchema Fields in Markdown Table\nDESCRIPTION: This markdown table defines the fields for a JSONSchema object. It includes the field name, data type, whether it's required, and a description column. The fields are name (required string), schema_definition (required dictionary), description (optional nullable string), and strict (optional boolean).\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/jsonschema.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                   | Type                    | Required                | Description             |\n| ----------------------- | ----------------------- | ----------------------- | ----------------------- |\n| `name`                  | *str*                   | :heavy_check_mark:      | N/A                     |\n| `schema_definition`     | Dict[str, *Any*]        | :heavy_check_mark:      | N/A                     |\n| `description`           | *OptionalNullable[str]* | :heavy_minus_sign:      | N/A                     |\n| `strict`                | *Optional[bool]*        | :heavy_minus_sign:      | N/A                     |\n```\n\n----------------------------------------\n\nTITLE: Fine-tuning Job Status Enum Values\nDESCRIPTION: Enumeration values representing all possible states of a fine-tuning job, including queued, running, validation, success, failure and cancellation states.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierjoboutstatus.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                     | Value                    |\n| ------------------------ | ------------------------ |\n| `QUEUED`                 | QUEUED                   |\n| `STARTED`                | STARTED                  |\n| `VALIDATING`             | VALIDATING               |\n| `VALIDATED`              | VALIDATED                |\n| `RUNNING`                | RUNNING                  |\n| `FAILED_VALIDATION`      | FAILED_VALIDATION        |\n| `FAILED`                 | FAILED                   |\n| `SUCCESS`                | SUCCESS                  |\n| `CANCELLED`              | CANCELLED                |\n| `CANCELLATION_REQUESTED` | CANCELLATION_REQUESTED   |\n```\n\n----------------------------------------\n\nTITLE: Instantiating ReferenceChunk in Python for Mistral AI Client\nDESCRIPTION: This snippet illustrates the creation of a ReferenceChunk object from the models module. ReferenceChunk might be used to represent reference or citation content in the Mistral AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/contentchunk.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ReferenceChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Classifier Status Enum Values in Markdown Table\nDESCRIPTION: Markdown table defining the enumeration values for ClassifierDetailedJobOutStatus. Each row maps a status name to its corresponding value, covering the complete lifecycle of a classifier job from queue to completion.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierdetailedjoboutstatus.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                     | Value                    |\n| ------------------------ | ------------------------ |\n| `QUEUED`                 | QUEUED                   |\n| `STARTED`                | STARTED                  |\n| `VALIDATING`             | VALIDATING               |\n| `VALIDATED`              | VALIDATED                |\n| `RUNNING`                | RUNNING                  |\n| `FAILED_VALIDATION`      | FAILED_VALIDATION        |\n| `FAILED`                 | FAILED                   |\n| `SUCCESS`                | SUCCESS                  |\n| `CANCELLED`              | CANCELLED                |\n| `CANCELLATION_REQUESTED` | CANCELLATION_REQUESTED   |\n```\n\n----------------------------------------\n\nTITLE: Markdown API Field Documentation Table\nDESCRIPTION: Documents the required fields for batch job cancellation requests, showing that job_id is a required string parameter.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesbatchcancelbatchjobrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `job_id`           | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining ClassifierDetailedJobOutJobType Enum in Python\nDESCRIPTION: This code snippet defines an enum class named ClassifierDetailedJobOutJobType with a single value 'CLASSIFIER'. The enum is likely used to represent the job type for a classifier detailed job output.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/classifierdetailedjoboutjobtype.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass ClassifierDetailedJobOutJobType(Enum):\n    CLASSIFIER = \"classifier\"\n```\n\n----------------------------------------\n\nTITLE: Job Status Enum Values in Markdown Table\nDESCRIPTION: A table listing all possible job status values used for filtering query results. Includes statuses for job lifecycle stages from initial queuing through execution to completion or failure states.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/queryparamstatus.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                     | Value                    |\n| ------------------------ | ------------------------ |\n| `QUEUED`                 | QUEUED                   |\n| `STARTED`                | STARTED                  |\n| `VALIDATING`             | VALIDATING               |\n| `VALIDATED`              | VALIDATED                |\n| `RUNNING`                | RUNNING                  |\n| `FAILED_VALIDATION`      | FAILED_VALIDATION        |\n| `FAILED`                 | FAILED                   |\n| `SUCCESS`                | SUCCESS                  |\n| `CANCELLED`              | CANCELLED                |\n| `CANCELLATION_REQUESTED` | CANCELLATION_REQUESTED   |\n```\n\n----------------------------------------\n\nTITLE: Defining Multiple Stop Tokens in Python\nDESCRIPTION: Demonstrates how to define multiple stop tokens as a list of strings. Generation will halt if any of the tokens is detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/stop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using models.ToolChoiceEnum Type in ChatCompletionStreamRequest\nDESCRIPTION: Shows how to define a variable of type models.ToolChoiceEnum that can be used with the ChatCompletionStreamRequest in the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequesttoolchoice.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoiceEnum = /* values here */\n```\n\n----------------------------------------\n\nTITLE: ModerationResponse Field Definitions - Markdown Table\nDESCRIPTION: Table defining the fields, types, requirements and descriptions for the ModerationResponse object structure\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/moderationresponse.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description | Example |\n| -------------------------------------------------------------- | -------------------------------------------------------------- | -------------------------------------------------------------- | -------------------------------------------------------------- | -------------------------------------------------------------- |\n| `id` | *str* | :heavy_check_mark: | N/A | mod-e5cc70bb28c444948073e77776eb30ef |\n| `model` | *str* | :heavy_check_mark: | N/A | |\n| `results` | List[[models.ModerationObject](../models/moderationobject.md)] | :heavy_check_mark: | N/A | |\n```\n\n----------------------------------------\n\nTITLE: Defining List of ContentChunk Objects Type in Python for MistralAI Client\nDESCRIPTION: Defines a list of ContentChunk objects as a supported content type for the MistralAI Python client. This allows passing structured content data to the client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/content.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[models.ContentChunk] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ToolChoiceEnum Type for ChatCompletionStreamRequest in Python\nDESCRIPTION: This snippet shows how to define a value of type models.ToolChoiceEnum for use in a ChatCompletionStreamRequest. The specific enum values are not included in the snippet.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionstreamrequesttoolchoice.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoiceEnum = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Error Handling in Python Client\nDESCRIPTION: Documentation of error types, including HTTP validation errors and SDK errors, associated with the Python client. It provides information on the relevant status codes and content types, crucial for proper error management in client applications.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/fim/README.md#2025-04-17_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n| Error Type                 | Status Code                | Content Type               |\n| -------------------------- | -------------------------- | -------------------------- |\n| models.HTTPValidationError | 422                        | application/json           |\n| models.SDKError            | 4XX, 5XX                   | */*                      |\n```\n\n----------------------------------------\n\nTITLE: Defining DeltaMessage Fields in Markdown\nDESCRIPTION: This snippet presents a markdown table that outlines the fields of the DeltaMessage class. It includes the field names, their types, whether they are required, and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/deltamessage.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                    | Type                                                     | Required                                                 | Description                                              |\n| -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- |\n| `role`                                                   | *OptionalNullable[str]*                                  | :heavy_minus_sign:                                       | N/A                                                      |\n| `content`                                                | [OptionalNullable[models.Content]](../models/content.md) | :heavy_minus_sign:                                       | N/A                                                      |\n| `tool_calls`                                             | List[[models.ToolCall](../models/toolcall.md)]           | :heavy_minus_sign:                                       | N/A                                                      |\n```\n\n----------------------------------------\n\nTITLE: Defining Fine-Tuning Job Configuration Parameters in Markdown\nDESCRIPTION: This markdown table defines the structure and types of parameters used to configure a fine-tuning job. It includes fields for integrations, auto-start, invalid sample handling, job type, repositories, and classifier targets.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobin.md#2025-04-17_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| `integrations`                                                                                                                                                                                                                                                                                                                                                    | List[[models.JobInIntegrations](../models/jobinintegrations.md)]                                                                                                                                                                                                                                                                                                  | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | A list of integrations to enable for your fine-tuning job.                                                                                                                                                                                                                                                                                                        |\n| `auto_start`                                                                                                                                                                                                                                                                                                                                                      | *Optional[bool]*                                                                                                                                                                                                                                                                                                                                                  | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | This field will be required in a future release.                                                                                                                                                                                                                                                                                                                  |\n| `invalid_sample_skip_percentage`                                                                                                                                                                                                                                                                                                                                  | *Optional[float]*                                                                                                                                                                                                                                                                                                                                                 | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | N/A                                                                                                                                                                                                                                                                                                                                                               |\n| `job_type`                                                                                                                                                                                                                                                                                                                                                        | [OptionalNullable[models.FineTuneableModelType]](../models/finetuneablemodeltype.md)                                                                                                                                                                                                                                                                              | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | N/A                                                                                                                                                                                                                                                                                                                                                               |\n| `repositories`                                                                                                                                                                                                                                                                                                                                                    | List[[models.JobInRepositories](../models/jobinrepositories.md)]                                                                                                                                                                                                                                                                                                  | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | N/A                                                                                                                                                                                                                                                                                                                                                               |\n| `classifier_targets`                                                                                                                                                                                                                                                                                                                                              | List[[models.ClassifierTargetIn](../models/classifiertargetin.md)]                                                                                                                                                                                                                                                                                                | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                | N/A                                                                                                                                                                                                                                                                                                                                                               |\n```\n\n----------------------------------------\n\nTITLE: Declaring ReferenceChunk in Mistral AI Python Client\nDESCRIPTION: Example of declaring a ReferenceChunk type variable for handling reference content in Mistral AI.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/contentchunk.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ReferenceChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Using models.ToolChoiceEnum Type\nDESCRIPTION: Shows the implementation of models.ToolChoiceEnum type for specifying tool choices in chat completion streams.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionstreamrequesttoolchoice.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ToolChoiceEnum = /* values here */\n```\n\n----------------------------------------\n\nTITLE: ImageURL Field Definition Table\nDESCRIPTION: Markdown table defining the fields of the ImageURL data model, including field names, types, requirements and descriptions.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/imageurl.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                   | Type                    | Required                | Description             |\n| ----------------------- | ----------------------- | ----------------------- | ----------------------- |\n| `url`                   | *str*                   | :heavy_check_mark:      | N/A                     |\n| `detail`                | *OptionalNullable[str]* | :heavy_minus_sign:      | N/A                     |\n```\n\n----------------------------------------\n\nTITLE: Declaring ImageURLChunk in Mistral AI Python Client\nDESCRIPTION: Example of declaring an ImageURLChunk type variable for handling image URL content in Mistral AI.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/contentchunk.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.ImageURLChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Documenting API Parameters in Markdown\nDESCRIPTION: This snippet outlines API parameters in a markdown table format. It includes parameters such as 'n' for the number of completions, 'prediction' for an optional Prediction model, 'parallel_tool_calls' as an optional boolean, and 'safe_prompt' for injecting a safety prompt.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| `n`                                                                                                                                                                                                                                                                                                                                                                                   | *OptionalNullable[int]*                                                                                                                                                                                                                                                                                                                                                                               | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | Number of completions to return for each request, input tokens are only billed once.                                                                                                                                                                                                                                                                                                                  |                                                                                                                                                                                                                                                                                                                                                                                                       |\n| `prediction`                                                                                                                                                                                                                                                                                          | [Optional[models.Prediction]](../models/prediction.md)                                                                                                                                                                                                                                                                                                                                                | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | N/A                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                       |\n| `parallel_tool_calls`                                                                                                                                                                                                                                                                                 | *Optional[bool]*                                                                                                                                                                                                                                                                                                                                                                                      | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | N/A                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                       |\n| `safe_prompt`                                                                                                                                                                                                                                                                                         | *Optional[bool]*                                                                                                                                                                                                                                                                                                                                                                                      | :heavy_minus_sign:                                                                                                                                                                                                                                                                                                                                                                                    | Whether to inject a safety prompt before all conversations.                                                                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                       |\n```\n\n----------------------------------------\n\nTITLE: Defining ToolChoice Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ToolChoice class, including their types, requirements, and descriptions. It specifies two fields: 'function' and 'type'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/toolchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                                        | Type                                                                         | Required                                                                     | Description                                                                  |\n| ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |\n| `function`                                                                   | [models.FunctionName](../models/functionname.md)                             | :heavy_check_mark:                                                           | this restriction of `Function` is used to select a specific function to call |\n| `type`                                                                       | [Optional[models.ToolTypes]](../models/tooltypes.md)                         | :heavy_minus_sign:                                                           | N/A                                                                          |\n```\n\n----------------------------------------\n\nTITLE: HTTP Validation Error Model Fields Definition\nDESCRIPTION: Defines the detail field of HTTPValidationError model which contains a list of ValidationError objects. This is typically used for API error handling and validation responses.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/httpvalidationerror.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                        | Type                                                         | Required                                                     | Description                                                  |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| `detail`                                                     | List[[models.ValidationError](../models/validationerror.md)] | :heavy_minus_sign:                                           | N/A                                                          |\n```\n\n----------------------------------------\n\nTITLE: Creating TextChunk in Python for Mistral AI Client\nDESCRIPTION: This code shows the initialization of a TextChunk object from the models module. TextChunk is likely used to represent textual content in the Mistral AI system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/contentchunk.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.TextChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Initializing AssistantMessage in Python\nDESCRIPTION: Shows the type hint for creating an AssistantMessage instance in the models module.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequestmessages.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.AssistantMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining FunctionName Class Structure in Markdown\nDESCRIPTION: This markdown table defines the structure of the FunctionName class. It specifies a single field 'name' of type string, which is required and used to identify the function to be called.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/functionname.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `name`             | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: String Type Definition in Tool Message Content\nDESCRIPTION: Demonstrates the type annotation for string values in tool message content. Shows how to declare a variable with string type.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/toolmessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Importing Custom Functions in Python\nDESCRIPTION: Demonstrates how to import custom functions in the __init__.py file of the extra package to make them accessible throughout the SDK.\nSOURCE: https://github.com/mistralai/client-python/blob/main/src/mistralai/extra/README.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom .my_custom_file import my_custom_function\n\n__all__ = [\"my_custom_function\"]\n```\n\n----------------------------------------\n\nTITLE: Defining Security Fields for Mistral AI Python Client\nDESCRIPTION: This markdown table defines the security configuration for the Mistral AI Python client. It specifies a single required field 'api_key' of type string.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/security.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `api_key`          | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining FilesAPIRoutesDeleteFileRequest Class Fields in Markdown\nDESCRIPTION: This snippet defines the fields for the FilesAPIRoutesDeleteFileRequest class using a Markdown table. It specifies a single required field 'file_id' of type string.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/filesapiroutesdeletefilerequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `file_id`          | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining DeleteModelOut Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the DeleteModelOut class using a markdown table. It specifies the field names, types, requirements, descriptions, and examples for each field in the class.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/deletemodelout.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                         | Type                                          | Required                                      | Description                                   | Example                                       |\n| --------------------------------------------- | --------------------------------------------- | --------------------------------------------- | --------------------------------------------- | --------------------------------------------- |\n| `id`                                          | *str*                                         | :heavy_check_mark:                            | The ID of the deleted model.                  | ft:open-mistral-7b:587a6b29:20240514:7e773925 |\n| `object`                                      | *Optional[str]*                               | :heavy_minus_sign:                            | The object type that was deleted              |                                               |\n| `deleted`                                     | *Optional[bool]*                              | :heavy_minus_sign:                            | The deletion status                           | true                                          |\n```\n\n----------------------------------------\n\nTITLE: Defining UserMessageRole Constants in Python\nDESCRIPTION: This code snippet defines a constant or enumeration for user message roles. It specifies a 'USER' role with the value 'user', which can be used to identify messages sent by users in a chat or messaging system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/usermessagerole.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nUSER = user\n```\n\n----------------------------------------\n\nTITLE: Defining RetryConfig Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the RetryConfig class using a Markdown table. It includes the field names, types, descriptions, and examples.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/utils/retryconfig.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                      | Type                                | Description                             | Example   |\n| ------------------------- | ----------------------------------- | --------------------------------------- | --------- |\n| `strategy`                | `*str*`                             | The retry strategy to use.              | `backoff` |\n| `backoff`                 | [BackoffStrategy](#backoffstrategy) | Configuration for the backoff strategy. |           |\n| `retry_connection_errors` | `*bool*`                            | Whether to retry on connection errors.  | `true`    |\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests for Extra Package in Bash\nDESCRIPTION: Command to run unit tests for the 'extra' package using the unittest module and discover option.\nSOURCE: https://github.com/mistralai/client-python/blob/main/src/mistralai/extra/README.md#2025-04-17_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython3.12 -m unittest discover -s src/mistralai/extra/tests -t src\n```\n\n----------------------------------------\n\nTITLE: Specifying Tools for AI Interaction\nDESCRIPTION: Optional list of tools that can be used by the AI during response generation. Enables advanced functionality and specialized task handling.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequest.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntools: List[models.Tool] = []\n```\n\n----------------------------------------\n\nTITLE: Configuring Single Stop Token in Python for MistralAI Client\nDESCRIPTION: Demonstrates how to set a single stop token as a string value. This configuration will halt text generation when the specified token is encountered.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/stop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining FIMCompletionStreamRequestStop with List of Strings in Python\nDESCRIPTION: Shows how to define a FIMCompletionStreamRequestStop using a list of strings. This will stop the generation if any of the specified tokens in the list are detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/fimcompletionstreamrequeststop.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: List[str] = /* values here */\n```\n\n----------------------------------------\n\nTITLE: ChatCompletionChoice Fields Table in Markdown\nDESCRIPTION: Markdown table defining the required fields, types, and examples for the ChatCompletionChoice model structure.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionchoice.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field | Type | Required | Description | Example |\n| ------------------------ | ------------------------ | ------------------------ | ------------------------ | ------------------------ |\n| `index` | *int* | :heavy_check_mark: | N/A | 0 |\n| `message` | [models.AssistantMessage](../models/assistantmessage.md) | :heavy_check_mark: | N/A | |\n| `finish_reason` | [models.ChatCompletionChoiceFinishReason](../models/chatcompletionchoicefinishreason.md) | :heavy_check_mark: | N/A | stop |\n```\n\n----------------------------------------\n\nTITLE: Initializing FIMCompletionRequestStop with String in Python\nDESCRIPTION: This snippet shows how to initialize the FIMCompletionRequestStop with a single string value. The stop token will trigger the generation to stop when detected.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/fimcompletionrequeststop.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ImageURLChunkType Enum in Python\nDESCRIPTION: This code snippet defines an enum class named ImageURLChunkType with a single value IMAGE_URL. The enum is likely used to represent different types of image URL chunks in the Mistral AI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/imageurlchunktype.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# ImageURLChunkType\n\n\n## Values\n\n| Name        | Value       |\n| ----------- | ----------- |\n| `IMAGE_URL` | image_url   |\n```\n\n----------------------------------------\n\nTITLE: Defining RetryConfig Fields in Markdown\nDESCRIPTION: This snippet defines the fields of the RetryConfig class using a markdown table. It includes the field names, types, descriptions, and examples for strategy, backoff, and retry_connection_errors.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/utils/retryconfig.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                      | Type                                | Description                             | Example   |\n| ------------------------- | ----------------------------------- | --------------------------------------- | --------- |\n| `strategy`                | `*str*`                             | The retry strategy to use.              | `backoff` |\n| `backoff`                 | [BackoffStrategy](#backoffstrategy) | Configuration for the backoff strategy. |           |\n| `retry_connection_errors` | `*bool*`                            | Whether to retry on connection errors.  | `true`    |\n```\n\n----------------------------------------\n\nTITLE: Returning Sum in Python\nDESCRIPTION: A simple Python function that returns the sum of two values. This snippet appears to be an example or placeholder in the documentation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/fimcompletionrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nreturn a+b\n```\n\n----------------------------------------\n\nTITLE: Initializing UserMessage in Python for Mistral AI Chat Completion\nDESCRIPTION: Creates an instance of UserMessage for use in chat completion requests. The specific values for initialization are not provided in the snippet.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/chatcompletionrequestmessages.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.UserMessage = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Collecting Environment Information using Node.js\nDESCRIPTION: Command to gather system environment information using Node.js's envinfo utility for issue reporting purposes.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/CONTRIBUTING.md#2025-04-17_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpx envinfo\n```\n\n----------------------------------------\n\nTITLE: CompletionTrainingParametersIn Class Title\nDESCRIPTION: Markdown documentation header for the CompletionTrainingParametersIn class that defines fine-tuning hyperparameter settings used in fine-tune jobs.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completiontrainingparametersin.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# CompletionTrainingParametersIn\\n\\nThe fine-tuning hyperparameter settings used in a fine-tune job.\n```\n\n----------------------------------------\n\nTITLE: Defining ReferenceChunkType Enum in Python\nDESCRIPTION: This code snippet defines an enum called ReferenceChunkType with a single value 'REFERENCE'. The enum is likely used to categorize or identify reference chunk types in a larger system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/referencechunktype.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# ReferenceChunkType\n\n\n## Values\n\n| Name        | Value       |\n| ----------- | ----------- |\n| `REFERENCE` | reference   |\n```\n\n----------------------------------------\n\nTITLE: Defining TEXT Constant in Python\nDESCRIPTION: This code snippet defines a constant value 'TEXT' with the string value 'text'. It is likely part of an enumeration or constant set used in a larger project, possibly for specifying data types or processing modes.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/type.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nTEXT = 'text'\n```\n\n----------------------------------------\n\nTITLE: Documenting API Parameters in Markdown\nDESCRIPTION: This snippet defines two API parameters: 'prediction' and 'parallel_tool_calls'. It specifies their types, optionality, and provides links to further documentation.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/agentscompletionstreamrequest.md#2025-04-17_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n| `prediction`                                                                                                                                                                                                                                                | [Optional[models.Prediction]](../models/prediction.md)                                                                                                                                                                                                                      | :heavy_minus_sign:                                                                                                                                                                                                                                                          | N/A                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                             |\n| `parallel_tool_calls`                                                                                                                                                                                                                                                       | *Optional[bool]*                                                                                                                                                                                                                                                            | :heavy_minus_sign:                                                                                                                                                                                                                                                          | N/A                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                             |\n```\n\n----------------------------------------\n\nTITLE: Defining GitHub Repository Type Constant in Python\nDESCRIPTION: This code snippet defines a constant value 'GITHUB' representing the GitHub repository type. It uses a class-like structure to associate the string 'github' with the name 'GITHUB'. This approach allows for easy reference and type-checking when working with repository types in the system.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/githubrepositoryintype.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nGITHUB = github\n```\n\n----------------------------------------\n\nTITLE: Defining Type Enumeration for MistralAI Python Client\nDESCRIPTION: This code snippet defines an enumeration called Type with a single value 'TEXT'. It's likely used to specify the content type in API requests or responses within the MistralAI Python client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/type.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# Type\n\n\n## Values\n\n| Name   | Value  |\n| ------ | ------ |\n| `TEXT` | text   |\n```\n\n----------------------------------------\n\nTITLE: Basic Python Addition Example\nDESCRIPTION: Simple code example showing a return statement that adds two variables.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/fimcompletionstreamrequest.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nreturn a+b\n```\n\n----------------------------------------\n\nTITLE: Creating TextChunk in Mistral AI Python Client\nDESCRIPTION: This code shows the initialization of a TextChunk object from the models module. TextChunk is likely used to represent textual content in the Mistral AI framework.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/contentchunk.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.TextChunk = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ArchiveFTModelOutObject Enum in Python\nDESCRIPTION: This code snippet defines an enum class called ArchiveFTModelOutObject with a single value 'MODEL'. The enum is likely used for specifying output object types in an archiving process for fine-tuned models.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/archiveftmodeloutobject.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# ArchiveFTModelOutObject\n\n\n## Values\n\n| Name    | Value   |\n| ------- | ------- |\n| `MODEL` | model   |\n```\n\n----------------------------------------\n\nTITLE: Defining FUNCTION Tool Type Constant\nDESCRIPTION: Defines the FUNCTION tool type constant with value 'function' used to identify function-type tools in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/tooltypes.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name       | Value      |\n| ---------- | ---------- |\n| `FUNCTION` | function   |\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionEvent Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the CompletionEvent class. It specifies a single field named 'data' of type CompletionChunk, which is required and does not have a specific description provided.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/completionevent.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                                  | Type                                                   | Required                                               | Description                                            |\n| ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------ |\n| `data`                                                 | [models.CompletionChunk](../models/completionchunk.md) | :heavy_check_mark:                                     | N/A                                                    |\n```\n\n----------------------------------------\n\nTITLE: Defining BatchJobStatus Enumeration Values in Markdown\nDESCRIPTION: This snippet defines the possible values for the BatchJobStatus enumeration using a markdown table. It includes statuses such as QUEUED, RUNNING, SUCCESS, FAILED, and various termination states.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/batchjobstatus.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name                     | Value                    |\n| ------------------------ | ------------------------ |\n| `QUEUED`                 | QUEUED                   |\n| `RUNNING`                | RUNNING                  |\n| `SUCCESS`                | SUCCESS                  |\n| `FAILED`                 | FAILED                   |\n| `TIMEOUT_EXCEEDED`       | TIMEOUT_EXCEEDED         |\n| `CANCELLATION_REQUESTED` | CANCELLATION_REQUESTED   |\n| `CANCELLED`              | CANCELLED                |\n```\n\n----------------------------------------\n\nTITLE: Using String Content Type in Mistral AI Python Client\nDESCRIPTION: Example of using a string type value as content in the Mistral AI Python client. This is the simplest content format for passing text to the API.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/content.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Asynchronous HTTP Client in Python\nDESCRIPTION: This snippet demonstrates the implementation of a custom asynchronous HTTP client by extending AsyncHttpClient. It shows how to override the send method to add a client-level header and to build requests with the custom logic.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/README.md#2025-04-17_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom mistralai_gcp import MistralGCP\nfrom mistralai_gcp.httpclient import AsyncHttpClient\nimport httpx\n\nclass CustomClient(AsyncHttpClient):\n    client: AsyncHttpClient\n\n    def __init__(self, client: AsyncHttpClient):\n        self.client = client\n\n    async def send(\n        self,\n        request: httpx.Request,\n        *,\n        stream: bool = False,\n        auth: Union[\n            httpx._types.AuthTypes, httpx._client.UseClientDefault, None\n        ] = httpx.USE_CLIENT_DEFAULT,\n        follow_redirects: Union[\n            bool, httpx._client.UseClientDefault\n        ] = httpx.USE_CLIENT_DEFAULT,\n    ) -> httpx.Response:\n        request.headers[\"Client-Level-Header\"] = \"added by client\"\n\n        return await self.client.send(\n            request, stream=stream, auth=auth, follow_redirects=follow_redirects\n        )\n\n    def build_request(\n        self,\n        method: str,\n        url: httpx._types.URLTypes,\n        *,\n        content: Optional[httpx._types.RequestContent] = None,\n        data: Optional[httpx._types.RequestData] = None,\n        files: Optional[httpx._types.RequestFiles] = None,\n        json: Optional[Any] = None,\n        params: Optional[httpx._types.QueryParamTypes] = None,\n        headers: Optional[httpx._types.HeaderTypes] = None,\n        cookies: Optional[httpx._types.CookieTypes] = None,\n        timeout: Union[\n            httpx._types.TimeoutTypes, httpx._client.UseClientDefault\n        ] = httpx.USE_CLIENT_DEFAULT,\n        extensions: Optional[httpx._types.RequestExtensions] = None,\n    ) -> httpx.Request:\n        return self.client.build_request(\n            method,\n            url,\n            content=content,\n            data=data,\n            files=files,\n            json=json,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            timeout=timeout,\n            extensions=extensions,\n        )\n\ns = MistralGCP(async_client=CustomClient(httpx.AsyncClient()))\n```\n\n----------------------------------------\n\nTITLE: Initializing CompletionJobOut Model in Python\nDESCRIPTION: This code shows the initialization of a CompletionJobOut model from the Mistral AI Python client. It utilizes the models module to instantiate a CompletionJobOut object.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/response1.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.CompletionJobOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining String Content Type in Python for MistralAI Client\nDESCRIPTION: Specifies the string type as a supported content type for the MistralAI Python client. This allows passing simple text data to the client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/content.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Configuring Chat Completion Request Parameters\nDESCRIPTION: Parameters for controlling chat completion request behavior, including number of completions, safety prompts, and retry configurations\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/sdks/chat/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nn: Optional[int] = None  # Number of completions to generate\nprediction: Optional[models.Prediction] = None  # Prediction model configuration\nparallel_tool_calls: Optional[bool] = None  # Enable parallel tool calls\nsafe_prompt: Optional[bool] = None  # Inject safety prompt\nretries: Optional[utils.RetryConfig] = None  # Retry configuration\n```\n\n----------------------------------------\n\nTITLE: Defining ValidationError Fields in Markdown\nDESCRIPTION: This markdown table defines the fields of the ValidationError model, including their types, whether they are required, and any additional description.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/validationerror.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field                                | Type                                 | Required                             | Description                          |\n| ------------------------------------ | ------------------------------------ | ------------------------------------ | ------------------------------------ |\n| `loc`                                | List[[models.Loc](../models/loc.md)] | :heavy_check_mark:                   | N/A                                  |\n| `msg`                                | *str*                                | :heavy_check_mark:                   | N/A                                  |\n| `type`                               | *str*                                | :heavy_check_mark:                   | N/A                                  |\n```\n\n----------------------------------------\n\nTITLE: Fine-Tuning Job Object Type Enumeration Values\nDESCRIPTION: Defines the possible object type values for fine-tuning jobs. Currently contains a single value 'job'.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/object.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name  | Value |\n| ----- | ----- |\n| `JOB` | job   |\n```\n\n----------------------------------------\n\nTITLE: Initializing models.LegacyJobMetadataOut in Python\nDESCRIPTION: Creates an instance of the models.LegacyJobMetadataOut class. This class probably represents metadata output for legacy jobs in the fine-tuning process.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/jobsapiroutesfinetuningcreatefinetuningjobresponse.md#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvalue: models.LegacyJobMetadataOut = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining ImageURLChunkType Enum Value in Python\nDESCRIPTION: Defines the IMAGE_URL constant with value 'image_url' as part of the ImageURLChunkType enumeration. This is used to identify and handle image URL type chunks in the Mistral AI client.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/imageurlchunktype.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nIMAGE_URL = image_url\n```\n\n----------------------------------------\n\nTITLE: Uploading Files with Original Filename in Bash\nDESCRIPTION: Example of how to upload a file while keeping its original filename in a bash request. This simpler syntax only requires specifying the file path.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/filesapiroutesuploadfilemultipartbodyparams.md#2025-04-17_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nfile=@path/to/your/file.jsonl\n```\n\n----------------------------------------\n\nTITLE: ChatCompletionStreamRequest Header\nDESCRIPTION: Header documentation marker for the ChatCompletionStreamRequest class definition\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/chatcompletionstreamrequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# ChatCompletionStreamRequest\n```\n\n----------------------------------------\n\nTITLE: Assistant Role Constant Definition in Markdown Table\nDESCRIPTION: Defines the ASSISTANT constant with value 'assistant' using a markdown table format. This represents the role identifier used when specifying messages from the AI assistant.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/assistantmessagerole.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name        | Value       |\n| ----------- | ----------- |\n| `ASSISTANT` | assistant   |\n```\n\n----------------------------------------\n\nTITLE: FilesAPIRoutesRetrieveFileRequest Class Fields Schema\nDESCRIPTION: Documents the required fields for making a file retrieval request through the Mistral AI Files API. The only required field is file_id which must be a string.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/filesapiroutesretrievefilerequest.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Field              | Type               | Required           | Description        |\n| ------------------ | ------------------ | ------------------ | ------------------ |\n| `file_id`          | *str*              | :heavy_check_mark: | N/A                |\n```\n\n----------------------------------------\n\nTITLE: Defining AssistantMessageRole Value in Markdown Table\nDESCRIPTION: A markdown table defining the AssistantMessageRole enumeration with a single value 'ASSISTANT' corresponding to the string 'assistant'. This is used to specify the role of messages in conversations with the Mistral AI assistant.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/assistantmessagerole.md#2025-04-17_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name        | Value       |\n| ----------- | ----------- |\n| `ASSISTANT` | assistant   |\n```\n\n----------------------------------------\n\nTITLE: Declaring String Value for SystemMessageContent in Python\nDESCRIPTION: This snippet shows how to declare a string value for the SystemMessageContent class. It uses type hinting to specify that the 'value' variable is of type str.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_gcp/docs/models/systemmessagecontent.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Running example script using poetry shell\nDESCRIPTION: These commands activate the poetry virtual environment shell, navigate to the examples directory, and run a Python script directly within the activated environment.\nSOURCE: https://github.com/mistralai/client-python/blob/main/OLD-README.md#2025-04-17_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npoetry shell\ncd examples\n\n>> python chat_no_streaming.py\n```\n\n----------------------------------------\n\nTITLE: String Type Declaration in Python\nDESCRIPTION: Demonstrates the type annotation for string values in Python using type hints.\nSOURCE: https://github.com/mistralai/client-python/blob/main/packages/mistralai_azure/docs/models/loc.md#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = /* values here */\n```\n\n----------------------------------------\n\nTITLE: Defining CompletionDetailedJobOutObject Enum in Python\nDESCRIPTION: This code snippet defines an enumeration called CompletionDetailedJobOutObject with a single value 'JOB'. It appears to be part of a larger system, possibly related to job or task completion details.\nSOURCE: https://github.com/mistralai/client-python/blob/main/docs/models/completiondetailedjoboutobject.md#2025-04-17_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# CompletionDetailedJobOutObject\n\n\n## Values\n\n| Name  | Value |\n| ----- | ----- |\n| `JOB` | job   |\n```"
  }
]