[
  {
    "owner": "systran",
    "repo": "faster-whisper",
    "content": "TITLE: Basic transcription with Faster-Whisper in Python\nDESCRIPTION: Demonstrates how to load a Whisper model and transcribe an audio file with GPU acceleration and FP16 precision. The code outputs the detected language and text segments with timestamps.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faster_whisper import WhisperModel\n\nmodel_size = \"large-v3\"\n\n# Run on GPU with FP16\nmodel = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n\n# or run on GPU with INT8\n# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n# or run on CPU with INT8\n# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n\nsegments, info = model.transcribe(\"audio.mp3\", beam_size=5)\n\nprint(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n\nfor segment in segments:\n    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n```\n\n----------------------------------------\n\nTITLE: Batched transcription with Faster-Whisper in Python\nDESCRIPTION: Shows how to use the BatchedInferencePipeline for improved performance with batch processing. This technique can significantly speed up transcription by processing multiple audio segments in parallel.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faster_whisper import WhisperModel, BatchedInferencePipeline\n\nmodel = WhisperModel(\"turbo\", device=\"cuda\", compute_type=\"float16\")\nbatched_model = BatchedInferencePipeline(model=model)\nsegments, info = batched_model.transcribe(\"audio.mp3\", batch_size=16)\n\nfor segment in segments:\n    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n```\n\n----------------------------------------\n\nTITLE: Using Distil-Whisper with Faster-Whisper for transcription\nDESCRIPTION: Demonstrates how to use the Distil-Whisper model (distil-large-v3) with Faster-Whisper. This model is specifically optimized for the Faster-Whisper transcription algorithm and offers improved performance.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faster_whisper import WhisperModel\n\nmodel_size = \"distil-large-v3\"\n\nmodel = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\nsegments, info = model.transcribe(\"audio.mp3\", beam_size=5, language=\"en\", condition_on_previous_text=False)\n\nfor segment in segments:\n    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n```\n\n----------------------------------------\n\nTITLE: Applying Voice Activity Detection (VAD) filtering with Faster-Whisper\nDESCRIPTION: Shows how to enable the Silero VAD model to filter out non-speech parts of audio. This technique can improve transcription efficiency by skipping silent or non-speech segments.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nsegments, _ = model.transcribe(\"audio.mp3\", vad_filter=True)\n```\n\n----------------------------------------\n\nTITLE: Handling generator output in Faster-Whisper transcription\nDESCRIPTION: Demonstrates the proper handling of the segments generator returned by the transcribe method. This code shows how to force the transcription to run to completion by gathering the segments in a list.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nsegments, _ = model.transcribe(\"audio.mp3\")\nsegments = list(segments)  # The transcription will actually run here.\n```\n\n----------------------------------------\n\nTITLE: Generating word-level timestamps with Faster-Whisper\nDESCRIPTION: Shows how to enable and access word-level timestamps in the transcription output. This provides more granular timing information for each individual word in the transcribed text.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsegments, _ = model.transcribe(\"audio.mp3\", word_timestamps=True)\n\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\n```\n\n----------------------------------------\n\nTITLE: Converting Whisper Models to CTranslate2 Format\nDESCRIPTION: Command to convert the original OpenAI Whisper large-v3 model to CTranslate2 format with FP16 precision. This conversion allows the model to be used with the faster-whisper library.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npip install transformers[torch]>=4.23\n\nct2-transformers-converter --model openai/whisper-large-v3 --output_dir whisper-large-v3-ct2\n--copy_files tokenizer.json preprocessor_config.json --quantization float16\n```\n\n----------------------------------------\n\nTITLE: Loading a Locally Converted Whisper Model\nDESCRIPTION: Code snippet showing how to load a locally converted Whisper model from a directory using the faster_whisper.WhisperModel class.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nmodel = faster_whisper.WhisperModel(\"whisper-large-v3-ct2\")\n```\n\n----------------------------------------\n\nTITLE: Loading a Whisper Model from Hugging Face Hub\nDESCRIPTION: Code snippet demonstrating how to load a converted Whisper model from the Hugging Face Hub using the faster_whisper.WhisperModel class and a username/model-name format.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmodel = faster_whisper.WhisperModel(\"username/whisper-large-v3-ct2\")\n```\n\n----------------------------------------\n\nTITLE: Customizing VAD parameters for Faster-Whisper transcription\nDESCRIPTION: Demonstrates how to customize Voice Activity Detection parameters for finer control over silence filtering. The example shows changing the minimum silence duration threshold.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nsegments, _ = model.transcribe(\n    \"audio.mp3\",\n    vad_filter=True,\n    vad_parameters=dict(min_silence_duration_ms=500),\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring logging for Faster-Whisper\nDESCRIPTION: Shows how to set up logging for the faster_whisper library. This is useful for debugging and understanding the internal processing steps during transcription.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport logging\n\nlogging.basicConfig()\nlogging.getLogger(\"faster_whisper\").setLevel(logging.DEBUG)\n```\n\n----------------------------------------\n\nTITLE: Setting Thread Count for CPU Performance Optimization\nDESCRIPTION: Bash command showing how to set the number of CPU threads using the OMP_NUM_THREADS environment variable when running a Python script for better performance control.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/README.md#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nOMP_NUM_THREADS=4 python3 my_script.py\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Faster-Whisper\nDESCRIPTION: This snippet lists the required Python packages and their version constraints for the Faster-Whisper project. It includes machine learning libraries, audio processing tools, and utility packages.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nctranslate2>=4.0,<5\nhuggingface_hub>=0.13\ntokenizers>=0.13,<1\nonnxruntime>=1.14,<2 \nav>=11\ntqdm\n```\n\n----------------------------------------\n\nTITLE: Installing faster-whisper for Development in Bash\nDESCRIPTION: Commands to clone the faster-whisper repository and install it in editable mode with development dependencies.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/CONTRIBUTING.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/SYSTRAN/faster-whisper.git\ncd faster-whisper/\npip install -e .[dev]\n```\n\n----------------------------------------\n\nTITLE: Specifying Transformers Library Dependency with PyTorch Support\nDESCRIPTION: This dependency specification requires the transformers library version 4.23 or higher with PyTorch support. This is typically used in a requirements.txt file or as part of a package dependency definition.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/requirements.conversion.txt#2025-04-23_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\ntransformers[torch]>=4.23\n```\n\n----------------------------------------\n\nTITLE: Running Tests for faster-whisper in Bash\nDESCRIPTION: Command to run the existing tests using pytest.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/CONTRIBUTING.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npytest tests/\n```\n\n----------------------------------------\n\nTITLE: Validating Code Changes for faster-whisper in Bash\nDESCRIPTION: Commands to reformat and validate the code using black, isort, and flake8.\nSOURCE: https://github.com/systran/faster-whisper/blob/master/CONTRIBUTING.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nblack .\nisort .\nflake8 .\n```"
  }
]