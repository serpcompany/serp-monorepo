[
  {
    "owner": "sylphai-inc",
    "repo": "adalflow",
    "content": "TITLE: Creating a Basic Generator with OpenAI Client\nDESCRIPTION: Demonstrates the simplest way to create and use a Generator with OpenAI's model client. This example shows how to initialize a Generator with model parameters and make a basic query.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import Generator\nfrom adalflow.components.model_client.openai_client import OpenAIClient\n\n# Create a generator\ngen = Generator(\n    model_client=OpenAIClient(),\n    model_kwargs={\n        \"model\": \"gpt-4o-mini\",\n        \"temperature\": 0.7\n    }\n)\n\n# Use the generator\nresponse = gen({\"input_str\": \"What is the capital of France?\"})\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Defining VanillaRAG Component Class in Python\nDESCRIPTION: Implementation of the main RAG component class that handles retrieval and generation. Includes configuration of trainable parameters for task description and few-shot examples.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass VanillaRAG(adal.GradComponent):\n    def __init__(self, passages_per_hop=3, model_client=None, model_kwargs=None):\n        super().__init__()\n\n        self.passages_per_hop = passages_per_hop\n\n        self.retriever = DspyRetriever(top_k=passages_per_hop)\n        self.llm_parser = adal.DataClassParser(\n            data_class=AnswerData, return_data_class=True, format_type=\"json\"\n        )\n        self.llm = Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            prompt_kwargs={\n                \"task_desc_str\": adal.Parameter(\n                    data=task_desc_str,\n                    role_desc=\"Task description for the language model\",\n                    param_type=adal.ParameterType.PROMPT,\n                ),\n                \"few_shot_demos\": adal.Parameter(\n                    data=None,\n                    requires_opt=True,\n                    role_desc=\"To provide few shot demos to the language model\",\n                    param_type=adal.ParameterType.DEMOS,\n                ),\n                \"output_format_str\": self.llm_parser.get_output_format_str(),\n            },\n            template=answer_template,\n            output_processors=self.llm_parser,\n            use_cache=True,\n        )\n```\n\n----------------------------------------\n\nTITLE: OpenAI Integration with AdalFlow\nDESCRIPTION: Example of setting up and using OpenAI's models with AdalFlow, including environment setup and basic query execution\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\nfrom adalflow.utils import setup_env\n\nsetup_env()\n\nopenai_llm = adal.Generator(\n   model_client=adal.OpenAIClient(), model_kwargs={\"model\": \"gpt-3.5-turbo\"}\n)\nresopnse = openai_llm(prompt_kwargs={\"input_str\": \"What is LLM?\"})\n```\n\n----------------------------------------\n\nTITLE: Evaluating Retriever Performance\nDESCRIPTION: Evaluates the retriever component using recall and context relevance metrics.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/eval_a_rag.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nretriever_evaluator = RetrieverEvaluator()\navg_recall, recall_list = retriever_evaluator.compute_recall(\n    all_retrieved_context, all_gt_context\n)\navg_relevance, relevance_list = retriever_evaluator.compute_context_relevance(\n    all_retrieved_context, all_gt_context\n)\nprint(f\"Average recall: {avg_recall}\")\nprint(f\"Average relevance: {avg_relevance}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI GPT-3.5-turbo Model for AdalFlow Pipeline\nDESCRIPTION: Sets up the OpenAI client and configures the GPT-3.5-turbo model parameters for use in the AdalFlow task pipeline.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client.openai_client import OpenAIClient\n\nadal.setup_env()\n\ngpt_3_model = {\n    \"model_client\": OpenAIClient(),\n    \"model_kwargs\": {\n        \"model\": \"gpt-3.5-turbo\",\n        \"max_tokens\": 2000,\n        \"temperature\": 0.0,\n        \"top_p\": 0.99,\n        \"frequency_penalty\": 0,\n        \"presence_penalty\": 0,\n        \"stop\": None,\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Adalflow Components\nDESCRIPTION: This snippet imports the necessary Adalflow components and utilities for building the RAG system, including core classes, data processing components, and retrieval tools.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any, List, Optional\nimport os\nfrom adalflow.core import Component, Generator, Embedder, Sequential\nfrom adalflow.core.types import Document, ModelClientType\nfrom adalflow.core.string_parser import JsonParser\nfrom adalflow.core.db import LocalDB\nfrom adalflow.utils import setup_env\nfrom adalflow.components.retriever.faiss_retriever import FAISSRetriever\nfrom adalflow.components.data_process import (\n    RetrieverOutputToContextStr,\n    ToEmbeddings,\n    TextSplitter,\n)\nfrom adalflow.utils.global_config import get_adalflow_default_root_path\n```\n\n----------------------------------------\n\nTITLE: Parsing JSON Output with JsonOutputParser in Python\nDESCRIPTION: Demonstrates how to use JsonOutputParser to parse a JSON string into a dictionary based on a defined DataClass structure. It includes setting up the parser and using it to parse a JSON string.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.output_parsers import JsonOutputParser\n\nparser = JsonOutputParser(data_class=User, examples=[user_example])\nprint(parser)\n\nuser_to_parse = '{\"id\": 2, \"name\": \"Jane\"}'\nparsed_user = parser(user_to_parse)\nprint(parsed_user)\n```\n\n----------------------------------------\n\nTITLE: Executing Summary Evaluation\nDESCRIPTION: Performs the actual evaluation using GEvalJudgeEvaluator to assess the quality of the summary, returning scores for relevance, fluency, consistency, and coherence metrics.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ng_evaluator = GEvalJudgeEvaluator(llm_judge=g_eval)\n\nresponse = g_evaluator(input_strs=[input_str])\nprint(f\"response: {response}\")\n```\n\n----------------------------------------\n\nTITLE: Defining Retriever Data Types in Python\nDESCRIPTION: Type definitions for retriever queries and documents that establish the foundation for retriever components. These types support both single and multiple queries, specify document formats, and enable batch processing capabilities.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nRetrieverQueryType = TypeVar(\"RetrieverQueryType\", contravariant=True)\nRetrieverStrQueryType = str\nRetrieverQueriesType = Union[RetrieverQueryType, Sequence[RetrieverQueryType]]\nRetrieverStrQueriesType = Union[str, Sequence[RetrieverStrQueryType]]\n```\n\n----------------------------------------\n\nTITLE: Creating AdalFlow Retriever from DsPy Retriever\nDESCRIPTION: Implements a custom Retriever by extending AdalFlow's Retriever class and wrapping DsPy's Retriever functionality. This allows using DsPy's retrieval capabilities within the AdalFlow framework.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport adaflow as adal\nimport dspy\n\nclass DspyRetriever(adal.Retriever):\n    def __init__(self, top_k: int = 3):\n        super().__init__()\n        self.top_k = top_k\n        self.dspy_retriever = dspy.Retrieve(k=top_k)\n\n    def call(self, input: str, top_k: Optional[int] = None) -> List[adal.RetrieverOutput]:\n\n        k = top_k or self.top_k\n\n        output = self.dspy_retriever(query_or_queries=input, k=k)\n        final_output: List[RetrieverOutput] = []\n        documents = output.passages\n\n        final_output.append(\n            RetrieverOutput(\n                query=input,\n                documents=documents,\n                doc_indices=[],\n            )\n        )\n        return final_output\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG Component with AdalFlow in Python\nDESCRIPTION: This class implements a Retrieval-Augmented Generation (RAG) component using AdalFlow. It initializes an embedder, database manager, and generator, and provides methods for preparing the retriever and processing queries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass RAG(adal.Component):\n    def __init__(self):\n        super().__init__()\n        self.embedder = adal.Embedder(\n            model_client=configs[\"embedder\"][\"model_client\"](),\n            model_kwargs=configs[\"embedder\"][\"model_kwargs\"],\n        )\n        self.initialize_db_manager()\n        data_parser = adal.DataClassParser(data_class=RAGAnswer, return_data_class=True)\n        self.generator = adal.Generator(\n            template=RAG_TEMPLATE,\n            prompt_kwargs={\n                \"output_format_str\": data_parser.get_output_format_str(),\n                \"system_prompt\": system_prompt,\n            },\n            model_client=configs[\"generator\"][\"model_client\"](),\n            model_kwargs=configs[\"generator\"][\"model_kwargs\"],\n            output_processors=data_parser,\n        )\n\n    def initialize_db_manager(self):\n        self.db_manager = DatabaseManager()\n        self.transformed_docs = []\n\n    def prepare_retriever(self, repo_url_or_path: str):\n        self.initialize_db_manager()\n        self.transformed_docs = self.db_manager.prepare_database(repo_url_or_path)\n        self.retriever = FAISSRetriever(\n            **configs[\"retriever\"],\n            embedder=self.embedder,\n            documents=self.transformed_docs,\n        )\n\n    def call(self, query: str) -> Any:\n        retrieved_documents = self.retriever(query)\n        prompt_kwargs = {\n            \"input_str\": query,\n            \"contexts\": retrieved_documents[0].documents,\n        }\n        response = self.generator(\n            prompt_kwargs=prompt_kwargs,\n        )\n        return response.data, retrieved_documents\n```\n\n----------------------------------------\n\nTITLE: Implementing Configurable RAG Data Pipeline in Python using AdalFlow\nDESCRIPTION: This code creates a data processing pipeline for RAG using AdalFlow components. It configures a text splitter and an embedder using OpenAI's model, then combines them into a sequential pipeline. The pipeline splits text and generates embeddings with customizable parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/rag.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# the data pipeline and the backend data processing\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.core.types import ModelClientType\nfrom adalflow.components.data_process import TextSplitter, ToEmbeddings\nfrom adalflow.core.container import Sequential\n\n\ndef prepare_data_pipeline():\n    model_kwargs = {\n        \"model\": \"text-embedding-3-small\",\n        \"dimensions\": 256,\n        \"encoding_format\": \"float\",\n    }\n\n    splitter_config = {\"split_by\": \"word\", \"split_length\": 50, \"split_overlap\": 10}\n\n    splitter = TextSplitter(**splitter_config)\n    embedder = Embedder(\n        model_client=ModelClientType.OPENAI(), model_kwargs=model_kwargs\n    )\n    embedder_transformer = ToEmbeddings(embedder, batch_size=2)\n    data_transformer = Sequential(splitter, embedder_transformer)\n    print(data_transformer)\n```\n\n----------------------------------------\n\nTITLE: Implementing the Training Mode Forward Method for RAG\nDESCRIPTION: Defines the forward method for a RAG component in training mode. It establishes a computational graph by connecting the Retriever and Generator components with a successor mapping function that processes the retrieved documents for the Generator's prompt.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef forward(self, question: str, id: str = None) -> adal.Parameter:\n    if not self.training:\n        raise ValueError(\"This component is not supposed to be called in eval mode\")\n    retriever_out = self.retriever.forward(input=question)\n    successor_map_fn = lambda x: (  # noqa E731\n        \"\\n\\n\".join(x.data[0].documents)\n        if x.data and x.data[0] and x.data[0].documents\n        else \"\"\n    )\n    retriever_out.add_successor_map_fn(successor=self.llm, map_fn=successor_map_fn)\n    generator_out = self.llm.forward(\n        prompt_kwargs={\"question\": question, \"context\": retriever_out}, id=id\n    )\n    return generator_out\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Supported String Parsing Types in Python\nDESCRIPTION: This code snippet demonstrates the various string formats that can be parsed by AdalFlow's parser components, including simple types (integers, floats, booleans) and complex types (lists, dictionaries, nested structures) in both JSON and YAML formats.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nint_str = \"42\"\nfloat_str = \"42.0\"\nboolean_str = \"True\"  # json works with true/false, yaml works for both True/False and true/false\nNone_str = \"None\"\nNull_str = \"null\"  # json works with null, yaml works with both null and None\ndict_str = '{\"key\": \"value\"}'\nlist_str = '[\"key\", \"value\"]'\nnested_dict_str = (\n    '{\"name\": \"John\", \"age\": 30, \"attributes\": {\"height\": 180, \"weight\": 70}}'\n)\nyaml_dict_str = \"key: value\"\nyaml_nested_dict_str = (\n    \"name: John\\nage: 30\\nattributes:\\n  height: 180\\n  weight: 70\"\n)\nyaml_list_str = \"- key\\n- value\"\n```\n\n----------------------------------------\n\nTITLE: Implementing a Complete Object Count Task Pipeline with AdalFlow\nDESCRIPTION: A class that defines a complete task pipeline for counting objects, configuring parameters for optimization and initializing the generator with appropriate processors.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict, Union\nimport adalflow as adal\n\n\nclass ObjectCountTaskPipeline(adal.Component):\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        super().__init__()\n\n        system_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=True,\n            param_type=ParameterType.PROMPT,\n        )\n        few_shot_demos = adal.Parameter(\n            data=None,\n            role_desc=\"To provide few shot demos to the language model\",\n            requires_opt=True,\n            param_type=ParameterType.DEMOS,\n        )\n\n        self.llm_counter = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            template=few_shot_template,\n            prompt_kwargs={\n                \"system_prompt\": system_prompt,\n                \"few_shot_demos\": few_shot_demos,\n            },\n            output_processors=parse_integer_answer,\n            use_cache=True,\n        )\n\n    def call(\n        self, question: str, id: str = None\n    ) -> Union[adal.GeneratorOutput, adal.Parameter]:\n        output = self.llm_counter(prompt_kwargs={\"input_str\": question}, id=id)\n        return output\n```\n\n----------------------------------------\n\nTITLE: Initializing AdalFlow Components and Templates for Consultant Bot\nDESCRIPTION: Sets up necessary imports, initializes AdalFlow components, and defines prompt templates for doctor, lawyer, and router roles using Jinja2. Also configures environment variables and logging.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/intermediate.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport re\nfrom adalflow.core import Component, Generator, Sequential\nfrom adalflow.components.model_client import OpenAIClient\nfrom adalflow.components.model_client import GroqAPIClient\nfrom adalflow.utils import (\n    setup_env,\n)  # make sure you have a .env file with OPENAI_API_KEY and GROQ_API_KEY\n\nsetup_env(\".env\")\n```\n\nLANGUAGE: python\nCODE:\n```\ntemplate_doc = r\"\"\"<SYS> You are a doctor </SYS> User: {{input_str}}\"\"\"\ntemplate_law = r\"\"\"<SYS> You are a lawyer </SYS> User: {{input_str}}\"\"\"\ntemplate_router = r\"\"\"<SYS> You are a router who will route a user question to the right generator.\n            Here are your choices in form of key: value pairs:\n             {% for key, value in choices.items() %}\n                {{ key }}: {{ value }}\n             {% endfor %}\n            Output the key of your choice.\n            </SYS> User question: {{input_str}}\n            You:\n            \"\"\"\n```\n\nLANGUAGE: python\nCODE:\n```\n# Let's turn on the library log to help with debugging.\nfrom adalflow.utils import get_logger\n\nget_logger()\n```\n\n----------------------------------------\n\nTITLE: Securely Inputting API Keys for OpenAI and GROQ\nDESCRIPTION: This snippet prompts the user to securely enter their OpenAI and GROQ API keys using the getpass function, which hides the input. These keys are essential for authenticating with the respective services.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_tracing.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\ngroq_api_key = getpass(\"Please enter your GROQ API key: \")\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM Evaluator for RAG Assessment in Python\nDESCRIPTION: Sets up an LLM-based evaluator using OpenAI client to assess answer predictions. The evaluator uses a JSON output format to compare predicted answers with ground truth, returning boolean judgements based on content matching.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/eval_a_rag.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nllm_evaluator = Generator(\n    model_client=OpenAIClient(),\n    prompt=Prompt(DEFAULT_LLM_EVALUATOR_PROMPT),\n    output_processors=Sequential(JsonParser()),\n    preset_prompt_kwargs={\n        \"task_desc_str\": r\"\"\"\n            You are a helpful assistant.\n            Given the question, ground truth answer, and predicted answer, you need to answer the judgement query.\n            Output True or False according to the judgement query following this JSON format:\n            {\n                \"judgement\": True\n            }\n            \"\"\"\n    },\n    model_kwargs=settings[\"llm_evaluator\"],\n)\nllm_judge = LLMasJudge(llm_evaluator)\njudgement_query = (\n    \"For the question, does the predicted answer contain the ground truth answer?\"\n)\navg_judgement, judgement_list = llm_judge.compute_judgement(\n    all_questions, all_pred_answer, all_gt_answer, judgement_query\n)\nprint(f\"Average judgement: {avg_judgement}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing AdalFlow's DataClass with Required Field Ordering\nDESCRIPTION: Example showing how to implement AdalFlow's DataClass to maintain field ordering and support required fields after optional fields, which is not possible with standard dataclasses.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import DataClass, required_field\n\n@dataclass\nclass TrecData2(DataClass):\n    question: Question = field(\n        metadata={\"desc\": \"The question asked by the user\"}\n    ) # Required field, you have to provide the question field at the instantiation\n    label: int = field(\n        metadata={\"desc\": \"The label of the question\"}, default=0\n```\n\n----------------------------------------\n\nTITLE: Referencing AdalFlow Core Components in Python\nDESCRIPTION: This code snippet demonstrates how to reference the core component classes and functions in AdalFlow. It includes the base Component class, FuncComponent for function-based components, Sequential for container components, and the func_to_component utility function.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/component.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n- :class:`core.component.Component`\n- :class:`core.component.FuncComponent`\n- :class:`core.container.Sequential`\n- :func:`core.component.func_to_component`\n```\n\n----------------------------------------\n\nTITLE: RST Table Definition for RAG Pipeline Components\nDESCRIPTION: ReStructuredText table defining RAG pipeline components, improvement techniques and evaluation metrics for different stages of the RAG system.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/build_a_rag.rst#2025-04-14_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n========================  =========================  =========================================\nRAG Pipeline Component     Improvement Techniques     Evaluation Metric\n========================  =========================  =========================================\nData Preparation           - Text preprocessing       -\n                           - Chunking Strategy\n\nEmbedding                 - Embedding Fine-tuning     -\n\nIndexing                   -                          -\n\nRetrieval                  - Retrieval Optimization    - HIT@K\n                           - Query Enhancement         - MRR@K\n                           - Reranking                 - MAP@K\n                                                       - NDCG@K\n                                                       - Ragas context relevancy, precision, recall\n\nCompletion                 - Prompt Engineering        - Ragas answer relevancy\n                           - LLM Fine-tuning           - AutoAIS\n                                                       - ROUGE\n                                                       - BLEU\n                                                       - METEOR\n                                                       - F1 Score\n                                                       - BERTScore\n                                                       - UniEval\n                                                       - G-Eval\n========================  =========================  =========================================\n\n```\n\n----------------------------------------\n\nTITLE: AdalFlow Prompt Template Implementation\nDESCRIPTION: Complete example demonstrating how to create and use a custom prompt template with Jinja2 syntax, including system message, tools list, and user input formatting.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/prompt.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\n\ntemplate = r\"\"\"<START_OF_SYSTEM_MESSAGE>{{ task_desc_str }}<END_OF_SYSTEM_MESSAGE>\n{# tools #}\n{% if tools %}\n<TOOLS>\n{% for tool in tools %}\n{{loop.index}}. {{ tool }}\n{% endfor %}\n</TOOLS>{% endif %}\n<START_OF_USER>{{ input_str }} <END_OF_USER>\"\"\"\n\ntask_desc_str = \"You are a helpful assitant\"\n\ntools = [\"google\", \"wikipedia\", \"wikidata\"]\n\nprompt = adal.Prompt(\n    template=template,\n    prompt_kwargs={\n        \"task_desc_str\": task_desc_str,\n        \"tools\": tools,\n    },\n)\n\nprint(prompt(input_str=\"What is the capital of France?\"))\n```\n\n----------------------------------------\n\nTITLE: Configuring AdalFlow Training Function\nDESCRIPTION: This function sets up and runs the AdalFlow training process. It configures the ObjectCountAdalComponent, initializes the Trainer, and fits the model using provided datasets.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef train(\n    train_batch_size=4,  # larger batch size is not that effective, probably because of llm's lost in the middle\n    raw_shots: int = 1,\n    bootstrap_shots: int = 1,\n    max_steps=1,\n    num_workers=4,\n    strategy=\"random\",\n    debug=False,\n):\n    adal_component = ObjectCountAdalComponent(\n        **gpt_3_model,\n        teacher_model_config=gpt_4o_model,\n        text_optimizer_model_config=gpt_4o_model,\n        backward_engine_model_config=gpt_4o_model\n    )\n    print(adal_component)\n    trainer = Trainer(\n        train_batch_size=train_batch_size,\n        strategy=strategy,\n        max_steps=max_steps,\n        num_workers=num_workers,\n        adaltask=adal_component,\n        raw_shots=raw_shots,\n        bootstrap_shots=bootstrap_shots,\n        debug=debug,\n        weighted_sampling=True,\n    )\n    print(trainer)\n\n    train_dataset, val_dataset, test_dataset = load_datasets()\n    trainer.fit(\n        train_dataset=train_dataset,\n        val_dataset=val_dataset,\n        test_dataset=test_dataset,\n        debug=debug,\n    )\n```\n\n----------------------------------------\n\nTITLE: Initializing Generator with GroqAPIClient in Python\nDESCRIPTION: This snippet shows how to initialize a Generator object with GroqAPIClient, set model parameters, and generate output based on a given prompt.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ngenerator = Generator(\n    model_client=GroqAPIClient(),\n    model_kwargs={\"model\": \"llama3-8b-8192\"},\n    template=template,\n    prompt_kwargs={\"task_desc_str\": \"You are a helpful assistant\"},\n)\n\nprompt_kwargs = {\"input_str\": \"What is LLM?\"}\n\ngenerator.print_prompt(\n    **prompt_kwargs,\n)\noutput = generator(\n    prompt_kwargs=prompt_kwargs,\n)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Generator Performance\nDESCRIPTION: Evaluates the generator component using fuzzy match accuracy metrics.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/eval_a_rag.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ngenerator_evaluator = AnswerMacthEvaluator(type=\"fuzzy_match\")\nanswer_match_acc, match_acc_list = generator_evaluator.compute_match_acc(\n    all_pred_answer, all_gt_answer\n)\nprint(f\"Answer match accuracy: {answer_match_acc}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing PyTorch vs AdalFlow Components Comparison\nDESCRIPTION: Comparative example showing how to implement components in PyTorch versus AdalFlow, demonstrating the structural similarities and differences between the two frameworks.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/component.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n\nfrom adalflow.core import Component, Generator\nfrom adalflow.components.model_client import OpenAIClient\n\ntemplate_doc = r\"\"\"<SYS> You are a doctor </SYS> User: {{input_str}}\"\"\"\n\nclass DocQA(Component):\n    def __init__(self):\n        super().__init__()\n        self.doc = Generator(\n            template=template_doc,\n            model_client=OpenAIClient(),\n            model_kwargs={\"model\": \"gpt-3.5-turbo\"},\n        )\n\n    def call(self, query: str) -> str:\n        return self.doc(prompt_kwargs={\"input_str\": query}).data\n```\n\n----------------------------------------\n\nTITLE: Defining Structured Output with DataClass in AdalFlow\nDESCRIPTION: This code defines a structured output using Python's dataclass, specifically for a question-answering task. It creates a QAOutput class with 'thought' and 'answer' fields, which will be used by the DataClassParser.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/generator.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass QAOutput(DataClass):\n    thought: str = field(\n        metadata={\n            \"desc\": \"Your thought process for the question to reach the answer.\"\n        }\n    )\n    answer: int = field(metadata={\"desc\": \"The answer to the question.\"})\n\n    __output_fields__ = [\"thought\", \"answer\"]\n```\n\n----------------------------------------\n\nTITLE: Computing Text Evaluation Metrics\nDESCRIPTION: Implementation of functions to compute ROUGE and BLEU scores for text evaluation using TorchMetrics. The code shows how to compare a ground truth text against a prediction using these metrics.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngt = \"Brazil has won 5 FIFA World Cup titles\"\npred = \"Brazil is the five-time champion of the FIFA WorldCup.\"\n\ndef compute_rouge(gt, pred):\n    from torchmetrics.text.rouge import ROUGEScore\n\n    rouge = ROUGEScore()\n    return rouge(pred, gt)\n\n\ndef compute_bleu(gt, pred):\n    from torchmetrics.text.bleu import BLEUScore\n\n    bleu = BLEUScore()\n    return bleu([pred], [[gt]])\n```\n\n----------------------------------------\n\nTITLE: Implementing AgenticRAG with AdalFlow in Python\nDESCRIPTION: This class implements an AgenticRAG component using AdalFlow. It initializes a DspyRetriever and a ReActAgent, and provides a method for processing queries using the agent.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nclass AgenticRAG(adal.Component):\n    def __init__(self, model_client, model_kwargs):\n        super().__init__()\n        self.dspy_retriever = DspyRetriever(top_k=2)\n\n        def dspy_retriever_as_tool(\n            input: str,\n            id: Optional[str] = None,\n        ) -> List[str]:\n            r\"\"\"Retrieves the top 2 passages from using input as the query.\n            Ensure you get all the context to answer the original question.\n            \"\"\"\n            output = self.dspy_retriever(input=input, id=id)\n            parsed_output = output\n            if isinstance(output, adal.Parameter):\n                parsed_output = output.data.documents\n                return parsed_output\n            documents = parsed_output.documents\n            return documents\n\n        tools = [\n            FunctionTool(dspy_retriever_as_tool, component=self.dspy_retriever),\n        ]\n\n        self.agent = ReActAgent(\n            max_steps=3,\n            add_llm_as_fallback=False,\n            tools=tools,\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n        )\n\n    def bicall(self, input: str, id: str = None) -> str:\n        out = self.agent(input=input, id=id)\n        return out\n```\n\n----------------------------------------\n\nTITLE: Building Prompt with Tools in Python\nDESCRIPTION: Demonstrates how to build a prompt using the Prompt class with tool definitions in YAML format.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.prompt_builder import Prompt\n\nprompt = Prompt(template=template)\nsmall_tool_manager = ToolManager(tools=tools[:2])\n\nrenered_prompt = prompt(tools=small_tool_manager.yaml_definitions)\nprint(renered_prompt)\n```\n\n----------------------------------------\n\nTITLE: Defining QAOutput DataClass for Structured LLM Responses in Python\nDESCRIPTION: This snippet defines a QAOutput class using AdalFlow's DataClass. It structures the output with 'explanation' and 'example' fields, providing metadata for each.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/README.md#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass QAOutput(DataClass):\n    explanation: str = field(\n        metadata={\"desc\": \"A brief explanation of the concept in one sentence.\"}\n    )\n    example: str = field(metadata={\"desc\": \"An example of the concept in a sentence.\"})\n```\n\n----------------------------------------\n\nTITLE: Training Process Implementation\nDESCRIPTION: Python code showing how to initialize training mode and enable backpropagation with teacher demonstrations\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/optimizer.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nself.task.train() # ensure we use forward that will return a parameter and then we can attach the backward engine for gradients, and if it has a teacher, we will attach a demo propose function.\n```\n\n----------------------------------------\n\nTITLE: Initializing and Querying RAG System\nDESCRIPTION: This code initializes the RAG system with sample documents, prepares the database, and demonstrates how to query the system with a sample question.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Prepare initial documents\ndoc1 = Document(\n    meta_data={\"title\": \"Li Yin's profile\"},\n    text=\"My name is Li Yin, I love rock climbing\" + \"lots of nonsense text\" * 500,\n    id=\"doc1\",\n)\ndoc2 = Document(\n    meta_data={\"title\": \"Interviewing Li Yin\"},\n    text=\"lots of more nonsense text\" * 250\n    + \"Li Yin is an AI researcher and a software engineer\"\n    + \"lots of more nonsense text\" * 250,\n    id=\"doc2\",\n)\n\n# Prepare the database (only runs once)\nprepare_database_with_index([doc1, doc2], index_file=\"index.faiss\")\n\n# Initialize RAG\nrag = RAG(index_file=\"index.faiss\")\nprint(rag)\n\n# Query the RAG system\nquery = \"What is Li Yin's hobby and profession?\"\nresponse = rag.call(query)\nprint(f\"Response: {response}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing an Object Counting Task Pipeline in AdalFlow\nDESCRIPTION: A complete implementation of a task pipeline for object counting questions using AdalFlow. It sets up parameters for system prompts and demonstrations that can be optimized, and configures a language model generator with the appropriate template and output processing.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict, Union\nimport adalflow as adal\n\n\nclass ObjectCountTaskPipeline(adal.Component):\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        super().__init__()\n\n        system_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=True,\n            param_type=ParameterType.PROMPT,\n        )\n        few_shot_demos = adal.Parameter(\n            data=None,\n            role_desc=\"To provide few shot demos to the language model\",\n            requires_opt=True,\n            param_type=ParameterType.DEMOS,\n        )\n\n        self.llm_counter = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            template=few_shot_template,\n            prompt_kwargs={\n                \"system_prompt\": system_prompt,\n                \"few_shot_demos\": few_shot_demos,\n            },\n            output_processors=parse_integer_answer,\n            use_cache=True,\n        )\n\n    def call(\n        self, question: str, id: str = None\n    ) -> Union[adal.GeneratorOutput, adal.Parameter]:\n        output = self.llm_counter(prompt_kwargs={\"input_str\": question}, id=id)\n        return output\n```\n\n----------------------------------------\n\nTITLE: Implementing VallinaRAGAdal Training Component\nDESCRIPTION: Training component that configures evaluation functions, loss calculations, and training pipeline execution. Handles both inference and training modes for the RAG system.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass VallinaRAGAdal(adal.AdalComponent):\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        backward_engine_model_config: Dict | None = None,\n        teacher_model_config: Dict | None = None,\n        text_optimizer_model_config: Dict | None = None,\n    ):\n        task = VanillaRAG(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            passages_per_hop=3,\n        )\n        eval_fn = AnswerMatchAcc(type=\"fuzzy_match\").compute_single_item\n        loss_fn = adal.EvalFnToTextLoss(\n            eval_fn=eval_fn, eval_fn_desc=\"fuzzy_match: 1 if str(y) in str(y_gt) else 0\"\n        )\n        super().__init__(\n            task=task,\n            eval_fn=eval_fn,\n            loss_fn=loss_fn,\n            backward_engine_model_config=backward_engine_model_config,\n            teacher_model_config=teacher_model_config,\n            text_optimizer_model_config=text_optimizer_model_config,\n        )\n```\n\n----------------------------------------\n\nTITLE: Formatting Instances to JSON and YAML in Python\nDESCRIPTION: Illustrates how to format instances of BaseDataClass to JSON and YAML. This functionality is useful for creating structured examples or outputs in different formats.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/introduction_to_basedataclass.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom core.base_data_class import BaseDataClass\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass MyOutputs(BaseDataClass):\n    age: int = field(metadata={\"desc\": \"The age of the person\", \"prefix\": \"Age:\"})\n    name: str = field(metadata={\"desc\": \"The name of the person\", \"prefix\": \"Name:\"})\n\nmy_instance = MyOutputs(age=25, name=\"John Doe\")\n# my_instance json signiture\nprint(my_instance.to_json())\n# my_instance yaml signiture\nprint(my_instance.to_yaml())\n```\n\n----------------------------------------\n\nTITLE: Configuring Optimizers in ObjectCountAdalComponent\nDESCRIPTION: Configures both DemoOptimizer and PromptOptimizer for the ObjectCountAdalComponent using helper methods.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef configure_optimizers(self):\n    to = super().configure_text_optimizer_helper(**self.text_optimizer_model_config)\n    do = super().configure_demo_optimizer_helper()\n    return to  + do\n```\n\n----------------------------------------\n\nTITLE: Integrating BaseDataClass with Prompt in AdalFlow\nDESCRIPTION: Demonstrates how to use BaseDataClass in conjunction with the Prompt class in AdalFlow. This example shows how to create structured output formats and examples for LLM interactions.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/introduction_to_basedataclass.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom core.base_data_class import BaseDataClass\nfrom dataclasses import dataclass, field\nfrom core.prompt_builder import Prompt\n\n# define a dataclass formatting the data\n@dataclass\nclass JokeOutput(BaseDataClass):\n    setup: str = field(metadata={\"desc\": \"question to set up a joke\"}, default=\"\")\n    punchline: str = field(metadata={\"desc\": \"answer to resolve the joke\"}, default=\"\")\n\n# initialize an example\njoke_example = JokeOutput(\n    setup=\"Why did the scarecrow win an award?\",\n    punchline=\"Because he was outstanding in his field.\",\n)\n\nOUTPUT_FORMAT = r\"\"\"\nYour output should be formatted as a standard YAML instance with the following schema:\n```\n{{schema}}\n```\n{% if example %}\nHere is an example:\n```\n{{example}}\n```\n{% endif %}\n\"\"\"\n\nprompt_template = Prompt(template=OUTPUT_FORMAT)\nprompt = prompt_template(schema=JokeOutput.to_yaml_signature(), example=joke_example.to_yaml())\n\nprint(prompt)\n```\n\n----------------------------------------\n\nTITLE: Implementing ChatBot Class with AdalFlow\nDESCRIPTION: This code defines the ChatBot class, which inherits from AdalFlow's Component. It initializes a Generator with OpenAI's model and a Memory component to store chat history. The call method implements the chat loop, processing user input and generating responses.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/question_answering/chatbot.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Build the ChatBot pipeline\nclass ChatBot(Component):\n    def __init__(self):\n        super().__init__()\n        self.generator = Generator(\n            model_client=OpenAIClient(), model_kwargs={\"model\": \"gpt-4o-mini\"}\n        )\n        self.chat_history = Memory()  # Memory to store the chat history\n\n    def call(self) -> str:\n        print(\"Welcome to the ChatBot. Type anything to chat. Type 'exit' to end.\")\n        while True:\n            user_input = input(\"You: \")\n            if user_input.lower() == \"exit\":\n                print(\"Goodbye!\")\n                break\n            chat_history_str = self.chat_history()\n            # Generate the response from the user input and chat history\n            response = self.generator(\n                prompt_kwargs={\n                    \"input_str\": user_input,\n                    \"chat_history_str\": chat_history_str,\n                },\n            )\n            # Save the user input and response to the memory\n            self.chat_history.add_dialog_turn(\n                user_query=user_input, assistant_response=response\n            )\n            print(f\"ChatBot: {response}\")\n\n\nchatbot = ChatBot()\nprint(chatbot)\n```\n\n----------------------------------------\n\nTITLE: Defining RAG Prompt Template and Task Description\nDESCRIPTION: This snippet defines the prompt template and task description for the RAG system, specifying the format for input, context, and expected output.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nRAG_PROMPT_TEMPLATE = r\"\"\"<START_OF_SYSTEM_MESSAGE>\n{{task_desc}}\n<END_OF_SYSTEM_MESSAGE>\n<START_OF_USER>\n{{input_str}}\n{{context_str}}\n<END_OF_USER>\n\"\"\"\n\nrag_prompt_task_desc = r\"\"\"\nYou are a helpful assistant.\n\nYour task is to answer the query that may or may not come with context information.\nWhen context is provided, you should stick to the context and less on your prior knowledge to answer the query.\n\nOutput JSON format:\n{\n    \"answer\": \"The answer to the query\",\n}\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Single Task ChatBot with Router in AdalFlow\nDESCRIPTION: Defines a ChatBotWithRouter class that combines multiple generators and a router into a single task. It uses different models for doctor and lawyer roles, and includes a method for creating generator signatures.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/intermediate.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass ChatBotWithRouter(Component):\n    def __init__(self):\n        super().__init__()\n        model_1_kwargs = {\n            \"model\": \"gpt-3.5-turbo\",\n        }\n        model_2_kwargs = {\"model\": \"llama3-8b-8192\"}\n        self.doc = Generator(\n            template=template_doc,\n            model_client=OpenAIClient(),\n            model_kwargs=model_1_kwargs,\n        )\n        self.lawyer = Generator(\n            template=template_law,\n            model_client=GroqAPIClient(),\n            model_kwargs=model_2_kwargs,\n        )\n        self.router_choices = {\n            \"doctor\": self.create_generator_signature(self.doc),\n            \"lawyer\": self.create_generator_signature(self.lawyer),\n            \"other\": \"Choose me the question does not apply to other choices.\",\n        }\n        print(self.router_choices)\n\n        self.router = Generator(\n            template=template_router,\n            model_client=OpenAIClient(),\n            model_kwargs=model_1_kwargs,\n        )\n\n    def call(self, query: str) -> str:\n        choice = self.router(\n            prompt_kwargs={\"input_str\": query, \"choices\": self.router_choices}\n        ).data\n        if choice == \"doctor\":\n            return self.doc(prompt_kwargs={\"input_str\": query}).data\n        elif choice == \"lawyer\":\n            return self.lawyer(prompt_kwargs={\"input_str\": query}).data\n        else:\n            return \"Sorry, I cannot help you with that.\"\n\n    def create_generator_signature(self, generator: Generator):\n        template = generator.template\n        pattern = r\"<SYS>(.*?)</SYS>\"\n\n        matches = re.findall(pattern, template)\n        for match in matches:\n            print(\"Content between <SYS> tags:\", match)\n            return match\n```\n\n----------------------------------------\n\nTITLE: FAISS Retriever Implementation\nDESCRIPTION: Implementation of FAISS-based retriever for semantic search functionality.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.retriever import FAISSRetriever\nretriever = FAISSRetriever(top_k=2, embedder=embedder, documents=documents_embeddings)\n\nprint(retriever)\n```\n\n----------------------------------------\n\nTITLE: Defining Sample Functions and Classes\nDESCRIPTION: Defines a set of sample functions and a Point class for demonstration purposes. Includes synchronous and asynchronous functions, as well as a NumPy function.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_function_calls.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\nfrom typing import List\nimport numpy as np\nimport time\nimport asyncio\n\n\ndef multiply(a: int, b: int) -> int:\n    \"\"\"Multiply two numbers.\"\"\"\n    time.sleep(1)\n    return a * b\n\n\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers.\"\"\"\n    time.sleep(1)\n    return a + b\n\n\nasync def divide(a: float, b: float) -> float:\n    \"\"\"Divide two numbers.\"\"\"\n    await asyncio.sleep(1)\n    return float(a) / b\n\n\nasync def search(query: str) -> List[str]:\n    \"\"\"Search for query and return a list of results.\"\"\"\n    await asyncio.sleep(1)\n    return [\"result1\" + query, \"result2\" + query]\n\n\ndef numpy_sum(arr: np.ndarray) -> float:\n    \"\"\"Sum the elements of an array.\"\"\"\n    return np.sum(arr)\n\n\nx = 2\n\n\n@dataclass\nclass Point:\n    x: int\n    y: int\n\n\ndef add_points(p1: Point, p2: Point) -> Point:\n    return Point(p1.x + p2.x, p1.y + p2.y)\n```\n\n----------------------------------------\n\nTITLE: Implementing Object Count Task Pipeline in Python\nDESCRIPTION: This class defines the task pipeline for object counting, including system prompt and few-shot demos as parameters, and uses a Generator for LLM-based counting.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict, Union\nimport adalflow as adal\n\n\nclass ObjectCountTaskPipeline(adal.Component):\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        super().__init__()\n\n        system_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=True,\n            param_type=ParameterType.PROMPT,\n        )\n        few_shot_demos = adal.Parameter(\n            data=None,\n            role_desc=\"To provide few shot demos to the language model\",\n            requires_opt=True,\n            param_type=ParameterType.DEMOS,\n        )\n\n        self.llm_counter = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            template=few_shot_template,\n            prompt_kwargs={\n                \"system_prompt\": system_prompt,\n                \"few_shot_demos\": few_shot_demos,\n            },\n            output_processors=parse_integer_answer,\n            use_cache=True,\n        )\n\n    def call(\n        self, question: str, id: str = None\n    ) -> Union[adal.GeneratorOutput, adal.Parameter]:\n        output = self.llm_counter(prompt_kwargs={\"input_str\": question}, id=id)\n        return output\n```\n\n----------------------------------------\n\nTITLE: Implementing HotPotQA Task Pipeline in Python using AdalComponent\nDESCRIPTION: A complete implementation of a custom AdalComponent class for the HotPotQA task. Includes initialization, task handling, loss computation, optimizer configuration, evaluation, and teacher generator setup. The class demonstrates integration with evaluation metrics and loss functions for question-answering tasks.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/adalcomponent.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass HotPotQARAGAdal(AdalComponent):\n    # TODO: move teacher model or config in the base class so users dont feel customize too much\n    def __init__(self, task: Component, teacher_model_config: dict):\n        super().__init__()\n        self.task = task\n        self.teacher_model_config = teacher_model_config\n\n        self.evaluator = AnswerMatchAcc(\"fuzzy_match\")\n        self.eval_fn = self.evaluator.compute_single_item\n\n    def handle_one_task_sample(\n        self, sample: HotPotQAData\n    ) -> Any:  # TODO: auto id, with index in call train examples\n        return self.task, {\"question\": sample.question, \"id\": sample.id}\n\n    def handle_one_loss_sample(\n        self, sample: HotPotQAData, y_pred: Any\n    ) -> Tuple[Callable, Dict]:\n        return self.loss_fn.forward, {\n            \"kwargs\": {\n                \"y\": y_pred,\n                \"y_gt\": Parameter(\n                    data=sample.answer,\n                    role_desc=\"The ground truth(reference correct answer)\",\n                    alias=\"y_gt\",\n                    requires_opt=False,\n                ),\n            }\n        }\n\n    def configure_optimizers(self, *args, **kwargs):\n\n        # TODO: simplify this, make it accept generator\n        parameters = []\n        for name, param in self.task.named_parameters():\n            param.name = name\n            parameters.append(param)\n        do = BootstrapFewShot(params=parameters)\n        return [do]\n\n    def evaluate_one_sample(\n        self, sample: Any, y_pred: Any, metadata: Dict[str, Any]\n    ) -> Any:\n\n        # we need \"context\" be passed as metadata\n        # print(f\"sample: {sample}, y_pred: {y_pred}\")\n        # convert pred to Dspy structure\n\n        # y_obj = convert_y_pred_to_dataclass(y_pred)\n        # print(f\"y_obj: {y_obj}\")\n        # raise ValueError(\"Stop here\")\n        if metadata:\n            return self.eval_fn(sample, y_pred, metadata)\n        return self.eval_fn(sample, y_pred)\n\n    def configure_teacher_generator(self):\n        super().configure_teacher_generator(**self.teacher_model_config)\n\n    def configure_loss_fn(self):\n        self.loss_fn = EvalFnToTextLoss(\n            eval_fn=self.eval_fn,\n            eval_fn_desc=\"ObjectCountingEvalFn, Output accuracy score: 1 for correct, 0 for incorrect\",\n            backward_engine=None,\n        )\n```\n\n----------------------------------------\n\nTITLE: TREC Classifier Component Implementation\nDESCRIPTION: Implements the main classifier component that processes questions and returns structured outputs using the configured models.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_classification_optimization.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass TRECClassifierStructuredOutput(adal.Component):\n\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        super().__init__()\n\n        label_desc = [\n            {\"label\": label, \"desc\": desc}\n            for label, desc in zip(_COARSE_LABELS, _COARSE_LABELS_DESC)\n        ]\n\n        task_desc_str = adal.Prompt(\n            template=task_desc_template, prompt_kwargs={\"classes\": label_desc}\n        )()\n\n        self.data_class = TRECExtendedData\n        self.data_class.set_task_desc(task_desc_str)\n\n        self.parser = adal.DataClassParser(\n            data_class=self.data_class, return_data_class=True, format_type=\"yaml\"\n        )\n\n        prompt_kwargs = {\n            \"system_prompt\": adal.Parameter(\n                data=self.parser.get_task_desc_str(),\n                role_desc=\"Task description\",\n                requires_opt=True,\n                param_type=adal.ParameterType.PROMPT,\n            ),\n            \"output_format_str\": adal.Parameter(\n                data=self.parser.get_output_format_str(),\n                role_desc=\"Output format requirements\",\n                requires_opt=False,\n                param_type=adal.ParameterType.PROMPT,\n            ),\n            \"few_shot_demos\": adal.Parameter(\n                data=None,\n                requires_opt=True,\n                role_desc=\"Few shot examples to help the model\",\n                param_type=adal.ParameterType.DEMOS,\n            ),\n        }\n\n        self.llm = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            prompt_kwargs=prompt_kwargs,\n            template=template,\n            output_processors=self.parser,\n            use_cache=True,\n        )\n\n    def _prepare_input(self, question: str):\n        input_data = self.data_class(question=question)\n        input_str = self.parser.get_input_str(input_data)\n        prompt_kwargs = {\n            \"input_str\": adal.Parameter(\n                data=input_str, requires_opt=False, role_desc=\"input to the LLM\"\n            )\n        }\n        return prompt_kwargs\n\n    def bicall(\n        self, question: str, id: Optional[str] = None\n    ) -> Union[adal.GeneratorOutput, adal.Parameter]:\n        prompt_kwargs = self._prepare_input(question)\n        output = self.llm(prompt_kwargs=prompt_kwargs, id=id)\n        return output\n```\n\n----------------------------------------\n\nTITLE: Creating Document and DialogTurn Objects\nDESCRIPTION: Demonstrates the creation of Document objects from the initial data and DialogTurn objects from the conversation turns.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# create Document objects\nfrom adalflow.core.types import Document\n\n# we will save the content to text and title in the meta_data\ndocuments = [\n    Document(text=doc[\"content\"], meta_data={\"title\": doc[\"title\"]})\n    for doc in org_documents\n]\nprint(documents)\n```\n\nLANGUAGE: python\nCODE:\n```\n# create DialogTurn objects\n\nfrom adalflow.core.types import DialogTurn, UserQuery, AssistantResponse\n\ndialog_turns = [\n    DialogTurn(\n        user_query=UserQuery(query_str=turn[\"user\"]),\n        assistant_response=AssistantResponse(response_str=turn[\"system\"]),\n        user_query_timestamp=turn[\"user_time\"],\n        assistant_response_timestamp=turn[\"system_time\"],\n    )\n    for turn in turns\n]\nprint(dialog_turns)\n```\n\n----------------------------------------\n\nTITLE: Implementing TrecClassifierAdal with AdalFlow in Python\nDESCRIPTION: This class implements a TREC classifier using AdalFlow components. It initializes the task, evaluation function, and loss function, and provides methods for preparing the task, evaluation, and loss computation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nclass TrecClassifierAdal(adal.AdalComponent):\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        teacher_model_config: Dict,\n        backward_engine_model_config: Dict,\n        text_optimizer_model_config: Dict,\n    ):\n        task = TRECClassifierStructuredOutput(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        loss_fn = adal.EvalFnToTextLoss(\n            eval_fn=eval_fn,\n            eval_fn_desc=\"exact_match: 1 if str(y) == str(y_gt) else 0. When the LLM prediction failed with format parsing which results with errors, we set y_pred = -1\",\n        )\n        super().__init__(\n            task=task,\n            eval_fn=eval_fn,\n            loss_fn=loss_fn,\n            backward_engine_model_config=backward_engine_model_config,\n            text_optimizer_model_config=text_optimizer_model_config,\n            teacher_model_config=teacher_model_config,\n        )\n\n    def prepare_task(self, sample: TRECExtendedData):\n        return self.task.bicall, {\"question\": sample.question, \"id\": sample.id}\n\n    def prepare_eval(\n        self, sample: TRECExtendedData, y_pred: adal.GeneratorOutput\n    ) -> float:\n        y_label = -1\n        if y_pred and y_pred.data is not None and y_pred.data.class_name is not None:\n            y_label = y_pred.data.class_name\n        return self.eval_fn, {\"y\": y_label, \"y_gt\": sample.class_name}\n\n    def prepare_loss(\n        self, sample: TRECExtendedData, y_pred: adal.Parameter, *args, **kwargs\n    ) -> Tuple[Callable[..., Any], Dict]:\n        full_response = y_pred.data\n        y_label = -1\n        if (full_response and full_response.data is not None\n            and full_response.data.class_name is not None):\n            y_label = full_response.data.class_name\n\n        y_pred.eval_input = y_label\n        y_gt = adal.Parameter(\n            name=\"y_gt\",\n            data=sample.class_name,\n            eval_input=sample.class_name,\n            requires_opt=False,\n        )\n        return self.loss_fn, {\n            \"kwargs\": {\"y\": y_pred, \"y_gt\": y_gt},\n            \"id\": sample.id,\n        }\n```\n\n----------------------------------------\n\nTITLE: Implementing ObjectCountAdalComponent Class\nDESCRIPTION: This code defines the ObjectCountAdalComponent class, which inherits from adal.AdalComponent. It initializes the component with model configurations, loss functions, and evaluation methods for object counting tasks.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nclass ObjectCountAdalComponent(adal.AdalComponent):\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        backward_engine_model_config: Dict,\n        teacher_model_config: Dict,\n        text_optimizer_model_config: Dict,\n    ):\n        task = ObjectCountTaskPipeline(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        loss_fn = adal.EvalFnToTextLoss(\n            eval_fn=eval_fn,\n            eval_fn_desc=\"exact_match: 1 if str(y) == str(y_gt) else 0\",\n        )\n        super().__init__(task=task, eval_fn=eval_fn, loss_fn=loss_fn)\n\n        self.backward_engine_model_config = backward_engine_model_config\n        self.teacher_model_config = teacher_model_config\n        self.text_optimizer_model_config = text_optimizer_model_config\n```\n\n----------------------------------------\n\nTITLE: Creating a Few-Shot Template for LLM Prompting\nDESCRIPTION: A Jinja template that structures the prompt with system instructions, optional few-shot demonstrations, and the input question for the language model.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfew_shot_template = r\"\"\"<START_OF_SYSTEM_PROMPT>\n{{system_prompt}}\n{# Few shot demos #}\n{% if few_shot_demos is not none %}\nHere are some examples:\n{{few_shot_demos}}\n{% endif %}\n<END_OF_SYSTEM_PROMPT>\n<START_OF_USER>\n{{input_str}}\n<END_OF_USER>\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Implementing DspyRetriever for AdalFlow\nDESCRIPTION: This class implements a retriever using dspy's Retrieve component, adapting it to the AdalFlow framework. It includes methods for retrieval and a test function.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass DspyRetriever(adal.Retriever):\n    def __init__(self, top_k: int = 3):\n        super().__init__()\n        self.top_k = top_k\n        self.dspy_retriever = dspy.Retrieve(k=top_k)\n\n    def call(\n        self, input: str, top_k: Optional[int] = None\n    ) -> List[adal.RetrieverOutput]:\n\n        k = top_k or self.top_k\n\n        output = self.dspy_retriever(query_or_queries=input, k=k)\n        final_output: List[RetrieverOutput] = []\n        documents = output.passages\n\n        final_output.append(\n            RetrieverOutput(\n                query=input,\n                documents=documents,\n                doc_indices=[],\n            )\n        )\n        return final_output\n\n\ndef test_retriever():\n    question = \"How many storeys are in the castle that David Gregory inherited?\"\n    retriever = DspyRetriever(top_k=3)\n    retriever_out = retriever(input=question)\n    print(f\"retriever_out: {retriever_out}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring RAG Components\nDESCRIPTION: This code defines the configuration settings for various components of the RAG system, including the embedder, retriever, generator, and text splitter.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconfigs = {\n    \"embedder\": {\n        \"batch_size\": 100,\n        \"model_kwargs\": {\n            \"model\": \"text-embedding-3-small\",\n            \"dimensions\": 256,\n            \"encoding_format\": \"float\",\n        },\n    },\n    \"retriever\": {\n        \"top_k\": 5,\n    },\n    \"generator\": {\n        \"model_client\": ModelClientType.OPENAI(),\n        \"model_kwargs\": {\n            \"model\": \"gpt-3.5-turbo\",\n            \"temperature\": 0.3,\n            \"stream\": False,\n        },\n    },\n    \"text_splitter\": {\n        \"split_by\": \"word\",\n        \"chunk_size\": 400,\n        \"chunk_overlap\": 200,\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Formatting DataClass Examples in JSON and YAML in Python\nDESCRIPTION: Shows how to use the format_example_str method with DataClassFormatType to generate example strings in JSON and YAML formats for a DataClass instance.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import DataClassFormatType\n\nexample_str = example.format_example_str(DataClassFormatType.EXAMPLE_JSON)\nprint(example_str)\n\nexample_str = example.format_example_str(DataClassFormatType.EXAMPLE_YAML)\nprint(example_str)\n```\n\n----------------------------------------\n\nTITLE: Using JsonParser in AdalFlow\nDESCRIPTION: Demonstrates the JsonParser which extracts and parses JSON content from text. It can handle dictionaries, nested structures, lists, and combinations of these data types.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import JsonParser\n\ndict_str = '{\"key\": \"value\"}'\nnested_dict_str = (\n    '{\"name\": \"John\", \"age\": 30, \"attributes\": {\"height\": 180, \"weight\": 70}}'\n)\nlist_str = '[\"key\", 2]'\nlist_dict_str = '[{\"key\": \"value\"}, {\"key\": \"value\"}]'\n\nparser = JsonParser()\nprint(parser)\nprint(parser(dict_str))\nprint(parser(nested_dict_str))\nprint(parser(list_str))\nprint(parser(list_dict_str))\n```\n\n----------------------------------------\n\nTITLE: Implementing SimpleQA Component\nDESCRIPTION: Defines the SimpleQA class that inherits from Component and initializes a Generator with OpenAI's GPT-3.5-turbo model. Implements the call method for processing queries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/question_answering/simple_qa.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Build the SimpleQA pipeline\nclass SimpleQA(Component):\n    def __init__(self):\n        super().__init__()\n        self.generator = Generator(\n            model_client=OpenAIClient(), model_kwargs={\"model\": \"gpt-3.5-turbo\"}\n        )\n\n    def call(self, query: str):\n        return self.generator.call(prompt_kwargs={\"input_str\": query})\n\n\nsimple_qa = SimpleQA()\nprint(simple_qa)\n```\n\n----------------------------------------\n\nTITLE: Implementing Classification Component with Structured Output\nDESCRIPTION: Creates a component class that handles the classification pipeline with structured output. Uses DataClassParser for output formatting and parsing, and sets up parameters for system prompts and few-shot demonstrations.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/classification.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass TRECClassifierStructuredOutput(adal.Component):\n\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        super().__init__()\n\n        label_desc = [\n            {\"label\": label, \"desc\": desc}\n            for label, desc in zip(_COARSE_LABELS, _COARSE_LABELS_DESC)\n        ]\n\n        task_desc_str = adal.Prompt(\n            template=task_desc_template, prompt_kwargs={\"classes\": label_desc}\n        )()\n\n        self.data_class = TRECExtendedData\n        self.data_class.set_task_desc(task_desc_str)\n\n        self.parser = adal.DataClassParser(\n            data_class=self.data_class, return_data_class=True, format_type=\"yaml\"\n        )\n\n        prompt_kwargs = {\n            \"system_prompt\": adal.Parameter(\n                data=self.parser.get_task_desc_str(),\n                role_desc=\"Task description\",\n                requires_opt=True,\n                param_type=adal.ParameterType.PROMPT,\n            ),\n            \"output_format_str\": adal.Parameter(\n                data=self.parser.get_output_format_str(),\n                role_desc=\"Output format requirements\",\n                requires_opt=False,\n                param_type=adal.ParameterType.PROMPT,\n            ),\n            \"few_shot_demos\": adal.Parameter(\n                data=None,\n                requires_opt=True,\n                role_desc=\"Few shot examples to help the model\",\n                param_type=adal.ParameterType.DEMOS,\n            ),\n        }\n\n        self.llm = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            prompt_kwargs=prompt_kwargs,\n            template=template,\n            output_processors=self.parser,\n            use_cache=True,\n        )\n\n    def _prepare_input(self, question: str):\n        input_data = self.data_class(question=question)\n        input_str = self.parser.get_input_str(input_data)\n        prompt_kwargs = {\n            \"input_str\": adal.Parameter(\n                data=input_str, requires_opt=False, role_desc=\"input to the LLM\"\n            )\n        }\n        return prompt_kwargs\n\n    def call(\n        self, question: str, id: Optional[str] = None\n    ) -> Union[adal.GeneratorOutput, adal.Parameter]:\n        prompt_kwargs = self._prepare_input(question)\n        output = self.llm(prompt_kwargs=prompt_kwargs, id=id)\n        return output\n```\n\n----------------------------------------\n\nTITLE: Using DataClassParser in AdalFlow\nDESCRIPTION: Creates a DataClassParser that uses a defined DataClass to parse JSON output back into a structured data class instance. This example shows how to initialize the parser with specific format and return options.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.output_parsers import DataClassParser\n\nparser = DataClassParser(data_class=SampleDataClass, return_data_class=True, format_type=\"json\")\n```\n\n----------------------------------------\n\nTITLE: Configuring AdalFlow Generator with DataClassParser\nDESCRIPTION: This snippet shows how to set up the AdalFlow Generator with a DataClassParser to produce structured output. It includes defining the parser, creating the generator with the appropriate template and prompt kwargs, and using the parser as the output processor.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/generator.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nparser = adal.DataClassParser(\n    data_class=QAOutput, return_data_class=True, format_type=\"json\"\n)\n\nobject_counter = Generator(\n    model_client=adal.GroqAPIClient(),\n    model_kwargs={\n        \"model\": \"llama3-8b-8192\",\n    },\n    template=template,\n    prompt_kwargs={\n        \"system_prompt\": \"You will answer a reasoning question. Think step by step. \",\n        \"output_format_str\": parser.get_output_format_str(),\n    },\n    output_processors=parser,\n)\n\nresponse = object_counter(prompt_kwargs={\"input_str\": question})\nprint(response)\n\nobject_counter.print_prompt(input_str=question)\n```\n\n----------------------------------------\n\nTITLE: Using FuncComponent in AdalFlow\nDESCRIPTION: Demonstrates how to create and use FuncComponents, both directly and using the decorator pattern, to convert functions into AdalFlow components.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/component.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.component import FuncComponent\n\ndef add_one(x):\n    return x + 1\n\nfun_component = FuncComponent(add_one)\nprint(fun_component(1))\nprint(type(fun_component))\n\n@func_to_component\ndef add_one(x):\n    return x + 1\n\nprint(add_one(1))\nprint(type(add_one))\n```\n\n----------------------------------------\n\nTITLE: Parsing Integer Values with IntParser in Python\nDESCRIPTION: Shows how to use IntParser to extract integer values from strings. It can handle whole numbers, floats (truncating the decimal part), and even extract the first number from a string containing text.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import IntParser\n\nint_str = \"42\"\nint_str_2 = \"42.0\"\nint_str_3 = \"42.7\"\nint_str_4 = \"the answer is 42.75\"\n\n# it will all return 42\nparser = IntParser()\nprint(parser(int_str))\nprint(parser(int_str_2))\nprint(parser(int_str_3))\nprint(parser(int_str_4))\n```\n\n----------------------------------------\n\nTITLE: Diagnosing Task Pipeline Performance with AdalFlow Trainer\nDESCRIPTION: Defines a function to diagnose the performance of the ObjectCountAdalComponent using the AdalFlow Trainer across train, validation, and test datasets.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef diagnose(\n    model_client: adal.ModelClient,\n    model_kwargs: Dict,\n) -> Dict:\n    from use_cases.question_answering.bhh_object_count.data import load_datasets\n\n    trainset, valset, testset = load_datasets()\n\n    adal_component = ObjectCountAdalComponent(model_client, model_kwargs)\n    trainer = adal.Trainer(adaltask=adal_component)\n    trainer.diagnose(dataset=trainset, split=\"train\")\n    trainer.diagnose(dataset=valset, split=\"val\")\n    trainer.diagnose(dataset=testset, split=\"test\")\n```\n\n----------------------------------------\n\nTITLE: Testing the DspyRetriever with a Sample Question\nDESCRIPTION: Demonstrates how to use the custom DspyRetriever with a test question. The function retrieves relevant passages from a corpus based on the input question.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef test_retriever():\n    question = \"How many storeys are in the castle that David Gregory inherited?\"\n    retriever = DspyRetriever(top_k=3)\n    retriever_out = retriever(input=question)\n    print(f\"retriever_out: {retriever_out}\")\n```\n\n----------------------------------------\n\nTITLE: Parsing YAML with YamlParser in Python\nDESCRIPTION: Shows how to use YamlParser to convert YAML-formatted strings into Python dictionaries or lists. It can handle simple dictionaries, nested dictionaries, and lists.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import YamlParser\n\nyaml_dict_str = \"key: value\"\nyaml_nested_dict_str = \"name: John\\nage: 30\\nattributes:\\n  height: 180\\n  weight: 70\"\nyaml_list_str = \"- key\\n- value\"\n\nparser = YamlParser()\nprint(parser)\nprint(parser(yaml_dict_str))\nprint(parser(yaml_nested_dict_str))\nprint(parser(yaml_list_str))\n```\n\n----------------------------------------\n\nTITLE: Implementing ReActAgent with Mathematical Tools\nDESCRIPTION: Sets up a ReActAgent with mathematical tools (multiply, add, divide) and tests it with different language models (Llama3 and GPT-3.5). Includes model configurations and test cases for comparing agent responses with direct LLM responses.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/react_note.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.agent import ReActAgent\nfrom adalflow.core import Generator, ModelClientType, ModelClient\nfrom adalflow.utils import setup_env\n\nsetup_env()\n\ndef multiply(a: int, b: int) -> int:\n    \"\"\"\n    Multiply two numbers.\n    \"\"\"\n    return a * b\n\nasync def add(a: int, b: int) -> int:\n    \"\"\"\n    Add two numbers.\n    \"\"\"\n    return a + b\n\ndef divide(a: float, b: float) -> float:\n    \"\"\"\n    Divide two numbers.\n    \"\"\"\n    return float(a) / b\n\nllama3_model_kwargs = {\n    \"model\": \"llama3-8b-8192\",\n    \"temperature\": 0.0,\n}\ngpt_model_kwargs = {\n    \"model\": \"gpt-3.5-turbo\",\n    \"temperature\": 0.0,\n}\n\ndef test_react_agent(model_client: ModelClient, model_kwargs: dict):\n    tools = [multiply, add, divide]\n    queries = [\n        \"Give me 5 words rhyming with cool, and make a 4-sentence poem using them\",\n    ]\n    generator = Generator(\n        model_client=model_client,\n        model_kwargs=model_kwargs,\n    )\n\n    react = ReActAgent(\n        max_steps=6,\n        add_llm_as_fallback=True,\n        tools=tools,\n        model_client=model_client,\n        model_kwargs=model_kwargs,\n    )\n\n    for query in queries:\n        print(f\"Query: {query}\")\n        agent_response = react.call(query)\n        llm_response = generator.call(prompt_kwargs={\"input_str\": query})\n        print(f\"Agent response: {agent_response}\")\n        print(f\"LLM response: {llm_response}\")\n        print(\"\")\n```\n\n----------------------------------------\n\nTITLE: Implementing BAAI BGE Reranker\nDESCRIPTION: Demonstrates implementation of the BAAI/bge-reranker-base model from transformers for document retrieval. Shows configuration and initialization of the local transformer-based reranker.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nmodel_client = ModelClientType.TRANSFORMERS()\nmodel_kwargs = {\"model\": \"BAAI/bge-reranker-base\"}\n\nreranker = RerankerRetriever(\n    top_k=2,\n    model_client=model_client,\n    model_kwargs=model_kwargs,\n    documents=documents,\n    document_map_func=document_map_func,\n)\nprint(reranker)\n```\n\n----------------------------------------\n\nTITLE: Using BatchEmbedder for Large-Scale Embedding Tasks\nDESCRIPTION: Demonstrates using BatchEmbedder for processing large batches of queries. This component automatically handles chunking large sets of queries into manageable batches to avoid memory issues.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import BatchEmbedder\n\nbatch_embedder = BatchEmbedder(embedder=local_embedder, batch_size=100)\n\nqueries = [query] * 1000\n\nresponse = batch_embedder(queries)\n# 100%|██████████| 11/11 [00:04<00:00,  2.59it/s]\n```\n\n----------------------------------------\n\nTITLE: Splitting Text by Word using TextSplitter in AdalFlow\nDESCRIPTION: This example demonstrates how to use the TextSplitter to split a document by words. It configures the splitter with a chunk size of 5 and an overlap of 1, then processes a sample document and outputs the resulting chunks with their corresponding document IDs.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/text_splitter.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.data_process.text_splitter import TextSplitter\nfrom adalflow.core.types import Document\n\n# Configure the splitter settings\ntext_splitter = TextSplitter(\n    split_by=\"word\",\n    chunk_size=5,\n    chunk_overlap=1\n)\n\n# Example document\ndoc = Document(\n    text=\"Example text. More example text. Even more text to illustrate.\",\n    id=\"doc1\"\n)\n\n# Execute the splitting\nsplitted_docs = text_splitter.call(documents=[doc])\n\nfor doc in splitted_docs:\n    print(doc)\n\n# Output:\n# Document(id=44a8aa37-0d16-40f0-9ca4-2e25ae5336c8, text='Example text. More example text. ', meta_data=None, vector=[], parent_doc_id=doc1, order=0, score=None)\n# Document(id=ca0af45b-4f88-49b5-97db-163da9868ea4, text='text. Even more text to ', meta_data=None, vector=[], parent_doc_id=doc1, order=1, score=None)\n# Document(id=e7b617b2-3927-4248-afce-ec0fc247ac8b, text='to illustrate.', meta_data=None, vector=[], parent_doc_id=doc1, order=2, score=None)\n```\n\n----------------------------------------\n\nTITLE: Evaluating React Agent with Tools using Python\nDESCRIPTION: Implementation of React Agent evaluation using both Exact Match and Fuzzy Match metrics. Sets up evaluation parameters and runs tests on 10 questions with tools enabled. Includes timing measurements and normalizes answers for comparison.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.eval.answer_match_acc import AnswerMatchAcc\n\n# set up evaluation type\nEM_evaluator = AnswerMatchAcc(type=\"exact_match\")\nFM_evaluator = AnswerMatchAcc(type=\"fuzzy_match\")\n\nagent = ReActAgent(\n    tools=tools,\n    max_steps=7,\n    model_client=OpenAIClient(),\n    model_kwargs=gpt_model_kwargs,\n    # preset_prompt_kwargs=preset_prompt_kwargs,\n)\n\nnum_questions = 10\ngt_answers = []\npred_answers = []\nstart_time = time.time()\nfor i in range(num_questions):\n    question = val_dataset[i][\"question\"]\n    gt_answer = normalize_answer(\n        val_dataset[i][\"answer\"]\n    )  # normalize the ground truth answer\n    gt_answers.append(gt_answer)\n\n    # get the agent's response\n    pred_answer = agent(question)\n    pred_answer = normalize_answer(pred_answer)\n    pred_answers.append(pred_answer)\n\n    printc(\n        f\"No. {i+1}, question: {question}, ground truth: {gt_answer}, pred answer: {pred_answer}\",\n        color=\"yellow\",\n    )\n\nend_time = time.time()\n\nem = EM_evaluator.compute(pred_answers=pred_answers, gt_answers=gt_answers)\nfm = FM_evaluator.compute(pred_answers=pred_answers, gt_answers=gt_answers)\navg_time = (end_time - start_time) / num_questions\n\nprint(f\"EM = {em}, FM = {fm}, average time = {avg_time}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing DataClassParser in Python\nDESCRIPTION: Definition of the DataClassParser initialization method, which takes a DataClass type, a boolean to determine if it should return a DataClass instance after parsing, and the output format type (JSON or YAML).\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n__init__(data_class: DataClass, return_data_class: bool = False, format_type: Literal[\"yaml\", \"json\"] = \"json\")\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Execution of Function Calls with AdalFlow in Python\nDESCRIPTION: This snippet demonstrates how to execute function calls asynchronously using AdalFlow. It includes an async function to process queries concurrently and handle the results.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nasync def run_async_function_call(self, generator, tool_manager):\n    answers = []\n    start_time = time.time()\n    tasks = []\n    for idx, query in enumerate(queries):\n        tasks.append(self.process_query(idx, query, generator, tool_manager))\n\n    results = await asyncio.gather(*tasks)\n    answers.extend(results)\n    end_time = time.time()\n    print(f\"Total time taken: {end_time - start_time :.2f} seconds\")\n    return answers\n\nasync def process_query(self, idx, query, generator, tool_manager: ToolManager):\n    print(f\"\\n{idx} Query: {query}\")\n    print(f\"{'-'*50}\")\n    try:\n        result = generator(prompt_kwargs={\"input_str\": query})\n        func_expr = FunctionExpression.from_dict(result.data)\n        print(f\"Function_expr: {func_expr}\")\n        func = tool_manager.parse_func_expr(func_expr)\n        func_output = await tool_manager.execute_func_async(func)\n        print(f\"Function output: {func_output}\")\n        return func_output\n    except Exception as e:\n        print(\n            f\"Failed to execute the function for query: {query}, func: {result.data}, error: {e}\"\n        )\n        return None\n```\n\n----------------------------------------\n\nTITLE: Movie Analysis Component Implementation\nDESCRIPTION: Implementation of the MovieReviewer component using AdalFlow's Component class with model integration.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass MovieReviewer(adal.Component):\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        data_class: adal.DataClass,\n    ):\n        super().__init__()\n        self.additional_structure_prompt = (\n            \"Dont use 'type' and 'properties' in output directly give as dict\"\n        )\n        parser = adal.DataClassParser(data_class=data_class, return_data_class=True)\n        self.generator = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            template=movie_review_template,\n            prompt_kwargs={\n                \"output_format_str\": parser.get_output_format_str()\n                + self.additional_structure_prompt\n            },\n            output_processors=parser,\n        )\n\n    def call(self, movie_title: str):\n        return self.generator.call({\"movie_title\": movie_title})\n```\n\n----------------------------------------\n\nTITLE: Generating Integer Output with AdalFlow Generator\nDESCRIPTION: This snippet demonstrates how to use AdalFlow's Generator to produce a structured integer output from a language model response. It prints the response and shows that the 'data' field is now an integer instead of a string.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/generator.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nresponse = object_counter(prompt_kwargs={\"input_str\": question})\nprint(response)\nprint(type(response.data))\n```\n\n----------------------------------------\n\nTITLE: Training Function Implementation\nDESCRIPTION: Main training function with configurable parameters for batch size, shots, steps and optimization strategy.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef train(\n    train_batch_size=4,  # larger batch size is not that effective, probably because of llm's lost in the middle\n    raw_shots: int = 0,\n    bootstrap_shots: int = 1,\n    max_steps=1,\n    num_workers=4,\n    strategy=\"random\",\n    optimization_order=\"sequential\",\n    debug=False,\n    resume_from_ckpt=None,\n    exclude_input_fields_from_bootstrap_demos=False,\n):\n    adal_component = ObjectCountAdalComponent(\n        **gpt_3_model,\n        teacher_model_config=gpt_4o_model,\n        text_optimizer_model_config=gpt_4o_model,\n        backward_engine_model_config=gpt_4o_model,\n    )\n    print(adal_component)\n    trainer = adal.Trainer(\n        train_batch_size=train_batch_size,\n        adaltask=adal_component,\n        strategy=strategy,\n        max_steps=max_steps,\n        num_workers=num_workers,\n        raw_shots=raw_shots,\n        bootstrap_shots=bootstrap_shots,\n        debug=debug,\n        weighted_sampling=True,\n        optimization_order=optimization_order,\n        exclude_input_fields_from_bootstrap_demos=exclude_input_fields_from_bootstrap_demos,\n    )\n    print(trainer)\n\n    train_dataset, val_dataset, test_dataset = load_datasets()\n    trainer.fit(\n        train_dataset=train_dataset,\n        val_dataset=val_dataset,\n        test_dataset=test_dataset,\n        debug=debug,\n        resume_from_ckpt=resume_from_ckpt,\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring Few-Shot Parameters in AdalFlow - Python\nDESCRIPTION: Demonstrates the setup of system prompt and few-shot demonstration parameters in the task pipeline, configuring optimization requirements for few-shot learning.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=False,\n            param_type=ParameterType.PROMPT,\n        )\nfew_shot_demos = adal.Parameter(\n    data=None,\n    role_desc=\"To provide few shot demos to the language model\",\n    requires_opt=True,\n    param_type=ParameterType.DEMOS,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing a Basic RAG Prompt Template in Python\nDESCRIPTION: This code snippet defines a basic RAG prompt template that combines system instructions, user input, and retrieved context. The template follows a structured format with clear delimiters for system message and user content, which helps the LLM understand different components of the prompt.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/rag_playbook.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nRAG_PROMPT_TEMPLATE = r\"\"\"<START_OF_SYSTEM_MESSAGE>\n{{task_desc}}\n<END_OF_SYSTEM_MESSAGE>\n<START_OF_USER>\n{{input_str}}\n{{context_str}}\n<END_OF_USER>\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: TREC Data Structures and Dataset Loading\nDESCRIPTION: Defines data structures, classification labels, and dataset loading functions for TREC question classification. Includes prompt templates and custom data classes.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_classification_optimization.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Union, Optional, Tuple, Any, Callable\nfrom datasets import load_dataset\nfrom adalflow.components.model_client import OpenAIClient\nimport adalflow as adal\nfrom adalflow.core.component import Component\nfrom adalflow.datasets.types import TrecData\nfrom adalflow.datasets.trec import TrecDataset\n\nfrom adalflow.eval.answer_match_acc import AnswerMatchAcc\n\n\n_COARSE_LABELS = [\"ABBR\", \"DESC\", \"ENTY\", \"HUM\", \"LOC\", \"NUM\"]\n\n_COARSE_LABELS_DESC = [\n    \"Abbreviation: Questions about abbreviations and their meanings\",\n    \"Description: Questions seeking descriptions of people, things, or concepts\",\n    \"Entity: Questions about entities (e.g., animals, colors, inventions)\",\n    \"Human: Questions about people or organizations\",\n    \"Location: Questions about places, cities, countries\",\n    \"Numeric: Questions seeking numeric answers (e.g., dates, amounts, distances)\",\n]\n\n\ntemplate = r\"\"\"<START_OF_SYSTEM_MESSAGE>\n {{system_prompt}}\n {% if output_format_str is not none %}\n {{output_format_str}}\n {% endif %}\n {% if few_shot_demos is not none %}\n Here are some examples:\n {{few_shot_demos}}\n {% endif %}\n <END_OF_SYSTEM_MESSAGE>\n <START_OF_USER_MESSAGE>\n {{input_str}}\n <END_OF_USER_MESSAGE>\n \"\"\"\n\ntask_desc_template = r\"\"\"You are a classifier. Given a question, you need to classify it into one of the following classes:\n Format: class_index. class_name, class_description\n {% if classes %}\n {% for class in classes %}\n {{loop.index-1}}. {{class.label}}, {{class.desc}}\n {% endfor %}\n {% endif %}\n - Do not try to answer the question:\n \"\"\"\n\n\n@dataclass\nclass TRECExtendedData(TrecData):\n    rationale: str = field(\n        metadata={\n            \"desc\": \"Your step-by-step reasoning to classify the question to class_name\"\n        },\n        default=None,\n    )\n    __input_fields__ = [\"question\"]\n    __output_fields__ = [\n        \"rationale\",\n        \"class_name\",\n    ]  # it is important to have the rationale before the class_name\n\n\ndef load_datasets():\n    \"\"\"Load the dataset\"\"\"\n    train_data = TrecDataset(split=\"train\")\n    val_data = TrecDataset(split=\"val\")\n    test_data = TrecDataset(split=\"test\")\n    return train_data, val_data, test_data  # 0.694, 0.847\n```\n\n----------------------------------------\n\nTITLE: Implementing a Combined Mode Method for RAG\nDESCRIPTION: Creates a bicall method that combines both training and inference functionality in a single method. This method detects whether it's in training mode based on the retriever's output type and handles the processing accordingly.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef bicall(\n    self, question: str, id: str = None\n) -> Union[adal.GeneratorOutput, adal.Parameter]:\n    \"\"\"You can also combine both the forward and call in the same function.\n    Supports both training and eval mode by using __call__ for GradComponents\n    like Retriever and Generator\n    \"\"\"\n    retriever_out = self.retriever(input=question)\n    if isinstance(retriever_out, adal.Parameter):\n        successor_map_fn = lambda x: (  # noqa E731\n            \"\\n\\n\".join(x.data[0].documents)\n            if x.data and x.data[0] and x.data[0].documents\n            else \"\"\n        )\n        retriever_out.add_successor_map_fn(\n            successor=self.llm, map_fn=successor_map_fn\n        )\n    else:\n        successor_map_fn = lambda x: (  # noqa E731\n            \"\\n\\n\".join(x[0].documents) if x and x[0] and x[0].documents else \"\"\n        )\n        retrieved_context = successor_map_fn(retriever_out)\n    prompt_kwargs = {\n        \"context\": retrieved_context,\n        \"question\": question,\n    }\n```\n\n----------------------------------------\n\nTITLE: Implementing Song Analysis DataClass in Python\nDESCRIPTION: Defines the top-level analysis class that includes detailed review, duration and awards information.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass SongAnalysis(adal.DataClass):\n    review: DetailedSongReview = field(\n        default=DetailedSongReview, metadata={\"desc\": \"Song review details\"}\n    )\n    duration: float = field(default=None, metadata={\"desc\": \"Duration of the song\"})\n    awards: Dict[str, int] = field(\n        default=None,\n        metadata={\"desc\": \"Dictionary of award categories and number of wins\"},\n    )\n\n    __output_fields__ = [\"review\", \"duration\", \"awards\"]\n```\n\n----------------------------------------\n\nTITLE: Implementing VanillaRAG and VallinaRAGAdal Components\nDESCRIPTION: These classes implement the core RAG components using AdalFlow. VanillaRAG sets up the retriever and language model, while VallinaRAGAdal wraps it with evaluation and loss functions.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntask_desc_str = r\"\"\"Answer questions with short factoid answers.\n\nYou will receive context(may contain relevant facts) and a question.\nThink step by step.\"\"\"\n\n\nclass VanillaRAG(adal.GradComponent):\n    def __init__(self, passages_per_hop=3, model_client=None, model_kwargs=None):\n        super().__init__()\n\n        self.passages_per_hop = passages_per_hop\n\n        self.retriever = DspyRetriever(top_k=passages_per_hop)\n        self.llm_parser = adal.DataClassParser(\n            data_class=AnswerData, return_data_class=True, format_type=\"json\"\n        )\n        self.llm = Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            prompt_kwargs={\n                \"task_desc_str\": adal.Parameter(\n                    data=task_desc_str,\n                    role_desc=\"Task description for the language model\",\n                    param_type=adal.ParameterType.PROMPT,\n                ),\n                \"few_shot_demos\": adal.Parameter(\n                    data=None,\n                    requires_opt=True,\n                    role_desc=\"To provide few shot demos to the language model\",\n                    param_type=adal.ParameterType.DEMOS,\n                ),\n                \"output_format_str\": self.llm_parser.get_output_format_str(),\n            },\n            template=answer_template,\n            output_processors=self.llm_parser,\n            use_cache=True,\n        )\n\n\nclass VallinaRAGAdal(adal.AdalComponent):\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        backward_engine_model_config: Dict | None = None,\n        teacher_model_config: Dict | None = None,\n        text_optimizer_model_config: Dict | None = None,\n    ):\n        task = VanillaRAG(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            passages_per_hop=3,\n        )\n        eval_fn = AnswerMatchAcc(type=\"fuzzy_match\").compute_single_item\n        loss_fn = adal.EvalFnToTextLoss(\n            eval_fn=eval_fn, eval_fn_desc=\"fuzzy_match: 1 if str(y) in str(y_gt) else 0\"\n        )\n        super().__init__(\n            task=task,\n            eval_fn=eval_fn,\n            loss_fn=loss_fn,\n            backward_engine_model_config=backward_engine_model_config,\n            teacher_model_config=teacher_model_config,\n            text_optimizer_model_config=text_optimizer_model_config,\n        )\n\n    # tell the trainer how to call the task\n    def prepare_task(self, sample: HotPotQAData) -> Tuple[Callable[..., Any], Dict]:\n        if self.task.training:\n            return self.task.forward, {\"question\": sample.question, \"id\": sample.id}\n        else:\n            return self.task.call, {\"question\": sample.question, \"id\": sample.id}\n\n    # eval mode: get the generator output, directly engage with the eval_fn\n    def prepare_eval(self, sample: HotPotQAData, y_pred: adal.GeneratorOutput) -> float:\n        y_label = \"\"\n        if y_pred and y_pred.data and y_pred.data.answer:\n            y_label = y_pred.data.answer\n        return self.eval_fn, {\"y\": y_label, \"y_gt\": sample.answer}\n\n    # train mode: get the loss and get the data from the full_response\n    def prepare_loss(self, sample: HotPotQAData, pred: adal.Parameter):\n        # prepare gt parameter\n        y_gt = adal.Parameter(\n            name=\"y_gt\",\n            data=sample.answer,\n            eval_input=sample.answer,\n            requires_opt=False,\n        )\n\n        # pred's full_response is the output of the task pipeline which is GeneratorOutput\n        pred.eval_input = (\n            pred.full_response.data.answer\n            if pred.full_response\n            and pred.full_response.data\n            and pred.full_response.data.answer\n            else \"\"\n        )\n        return self.loss_fn, {\"kwargs\": {\"y\": pred, \"y_gt\": y_gt}}\n```\n\n----------------------------------------\n\nTITLE: Creating Signatures and Schemas from DataClass in Python\nDESCRIPTION: Demonstrates how to define a dataclass using BaseDataClass and generate JSON/YAML signatures and schema from it. This helps in creating structured data representations for LLM interactions.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/introduction_to_basedataclass.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom core.base_data_class import BaseDataClass\nfrom dataclasses import dataclass, field\n# Define a dataclass\n@dataclass\nclass MyOutputs(BaseDataClass):\n    age: int = field(metadata={\"desc\": \"The age of the person\", \"prefix\": \"Age:\"})\n    name: str = field(metadata={\"desc\": \"The name of the person\", \"prefix\": \"Name:\"})\n# Create signatures\nprint(f\"json signature:\")\nprint(MyOutputs.to_json_signature())\nprint(f\"yaml signature:\")\nprint(MyOutputs.to_yaml_signature())\n# Create class schema\nprint(f\"class schema:\")\nprint(MyOutputs.get_data_class_schema())\n```\n\n----------------------------------------\n\nTITLE: Defining Classification Template and Data Structure\nDESCRIPTION: Sets up the base template structure for classification tasks with system prompts, output formatting, and few-shot demonstrations. Includes a dataclass TRECExtendedData that extends TrecData with rationale field for chain-of-thought reasoning.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/classification.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ntemplate = r\"\"\"<START_OF_SYSTEM_MESSAGE>\n    {{system_prompt}}\n    {% if output_format_str is not none %}\n    {{output_format_str}}\n    {% endif %}\n    {% if few_shot_demos is not none %}\n    Here are some examples:\n    {{few_shot_demos}}\n    {% endif %}\n    <END_OF_SYSTEM_MESSAGE>\n    <START_OF_USER_MESSAGE>\n    {{input_str}}\n    <END_OF_USER_MESSAGE>\n    \"\"\"\n\ntask_desc_template = r\"\"\"You are a classifier. Given a question, you need to classify it into one of the following classes:\nFormat: class_index. class_name, class_description\n{% if classes %}\n{% for class in classes %}\n{{loop.index-1}}. {{class.label}}, {{class.desc}}\n{% endfor %}\n{% endif %}\n- Do not try to answer the question:\n\"\"\"\n\n@dataclass\nclass TRECExtendedData(TrecData):\n    rationale: str = field(\n        metadata={\n            \"desc\": \"Your step-by-step reasoning to classify the question to class_name\"\n        },\n        default=None,\n    )\n    __input_fields__ = [\"question\"]\n    __output_fields__ = [\"rationale\", \"class_name\"]\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple QA Component with Groq API in AdalFlow\nDESCRIPTION: This snippet defines a SimpleQA component using AdalFlow and the Groq API. It sets up a Generator with a custom template and the Groq model. The component provides both synchronous and asynchronous methods for question answering. The example demonstrates how to use the component to ask a question about AdalFlow.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/generator.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import Component, Generator\nfrom adalflow.components.model_client import GroqAPIClient\nfrom adalflow.utils import setup_env  # noqa\n\n\nclass SimpleQA(Component):\n    def __init__(self):\n        super().__init__()\n        template = r\"\"\"<SYS>\n        You are a helpful assistant.\n        </SYS>\n        User: {{input_str}}\n        You:\n        \"\"\"\n        self.generator = Generator(\n            model_client=GroqAPIClient(),\n            model_kwargs={\"model\": \"llama3-8b-8192\"},\n            template=template,\n        )\n\n    def call(self, query):\n        return self.generator({\"input_str\": query})\n\n    async def acall(self, query):\n        return await self.generator.acall({\"input_str\": query})\n\n\nqa = SimpleQA()\nanswer = qa(\"What is AdalFLow?\")\n\nprint(answer)\n```\n\n----------------------------------------\n\nTITLE: Setting Up FAISS Retriever for Semantic Search in Python\nDESCRIPTION: This snippet demonstrates how to set up a FAISS retriever for semantic search, build an index from document embeddings, and retrieve relevant dialog turns based on semantic similarity.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.retriever.faiss_retriever import FAISSRetriever\n\nretriever = FAISSRetriever(top_k=3, embedder=embedder)\nembeddings = [item.vector for item in dialog_turn_db.transformed_items[key]]\nretriever.build_index_from_documents(documents=embeddings)\n\n# get the relevant documents\ntop_k_documents = retriever(input=input_str)\n\n# get the relevant dialog turns\nparent_doc_ids = set(\n    [\n        dialog_turn_db.transformed_items[key][doc_index].parent_doc_id\n        for doc_index in top_k_documents[0].doc_indices\n    ]\n)\n\ncondition_fn = lambda item: item.id in parent_doc_ids\nfetched_dialog_turns = [item for item in dialog_turn_db.items if condition_fn(item)]\n```\n\n----------------------------------------\n\nTITLE: Implementing LLM-based Retriever\nDESCRIPTION: Shows the implementation of an LLM-based retriever using GPT-4 for document retrieval. Demonstrates how to configure the LLM retriever with appropriate model parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.retriever import LLMRetriever\n\nmodel_client = ModelClientType.OPENAI()\nmodel_kwargs = {\n    \"model\": \"gpt-4o\",\n}\ndocument_map_func = lambda x: x[\"content\"]\nllm_retriever = LLMRetriever(\n        top_k=2,\n        model_client=model_client,\n        model_kwargs=model_kwargs,\n        documents=documents,\n```\n\n----------------------------------------\n\nTITLE: Updating HTTP Libraries for Compatibility\nDESCRIPTION: This code snippet uninstalls specific versions of httpx and anyio, then reinstalls compatible versions to ensure proper functionality with AdalFlow.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_tracing.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip uninstall httpx anyio -y\n!pip install \"anyio>=3.1.0,<4.0\"\n!pip install httpx==0.24.1\n```\n\n----------------------------------------\n\nTITLE: Implementing Structured Output Parser in Python\nDESCRIPTION: This snippet shows how to create a custom parser for structured output. It defines a function to extract and parse integer answers from the model's response, and integrates it with the Generator as an output processor.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/generator.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport re\n\n@adal.func_to_data_component\ndef parse_integer_answer(answer: str):\n    try:\n        numbers = re.findall(r\"\\d+\", answer)\n        if numbers:\n            answer = int(numbers[-1])\n        else:\n            answer = -1\n    except ValueError:\n        answer = -1\n\n    return answer\n\nobject_counter = Generator(\n    model_client=adal.GroqAPIClient(),\n    model_kwargs={\n        \"model\": \"llama3-8b-8192\",\n    },\n    template=few_shot_template,\n    prompt_kwargs={\n        \"system_prompt\": \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n    },\n    output_processors=parse_integer_answer,\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Document Embeddings for LanceDBRetriever in Python\nDESCRIPTION: This snippet demonstrates how to prepare document embeddings for use with LanceDBRetriever by using an Embedder with the text-embedding-3-small model. The embeddings are generated from the content field of documents.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.core.types import ModelClientType\n\nmodel_kwargs = {\n    \"model\": \"text-embedding-3-small\",\n    \"dimensions\": 256,\n    \"encoding_format\": \"float\",\n}\n\nembedder = Embedder(model_client=ModelClientType.OPENAI(), model_kwargs=model_kwargs)\noutput = embedder(input=[doc[\"content\"] for doc in documents])\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Diagnostics Function\nDESCRIPTION: Diagnostic function to evaluate pipeline performance before optimization. Sets up the training components and runs evaluation on different dataset splits.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef train_diagnose(\n    model_client: adal.ModelClient,\n    model_kwargs: Dict,\n) -> Dict:\n\n    trainset, valset, testset = load_datasets()\n\n    adal_component = VallinaRAGAdal(\n        model_client,\n        model_kwargs,\n        backward_engine_model_config=gpt_4o_model,\n        teacher_model_config=gpt_3_model,\n        text_optimizer_model_config=gpt_3_model,\n    )\n    trainer = adal.Trainer(adaltask=adal_component)\n    trainer.diagnose(dataset=trainset, split=\"train\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Data Processing Pipeline in AdalFlow\nDESCRIPTION: This code snippet demonstrates how to create a data processing pipeline using TextSplitter and Embedder components in the AdalFlow framework.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.core.types import ModelClientType\nfrom adalflow.components.data_process import TextSplitter, ToEmbeddings\nfrom adalflow.core.component import Sequential\n\n\nmodel_kwargs = {\n    \"model\": \"text-embedding-3-small\",\n    \"dimensions\": 256,\n    \"encoding_format\": \"float\",\n}\n\nsplitter_config = {\n    \"split_by\": \"word\",\n    \"split_length\": 50,\n    \"split_overlap\": 10\n}\n\nsplitter = TextSplitter(**splitter_config)\nembedder = Embedder(model_client =ModelClientType.OPENAI(), model_kwargs=model_kwargs)\nembedder_transformer = ToEmbeddings(embedder, batch_size=2)\ndata_transformer = Sequential(splitter, embedder_transformer)\nprint(data_transformer)\n```\n\n----------------------------------------\n\nTITLE: Implementing ObjectCountAdalComponent for Task Evaluation\nDESCRIPTION: Creates a custom AdalComponent subclass to handle the object counting task, including methods for processing individual samples and evaluating predictions.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.datasets.types import Example\nfrom adalflow.eval.answer_match_acc import AnswerMatchAcc\n\n\nclass ObjectCountAdalComponent(adal.AdalComponent):\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        task = ObjectCountTaskPipeline(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        super().__init__(task=task, eval_fn=eval_fn)\n\n    def handle_one_task_sample(self, sample: Example):\n        return self.task.call, {\"question\": sample.question, \"id\": sample.id}\n\n    def evaluate_one_sample(\n        self, sample: Example, y_pred: adal.GeneratorOutput\n    ) -> float:\n        y_label = -1\n        if (y_pred is not None and y_pred.data is not None):  # if y_pred and y_pred.data: might introduce bug when the data is 0\n            y_label = y_pred.data\n        return self.eval_fn(y=y_label, y_gt=sample.answer)\n```\n\n----------------------------------------\n\nTITLE: Initializing Local Transformer Embedder in Python\nDESCRIPTION: Sets up an Embedder using a local Transformers model for text embedding.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/embedder.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.components.model_client import TransformersClient\n\nmodel_kwargs = {\"model\": \"thenlper/gte-base\"}\nlocal_embedder = Embedder(model_client=TransformersClient(), model_kwargs=model_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Parsing and Executing Function Call in Python\nDESCRIPTION: Demonstrates how to parse the function call response from the API, extract arguments, and execute the function with the provided parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfunction_name = tool_call.function.name\nfunction_to_call = available_functions[function_name]\nfunction_args = json.loads(tool_call.function.arguments)\nfunction_response = function_to_call(\n    location=function_args.get(\"location\"),\n    unit=function_args.get(\"unit\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using SambaNova LLM Generator in Python\nDESCRIPTION: Sets up a Generator with SambaNovaClient, configures model parameters, and demonstrates a simple prompt generation. It also includes error handling for the response.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/sambanova_integration.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client.sambanova_client import SambaNovaClient\nfrom adalflow.core import Generator\n\ngenerator = Generator(\n    model_client=SambaNovaClient(),\n    model_kwargs={\n        \"model\": \"Meta-Llama-3.1-8B-Instruct\",\n        \"temperature\": 0.7,\n        \"top_p\": 0.9,\n    },\n)\n\n# Provide a single prompt\nprompt_kwargs = {\"input_str\": \"Just say hi and hello world and nothing else.\"}\n\nresponse = generator(prompt_kwargs)\n\nif response.error:\n    print(f\"[SambaNova] Generator error: {response.error}\")\nelse:\n    print(\"[SambaNova] LLM output:\")\n    print(response.data)\n```\n\n----------------------------------------\n\nTITLE: Invoking QdrantRetriever for Document Retrieval in Python\nDESCRIPTION: This snippet shows how to execute queries with a QdrantRetriever for document retrieval. It demonstrates different ways to invoke the retriever, including with single queries and multiple queries at once.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_16\n\nLANGUAGE: python\nCODE:\n```\noutput_1 = qdrant_retriever(input=query_1)\noutput_2 = qdrant_retriever(input=query_2)\noutput_3 = qdrant_retriever(input = [query_1, query_2])\n```\n\n----------------------------------------\n\nTITLE: RAG Pipeline Implementation\nDESCRIPTION: Implementation of a Retrieval-Augmented Generation (RAG) data pipeline\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Part 1: Data Pipeline using AdalFlow DataComponents\ndef prepare_data_pipeline():\n   splitter = TextSplitter(**configs[\"text_splitter\"])\n   embedder = adal.Embedder(\n      model_client=configs[\"embedder\"][\"model_client\"](),\n      model_kwargs=configs[\"embedder\"][\"model_kwargs\"],\n   )\n   embedder_transformer = ToEmbeddings(\n      embedder=embedder, batch_size=configs[\"embedder\"][\"batch_size\"]\n   )\n   data_transformer = adal.Sequential(\n      splitter, embedder_transformer\n```\n\n----------------------------------------\n\nTITLE: Implementing Call Methods for AdalFlow Components\nDESCRIPTION: These methods implement the call functionality for different components in the AdalFlow framework, handling both training and evaluation modes.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef call(\n    self, question: str, id: Optional[str] = None\n) -> Union[adal.GeneratorOutput, adal.Parameter]:\n    prompt_kwargs = self._prepare_input(question)\n    output = self.llm(prompt_kwargs=prompt_kwargs, id=id)\n    return output\n\n\ndef call(self, question: str, id: str = None) -> adal.GeneratorOutput:\n    if self.training:\n        raise ValueError(\"This component is not supposed to be called in training mode\")\n\n    retriever_out = self.retriever.call(input=question)\n\n    successor_map_fn = lambda x: (  # noqa E731\n        \"\\n\\n\".join(x[0].documents) if x and x[0] and x[0].documents else \"\"\n    )\n    retrieved_context = successor_map_fn(retriever_out)\n\n    prompt_kwargs = {\n        \"context\": retrieved_context,\n        \"question\": question,\n    }\n\n    output = self.llm.call(\n        prompt_kwargs=prompt_kwargs,\n        id=id,\n    )\n    return output\n\n\ndef forward(self, question: str, id: str = None) -> adal.Parameter:\n    if not self.training:\n        raise ValueError(\"This component is not supposed to be called in eval mode\")\n    retriever_out = self.retriever.forward(input=question)\n    successor_map_fn = lambda x: (  # noqa E731\n        \"\\n\\n\".join(x.data[0].documents)\n        if x.data and x.data[0] and x.data[0].documents\n        else \"\"\n    )\n    retriever_out.add_successor_map_fn(successor=self.llm, map_fn=successor_map_fn)\n    generator_out = self.llm.forward(\n        prompt_kwargs={\"question\": question, \"context\": retriever_out}, id=id\n    )\n    return generator_out\n\n\ndef bicall(\n    self, question: str, id: str = None\n) -> Union[adal.GeneratorOutput, adal.Parameter]:\n    \"\"\"You can also combine both the forward and call in the same function.\n    Supports both training and eval mode by using __call__ for GradComponents\n    like Retriever and Generator\n    \"\"\"\n    retriever_out = self.retriever(input=question)\n    if isinstance(retriever_out, adal.Parameter):\n        successor_map_fn = lambda x: (  # noqa E731\n            \"\\n\\n\".join(x.data[0].documents)\n            if x.data and x.data[0] and x.data[0].documents\n            else \"\"\n        )\n        retriever_out.add_successor_map_fn(successor=self.llm, map_fn=successor_map_fn)\n    else:\n        successor_map_fn = lambda x: (  # noqa E731\n            \"\\n\\n\".join(x[0].documents) if x and x[0] and x[0].documents else \"\"\n        )\n        retrieved_context = successor_map_fn(retriever_out)\n    prompt_kwargs = {\n        \"context\": retrieved_context,\n        \"question\": question,\n    }\n    output = self.llm(prompt_kwargs=prompt_kwargs, id=id)\n    return output\n```\n\n----------------------------------------\n\nTITLE: Using BooleanParser in AdalFlow\nDESCRIPTION: Demonstrates the BooleanParser which extracts boolean values from text. This parser supports both 'True/False' and 'true/false' formats but not alternatives like '1/0' or 'yes/no'.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import BooleanParser\n\nbool_str = \"True\"\nbool_str_2 = \"False\"\nbool_str_3 = \"true\"\nbool_str_4 = \"false\"\nbool_str_5 = \"1\"  # will fail\nbool_str_6 = \"0\"  # will fail\nbool_str_7 = \"yes\"  # will fail\nbool_str_8 = \"no\"  # will fail\n\n# it will all return True/False\nparser = BooleanParser()\nprint(parser(bool_str))\nprint(parser(bool_str_2))\nprint(parser(bool_str_3))\nprint(parser(bool_str_4))\n```\n\n----------------------------------------\n\nTITLE: Defining Example Functions in Python\nDESCRIPTION: Defines a set of example functions including synchronous and asynchronous functions, and functions using custom data structures. These functions are used to demonstrate AdalFlow's function call capabilities.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\nimport numpy as np\nimport time\nimport asyncio\n\n\ndef multiply(a: int, b: int) -> int:\n    \"\"\"Multiply two numbers.\"\"\"\n    time.sleep(1)\n    return a * b\n\n\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers.\"\"\"\n    time.sleep(1)\n    return a + b\n\n\nasync def divide(a: float, b: float) -> float:\n    \"\"\"Divide two numbers.\"\"\"\n    await asyncio.sleep(1)\n    return float(a) / b\n\n\nasync def search(query: str) -> List[str]:\n    \"\"\"Search for query and return a list of results.\"\"\"\n    await asyncio.sleep(1)\n    return [\"result1\" + query, \"result2\" + query]\n\n\ndef numpy_sum(arr: np.ndarray) -> float:\n    \"\"\"Sum the elements of an array.\"\"\"\n    return np.sum(arr)\n\n\nx = 2\n\n@dataclass\nclass Point:\n    x: int\n    y: int\n\n\ndef add_points(p1: Point, p2: Point) -> Point:\n    return Point(p1.x + p2.x, p1.y + p2.y)\n```\n\n----------------------------------------\n\nTITLE: Creating Function Expression Example and JSON Output Parser in Python\nDESCRIPTION: This code snippet creates an example function expression for adding points and initializes a JSON output parser with this example.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nexample = FunctionExpression.from_function(\n        func=add_points, p1=Point(x=1, y=2), p2=Point(x=3, y=4)\n)\nfunc_parser = JsonOutputParser(\n        data_class=FunctionExpression, examples=[example]\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing FunctionTool Collection in Python\nDESCRIPTION: Creates FunctionTool instances from a list of functions to generate automatic function definitions for LLM interaction.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.func_tool import FunctionTool\n\nfunctions =[multiply, add, divide, search, numpy_sum, add_points]\ntools = [\n    FunctionTool(fn=fn) for fn in functions\n]\nfor tool in tools:\n    print(tool)\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Song Review DataClass in Python\nDESCRIPTION: Defines a base SongReview data class with fields for title, album, ranking, streaming counts, pros and cons. Uses field metadata for descriptions and validation constraints.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass SongReview(adal.DataClass):\n    title: str = field(metadata={\"desc\": \"The title of the song\"})\n    album: str = field(metadata={\"desc\": \"The album of the song\"})\n    ranking: int = field(\n        metadata={\"desc\": \"Billboard peak ranking from 1 to 200\", \"min\": 1, \"max\": 200}\n    )\n    streaming: Dict[str, int] = field(\n        default_factory=list,\n        metadata={\n            \"desc\": \"Dict of lastest approximate streaming count in spotify and in youtube. Gives the count in millions\"\n        },\n    )\n    pros: List[str] = field(\n        default_factory=list,\n        metadata={\"desc\": \"List of positive points about the song\"},\n    )\n    cons: List[str] = field(\n        default_factory=list,\n        metadata={\"desc\": \"List of negative points about the song\"},\n    )\n\n    __output_fields__ = [\"title\", \"rating\", \"streaming\", \"pros\", \"cons\"]\n```\n\n----------------------------------------\n\nTITLE: Using ToEmbeddings for Document Processing\nDESCRIPTION: Shows how to use the ToEmbeddings component to embed a list of Document objects. This component handles the conversion from documents to embeddings and supports batch processing automatically.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.data_process.data_components import ToEmbeddings\nfrom adalflow.core.types import Document\n\nto_embeddings = ToEmbeddings(embedder=embedder, batch_size=100)\n\ndocs = [Document(text=\"What is LLM?\")] * 1000\noutput = to_embeddings(docs)\nprint(f\"Response - Length: {len(response)})\"\n# 1000\n```\n\n----------------------------------------\n\nTITLE: Implementing RetrieverOutput Data Structure in Python\nDESCRIPTION: A dataclass that standardizes retriever output format, containing document indices, scores, original query, and retrieved documents. This unified structure enables easy switching between different retriever implementations in the task pipeline.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass RetrieverOutput(DataClass):\n    doc_indices: List[int] = field(metadata={\"desc\": \"List of document indices\"})\n    doc_scores: Optional[List[float]] = field(\n        default=None, metadata={\"desc\": \"List of document scores\"}\n    )\n    query: Optional[RetrieverQueryType] = field(\n        default=None, metadata={\"desc\": \"The query used to retrieve the documents\"}\n    )\n    documents: Optional[List[RetrieverDocumentType]] = field(\n        default=None, metadata={\"desc\": \"List of retrieved documents\"}\n    )\n\n\nRetrieverOutputType = List[RetrieverOutput]  # so to support multiple queries at once\n```\n\n----------------------------------------\n\nTITLE: Setting up Local LM with Ollama\nDESCRIPTION: Instructions for installing and pulling models using Ollama for local LM deployment\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/installation.rst#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Download Ollama command line tool\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Pull the model to use\nollama pull llama3\n```\n\n----------------------------------------\n\nTITLE: Switching Model Clients in Generator using ModelClientType in Python\nDESCRIPTION: This snippet shows how to switch between different model clients using ModelClientType in the Generator initialization.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import ModelClientType\n\ngenerator = Generator(\n    model_client=ModelClientType.OPENAI(),  # or ModelClientType.GROQ()\n    model_kwargs={\"model\": \"gpt-3.5-turbo\"},\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Function Tools and ToolManager\nDESCRIPTION: Demonstrates the creation of FunctionTool instances for each defined function and initializes a ToolManager with these tools.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_function_calls.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.func_tool import FunctionTool\n\nfunctions = [multiply, add, divide, search, numpy_sum, add_points]\ntools = [FunctionTool(fn=fn) for fn in functions]\nfor tool in tools:\n    print(tool)\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(tools[-2].definition.to_dict())\n```\n\nLANGUAGE: python\nCODE:\n```\ncontext_map = {tool.definition.func_name: tool for tool in tools}\n```\n\nLANGUAGE: python\nCODE:\n```\nfunction_name = \"add\"\nfunction_to_call = context_map[function_name]\nfunction_args = {\"a\": 1, \"b\": 2}\nfunction_response = function_to_call.call(**function_args)\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.tool_manager import ToolManager\n\ntool_manager = ToolManager(tools=functions)\nprint(tool_manager)\n```\n\n----------------------------------------\n\nTITLE: Transforming Documents and Saving to Database in Python\nDESCRIPTION: This function prepares a data pipeline, transforms documents, and saves them to a local database. It uses AdalFlow components for document processing and embedding.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef transform_documents_and_save_to_db(\n    documents: List[Document], db_path: str\n) -> adal.LocalDB:\n    data_transformer = prepare_data_pipeline()\n\n    db = LocalDB()\n    db.register_transformer(transformer=data_transformer, key=\"split_and_embed\")\n    db.load(documents)\n    db.transform(key=\"split_and_embed\")\n    os.makedirs(os.path.dirname(db_path), exist_ok=True)\n    db.save_state(filepath=db_path)\n    return db\n```\n\n----------------------------------------\n\nTITLE: Configuring Cohere Reranker Retriever\nDESCRIPTION: Sets up a reranker-based retriever using Cohere's rerank-english-v3.0 model. The code demonstrates how to initialize and configure the reranker retriever with appropriate model parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.retriever import RerankerRetriever\n\nmodel_client = ModelClientType.COHERE()\nmodel_kwargs = {\"model\": \"rerank-english-v3.0\"}\n\nreranker = RerankerRetriever(\n    top_k=2, model_client=model_client, model_kwargs=model_kwargs\n)\nprint(reranker)\n```\n\n----------------------------------------\n\nTITLE: Converting JSON to DataClass Instance\nDESCRIPTION: Demonstrates how to convert a JSON string into a data class instance using the parser's call method.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nuser_input = '{\"description\": \"Parsed description\", \"category\": \"Sample Category\", \"value\": 100, \"status\": \"active\"}'\nparsed_instance = parser.call(user_input)\n\nprint(parsed_instance)\n```\n\n----------------------------------------\n\nTITLE: Creating Generator from Pure Configs in Python\nDESCRIPTION: This snippet shows how to create a Generator object using the new_component function, allowing for more flexible component creation from configurations.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.config import new_component\nfrom adalflow.core import Generator\n\nconfig = {\n    \"generator\": {\n        \"component_name\": \"Generator\",\n        \"component_config\": {\n            \"model_client\": {\n                \"component_name\": \"GroqAPIClient\",\n                \"component_config\": {},\n            },\n            \"model_kwargs\": {\n                \"model\": \"llama3-8b-8192\",\n            },\n        }\n    }\n}\n\ngenerator: Generator = new_component(config[\"generator\"])\nprint(generator)\n\nprompt_kwargs = {\"input_str\": \"What is LLM? Explain in one sentence.\"}\ngenerator.print_prompt(**prompt_kwargs)\noutput = generator(\n    prompt_kwargs=prompt_kwargs,\n)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Formatting Chat History and Generating Prompts\nDESCRIPTION: Demonstrates how to format chat history and generate prompts for the language model, including exclusion of unnecessary fields.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# lets see how the prompt will be if we pass the input_str and chat_history_str\ninput_str = \"What are the benefits of renewable energy? Did I ask this before?\"\n\n\ndef format_chat_history_str(turns: list) -> str:\n    chat_history_str = []\n    for turn in turns:\n        chat_history_str.append(turn.to_yaml())  # format as yaml\n    # join with newline\n    chat_history_str = \"\\n_________\\n\".join(chat_history_str)\n    return chat_history_str\n\n\nchat_history_str = format_chat_history_str(dialog_turns)\nprint(generator.print_prompt(input_str=input_str, chat_history_str=chat_history_str))\n```\n\nLANGUAGE: python\nCODE:\n```\n# as we have quite a bit of empty fields, lets exclude them\nfrom typing import List\n\ninput_str = \"What are the benefits of renewable energy? Did I ask this before?\"\n\n\ndef format_chat_history_str(turns: List[DialogTurn]) -> str:\n    chat_history_str = []\n    for turn in turns:\n        chat_history_str.append(\n            turn.to_yaml(\n                exclude=[\n                    \"id\",\n                    \"user_id\",\n                    \"session_id\",\n                    \"user_query_timestamp\",\n                    \"assistant_response_timestamp\",\n                    \"order\",\n                    \"metadata\",\n                    \"vector\",\n                ],\n            )\n        )\n    chat_history_str = \"\\n_________\\n\".join(chat_history_str)\n    return chat_history_str\n\n\nchat_history_str = format_chat_history_str(dialog_turn_db.items[0:1])\nprint(generator.print_prompt(input_str=input_str, chat_history_str=chat_history_str))\n```\n\n----------------------------------------\n\nTITLE: Running Q&A Examples with ReActAgent in Python\nDESCRIPTION: This code demonstrates how to use the ReActAgent to answer questions. It iterates through a set number of questions from a validation dataset, processes them with the agent, and prints the results.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.logger import printc\n\nnum_questions = 5\nfor i in range(num_questions):\n    question = val_dataset[i][\"question\"]\n    gt_answer = normalize_answer(\n        val_dataset[i][\"answer\"]\n    )  # normalize the ground truth answer\n\n    # get the agent's response\n    pred_answer = agent(question)\n    pred_answer = normalize_answer(pred_answer)\n\n    printc(\n        f\"question: {question}, ground truth: {gt_answer}, pred answer: {pred_answer}\",\n        color=\"yellow\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Using Generator with Groq API Client in Python\nDESCRIPTION: Shows how to use the Generator with a different model client, specifically the Groq API Client with the llama3 model.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/basic.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client import GroqAPIClient\n\ngroq_model_kwargs = {\"model\": \"llama3-8b-8192\"}\ngenerator3 = Generator(\n    model_client=GroqAPIClient(), model_kwargs=groq_model_kwargs, template=template\n)\n\nresponse = generator3(prompt_kwargs=prompt_kwargs)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Implementing Training and Diagnosis Function for AdalFlow RAG\nDESCRIPTION: This function sets up the training and diagnosis process for the VallinaRAGAdal component, including dataset loading and trainer configuration.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef train_diagnose(\n    model_client: adal.ModelClient,\n    model_kwargs: Dict,\n) -> Dict:\n\n    trainset, valset, testset = load_datasets()\n\n    adal_component = VallinaRAGAdal(\n        model_client,\n        model_kwargs,\n        backward_engine_model_config=gpt_4o_model,\n        teacher_model_config=gpt_3_model,\n        text_optimizer_model_config=gpt_3_model,\n    )\n    trainer = adal.Trainer(adaltask=adal_component)\n    trainer.diagnose(dataset=trainset, split=\"train\")\n    # trainer.diagnose(dataset=valset, split=\"val\")\n    # trainer.diagnose(dataset=testset, split=\"test\")\n```\n\n----------------------------------------\n\nTITLE: Implementing prepare_loss Method\nDESCRIPTION: This method prepares the loss function and its arguments for the AdalComponent. It converts the ground truth into a Parameter and sets the eval_input for the prediction.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef prepare_loss(\n    self, sample: Example, pred: adal.Parameter\n) -> Tuple[Callable, Dict[str, Any]]:\n    y_gt = adal.Parameter(\n        name=\"y_gt\",\n        data=sample.answer,\n        eval_input=sample.answer,\n        requires_opt=False,\n    )\n    pred.eval_input = pred.full_response.data\n    return self.loss_fn, {\"kwargs\": {\"y\": pred, \"y_gt\": y_gt}}\n```\n\n----------------------------------------\n\nTITLE: Initializing GEvalLLMJudge for Text Summarization\nDESCRIPTION: Sets up a GEvalLLMJudge instance with GPT-4 configuration parameters for evaluating text summarization quality across multiple metrics including relevance, fluency, consistency and coherence.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.eval.g_eval import GEvalLLMJudge, GEvalJudgeEvaluator, NLGTask\n\nmodel_kwargs = {\n    \"model\": \"gpt-4o\",\n    \"n\": 20,\n    \"top_p\": 1,\n    \"max_tokens\": 5,\n    \"temperature\": 1,\n}\n\ng_eval = GEvalLLMJudge(\n    default_task=NLGTask.SUMMARIZATION, model_kwargs=model_kwargs\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing QAWithRouter using Sequential Container in AdalFlow\nDESCRIPTION: Defines a QAWithRouter class that combines Router and Chat components using a Sequential container. This creates a complete pipeline for handling multi-domain queries in AdalFlow.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/intermediate.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass QAWithRouter(Component):\n    def __init__(self):\n        super().__init__()\n        self.router = Router(\n            choices={\"doctor\": \"Doctor\", \"lawyer\": \"Lawyer\", \"other\": \"Other\"}\n        )\n        self.chat = Chat()\n        self.pipeline = Sequential(self.router, self.chat)\n\n    def call(self, query: str) -> str:\n        return self.pipeline(query)\n```\n\nLANGUAGE: python\nCODE:\n```\nqa = QAWithRouter()\nqa\n```\n\nLANGUAGE: python\nCODE:\n```\nqa(\"I have a legal question\")\n```\n\n----------------------------------------\n\nTITLE: Implementing the Inference Mode Call Method for RAG\nDESCRIPTION: Defines the call method for a RAG component in inference mode. This method retrieves relevant documents using the retriever, formats them into a prompt context, and then generates an answer using the LLM component.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef call(self, question: str, id: str = None) -> adal.GeneratorOutput:\n    if self.training:\n        raise ValueError(\n            \"This component is not supposed to be called in training mode\"\n        )\n\n    retriever_out = self.retriever.call(input=question)\n\n    successor_map_fn = lambda x: (  # noqa E731\n        \"\\n\\n\".join(x[0].documents) if x and x[0] and x[0].documents else \"\"\n    )\n    retrieved_context = successor_map_fn(retriever_out)\n\n    prompt_kwargs = {\n        \"context\": retrieved_context,\n        \"question\": question,\n    }\n\n    output = self.llm.call(\n        prompt_kwargs=prompt_kwargs,\n        id=id,\n    )\n    return output\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Logger in User Application Code\nDESCRIPTION: Shows how to set up logging in application code using the standard Python logging module pattern.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logging\n\nlog = logging.getLogger(__name__)\n\nclass Task:\n    def __init__(self):\n        log.info(\"This is a user program child logger\")\n```\n\n----------------------------------------\n\nTITLE: Training Function for ObjectCountAdalComponent\nDESCRIPTION: This function sets up the training process for the ObjectCountAdalComponent, including dataset loading and trainer configuration.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef train(\n    train_batch_size=4,  # larger batch size is not that effective, probably because of llm's lost in the middle\n    raw_shots: int = 1,\n    bootstrap_shots: int = 1,\n    max_steps=1,\n    num_workers=4,\n    strategy=\"random\",\n    debug=False,\n):\n    adal_component = ObjectCountAdalComponent(\n        **gpt_3_model,\n        teacher_model_config=gpt_4o_model,\n        text_optimizer_model_config=gpt_4o_model,\n        backward_engine_model_config=gpt_4o_model\n    )\n    print(adal_component)\n    trainer = Trainer(\n        train_batch_size=train_batch_size,\n        strategy=strategy,\n        max_steps=max_steps,\n        num_workers=num_workers,\n        adaltask=adal_component,\n        raw_shots=raw_shots,\n        bootstrap_shots=bootstrap_shots,\n        debug=debug,\n        weighted_sampling=True,\n    )\n    print(trainer)\n\n    train_dataset, val_dataset, test_dataset = load_datasets()\n    trainer.fit(\n        train_dataset=train_dataset,\n        val_dataset=val_dataset,\n        test_dataset=test_dataset,\n        debug=debug,\n    )\n```\n\n----------------------------------------\n\nTITLE: Parsing YAML Output with YamlOutputParser in Python\nDESCRIPTION: Shows how to use YamlOutputParser to parse a YAML string into a dictionary based on a defined DataClass structure. It includes setting up the parser and using it to parse a YAML string.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.output_parsers import YamlOutputParser\n\nparser = YamlOutputParser(data_class=User, examples=[user_example])\nprint(parser)\n\nuser_to_parse = \"id: 2\\nname: Jane\"\nparsed_user = parser(user_to_parse)\nprint(parsed_user)\n```\n\n----------------------------------------\n\nTITLE: Question Answering Pipeline Implementation\nDESCRIPTION: Complete implementation of a question answering pipeline using AdalFlow components and templates\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntemplate = r\"\"\"<START_OF_SYSTEM_PROMPT>\n{{system_prompt}}\n<END_OF_SYSTEM_PROMPT>\n<START_OF_USER>\n{{input_str}}\n<END_OF_USER>\"\"\"\n\n@adal.func_to_data_component\ndef parse_integer_answer(answer: str):\n      numbers = re.findall(r\"\\d+\", answer)\n      return int(numbers[-1])\n\nclass ObjectCountTaskPipeline(adal.Component):\n   def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n      super().__init__()\n      system_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=True,\n            param_type=ParameterType.PROMPT,\n      )\n      self.llm_counter = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            template=template,\n            prompt_kwargs={\n               \"system_prompt\": system_prompt,\n            },\n            output_processors=parse_integer_answer,\n      )\n\n   def bicall(\n      self, question: str, id: str = None\n   ) -> Union[adal.GeneratorOutput, adal.Parameter]:\n      output = self.llm_counter(prompt_kwargs={\"input_str\": question}, id=id)\n      return output\n```\n\n----------------------------------------\n\nTITLE: Creating Generator from Configs in Python\nDESCRIPTION: This example demonstrates how to create a Generator object from a configuration dictionary using the from_config method.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import Generator\n\nconfig = {\n    \"model_client\": {\n        \"component_name\": \"GroqAPIClient\",\n        \"component_config\": {},\n    },\n    \"model_kwargs\": {\n        \"model\": \"llama3-8b-8192\",\n    },\n}\n\ngenerator: Generator = Generator.from_config(config)\nprint(generator)\n\nprompt_kwargs = {\"input_str\": \"What is LLM? Explain in one sentence.\"}\ngenerator.print_prompt(**prompt_kwargs)\noutput = generator(\n    prompt_kwargs=prompt_kwargs,\n)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Generating JSON and YAML Signatures for Custom DataClass\nDESCRIPTION: This snippet demonstrates how to generate JSON and YAML signatures for a custom DataClass, including options to exclude specific fields from the signatures.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\njson_signature = TrecData2.to_json_signature()\nprint(json_signature)\n\n# exclude field of the parent and child class\njson_signature_exclude = TrecData2.to_json_signature(\n    exclude={\"TrecData2\": [\"metadata\"], \"Question\": [\"metadata\"]}\n)\nprint(json_signature_exclude)\n\n# only exclude the parent class\njson_signature_exclude = TrecData2.to_json_signature(exclude=[\"metadata\"])\nprint(json_signature_exclude)\n\n# signature, yaml_signature\nyaml_signature = TrecData2.to_yaml_signature()\nprint(yaml_signature)\n```\n\n----------------------------------------\n\nTITLE: Initializing Generator with OpenAI Client in Python\nDESCRIPTION: This snippet demonstrates how to initialize and use the Generator class with an OpenAI client. It sets up the generator with model parameters and executes a simple prompt.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/generator.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import Generator\nfrom adalflow.components.model_client.openai_client import OpenAIClient\n\nllm = Generator(\n    model_client=OpenAIClient(),\n    model_kwargs={\n        \"model\": \"o3-mini\",\n    }\n)\n\nprompt_kwargs = {\"input_str\": \"What is LLM?\"}\n\nresponse = llm(prompt_kwargs=prompt_kwargs) # or llm.call in eval and llm.forward in training\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Optimized Prompts for TREC Classification in Python\nDESCRIPTION: This snippet shows the optimized system prompt and few-shot demonstration prompt for the TREC classifier. These prompts are the result of AdalFlow's optimization process.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/classification.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = \"You are a classifier. Given a question, you need to classify it into one of the following classes:\\nFormat: class_index. class_name, class_description\\n0. ABBR, Abbreviation or acronym\\n1. ENTY, Entity, including specific terms, brand names, or other distinct entities\\n2. DESC, Description and abstract concept, including explanations, characteristics, and meanings\\n3. HUM, Human being\\n4. LOC, Location, including spatial information, geographical places\\n5. NUM, Numeric value, including measurable figures, quantities, distances, and time\\n- Focus on correctly identifying the class based on the question's main inquiry:\"\nfew_shot_demos = \"rationale: The question is asking for a specific term used to describe the sum of\\n  all genetic material in an organism.\\nclass_name: ENTY\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Sequential Components in AdalFlow\nDESCRIPTION: Shows how to chain multiple components together using Sequential, including function components and DocQA implementations.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/component.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.container import Sequential\n\n@func_to_component\ndef enhance_query(query: str) -> str:\n    return query + \"Please be concise and only list the top treatments.\"\n\nseq = Sequential(enhance_query, doc)\n\nquery = \"What is the best treatment for headache?\"\nprint(seq(query))\n```\n\n----------------------------------------\n\nTITLE: Initializing ReActAgent with AdalFlow in Python\nDESCRIPTION: This code initializes a ReActAgent using AdalFlow, setting up the tools, maximum steps, model client, and model parameters. It uses the OpenAIClient for the model.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nagent = ReActAgent(\n    tools=tools,\n    max_steps=3,\n    model_client=OpenAIClient(),\n    model_kwargs=gpt_model_kwargs,\n    # preset_prompt_kwargs=preset_prompt_kwargs,\n)\nagent\n```\n\n----------------------------------------\n\nTITLE: Generating YAML Signature for TrecData2 Class in Python\nDESCRIPTION: This snippet illustrates how to generate and print the YAML signature for the TrecData2 class. The YAML signature provides a human-readable representation of the class structure, including field descriptions, types, and requirements.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nquestion: The question asked by the user ({'type': 'Question', 'properties': {'question': {'type': 'str', 'desc': 'The question asked by the user'}, 'metadata': {'type': 'dict', 'desc': 'The metadata of the question'}}, 'required': ['question']}) (required)\nlabel: The label of the question (int) (optional)\nmetadata: The metadata of the question (dict) (required)\n```\n\n----------------------------------------\n\nTITLE: Implementing Diagnosis Function\nDESCRIPTION: Function to diagnose model performance across train, validation and test datasets using the AdalComponent.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef diagnose(\n    model_client: adal.ModelClient,\n    model_kwargs: Dict,\n) -> Dict:\n\n    trainset, valset, testset = load_datasets()\n    # use max_samples=10 to test the code\n\n    adal_component = ObjectCountAdalComponent(model_client, model_kwargs)\n    trainer = adal.Trainer(adaltask=adal_component)\n    trainer.diagnose(dataset=trainset, split=\"train\")\n    trainer.diagnose(dataset=valset, split=\"val\")\n    trainer.diagnose(dataset=testset, split=\"test\")\n```\n\n----------------------------------------\n\nTITLE: Jinja2 Template Example with Conditional Rendering\nDESCRIPTION: Shows how to use Jinja2 templating to create more complex prompt templates with conditionals, loops, and blocks. This example demonstrates how to conditionally include tools in a prompt.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/prompt.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef jinja2_template_example(**kwargs):\n   from jinja2 import Template\n\n   template = r\"\"\"<SYS>{{ task_desc_str }}</SYS>\n{# tools #}\n{% if tools %}\n<TOOLS>\n{% for tool in tools %}\n{{loop.index}}. {{ tool }}\n{% endfor %}\n</TOOLS>\n{% endif %}\nUser: {{ input_str }}\"\"\"\n   t = Template(template, trim_blocks=True, lstrip_blocks=True)\n   print(t.render(**kwargs))\n```\n\n----------------------------------------\n\nTITLE: Switching to OpenAI Model in Python\nDESCRIPTION: Shows how to switch the LLM provider from the default to OpenAI's GPT-3.5-turbo model. This demonstrates the model-agnostic nature of AdalFlow, allowing easy swapping of underlying models.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/README.md#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client import OpenAIClient\n\nself.generator = Generator(\n    model_client=OpenAIClient(),\n    model_kwargs={\"model\": \"gpt-3.5-turbo\"},\n    template=qa_template,\n    prompt_kwargs={\"output_format_str\": parser.format_instructions()},\n    output_processors=parser,\n)\n```\n\n----------------------------------------\n\nTITLE: Testing Task Pipeline in Evaluation and Training Modes\nDESCRIPTION: Demonstrates how to use the task pipeline for object counting with a sample question in both evaluation and training modes.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nquestion = \"I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?\"\ntask_pipeline = ObjectCountTaskPipeline(**gpt_3_model)\nprint(task_pipeline)\n\nanswer = task_pipeline(question)\nprint(answer)\n\n# set it to train mode\ntask_pipeline.train()\nanswer = task_pipeline(question, id=\"1\")\nprint(answer)\nprint(f\"full_response: {answer.full_response}\")\n```\n\n----------------------------------------\n\nTITLE: Using LLM as Judge for Text Evaluation in Python\nDESCRIPTION: Implementation of an LLM-based evaluator that compares predicted answers against ground truth with customizable judgment queries. This function uses OpenAI's models and returns evaluation results with confidence intervals.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef compute_llm_as_judge():\n    import adalflow as adal\n    from adalflow.eval.llm_as_judge import LLMasJudge, DefaultLLMJudge\n    from adalflow.components.model_client import OpenAIClient\n\n    adal.setup_env()\n\n    questions = [\n        \"Is Beijing in China?\",\n        \"Is Apple founded before Google?\",\n        \"Is earth flat?\",\n    ]\n    pred_answers = [\"Yes\", \"Yes, Appled is founded before Google\", \"Yes\"]\n    gt_answers = [\"Yes\", \"Yes\", \"No\"]\n\n    llm_judge = DefaultLLMJudge(\n        model_client=OpenAIClient(),\n        model_kwargs={\n            \"model\": \"gpt-4o\",\n            \"temperature\": 1.0,\n            \"max_tokens\": 10,\n        },\n    )\n    llm_evaluator = LLMasJudge(llm_judge=llm_judge)\n    print(llm_judge)\n    eval_rslt = llm_evaluator.compute(\n        questions=questions, gt_answers=gt_answers, pred_answers=pred_answers\n    )\n    print(eval_rslt)\n```\n\n----------------------------------------\n\nTITLE: TREC Classifier ADAL Component Class Definition\nDESCRIPTION: Defines a complete ADAL component class for TREC classification, including initialization, task preparation, evaluation, and loss calculation methods.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_classification_optimization.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass TrecClassifierAdal(adal.AdalComponent):\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        teacher_model_config: Dict,\n        backward_engine_model_config: Dict,\n        text_optimizer_model_config: Dict,\n    ):\n        task = TRECClassifierStructuredOutput(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        loss_fn = adal.EvalFnToTextLoss(\n            eval_fn=eval_fn,\n            eval_fn_desc=\"exact_match: 1 if str(y) == str(y_gt) else 0. When the LLM prediction failed with format parsing which results with errors, we set y_pred = -1\",\n        )\n        super().__init__(\n            task=task,\n            eval_fn=eval_fn,\n            loss_fn=loss_fn,\n            backward_engine_model_config=backward_engine_model_config,\n            text_optimizer_model_config=text_optimizer_model_config,\n            teacher_model_config=teacher_model_config,\n        )\n\n    def prepare_task(self, sample: TRECExtendedData):\n        return self.task.call, {\"question\": sample.question, \"id\": sample.id}\n\n    def prepare_eval(\n        self, sample: TRECExtendedData, y_pred: adal.GeneratorOutput\n    ) -> float:\n        y_label = -1\n        if y_pred and y_pred.data is not None and y_pred.data.class_name is not None:\n            y_label = y_pred.data.class_name\n        return self.eval_fn, {\"y\": y_label, \"y_gt\": sample.class_name}\n\n    def prepare_loss(\n        self, sample: TRECExtendedData, y_pred: adal.Parameter, *args, **kwargs\n    ) -> Tuple[Callable[..., Any], Dict]:\n        full_response = y_pred.data\n        y_label = -1  # default value for failed prediction\n        if (\n            full_response\n            and full_response.data is not None\n            and full_response.data.class_name is not None\n        ):\n            y_label = full_response.data.class_name\n\n        y_pred.eval_input = y_label\n        y_gt = adal.Parameter(\n            name=\"y_gt\",\n            data=sample.class_name,\n            eval_input=sample.class_name,\n            requires_opt=False,\n        )\n        return self.loss_fn, {\n            \"kwargs\": {\"y\": y_pred, \"y_gt\": y_gt},\n            \"id\": sample.id,\n            \"gt\": y_gt.eval_input,\n        }\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Embedder\nDESCRIPTION: Example of creating an Embedder instance using OpenAI's text-embedding-3-small model with specific configuration parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_embedder.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.components.model_client import OpenAIClient\n\nmodel_kwargs = {\n    \"model\": \"text-embedding-3-small\",\n    \"dimensions\": 256,\n    \"encoding_format\": \"float\",\n}\n\nquery = \"What is the capital of China?\"\n\nqueries = [query] * 100\n\n\nembedder = Embedder(model_client=OpenAIClient(), model_kwargs=model_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Initializing ToolManager with Functions in Python\nDESCRIPTION: Shows how to create and use a ToolManager instance to handle multiple function tools.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.tool_manager import ToolManager\n\ntool_manager = ToolManager(tools=functions)\nprint(tool_manager)\n```\n\n----------------------------------------\n\nTITLE: Basic Generator Usage with OpenAI Client in Python\nDESCRIPTION: Demonstrates how to set up and use the Generator class with an OpenAI client. It includes setting up environment variables, creating a Generator instance, and running a query.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/basic.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import Generator\nfrom adalflow.components.model_client import OpenAIClient\nfrom adalflow.utils import setup_env  # ensure you have .env with OPENAI_API_KEY\n\nsetup_env(\".env\")\nquery = \"What is the capital of France?\"\nmodel_kwargs = {\"model\": \"gpt-3.5-turbo\"}\ngenerator = Generator(model_client=OpenAIClient(), model_kwargs=model_kwargs)\nprompt_kwargs = {\n    \"input_str\": query,\n}\n# run the generator\noutput = generator(prompt_kwargs=prompt_kwargs)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Using Generator's print_prompt Method\nDESCRIPTION: Demonstrates how to use the print_prompt method to see the formatted prompt before sending it to the model. This is useful for debugging and understanding how inputs are processed.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprompt_kwargs = {\"input_str\": \"What is LLM? Explain in one sentence.\"}\ngenerator.print_prompt(**prompt_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Adding Documents and Performing Retrieval with LanceDBRetriever in Python\nDESCRIPTION: This snippet demonstrates how to add documents to a LanceDBRetriever and perform retrieval operations with specific queries. It shows the process of indexing documents and retrieving the most relevant results based on vector similarity.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nretriever.add_documents(documents)\n\n# Perform retrieval queries\noutput_1 = retriever.retrieve(query=\"What are the benefits of renewable energy?\")\noutput_2 = retriever.retrieve(query=\"How do solar panels impact the environment?\")\nprint(\"Query 1 Results:\", output_1)\nprint(\"Query 2 Results:\", output_2)\n```\n\n----------------------------------------\n\nTITLE: Defining Few-Shot Template in Python\nDESCRIPTION: This template is used for few-shot learning, taking system prompt, few-shot demos, and input string as arguments.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfew_shot_template = r\"\"\"<START_OF_SYSTEM_PROMPT>\n{{system_prompt}}\n{# Few shot demos #}\n{% if few_shot_demos is not none %}\nHere are some examples:\n{{few_shot_demos}}\n{% endif %}\n<END_OF_SYSTEM_PROMPT>\n<START_OF_USER>\n{{input_str}}\n<END_OF_USER>\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Executing QA Pipeline and Displaying Results in Python\nDESCRIPTION: This snippet demonstrates how to instantiate the QA component, visualize its structure, and make a synchronous call to generate a response for a given query.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/README.md#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nqa = QA()\nprint(qa)\n\n# call\noutput = qa(\"What is LLM?\")\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: OpenAI Model Configuration Setup\nDESCRIPTION: Configures GPT-3.5-turbo and GPT-4o-mini models with specific parameters for classification and optimization tasks.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_classification_optimization.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client.openai_client import OpenAIClient\n\n# used as the target model\ngpt_3_model = {\n    \"model_client\": OpenAIClient(),\n    \"model_kwargs\": {\n        \"model\": \"gpt-3.5-turbo\",\n        \"max_tokens\": 2000,\n        \"temperature\": 0.0,\n        \"top_p\": 0.99,\n        \"frequency_penalty\": 0,\n        \"presence_penalty\": 0,\n        \"stop\": None,\n    },\n}\n\n# used as optimizer and backward engine\ngpt_4o_mini_model = {\n    \"model_client\": OpenAIClient(),\n    \"model_kwargs\": {\n        \"model\": \"gpt-4o-mini\",\n        \"temperature\": 1,\n        \"top_p\": 0.99,\n        \"max_tokens\": 1000,\n        # \"frequency_penalty\": 1,  # high for nto repeating prompt\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Custom-Processed Embeddings\nDESCRIPTION: Verifies the custom output processor is working by embedding a query and checking the dimensions. This shows the embedding has been reduced to the specified dimension while maintaining normalization.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\noutput = local_embedder_256(query)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 1 256 True\n```\n\n----------------------------------------\n\nTITLE: Embedding Single Query with OpenAI in Python\nDESCRIPTION: Demonstrates how to use the Embedder to embed a single query and print the output details.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/embedder.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\noutput = embedder(query)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 1 256 True\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow via pip\nDESCRIPTION: Simple pip command to install the AdalFlow library, which is the first step to start using the framework for building and auto-optimizing LLM workflows.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/README.md#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install adalflow\n```\n\n----------------------------------------\n\nTITLE: Debug Mode Training for ObjectCountAdalComponent\nDESCRIPTION: This snippet demonstrates how to run the training in debug mode with specific parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ntrain(debug=True, max_steps=12, strategy=\"constrained\")\n```\n\n----------------------------------------\n\nTITLE: Calling the Generator with Prompt Arguments\nDESCRIPTION: Shows how to call a Generator with prompt arguments and receive the standardized GeneratorOutput object. This pattern allows for consistent processing of model responses.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\noutput = generator(\n    prompt_kwargs=prompt_kwargs,\n)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Parsing JSON with JsonParser in Python\nDESCRIPTION: Demonstrates the usage of JsonParser to convert JSON-formatted strings into Python dictionaries or lists. It can handle simple dictionaries, nested dictionaries, lists, and lists of dictionaries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import JsonParser\n\ndict_str = '{\"key\": \"value\"}'\nnested_dict_str = '{\"name\": \"John\", \"age\": 30, \"attributes\": {\"height\": 180, \"weight\": 70}}'\nlist_str = '[\"key\", 2]'\nlist_dict_str = '[{\"key\": \"value\"}, {\"key\": \"value\"}]'\n\nparser = JsonParser()\nprint(parser)\nprint(parser(dict_str))\nprint(parser(nested_dict_str))\nprint(parser(list_str))\nprint(parser(list_dict_str))\n```\n\n----------------------------------------\n\nTITLE: Creating a Response Parameter in Python for AdalFlow\nDESCRIPTION: This code snippet demonstrates how to create a response Parameter object in AdalFlow. It includes setting the data, alias, role description, predecessors, and input arguments for the parameter.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/parameter.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nresponse = Parameter(\n    data=retriever_reponse,\n    alias=self.name + \"_output\",\n    role_desc=\"Retriever response\",\n    predecessors=predecessors,\n    input_args=input_args,\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using Mistral Generator\nDESCRIPTION: Creates an AdalFlow generator instance with Mistral AI configuration and demonstrates basic usage with a sample prompt for machine learning explanation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/mistral_integration.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client import MistralClient\nimport adalflow as adal\n\ngenerator = adal.Generator(\n    model_client=MistralClient(),\n    model_kwargs={\n        \"model\": \"mistral-large-latest\",\n        \"temperature\": 0.7,\n        \"max_tokens\": 2000,\n    },\n)\n\nprompt_kwargs = {\"input_str\": \"Explain the concept of machine learning.\"}\n\nresponse = generator(prompt_kwargs)\n\nif response.error:\n    print(f\"[Mistral] Generator Error: {response.error}\")\nelse:\n    print(f\"[Mistral] Response: {response.data}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom DataClass with Required Fields After Optional Fields\nDESCRIPTION: This snippet introduces a custom DataClass implementation that allows required fields to be placed after optional fields using a required_field decorator. It demonstrates how to overcome limitations of standard dataclasses.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import DataClass, required_field\n\n\n@dataclass\nclass TrecData2(DataClass):\n    question: Question = field(\n        metadata={\"desc\": \"The question asked by the user\"}\n    )  # Required field, you have to provide the question field at the instantiation\n    label: int = field(\n        metadata={\"desc\": \"The label of the question\"}, default=0\n    )  # Optional field\n    metadata: dict = field(\n        metadata={\"desc\": \"The metadata of the question\"},\n        default_factory=required_field(),\n    )  # required field\n```\n\n----------------------------------------\n\nTITLE: Configuring Generator with Function Output Format in Python\nDESCRIPTION: This snippet shows how to set up a Generator with the Function data class and JsonOutputParser. It includes configuration of model parameters, prompt kwargs, and output processors.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.generator import Generator\nfrom adalflow.core.types import ModelClientType\n\nmodel_kwargs = {\"model\": \"gpt-3.5-turbo\"}\nprompt_kwargs = {\n    \"tools\": tool_manager.yaml_definitions,\n    \"output_format_str\": func_parser.format_instructions(),\n}\ngenerator = Generator(\n    model_client=ModelClientType.OPENAI(),\n    model_kwargs=model_kwargs,\n    template=template,\n    prompt_kwargs=prompt_kwargs,\n    output_processors=func_parser,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Backward Engine in ObjectCountAdalComponent\nDESCRIPTION: Sets up the backward engine for the ObjectCountAdalComponent using the configure_backward_engine_helper method.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef configure_backward_engine(self):\n    super().configure_backward_engine_helper(\n        **self.backward_engine_model_config\n    )\n```\n\n----------------------------------------\n\nTITLE: Executing Function Expressions with Error Handling in Python\nDESCRIPTION: This code executes function expressions parsed from user queries. It uses AdalFlow's ToolManager to execute the expressions via a sandbox and handles potential errors.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfor idx in range(0, len(queries), 2):\n    query = \" and \".join(queries[idx : idx + 2])\n    prompt_kwargs = {\"input_str\": query}\n    print(f\"\\n{idx} Query: {query}\")\n    print(f\"{'-'*50}\")\n    try:\n        result = generator(prompt_kwargs=prompt_kwargs)\n        func_expr: List[FunctionExpression] = [\n            FunctionExpression.from_dict(item) for item in result.data\n        ]\n        print(f\"Function_expr: {func_expr}\")\n        for expr in func_expr:\n            func_output = tool_manager.execute_func_expr_via_sandbox(expr)\n            print(f\"Function output: {func_output}\")\n    except Exception as e:\n        print(\n            f\"Failed to execute the function for query: {query}, func: {result.data}, error: {e}\"\n        )\n```\n\n----------------------------------------\n\nTITLE: Converting TrecData2 Instance to Dictionary and Back in Python\nDESCRIPTION: This code demonstrates how to create a TrecData2 instance, convert it to a dictionary, and then reconstruct the instance from the dictionary. It also shows how to compare the original and reconstructed instances for equality.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nexample = TrecData2(Question(\"What is the capital of France?\"), 1, {\"key\": \"value\"})\nprint(example)\n\ndict_example = example.to_dict()\nprint(dict_example)\n\nreconstructed = TrecData2.from_dict(dict_example)\nprint(reconstructed)\n\nprint(reconstructed == example)\n```\n\nLANGUAGE: python\nCODE:\n```\nTrecData2(question=Question(question='What is the capital of France?', metadata={}), label=1, metadata={'key': 'value'})\n{'question': {'question': 'What is the capital of France?', 'metadata': {}}, 'label': 1, 'metadata': {'key': 'value'}}\nTrecData2(question=Question(question='What is the capital of France?', metadata={}), label=1, metadata={'key': 'value'})\nTrue\n```\n\n----------------------------------------\n\nTITLE: Implementing Router Component for Multi-Task Approach in AdalFlow\nDESCRIPTION: Defines a Router class that selects the appropriate task based on input choices. This component is designed to be used as part of a Sequential container in AdalFlow.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/intermediate.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Router component\n\nfrom typing import Dict\n\n\nclass Router(Component):\n    def __init__(self, choices: Dict[str, str] = {}):\n        super().__init__()\n        self.choices = choices\n        self.router = Generator(\n            template=template_router,\n            model_client=OpenAIClient(),\n            model_kwargs={\"model\": \"gpt-3.5-turbo\"},\n        )\n\n    def call(self, query: str) -> str:\n        prompt_kwargs = {\"input_str\": query, \"choices\": self.choices}\n        choice = self.router(prompt_kwargs=prompt_kwargs).data\n        return {\"choice\": choice, \"query\": query}\n\n    def _extra_repr(self):\n        return f\"Choices: {self.choices}, \"\n```\n\nLANGUAGE: python\nCODE:\n```\nr = Router()\nr\n```\n\n----------------------------------------\n\nTITLE: Loading HotPotQA Datasets and Defining Answer Data Structure\nDESCRIPTION: This code defines a function to load HotPotQA datasets and an AnswerData class for structuring the model's output. It also demonstrates loading and printing a sample from the dataset.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef load_datasets():\n\n    trainset = HotPotQA(split=\"train\", size=20)\n    valset = HotPotQA(split=\"val\", size=50)\n    testset = HotPotQA(split=\"test\", size=50)\n    print(f\"trainset, valset: {len(trainset)}, {len(valset)}, example: {trainset[0]}\")\n    return trainset, valset, testset\n\n\n@dataclass\nclass AnswerData(adal.DataClass):\n    reasoning: str = field(\n        metadata={\"desc\": \"The reasoning to produce the answer\"},\n    )\n    answer: str = field(\n        metadata={\"desc\": \"The answer you produced\"},\n    )\n\n    __output_fields__ = [\"reasoning\", \"answer\"]\n\n\ndataset = HotPotQA(split=\"train\", size=20)\nprint(dataset[0], type(dataset[0]))\n\nHotPotQAData(\n    id=\"5a8b57f25542995d1e6f1371\",\n    question=\"Were Scott Derrickson and Ed Wood of the same nationality?\",\n    answer=\"yes\",\n    gold_titles=\"{'Scott Derrickson', 'Ed Wood'}\",\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Function Components\nDESCRIPTION: Examples of converting functions to AdalFlow components using decorators and explicit conversion\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_component.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@func_to_component\ndef add_one(x):\n    return x + 1\n\nprint(add_one(1))\nprint(type(add_one))\n```\n\n----------------------------------------\n\nTITLE: Applying Data Pipeline to Dialog Turns in Python\nDESCRIPTION: This code demonstrates how to apply the created data pipeline to a list of dialog turns, converting them to documents and processing them.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndialog_turns_as_documents = [map_dialogturn_to_document(turn) for turn in dialog_turns]\nprint(dialog_turns_as_documents)\n\n# apply data transformation to the documents\noutput = data_transformer(dialog_turns_as_documents)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Custom Embedding Dimension Processor\nDESCRIPTION: Custom component implementation to decrease embedding dimensions and optionally normalize the vectors.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_embedder.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import Embedding, EmbedderOutput\nfrom adalflow.core.functional import normalize_vector\nfrom typing import List\nfrom adalflow.core.component import Component\nfrom copy import deepcopy\n\n\nclass DecreaseEmbeddingDim(Component):\n    def __init__(self, old_dim: int, new_dim: int, normalize: bool = True):\n        super().__init__()\n        self.old_dim = old_dim\n        self.new_dim = new_dim\n        self.normalize = normalize\n        assert self.new_dim < self.old_dim, \"new_dim should be less than old_dim\"\n\n    def call(self, input: List[Embedding]) -> List[Embedding]:\n        output: EmbedderOutput = deepcopy(input)\n        for embedding in output.data:\n            old_embedding = embedding.embedding\n            new_embedding = old_embedding[: self.new_dim]\n            if self.normalize:\n                new_embedding = normalize_vector(new_embedding)\n            embedding.embedding = new_embedding\n        return output.data\n\n    def _extra_repr(self) -> str:\n        repr_str = f\"old_dim={self.old_dim}, new_dim={self.new_dim}, normalize={self.normalize}\"\n        return repr_str\n```\n\n----------------------------------------\n\nTITLE: Custom Field Mapping for Dataset Loading in Python\nDESCRIPTION: Demonstrates how to create a custom DataClass with field mapping to load data from a dataset. It includes a custom from_dict method to map dataset keys to class fields.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass OutputFormat(DataClass):\n    thought: str = field(\n        metadata={\n            \"desc\": \"Your reasoning to classify the question to class_name\",\n        }\n    )\n    class_name: str = field(metadata={\"desc\": \"class_name\"})\n    class_index: int = field(metadata={\"desc\": \"class_index in range[0, 5]\"})\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, object]):\n        _COARSE_LABELS_DESC = [\n            \"Abbreviation\",\n            \"Entity\",\n            \"Description and abstract concept\",\n            \"Human being\",\n            \"Location\",\n            \"Numeric value\",\n        ]\n        data = {\n            \"thought\": None,\n            \"class_index\": data[\"coarse_label\"],\n            \"class_name\": _COARSE_LABELS_DESC[data[\"coarse_label\"]],\n        }\n        return super().from_dict(data)\n```\n\n----------------------------------------\n\nTITLE: Testing Object Count Task Pipeline in Evaluation and Training Modes\nDESCRIPTION: Demonstrates how to use the ObjectCountTaskPipeline with a sample question in both evaluation and training modes, showcasing the difference in output formats.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nquestion = \"I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?\"\ntask_pipeline = ObjectCountTaskPipeline(**gpt_3_model)\nprint(task_pipeline)\n\nanswer = task_pipeline(question)\nprint(answer)\n\n# set it to train mode\ntask_pipeline.train()\nanswer = task_pipeline(question, id=\"1\")\nprint(answer)\nprint(f\"full_response: {answer.full_response}\")\n```\n\n----------------------------------------\n\nTITLE: Importing AdalFlow Modules for ChatBot\nDESCRIPTION: This code imports necessary modules from AdalFlow to build the chatbot. It includes components for memory management, model client (OpenAI in this case), and core functionalities like Component and Generator.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/question_answering/chatbot.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Import needed modules from Adalflow\nimport os\nfrom getpass import getpass\nfrom adalflow.core.component import Component\nfrom adalflow.core.generator import Generator\nfrom adalflow.components.memory.memory import Memory\nfrom adalflow.components.model_client import (\n    OpenAIClient,\n)  # Here, we use the OpenAIClient as an example, but you can use any other clients (with the corresponding API Key as needed), such as AnthropicAPIClient\n```\n\n----------------------------------------\n\nTITLE: BM25 Retriever Implementation\nDESCRIPTION: Implementation of BM25-based text retrieval with tokenization support.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.retriever import BM25Retriever\n\ndocument_map_func = lambda x: x[\"content\"]\n\nbm25_retriever = BM25Retriever(top_k=2, documents=documents, document_map_func=document_map_func)\nprint(bm25_retriever)\n```\n\n----------------------------------------\n\nTITLE: Creating Generator with Custom Template\nDESCRIPTION: Demonstrates how to use a custom template with the Generator. The template defines how input variables are structured before being sent to the model.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntemplate = r\"\"\"<SYS>{{task_desc_str}}</SYS>\nUser: {{input_str}}\nYou:\"\"\"\ngenerator = Generator(\n```\n\n----------------------------------------\n\nTITLE: Question Answering Pipeline Usage\nDESCRIPTION: Example of using the implemented question answering pipeline\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nobject_count_pipeline = ObjectCountTaskPipeline(**model_config)\n\nquestion = \"I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?\"\nresponse = object_count_pipeline(question)\n```\n\n----------------------------------------\n\nTITLE: Embedding with Local HuggingFace Model\nDESCRIPTION: Demonstrates embedding operations using a local HuggingFace model. The code shows both single query and batch processing, displaying the output properties.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\noutput = local_embedder(query)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 1 768 True\n\noutput = local_embedder(queries)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 100 768 True\n```\n\n----------------------------------------\n\nTITLE: Batch Embedding with OpenAI in Python\nDESCRIPTION: Shows how to use the Embedder for batch processing of multiple queries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/embedder.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\noutput = embedder(queries)\nprint(output.length, output.embedding_dim)\n# 100 256\n```\n\n----------------------------------------\n\nTITLE: Embedding with Local Transformer Model in Python\nDESCRIPTION: Demonstrates embedding single and batch queries using a local Transformer model.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/embedder.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\noutput = local_embedder(query)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 1 768 True\n\noutput = local_embedder(queries)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 100 768 True\n```\n\n----------------------------------------\n\nTITLE: Training Configuration of ObjectCountAdalComponent\nDESCRIPTION: Extended implementation of ObjectCountAdalComponent with training capabilities including loss function and parameter preparation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.datasets.types import Example\n\n\nclass ObjectCountAdalComponent(adal.AdalComponent):  # noqa: F811\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        backward_engine_model_config: Dict,\n        teacher_model_config: Dict,\n        text_optimizer_model_config: Dict,\n    ):\n        task = ObjectCountTaskPipeline(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        loss_fn = adal.EvalFnToTextLoss(\n            eval_fn=eval_fn,\n            eval_fn_desc=\"exact_match: 1 if str(y) == str(y_gt) else 0\",\n        )\n        super().__init__(task=task, eval_fn=eval_fn, loss_fn=loss_fn)\n\n        self.backward_engine_model_config = backward_engine_model_config\n        self.teacher_model_config = teacher_model_config\n        self.text_optimizer_model_config = text_optimizer_model_config\n\n    def prepare_task(self, sample: Example):\n        return self.task.bicall, {\"question\": sample.question, \"id\": sample.id}\n\n    def prepare_eval(self, sample: Example, y_pred: adal.GeneratorOutput) -> float:\n        y_label = -1\n        if (\n            y_pred is not None and y_pred.data is not None\n        ):  # if y_pred and y_pred.data: might introduce bug when the data is 0\n            y_label = y_pred.data\n        return self.eval_fn, {\"y\": y_label, \"y_gt\": sample.answer}\n\n    def prepare_loss(self, sample: Example, pred: adal.Parameter):\n        # prepare gt parameter\n        y_gt = adal.Parameter(\n            name=\"y_gt\",\n            data=sample.answer,\n            eval_input=sample.answer,\n            requires_opt=False,\n        )\n\n        # pred's full_response is the output of the task pipeline which is GeneratorOutput\n        pred.eval_input = pred.full_response.data\n        return self.loss_fn, {\"kwargs\": {\"y\": pred, \"y_gt\": y_gt}}\n```\n\n----------------------------------------\n\nTITLE: Importing AdalFlow Core Components\nDESCRIPTION: Imports essential modules from AdalFlow framework including Component and Generator classes for building the QA pipeline.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/question_answering/simple_qa.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import needed modules from AdalFlow\nfrom adalflow.core.component import Component\nfrom adalflow.core.generator import Generator\n```\n\n----------------------------------------\n\nTITLE: Using Custom Output Processor with Embedder\nDESCRIPTION: Demonstrates how to integrate a custom output processor with an Embedder. This code creates an embedder that uses a local model but reduces the embedding dimension from 768 to 256.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nlocal_embedder_256 = Embedder(\n     model_client=TransformersClient(),\n     model_kwargs=model_kwargs,\n     output_processors=DecreaseEmbeddingDim(768, 256),\n )\nprint(local_embedder_256)\n```\n\n----------------------------------------\n\nTITLE: Basic Prompt Formatting with Special Tokens\nDESCRIPTION: Shows how a simple prompt is formatted with system message tags for LLM interactions. Demonstrates the format used by AdalFlow and how it would be processed by Llama3.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/prompt.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nsimple_prompt = r\"\"\"<SYS> You are a helpful assistant. </SYS> User: What can you help me with?\"\"\"\n```\n\nLANGUAGE: python\nCODE:\n```\nfinal_prompt = r\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n{{simple_prompt}} <|eot_id|>\"\"\"\n```\n\nLANGUAGE: python\nCODE:\n```\nprediction = r\"\"\"<|start_header_id|>assistant<|end_header_id|> You can ask me anything you want. <|eot_id|><|end_of_text|>\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Generator with Groq API Client\nDESCRIPTION: Shows a minimal example of creating a Generator with Groq's API client. This demonstrates the essential parameters needed to initialize a Generator with a specific model client and model configuration.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\nfrom adalflow.components.model_client import GroqAPIClient\n\ngenerator = adal.Generator(\n    model_client=GroqAPIClient(),\n    model_kwargs={\"model\": \"llama3-8b-8192\"},\n)\nprint(generator)\n```\n\n----------------------------------------\n\nTITLE: Importing Retriever Components in Python\nDESCRIPTION: This code snippet shows the import statements for two retriever components: LLMRetriever and QdrantRetriever. These classes are likely used for different types of information retrieval within the AdalFlow project.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_21\n\nLANGUAGE: Python\nCODE:\n```\nfrom components.retriever.llm_retriever import LLMRetriever\nfrom components.retriever.qdrant_retriever import QdrantRetriever\n```\n\n----------------------------------------\n\nTITLE: Initializing QdrantRetriever with a Client in Python\nDESCRIPTION: This code demonstrates how to set up a QdrantRetriever with a QdrantClient, collection name, embedder, and document configuration parameters. The retriever connects to a Qdrant database to perform vector-based document retrieval.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.retriever import QdrantRetriever\nfrom qdrant_client import QdrantClient\n\n\nclient = QdrantClient(url=\"http://localhost:6333\")\nqdrant_retriever = QdrantRetriever(\n    collection_name=\"{collection_name}\",\n    client=client,\n    embedder=embedder,\n    top_k=5,\n    text_key=\"content\",\n)\nprint(qdrant_retriever)\n```\n\n----------------------------------------\n\nTITLE: Importing HotPotQA Dataset and Printing Example\nDESCRIPTION: Demonstrates how to import the HotPotQA dataset using AdalFlow's dataset module and print a sample entry. HotPotQA is a widely used dataset for benchmarking question answering and RAG tasks.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.datasets.hotpot_qa import HotPotQA, HotPotQAData\n\ndataset = HotPotQA(split=\"train\", size=20)\nprint(dataset[0], type(dataset[0]))\n```\n\n----------------------------------------\n\nTITLE: Implementing SongReviewer Component in Python\nDESCRIPTION: Creates a component class that handles song review generation using a model client and data class parser.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass SongReviewer(adal.Component):\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        super().__init__()\n        self.additional_structure_prompt = (\n            \"Dont use 'type' and 'properties' in output directly give as dict\"\n        )\n        parser = adal.DataClassParser(\n            data_class=SongAnalysis, return_data_class=False, format_type=\"json\"\n        )\n        self.generator = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            template=song_review_template,\n            prompt_kwargs={\n                \"output_format_str\": parser.get_output_format_str()\n                + self.additional_structure_prompt\n            },\n            output_processors=parser,\n        )\n\n    def call(self, song_title: str):\n        return self.generator.call({\"song_title\": song_title})\n```\n\n----------------------------------------\n\nTITLE: Using IntParser in AdalFlow\nDESCRIPTION: Demonstrates the IntParser which extracts the first integer value from text. This parser will convert floats to integers by truncating the decimal part.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nrom adalflow.core.string_parser import IntParser\n\nint_str = \"42\"\nint_str_2 = \"42.0\"\nint_str_3 = \"42.7\"\nint_str_4 = \"the answer is 42.75\"\n\n# it will all return 42\nparser = IntParser()\nprint(parser(int_str))\nprint(parser(int_str_2))\nprint(parser(int_str_3))\nprint(parser(int_str_4))\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Keys\nDESCRIPTION: This code securely prompts the user for OpenAI and Groq API keys, then sets them as environment variables for use in the application.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\ngroq_api_key = getpass(\"Please enter your GROQ API key: \")\n\n# Set environment variables\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Local Transformers Embedder\nDESCRIPTION: Initializes an Embedder with a local HuggingFace model. This code configures the embedder to use the 'thenlper/gte-base' model through the TransformersClient.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.components.model_client import TransformersClient\n\nmodel_kwargs = {\"model\": \"thenlper/gte-base\"}\nlocal_embedder = Embedder(model_client=TransformersClient(), model_kwargs=model_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Creating DialogTurn Objects for Conversation History\nDESCRIPTION: Demonstrates how to create DialogTurn objects to represent conversation turns between user and assistant.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import DialogTurn, UserQuery, AssistantResponse\n\ndialog_turns = [\nDialogTurn(\n        user_query=UserQuery(query_str=turn[\"user\"]),\n        assistant_response=AssistantResponse(response_str=turn[\"system\"]),\n        user_query_timestamp=turn[\"user_time\"],\n        assistant_response_timestamp=turn[\"system_time\"],\n    )\n    for turn in turns\n]\nprint(dialog_turns)\n```\n\n----------------------------------------\n\nTITLE: Implementing Base Retriever Class in Python\nDESCRIPTION: Abstract base class for retriever components that defines the interface for document retrieval operations with generic type support.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass Retriever(Component, Generic[RetrieverDocumentType, RetrieverQueryType]):\n\n    ...\n\n    def call(\n        self,\n        input: RetrieverQueriesType,\n        top_k: Optional[int] = None,\n        **kwargs,\n    ) -> RetrieverOutputType:\n        raise NotImplementedError(f\"retrieve is not implemented\")\n\n    async def acall(\n        self,\n        input: RetrieverQueriesType,\n        top_k: Optional[int] = None,\n        **kwargs,\n    ) -> RetrieverOutputType:\n        raise NotImplementedError(f\"Async retrieve is not implemented\")\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Generator Calls with Groq API Client in Python\nDESCRIPTION: Demonstrates how to perform multiple asynchronous calls using the Generator with Groq API Client. This approach is used for improved performance when making multiple queries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/basic.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport nest_asyncio  # import asyncio, use nest_asyncio.apply() if you are in jupyter notebook\nimport asyncio\n\nnest_asyncio.apply()\n\nimport time\nfrom typing import List\n\n\nasync def make_async_calls(queries: List[str]):\n    calls = [generator3.acall(prompt_kwargs={\"input_str\": query}) for query in queries]\n    responses = await asyncio.gather(*calls)\n    return responses\n\n\nqueries = [query] * 10\nstart = time.time()\nresponses = asyncio.run(make_async_calls(queries))\nprint(f\"Time taken for 10 async calls: {time.time() - start}\")\nprint(responses)\n```\n\n----------------------------------------\n\nTITLE: Using Custom Output Processor with Embedder in Python\nDESCRIPTION: Demonstrates how to use a custom output processor with the Embedder to modify embedding dimensions.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/embedder.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nlocal_embedder_256 = Embedder(\n     model_client=TransformersClient(),\n     model_kwargs=model_kwargs,\n     output_processors=DecreaseEmbeddingDim(768, 256),\n)\nprint(local_embedder_256)\n\noutput = local_embedder_256(query)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 1 256 True\n```\n\n----------------------------------------\n\nTITLE: Training Function for ObjectCountAdalComponent\nDESCRIPTION: Defines a train function that sets up the ObjectCountAdalComponent, configures the Trainer, and fits the model on the dataset.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef train(\n    train_batch_size=4,  # larger batch size is not that effective, probably because of llm's lost in the middle\n    raw_shots: int = 1,\n    bootstrap_shots: int = 1,\n    max_steps=1,\n    num_workers=4,\n    strategy=\"random\",\n    debug=False,\n):\n    adal_component = ObjectCountAdalComponent(\n        **gpt_3_model,\n        teacher_model_config=gpt_3_model,\n        text_optimizer_model_config=gpt_4o_model,\n        backward_engine_model_config=gpt_4o_model\n    )\n    print(adal_component)\n    trainer = Trainer(\n        train_batch_size=train_batch_size,\n        strategy=strategy,\n        max_steps=max_steps,\n        num_workers=num_workers,\n        adaltask=adal_component,\n        raw_shots=raw_shots,\n        bootstrap_shots=bootstrap_shots,\n        debug=debug,\n        weighted_sampling=True,\n    )\n    print(trainer)\n\n    train_dataset, val_dataset, test_dataset = load_datasets()\n    trainer.fit(\n        train_dataset=train_dataset,\n        val_dataset=val_dataset,\n        test_dataset=test_dataset,\n        debug=debug,\n    )\n```\n\n----------------------------------------\n\nTITLE: LLM Judge Evaluation Result Example in JSON\nDESCRIPTION: Example output from an LLM judge evaluation showing the average score, list of individual judgment scores, and confidence interval. This demonstrates the statistical robustness of the evaluation approach.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_7\n\nLANGUAGE: json\nCODE:\n```\nLLMJudgeEvalResult(avg_score=0.6666666666666666, judgement_score_list=[1, 1, 0], confidence_interval=(0.013333333333333197, 1))\n```\n\n----------------------------------------\n\nTITLE: Creating Documents from Raw Data in Python\nDESCRIPTION: Demonstrates how to create Document objects from raw document data with text content and metadata.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\norg_documents =[\n    {\n        \"title\": \"The Impact of Renewable Energy on the Economy\",\n        \"content\": \"Renewable energy technologies not only help in reducing greenhouse gas emissions but also contribute significantly to the economy by creating jobs in the manufacturing and installation sectors. The growth in renewable energy usage boosts local economies through increased investment in technology and infrastructure.\"\n    },\n    {\n        \"title\": \"Understanding Solar Panels\",\n        \"content\": \"Solar panels convert sunlight into electricity by allowing photons, or light particles, to knock electrons free from atoms, generating a flow of electricity. Solar panels are a type of renewable energy technology that has been found to have a significant positive effect on the environment by reducing the reliance on fossil fuels.\"\n    },\n    {\n        \"title\": \"Pros and Cons of Solar Energy\",\n        \"content\": \"While solar energy offers substantial environmental benefits, such as reducing carbon footprints and pollution, it also has downsides. The production of solar panels can lead to hazardous waste, and large solar farms require significant land, which can disrupt local ecosystems.\"\n    },\n    {\n        \"title\":  \"Renewable Energy and Its Effects\",\n        \"content\": \"Renewable energy sources like wind, solar, and hydro power play a crucial role in combating climate change. They do not produce greenhouse gases during operation, making them essential for sustainable development. However, the initial setup and material sourcing for these technologies can still have environmental impacts.\"\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Training TREC Classifier with AdalFlow in Python\nDESCRIPTION: This function trains a TREC classifier using AdalFlow. It sets up the AdalComponent and Trainer with various parameters like batch size, optimization strategy, and number of steps. The function also loads datasets and fits the model.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/classification.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef train(\n    model_client: adal.ModelClient,\n    model_kwargs: Dict,\n    train_batch_size=4,  # larger batch size is not that effective, probably because of llm's lost in the middle\n    raw_shots: int = 0,\n    bootstrap_shots: int = 1,\n    max_steps=12,\n    num_workers=4,\n    strategy=\"constrained\",\n    optimization_order=\"sequential\",\n    debug=False,\n):\n    # TODO: ensure the teacher prompt gets updated with the new model\n    adal_component = TrecClassifierAdal(\n        model_client=model_client,\n        model_kwargs=model_kwargs,\n        text_optimizer_model_config=gpt_4o_model,\n        backward_engine_model_config=gpt_4o_model,\n        teacher_model_config=gpt_4o_model,\n    )\n    print(adal_component)\n    trainer = adal.Trainer(\n        train_batch_size=train_batch_size,\n        adaltask=adal_component,\n        strategy=strategy,\n        max_steps=max_steps,\n        num_workers=num_workers,\n        raw_shots=raw_shots,\n        bootstrap_shots=bootstrap_shots,\n        debug=debug,\n        weighted_sampling=True,\n        optimization_order=optimization_order,\n        exclude_input_fields_from_bootstrap_demos=True,\n    )\n    print(trainer)\n\n    train_dataset, val_dataset, test_dataset = load_datasets()\n    trainer.fit(\n        train_dataset=train_dataset,\n        val_dataset=test_dataset,\n        debug=debug,\n    )\n```\n\n----------------------------------------\n\nTITLE: Using Local Transformer Model for Embeddings\nDESCRIPTION: Implementation of Embedder using a local transformer model (thenlper/gte-base) instead of OpenAI API.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_embedder.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.components.model_client import TransformersClient\n\nmodel_kwargs = {\"model\": \"thenlper/gte-base\"}\nlocal_embedder = Embedder(model_client=TransformersClient(), model_kwargs=model_kwargs)\n\noutput = local_embedder(query)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 1 768 True\n\noutput = local_embedder(queries)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 100 768 True\n```\n\n----------------------------------------\n\nTITLE: Using BatchEmbedder for Large-Scale Embedding in Python\nDESCRIPTION: Sets up and uses a BatchEmbedder to process a large number of queries in batches.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/embedder.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import BatchEmbedder\n\nbatch_embedder = BatchEmbedder(embedder=local_embedder, batch_size=100)\n\nqueries = [query] * 1000\n\nresponse = batch_embedder(queries)\n# 100%|██████████| 11/11 [00:04<00:00,  2.59it/s]\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Classes and Generator Configuration for Few-Shot Learning in Python\nDESCRIPTION: Illustrates how to implement a data class for few-shot demonstrations and configure a generator with this class for tracing inputs and outputs during teacher mode operation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/optimizer.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass ObjectCountSimple(DataClass):\n    \"\"\"Dataclass for string output\"\"\"\n    id: str = field(\n        default=None,\n        metadata={\"desc\": \"The unique identifier of the example\"},\n    )\n\n    question: str = field(\n        default=None,\n        metadata={\"desc\": \"The question to be answered\"},\n    )\n\n    answer: str = field(\n        default=None,\n        metadata={\"desc\": \"The raw answer to the question\"},\n    )\n    score: float = field(\n        default=None,\n        metadata={\n            \"desc\": \"The score of the answer, in range [0, 1]. The higher the better\"\n        },\n    )\n\n_few_shot_demos = Parameter(\n        alias=\"few_shot_demos\",\n        data=None,\n        role_desc=\"To provide few shot demos to the language model\",\n        requires_opt=True,\n        param_type=ParameterType.DEMOS,\n    )\n\nself.llm_counter = Generator(\n    model_client=model_client,\n    model_kwargs=model_kwargs,\n    template=few_shot_template,\n    prompt_kwargs={\n        \"system_prompt\": system_prompt,\n        \"few_shot_demos\": _few_shot_demos,\n    },\n    output_processors=parse_integer_answer,  # transform data field\n    use_cache=True,\n    demo_data_class=ObjectCountSimple,  # for output format\n    demo_data_class_input_mapping={\"question\": \"input_str\"},\n    demo_data_class_output_mapping={\"answer\": lambda x: x.raw_response},\n)\n```\n\n----------------------------------------\n\nTITLE: Using ListParser in AdalFlow\nDESCRIPTION: Demonstrates the ListParser which extracts and parses list content from text using both JSON and YAML parsing methods. It can extract lists containing strings, numbers, and even complex objects.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import ListParser\n\nlist_str = '[\"key\", \"value\"]'\nlist_str_2 = 'prefix[\"key\", 2]...'\nlist_str_3 = '[{\"key\": \"value\"}, {\"key\": \"value\"}]'\n\nparser = ListParser()\nprint(parser(list_str))\nprint(parser(list_str_2))\nprint(parser(list_str_3))\n```\n\n----------------------------------------\n\nTITLE: Initializing ObjectCountAdalComponent in Python\nDESCRIPTION: Defines the ObjectCountAdalComponent class, initializing task pipeline, evaluation function, and loss function. It sets up the necessary configurations for backward engine, teacher model, and text optimizer.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass ObjectCountAdalComponent(adal.AdalComponent):\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        backward_engine_model_config: Dict,\n        teacher_model_config: Dict,\n        text_optimizer_model_config: Dict,\n    ):\n        task = ObjectCountTaskPipeline(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        loss_fn = adal.EvalFnToTextLoss(\n            eval_fn=eval_fn,\n            eval_fn_desc=\"exact_match: 1 if str(y) == str(y_gt) else 0\",\n        )\n        super().__init__(task=task, eval_fn=eval_fn, loss_fn=loss_fn)\n\n        self.backward_engine_model_config = backward_engine_model_config\n        self.teacher_model_config = teacher_model_config\n        self.text_optimizer_model_config = text_optimizer_model_config\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Embedder in AdalFlow\nDESCRIPTION: Sets up an Embedder with OpenAI's embedding model. This code configures the Embedder with the text-embedding-3-small model, setting the dimensions to 256 and using float encoding format.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.components.model_client import OpenAIClient\nfrom adalflow.utils import setup_env # ensure you setup OPENAI_API_KEY in your project .env file\n\nsetup_env()\n\nmodel_kwargs = {\n    \"model\": \"text-embedding-3-small\",\n    \"dimensions\": 256,\n    \"encoding_format\": \"float\",\n}\n\nquery = \"What is LLM?\"\n\nqueries = [query] * 100\n\n\nembedder = Embedder(model_client=OpenAIClient(), model_kwargs=model_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Generating Signatures and Schema from Instance in Python\nDESCRIPTION: Shows how to create an instance of a BaseDataClass and generate JSON/YAML signatures and schema from it. This is useful for creating dynamic data representations based on specific instances.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/introduction_to_basedataclass.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom core.base_data_class import BaseDataClass\nfrom dataclasses import dataclass, field\n# Define a dataclass\n@dataclass\nclass MyOutputs(BaseDataClass):\n    age: int = field(metadata={\"desc\": \"The age of the person\", \"prefix\": \"Age:\"})\n    name: str = field(metadata={\"desc\": \"The name of the person\", \"prefix\": \"Name:\"})\n\nmy_instance = MyOutputs(age=25, name=\"John Doe\")\n# my_instance json signiture\nprint(my_instance.to_json_signature())\n# my_instance yaml signiture\nprint(my_instance.to_yaml_signature())\n# my_instance schema\nprint(my_instance.get_data_class_schema())\n```\n\n----------------------------------------\n\nTITLE: Initializing FAISS Retriever for Relevant Conversation Retrieval\nDESCRIPTION: Sets up a FAISS retriever to find the most relevant parts of the conversation history when the chat history becomes too long.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.retriever.faiss_retriever import FAISSRetriever\n\nretriever = FAISSRetriever(top_k=3, embedder=embedder)\n```\n\nLANGUAGE: python\nCODE:\n```\ndialog_turn_db.transformed_items[key]\n```\n\n----------------------------------------\n\nTITLE: Instantiating and Testing ChatBotWithRouter in AdalFlow\nDESCRIPTION: Creates an instance of the ChatBotWithRouter class and demonstrates how to use it with a sample query. This snippet shows the practical application of the single task approach.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/intermediate.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Initiate the task component, and print the task details.\n\ntask = ChatBotWithRouter()\ntask\n```\n\nLANGUAGE: python\nCODE:\n```\n# Call the task with a query\n\nquery = \"I have a legal question\"\nprint(task(query))\n```\n\n----------------------------------------\n\nTITLE: Retrieving Context and Generating Answers\nDESCRIPTION: Processes each dataset sample to retrieve context and generate answers, storing results for evaluation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/eval_a_rag.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nall_questions = []\nall_retrieved_context = []\nall_gt_context = []\nall_pred_answer = []\nall_gt_answer = []\nfor data in dataset:\n    # following the previous code snippet\n    query = data[\"question\"]\n    response, context_str = rag.call(query)\n    gt_context_sentence_list = get_supporting_sentences(\n        data[\"supporting_facts\"], data[\"context\"]\n    )\n    all_questions.append(query)\n    all_retrieved_context.append(context_str)\n    all_gt_context.append(gt_context_sentence_list)\n    all_pred_answer.append(response[\"answer\"])\n    all_gt_answer.append(data[\"answer\"])\n    print(f\"query: {query}\")\n    print(f\"response: {response['answer']}\")\n    print(f\"ground truth response: {data['answer']}\")\n    print(f\"context_str: {context_str}\")\n    print(f\"ground truth context_str: {gt_context_sentence_list}\")\n```\n\n----------------------------------------\n\nTITLE: Visualizing Pipeline Structure in Python\nDESCRIPTION: Demonstrates how to print the pipeline structure using the 'print(qa)' command, showing the components of the QA pipeline including the generator, prompt, model client, and output processors.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/README.md#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nQA(\n  (generator): Generator(\n    model_kwargs={'model': 'llama3-8b-8192'},\n    (prompt): Prompt(\n      template: <SYS>\n      You are a helpful assistant.\n      <OUTPUT_FORMAT>\n      {{output_format_str}}\n      </OUTPUT_FORMAT>\n      </SYS>\n      User: {{input_str}}\n      You:, prompt_kwargs: {'output_format_str': 'Your output should be formatted as a standard JSON instance with the following schema:\\n```\\n{\\n    \"explanation\": \"A brief explanation of the concept in one sentence. (str) (required)\",\\n    \"example\": \"An example of the concept in a sentence. (str) (required)\"\\n}\\n```\\n-Make sure to always enclose the JSON output in triple backticks (```). Please do not add anything other than valid JSON output!\\n-Use double quotes for the keys and string values.\\n-Follow the JSON formatting conventions.'}, prompt_variables: ['output_format_str', 'input_str']\n    )\n    (model_client): GroqAPIClient()\n    (output_processors): JsonOutputParser(\n      data_class=QAOutput, examples=None, exclude_fields=None, return_data_class=True\n      (json_output_format_prompt): Prompt(\n        template: Your output should be formatted as a standard JSON instance with the following schema:\n        ```\n        {{schema}}\n        ```\n        {% if example %}\n        Examples:\n        ```\n        {{example}}\n        ```\n        {% endif %}\n        -Make sure to always enclose the JSON output in triple backticks (```). Please do not add anything other than valid JSON output!\n        -Use double quotes for the keys and string values.\n        -Follow the JSON formatting conventions., prompt_variables: ['schema', 'example']\n      )\n      (output_processors): JsonParser()\n    )\n  )\n)\n```\n\n----------------------------------------\n\nTITLE: Executing Function Calls with Different Queries\nDESCRIPTION: Demonstrates the execution of function calls for various queries, including error handling and result processing.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_function_calls.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nqueries = [\n    \"add 2 and 3\",\n    \"search for something\",\n    \"add points (1, 2) and (3, 4)\",\n    \"sum numpy array with arr = np.array([[1, 2], [3, 4]])\",\n    \"multiply 2 with local variable x\",\n    \"divide 2 by 3\",\n    \"Add 5 to variable y\",\n]\n\nfor idx, query in enumerate(queries):\n    prompt_kwargs = {\"input_str\": query}\n    print(f\"\\n{idx} Query: {query}\")\n    print(f\"{'-'*50}\")\n    try:\n        result = generator(prompt_kwargs=prompt_kwargs)\n        # print(f\"LLM raw output: {result.raw_response}\")\n        func = Function.from_dict(result.data)\n        print(f\"Function: {func}\")\n        func_output = tool_manager.execute_func(func)\n        print(f\"Function output: {func_output}\")\n    except Exception as e:\n        print(\n            f\"Failed to execute the function for query: {query}, func: {result.data}, error: {e}\"\n        )\n```\n\n----------------------------------------\n\nTITLE: Viewing Documents in RAG Database\nDESCRIPTION: This code snippet demonstrates how to view all documents stored in the RAG system's database, displaying their IDs, titles, and the beginning of their text content.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# View all documents in the database\nprint(\"All documents in the database:\")\nfor item in rag.db.items:\n    print(\n        f\"ID: {item.id}, Title: {item.meta_data['title']}, Text: {item.text[:100]}...\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Initializing AdalFlow Trainer for Object Counting\nDESCRIPTION: This snippet shows the initialization of an AdalFlow trainer for an object counting task. It sets up the trainer with specific parameters and prepares datasets for training, validation, and testing.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntrainer = adal.Trainer(adaltask=adal_component)\ntrainer.diagnose(dataset=trainset, split=\"train\")\ntrainer.diagnose(dataset=valset, split=\"val\")\ntrainer.diagnose(dataset=testset, split=\"test\")\n```\n\n----------------------------------------\n\nTITLE: Using OpenAI Client for LLM and Embedding Models in Python\nDESCRIPTION: Demonstrates how to initialize and use OpenAIClient for both text completion using GPT-3.5-turbo and generating embeddings using text-embedding-3-small. Shows the complete workflow including input preparation, API call conversion, and response parsing for both model types.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/model_client.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client import OpenAIClient\nfrom adalflow.core.types import ModelType\n\nopenai_client = OpenAIClient()\n\nquery = \"What is the capital of France?\"\n\n# try LLM model\nmodel_type = ModelType.LLM\n\nprompt = f\"User: {query}\\n\"\nmodel_kwargs = {\"model\": \"gpt-3.5-turbo\", \"temperature\": 0.5, \"max_tokens\": 100}\napi_kwargs = openai_client.convert_inputs_to_api_kwargs(\n    input=prompt, model_kwargs=model_kwargs, model_type=model_type\n)\nprint(f\"api_kwargs: {api_kwargs}\")\n\nresponse = openai_client.call(api_kwargs=api_kwargs, model_type=model_type)\nresponse_text = openai_client.parse_chat_completion(response)\nprint(f\"response_text: {response_text}\")\n\n# try embedding model\nmodel_type = ModelType.EMBEDDER\n# do batch embedding\ninput = [query] * 2\nmodel_kwargs = {\n    \"model\": \"text-embedding-3-small\",\n    \"dimensions\": 8,\n    \"encoding_format\": \"float\",\n}\napi_kwargs = openai_client.convert_inputs_to_api_kwargs(\n    input=input, model_kwargs=model_kwargs, model_type=model_type\n)\nprint(f\"api_kwargs: {api_kwargs}\")\n\n\nresponse = openai_client.call(api_kwargs=api_kwargs, model_type=model_type)\nreponse_embedder_output = openai_client.parse_embedding_response(response)\nprint(f\"reponse_embedder_output: {reponse_embedder_output}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Function Call End-to-End\nDESCRIPTION: Sets up a template for function calls, creates a Prompt object, and demonstrates the use of different output formats for function calls.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_function_calls.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntemplate = r\"\"\"<SYS>You have these tools available:\n{% if tools %}\n<TOOLS>\n{% for tool in tools %}\n{{ loop.index }}.\n{{tool}}\n------------------------\n{% endfor %}\n</TOOLS>\n{% endif %}\n<OUTPUT_FORMAT>\n{{output_format_str}}\n</OUTPUT_FORMAT>\n</SYS>\nUser: {{input_str}}\nYou:\n\"\"\"\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.prompt_builder import Prompt\n\nprompt = Prompt(template=template)\nsmall_tool_manager = ToolManager(tools=tools[:2])\n\nrenered_prompt = prompt(tools=small_tool_manager.yaml_definitions)\nprint(renered_prompt)\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import Function\n\noutput_data_class = Function\noutput_format_str = output_data_class.to_json_signature(exclude=[\"thought\", \"args\"])\n\nrenered_prompt = prompt(output_format_str=output_format_str)\nprint(renered_prompt)\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import FunctionExpression\n\noutput_data_class = FunctionExpression\noutput_format_str = output_data_class.to_json_signature(exclude=[\"thought\"])\nprint(prompt(output_format_str=output_format_str))\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.output_parsers import JsonOutputParser\n\nfunc_parser = JsonOutputParser(data_class=Function, exclude_fields=[\"thought\", \"args\"])\ninstructions = func_parser.format_instructions()\nprint(instructions)\n```\n\n----------------------------------------\n\nTITLE: LLM Function Call Template in Python\nDESCRIPTION: Defines a template for LLM function calls using Jinja-style formatting.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntemplate = r\"\"\"<START_OF_SYS_PROMPT>You have these tools available:\n{% if tools %}\n<TOOLS>\n{% for tool in tools %}\n{{ loop.index }}.\n{{tool}}\n------------------------\n{% endfor %}\n</TOOLS>\n{% endif %}\n<OUTPUT_FORMAT>\n{{output_format_str}}\n</OUTPUT_FORMAT>\n<END_OF_SYS_PROMPT>\n<START_OF_USER>: {{input_str}}<END_OF_USER>\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Output Processor in Python\nDESCRIPTION: Defines a custom output processor to decrease embedding dimension and optionally normalize the vectors.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/embedder.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import Embedding, EmbedderOutput\nfrom adalflow.core.functional import normalize_vector\nfrom typing import List\nfrom adalflow.core.component import Component\nfrom copy import deepcopy\n\nclass DecreaseEmbeddingDim(Component):\n    def __init__(self, old_dim: int, new_dim: int,  normalize: bool = True):\n        super().__init__()\n        self.old_dim = old_dim\n        self.new_dim = new_dim\n        self.normalize = normalize\n        assert self.new_dim < self.old_dim, \"new_dim should be less than old_dim\"\n\n    def call(self, input: List[Embedding]) -> List[Embedding]:\n        output: EmbedderOutput = deepcopy(input)\n        for embedding in output.data:\n            old_embedding = embedding.embedding\n            new_embedding = old_embedding[: self.new_dim]\n            if self.normalize:\n                new_embedding = normalize_vector(new_embedding)\n            embedding.embedding = new_embedding\n        return output.data\n\n    def _extra_repr(self) -> str:\n        repr_str = f\"old_dim={self.old_dim}, new_dim={self.new_dim}, normalize={self.normalize}\"\n        return repr_str\n```\n\n----------------------------------------\n\nTITLE: Implementing Classical Text Metrics\nDESCRIPTION: Functions to compute ROUGE and BLEU scores for text comparison using TorchMetrics.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef compute_rouge(gt, pred):\n    r\"\"\"\n    https://lightning.ai/docs/torchmetrics/stable/text/rouge_score.html\n    \"\"\"\n    from torchmetrics.text.rouge import ROUGEScore\n\n    rouge = ROUGEScore()\n    return rouge(pred, gt)\n\n\ndef compute_bleu(gt, pred):\n    r\"\"\"\n    https://lightning.ai/docs/torchmetrics/stable/text/bleu_score.html\n    \"\"\"\n    from torchmetrics.text.bleu import BLEUScore\n\n    bleu = BLEUScore()\n    return bleu([pred], [[gt]])\n```\n\n----------------------------------------\n\nTITLE: Applying Data Transformations to DialogTurns and Documents\nDESCRIPTION: Demonstrates the application of the data pipeline to transform dialog turns and documents into embedded representations.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# apply data transformation to the dialog_turns\n\ndialog_turns_as_documents = [map_dialogturn_to_document(turn) for turn in dialog_turns]\nprint(dialog_turns_as_documents)\n\n# apply data transformation to the documents\noutput = data_transformer(dialog_turns_as_documents)\nprint(output)\n```\n\nLANGUAGE: python\nCODE:\n```\n# apply data transformation to the documents\norg_documents_as_documents = [map_to_document(doc) for doc in org_documents]\n\n# apply data transformation to the documents\noutput = data_transformer(org_documents_as_documents)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Defining a Few-Shot Template for Question Answering\nDESCRIPTION: Template for few-shot prompting that includes a system prompt, optional examples, and the input question.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfew_shot_template = r\"\"\"<START_OF_SYSTEM_PROMPT>\n{{system_prompt}}\n{# Few shot demos #}\n{% if few_shot_demos is not none %}\nHere are some examples:\n{{few_shot_demos}}\n{% endif %}\n<END_OF_SYSTEM_PROMPT>\n<START_OF_USER>\n{{input_str}}\n<END_OF_USER>\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Classification Pipeline Implementation\nDESCRIPTION: Implementation of a classification pipeline with structured output parsing\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntemplate = r\"\"\"<START_OF_SYSTEM_PROMPT>;\n{{system_prompt}}\n{% if output_format_str is not none %}\n{{output_format_str}}\n{% endif %}\n<END_OF_SYSTEM_PROMPT>\n<START_OF_USER>\n{{input_str}}\n<END_OF_USER>\"\"\"\n\ntask_desc_template = r\"\"\"You are a classifier. Given a question, you need to classify it into one of the following classes:\nFormat: class_index. class_name, class_description\n{% if classes %}\n{% for class in classes %}\n{{loop.index-1}}. {{class.label}}, {{class.desc}}\n{% endfor %}\n{% endif %}\n- Do not try to answer the question.\"\"\"\n\n@dataclass\nclass TRECExtendedData(adal.DataClass):\n   question: str = field(\n      metadata={\"desc\": \"The question to be classified\"}, default=None)\n   rationale: str = field(\n      metadata={\n            \"desc\": \"Your step-by-step reasoning to classify the question to class_name\"\n      }, default=None)\n   class_name: Literal[\"ABBR\", \"ENTY\", \"DESC\", \"HUM\", \"LOC\", \"NUM\"] = field(\n      metadata={\"desc\": \"The class name\"}, default=None)\n\n   __input_fields__ = [\"question\"]\n   __output_fields__ = [\"rationale\", \"class_name\"]\n\n\nclass TRECClassifierStructuredOutput(adal.Component):\n   def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n      super().__init__()\n      label_desc = [\n            {\"label\": label, \"desc\": desc}\n            for label, desc in zip(_COARSE_LABELS, _COARSE_LABELS_DESC)\n      ]\n      task_desc_str = adal.Prompt(\n            template=task_desc_template, prompt_kwargs={\"classes\": label_desc}\n      )()\n      parser = adal.DataClassParser(\n            data_class=TRECExtendedData, return_data_class=True, format_type=\"yaml\"\n      )\n      prompt_kwargs = {\n            \"system_prompt\": adal.Parameter(\n               data=task_desc_str,\n               role_desc=\"Task description\",\n               requires_opt=True,\n               param_type=adal.ParameterType.PROMPT,\n            ),\n            \"output_format_str\": parser.get_output_format_str(),\n      }\n      self.llm = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            prompt_kwargs=prompt_kwargs,\n            template=template,\n            output_processors=self.parser,\n      )\n\n   def bicall(\n      self, question: str, id: Optional[str] = None\n   ) -> Union[adal.GeneratorOutput, adal.Parameter]:\n      output = self.llm(prompt_kwargs={\"input_str\": question}, id=id)\n      return output\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Generation with Generator in Python\nDESCRIPTION: This example shows how to use the Generator class for image generation tasks using DALL-E models, including image creation, editing, and variation generation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow import Generator\nfrom adalflow.core.types import ModelType\n\nclass ImageGenerator(Generator):\n    \"\"\"Generator subclass for image generation.\"\"\"\n    model_type = ModelType.IMAGE_GENERATION\n\nfrom adalflow import OpenAIClient\n\ngenerator = ImageGenerator(\n    model_client=OpenAIClient(),\n    model_kwargs={\n        \"model\": \"dall-e-3\",  # or \"dall-e-2\"\n        \"size\": \"1024x1024\",  # \"1024x1024\", \"1024x1792\", or \"1792x1024\" for DALL-E 3\n        \"quality\": \"standard\",  # \"standard\" or \"hd\" (DALL-E 3 only)\n        \"n\": 1  # Number of images (1 for DALL-E 3, 1-10 for DALL-E 2)\n    }\n)\n\n# Generate an image from text\nresponse = generator(\n    prompt_kwargs={\"input_str\": \"A white siamese cat in a space suit\"}\n)\n# response.data will contain the image URL\n\n# Edit an existing image\nresponse = generator(\n    prompt_kwargs={\"input_str\": \"Add a red hat\"},\n    model_kwargs={\n        \"model\": \"dall-e-2\",\n        \"image\": \"path/to/cat.png\",  # Original image\n        \"mask\": \"path/to/mask.png\"   # Optional mask showing where to edit\n    }\n)\n\n# Create variations of an image\nresponse = generator(\n    prompt_kwargs={\"input_str\": None},  # Not needed for variations\n    model_kwargs={\n        \"model\": \"dall-e-2\",\n        \"image\": \"path/to/cat.png\"  # Image to create variations of\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Default Prompt Template Arguments\nDESCRIPTION: Lists the default prompt arguments that AdalFlow uses in its system prompt template. These variables cover various aspects of LLM interactions including task description, tools, examples, and user input.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/prompt.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nADALFLOW_DEFAULT_PROMPT_ARGS = [\n   \"task_desc_str\",  # task description\n   \"output_format_str\",  # output format of the task\n   \"tools_str\",  # tools used in the task\n   \"examples_str\",  # examples of the task\n   \"chat_history_str\",  # chat history of the user\n   \"context_str\",  # context of the user query\n   \"steps_str\",  # used in agent steps\n   \"input_str\",  # user query or input\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring Anthropic Client\nDESCRIPTION: Example showing how to set up and use Anthropic's Claude models with AdalFlow. Requires ANTHROPIC_API_KEY to be set in environment variables.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/installation.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\n\n# setup env or pass the api_key to client\nfrom adalflow.utils import setup_env\n\nsetup_env()\n\nanthropic_llm = adal.Generator(\n   model_client=adal.AnthropicAPIClient(), model_kwargs={\"model\": \"claude-3-opus-20240229\"}\n)\nresopnse = anthropic_llm(prompt_kwargs={\"input_str\": \"What is LLM?\"})\n```\n\n----------------------------------------\n\nTITLE: Initializing Data Structures for Renewable Energy Conversation\nDESCRIPTION: Sets up initial data structures for a conversation about renewable energy, including sample queries, documents, and dialog turns.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# setup data needed for the notes\nquery_1 = \"What are the benefits of renewable energy?\"  # gt is [0, 3]\nquery_2 = \"How do solar panels impact the environment?\"  # gt is [1, 2]\n\norg_documents = [\n    {\n        \"title\": \"The Impact of Renewable Energy on the Economy\",\n        \"content\": \"Renewable energy technologies not only help in reducing greenhouse gas emissions but also contribute significantly to the economy by creating jobs in the manufacturing and installation sectors. The growth in renewable energy usage boosts local economies through increased investment in technology and infrastructure.\",\n    },\n    {\n        \"title\": \"Understanding Solar Panels\",\n        \"content\": \"Solar panels convert sunlight into electricity by allowing photons, or light particles, to knock electrons free from atoms, generating a flow of electricity. Solar panels are a type of renewable energy technology that has been found to have a significant positive effect on the environment by reducing the reliance on fossil fuels.\",\n    },\n    {\n        \"title\": \"Pros and Cons of Solar Energy\",\n        \"content\": \"While solar energy offers substantial environmental benefits, such as reducing carbon footprints and pollution, it also has downsides. The production of solar panels can lead to hazardous waste, and large solar farms require significant land, which can disrupt local ecosystems.\",\n    },\n    {\n        \"title\": \"Renewable Energy and Its Effects\",\n        \"content\": \"Renewable energy sources like wind, solar, and hydro power play a crucial role in combating climate change. They do not produce greenhouse gases during operation, making them essential for sustainable development. However, the initial setup and material sourcing for these technologies can still have environmental impacts.\",\n    },\n]\n\nturns = [\n    {\n        \"user\": \"What are the benefits of renewable energy?\",\n        \"system\": \"I can see you are interested in renewable energy. Renewable energy technologies not only help in reducing greenhouse gas emissions but also contribute significantly to the economy by creating jobs in the manufacturing and installation sectors. The growth in renewable energy usage boosts local economies through increased investment in technology and infrastructure.\",\n        \"user_time\": \"2021-09-01T12:00:00Z\",\n        \"system_time\": \"2021-09-01T12:00:01Z\",\n    },\n    {\n        \"user\": \"How do solar panels impact the environment?\",\n        \"system\": \"Solar panels convert sunlight into electricity by allowing photons, or light particles, to knock electrons free from atoms, generating a flow of electricity. Solar panels are a type of renewable energy technology that has been found to have a significant positive effect on the environment by reducing the reliance on fossil fuels.\",\n        \"user_time\": \"2021-09-01T12:00:02Z\",\n        \"system_time\": \"2021-09-01T12:00:03Z\",\n    },\n]\n```\n\n----------------------------------------\n\nTITLE: JSON and YAML Serialization/Deserialization of Custom DataClass\nDESCRIPTION: This snippet shows how to serialize and deserialize custom DataClass objects to and from JSON and YAML formats. It demonstrates round-trip conversion and equality checking.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\njson_str = example.to_json()\nprint(json_str)\n\nyaml_str = example.to_yaml()\nprint(yaml_str)\n\nreconstructed_from_json = TrecData2.from_json(json_str)\nprint(reconstructed_from_json)\nprint(reconstructed_from_json == example)\n\nreconstructed_from_yaml = TrecData2.from_yaml(yaml_str)\nprint(reconstructed_from_yaml)\nprint(reconstructed_from_yaml == example)\n```\n\n----------------------------------------\n\nTITLE: Implementing BERTScore Metric\nDESCRIPTION: Function to compute BERTScore using pre-trained contextual embeddings for text similarity evaluation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef compute_bertscore(gt, pred):\n    r\"\"\"\n    https://lightning.ai/docs/torchmetrics/stable/text/bert_score.html\n    \"\"\"\n    from torchmetrics.text.bert import BERTScore\n\n    bertscore = BERTScore()\n    return bertscore([pred], [gt])\n```\n\n----------------------------------------\n\nTITLE: Preparing Examples for ReAct Agent in Python\nDESCRIPTION: This snippet defines a list of examples for few-shot prompt engineering to improve model performance. Each example contains a question, thoughts, actions, and observations in a structured format.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nexamples = [\n    \"\"\"Question: What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\nThought 1: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\nAction 1: search(\"Colorado orogeny\")\nObservation 1: The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\nThought 2: It does not mention the eastern sector. So I need to look up eastern sector.\nAction 2: lookup(\"eastern sector\")\nObservation 2: (Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny.\nThought 3: The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\nAction 3: search(\"High Plains\")\nObservation 3: High Plains refers to one of two distinct land regions:\nThought 4: I need to instead search High Plains (United States).\nAction 4: search(\"High Plains (United States)\")\nObservation 4: The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).[3]\nThought 5: High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\nAction 5: finish(\"1,800 to 7,000 ft\")\"\"\",\n    # ... [other examples omitted for brevity]\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Generator with Groq Client in Python\nDESCRIPTION: This code creates a custom Generator using a Groq API client. It defines a custom template for few-shot learning and demonstrates how to use it for a specific task of counting objects.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/generator.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\n\n# the template has three variables: system_prompt, few_shot_demos, and input_str\nfew_shot_template = r\"\"\"<START_OF_SYSTEM_PROMPT>\n{{system_prompt}}\n{# Few shot demos #}\n{% if few_shot_demos is not none %}\nHere are some examples:\n{{few_shot_demos}}\n{% endif %}\n<END_OF_SYSTEM_PROMPT>\n<START_OF_USER>\n{{input_str}}\n<END_OF_USER>\n\"\"\"\n\nobject_counter = Generator(\n    model_client=adal.GroqAPIClient(),\n    model_kwargs={\n        \"model\": \"llama3-8b-8192\",\n    },\n    template=few_shot_template,\n    prompt_kwargs={\n        \"system_prompt\": \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n    }\n)\n\nquestion = \"I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?\"\nresponse = object_counter(prompt_kwargs={\"input_str\": question})\nprint(response)\n\nprompt = object_counter.print_prompt(input_str=question)\nprint(prompt)\n```\n\n----------------------------------------\n\nTITLE: Defining a DataClass for Output Parsing in Python\nDESCRIPTION: Creates a simple User DataClass with id and name fields, which will be used to demonstrate JSON and YAML output parsing.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass, field\nfrom adalflow.core import DataClass\n\n@dataclass\nclass User(DataClass):\n    id: int = field(default=1, metadata={\"description\": \"User ID\"})\n    name: str = field(default=\"John\", metadata={\"description\": \"User name\"})\n\nuser_example = User(id=1, name=\"John\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Generator State Tracing in Python\nDESCRIPTION: Shows how to use the trace_generator_states decorator to automatically track any Generator attributes in a Component class. This tracing helps developers keep a history of prompt changes during development.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging_tracing.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.tracing import trace_generator_states\nfrom adalflow.core import Component, Generator\n\n@trace_generator_states()\nclass SimpleQA(Component):\n    def __init__(self):\n        super().__init__()\n        self.generator = Generator(...)\n        self.generator_2 = Generator(...)\n    def call(...):\n```\n\n----------------------------------------\n\nTITLE: Using YamlParser in AdalFlow\nDESCRIPTION: Demonstrates the YamlParser which extracts and parses YAML content from text. It handles dictionary structures, nested dictionaries, and lists in YAML format.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import YamlParser\n\nyaml_dict_str = \"key: value\"\nyaml_nested_dict_str = (\n    \"name: John\\nage: 30\\nattributes:\\n  height: 180\\n  weight: 70\"\n)\nyaml_list_str = \"- key\\n- value\"\n\nparser = YamlParser()\nprint(parser)\nprint(parser(yaml_dict_str))\nprint(parser(yaml_nested_dict_str))\nprint(parser(yaml_list_str))\n```\n\n----------------------------------------\n\nTITLE: Building Document List from Dataset\nDESCRIPTION: Creates a list of Document objects from the dataset context, with each document containing a title and sentences.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/eval_a_rag.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfor data in dataset:\n    num_docs = len(data[\"context\"][\"title\"])\n    doc_list = [\n        Document(\n            meta_data={\"title\": data[\"context\"][\"title\"][i]},\n            text=\" \".join(data[\"context\"][\"sentences\"][i]),\n        )\n        for i in range(num_docs)\n    ]\n```\n\n----------------------------------------\n\nTITLE: Customizing Separators for Question-based Splitting in Python\nDESCRIPTION: This snippet demonstrates how to customize the SEPARATORS dictionary to split text based on question marks. It's useful for processing text structured as a series of questions.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/text_splitter.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nSEPARATORS = {\"question\": \"?\"}\nsplit_by = \"question\"\n```\n\n----------------------------------------\n\nTITLE: Initializing DataClassParser in Python\nDESCRIPTION: Creates a new DataClassParser instance configured to work with a specific data class, setting JSON as the format type and enabling direct data class return.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.output_parsers import DataClassParser\n\nparser = DataClassParser(data_class=SampleDataClass, return_data_class=True, format_type=\"json\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Detailed Song Review DataClass in Python\nDESCRIPTION: Creates a nested data class that combines basic review, cast list, genre information and recommendation status.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass DetailedSongReview(adal.DataClass):\n    basic_review: SongReview = field(\n        default=SongReview, metadata={\"desc\": \"basic Song review details\"}\n    )\n    cast: List[Artist] = field(\n        default_factory=list,\n        metadata={\"desc\": \"List of main singer, lyrisist and musicians in the song\"},\n    )\n    genre: List[str] = field(\n        default_factory=list, metadata={\"desc\": \"List of genres for the song\"}\n    )\n    recommend: bool = field(\n        default_factory=str, metadata={\"desc\": \"Whether you would recommend this song\"}\n    )\n\n    __output_fields__ = [\"basic_review\", \"cast\", \"genre\", \"recommend\"]\n```\n\n----------------------------------------\n\nTITLE: Implementing FunctionExpression with Additional Context in Python\nDESCRIPTION: This snippet shows how to use FunctionExpression with additional context for handling local variables and numpy arrays. It includes setting up the ToolManager with additional context and updating the parser.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntool_manager = ToolManager(\n    tools=functions,\n    additional_context={\"x\": x, \"y\": 0, \"np.array\": np.array, \"np\": np},\n)\nfunc_parser = JsonOutputParser(data_class=FunctionExpression)\n```\n\n----------------------------------------\n\nTITLE: Defining Question Example in Python\nDESCRIPTION: This snippet defines an example question for the object counting task.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nquestion = \"I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Component for Multi-Task Approach in AdalFlow\nDESCRIPTION: Defines a Chat class that handles different types of queries based on the router's choice. It uses different models for doctor and lawyer roles and is designed to work with the Router component in a Sequential container.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/intermediate.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# the second chat component with two generators\n\n\nclass Chat(Component):\n    def __init__(self):\n        super().__init__()\n        self.doc = Generator(\n            template=template_doc,\n            model_client=OpenAIClient(),\n            model_kwargs={\"model\": \"gpt-3.5-turbo\"},\n        )\n        self.lawyer = Generator(\n            template=template_law,\n            model_client=GroqAPIClient(),\n            model_kwargs={\"model\": \"llama3-8b-8192\"},\n        )\n\n    # to chain together just to make sure the output can be directly passed to the next as input\n    def call(self, input: Dict[str, str]) -> Dict[str, str]:\n        choice = input.get(\"choice\", None)\n        query = input.get(\"query\", None)\n        if choice == \"doctor\":\n            return self.doc(prompt_kwargs={\"input_str\": query}).data\n        elif choice == \"lawyer\":\n            return self.lawyer(prompt_kwargs={\"input_str\": query}).data\n        else:\n            return \"Sorry, I am not able to help you with that.\"\n```\n\nLANGUAGE: python\nCODE:\n```\nchat = Chat()\nchat\n```\n\n----------------------------------------\n\nTITLE: Embedding Generation for FAISS Retriever\nDESCRIPTION: Code for generating document embeddings using OpenAI's text embedding model for use with FAISS retriever.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.core.types import ModelClientType\n\n\nmodel_kwargs = {\n    \"model\": \"text-embedding-3-small\",\n    \"dimensions\": 256,\n    \"encoding_format\": \"float\",\n}\n\nembedder = Embedder(model_client =ModelClientType.OPENAI(), model_kwargs=model_kwargs)\noutput = embedder(input=[doc[\"content\"] for doc in documents])\ndocuments_embeddings = [x.embedding for x in output.data]\n```\n\n----------------------------------------\n\nTITLE: Defining Document Types in Python for Retrievers\nDESCRIPTION: Type definitions for document objects used by retrievers, allowing for flexible document formats while maintaining type safety across the retriever framework.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nRetrieverDocumentType = TypeVar(\"RetrieverDocumentType\", contravariant=True) # a single document\nRetrieverDocumentsType = Sequence[RetrieverDocumentType] # The final documents types retriever can use\n```\n\n----------------------------------------\n\nTITLE: Executing Function Queries with AdalFlow in Python\nDESCRIPTION: This snippet demonstrates how to run queries using the configured Generator and ToolManager. It processes a list of queries, generates function calls, and executes them using the ToolManager.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nqueries = [\n    \"add 2 and 3\",\n    \"search for something\",\n    \"add points (1, 2) and (3, 4)\",\n    \"sum numpy array with arr = np.array([[1, 2], [3, 4]])\",\n    \"multiply 2 with local variable x\",\n    \"divide 2 by 3\",\n    \"Add 5 to variable y\",\n]\n\nfor idx, query in enumerate(queries):\n    prompt_kwargs = {\"input_str\": query}\n    print(f\"\\n{idx} Query: {query}\")\n    print(f\"{'-'*50}\")\n    try:\n        result = generator(prompt_kwargs=prompt_kwargs)\n        func = Function.from_dict(result.data)\n        print(f\"Function: {func}\")\n        func_output = tool_manager.execute_func(func)\n        print(f\"Function output: {func_output}\")\n    except Exception as e:\n        print(\n            f\"Failed to execute the function for query: {query}, func: {result.data}, error: {e}\"\n        )\n```\n\n----------------------------------------\n\nTITLE: Generating Example Strings from DataClass Instances\nDESCRIPTION: Shows how to create example strings from a list of sample data class instances using the parser's get_examples_str method.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nsamples = [\n    SampleDataClass(\n        description=\"Sample description\",\n        category=\"Sample category\",\n        value=100,\n        status=\"active\",\n    ),\n    SampleDataClass(\n        description=\"Another description\",\n        category=\"Another category\",\n        value=200,\n        status=\"inactive\",\n    ),\n]\n\nexamples_str = parser.get_examples_str(examples=samples)\nprint(examples_str)\n```\n\n----------------------------------------\n\nTITLE: Connecting Components in AdalFlow\nDESCRIPTION: Demonstrates how to connect the output of one component to the input of another in AdalFlow using successor_map_fn.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/auto_text_grad.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef foward(self, question: str, id: str = None) -> adal.Parameter:\n    retriever_out = self.retriever.forward(input=question)\n    successor_map_fn = lambda x: (\n        \"\\n\\n\".join(x.data[0].documents)\n        if x.data and x.data[0] and x.data[0].documents\n        else \"\"\n    )\n    retriever_out.add_successor_map_fn(successor=self.llm, map_fn=successor_map_fn)\n    generator_out = self.llm.forward(\n        prompt_kwargs={\"question\": question, \"context\": retriever_out}, id=id\n    )\n    return generator_out\n```\n\n----------------------------------------\n\nTITLE: Llama3 Input Prompt Format Example\nDESCRIPTION: Example showing the format of input prompt text for Llama3 model with special tokens for system and message delimitation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/prompt.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfinal_prompt = r\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n{{simple_prompt}} <|eot_id|>\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Function Output Format in Python\nDESCRIPTION: Shows how to configure the output format for LLM function calls using Function data type.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import Function\n\noutput_data_class = Function\noutput_format_str = output_data_class.to_json_signature(exclude=[\"thought\", \"args\"])\n\nrenered_prompt= prompt(output_format_str=output_format_str)\nprint(renered_prompt)\n```\n\n----------------------------------------\n\nTITLE: Using Output Processors with Generator in Python\nDESCRIPTION: This example demonstrates how to use the JsonParser output processor with the Generator to parse LLM responses into JSON format.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import Generator\nfrom adalflow.core.types import GeneratorOutput\nfrom adalflow.components.model_client import OpenAIClient\nfrom adalflow.core.string_parser import JsonParser\n\noutput_format_str = r\"\"\"Your output should be formatted as a standard JSON object with two keys:\n{\n    \"explanation\": \"A brief explanation of the concept in one sentence.\",\n    \"example\": \"An example of the concept in a sentence.\"\n}\n\"\"\"\n\ngenerator = Generator(\n    model_client=OpenAIClient(),\n    model_kwargs={\"model\": \"gpt-3.5-turbo\"},\n    prompt_kwargs={\"output_format_str\": output_format_str},\n    output_processors=JsonParser(),\n)\n\nprompt_kwargs = {\"input_str\": \"What is LLM?\"}\ngenerator.print_prompt(**prompt_kwargs)\n\noutput: GeneratorOutput = generator(prompt_kwargs=prompt_kwargs)\nprint(type(output.data))\nprint(output.data)\n```\n\n----------------------------------------\n\nTITLE: Configuring QdrantRetriever with Filters in Python\nDESCRIPTION: This code shows how to add filters to a QdrantRetriever to refine search results based on specific criteria. The example demonstrates filtering by document category and weight using Qdrant's filtering capabilities.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom qdrant_client import models\n\nqdrant_retriever = QdrantRetriever(\n    collection_name=\"{collection_name}\",\n    client=client,\n    embedder=embedder,\n    text_key=\"content\",\n    filter=models.Filter(\n        must=[\n            models.FieldCondition(\n                key=\"category\",\n                match=models.MatchValue(value=\"facts\"),\n            ),\n            models.FieldCondition(\n                key=\"weight\",\n                range=models.Range(gte=0.98),\n            ),\n        ]\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Using Default Prompt Template with Minimal Arguments\nDESCRIPTION: Demonstrates using the AdalFlow Prompt class with only the required input_str argument, showing how the system falls back to default templates when minimal information is provided.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/prompt.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprompt = Prompt()\noutput = prompt(input_str=input_str)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Computing Retriever Recall with AdalFlow\nDESCRIPTION: Example demonstrating how to use AdalFlow's RetrieverRecall class to evaluate retriever performance by comparing retrieved contexts against ground truth contexts. The metric calculates recall scores for multiple queries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.eval import RetrieverRecall, RetrieverRelevance\n\nretrieved_contexts = [\n    \"Apple is founded before Google.\",\n    \"Feburary has 28 days in common years. Feburary has 29 days in leap years. Feburary is the second month of the year.\",\n]\ngt_contexts = [\n    [\n        \"Apple is founded in 1976.\",\n        \"Google is founded in 1998.\",\n        \"Apple is founded before Google.\",\n    ],\n    [\"Feburary has 28 days in common years\", \"Feburary has 29 days in leap years\"],\n]\nretriever_recall = RetrieverRecall()\navg_recall, recall_list = retriever_recall.compute(retrieved_contexts, gt_contexts) # Compute the recall of the retriever\nprint(f\"Recall: {avg_recall}, Recall List: {recall_list}\")\n```\n\nLANGUAGE: json\nCODE:\n```\nRecall: 0.6666666666666666, Recall List: [0.3333333333333333, 1.0]\n```\n\n----------------------------------------\n\nTITLE: Listing Agent Design Patterns in Markdown\nDESCRIPTION: This snippet presents four main design patterns for AI agents: Reflection, Tool use, Planning, and Multi-agent collaboration, with examples for each pattern.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/adalflow/components/agent/README.md#2025-04-14_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n1️⃣ Reflection\n\n- Self-Refine: Iterative Refinement with Self-Feedback\n- Reflexion: Language Agents with Verbal Reinforcement Learning\n\n2️⃣ Tool use\n\n- Gorilla: Large Language Model Connected with Massive APIs\n- MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action\n\n3️⃣ Planning\n\n- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\n- HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face\n- React\n\n4️⃣ Multi-agent collaboration\n\n- Communicative Agents for Software Development\n- AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation\n```\n\n----------------------------------------\n\nTITLE: Executing QA Query\nDESCRIPTION: Demonstrates how to use the SimpleQA pipeline by sending a sample question and retrieving the response.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/question_answering/simple_qa.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nquery = \"What is the capital of France?\"\nresponse = simple_qa.call(query)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Executing Function Using Context Map in Python\nDESCRIPTION: Demonstrates how to create and use a context map for function execution using FunctionTool instances.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncontext_map = {tool.definition.func_name: tool for tool in tools}\n\nfunction_name = \"add\"\nfunction_to_call = context_map[function_name]\nfunction_args = {\"a\": 1, \"b\": 2}\nfunction_response = function_to_call.call(**function_args)\n```\n\n----------------------------------------\n\nTITLE: Building Sequential Pipeline\nDESCRIPTION: Example of creating a sequential pipeline combining query enhancement and doctor QA components\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_component.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import Sequential\n\n@func_to_component\ndef enhance_query(query: str) -> str:\n    return query + \"Please be concise and only list the top treatments.\"\n\nseq = Sequential(enhance_query, doc)\n\nquery = \"What is the best treatment for headache?\"\nprint(seq(query))\n```\n\n----------------------------------------\n\nTITLE: Configuring Root Logger for Both Library and Application Logs\nDESCRIPTION: Demonstrates how to configure a single root logger to capture both library and application logs in one file.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom adalflow.utils.logger import get_logger\n\nroot_logger = get_logger(level=\"DEBUG\", save_dir=\"./logs\") # log to ./logs/lib.log\n\n# run code from the library components such as generator\n# ....\n\nroot_logger.info(\"This is the log in the main file\")\n```\n\n----------------------------------------\n\nTITLE: Using OpenAI GPT with AdalFlow in Python\nDESCRIPTION: This snippet demonstrates how to use AdalFlow with OpenAI's GPT model. It sets up a Generator with an OpenAIClient, configures model parameters, and generates a response to a simple question. The code also enables logging for debugging purposes.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/generator.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import Generator\nfrom adalflow.components.model_client import OpenAIClient, get_probabilities\nfrom adalflow.utils import enable_library_logging\n\nenable_library_logging(level=\"DEBUG\")\n\nmodel_kwargs = {\n    \"model\": \"gpt-3.5-turbo\",\n    \"logprobs\": True,\n    \"n\": 2,  # the number of chat completion choices\n}\nmodel_client = OpenAIClient(chat_completion_parser=get_probabilities)\ngenerator = Generator(model_client=model_client, model_kwargs=model_kwargs)\n\n\nprompt_kwargs = {\n    \"input_str\": \"What is the capital of France?\",\n}\noutput = generator(prompt_kwargs=prompt_kwargs)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: AdalFlow Prompt Class Implementation\nDESCRIPTION: Shows how to use AdalFlow's Prompt component to render prompts with templates and keyword arguments. The Prompt class allows preset arguments at initialization and additional arguments when called.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/prompt.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.prompt_builder import Prompt\n\nprompt = Prompt(\n   template=template,\n   prompt_kwargs={\n      \"task_desc_str\": task_desc_str,\n      \"tools\": tools,\n   },\n)\nprint(prompt)\nprint(prompt(input_str=input_str)) # takes the rest arguments in keyword arguments\n```\n\n----------------------------------------\n\nTITLE: Connecting Components in LangGraph\nDESCRIPTION: Illustrates how to connect components in LangGraph using a GraphState and defined nodes for retriever and generation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/auto_text_grad.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass GraphState(BaseModel):\n\n    question: Optional[str] = None\n    generation: Optional[str] = None\n    documents: List[str] = []\n\ndef retriever_node(state: GraphState):\n    new_documents = retriever.invoke(state.question)\n    new_documents = [d.page_content for d in new_documents]\n    state.documents.extend(new_documents)\n    return {\"documents\": state.documents}\n\ndef generation_node(state: GraphState):\n    generation = rag_chain.invoke({\n        \"context\": \"\\n\\n\".join(state.documents),\n        \"question\": state.question,\n    })\n    return {\"generation\": generation}\n```\n\n----------------------------------------\n\nTITLE: Dataset Class Reference Structure\nDESCRIPTION: Conceptual structure showing the two main classes needed for dataset implementation: DataClass for defining data structure and Dataset for handling data loading and processing. Data is cached in ~/.adalflow/cached_datasets by default.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/datasets.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass DataClass:\n    # Define data structure\n    # - unique identifier\n    # - input fields\n    # - output fields for LLM calls\n    pass\n\nclass Dataset(utils.data.Dataset):\n    # Define:\n    # - data loading (local/cloud)\n    # - data splitting\n    # - conversion to DataClass\n    # - data preprocessing\n    pass\n```\n\n----------------------------------------\n\nTITLE: Configuring GPT-3.5-turbo Model Parameters in Python\nDESCRIPTION: This snippet sets up the configuration for the OpenAI GPT-3.5-turbo model, specifying the model name and setting the temperature to 0.0 for consistent responses.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ngpt_model_kwargs = {\n    \"model\": \"gpt-3.5-turbo\",\n    \"temperature\": 0.0,\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing BM25 Retrieval with Title and Content\nDESCRIPTION: Demonstrates BM25 retrieval implementation using both document title and content fields for improved accuracy. The code shows how combining fields can improve retrieval performance for keyword-based queries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nquery_1_short = \"renewable energy?\"  # gt is [0, 3]\nquery_2_short = \"solar panels?\"  # gt is [1, 2]\ndocument_map_func = lambda x: x[\"title\"] + \" \" + x[\"content\"]\nbm25_retriever.build_index_from_documents(documents=documents, document_map_func=document_map_func)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Client\nDESCRIPTION: Example showing how to set up and use OpenAI's language models with AdalFlow. Requires OPENAI_API_KEY to be set in environment variables.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/installation.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\n\n# setup env or pass the api_key to client\nfrom adalflow.utils import setup_env\n\nsetup_env()\n\nopenai_llm = adal.Generator(\n   model_client=adal.OpenAIClient(), model_kwargs={\"model\": \"gpt-3.5-turbo\"}\n)\nresopnse = openai_llm(prompt_kwargs={\"input_str\": \"What is LLM?\"})\n```\n\n----------------------------------------\n\nTITLE: Implementing Generator Callback Registration in Python\nDESCRIPTION: Code that sets up callback registration for generators in AdalComponent, configuring logging for each generator with file paths and completion callbacks.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/trainer.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfor name, generator in all_generators:\n    call_logger = GeneratorCallLogger(save_dir=save_dir)\n    call_logger.reset()\n    call_logger.register_generator(name)\n    logger_call = partial(call_logger.log_call, name)\n    generator.register_callback(\n        \"on_complete\", partial(_on_completion_callback, logger_call=logger_call)\n    )\n    file_path = call_logger.get_log_location(name)\n    file_paths.append(file_path)\n    log.debug(f\"Registered callback for {name}, file path: {file_path}\")\n```\n\n----------------------------------------\n\nTITLE: Creating Function Definition for OpenAI API in Python\nDESCRIPTION: Defines the function schema for the weather function to be used with OpenAI's function calling API. Specifies parameters and their types.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfunction_definition = {\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n                },\n                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n            },\n            \"required\": [\"location\"],\n        },\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Wikipedia Search and Lookup Tools\nDESCRIPTION: Defines utility functions for searching Wikipedia and performing text lookups, including string cleaning and answer normalization.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\nimport string\n\n\n# copy code from the paper\ndef clean_str(p):\n    return p.encode().decode(\"unicode-escape\").encode(\"latin1\").decode(\"utf-8\")\n\n\n# normalization copied from the paper's code\ndef normalize_answer(s):\n    def remove_articles(text):\n        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n\n    def white_space_fix(text):\n        return \" \".join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \"\".join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\n\ndef search(entity: str) -> str:\n    \"\"\"\n    searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n    \"\"\"\n    # Format the entity for URL encoding\n    entity_formatted = entity.replace(\" \", \"+\")\n    url = f\"https://en.wikipedia.org/w/index.php?search={entity_formatted}\"\n\n    # Fetch the page\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, \"html.parser\")\n\n    # Check if the exact page was found or suggest similar items\n    # when <div class=mw-search-result-heading> is detected, it means the entity page is not found on wikipedia\n    result_divs = soup.find_all(\"div\", {\"class\": \"mw-search-result-heading\"})\n\n    if (\n        result_divs\n    ):  # this means the searched entity page is not in wikipedia, wikipedia will show a list of similar entities\n        # get Similar results\n        similar_titles = [div.a.get_text() for div in result_divs]\n        return f\"Could not find exact page for '{entity}'. Similar topics: {similar_titles[:5]}\"  # return the top 5 similar titles\n    else:\n        # the paper uses page to represent content in <p>\n        # Extract xontent\n        page_list = [\n            p.get_text().strip() for p in soup.find_all(\"p\") + soup.find_all(\"ul\")\n        ]\n        # TODO: Recursive search, if find any concept that needs more search then call search again\n        # if any(\"may refer to:\" in p for p in page_list):\n        #     search(entity)\n\n        # restructure & clean the page content following the paper's logic\n        page = \"\"\n        for p in page_list:\n            if len(p.split(\" \")) > 2:\n                page += clean_str(p)\n                if not p.endswith(\"\\n\"):\n                    page += \"\\n\"\n        paragraphs = page.split(\"\\n\")\n        paragraphs = [p.strip() for p in paragraphs if p.strip()]\n\n        sentences = []\n        for p in paragraphs:\n            sentences += p.split(\". \")\n        sentences = [s.strip() + \".\" for s in sentences if s.strip()]\n\n        # return the first 5 sentences\n        if sentences:\n            return (\n                \" \".join(sentences[:5]) if len(sentences) >= 5 else \" \".join(sentences)\n            )\n        else:\n            return \"No content found on this page.\"\n\n        # TODO: clean the paragraphs and return the searched content\n\n\ndef lookup(text: str, keyword: str) -> str:\n    \"\"\"\n    returns the sentences containing keyword in the current passage.\n    \"\"\"\n    sentences = text.split(\".\")\n    matching_sentences = [\n        sentence.strip() + \".\"\n        for sentence in sentences\n        if keyword.lower() in sentence.lower()\n    ]\n    if not matching_sentences:\n        return \"No sentences found with the keyword.\"\n    else:\n        return \" \".join(\n            matching_sentences\n        )  # Join all matching sentences into a single string\n```\n\n----------------------------------------\n\nTITLE: Implementing Text Extraction Function with AdalFlow\nDESCRIPTION: This snippet defines a function to extract text enclosed in <think> tags and the following answer, using AdalFlow's func_to_data_component decorator. It demonstrates how to create custom data processing components in AdalFlow.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/adalflow_together_deepseek_r1.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\n\nfrom adalflow.components.model_client import TogetherClient\nimport re\n\n# parse the text as it starts with <think> and ends with </think>, then followed with the final answer\n\n\n@adal.func_to_data_component\ndef extract_think_and_answer(text: str) -> str:\n    \"\"\"\n    Extracts text enclosed between <think>...</think> as 'think'\n    and the text after </think> as 'answer'.\n\n    Returns:\n        dict: {\n            \"think\": <content within <think>...</think>>,\n            \"answer\": <content after </think>>\n        }\n        or None if no match is found.\n    \"\"\"\n\n    # Use DOTALL so '.' will match newlines as well\n    pattern = r\"<think>(.*?)</think>([\\s\\S]*)\"\n    match = re.search(pattern, text, re.DOTALL)\n\n    if match:\n        return {\"think\": match.group(1).strip(), \"answer\": match.group(2).strip()}\n    return None\n```\n\n----------------------------------------\n\nTITLE: Configuring GPT-3.5-Turbo with LLMRetriever in Python\nDESCRIPTION: This code snippet demonstrates how to configure and use an LLMRetriever with the gpt-3.5-turbo model to retrieve relevant documents without reinitializing the retriever. The example shows setting model parameters and executing queries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmodel_kwargs = {\n    \"model\": \"gpt-3.5-turbo\",\n}\noutput_1 = llm_retriever(model_kwargs=model_kwargs, input=query_1)\noutput_2 = llm_retriever(model_kwargs=model_kwargs, input=query_2)\n```\n\n----------------------------------------\n\nTITLE: Converting JSON String to DataClass Instance\nDESCRIPTION: Demonstrates how to parse a JSON string into a DataClass instance using a parser utility. The input JSON contains description, category, value and status fields.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nuser_input = '{\"description\": \"Parsed description\", \"category\": \"Sample Category\", \"value\": 100, \"status\": \"active\"}'\nparsed_instance = parser.call(user_input)\n\nprint(parsed_instance)\n```\n\n----------------------------------------\n\nTITLE: Groq Integration with AdalFlow\nDESCRIPTION: Configuration and usage of Groq's LLM service through AdalFlow framework\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\nfrom adalflow.utils import setup_env\n\nsetup_env()\n\ngroq_llm = adal.Generator(\n   model_client=adal.GroqAPIClient(), model_kwargs={\"model\": \"llama3-8b-8192\"}\n)\nresopnse = groq_llm(prompt_kwargs={\"input_str\": \"What is LLM?\"})\n```\n\n----------------------------------------\n\nTITLE: Formatting Input for Summary Evaluation\nDESCRIPTION: Prepares input text for evaluation by formatting source document and summary using a template structure. The example uses a news article about Paul Merson and Andros Townsend.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ninput_template = \"\"\"Source Document: {source}\nSummary: {summary}\n\"\"\"\n\ninput_str = input_template.format(\n    source=\"Paul Merson has restarted his row...\",\n    summary=\"Paul merson was brought on with only seven minutes...\"\n)\n```\n\n----------------------------------------\n\nTITLE: Initialize Logger and Build Embeddings Index\nDESCRIPTION: Sets up logging and builds an index from dialog turn embeddings for document retrieval\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.logger import get_logger\n\nget_logger()\n\nembeddings = [item.vector for item in dialog_turn_db.transformed_items[key]]\nprint(embeddings)\nretriever.build_index_from_documents(documents=embeddings)\n```\n\n----------------------------------------\n\nTITLE: Parsing Lists with ListParser in Python\nDESCRIPTION: Shows how to use ListParser to convert string representations of lists into Python list objects. It can handle simple lists, lists with prefixes, and lists of dictionaries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import ListParser\n\nlist_str = '[\"key\", \"value\"]'\nlist_str_2 = 'prefix[\"key\", 2]...'\nlist_str_3 = '[{\"key\": \"value\"}, {\"key\": \"value\"}]'\n\nparser = ListParser()\nprint(parser(list_str))\nprint(parser(list_str_2))\nprint(parser(list_str_3))\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Embedding Processing\nDESCRIPTION: Example of using BatchEmbedder to process large numbers of queries in smaller batches to avoid memory issues.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_embedder.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import BatchEmbedder\n\nbatch_embedder = BatchEmbedder(embedder=local_embedder, batch_size=100)\n\nqueries = [query] * 1000\n\nresponse = batch_embedder(queries)\n# 100%|██████████| 11/11 [00:04<00:00,  2.59it/s]\n```\n\n----------------------------------------\n\nTITLE: Initializing ObjectCount AdalComponent for Diagnosis\nDESCRIPTION: Basic implementation of ObjectCountAdalComponent class for diagnostic purposes. Sets up model client and evaluation function using exact match accuracy.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.datasets.types import Example\nfrom adalflow.eval.answer_match_acc import AnswerMatchAcc\n\n\nclass ObjectCountAdalComponent(adal.AdalComponent):\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        task = ObjectCountTaskPipeline(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        super().__init__(task=task, eval_fn=eval_fn)\n\n    def prepare_task(self, sample: Example):\n        return self.task.bicall, {\"question\": sample.question, \"id\": sample.id}\n\n    def prepare_eval(self, sample: Example, y_pred: adal.GeneratorOutput) -> float:\n        y_label = -1\n        if (\n            y_pred is not None and y_pred.data is not None\n        ):  # if y_pred and y_pred.data: might introduce bug when the data is 0\n            y_label = y_pred.data\n        return self.eval_fn, {\"y\": y_label, \"y_gt\": sample.answer}\n```\n\n----------------------------------------\n\nTITLE: API Key Configuration Setup\nDESCRIPTION: Script to securely set up OpenAI and Groq API keys as environment variables using getpass for secure input\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/adalflow_colab_template.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\ngroq_api_key = getpass(\"Please enter your GROQ API key: \")\n\n\n# Set environment variables\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Training Data JSON Sample Structure\nDESCRIPTION: Example of JSON structure showing how training samples are formatted with questions, answers and scores\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/optimizer.rst#2025-04-14_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n[\n    {\n        \"id\": \"37da1fbf-402c-44fc-a8b8-a45ad4690a47\",\n        \"question\": \"I have an apple, three bananas, a strawberry, a peach, three oranges, a plum, a raspberry, two grapes, a nectarine, and a blackberry. How many fruits do I have?\",\n        \"answer\": \"To solve this problem, we need to count the total number of fruits listed.\\n\\n1. One apple: 1\\n2. Three bananas: 3\\n3. One strawberry: 1\\n4. One peach: 1\\n5. Three oranges: 3\\n6. One plum: 1\\n7. One raspberry: 1\\n8. Two grapes: 2\\n9. One nectarine: 1\\n10. One blackberry: 1\\n\\nNext, we add these quantities together:\\n\\n1 + 3 + 1 + 1 + 3 + 1 + 1 + 2 + 1 + 1 = 15\\n\\nThus, the total number of fruits is 15.\\n\\nAnswer: 15\",\n        \"score\": 1.0\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Adding Documents and Updating RAG System\nDESCRIPTION: This snippet demonstrates how to add new documents to the RAG system at runtime, update the retriever, and perform a new query with the updated information.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Add more documents at runtime\ndoc3 = Document(\n    meta_data={\"title\": \"Apple's profile\"},\n    text=\"Apple is a cute dog with black and tan fur\" + \"lots of nonsense text\" * 500,\n    id=\"doc3\",\n)\ndoc4 = Document(\n    meta_data={\"title\": \"Apple's characteristics\"},\n    text=\"lots of more nonsense text\" * 250\n    + \"Apple is energetic, loves to play with her monkey toy\"\n    + \"lots of more nonsense text\" * 250,\n    id=\"doc4\",\n)\n\nrag.add_documents([doc3, doc4])\nrag.prepare_retriever()\n\n# Test a new query\nquery = \"What is Apple's favorite toy?\"\nresponse = rag.call(query)\nprint(f\"Response: {response}\")\n```\n\n----------------------------------------\n\nTITLE: Upgrading AdalFlow Installation\nDESCRIPTION: Commands to uninstall existing AdalFlow and install pre-release version with additional dependencies\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_component.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip uninstall -y adalflow\n!pip install --pre 'adalflow[openai,groq,datasets]'\n```\n\n----------------------------------------\n\nTITLE: Initializing AdalFlow Generator with Fireworks AI\nDESCRIPTION: Creates an AdalFlow generator instance using FireworksClient with specific model parameters and demonstrates generating a response for a quantum mechanics query.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/fireworks_integration.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client import FireworksClient\nimport adalflow as adal\n\ngenerator = adal.Generator(\n    model_client=FireworksClient(),\n    model_kwargs={\n        \"model\": \"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n        \"temperature\": 0.7,\n    },\n)\n\nprompt_kwargs = {\n    \"input_str\": \"Hello from Fireworks AI! Can you summarize the concept of quantum mechanics?\"\n}\n\nresponse = generator(prompt_kwargs)\n\nif response.error:\n    print(f\"[Fireworks] Generator error: {response.error}\")\nelse:\n    print(\"[Fireworks] LLM output:\")\n    print(response.data)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using SongReviewer in Python\nDESCRIPTION: Shows how to initialize the SongReviewer with a model client and generate a review.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nanalysis = SongReviewer(\n    model_client=GroqAPIClient(),\n    model_kwargs={\"model\": \"llama3-8b-8192\"},\n)\n\nresponse = analysis(\"Shape of you\")\nprint(f\"SongAnalysis: {response.data}\")\n\n# this time as we set `return_data_class` to False in the parser, we get the output as dict\n```\n\n----------------------------------------\n\nTITLE: Defining AdalComponent for Training Pipeline\nDESCRIPTION: Creates a subclass of AdalComponent to prepare the pipeline for training. Implements evaluation functions, loss functions, and methods to configure backward engine and teacher generator.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/classification.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass TrecClassifierAdal(adal.AdalComponent):\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        teacher_model_config: Dict,\n        backward_engine_model_config: Dict,\n        text_optimizer_model_config: Dict,\n    ):\n        task = TRECClassifierStructuredOutput(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        loss_fn = adal.EvalFnToTextLoss(\n            eval_fn=eval_fn,\n            eval_fn_desc=\"exact_match: 1 if str(y) == str(y_gt) else 0\",\n        )\n        super().__init__(\n            task=task,\n            eval_fn=eval_fn,\n            loss_fn=loss_fn,\n            backward_engine_model_config=backward_engine_model_config,\n            text_optimizer_model_config=text_optimizer_model_config,\n            teacher_model_config=teacher_model_config,\n        )\n\n    def prepare_task(self, sample: TRECExtendedData):\n        return self.task.call, {\"question\": sample.question, \"id\": sample.id}\n\n    def prepare_eval(\n        self, sample: TRECExtendedData, y_pred: adal.GeneratorOutput\n    ) -> float:\n        y_label = -1\n        if y_pred and y_pred.data is not None and y_pred.data.class_name is not None:\n            y_label = y_pred.data.class_name\n        return self.eval_fn, {\"y\": y_label, \"y_gt\": sample.class_name}\n\n    def prepare_loss(\n        self, sample: TRECExtendedData, y_pred: adal.Parameter, *args, **kwargs\n    ) -> Tuple[Callable[..., Any], Dict]:\n        full_response = y_pred.full_response\n        y_label = -1\n        if (\n            full_response\n            and full_response.data is not None\n            and full_response.data.class_name is not None\n        ):\n            y_label = full_response.data.class_name\n\n        y_pred.eval_input = y_label\n        y_gt = adal.Parameter(\n            name=\"y_gt\",\n            data=sample.class_name,\n            eval_input=sample.class_name,\n            requires_opt=False,\n        )\n        return self.loss_fn, {\"kwargs\": {\"y\": y_pred, \"y_gt\": y_gt}}\n```\n\n----------------------------------------\n\nTITLE: Local Ollama Integration with AdalFlow\nDESCRIPTION: Integration code for using local Ollama models with AdalFlow\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\n\nllama_llm = adal.Generator(\n   model_client=adal.OllamaClient(), model_kwargs={\"model\": \"llama3\"}\n)\nresopnse = llama_llm(prompt_kwargs={\"input_str\": \"What is LLM?\"})\n```\n\n----------------------------------------\n\nTITLE: Teacher Traces Example in JSON for Few-Shot Optimization\nDESCRIPTION: Shows a partial example of teacher model traces for comparison with student model traces during weighted sampling for optimizing few-shot examples.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/optimizer.rst#2025-04-14_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n\n    \"2d72e6e7-71a2-428d-90ff-6986ba52a0d3\": {\n        \"id\": \"2d72e6e7-71a2-428d-90ff-6986ba52a0d3\",\n        \"question\": \"I have a yam, a cauliflower, a bed, two cabbages, a garlic, an oven, a carrot, a head of broccoli, a potato, a stalk of celery, a lettuce head, and a toaster. How many vegetables do I have?\",\n        \"answer\": \"Let's identify which items from the given list are vegetables:\\n\\n1. Yam - vegetable\\n2. Cauliflower - vegetable\\n3. Bed - not a vegetable\\n4. Two cabbages - vegetables (counted as two)\\n5. Garlic - vegetable\\n6. Oven - not a vegetable\\n7. Carrot - vegetable\\n8. Head of broccoli - vegetable\\n9. Potato - vegetable\\n10. Stalk of celery - vegetable\\n11. Lettuce head - vegetable\\n12. Toaster - not a vegetable\\n\\nNow, let's count the vegetables:\\n\\n1. Yam\\n2. Cauliflower\\n3. Two cabbages (counted as two)\\n4. Garlic\\n5. Carrot\\n6. Head of broccoli\\n7. Potato\\n8. Stalk of celery\\n9. Lettuce head\\n\\nAdding these up, we get:\\n\\n1 (yam) + 1 (cauliflower) + 2 (cabbages) + 1 (garlic) + 1 (carrot) + 1 (broccoli) + 1 (potato) + 1 (celery) + 1 (lettuce) = 10\\n\\nAnswer: 10\",\n        \"score\": 1.0\n    },\n    \"37da1fbf-402c-44fc-a8b8-a45ad4690a47\": {\n        \"id\": \"37da1fbf-402c-44fc-a8b8-a45ad4690a47\",\n        \"question\": \"I have an apple, three bananas, a strawberry, a peach, three oranges, a plum, a raspberry, two grapes, a nectarine, and a blackberry. How many fruits do I have?\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Document Objects with AdalFlow\nDESCRIPTION: Shows how to instantiate Document objects from the core.types module using document content and metadata.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import Document\n\ndocuments  = [Document(text=doc['content'], meta_data={'title': doc['title']}) for doc in org_documents]\nprint(documents)\n```\n\n----------------------------------------\n\nTITLE: Defining a DataClass with Input and Output Fields in Python\nDESCRIPTION: Creates a SampleDataClass with both input and output fields, demonstrating how to specify which fields are for input and which are for output in a DataClass.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass SampleDataClass(DataClass):\n    description: str = field(metadata={\"desc\": \"A sample description\"})\n    category: str = field(metadata={\"desc\": \"Category of the sample\"})\n    value: int = field(metadata={\"desc\": \"A sample integer value\"})\n    status: str = field(metadata={\"desc\": \"Status of the sample\"})\n\n    __input_fields__ = [\n        \"description\",\n        \"category\",\n    ]  # Define which fields are input fields\n    __output_fields__ = [\"value\", \"status\"]  # Define which fields are output fields\n```\n\n----------------------------------------\n\nTITLE: Configuring Zero-Shot ICL with System Prompt Optimization in Python\nDESCRIPTION: Demonstrates how to set up a system prompt parameter with optimization enabled, including an instruction to the optimizer for creating synthetic examples.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/optimizer.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = Parameter(\n        alias=\"task_instruction\",\n        data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n        role_desc=\"To give task instruction to the language model in the system prompt\",\n        requires_opt=True,\n        param_type=ParameterType.NONE,\n        instruction_to_optimizer=\"You can show some examples if you think that will help.\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Setting Up and Running AdalFlow Generator with DeepSeek-R1 Model\nDESCRIPTION: This code snippet demonstrates how to set up an AdalFlow Generator using the TogetherClient with the DeepSeek-R1 model. It configures model parameters and applies the custom text extraction function as an output processor.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/adalflow_together_deepseek_r1.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# set up the generator\n\ngenerator = adal.Generator(\n    model_client=TogetherClient(),\n    model_kwargs={\n        \"model\": \"deepseek-ai/DeepSeek-R1\",\n        \"temperature\": 0.7,\n        \"max_tokens\": 2000,\n    },\n    output_processors=extract_think_and_answer,\n)\n\n# run the code\nprompt_kwargs = {\"input_str\": \"Hi from AdalFlow! Summarize generative AI briefly.\"}\noutput = generator(prompt_kwargs=prompt_kwargs)\noutput\n```\n\n----------------------------------------\n\nTITLE: Securely Setting API Keys for OpenAI and Groq in Python\nDESCRIPTION: This code prompts the user to enter API keys for OpenAI and Groq, then sets them as environment variables for secure access in the application.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_logger.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\ngroq_api_key = getpass(\"Please enter your GROQ API key: \")\n\n# Set environment variables\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Creating and Loading Data into LocalDB in AdalFlow\nDESCRIPTION: This snippet shows how to create a LocalDB instance for managing dialog turns and load data into it using the AdalFlow framework.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.db import LocalDB\n\ndialog_turn_db = LocalDB('dialog_turns')\nprint(dialog_turn_db)\n\ndialog_turn_db.load(dialog_turns)\nprint(dialog_turn_db)\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Package with Dependencies\nDESCRIPTION: Installation commands for AdalFlow package including OpenAI and Groq integrations\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_component.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install adalflow[openai,groq]\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Pipeline Component\nDESCRIPTION: Definition of ObjectCountTaskPipeline component with trainable parameters and custom parsing logic\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\nimport re\nfrom typing import Dict, Union\nimport adalflow as adal\nfrom adalflow.optim.types import ParameterType\n\n@adal.func_to_data_component\ndef parse_integer_answer(answer: str):\n    \"\"\"A function that parses the last integer from a string using regular expressions.\"\"\"\n    try:\n        # Use regular expression to find all sequences of digits\n        numbers = re.findall(r\"\\d+\", answer)\n        if numbers:\n            # Get the last number found\n            answer = int(numbers[-1])\n        else:\n            answer = -1\n    except ValueError:\n        answer = -1\n\n    return answer\n\nfew_shot_template = r\"\"\"<START_OF_SYSTEM_PROMPT>\n{{system_prompt}}\n{# Few shot demos #}\n{% if few_shot_demos is not none %}\nHere are some examples:\n{{few_shot_demos}}\n{% endif %}\n<END_OF_SYSTEM_PROMPT>\n<START_OF_USER>\n{{input_str}}\n<END_OF_USER>\n\"\"\"\n\nclass ObjectCountTaskPipeline(adal.Component):\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        super().__init__()\n\n        system_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=True,\n            param_type=ParameterType.PROMPT,\n        )\n        few_shot_demos = adal.Parameter(\n            data=None,\n            role_desc=\"To provide few shot demos to the language model\",\n            requires_opt=True,\n            param_type=ParameterType.DEMOS,\n        )\n\n        self.llm_counter = adal.Generator(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            template=few_shot_template,\n            prompt_kwargs={\n                \"system_prompt\": system_prompt,\n                \"few_shot_demos\": few_shot_demos,\n            },\n            output_processors=parse_integer_answer,\n            use_cache=True,\n        )\n\n    def bicall(\n        self, question: str, id: str = None\n    ) -> Union[adal.GeneratorOutput, adal.Parameter]:\n        output = self.llm_counter(prompt_kwargs={\"input_str\": question}, id=id)\n        return output\n```\n\n----------------------------------------\n\nTITLE: Generating Responses and Updating Dialog Database\nDESCRIPTION: Shows how to generate a response using the language model and add it to the dialog turn database with transformation applied.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(dialog_turn_db.length, len(dialog_turn_db.transformed_items[key]))\n```\n\nLANGUAGE: python\nCODE:\n```\nprompt_kwargs = {\"input_str\": input_str, \"chat_history_str\": chat_history_str}\n\nresponse = generator(prompt_kwargs=prompt_kwargs)\nprint(response)\n```\n\nLANGUAGE: python\nCODE:\n```\n# create a turn from the last dialog\n\nnew_turn = DialogTurn(\n    user_query=UserQuery(query_str=input_str),\n    assistant_response=AssistantResponse(response_str=response.data),\n)\ndialog_turn_db.add(new_turn, apply_transformer=True)\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(dialog_turn_db.length, len(dialog_turn_db.transformed_items[key]))\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(dialog_turn_db.transformed_items[key])\n\n# we will find them by comparing the id of new_turn to the parent_doc_id in the transformed_items\nnew_turn_id = new_turn.id\nprint(new_turn_id)\nfor item in dialog_turn_db.transformed_items[key]:\n    if item.parent_doc_id == new_turn_id:\n        print(item)\n        print(item.text)\n```\n\n----------------------------------------\n\nTITLE: Configuring ReAct Agent Tools\nDESCRIPTION: Sets up the tools array with the search function for the ReAct agent to use.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# set up tools for the agent\ntools = [FunctionTool(fn=search)]\n```\n\n----------------------------------------\n\nTITLE: Loading Configuration Settings\nDESCRIPTION: Loads RAG pipeline configuration settings from a YAML file containing parameters and settings.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/eval_a_rag.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwith open(\"./configs/rag_hotpotqa.yaml\", \"r\") as file:\n    settings = yaml.safe_load(file)\n```\n\n----------------------------------------\n\nTITLE: Configuring Parameters for Few-shot Bootstrap Training in Python\nDESCRIPTION: Sets up system_prompt and few_shot_demos parameters for few-shot bootstrap training in AdalFlow. The few_shot_demos is set for optimization while system_prompt is not.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=False,\n            param_type=ParameterType.PROMPT,\n        )\nfew_shot_demos = adal.Parameter(\n    data=None,\n    role_desc=\"To provide few shot demos to the language model\",\n    requires_opt=True,\n    param_type=ParameterType.DEMOS,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom from_dict Method in DataClass\nDESCRIPTION: This snippet demonstrates how to implement a custom from_dict class method in a DataClass to handle specific data transformation during object creation from a dictionary.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict\n\n\n@dataclass\nclass OutputFormat(DataClass):\n    thought: str = field(\n        metadata={\n            \"desc\": \"Your reasoning to classify the question to class_name\",\n        }\n    )\n    class_name: str = field(metadata={\"desc\": \"class_name\"})\n    class_index: int = field(metadata={\"desc\": \"class_index in range[0, 5]\"})\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, object]):\n        _COARSE_LABELS_DESC = [\n            \"Abbreviation\",\n            \"Entity\",\n            \"Description and abstract concept\",\n            \"Human being\",\n            \"Location\",\n            \"Numeric value\",\n        ]\n        data = {\n            \"thought\": None,\n            \"class_index\": data[\"coarse_label\"],\n            \"class_name\": _COARSE_LABELS_DESC[data[\"coarse_label\"]],\n        }\n        return super().from_dict(data)\n\n\ndata = OutputFormat.from_dict({\"coarse_label\": 1})\nprint(data)\n```\n\n----------------------------------------\n\nTITLE: Initializing FunctionExpression Output Format in Python\nDESCRIPTION: This snippet demonstrates how to set up the FunctionExpression output format using AdalFlow's core types and output parsers. It includes the creation of a custom output format string and the use of JsonOutputParser.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import FunctionExpression\n\noutput_data_class = FunctionExpression\noutput_format_str = output_data_class.to_json_signature(exclude=[\"thought\"])\nprint(prompt(output_format_str=output_format_str))\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.output_parsers import JsonOutputParser\n\nfunc_parser = JsonOutputParser(data_class=Function, exclude_fields=[\"thought\", \"args\"])\ninstructions = func_parser.format_instructions()\nprint(instructions)\n```\n\n----------------------------------------\n\nTITLE: Implementing Generator Call Tracing in Python\nDESCRIPTION: Shows how to combine both trace_generator_call and trace_generator_states decorators to track both generator state changes and call results. This helps with debugging and improving LLM predictions.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging_tracing.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom tracing import trace_generator_errors\n\n@trace_generator_call()\n@trace_generator_states()\nclass SimpleQA(Component):\n    def __init__(self):\n        super().__init__()\n        self.generator = Generator(...)\n        self.generator_2 = Generator(...)\n    def call(...):\n```\n\n----------------------------------------\n\nTITLE: Implementing Asynchronous Function Calls\nDESCRIPTION: Defines asynchronous methods for running function calls concurrently and processing individual queries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_function_calls.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nasync def run_async_function_call(self, generator, tool_manager):\n    answers = []\n    start_time = time.time()\n    tasks = []\n    for idx, query in enumerate(queries):\n        tasks.append(self.process_query(idx, query, generator, tool_manager))\n\n    results = await asyncio.gather(*tasks)\n    answers.extend(results)\n    end_time = time.time()\n    print(f\"Total time taken: {end_time - start_time :.2f} seconds\")\n    return answers\n\n\nasync def process_query(self, idx, query, generator, tool_manager: ToolManager):\n    print(f\"\\n{idx} Query: {query}\")\n    print(f\"{'-'*50}\")\n    try:\n        result = generator(prompt_kwargs={\"input_str\": query})\n        func_expr = FunctionExpression.from_dict(result.data)\n        print(f\"Function_expr: {func_expr}\")\n        func = tool_manager.parse_func_expr(func_expr)\n        func_output = await tool_manager.execute_func_async(func)\n        print(f\"Function output: {func_output}\")\n        return func_output\n    except Exception as e:\n        print(\n            f\"Failed to execute the function for query: {query}, func: {result.data}, error: {e}\"\n        )\n        return None\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Dependencies\nDESCRIPTION: Installs the required AdalFlow package with OpenAI, GROQ, and FAISS CPU dependencies. It also updates specific package versions for compatibility.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_function_calls.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[openai,groq,faiss-cpu]\n\nclear_output()\n```\n\nLANGUAGE: python\nCODE:\n```\n!pip uninstall httpx anyio -y\n!pip install \"anyio>=3.1.0,<4.0\"\n!pip install httpx==0.24.1\n```\n\n----------------------------------------\n\nTITLE: Generator Call Log Entry Format\nDESCRIPTION: Shows an example of a log entry in the generator call log file, containing the input prompt, model parameters, output response, and timestamp. This helps track LLM behavior and diagnose issues.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging_tracing.rst#2025-04-14_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\"prompt_kwargs\": {\"input_str\": \"What is the capital of France?\"}, \"model_kwargs\": {}, \"output\": {\"data\": \"Bonjour!\\n\\nThe capital of France is Paris, of course! But did you know that the Eiffel Tower in Paris is actually the most-visited paid monument in the world? Mind-blowing, right?\\n\\nNow, would you like to know some more fun facts or perhaps ask another question? I'm all ears (or should I say, all eyes?)\"}, \"error_message\": null, \"raw_response\": \"Bonjour!\\n\\nThe capital of France is Paris, of course! But did you know that the Eiffel Tower in Paris is actually the most-visited paid monument in the world? Mind-blowing, right?\\n\\nNow, would you like to know some more fun facts or perhaps ask another question? I'm all ears (or should I say, all eyes?)\"}, \"time_stamp\": \"2024-06-03T16:44:45.582859\"}\n```\n\n----------------------------------------\n\nTITLE: Using FloatParser in AdalFlow\nDESCRIPTION: Demonstrates the FloatParser which extracts the first float value from text. It can handle both integer and decimal numbers, converting integers to floats.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import FloatParser\n\nfloat_str = \"42.0\"\nfloat_str_2 = \"42\"\nfloat_str_3 = \"42.7\"\nfloat_str_4 = \"the answer is 42.75\"\n\n# it will all return 42.0\nparser = FloatParser()\nprint(parser(float_str))\nprint(parser(float_str_2))\nprint(parser(float_str_3))\nprint(parser(float_str_4))\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment and Client Configuration\nDESCRIPTION: Configures the environment and initializes the OpenAI client. Requires a .env file containing API keys for the selected model service.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/question_answering/simple_qa.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Here, we use the OpenAIClient as an example, but you can use any other clients (with the corresponding API Key as needed), such as AnthropicAPIClient\nfrom adalflow.utils import (\n    setup_env,\n)  # make sure you have a .env file with OPENAI_API_KEY or any other key mentioned with respect to your usage\n\nsetup_env(\".env\")\nfrom adalflow.components.model_client import OpenAIClient\n```\n\n----------------------------------------\n\nTITLE: Using Basic Python Dataclasses for LLM Interaction\nDESCRIPTION: Example of using Python's native dataclasses module to define a structured data class for LLM interaction. This shows the basic approach before implementing AdalFlow's DataClass functionality.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass TrecData:\n    question: str = field(\n        metadata={\"desc\": \"The question asked by the user\"}\n    ) # Required field, you have to provide the question field at the instantiation\n    label: int = field(\n        metadata={\"desc\": \"The label of the question\"}, default=0\n    ) # Optional field\n```\n\n----------------------------------------\n\nTITLE: TREC Classifier Task Initialization and Testing\nDESCRIPTION: Initializes a TREC classifier task with GPT-3 model configuration and runs a test prediction on a sample question.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_classification_optimization.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntask = TRECClassifierStructuredOutput(\n    model_client=gpt_3_model[\"model_client\"],\n    model_kwargs=gpt_3_model[\"model_kwargs\"],\n)\ntask.train()\n\noutput = task(question=example.question, id=example.id)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Document Filtering with LocalDB\nDESCRIPTION: Example of filtering documents using LocalDB and Document type, demonstrating basic database operations.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.db import LocalDB\nfrom adalflow.core.types import Document\n\ndb = LocalDB()\ndb.connect()\n\n# Add the documents to the database\nfor doc in documents:\n    db.add_item(Document(**doc))\n\n# Filter the documents\nfiltered_documents = db.filter(Document, title=\"Solar Panels\")\n\nprint(filtered_documents)\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for RAG Evaluation\nDESCRIPTION: Imports required modules for dataset loading, RAG pipeline construction, and evaluation components.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/eval_a_rag.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport yaml\n\nfrom datasets import load_dataset\n\nfrom core.openai_client import OpenAIClient\nfrom core.generator import Generator\nfrom core.base_data_class import Document\nfrom core.string_parser import JsonParser\nfrom core.component import Sequential\nfrom eval.evaluators import (\n    RetrieverEvaluator,\n    AnswerMacthEvaluator,\n    LLMasJudge,\n    DEFAULT_LLM_EVALUATOR_PROMPT,\n)\nfrom core.prompt_builder import Prompt\nfrom use_cases.rag import RAG\n```\n\n----------------------------------------\n\nTITLE: Using Jinja2 Templates with Different Arguments\nDESCRIPTION: Demonstrates how to call the Jinja2 template function with different sets of arguments, showing how the template conditionally renders based on the provided parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/prompt.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\njinja2_template_example(task_desc_str=task_desc_str, input_str=input_str)\njinja2_template_example(\n     task_desc_str=task_desc_str, input_str=input_str, tools=tools\n )\n```\n\n----------------------------------------\n\nTITLE: Configuring Groq Client\nDESCRIPTION: Example showing how to set up and use Groq's language models with AdalFlow. Requires GROQ_API_KEY to be set in environment variables.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/installation.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\n\n# setup env or pass the api_key to client\nfrom adalflow.utils import setup_env\n\nsetup_env()\n\nllama_llm = adal.Generator(\n   model_client=adal.GroqAPIClient(), model_kwargs={\"model\": \"llama3-8b-8192\"}\n)\nresopnse = llama_llm(prompt_kwargs={\"input_str\": \"What is LLM?\"})\n```\n\n----------------------------------------\n\nTITLE: Configuring FunctionExpression Output Format\nDESCRIPTION: Sets up a ToolManager with additional context and configures a JsonOutputParser for FunctionExpression output format.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_function_calls.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntool_manager = ToolManager(\n    tools=functions,\n    additional_context={\"x\": x, \"y\": 0, \"np.array\": np.array, \"np\": np},\n)\nfunc_parser = JsonOutputParser(data_class=FunctionExpression)\n```\n\nLANGUAGE: python\nCODE:\n```\ncontext = r\"\"\"<CONTEXT>\nYour function expression also have access to these context:\n{{context_str}}\n</CONTEXT>\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Formatting Chat History and Generating Prompt in Python\nDESCRIPTION: This snippet defines a function to format chat history as a string and demonstrates how to use it with a generator to create and print a prompt for conversation continuation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\ninput_str = \"What are the benefits of renewable energy? Did I ask this before?\"\n\ndef format_chat_history_str(turns: List[DialogTurn]) -> str:\n    chat_history_str = []\n    for turn in turns:\n        chat_history_str.append(\n                    turn.to_yaml(\n                        exclude=[\n                            \"id\",\n                            \"user_id\",\n                            \"session_id\",\n                            \"user_query_timestamp\",\n                            \"assistant_response_timestamp\",\n                            \"order\",\n                            \"metadata\",\n                            \"vector\",\n                        ],\n                    )\n                )\n    chat_history_str = '\\n_________\\n'.join(chat_history_str)\n    return chat_history_str\n\nchat_history_str = format_chat_history_str(dialog_turn_db.items[0:1])\nprint(generator.print_prompt(input_str=input_str, chat_history_str=chat_history_str))\n```\n\n----------------------------------------\n\nTITLE: Fetch Dialog Turns\nDESCRIPTION: Retrieves dialog turns from the database based on the extracted parent document IDs\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfetched_dialog_turns = dialog_turn_db.fetch_items(\n    condition=lambda x: x.id in parent_doc_ids\n)\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Package Dependencies\nDESCRIPTION: Installation command for AdalFlow with OpenAI, Groq, and FAISS-CPU dependencies using pip.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_embedder.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install adalflow[openai,groq,faiss-cpu]\n```\n\n----------------------------------------\n\nTITLE: Handling Loss Sample in ObjectCountAdalComponent\nDESCRIPTION: This method prepares the ground truth and prediction parameters for loss computation in the ObjectCountAdalComponent.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef handle_one_loss_sample(self, sample: Example, pred: adal.Parameter):\n    # prepare gt parameter\n    y_gt = adal.Parameter(\n        name=\"y_gt\",\n        data=sample.answer,\n        eval_input=sample.answer,\n        requires_opt=False,\n    )\n\n    # pred's full_response is the output of the task pipeline which is GeneratorOutput\n    pred.eval_input = pred.full_response.data\n    return self.loss_fn, {\"kwargs\": {\"y\": pred, \"y_gt\": y_gt}}\n```\n\n----------------------------------------\n\nTITLE: Configuring Backward Engine in ObjectCountAdalComponent\nDESCRIPTION: This method configures the backward engine for the ObjectCountAdalComponent using the provided model configuration.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef configure_backward_engine(self):\n    super().configure_backward_engine_helper(\n        **self.backward_engine_model_config\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating an Answer Parser Component with AdalFlow\nDESCRIPTION: Implementation of a function that parses integer answers from model responses, converted to a data component using the AdalFlow decorator.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\nimport re\n\n@adal.func_to_data_component\ndef parse_integer_answer(answer: str):\n    \"\"\"A function that parses the last integer from a string using regular expressions.\"\"\"\n    try:\n        # Use regular expression to find all sequences of digits\n        numbers = re.findall(r\"\\d+\", answer)\n        if numbers:\n            # Get the last number found\n            answer = int(numbers[-1])\n        else:\n            answer = -1\n    except ValueError:\n        answer = -1\n\n    return answer\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI GPT-3.5 Model Configuration\nDESCRIPTION: Sets up the OpenAI client and configures GPT-3.5-turbo model parameters including tokens, temperature, and other generation settings.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client.openai_client import OpenAIClient\n\nadal.setup_env()\n\ngpt_3_model = {\n    \"model_client\": OpenAIClient(),\n    \"model_kwargs\": {\n        \"model\": \"gpt-3.5-turbo\",\n        \"max_tokens\": 2000,\n        \"temperature\": 0.0,\n        \"top_p\": 0.99,\n        \"frequency_penalty\": 0,\n        \"presence_penalty\": 0,\n        \"stop\": None,\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow with Together Integration\nDESCRIPTION: This snippet shows how to install the AdalFlow library with the 'together' extra package using pip. It also clears the output after installation for a cleaner notebook.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/adalflow_together_deepseek_r1.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[together]\n\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using AdalFlow Generator with xAI\nDESCRIPTION: Demonstrates how to create and use an AdalFlow Generator with xAI client integration. Sets up the generator with Grok-2 model configuration and executes a simple test prompt.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/xai_integration.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client import XAIClient\nfrom adalflow.core import Generator\n\ngenerator = Generator(\n    model_client=XAIClient(),\n    model_kwargs={\n        \"model\": \"grok-2-latest\",\n        \"temperature\": 0,\n        \"stream\": False,\n    },\n)\n\nprompt_kwargs = {\"input_str\": \"Testing. Just say hi and hello world and nothing else.\"}\n\n# Call the generator\nresponse = generator(prompt_kwargs)\n\nif response.error:\n    print(f\"[xAI] Generator Error: {response.error}\")\nelse:\n    print(f\"[xAI] Response: {response.data}\")\n```\n\n----------------------------------------\n\nTITLE: Basic G-eval Function Call with Variables\nDESCRIPTION: Simple example showing how to call the G-eval function using gt and pred variables as parameters. Demonstrates the basic usage pattern for the evaluation function.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ncompute_g_eval_summarization(source=gt, summary=pred)\n```\n\n----------------------------------------\n\nTITLE: Splitting Text by Token using TextSplitter in AdalFlow\nDESCRIPTION: This example shows how to split a document using token-based chunking. It configures the TextSplitter with a chunk size of 5 tokens and no overlap, then processes the document and displays the resulting chunks which align with the tokenization boundaries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/text_splitter.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.data_process.text_splitter import TextSplitter\nfrom adalflow.core.types import Document\nimport tiktoken\n\n# Configure the splitter settings\ntext_splitter = TextSplitter(\n    split_by=\"token\",\n    chunk_size=5,\n    chunk_overlap=0\n)\n\ndoc = Document(\n    text=\"Example text. More example text. Even more text to illustrate.\",\n    id = \"doc1\"\n    )\n\nsplitted_docs = (text_splitter.call(documents=[doc]))\n\nfor doc in splitted_docs:\n    print(doc)\n\n# Output:\n# Document(id=27cec433-b400-4f11-8871-e386e774d150, text='Example text. More example', meta_data=None, vector=[], parent_doc_id=doc1, order=0, score=None)\n# Document(id=8905dc5f-8be5-4ca4-88b1-2ae492258b53, text=' text. Even more text', meta_data=None, vector=[], parent_doc_id=doc1, order=1, score=None)\n# Document(id=ba8e1e23-82fb-4aa8-bfc5-e22084984bb9, text=' to illustrate.', meta_data=None, vector=[], parent_doc_id=doc1, order=2, score=None)\n```\n\n----------------------------------------\n\nTITLE: Serializing and Deserializing DataClass to JSON and YAML in Python\nDESCRIPTION: Demonstrates how to convert a DataClass instance to JSON and YAML strings, and how to reconstruct instances from these strings. It also shows equality comparison between original and reconstructed objects.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\njson_str = example.to_json()\nprint(json_str)\n\nyaml_str = example.to_yaml(example)\nprint(yaml_str)\n\nreconstructed_from_json = TrecData2.from_json(json_str)\nprint(reconstructed_from_json)\nprint(reconstructed_from_json == example)\n\nreconstructed_from_yaml = TrecData2.from_yaml(yaml_str)\nprint(reconstructed_from_yaml)\nprint(reconstructed_from_yaml == example)\n```\n\n----------------------------------------\n\nTITLE: Defining Nested Data Structures with Python Dataclasses\nDESCRIPTION: Example demonstrating how to create nested dataclass structures that can be used with LLMs. This shows a Question class nested within a TrecData class before implementing AdalFlow's DataClass functionality.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass Question:\n    question: str = field(\n        metadata={\"desc\": \"The question asked by the user\"}\n    )\n    metadata: dict = field(\n        metadata={\"desc\": \"The metadata of the question\"}, default_factory=dict\n    )\n\n@dataclass\nclass TrecData:\n    question: Question = field(\n        metadata={\"desc\": \"The question asked by the user\"}\n    ) # Required field, you have to provide the question field at the instantiation\n    label: int = field(\n        metadata={\"desc\": \"The label of the question\"}, default=0\n    ) # Optional field\n```\n\n----------------------------------------\n\nTITLE: TREC Classifier Training Function Implementation\nDESCRIPTION: Implements the main training function that sets up model configurations, initializes components, and manages the training process with error handling.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_classification_optimization.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef train(\n    model_client: adal.ModelClient,\n    model_kwargs: Dict,\n    train_batch_size=4,\n    raw_shots: int = 0,\n    bootstrap_shots: int = 1,\n    max_steps=12,\n    num_workers=4,\n    strategy=\"constrained\",\n    optimization_order=\"sequential\",\n    debug=False,\n):\n    print(\"Starting training process...\")\n\n    # Define the model configuration for all components\n    gpt_4o_model = {\n        \"model_client\": OpenAIClient(),\n        \"model_kwargs\": {\n            \"model\": \"gpt-4o-mini\",\n            \"temperature\": 1,\n            \"top_p\": 0.99,\n            \"max_tokens\": 1000,\n            # \"frequency_penalty\": 1,  # high for nto repeating prompt\n        },\n    }\n\n    print(f\"Component model configuration: {gpt_4o_model}\")\n\n    try:\n        print(\"Initializing ADAL component...\")\n        adal_component = TrecClassifierAdal(\n            model_client=model_client,\n            model_kwargs=model_kwargs,\n            text_optimizer_model_config=gpt_4o_model,\n            backward_engine_model_config=gpt_4o_model,\n            teacher_model_config=gpt_4o_model,\n        )\n        print(\"ADAL component initialized successfully\")\n\n        print(\"Initializing trainer...\")\n        trainer = adal.Trainer(\n            train_batch_size=train_batch_size,\n            adaltask=adal_component,\n            strategy=strategy,\n            max_steps=max_steps,\n            num_workers=num_workers,\n            raw_shots=raw_shots,\n            bootstrap_shots=bootstrap_shots,\n            debug=debug,\n            weighted_sampling=True,\n            optimization_order=optimization_order,\n            exclude_input_fields_from_bootstrap_demos=True,\n        )\n        print(\"Trainer initialized successfully\")\n\n        print(\"Loading datasets...\")\n        train_dataset, val_dataset, test_dataset = load_datasets()\n        print(\n            f\"Datasets loaded - Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\"\n        )\n\n        print(\"Starting model training...\")\n        trainer.fit(\n            train_dataset=train_dataset,\n            val_dataset=val_dataset,\n            test_dataset=test_dataset,\n            debug=debug,\n        )\n        print(\"Training completed successfully\")\n\n    except Exception as e:\n        print(f\"Error occurred: {str(e)}\")\n        raise\n```\n\n----------------------------------------\n\nTITLE: Local Ollama Setup Commands\nDESCRIPTION: Installation and model setup commands for local Ollama deployment\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Download Ollama command line tool\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Pull the model to use\nollama pull llama3\n```\n\n----------------------------------------\n\nTITLE: Running AdalFlow Training in Debug Mode\nDESCRIPTION: This snippet demonstrates how to run the AdalFlow training process in debug mode, which provides detailed information about the training process and helps in identifying potential issues.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ntrain(debug=True, max_steps=12, strategy=\"constrained\")\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for AdalFlow RAG Implementation\nDESCRIPTION: This code block imports necessary modules and classes from dspy, adalflow, and other standard Python libraries for implementing the RAG system.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\nimport re\nfrom typing import List, Union, Optional, Dict, Callable, Any, Tuple\nfrom dataclasses import dataclass, field\nimport adalflow as adal\nfrom adalflow.optim.parameter import Parameter, ParameterType\nfrom adalflow.datasets.hotpot_qa import HotPotQA, HotPotQAData\nfrom adalflow.datasets.types import Example\nfrom adalflow.core.types import RetrieverOutput\nfrom adalflow.core import Component, Generator\nfrom adalflow.core.retriever import Retriever\nfrom adalflow.core.component import func_to_component\nfrom adalflow.components.model_client.openai_client import OpenAIClient\n```\n\n----------------------------------------\n\nTITLE: Configuring Optimizers in ObjectCountAdalComponent\nDESCRIPTION: This method configures both the text optimizer and demo optimizer for the ObjectCountAdalComponent.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef configure_optimizers(self):\n    to = super().configure_text_optimizer_helper(**self.text_optimizer_model_config)\n    do = super().configure_demo_optimizer_helper()\n    return to  + do\n```\n\n----------------------------------------\n\nTITLE: Mapping Functions for Document Conversion in Python\nDESCRIPTION: These functions convert dictionary and DialogTurn objects to Document objects, which are used in the AdalFlow framework for data processing.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# mapping function for org_documents\ndef map_to_document(doc: Dict) -> Document:\n    return Document(text=doc['content'], meta_data={'title': doc['title']})\n\ndef map_dialogturn_to_document(turn: DialogTurn) -> Document:\n    # it can be important to keep the original data's id\n    return Document(id=turn.id, text=turn.user_query.query_str + ' ' + turn.assistant_response.response_str)\n```\n\n----------------------------------------\n\nTITLE: Loading Datasets and Training with AdalFlow in Python\nDESCRIPTION: This code snippet demonstrates how to load datasets, initialize an AdalComponent, and train it using AdalFlow's Trainer. It includes dataset loading, component initialization, and trainer configuration.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef load_datasets():\n    train_data = TrecDataset(split=\"train\")\n    val_data = TrecDataset(split=\"val\")\n    test_data = TrecDataset(split=\"test\")\n    return train_data, val_data, test_data\n\nadal_component = TrecClassifierAdal(\n    model_client=model_client,\n    model_kwargs=model_kwargs,\n    text_optimizer_model_config=deepseek_r1_model,\n    backward_engine_model_config=gpt_4o_model,\n    teacher_model_config=gpt_4o_model,\n)\ntrainer = adal.Trainer(\n    adaltask=adal_component,\n    max_steps=12,\n    raw_shots=1,\n    bootstrap_shots=1,\n)\n\ntrain_dataset, val_dataset, test_dataset = load_datasets()\nckpt, _ = trainer(\n    train_dataset=train_dataset,\n    val_dataset=val_dataset,\n    test_dataset=test_dataset,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Parameters for Few-Shot Learning in AdalFlow\nDESCRIPTION: Code snippet demonstrating how to configure system prompt and few-shot demonstration parameters in AdalFlow. It shows how to set the requires_opt flag to enable few-shot bootstrapping by turning it on for demos and off for the system prompt.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = adal.Parameter(\n                data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n                role_desc=\"To give task instruction to the language model in the system prompt\",\n                requires_opt=False,\n                param_type=ParameterType.PROMPT,\n            )\nfew_shot_demos = adal.Parameter(\n    data=None,\n    role_desc=\"To provide few shot demos to the language model\",\n    requires_opt=True,\n    param_type=ParameterType.DEMOS,\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Doctor QA Component\nDESCRIPTION: Implementation of DocQA component class that uses OpenAI for medical question answering\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_component.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass DocQA(Component):\n    def __init__(self):\n        super(DocQA, self).__init__()\n        self.doc = Generator(\n            template=template_doc,\n            model_client=OpenAIClient(),\n            model_kwargs={\"model\": \"gpt-3.5-turbo\"},\n        )\n\n    def call(self, query: str) -> str:\n        return self.doc(prompt_kwargs={\"input_str\": query}).data\n```\n\n----------------------------------------\n\nTITLE: Execute Training with GPT-3 Model Configuration\nDESCRIPTION: Calls the training function with GPT-3 model configuration using parameter unpacking.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_classification_optimization.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntrain(**gpt_3_model)\n```\n\n----------------------------------------\n\nTITLE: Implementing LLM Judge With Questions\nDESCRIPTION: Implementation of LLM-based evaluation with questions using OpenAI's GPT model as judge.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef compute_llm_as_judge():\n    from adalflow.eval.llm_as_judge import LLMasJudge, DefaultLLMJudge\n    from adalflow.components.model_client import OpenAIClient\n\n    questions = [\n        \"Is Beijing in China?\",\n        \"Is Apple founded before Google?\",\n        \"Is earth flat?\",\n    ]\n    pred_answers = [\"Yes\", \"Yes, Appled is founded before Google\", \"Yes\"]\n    gt_answers = [\"Yes\", \"Yes\", \"No\"]\n\n    llm_judge = DefaultLLMJudge(\n        model_client=OpenAIClient(),\n        model_kwargs={\n            \"model\": \"gpt-4o\",\n            \"temperature\": 1.0,\n            \"max_tokens\": 10,\n        },\n    )\n    llm_evaluator = LLMasJudge(llm_judge=llm_judge)\n    print(llm_judge)\n    eval_rslt = llm_evaluator.compute(\n        questions=questions, gt_answers=gt_answers, pred_answers=pred_answers\n    )\n    print(eval_rslt)\n```\n\n----------------------------------------\n\nTITLE: Generating Schema for Custom DataClass\nDESCRIPTION: This snippet shows how to generate a schema for a custom DataClass, including options to exclude specific fields from the schema.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nschema = TrecData2.to_schema()\nschema\n\n# schema with exclude\nschema_exclude = TrecData2.to_schema(\n    exclude={\"TrecData2\": [\"metadata\"], \"Question\": [\"metadata\"]}\n)\nschema_exclude\n```\n\n----------------------------------------\n\nTITLE: Defining Parallel Function Call Template in Python\nDESCRIPTION: This snippet defines a template for parallel function calls. It includes a system message with available tools and an output format instruction for function calls.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nmultple_function_call_template = r\"\"\"<SYS>You have these tools available:\n{% if tools %}\n<TOOLS>\n{% for tool in tools %}\n{{ loop.index }}.\n{{tool}}\n------------------------\n{% endfor %}\n</TOOLS>\n{% endif %}\n<OUTPUT_FORMAT>\nHere is how you call one function.\n{{output_format_str}}\n-Always return a List using `[]` of the above JSON objects, even if its just one item.\n</OUTPUT_FORMAT>\n<SYS>\n{{input_str}}\nYou:\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring AdalFlow Logger for Debugging\nDESCRIPTION: This code snippet shows how to set up detailed logging for AdalFlow, which is useful for debugging and monitoring the training process.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils import get_logger\n\nget_logger(level=\"DEBUG\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Responsive Trace Graph Visualization with CSS and HTML\nDESCRIPTION: This code snippet defines the styling and structure for displaying the AdalFlow Trace Graph in a responsive iframe container. It includes CSS for the container layout, iframe positioning, and a placeholder for zoom controls.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/trace_graph.rst#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<style>\n.iframe-container {\n    width: 100%;\n    height: 100vh; /* Full height of the viewport */\n    max-height: 1000px; /* Maximum height to ensure it doesn't get too tall on larger screens */\n    overflow: hidden;\n    position: relative;\n}\n.iframe-container iframe {\n    width: 100%;\n    height: 100%;\n    border: none;\n}\n.zoom-controls {\n    position: absolute;\n    top: 10px;\n    right: 10px;\n    display: flex;\n    gap: 10px;\n}\n.zoom-controls button {\n    padding: 5px 10px;\n    cursor: pointer;\n}\n</style>\n\n<div class=\"iframe-container\">\n    <iframe srcdoc=\"\n        <html>\n        <body style='margin:0; padding:0;'>\n            <img id='zoomImage' src='../_static/images/trace_graph_sum.png' style='width:100%; height:auto; transform-origin: center center; transition: transform 0.25s ease;'>\n        </body>\n        </html>\n    \"></iframe>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Generating Schema for TrecData2 Class in Python\nDESCRIPTION: This snippet demonstrates how to generate and print the schema for the TrecData2 class using the to_schema() method. The schema includes detailed information about the class properties, their types, and required fields.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(TrecData2.to_schema())\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"TrecData2\",\n    \"properties\": {\n        \"question\": {\n            \"type\": \"{'type': 'Question', 'properties': {'question': {'type': 'str', 'desc': 'The question asked by the user'}, 'metadata': {'type': 'dict', 'desc': 'The metadata of the question'}}, 'required': ['question']}\",\n            \"desc\": \"The question asked by the user\",\n        },\n        \"label\": {\"type\": \"int\", \"desc\": \"The label of the question\"},\n        \"metadata\": {\"type\": \"dict\", \"desc\": \"The metadata of the question\"},\n    },\n    \"required\": [\"question\", \"metadata\"],\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Named Logger for Separate Application Logs\nDESCRIPTION: Shows how to create a named logger for application-specific logs, separate from library logs.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.logger import get_logger\n\napp_logger = get_logger(name=\"my_app\", level=\"DEBUG\", save_dir=\"./logs\") # log to ./logs/my_app.log\n\nclass Task:\n    def __init__(self):\n        app_logger.info(\"This is a user program child logger\")\n```\n\n----------------------------------------\n\nTITLE: Debug Mode Training for ObjectCountAdalComponent\nDESCRIPTION: Demonstrates how to run the training function in debug mode with specific parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ntrain(debug=True, max_steps=12, strategy=\"constrained\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Answer Parsing Function in Python\nDESCRIPTION: This function parses the integer answer from a string response using regular expressions. It's decorated to convert it into a component for use in the generator.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\nimport re\n\n@adal.func_to_component\ndef parse_integer_answer(answer: str):\n    \"\"\"A function that parses the last integer from a string using regular expressions.\"\"\"\n    try:\n        # Use regular expression to find all sequences of digits\n        numbers = re.findall(r\"\\d+\", answer)\n        if numbers:\n            # Get the last number found\n            answer = int(numbers[-1])\n        else:\n            answer = -1\n    except ValueError:\n        answer = -1\n\n    return answer\n```\n\n----------------------------------------\n\nTITLE: Implementing AdalComponent for Task Evaluation\nDESCRIPTION: Creates a custom AdalComponent implementation for object counting tasks with evaluation and task preparation methods.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.datasets.types import Example\nfrom adalflow.eval.answer_match_acc import AnswerMatchAcc\n\n\nclass ObjectCountAdalComponent(adal.AdalComponent):\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        task = ObjectCountTaskPipeline(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        super().__init__(task=task, eval_fn=eval_fn)\n\n    def prepare_task(self, sample: Example):\n        return self.task.call, {\"question\": sample.question, \"id\": sample.id}\n\n    def prepare_eval(self, sample: Example, y_pred: adal.GeneratorOutput) -> float:\n        y_label = -1\n        if (y_pred is not None and y_pred.data is not None):\n            y_label = y_pred.data\n        return self.eval_fn, {\"y\": y_label, \"y_gt\": sample.answer}\n```\n\n----------------------------------------\n\nTITLE: Defining DataClass in AdalFlow\nDESCRIPTION: Creates a custom DataClass that can be used with the DataClassParser. The class defines fields with metadata descriptions and specifies input and output fields for structured data handling.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass, field\nfrom adalflow.core import DataClass\n\n# no need to use Optional, when default is on, it is optional.\n@dataclass\nclass SampleDataClass(DataClass):\n    description: str = field(metadata={\"desc\": \"A sample description\"})\n    category: str = field(metadata={\"desc\": \"Category of the sample\"})\n    value: int = field(metadata={\"desc\": \"A sample integer value\"})\n    status: str = field(metadata={\"desc\": \"Status of the sample\"})\n\n    # input and output fields can work with DataClassParser\n    __input_fields__ = [\n        \"description\",\n        \"category\",\n    ]\n    __output_fields__ = [\"value\", \"status\"]\n```\n\n----------------------------------------\n\nTITLE: AdalFlow Training Output in Bash\nDESCRIPTION: This bash output shows the results of training the TREC classifier with AdalFlow. It displays the progress, evaluation metrics, and final checkpoint location.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/classification.rst#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nLoading Data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 144/144 [00:00<00:00, 51011.81it/s]\nEvaluating step(24): 0.8426 across 108 samples, Max potential: 0.8819:  75%|█████████████████████████████████████████████████████████████████████▊                       | 108/144 [00:00<00:00, 1855.48it/s]\nFail validation: 0.8348623853211009 <= 0.8819444444444444, revert\nTraining Step: 24: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [03:05<00:00, 15.46s/it]\nSaved ckpt to /Users/liyin/.adalflow/ckpt/TrecClassifierAdal/constrained_max_steps_12_848d2_run_7.json\nTraining time: 823.8977522850037s\n```\n\n----------------------------------------\n\nTITLE: Generating Response and Adding to Database in AdalFlow\nDESCRIPTION: This code snippet shows how to generate a response using the generator, create a new DialogTurn object, and add it to the database while applying a transformer.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nresponse = generator(prompt_kwargs={\"input_str\": input_str, \"chat_history_str\": chat_history_str})\nprint(response)\n\n# add the turn and apply the transformer\nnew_turn = DialogTurn(\n    user_query=UserQuery(query_str=input_str),\n    assistant_response=AssistantResponse(response_str=response.data),\n)\ndialog_turn_db.add(new_turn, apply_transformer=True)\n\nprint(dialog_turn_db.length, len(dialog_turn_db.transformed_items[key]))\n\n# 3 6\n```\n\n----------------------------------------\n\nTITLE: Batch Embedding Multiple Queries with OpenAI\nDESCRIPTION: Shows how to embed multiple queries in a single batch operation with the OpenAI embedder. This handles passing a list of strings to get their vector representations simultaneously.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\noutput = embedder(queries)\nprint(output.length, output.embedding_dim)\n# 100 256\n```\n\n----------------------------------------\n\nTITLE: Initializing ObjectCountAdalComponent in Python\nDESCRIPTION: This snippet defines the ObjectCountAdalComponent class, initializing it with model configurations, task pipeline, evaluation function, and loss function.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass ObjectCountAdalComponent(adal.AdalComponent):\n    def __init__(\n        self,\n        model_client: adal.ModelClient,\n        model_kwargs: Dict,\n        backward_engine_model_config: Dict,\n        teacher_model_config: Dict,\n        text_optimizer_model_config: Dict,\n    ):\n        task = ObjectCountTaskPipeline(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        loss_fn = adal.EvalFnToTextLoss(\n            eval_fn=eval_fn,\n            eval_fn_desc=\"exact_match: 1 if str(y) == str(y_gt) else 0\",\n        )\n        super().__init__(task=task, eval_fn=eval_fn, loss_fn=loss_fn)\n\n        self.backward_engine_model_config = backward_engine_model_config\n        self.teacher_model_config = teacher_model_config\n        self.text_optimizer_model_config = text_optimizer_model_config\n```\n\n----------------------------------------\n\nTITLE: Implementing AdalComponent for Evaluation\nDESCRIPTION: Implementation of ObjectCountAdalComponent class that extends AdalComponent for task pipeline evaluation with answer matching accuracy.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.eval.answer_match_acc import AnswerMatchAcc\n\nclass ObjectCountAdalComponent(adal.AdalComponent):\n    def __init__(self, model_client: adal.ModelClient, model_kwargs: Dict):\n        task = ObjectCountTaskPipeline(model_client, model_kwargs)\n        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n        super().__init__(task=task, eval_fn=eval_fn)\n\n    def handle_one_task_sample(self, sample: Example):\n        return self.task.call, {\"question\": sample.question, \"id\": sample.id}\n\n    def evaluate_one_sample(self, sample: Example, y_pred: adal.GeneratorOutput) -> float:\n        y_label = -1\n        if (y_pred is not None and y_pred.data is not None):\n            y_label = y_pred.data\n        return self.eval_fn(y=y_label, y_gt=sample.answer)\n```\n\n----------------------------------------\n\nTITLE: Accessing Question and Answer Pairs\nDESCRIPTION: Demonstrates how to access the question and answer fields from a dataset sample.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Each sample contains a question and a corresponding answer.\nprint(f\"question: {test_sample.get('question')}\")\nprint(f\"answer: {test_sample.get('answer')}\")\n```\n\n----------------------------------------\n\nTITLE: Setting Parameters for Text-Gradient Descent Training\nDESCRIPTION: Configures the system_prompt and few_shot_demos parameters for text-gradient descent training in the task pipeline.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=True,\n            param_type=ParameterType.PROMPT,\n        )\nfew_shot_demos = adal.Parameter(\n    data=None,\n    role_desc=\"To provide few shot demos to the language model\",\n    requires_opt=False,\n    param_type=ParameterType.DEMOS,\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Logger for AdalFlow in Python\nDESCRIPTION: Sets up the library logger for AdalFlow, defaulting to INFO level. This is useful for debugging and monitoring the library's operations.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/basic.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.logger import get_logger\n\nget_logger()\n```\n\n----------------------------------------\n\nTITLE: Trace Directory Structure for AdalFlow\nDESCRIPTION: Shows the directory structure created by the tracing feature to store log files. The logs are organized by project name with separate files for different types of traces.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging_tracing.rst#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n.\n├── traces\n│   ├── SimpleQA\n│   │   ├── generator_state_trace.json\n```\n\n----------------------------------------\n\nTITLE: Implementing Retry Logic for ColBERTv2 Requests in Python\nDESCRIPTION: This code snippet adds retry logic to the ColBERTv2 request function using the tenacity library. It includes error handling for timeouts and connection issues, and processes the response to return the top-k results.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/multi_hop_rag_opt.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\n@CacheMemory.cache\n@retry(\n    stop=stop_after_attempt(5),\n    wait=wait_exponential(multiplier=1, min=2, max=10),\n    reraise=True,\n)\ndef colbertv2_get_request_v2(url: str, query: str, k: int):\n    assert k <= 100, \"Only k <= 100 is supported for the hosted ColBERTv2 server.\"\n\n    payload = {\"query\": query, \"k\": k}\n\n    try:\n        res = requests.get(url, params=payload, timeout=10)\n        res.raise_for_status()\n        response_json = res.json()\n\n        # Check for an error in the response.\n        if response_json.get(\"error\"):\n            raise ConnectionError(f\"Error from server: {response_json['message']}\")\n\n        # If we get a valid 'topk' response, return immediately.\n        if \"topk\" in response_json:\n            topk = response_json[\"topk\"][:k]\n            return [{**d, \"long_text\": d[\"text\"]} for d in topk]\n\n    except requests.exceptions.Timeout:\n        raise TimeoutError(\"The request timed out. Please try again.\")\n    except requests.exceptions.RequestException as e:\n        raise ConnectionError(f\"Request failed: {e}\")\n\n    raise KeyError(\"'topk' key not found in the response.\")\n```\n\n----------------------------------------\n\nTITLE: Loading and Subsetting BigBenchHard Dataset for AdalFlow\nDESCRIPTION: Defines a function to load the BigBenchHard dataset and optionally limit the number of samples for each split (train, validation, test).\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.datasets.big_bench_hard import BigBenchHard\nfrom adalflow.utils.data import subset_dataset\n\ndef load_datasets(max_samples: int = None):\n    \"\"\"Load the dataset\"\"\"\n    train_data = BigBenchHard(split=\"train\")\n    val_data = BigBenchHard(split=\"val\")\n    test_data = BigBenchHard(split=\"test\")\n\n    # Limit the number of samples\n    if max_samples:\n        train_data = subset_dataset(train_data, max_samples)\n        val_data = subset_dataset(val_data, max_samples)\n        test_data = subset_dataset(test_data, max_samples)\n\n    return train_data, val_data, test_data\n```\n\n----------------------------------------\n\nTITLE: Setting Up Model Diagnosis Function\nDESCRIPTION: Implements a diagnosis function that initializes the AdalComponent with model configuration and datasets.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef diagnose(\n    model_client: adal.ModelClient,\n    model_kwargs: Dict,\n) -> Dict:\n    from use_cases.question_answering.bhh_object_count.data import load_datasets\n\n    trainset, valset, testset = load_datasets()\n\n    adal_component = ObjectCountAdalComponent(model_client, model_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Parsing Integer Answers from LLM Output\nDESCRIPTION: A function decorated with adal.func_to_data_component that extracts the last integer from a string using regular expressions, intended to process model outputs that end with 'Answer: $VALUE'.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\nimport re\n\n@adal.func_to_data_component\ndef parse_integer_answer(answer: str):\n    \"\"\"A function that parses the last integer from a string using regular expressions.\"\"\"\n    try:\n        # Use regular expression to find all sequences of digits\n        numbers = re.findall(r\"\\d+\", answer)\n        if numbers:\n            # Get the last number found\n            answer = int(numbers[-1])\n        else:\n            answer = -1\n    except ValueError:\n        answer = -1\n\n    return answer\n```\n\n----------------------------------------\n\nTITLE: Running the GitHub Chat RAG Application\nDESCRIPTION: Bash commands for launching either the web interface (app.py) or the repository analysis tool (app_repo.py) using Streamlit.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/rag_with_memory.rst#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Web interface\npoetry run streamlit run app.py\n\n# Repository analysis\npoetry run streamlit run app_repo.py\n```\n\n----------------------------------------\n\nTITLE: Defining Tracing Module Structure with reStructuredText\nDESCRIPTION: This RST code defines the structure and navigation for the tracing module documentation. It includes an autosummary section listing the three main components and a hidden toctree for navigation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/apis/tracing/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. _apis-tracing:\n\nTracing\n==============\n\nOverview\n----------\n.. autosummary::\n\n   tracing.decorators\n   tracing.generator_state_logger\n   tracing.generator_call_logger\n\n\n.. toctree::\n   :maxdepth: 2\n   :hidden:\n\n   tracing.decorators\n   tracing.generator_state_logger\n   tracing.generator_call_logger\n```\n\n----------------------------------------\n\nTITLE: Implementing G-eval Text Evaluation Function in Python\nDESCRIPTION: Function that computes G-eval scores for text summarization using GPT-4. Evaluates the quality of generated summaries against source text across multiple criteria including relevance, fluency, consistency and coherence. Uses a template-based approach for input formatting.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef compute_g_eval_summarization(source, summary):\n    from adalflow.eval.g_eval import GEvalLLMJudge, GEvalJudgeEvaluator, NLGTask\n\n    model_kwargs = {\n        \"model\": \"gpt-4o\",\n        \"n\": 20,\n        \"top_p\": 1,\n        \"max_tokens\": 5,\n        \"temperature\": 1,\n    }\n\n    g_eval = GEvalLLMJudge(\n        default_task=NLGTask.SUMMARIZATION, model_kwargs=model_kwargs\n    )\n    print(g_eval)\n    input_template = \"\"\"Source Document: {source}\n    Summary: {summary}\n    \"\"\"\n\n    input_str = input_template.format(\n        source=source,\n        summary=summary,\n    )\n\n    g_evaluator = GEvalJudgeEvaluator(llm_judge=g_eval)\n\n    response = g_evaluator(input_strs=[input_str])\n    print(f\"response: {response}\")\n```\n\n----------------------------------------\n\nTITLE: Customizing Generator Template in Python\nDESCRIPTION: Demonstrates how to create a custom template for the Generator. In this example, the template sets up an AI assistant with a sense of humor.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/basic.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntemplate = \"\"\"<SYS> Your are an assistant with a great sense of humor.</SYS> User: {{input_str}}. You:\"\"\"\n\ngenerator2 = Generator(\n    model_client=OpenAIClient(), model_kwargs=model_kwargs, template=template\n)\nresponse = generator2(prompt_kwargs=prompt_kwargs)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Displaying Structured Output in Python\nDESCRIPTION: Shows how to print the structured output from the pipeline, which includes the generated data, potential errors, and metadata. This helps in tracking and debugging the LLM workflow.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/README.md#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nGeneratorOutput(data=QAOutput(explanation='LLM stands for Large Language Model, which refers to a type of artificial intelligence designed to process and generate human-like language.', example='For instance, LLMs are used in chatbots and virtual assistants, such as Siri and Alexa, to understand and respond to natural language input.'), error=None, usage=None, raw_response='```\\n{\\n  \"explanation\": \"LLM stands for Large Language Model, which refers to a type of artificial intelligence designed to process and generate human-like language.\",\\n  \"example\": \"For instance, LLMs are used in chatbots and virtual assistants, such as Siri and Alexa, to understand and respond to natural language input.\"\\n}', metadata=None)\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Dataset Functions\nDESCRIPTION: Implements dataset loading functionality with support for train, validation, and test splits, including optional sample size limiting.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.datasets.big_bench_hard import BigBenchHard\nfrom adalflow.utils.data import subset_dataset\n\ndef load_datasets(max_samples: int = None):\n    \"\"\"Load the dataset\"\"\"\n    train_data = BigBenchHard(split=\"train\")\n    val_data = BigBenchHard(split=\"val\")\n    test_data = BigBenchHard(split=\"test\")\n\n    # Limit the number of samples\n    if max_samples:\n        train_data = subset_dataset(train_data, max_samples)\n        val_data = subset_dataset(val_data, max_samples)\n        test_data = subset_dataset(test_data, max_samples)\n\n    return train_data, val_data, test_data\n```\n\n----------------------------------------\n\nTITLE: Saving and Reloading LocalDB State in Python\nDESCRIPTION: This snippet demonstrates how to save the state of a dialog turn database to a file and reload it. It also shows how to verify if the reloaded database is identical to the original one.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndialog_turn_db.save_state(filepath='.storage/dialog_turns.pkl')\nreloaded_dialog_turn_db = LocalDB.load_state(filepath='.storage/dialog_turns.pkl')\nprint(str(dialog_turn_db.__dict__) == str(restored_dialog_turn_db.__dict__))\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Processing Pipeline\nDESCRIPTION: This code defines functions to prepare the data processing pipeline and initialize the database with an index. It includes text splitting, embedding, and document transformation steps.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef prepare_data_pipeline():\n    splitter = TextSplitter(**configs[\"text_splitter\"])\n    embedder = Embedder(\n        model_client=ModelClientType.OPENAI(),\n        model_kwargs=configs[\"embedder\"][\"model_kwargs\"],\n    )\n    embedder_transformer = ToEmbeddings(\n        embedder=embedder, batch_size=configs[\"embedder\"][\"batch_size\"]\n    )\n    data_transformer = Sequential(splitter, embedder_transformer)\n    return data_transformer\n\n\ndef prepare_database_with_index(\n    docs: List[Document],\n    index_file: str = \"index.faiss\",\n    index_path: Optional[str] = None,\n):\n    index_path = index_path or get_adalflow_default_root_path()\n    index_path = os.path.join(index_path, index_file)\n    if os.path.exists(index_path):\n        return None\n    db = LocalDB()\n    db.load(docs)\n    data_transformer = prepare_data_pipeline()\n    db.transform(transformer=data_transformer, key=\"data_transformer\")\n    db.save_state(index_path)\n```\n\n----------------------------------------\n\nTITLE: Sample DataClass Examples Generation\nDESCRIPTION: Shows how to create sample DataClass instances and convert them to a formatted string representation using a parser's get_examples_str method.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/parser.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nsamples = [\n    SampleDataClass(\n        description=\"Sample description\",\n        category=\"Sample category\",\n        value=100,\n        status=\"active\",\n    ),\n    SampleDataClass(\n        description=\"Another description\",\n        category=\"Another category\",\n        value=200,\n        status=\"inactive\",\n    ),\n]\n\nexamples_str = parser.get_examples_str(examples=samples)\nprint(examples_str)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Output Processor to Reduce Embedding Dimensions\nDESCRIPTION: Implements a custom DataComponent for post-processing embedding outputs. This component reduces the embedding dimension from a larger size to a smaller one and optionally normalizes the vectors.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.types import Embedding, EmbedderOutput\nfrom adalflow.core.functional import normalize_vector\nfrom typing import List\nfrom adalflow.core.component import DataComponent\nfrom copy import deepcopy\n\nclass DecreaseEmbeddingDim(DataComponent):\n    def __init__(self, old_dim: int, new_dim: int,  normalize: bool = True):\n        super().__init__()\n        self.old_dim = old_dim\n        self.new_dim = new_dim\n        self.normalize = normalize\n        assert self.new_dim < self.old_dim, \"new_dim should be less than old_dim\"\n\n    def call(self, input: List[Embedding]) -> List[Embedding]:\n        output: EmbedderOutput = deepcopy(input)\n        for embedding in output.data:\n            old_embedding = embedding.embedding\n            new_embedding = old_embedding[: self.new_dim]\n            if self.normalize:\n                new_embedding = normalize_vector(new_embedding)\n            embedding.embedding = new_embedding\n        return output.data\n\n    def _extra_repr(self) -> str:\n        repr_str = f\"old_dim={self.old_dim}, new_dim={self.new_dim}, normalize={self.normalize}\"\n        return repr_str\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow via pip\nDESCRIPTION: Basic installation command for the AdalFlow package using pip package manager\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U adalflow\n```\n\n----------------------------------------\n\nTITLE: LLM Judge Evaluation Without Question Context in Python\nDESCRIPTION: Implementation of an LLM-based evaluator that focuses on semantic similarity between prediction and ground truth without question context. Uses a custom judgment query to determine if answers have the same meaning.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef compute_llm_as_judge_wo_questions():\n    from adalflow.eval.llm_as_judge import LLMasJudge, DefaultLLMJudge\n    from adalflow.components.model_client import OpenAIClient\n\n\n    llm_judge = DefaultLLMJudge(\n        model_client=OpenAIClient(),\n        model_kwargs={\n            \"model\": \"gpt-4o\",\n            \"temperature\": 1.0,\n            \"max_tokens\": 10,\n        },\n        jugement_query=\"Does the predicted answer means the same as the ground truth answer? Say True if yes, False if no.\",\n    )\n    llm_evaluator = LLMasJudge(llm_judge=llm_judge)\n    print(llm_judge)\n    eval_rslt = llm_evaluator.compute(gt_answers=[gt], pred_answers=[pred])\n    print(eval_rslt)\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure - Training Components\nDESCRIPTION: ReStructuredText documentation defining the structure and relationships between key training components including TextOptimizer, AdalComponent, and Trainer classes.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n   :caption: Training - Classes\n   :hidden:\n\n  ..  parameter\n  ..  optimizer\n  ..  few_shot_optimizer\n  ..  auto_text_grad\n  ..  adalcomponent\n  ..  trainer\n\n   trace_graph\n```\n\n----------------------------------------\n\nTITLE: Initializing LanceDBRetriever in Python\nDESCRIPTION: This code shows how to initialize a LanceDBRetriever with an embedder, dimensionality settings, database location, and retrieval parameters. The retriever is set up for efficient vector-based document retrieval using LanceDB.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.retriever import LanceDBRetriever\nretriever = LanceDBRetriever(embedder=embedder, dimensions=256, db_uri=\"/tmp/lancedb\", top_k=2)\n\nprint(retriever)\n```\n\n----------------------------------------\n\nTITLE: Generating JSON Signature for TrecData2 Class in Python\nDESCRIPTION: This code snippet shows how to generate and print the JSON signature for the TrecData2 class using the to_json_signature() method. The signature provides a concise representation of the class structure, including field types and requirements.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(TrecData2.to_json_signature())\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"question\": \"The question asked by the user ({'type': 'Question', 'properties': {'question': {'type': 'str', 'desc': 'The question asked by the user'}, 'metadata': {'type': 'dict', 'desc': 'The metadata of the question'}}, 'required': ['question']}) (required)\",\n    \"label\": \"The label of the question (int) (optional)\",\n    \"metadata\": \"The metadata of the question (dict) (required)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieve Top K Documents\nDESCRIPTION: Retrieves the most relevant documents based on the input string using the retriever\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntop_k_documents = retriever(input=input_str)\nprint(top_k_documents)\n```\n\n----------------------------------------\n\nTITLE: Configuring Parameters for Text-Gradient Descent Training in Python\nDESCRIPTION: Sets up system_prompt and few_shot_demos parameters for text-gradient descent training in AdalFlow. The system_prompt is set for optimization while few_shot_demos is not.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=True,\n            param_type=ParameterType.PROMPT,\n        )\nfew_shot_demos = adal.Parameter(\n    data=None,\n    role_desc=\"To provide few shot demos to the language model\",\n    requires_opt=False,\n    param_type=ParameterType.DEMOS,\n)\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI API Key for GitHub Chat\nDESCRIPTION: Bash commands for creating the Streamlit secrets directory and configuring the OpenAI API key required for the application.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/rag_with_memory.rst#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p .streamlit\necho 'OPENAI_API_KEY = \"your-key-here\"' > .streamlit/secrets.toml\n```\n\n----------------------------------------\n\nTITLE: Defining Custom DataClasses for Question and TrecData in Python\nDESCRIPTION: This snippet defines two dataclasses, Question and TrecData, using Python's dataclass decorator. It demonstrates the use of field metadata and default factories.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass, field\n\n\n@dataclass\nclass Question:\n    question: str = field(metadata={\"desc\": \"The question asked by the user\"})\n    metadata: dict = field(\n        metadata={\"desc\": \"The metadata of the question\"}, default_factory=dict\n    )\n\n\n@dataclass\nclass TrecData:\n    question: Question = field(\n        metadata={\"desc\": \"The question asked by the user\"}\n    )  # Required field, you have to provide the question field at the instantiation\n    label: int = field(\n        metadata={\"desc\": \"The label of the question\"}, default=0\n    )  # Optional field\n```\n\n----------------------------------------\n\nTITLE: AdalFlow Components Module Structure in RST\nDESCRIPTION: ReStructuredText markup defining the structure of the components module, including agents, model clients, data processing, reasoning, retriever and output parser submodules.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/apis/index.rst#2025-04-14_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n\n   components.agent.react\n\n   components.model_client.anthropic_client\n   components.model_client.cohere_client\n   components.model_client.google_client\n   components.model_client.groq_client\n   components.model_client.openai_client\n   components.model_client.transformers_client\n   components.model_client.utils\n\n   components.data_process.data_components\n   components.data_process.text_splitter\n\n   components.reasoning.chain_of_thought\n\n   components.retriever.bm25_retriever\n   components.retriever.faiss_retriever\n   components.retriever.llm_retriever\n   components.retriever.postgres_retriever\n   components.retriever.reranker_retriever\n\n   components.output_parsers.outputs\n```\n\n----------------------------------------\n\nTITLE: Building Document Index for Reranker\nDESCRIPTION: Shows how to build a document index for the reranker retriever using document content. The code includes document mapping and index building functionality.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndocument_map_func = lambda x: x[\"content\"]\nreranker.build_index_from_documents(documents=documents, document_map_func=document_map_func)\n\noutput_1 = reranker(input=query_1)\noutput_2 = reranker(input=query_2)\noutput_3 = reranker(input = [query_1, query_2])\n```\n\n----------------------------------------\n\nTITLE: Defining Weather Function in Python\nDESCRIPTION: Defines a function to get current weather for a given location, with optional unit parameter. The function returns mock data for specific cities.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/tool_helper.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef get_current_weather(location, unit=\"fahrenheit\"):\n    \"\"\"Get the current weather in a given location\"\"\"\n    import json\n\n    if \"tokyo\" in location.lower():\n        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n    elif \"san francisco\" in location.lower():\n        return json.dumps(\n            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n        )\n    elif \"paris\" in location.lower():\n        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n    else:\n        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n```\n\n----------------------------------------\n\nTITLE: Dataset Loading Implementation\nDESCRIPTION: Function to load and subset BigBenchHard dataset for training, validation and testing\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.datasets.big_bench_hard import BigBenchHard\nfrom adalflow.utils.data import subset_dataset\n\ndef load_datasets(max_samples: int = None):\n    \"\"\"Load the dataset\"\"\"\n    train_data = BigBenchHard(split=\"train\")\n    val_data = BigBenchHard(split=\"val\")\n    test_data = BigBenchHard(split=\"test\")\n\n    # Limit the number of samples\n    if max_samples:\n        train_data = subset_dataset(train_data, max_samples)\n        val_data = subset_dataset(val_data, max_samples)\n        test_data = subset_dataset(test_data, max_samples)\n\n    return train_data, val_data, test_data\n```\n\n----------------------------------------\n\nTITLE: Using LocalDB for In-Memory CRUD Operations\nDESCRIPTION: Sets up a LocalDB instance for storing and managing dialog turns, including data transformation and state persistence.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# create a db for the dialog_turns\nfrom adalflow.core.db import LocalDB\n\ndialog_turn_db = LocalDB(\"dialog_turns\")\nprint(dialog_turn_db)\n\ndialog_turn_db.load(dialog_turns)\nprint(dialog_turn_db)\n```\n\nLANGUAGE: python\nCODE:\n```\n# apply data transformation to the dialog_turn_db\n\nkey = \"split_and_embed\"\ndialog_turn_db.transform(data_transformer, map_fn=map_dialogturn_to_document, key=key)\nprint(dialog_turn_db.transformed_items[key])\nprint(dialog_turn_db.transformer_setups[key])\nprint(dialog_turn_db.mapper_setups[key])\n```\n\nLANGUAGE: python\nCODE:\n```\n# save the state of the dialog_turn_db\ndialog_turn_db.save_state(\"dialog_turn_db_state.pkl\")\n\nprint(dialog_turn_db)\n```\n\nLANGUAGE: python\nCODE:\n```\n# restore the state of the restored_dialog_turn_db\nrestored_dialog_turn_db = LocalDB.load_state(\"dialog_turn_db_state.pkl\")\nprint(restored_dialog_turn_db)\n```\n\nLANGUAGE: python\nCODE:\n```\n# check if the restored_dialog_turn_db is the same as the dialog_turn_db\n\nprint(str(dialog_turn_db.__dict__) == str(restored_dialog_turn_db.__dict__))\n```\n\n----------------------------------------\n\nTITLE: Setting Up Function Output Format and Generator\nDESCRIPTION: Configures a Generator with a model client, prompt template, and output parser for processing function calls.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_function_calls.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.generator import Generator\nfrom adalflow.core.types import ModelClientType\n\nmodel_kwargs = {\"model\": \"gpt-4o-mini\"}\nprompt_kwargs = {\n    \"tools\": tool_manager.yaml_definitions,\n    \"output_format_str\": func_parser.format_instructions(),\n}\ngenerator = Generator(\n    model_client=ModelClientType.OPENAI(),\n    model_kwargs=model_kwargs,\n    template=template,\n    prompt_kwargs=prompt_kwargs,\n    output_processors=func_parser,\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Song Review Template in Python\nDESCRIPTION: Creates a template string for song review generation with system and user prompts.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsong_review_template = r\"\"\"<SYS>\nYou are a professional song critic. Analyze the given song and provide a detailed review.\n<OUTPUT_FORMAT>\n{{output_format_str}}\n</OUTPUT_FORMAT>\n</SYS>\n<USER> Review this song: {{song_title}} </USER>\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Handling JSON-related Error in Python Training Script\nDESCRIPTION: This code snippet demonstrates an error that occurs when loading a JSON Lines file during training. It suggests cleaning the content of the problematic file as a solution to resolve the issue and continue training.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/multi_hop_rag_opt.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nError loading jsonl file /Users/liyin/.adalflow/ckpt/MultiHopRAGAdal/diagnose_train/llm_call.jsonl: line contains invalid json: unexpected content after document: line 1 column 8568 (char 8567) (line 62)\nTraceback (most recent call last):\nFile \"/Users/liyin/Documents/test/LightRAG/benchmarks/hotpot_qa/adal_exp/train_multi_hop_rag.py\", line 153, in <module>\n    train_diagnose(**gpt_3_model)\nFile \"/Users/liyin/Documents/test/LightRAG/benchmarks/hotpot_qa/adal_exp/train_multi_hop_rag.py\", line 97, in train_diagnose\n    trainer.diagnose(dataset=trainset, split=\"train\")\nFile \"/Users/liyin/Documents/test/LightRAG/adalflow/adalflow/optim/trainer/trainer.py\", line 228, in diagnose\n    sorted_logs = [logs_dict[id] for id in sorted_ids]\n                ~~~~~~~~~^^^^\nKeyError: '5a8b57f25542995d1e6f1371'\n```\n\n----------------------------------------\n\nTITLE: Embedding a Single Query with OpenAI\nDESCRIPTION: Demonstrates how to embed a single query string and access the output properties. The code shows how to check the embedding length, dimension, and normalization status.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\noutput = embedder(query)\nprint(output.length, output.embedding_dim, output.is_normalized)\n# 1 256 True\n```\n\n----------------------------------------\n\nTITLE: Handling Loss Sample in ObjectCountAdalComponent\nDESCRIPTION: Implements the handle_one_loss_sample method in ObjectCountAdalComponent. It prepares the ground truth parameter and sets the evaluation input for the prediction.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef handle_one_loss_sample(self, sample: Example, pred: adal.Parameter):\n    # prepare gt parameter\n    y_gt = adal.Parameter(\n        name=\"y_gt\",\n        data=sample.answer,\n        eval_input=sample.answer,\n        requires_opt=False,\n    )\n\n    # pred's full_response is the output of the task pipeline which is GeneratorOutput\n    pred.eval_input = pred.full_response.data\n    return self.loss_fn, {\"kwargs\": {\"y\": pred, \"y_gt\": y_gt}}\n```\n\n----------------------------------------\n\nTITLE: File Structure for Diagnostics\nDESCRIPTION: Shows the directory structure for diagnostic outputs including checkpoints and evaluation results.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n.adalflow/\n├── ckpt/\n│   └── ObjectCountAdalComponent/\n│       ├── diagnose_{train, val, test}/  # Directory for training data diagnostics\n│       │   ├── llm_counter_call.jsonl    # Sorted by score from lowest to highest\n│       │   ├── logger_metadata.jsonl\n│       │   ├── llm_counter_diagnose.json # Contains samples with score < 0.5, sorted by score\n│       │   └── stats.json\n```\n\n----------------------------------------\n\nTITLE: Defining AdalFlow File Structure\nDESCRIPTION: This snippet outlines the file structure for AdalFlow, including directories for checkpoints, diagnostics, and various JSON files containing model performance data and statistics.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n.adalflow/\n├── ckpt/\n│   └── ObjectCountAdalComponent/\n│       ├── diagnose_{train, val, test}/  # Directory for training data diagnostics\n│       │   ├── llm_counter_call.jsonl    # Sorted by score from lowest to highest\n│       │   ├── logger_metadata.jsonl\n│       │   ├── llm_counter_diagnose.json # Contains samples with score < 0.5, sorted by score\n│       │   └── stats.json\n```\n\n----------------------------------------\n\nTITLE: Defining Mapping Functions for Data Transformation\nDESCRIPTION: Defines functions to map original data structures to Document objects for processing in the pipeline.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# prepare mapping functions to map the data to Document object for the pipeline\n\nfrom typing import Dict\n\n\n# mapping function for org_documents\ndef map_to_document(doc: Dict) -> Document:\n    return Document(text=doc[\"content\"], meta_data={\"title\": doc[\"title\"]})\n\n\ndef map_dialogturn_to_document(turn: DialogTurn) -> Document:\n    # it can be important to keep the original data's id\n    return Document(\n        id=turn.id,\n        text=turn.user_query.query_str + \" \" + turn.assistant_response.response_str,\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing Artist DataClass in Python\nDESCRIPTION: Defines an Artist data class for storing artist information including name and role in the song.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass Artist(adal.DataClass):\n    name: str = field(metadata={\"desc\": \"Artist's full name\"})\n    role: str = field(metadata={\"desc\": \"Artist's role in the song\"})\n```\n\n----------------------------------------\n\nTITLE: Evaluating React Agent without Tools using Python\nDESCRIPTION: Similar evaluation implementation but without tools, using only the base LLM capabilities. Used to compare performance between tool-enabled and tool-disabled scenarios.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.eval.answer_match_acc import AnswerMatchAcc\n\n# set up evaluation type\nEM_evaluator = AnswerMatchAcc(type=\"exact_match\")\nFM_evaluator = AnswerMatchAcc(type=\"fuzzy_match\")\n\nagent = ReActAgent(\n    max_steps=7, model_client=OpenAIClient(), model_kwargs=gpt_model_kwargs\n)\n\nnum_questions = 10\ngt_answers = []\npred_answers = []\nstart_time = time.time()\nfor i in range(num_questions):\n    question = val_dataset[i][\"question\"]\n    gt_answer = normalize_answer(\n        val_dataset[i][\"answer\"]\n    )  # normalize the ground truth answer\n    gt_answers.append(gt_answer)\n\n    # get the agent's response\n    pred_answer = agent(question)\n    pred_answer = normalize_answer(pred_answer)\n    pred_answers.append(pred_answer)\n\n    printc(\n        f\"No. {i+1}, question: {question}, ground truth: {gt_answer}, pred answer: {pred_answer}\",\n        color=\"yellow\",\n    )\n\nend_time = time.time()\n\nem = EM_evaluator.compute(pred_answers=pred_answers, gt_answers=gt_answers)\nfm = FM_evaluator.compute(pred_answers=pred_answers, gt_answers=gt_answers)\navg_time = (end_time - start_time) / num_questions\n\nprint(f\"EM = {em}, FM = {fm}, average time = {avg_time}\")\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Dataset\nDESCRIPTION: Functions to load and process datasets from BigBenchHard, including train, validation, and test splits with optional sample limiting.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.datasets.big_bench_hard import BigBenchHard\nfrom adalflow.datasets.types import Example\nfrom adalflow.utils.data import subset_dataset\n\ndef load_datasets(max_samples: int = None):\n    \"\"\"Load the dataset\"\"\"\n    train_data = BigBenchHard(split=\"train\")\n    val_data = BigBenchHard(split=\"val\")\n    test_data = BigBenchHard(split=\"test\")\n\n    # Limit the number of samples\n    if max_samples:\n        train_data = subset_dataset(train_data, max_samples)\n        val_data = subset_dataset(val_data, max_samples)\n        test_data = subset_dataset(test_data, max_samples)\n\n    return train_data, val_data, test_data\n```\n\n----------------------------------------\n\nTITLE: Implementing QA Component for LLM-based Question Answering in Python\nDESCRIPTION: This snippet creates a QA class inheriting from AdalFlow's Component. It sets up a Generator with GroqAPIClient, defines a template, and implements call methods for synchronous and asynchronous operations.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/README.md#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass QA(Component):\n    def __init__(self):\n        super().__init__()\n\n        parser = JsonOutputParser(data_class=QAOutput, return_data_class=True)\n        self.generator = Generator(\n            model_client=GroqAPIClient(),\n            model_kwargs={\"model\": \"llama3-8b-8192\"},\n            template=qa_template,\n            prompt_kwargs={\"output_format_str\": parser.format_instructions()},\n            output_processors=parser,\n        )\n\n    def call(self, query: str):\n        return self.generator.call({\"input_str\": query})\n\n    async def acall(self, query: str):\n        return await self.generator.acall({\"input_str\": query})\n```\n\n----------------------------------------\n\nTITLE: Running Specific Test File\nDESCRIPTION: Command to run a specific test file using pytest.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribute_to_code.rst#2025-04-14_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npytest tests/test_components.py\n```\n\n----------------------------------------\n\nTITLE: AdalFlow Directory Structure in Bash\nDESCRIPTION: This snippet shows the directory structure created by AdalFlow during training and debugging.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n.adalflow/\n├── ckpt/\n│   └── ObjectCountAdalComponent/\n│       ├── diagnose_{train, val, test}/  # Directory for training data diagnostics\n│       │   ├── llm_counter_call.jsonl    # Sorted by score from lowest to highest\n│       │   ├── logger_metadata.jsonl\n│       │   ├── llm_counter_diagnose.json # Contains samples with score < 0.5, sorted by score\n│       │   └── stats.json\n│       ├── debug_text_grads                          # Directory for debug mode with text optimizer\n│       │   ├── lib.log                    # Log file\n│       │   ├── trace_graph_sum.png       # Trace graph with textual feedback and new proposed value\n│       │   ├── trace_graph_sum_root.json # Json representation of the root loss node (sum of the success and fail loss)\n```\n\n----------------------------------------\n\nTITLE: Example Usage of G-eval with News Article Text\nDESCRIPTION: Example showing how to use the G-eval function with a sample news article about Paul Merson and Andros Townsend as source text and its summary. Demonstrates practical application of the evaluation function with real-world content.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nsource = (\n    \"Paul Merson has restarted his row with Andros Townsend after the Tottenham midfielder was brought on with only seven minutes remaining in his team 's 0-0 draw with Burnley on Sunday . 'Just been watching the game , did you miss the coach ? # RubberDub # 7minutes , ' Merson put on Twitter . Merson initially angered Townsend for writing in his Sky Sports column that 'if Andros Townsend can get in ( the England team ) then it opens it up to anybody . ' Paul Merson had another dig at Andros Townsend after his appearance for Tottenham against Burnley Townsend was brought on in the 83rd minute for Tottenham as they drew 0-0 against Burnley Andros Townsend scores England 's equaliser in their 1-1 friendly draw with Italy in Turin on Tuesday night The former Arsenal man was proven wrong when Townsend hit a stunning equaliser for England against Italy and he duly admitted his mistake . 'It 's not as though I was watching hoping he would n't score for England , I 'm genuinely pleased for him and fair play to him \\u00e2\\u20ac\\u201c it was a great goal , ' Merson said . 'It 's just a matter of opinion , and my opinion was that he got pulled off after half an hour at Manchester United in front of Roy Hodgson , so he should n't have been in the squad . 'When I 'm wrong , I hold my hands up . I do n't have a problem with doing that - I 'll always be the first to admit when I 'm wrong . ' Townsend hit back at Merson on Twitter after scoring for England against Italy Sky Sports pundit Merson ( centre ) criticised Townsend 's call-up to the England squad last week Townsend hit back at Merson after netting for England in Turin on Wednesday , saying 'Not bad for a player that should be 'nowhere near the squad ' ay @ PaulMerse ? ' Any bad feeling between the pair seemed to have passed but Merson was unable to resist having another dig at Townsend after Tottenham drew at Turf Moor .\",\n)\nsummary = (\n    \"Paul merson was brought on with only seven minutes remaining in his team 's 0-0 draw with burnley . Andros townsend scored the tottenham midfielder in the 89th minute . Paul merson had another dig at andros townsend after his appearance . The midfielder had been brought on to the england squad last week . Click here for all the latest arsenal news news .\",\n)\n\ncompute_g_eval_summarization(source=source, summary=summary)\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Embedder in Python\nDESCRIPTION: Sets up an Embedder using OpenAI's API client with specific model parameters for text embedding.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/embedder.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.components.model_client import OpenAIClient\nfrom adalflow.utils import setup_env\n\nmodel_kwargs = {\n    \"model\": \"text-embedding-3-small\",\n    \"dimensions\": 256,\n    \"encoding_format\": \"float\",\n}\n\nquery = \"What is the capital of China?\"\n\nqueries = [query] * 100\n\n\nembedder = Embedder(model_client=OpenAIClient(), model_kwargs=model_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Data Pipeline for Document Processing\nDESCRIPTION: Creates a data pipeline using DocumentSplitter and ToEmbeddings components to process and embed documents.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# prepare the data pipeline\n\nfrom adalflow.core.embedder import Embedder\nfrom adalflow.core.types import ModelClientType\nfrom adalflow.components.data_process import DocumentSplitter, ToEmbeddings\nfrom adalflow.core.component import Sequential\n\n\nmodel_kwargs = {\n    \"model\": \"text-embedding-3-small\",\n    \"dimensions\": 256,\n    \"encoding_format\": \"float\",\n}\n\nsplitter_config = {\"split_by\": \"word\", \"split_length\": 50, \"split_overlap\": 10}\n\nsplitter = DocumentSplitter(**splitter_config)\nembedder = Embedder(model_client=ModelClientType.OPENAI(), model_kwargs=model_kwargs)\nembedder_transformer = ToEmbeddings(embedder, batch_size=2)\ndata_transformer = Sequential(splitter, embedder_transformer)\nprint(data_transformer)\n```\n\n----------------------------------------\n\nTITLE: Uninstalling and Reinstalling HTTP Libraries in Python\nDESCRIPTION: This snippet uninstalls httpx and anyio, then reinstalls specific versions of these libraries to ensure compatibility.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_logger.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip uninstall httpx anyio -y\n!pip install \"anyio>=3.1.0,<4.0\"\n!pip install httpx==0.24.1\n```\n\n----------------------------------------\n\nTITLE: Describing ReAct Agent Capabilities in Markdown\nDESCRIPTION: This snippet outlines the capabilities of ReAct agents, including multi-hop reasoning and flexible tool usage for various tasks.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/adalflow/components/agent/README.md#2025-04-14_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n# REact agent can be useful for\n# - Multi-hop reasoning [Q&A], including dividing the query into subqueries and answering them one by one.\n# - Plan the usage of the given tools: highly flexible. Retriever, Generator modules or any other functions can all be wrapped as tools.\n```\n\n----------------------------------------\n\nTITLE: Embedding Class Hierarchy Visualization with HTML\nDESCRIPTION: HTML markup that creates a responsive container for embedding the class hierarchy visualization. The iframe loads the class hierarchy visualization from a relative path in the static files directory.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/class_hierarchy.rst#2025-04-14_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"iframe-container\">\n    <iframe src=\"../_static/class_hierarchy.html\"></iframe>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Setting Up Generator for Dynamic Conversation\nDESCRIPTION: Initializes a Generator for producing responses in a conversational context using a language model.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# prepare the generator for the dialog turns\n\nfrom adalflow.core import Generator\n\nllm_kwargs = {\"model\": \"gpt-3.5-turbo\"}\n\n# we will use the default prompt, and using input_str and chat_history_str for the final prompt\ngenerator = Generator(model_client=ModelClientType.OPENAI(), model_kwargs=llm_kwargs)\nprint(generator)\n```\n\n----------------------------------------\n\nTITLE: Defining Demo Parameter Fields for Few-Shot Learning in Python\nDESCRIPTION: Shows the structure of a demo parameter for few-shot learning, including field definitions for parameter type, optimization requirements, alias, data storage, and trace tracking.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/optimizer.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nparam_type = ParameterType.DEMOS\nrequires_opt = True\nalias = \"few_shot_demos\"\ndata = None\nrole_desc = \"To provide few shot demos to the language model\"\n_traces: Dict[str, DataClass] = {} # teacher mode traces\n_score: float = 0.0  # end to end score, used for once-off parameter such as y_pred, or any intermedia component output to have the score\n```\n\n----------------------------------------\n\nTITLE: Using DataClassFormatType for TrecData2 Class Formatting in Python\nDESCRIPTION: This snippet shows how to use the DataClassFormatType enum to specify different format types when generating string representations of the TrecData2 class. It demonstrates JSON signature, YAML signature, and schema formats.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import DataClassFormatType\n\njson_signature = TrecData2.format_class_str(DataClassFormatType.SIGNATURE_JSON)\nprint(json_signature)\n\nyaml_signature = TrecData2.format_class_str(DataClassFormatType.SIGNATURE_YAML)\nprint(yaml_signature)\n\nschema = TrecData2.format_class_str(DataClassFormatType.SCHEMA)\nprint(schema)\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Dependencies\nDESCRIPTION: Installation of adalflow package and required dependencies using pip\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install adalflow[openai,groq,faiss-cpu]\n```\n\n----------------------------------------\n\nTITLE: Configuring Parameters for Text-Gradient Descent in Python\nDESCRIPTION: This snippet shows how to configure the system prompt and few-shot demos parameters for text-gradient descent training.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = adal.Parameter(\n            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n            role_desc=\"To give task instruction to the language model in the system prompt\",\n            requires_opt=True,\n            param_type=ParameterType.PROMPT,\n        )\nfew_shot_demos = adal.Parameter(\n    data=None,\n    role_desc=\"To provide few shot demos to the language model\",\n    requires_opt=False,\n    param_type=ParameterType.DEMOS,\n)\n```\n\n----------------------------------------\n\nTITLE: Converting Markdown to RST using Pandoc\nDESCRIPTION: Generic syntax for converting Markdown files to reStructuredText format using Pandoc\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\npandoc -s <input.md> -o <path/to/target.rst>\n```\n\n----------------------------------------\n\nTITLE: Configuring Model Clients\nDESCRIPTION: Setup of OpenAI and Groq model clients with specific configuration parameters\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client.openai_client import OpenAIClient\nfrom adalflow.components.model_client.groq_client import GroqAPIClient\n\nif len(os.environ[\"OPENAI_API_KEY\"]) > 1:\n    gpt_3_model = {\n        \"model_client\": OpenAIClient(),\n        \"model_kwargs\": {\n            \"model\": \"gpt-3.5-turbo\",\n            \"max_tokens\": 2000,\n            \"temperature\": 0.0,\n            \"top_p\": 0.99,\n            \"frequency_penalty\": 0,\n            \"presence_penalty\": 0,\n            \"stop\": None,\n        },\n    }\n    gpt_4o_model = {\n        \"model_client\": OpenAIClient(),\n        \"model_kwargs\": {\n            \"model\": \"gpt-4o\",\n            \"max_tokens\": 4000,\n            \"temperature\": 0.0,\n            \"top_p\": 0.99,\n            \"frequency_penalty\": 0,\n            \"presence_penalty\": 0,\n            \"stop\": None,\n        },\n    }\n\nif len(os.environ[\"GROQ_API_KEY\"]) > 1:\n    llama_3_1_model = {\n        \"model_client\": GroqAPIClient(),\n        \"model_kwargs\": {\"model\": \"llama-3.1-8b-instant\"},\n    }\n```\n\n----------------------------------------\n\nTITLE: Repository Sync Commands\nDESCRIPTION: Commands for syncing local repository with upstream changes\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribution.rst#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit fetch upstream\ngit checkout main\ngit merge upstream/main\n```\n\n----------------------------------------\n\nTITLE: Implementing Generator State Logging\nDESCRIPTION: Example of using the trace_generator_states decorator to track Generator attributes in a DocQA component using OpenAI client\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_tracing.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.tracing import trace_generator_states\nfrom adalflow.core import Component, Generator\nimport adalflow as adal\nfrom adalflow.components.model_client import OpenAIClient\n\ntemplate_doc = r\"\"\"<SYS> You are a doctor </SYS> User: {{input_str}}\"\"\"\n\n\n@trace_generator_states()\nclass DocQA(adal.Component):\n    def __init__(self):\n        super(DocQA, self).__init__()\n        self.generator = Generator(\n            template=template_doc,\n            model_client=OpenAIClient(),\n            model_kwargs={\"model\": \"gpt-4o-mini\"},\n        )\n\n    def call(self, query: str) -> str:\n        return self.doc(prompt_kwargs={\"input_str\": query}).data\n```\n\n----------------------------------------\n\nTITLE: Excluding Fields from JSON Signature in TrecData2 Class\nDESCRIPTION: This code demonstrates how to exclude specific fields when generating the JSON signature for the TrecData2 class. It shows two examples: excluding metadata from both TrecData2 and Question classes, and excluding only the metadata from TrecData2.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/base_data_class.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\njson_signature_exclude = TrecData2.to_json_signature(exclude={\"TrecData2\": [\"metadata\"], \"Question\": [\"metadata\"]})\nprint(json_signature_exclude)\n\njson_signature_exclude = TrecData2.to_json_signature(exclude=[\"metadata\"])\nprint(json_signature_exclude)\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"question\": \"The question asked by the user ({'type': 'Question', 'properties': {'question': {'type': 'str', 'desc': 'The question asked by the user'}}, 'required': ['question']}) (required)\",\n    \"label\": \"The label of the question (int) (optional)\"\n}\n\n{\n    \"question\": \"The question asked by the user ({'type': 'Question', 'properties': {'question': {'type': 'str', 'desc': 'The question asked by the user'}, 'metadata': {'type': 'dict', 'desc': 'The metadata of the question'}}, 'required': ['question']}) (required)\",\n    \"label\": \"The label of the question (int) (optional)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Separating Library and Application Logs in Python\nDESCRIPTION: This code demonstrates how to create separate loggers for the library and the application, with different log file outputs.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_logger.ipynb#2025-04-14_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.logger import get_logger\n\napp_logger = get_logger(\n    name=\"my_app\", level=\"DEBUG\", save_dir=\"./logs\"\n)  # log to ./logs/my_app.log\n\n\nclass Task:\n    def __init__(self):\n        app_logger.info(\"This is a user program child logger\")\n```\n\n----------------------------------------\n\nTITLE: Serving Documentation Locally with Python\nDESCRIPTION: Commands to start a local server to view the documentation, avoiding browser restrictions on local resources.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ncd docs/build/html\npython -m http.server\n```\n\n----------------------------------------\n\nTITLE: Using Local Ollama Model\nDESCRIPTION: Example showing how to use locally deployed Ollama models with AdalFlow\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/installation.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\n\nllama_llm = adal.Generator(\n   model_client=adal.OllamaClient(), model_kwargs={\"model\": \"llama3\"}\n)\nresopnse = llama_llm(prompt_kwargs={\"input_str\": \"What is LLM?\"})\n```\n\n----------------------------------------\n\nTITLE: Generate Response from Chat History\nDESCRIPTION: Formats the chat history and generates a response using the generator with the input string and chat history\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nchat_history_str = format_chat_history_str(fetched_dialog_turns)\n\noutput = generator(\n    prompt_kwargs={\"input_str\": input_str, \"chat_history_str\": chat_history_str}\n)\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Configuring Teacher Generator in ObjectCountAdalComponent\nDESCRIPTION: Sets up the teacher generator for the ObjectCountAdalComponent using the configure_teacher_generator_helper method.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef configure_teacher_generator(self):\n    super().configure_teacher_generator_helper(\n        **self.teacher_generator_model_config\n    )\n```\n\n----------------------------------------\n\nTITLE: Defining Optimization Goal Enum in Python\nDESCRIPTION: An Enum class that defines different optimization targets for LLM systems, including fixed system prompts, few-shot examples, dynamic retrieval-based examples, and LLM responses with reflection capabilities.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/adalflow/optim/README.md#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass OptimizeGoal(Enum):\n    # 1. Similar to normal model auto-grad\n    LLM_SYS_INSTRUCTION = auto()  # fixed system prompt instruction across all calls\n    LLM_SYS_EXAMPLE = (\n        auto()\n    )  # few-shot examples (fixed across all calls) => vs dynamic examples\n    DYNAMIC_FEW_SHOT_EXAMPLES = auto()  # dynamic examples leverage retrieval\n    LLM_RESPONSE = (\n        auto()\n    )  # similar to reflection, to optimize the response with optimizer\n```\n\n----------------------------------------\n\nTITLE: Installing ipykernel for AdalFlow Development\nDESCRIPTION: Command to install a custom kernel for Jupyter to test notebooks during development. This allows developers to work with the current codebase in notebooks without requiring a full package installation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/README.md#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python -m ipykernel install --user --name my-project-kernel\n```\n\n----------------------------------------\n\nTITLE: Parsing Float Values with FloatParser in Python\nDESCRIPTION: Demonstrates the use of FloatParser to convert string representations of numbers to float values. It can handle integers, floats, and extract the first number from a string containing text.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import FloatParser\n\nfloat_str = \"42.0\"\nfloat_str_2 = \"42\"\nfloat_str_3 = \"42.7\"\nfloat_str_4 = \"the answer is 42.75\"\n\n# it will all return 42.0\nparser = FloatParser()\nprint(parser(float_str))\nprint(parser(float_str_2))\nprint(parser(float_str_3))\nprint(parser(float_str_4))\n```\n\n----------------------------------------\n\nTITLE: Configuring Mistral API Credentials\nDESCRIPTION: Sets up the Mistral API key securely using getpass and stores it in environment variables.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/mistral_integration.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\nMISTRAL_API_KEY = getpass(\"Please enter your Mistral API key:\")\n\nos.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: AdalFlow Documentation Tree Structure in RST\nDESCRIPTION: ReStructuredText markup defining the documentation tree structure with maxdepth of 2 and hidden property, listing all major documentation sections.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/apis/index.rst#2025-04-14_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 2\n   :hidden:\n\n   core/index\n   components/index\n   datasets/index\n   eval/index\n   optim/index\n   tracing/index\n   utils/index\n```\n\n----------------------------------------\n\nTITLE: DsPy Signature for TREC Classification in Python\nDESCRIPTION: This code defines the DsPy Signature for the TREC classification task. It includes the task description and input/output fields for comparison with AdalFlow's approach.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/classification.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass GenerateAnswer(dspy.Signature):\n    \"\"\"You are a classifier. Given a question, you need to classify it into one of the following classes:\n    Format: class_index. class_name, class_description\n    1. ABBR, Abbreviation\n    2. ENTY, Entity\n    3. DESC, Description and abstract concept\n    4. HUM, Human being\n    5. LOC, Location\n    6. NUM, Numeric value\n    - Do not try to answer the question:\"\"\"\n\n    question: str = dspy.InputField(desc=\"Question to be classified\")\n    answer: str = dspy.OutputField(\n        desc=\"Select one from ABBR, ENTY, DESC, HUM, LOC, NUM\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Initializing Doctor AI Prompt Template in Python\nDESCRIPTION: This code initializes a prompt template for a doctor AI assistant. It sets up a system message and a placeholder for user input. The template is structured as a JSON object with additional metadata like timestamp and prompt variables.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_tracing.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\n {\n    \"doc\": [\n        {\n            \"prompt_states\": {\n                \"type\": \"Prompt\",\n                \"data\": {\n                    \"_components\": {\n                        \"_ordered_dict\": true,\n                        \"data\": []\n                    },\n                    \"_parameters\": {\n                        \"_ordered_dict\": true,\n                        \"data\": []\n                    },\n                    \"training\": false,\n                    \"teacher_mode\": false,\n                    \"tracing\": false,\n                    \"name\": \"Prompt\",\n                    \"_init_args\": {\n                        \"template\": null,\n                        \"prompt_kwargs\": {}\n                    },\n                    \"template\": \"<SYS> You are a doctor </SYS> User: {{input_str}}\",\n                    \"prompt_variables\": [\n                        \"input_str\"\n                    ],\n                    \"prompt_kwargs\": {}\n                }\n            },\n            \"time_stamp\": \"2024-11-29T12:36:33.302956\"\n        }\n    ]\n}\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Testing Task Pipeline Execution\nDESCRIPTION: Demonstrates how to run the object counting task pipeline in both evaluation and training modes using a sample question.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nquestion = \"I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?\"\ntask_pipeline = ObjectCountTaskPipeline(**gpt_3_model)\nprint(task_pipeline)\n\nanswer = task_pipeline(question)\nprint(answer)\n\n# set it to train mode\ntask_pipeline.train()\nanswer = task_pipeline(question, id=\"1\")\nprint(answer)\nprint(f\"full_response: {answer.full_response}\")\n```\n\n----------------------------------------\n\nTITLE: Converting README to RST Example\nDESCRIPTION: Example command showing how to convert README.md to introduction.rst in the documentation directory\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\npandoc -s README.md -o docs/source/get_started/introduction.rst\n```\n\n----------------------------------------\n\nTITLE: LLM Judge Without Questions Evaluation Result in JSON\nDESCRIPTION: Example output from an LLM judge evaluation without question context, showing a perfect match between predicted and ground truth answers with a confidence interval.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_8\n\nLANGUAGE: json\nCODE:\n```\nLLMJudgeEvalResult(avg_score=1.0, judgement_score_list=[1], confidence_interval=(0, 1))\n```\n\n----------------------------------------\n\nTITLE: Setting API Keys for OpenAI and Groq\nDESCRIPTION: Script to securely set environment variables for OpenAI and Groq API keys using getpass.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_embedder.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\ngroq_api_key = getpass(\"Please enter your GROQ API key: \")\n\n\n# Set environment variables\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Printing Formatted Prompt in Python\nDESCRIPTION: Demonstrates how to print the formatted prompt used in the pipeline, which includes system instructions, output format specifications, and the user's input. This is useful for understanding and debugging the prompt structure.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/README.md#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nqa2.generator.print_prompt(\n        output_format_str=qa2.generator.output_processors.format_instructions(),\n        input_str=\"What is LLM?\",\n)\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure - Logging Components\nDESCRIPTION: ReStructuredText documentation defining the structure for logging and tracing utilities, including native logging module integration and trace history functionality.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/index.rst#2025-04-14_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n   :caption: Logging & Tracing\n   :hidden:\n\n\n   logging\n   logging_tracing\n```\n\n----------------------------------------\n\nTITLE: Importing AdalFlow Components\nDESCRIPTION: Core class and function imports from the AdalFlow library, including model clients for OpenAI and Transformers, and vector normalization functionality.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/embedder.rst#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ncomponents.model_client.openai_client.OpenAIClient\ncomponents.model_client.transformers_client.TransformersClient\ncore.functional.normalize_vector\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI GPT Model Settings in Python\nDESCRIPTION: Sets up OpenAI client and model configuration parameters for GPT-3.5-turbo including token limits and temperature settings.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.model_client.openai_client import OpenAIClient\n\nadal.setup_env()\n\ngpt_3_model = {\n    \"model_client\": OpenAIClient(),\n    \"model_kwargs\": {\n        \"model\": \"gpt-3.5-turbo\",\n        \"max_tokens\": 2000,\n        \"temperature\": 0.0,\n        \"top_p\": 0.99,\n        \"frequency_penalty\": 0,\n        \"presence_penalty\": 0,\n        \"stop\": None,\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Native Python String Formatting Examples\nDESCRIPTION: Demonstrates various native Python methods for formatting strings, including percent formatting, format() method, f-strings, and Template strings. Shows different approaches before explaining why Jinja2 was chosen instead.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/prompt.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# percent(%) formatting\nprint(\"<SYS>%s</SYS> User: %s\" % (task_desc_str, input_str))\n\n# format() method with kwargs\nprint(\n    \"<SYS>{task_desc_str}</SYS> User: {input_str}\".format(\n        task_desc_str=task_desc_str, input_str=input_str\n    )\n)\n\n# f-string\nprint(f\"<SYS>{task_desc_str}</SYS> User: {input_str}\")\n\n# Templates\nfrom string import Template\n\nt = Template(\"<SYS>$task_desc_str</SYS> User: $input_str\")\nprint(t.substitute(task_desc_str=task_desc_str, input_str=input_str))\n```\n\n----------------------------------------\n\nTITLE: Anthropic Integration with AdalFlow\nDESCRIPTION: Setup for using Anthropic's Claude model through AdalFlow interface\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/index.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\nfrom adalflow.utils import setup_env\n\nsetup_env()\n\nanthropic_llm = adal.Generator(\n   model_client=adal.AnthropicAPIClient(), model_kwargs={\"model\" \"claude-3-opus-20240229\"}\n)\nresopnse = anthropic_llm(prompt_kwargs={\"input_str\": \"What is LLM?\"})\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI and Groq API Keys\nDESCRIPTION: Sets environment variables for OpenAI and Groq API keys for authentication\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_tracing.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Accessing Nested Song Review Data in Python\nDESCRIPTION: Demonstrates how to access and print nested data from the song review response.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nanalysis = response.data\nprint(f\"Song Title: {analysis['review']['basic_review']['title']}\")\nprint(f\"Album: {analysis['review']['basic_review']['album']}\")\nprint(f\"Ranking: {analysis['review']['basic_review']['ranking']}\")\n\nfor platform, views in analysis[\"review\"][\"basic_review\"][\"streaming\"].items():\n    print(f\"- {platform} - {views} million views\")\nprint(\"\\nPros:\")\nfor pro in analysis[\"review\"][\"basic_review\"][\"pros\"]:\n    print(f\"- {pro}\")\n\nprint(\"\\nArtist's:\")\nfor actor in analysis[\"review\"][\"cast\"]:\n    print(f\"- {actor['name']} as {actor['role']}\")\n\nif analysis[\"review\"][\"genre\"]:\n    print(\"\\nGenere:  \")\n    for genre in analysis[\"review\"][\"genre\"]:\n        print(f\" {genre} \")\n\nif analysis[\"duration\"]:\n    print(f\"\\nDuration: {analysis['duration']} minutes\")\n\nif hasattr(analysis, \"awards\") and analysis[\"awards\"]:\n    print(\"\\nAwards:\")\n    for category, count in analysis[\"awards\"].items():\n        print(f\"- {category}: {count}\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Key\nDESCRIPTION: This snippet prompts the user to enter their OpenAI API key securely and sets it as an environment variable. This is crucial for authenticating with the OpenAI service.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/question_answering/chatbot.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\n# Set environment variables\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n# Replace with your OpenAI API Key, or you can put it in a .env file\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Enhanced Functionality of Custom DataClass\nDESCRIPTION: This snippet showcases the enhanced functionality of the custom DataClass, including the ability to reconstruct nested dataclasses and use both class and instance methods for dictionary conversion.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nexample = TrecData2(Question(\"What is the capital of France?\"), 1, {\"key\": \"value\"})\nprint(example)\n\ndict_example = TrecData2.to_dict(example)  # use as if its a class method\nprint(dict_example)\n\ndict_example_2 = example.to_dict()  # use it  as instance method\nprint(dict_example)\n\nreconstructed = TrecData2.from_dict(dict_example)\nprint(reconstructed)\n\nprint(reconstructed == example)\nprint(dict_example == dict_example_2)\n```\n\n----------------------------------------\n\nTITLE: Logger Metadata JSON Structure\nDESCRIPTION: Example JSON structure showing the logger metadata format with file paths for different components including retrievers and LLM calls.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/trainer.rst#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n\"retriever.query_generators.0\": \"/Users/liyin/.adalflow/ckpt/MultiHopRAGAdal/diagnose_train/retriever.query_generators.0_call.jsonl\",\n\"retriever.query_generators.1\": \"/Users/liyin/.adalflow/ckpt/MultiHopRAGAdal/diagnose_train/retriever.query_generators.1_call.jsonl\",\n\"llm\": \"/Users/liyin/.adalflow/ckpt/MultiHopRAGAdal/diagnose_train/llm_call.jsonl\"\n}\n```\n\n----------------------------------------\n\nTITLE: Basic QA DataClass Implementation\nDESCRIPTION: Implementation of a basic question-answering system using AdalFlow's DataClass.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass BasicQAOutput(adal.DataClass):\n    explanation: str = field(\n        metadata={\"desc\": \"A brief explanation of the concept in one sentence.\"}\n    )\n    example: str = field(metadata={\"desc\": \"An example of the concept in a sentence.\"})\n\n    __output_fields__ = [\"explanation\", \"example\"]\n\n\nqa_template = r\"\"\"<SYS>\nYou are a helpful assistant.\n<OUTPUT_FORMAT>\n{{output_format_str}}\n</OUTPUT_FORMAT>\n</SYS>\n<USER> {{input_str}} </USER>\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining AdalFlow Debug File Structure\nDESCRIPTION: This snippet outlines the file structure for AdalFlow's debug mode, including directories for text gradients, demo optimization, and various debug-related files and graphs.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n.adalflow/\n├── ckpt/\n│   └── ObjectCountAdalComponent/\n│       ├── diagnose_{train, val, test}/  # Directory for training data diagnostics\n│       │   ├── llm_counter_call.jsonl    # Sorted by score from lowest to highest\n│       │   ├── logger_metadata.jsonl\n│       │   ├── llm_counter_diagnose.json # Contains samples with score < 0.5, sorted by score\n│       │   └── stats.json\n│       ├── debug_text_grads                          # Directory for debug mode with text optimizer\n│       │   ├── lib.log                    # Log file\n│       │   ├── trace_graph_sum.png       # Trace graph with textual feedback and new proposed value\n│       │   ├── trace_graph_sum_root.json # Json representation of the root loss node (sum of the success and fail loss)\n│       |-- debug_demos                           # Directory for debug mode with demo optimizer\n│       │   ├── student_graph\n│       │   │   ├── trace_graph_EvalFnToTextLoss_output_id_6ea5da3c-d414-4aae-8462-75dd1e09abab.png # Trace graph with textual feedback and new proposed value\n```\n\n----------------------------------------\n\nTITLE: Loading HotpotQA Dataset with Hugging Face\nDESCRIPTION: Demonstrates how to load the HotpotQA dataset using the Hugging Face datasets library.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# load the dataset\nfrom datasets import load_dataset\n\ndataset = load_dataset(path=\"hotpot_qa\", name=\"fullwiki\")\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry\nDESCRIPTION: Commands to install project dependencies and activate the Poetry virtual environment shell. This initializes the project's development environment with required packages.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/installation.rst#2025-04-14_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\npoetry shell\n```\n\n----------------------------------------\n\nTITLE: Parsing Boolean Values with BooleanParser in Python\nDESCRIPTION: Demonstrates the usage of BooleanParser to convert string representations of boolean values to actual boolean types. It handles 'True', 'False', 'true', and 'false' correctly, but fails for non-standard boolean representations like '1', '0', 'yes', or 'no'.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/output_parsers.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core.string_parser import BooleanParser\n\nbool_str = \"True\"\nbool_str_2 = \"False\"\nbool_str_3 = \"true\"\nbool_str_4 = \"false\"\nbool_str_5 = \"1\"  # will fail\nbool_str_6 = \"0\"  # will fail\nbool_str_7 = \"yes\"  # will fail\nbool_str_8 = \"no\"  # will fail\n\n# it will all return True/False\nparser = BooleanParser()\nprint(parser(bool_str))\nprint(parser(bool_str_2))\nprint(parser(bool_str_3))\nprint(parser(bool_str_4))\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Package with Dependencies\nDESCRIPTION: Command to install AdalFlow Python package along with required dependencies including OpenAI, Groq, and FAISS-CPU using pip\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/adalflow_colab_template.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install adalflow[openai,groq,faiss-cpu]\n```\n\n----------------------------------------\n\nTITLE: Sample Document and Query Data Structure\nDESCRIPTION: Example data structure showing document format and sample queries for testing retrieval systems.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/retriever.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nquery_1 = \"What are the benefits of renewable energy?\" # gt is [0, 3]\nquery_2 = \"How do solar panels impact the environment?\" # gt is [1, 2]\n\ndocuments =[\n    {\n        \"title\": \"The Impact of Renewable Energy on the Economy\",\n        \"content\": \"Renewable energy technologies not only help in reducing greenhouse gas emissions but also contribute significantly to the economy by creating jobs in the manufacturing and installation sectors. The growth in renewable energy usage boosts local economies through increased investment in technology and infrastructure.\"\n    },\n    {\n        \"title\": \"Understanding Solar Panels\",\n        \"content\": \"Solar panels convert sunlight into electricity by allowing photons, or light particles, to knock electrons free from atoms, generating a flow of electricity. Solar panels are a type of renewable energy technology that has been found to have a significant positive effect on the environment by reducing the reliance on fossil fuels.\"\n    },\n    {\n        \"title\": \"Pros and Cons of Solar Energy\",\n        \"content\": \"While solar energy offers substantial environmental benefits, such as reducing carbon footprints and pollution, it also has downsides. The production of solar panels can lead to hazardous waste, and large solar farms require significant land, which can disrupt local ecosystems.\"\n    },\n    {\n        \"title\":  \"Renewable Energy and Its Effects\",\n        \"content\": \"Renewable energy sources like wind, solar, and hydro power play a crucial role in combating climate change. They do not produce greenhouse gases during operation, making them essential for sustainable development. However, the initial setup and material sourcing for these technologies can still have environmental impacts.\"\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Running the ChatBot\nDESCRIPTION: This simple snippet calls the ChatBot's call method to start the interactive chat session. Users can now interact with the chatbot through the console.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/question_answering/chatbot.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nchatbot.call()\n```\n\n----------------------------------------\n\nTITLE: Defining Agent Systems in Markdown\nDESCRIPTION: This snippet defines what an agent is, emphasizing that it's not just a model but a system that uses LLM models to plan and execute tasks autonomously using various tools.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/adalflow/components/agent/README.md#2025-04-14_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Agent is not a model or LLM model.\n# Agent is better defined as a system that uses LLM models to plan and replan steps that each involves the usage of various tools,\n# such as function calls, another LLM model based on the context and history (memory) to complete a task autonomously.\n```\n\n----------------------------------------\n\nTITLE: Initializing Python Logging\nDESCRIPTION: This snippet sets up basic logging using Python's built-in logging module.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_logger.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logging\n\nlog = logging.getLogger(__name__)\n```\n\n----------------------------------------\n\nTITLE: Llama3 Output Prediction Format\nDESCRIPTION: Example showing the expected format of prediction output from Llama3 model with special tokens.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/prompt.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprediction = r\"\"\"<|start_header_id|>assistant<|end_header_id|> You can ask me anything you want. <|eot_id|><|end_of_text|>\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Installing Pandoc via Homebrew\nDESCRIPTION: Command to install Pandoc document converter using Homebrew package manager\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nbrew install pandoc\n```\n\n----------------------------------------\n\nTITLE: Movie Review DataClass Implementation\nDESCRIPTION: Implementation of nested dataclasses for movie reviews with multiple levels of detail.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass MovieReview(adal.DataClass):\n    title: str = field(metadata={\"desc\": \"The title of the movie\"})\n    rating: float = field(\n        metadata={\"desc\": \"Rating from 1.0 to 10.0\", \"min\": 1.0, \"max\": 10.0}\n    )\n    pros: List[str] = field(\n        default_factory=list,\n        metadata={\"desc\": \"List of positive points about the movie\"},\n    )\n    cons: List[str] = field(\n        default_factory=list,\n        metadata={\"desc\": \"List of negative points about the movie\"},\n    )\n\n    __output_fields__ = [\"title\", \"rating\", \"pros\", \"cons\"]\n```\n\n----------------------------------------\n\nTITLE: Initializing RAG Pipeline\nDESCRIPTION: Initializes the RAG pipeline and builds the index using the document list.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/eval_a_rag.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfor data in dataset:\n    # following the previous code snippet\n    rag = RAG(settings)\n    rag.build_index(doc_list)\n```\n\n----------------------------------------\n\nTITLE: Simple LLM Logger Configuration\nDESCRIPTION: Basic JSON configuration example for LLM call logging showing the file path structure.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/trainer.rst#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"llm\": \"/Users/liyin/.adalflow/ckpt/MultiHopRAGAdal/diagnose_train/llm_call.jsonl\"\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG Component Class\nDESCRIPTION: This code defines the RAG component class, which encapsulates the entire RAG system functionality, including document indexing, retrieval, and generation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass RAG(Component):\n    def __init__(\n        self,\n        index_file: str = \"index.faiss\",\n        index_path: Optional[str] = None,\n        configs: dict = configs,\n    ):\n        super().__init__()\n\n        index_path = index_path or get_adalflow_default_root_path()\n        index_path = os.path.join(index_path, index_file)\n        self.index_path = index_path\n\n        if not os.path.exists(index_path):\n            self.db = LocalDB()\n            self.register_data_transformer()\n            self.transformed_docs = []\n        else:\n            self.db = LocalDB.load_state(index_path)\n            self.transformed_docs = self.db.get_transformed_data(\"data_transformer\")\n\n        embedder = Embedder(\n            model_client=ModelClientType.OPENAI(),\n            model_kwargs=configs[\"embedder\"][\"model_kwargs\"],\n        )\n\n        self.retriever = FAISSRetriever(\n            **configs[\"retriever\"],\n            embedder=embedder,\n            documents=self.transformed_docs,\n            document_map_func=lambda doc: doc.vector,\n        )\n        self.retriever_output_processors = RetrieverOutputToContextStr(deduplicate=True)\n\n        self.generator = Generator(\n            **configs[\"generator\"],\n            prompt_kwargs={\"task_desc_str\": rag_prompt_task_desc},\n            output_processors=JsonParser(),\n        )\n\n    def register_data_transformer(self):\n        if \"data_transformer\" not in self.db.get_transformer_keys():\n            data_transformer = prepare_data_pipeline()\n            self.db.register_transformer(data_transformer, key=\"data_transformer\")\n            print(\"Data transformer registered\")\n\n    def add_documents(self, docs: List[Document]):\n        self.db.extend(docs, apply_transformer=True)\n        self.db.save_state(self.index_path)\n\n    def get_transformed_docs(self, filter_func=None):\n        return self.db.get_transformed_data(\"data_transformer\", filter_func)\n\n    def prepare_retriever(self, filter_func=None):\n        self.transformed_docs = self.get_transformed_docs(filter_func)\n        self.retriever.build_index_from_documents(\n            self.transformed_docs, document_map_func=lambda doc: doc.vector\n        )\n\n    def generate(self, query: str, context: Optional[str] = None) -> Any:\n        if not self.generator:\n            raise ValueError(\"Generator is not set\")\n        prompt_kwargs = {\"context_str\": context, \"input_str\": query}\n        response = self.generator(prompt_kwargs=prompt_kwargs)\n        return response, context\n\n    def call(self, query: str, verbose: bool = False) -> Any:\n        retrieved_documents = self.retriever(query)\n        for i, retriever_output in enumerate(retrieved_documents):\n            retrieved_documents[i].documents = [\n                self.transformed_docs[doc_index]\n                for doc_index in retriever_output.doc_indices\n            ]\n        if verbose:\n            print(f\"retrieved_documents: \\n {retrieved_documents}\")\n\n        context_str = self.retriever_output_processors(retrieved_documents)\n        if verbose:\n            print(f\"context_str: \\n {context_str}\")\n\n        return self.generate(query, context=context_str)\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Root Logger with AdalFlow's get_logger Function\nDESCRIPTION: Demonstrates how to set up a root logger using AdalFlow's get_logger utility function, which configures logging with good default formatting and handlers.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.logger import get_logger\n\n\nroot_logger = get_logger()\n```\n\n----------------------------------------\n\nTITLE: Cloning AdalFlow Repository\nDESCRIPTION: Commands to clone the AdalFlow repository from GitHub and navigate to the project directory.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribute_to_code.rst#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/SylphAI-Inc/AdalFlow\ncd AdalFlow\n```\n\n----------------------------------------\n\nTITLE: Setting API Environment Variables\nDESCRIPTION: Secure setup of API keys for OpenAI and Groq using getpass.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\ngroq_api_key = getpass(\"Please enter your GROQ API key: \")\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\n\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Implementing LLM Judge Without Questions\nDESCRIPTION: Implementation of LLM-based evaluation without questions using OpenAI's GPT model as judge.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef compute_llm_as_judge_wo_questions():\n    from adalflow.eval.llm_as_judge import LLMasJudge, DefaultLLMJudge\n    from adalflow.components.model_client import OpenAIClient\n\n    llm_judge = DefaultLLMJudge(\n        model_client=OpenAIClient(),\n        model_kwargs={\n            \"model\": \"gpt-4o\",\n            \"temperature\": 1.0,\n            \"max_tokens\": 10,\n        },\n        jugement_query=\"Does the predicted answer means the same as the ground truth answer? Say True if yes, False if no.\",\n    )\n    llm_evaluator = LLMasJudge(llm_judge=llm_judge)\n    print(llm_judge)\n    eval_rslt = llm_evaluator.compute(gt_answers=[gt], pred_answers=[pred])\n    print(eval_rslt)\n```\n\n----------------------------------------\n\nTITLE: Score Propagation in EvalFnToTextLoss for Few-Shot Training in Python\nDESCRIPTION: Shows how evaluation scores are propagated back to traced examples during the backpropagation process within the EvalFnToTextLoss class.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/optimizer.rst#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npred._score = respose.data\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages\nDESCRIPTION: Installation commands for AdalFlow with OpenAI support, DSPy, and datasets packages.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[openai] # also install the package for the model client you'll use\n!pip install dspy\n!pip install datasets\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Word-based Text Splitting Example\nDESCRIPTION: Demonstrates text splitting using word-based strategy with chunk size of 5 and overlap of 1.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_text_splitter.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.data_process.text_splitter import TextSplitter\nfrom adalflow.core.types import Document\n\n# Configure the splitter settings\ntext_splitter = TextSplitter(split_by=\"word\", chunk_size=5, chunk_overlap=1)\n\n# Example document\ndoc = Document(\n    text=\"Example text. More example text. Even more text to illustrate.\", id=\"doc1\"\n)\n\n# Execute the splitting\nsplitted_docs = text_splitter.call(documents=[doc])\n\nfor doc in splitted_docs:\n    print(doc)\n```\n\n----------------------------------------\n\nTITLE: Creating Symbolic Link\nDESCRIPTION: Creating a symbolic link to AdalFlow default file path for data and checkpoint access\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nln -s /root/.adalflow /content/adalflow\n```\n\n----------------------------------------\n\nTITLE: Configuring Teacher Generator in ObjectCountAdalComponent\nDESCRIPTION: This method sets up the teacher generator for the ObjectCountAdalComponent using the teacher model configuration.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef configure_teacher_generator(self):\n    super().configure_teacher_generator_helper(\n        **self.teacher_generator_model_config\n    )\n```\n\n----------------------------------------\n\nTITLE: Displaying Teacher Model's Example Reasoning for Few-Shot Learning\nDESCRIPTION: Example of a teacher model's detailed reasoning process for counting fruits, which can be used as a demonstration for bootstrap few-shot learning.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n\"Example: 'Let\\'s count the fruits one by one:\\n\\n\\n  1. Orange: 1\\n\\n  2. Strawberries: 3\\n\\n  3. Apple: 1\\n\\n  4. Bananas: 3\\n\\n  5. Raspberries: 3\\n\\n  6. Peach: 1\\n\\n  7. Blackberry: 1\\n\\n  8. Grape: 1\\n\\n  9. Plum: 1\\n\\n  10. Nectarines: 2\\n\\n\\n  Now, we sum them up:\\n\\n  \\[ 1 + 3 + 1 + 3 + 3 + 1 + 1 + 1 + 1 + 2 = 17 \\]\\n\\n\\n  Answer: 17'\"\n```\n\n----------------------------------------\n\nTITLE: Applying Transformer to LocalDB Data in AdalFlow\nDESCRIPTION: This code demonstrates how to register and apply a data transformer to the data stored in a LocalDB instance using the AdalFlow framework.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nkey = \"split_and_embed\"\ndialog_turn_db.transform(data_transformer, map_fn=map_dialogturn_to_document, key=key)\n\nprint(dialog_turn_db.transformed_items[key])\nprint(dialog_turn_db.transformer_setups[key])\nprint(dialog_turn_db.mapper_setups[key])\n```\n\n----------------------------------------\n\nTITLE: Initializing Logger in AdalFlow Source Files\nDESCRIPTION: Shows how AdalFlow initializes a logger in each source file using the standard Python logging module with the __name__ pattern.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport logging\n\nlog = logging.getLogger(__name__)\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Table of Contents for Contributor Guide\nDESCRIPTION: A toctree directive that organizes the contributor guide documentation into sections with a specified caption and depth level. It links to separate files for general contribution guidelines and code contribution specifics.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n   :caption: Contributor Guide\n   :maxdepth: 1\n\n   contribution\n   contribute_to_code\n```\n\n----------------------------------------\n\nTITLE: Initializing Generator for Conversation in AdalFlow\nDESCRIPTION: This code initializes a Generator object from AdalFlow's core module, setting up the model client and parameters for generating responses in a conversation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/db.rst#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import Generator\n\nllm_kwargs = {\n    \"model\": \"gpt-3.5-turbo\"\n}\n\ngenerator = Generator(model_client = ModelClientType.OPENAI(), model_kwargs=llm_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Excluding Fields in Custom DataClass Serialization\nDESCRIPTION: This snippet demonstrates how to exclude specific fields when serializing a custom DataClass to a dictionary. It shows exclusion for both parent and child classes.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# exclude field of only the parent class\ndict_exclude = example.to_dict(exclude=[\"metadata\"])\nprint(dict_exclude)\n\n# exclude field of the parent and child class\ndict_exclude = example.to_dict(\n    exclude={\"TrecData2\": [\"metadata\"], \"Question\": [\"metadata\"]}\n)\nprint(dict_exclude)\n```\n\n----------------------------------------\n\nTITLE: Using the printc Function for Colored Console Output\nDESCRIPTION: Shows how to use AdalFlow's printc utility function to output colored text to the console with similar formatting to the logger.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.logger import printc\n\nprintc(\"All logging examples are done. Feeling green!\", color=\"green\")\n```\n\n----------------------------------------\n\nTITLE: Fixing Dependency Conflicts\nDESCRIPTION: Commands to resolve HTTP client dependency conflicts by installing specific versions.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip uninstall httpx anyio -y\n!pip install \"anyio>=3.1.0,<4.0\"\n!pip install httpx==0.24.1\n```\n\n----------------------------------------\n\nTITLE: Token-based Text Splitting Example\nDESCRIPTION: Demonstrates text splitting using token-based strategy with chunk size of 5 and no overlap.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_text_splitter.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.components.data_process.text_splitter import TextSplitter\nfrom adalflow.core.types import Document\n\n# Configure the splitter settings\ntext_splitter = TextSplitter(split_by=\"token\", chunk_size=5, chunk_overlap=0)\n\ndoc = Document(\n    text=\"Example text. More example text. Even more text to illustrate.\", id=\"doc1\"\n)\n\nsplitted_docs = text_splitter.call(documents=[doc])\n\nfor doc in splitted_docs:\n    print(doc)\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Package\nDESCRIPTION: Installs or updates the AdalFlow package using pip and clears the output cell.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/xai_integration.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow\n\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: REALM Gradient Calculation for Retriever Optimization (LaTeX)\nDESCRIPTION: This LaTeX equation shows the gradient calculation used in REALM to optimize the retriever. It determines how the retriever's scoring function should be adjusted based on the relevance of retrieved documents to the input and prediction.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/rag_playbook.rst#2025-04-14_snippet_3\n\nLANGUAGE: latex\nCODE:\n```\n\\frac{\\partial \\log p(y | x)}{\\partial f(x, z)} = \\left[ \\frac{p(y | z, x)}{p(y | x)} - 1 \\right] p(z | x)\n```\n\n----------------------------------------\n\nTITLE: Loading and Testing Dataset Example\nDESCRIPTION: Loads training, validation and test datasets and prints a sample example from the training set.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_classification_optimization.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataset, val_dataset, test_dataset = load_datasets()\nexample = train_dataset[0]\nprint(example)\n```\n\n----------------------------------------\n\nTITLE: Inference in AdalFlow\nDESCRIPTION: Shows how to perform inference in AdalFlow, which is similar to using torch.no_grad() in PyTorch.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/auto_text_grad.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport adalflow as adal\n\ntask_pipeline = MyTaskPipeline()\ntask_pipeline.eval()  # Set model to evaluation mode\ntask_pipeline(input_data)  # similar to torch.no_grad() or\n# task_pipeline.call(input_data)  # Forward pass only\n# task_pipeline.acall(input_data)  # Forward pass only\n```\n\n----------------------------------------\n\nTITLE: Fixing HTTP Dependencies\nDESCRIPTION: Resolves version conflicts by uninstalling and reinstalling specific versions of httpx and anyio libraries.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_text_splitter.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip uninstall httpx anyio -y\n!pip install \"anyio>=3.1.0,<4.0\"\n!pip install httpx==0.24.1\n```\n\n----------------------------------------\n\nTITLE: Initializing a Question Example in Python\nDESCRIPTION: Example question from the dataset that requires the model to count the total number of musical instruments among various objects mentioned.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nquestion = \"I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?\"\n```\n\n----------------------------------------\n\nTITLE: Execute Function Call\nDESCRIPTION: Simple execution of the previously defined execute() function to test the async event loop detection and handling.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/react_note.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nexecute()\n```\n\n----------------------------------------\n\nTITLE: Loading HotpotQA Dataset\nDESCRIPTION: Loads a subset of the HotpotQA dataset for evaluation purposes using the Hugging Face datasets library.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/eval_a_rag.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndataset = load_dataset(path=\"hotpot_qa\", name=\"fullwiki\")\ndataset = dataset[\"train\"].select(range(5))\n```\n\n----------------------------------------\n\nTITLE: Complete Trace Directory Structure with Call Logging\nDESCRIPTION: Shows the expanded directory structure when both state tracing and call tracing are enabled, with separate log files for each generator and a metadata file.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging_tracing.rst#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n.\n├── traces\n│   ├── SimpleQA\n│   │   ├── logger_metadata.json\n│   │   ├── generator_call.jsonl\n│   │   ├── generator_2_call.jsonl\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Structure with reST\nDESCRIPTION: Sets up a toctree directive to organize documentation navigation with maxdepth of 1, including links to installation guide, tutorial notebook, and community pages.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n    :maxdepth: 1\n    :caption: Get Started\n\n    installation\n    adalflow_in_15mins <https://colab.research.google.com/drive/1_YnD4HshzPRARvishoU4IA-qQuX9jHrT?usp=sharing>\n    community\n```\n\n----------------------------------------\n\nTITLE: AdalFlow Training Output Directory Structure in Bash\nDESCRIPTION: This snippet shows the directory structure for storing training output in AdalFlow.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering_word_sort.rst#2025-04-14_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n.adalflow/\n├── ckpt/\n│   └── ObjectCountAdalComponent/\n```\n\n----------------------------------------\n\nTITLE: Installing the GitHub Chat RAG Application\nDESCRIPTION: Bash commands for cloning the github_chat repository, navigating to the project directory, and installing dependencies using Poetry.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/rag_with_memory.rst#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/SylphAI-Inc/github_chat\ncd github_chat\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Using AdalFlow's Colored Print Function\nDESCRIPTION: This snippet demonstrates the use of a custom colored print function from AdalFlow's logger utility.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_logger.ipynb#2025-04-14_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.logger import printc\n\nprintc(\"All logging examples are done. Feeling green!\", color=\"green\")\n```\n\n----------------------------------------\n\nTITLE: Printing Generator Prompt in Python\nDESCRIPTION: Shows how to print the prompt used by the Generator. This is useful for understanding what is being sent to the language model.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/generator/basic.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ngenerator.print_prompt(**prompt_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Extract Parent Document IDs\nDESCRIPTION: Extracts unique parent document IDs from the retrieved top K documents using set comprehension\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/database.ipynb#2025-04-14_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nparent_doc_ids = set(\n    [\n        dialog_turn_db.transformed_items[key][doc_index].parent_doc_id\n        for doc_index in top_k_documents[0].doc_indices\n    ]\n)\nprint(parent_doc_ids)\n```\n\n----------------------------------------\n\nTITLE: Disabling Gradient Calculation in PyTorch\nDESCRIPTION: Demonstrates how to disable gradient calculation in PyTorch using torch.no_grad() for inference.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/auto_text_grad.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\n\nmodel = MyModel()\nmodel.eval()  # Set model to evaluation mode\n\nwith torch.no_grad():  # Disable gradient tracking\n    output = model(input_data)  # Forward pass only\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Dependencies\nDESCRIPTION: This snippet installs the required AdalFlow packages with OpenAI, Groq, and FAISS CPU support. It uses pip to install the latest version and clears the output for a clean display.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/question_answering/chatbot.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[openai,groq,faiss-cpu]\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Configuring GPT-4 and GPT-3.5 Models for AdalFlow\nDESCRIPTION: This snippet defines configuration dictionaries for GPT-4 and GPT-3.5 models, specifying the OpenAI client and model parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ngpt_4o_model = {\n    \"model_client\": OpenAIClient(),\n    \"model_kwargs\": {\n        \"model\": \"gpt-4o-mini\",\n        \"max_tokens\": 2000,\n    },\n}\n\ngpt_3_model = {\n    \"model_client\": OpenAIClient(),\n    \"model_kwargs\": {\n        \"model\": \"gpt-3.5-turbo\",\n        \"max_tokens\": 2000,\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up AdalFlow Dev Environment\nDESCRIPTION: Commands to set up the AdalFlow development environment using Poetry, install dependencies, and run tests.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribute_to_code.rst#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd adalflow\npoetry install\npoetry shell\n\npytest tests\n```\n\n----------------------------------------\n\nTITLE: Repository Setup Commands for Pull Requests\nDESCRIPTION: Git commands for cloning and syncing a forked repository with the upstream AdalFlow repository\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribution.rst#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone your_forked_repository_url\n```\n\n----------------------------------------\n\nTITLE: Future Improvements TODO List\nDESCRIPTION: A list of planned future improvements for the React Agent implementation including history support, training enhancements, and additional features.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# TODO:\n# 1. advanced, add history to react\n# 2. add training, few shot\n# 3. llm as judge\n# 4. add picture\n# 5. better json handling, we need to store the answer output\n```\n\n----------------------------------------\n\nTITLE: Installing Poetry for Python Dependency Management\nDESCRIPTION: Command to install Poetry, a tool for Python dependency management and packaging.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install poetry\n```\n\n----------------------------------------\n\nTITLE: Sample Output from DspyRetriever\nDESCRIPTION: Shows the output format from the DspyRetriever, which includes a RetrieverOutput object containing the original query and retrieved document passages related to David Gregory.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n[RetrieverOutput(doc_indices=[], doc_scores=None, query='How many storeys are in the castle that David Gregory inherited?', documents=['David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory\\'s use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.', 'St. Gregory Hotel | The St. Gregory Hotel is a boutique hotel located in downtown Washington, D.C., in the United States. Established in 2000, the nine-floor hotel has 155 rooms, which includes 54 deluxe rooms, 85 suites with kitchens, and 16 top-floor suites with balconies. The hotel, which changed hands in June 2015, has a life-size statue of Marilyn Monroe in the lobby.', 'Karl D. Gregory Cooperative House | Karl D. Gregory Cooperative House is a member of the Inter-Cooperative Council at the University of Michigan. The structure that stands at 1617 Washtenaw was originally built in 1909 for the Tau Gamma Nu fraternity, but was purchased by the ICC in 1995. Gregory House is the only house in the organization that is expressly substance free. No tobacco, alcohol, or illicit drugs are allowed on the property. Gregory House has a maximum capacity of 29 members (by way of 13 single and 8 double capacity rooms) as of June 2008.'])]\n```\n\n----------------------------------------\n\nTITLE: Fixing Dependencies\nDESCRIPTION: Commands to resolve dependency conflicts by uninstalling and reinstalling specific versions of httpx and anyio.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!pip uninstall httpx anyio -y\n!pip install \"anyio>=3.1.0,<4.0\"\n!pip install httpx==0.24.1\n```\n\n----------------------------------------\n\nTITLE: Running Test with Full Debug Output\nDESCRIPTION: Executes a test with maximum verbosity and output capture\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/tests/README.md#2025-04-14_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npytest tests/test_file.py::test_function -vv -s\n```\n\n----------------------------------------\n\nTITLE: Setting Up Fireworks AI API Credentials\nDESCRIPTION: Securely captures the Fireworks AI API key from user input and sets it as an environment variable for authentication.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/fireworks_integration.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom getpass import getpass\nimport os\n\nFIREWORKS_API_KEY = getpass(\"Please enter your Mistral API key:\")\n\nos.environ[\"FIREWORKS_API_KEY\"] = FIREWORKS_API_KEY\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Formatted Prompt Output Example\nDESCRIPTION: Example showing the formatted output of the prompt template after rendering with the provided parameters.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/prompt.rst#2025-04-14_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n<START_OF_SYSTEM_MESSAGE>You are a helpful assitant<END_OF_SYSTEM_MESSAGE>\n<TOOLS>\n1. google\n2. wikipedia\n3. wikidata\n</TOOLS>\n<START_OF_USER>What is the capital of France? <END_OF_USER>\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Limitations of Native Python Dataclasses\nDESCRIPTION: This snippet shows the limitations of native Python dataclasses when dealing with nested dataclasses and reconstruction. It illustrates that while dataclasses are powerful, they cannot automatically reconstruct nested dataclass structures.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# dataclass itself is powerful, but it can not reconstruct nested dataclass\nexample = TrecData(Question(\"What is the capital of France?\"), 1)\nprint(example)\n\nfrom dataclasses import asdict\n\nprint(asdict(example))\nreconstructed = TrecData(**asdict(example))\nprint(reconstructed)\nprint(reconstructed == example)\n```\n\n----------------------------------------\n\nTITLE: Setting up ReAct Agent Environment\nDESCRIPTION: Imports required packages and initializes environment variables for the ReAct agent implementation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport dotenv\nfrom adalflow.components.model_client import OpenAIClient\nfrom adalflow.components.agent.react import ReActAgent\nfrom adalflow.core.func_tool import FunctionTool\n\nimport time\n\n# load evironment, please set the relative path to your .env file that includes the api key\ndotenv.load_dotenv(dotenv_path=\"../../.env\", override=True)\n```\n\n----------------------------------------\n\nTITLE: Documenting Evaluation Module in reStructuredText\nDESCRIPTION: This snippet uses the automodule directive to generate documentation for the eval module, including all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/apis/eval/index.rst#2025-04-14_snippet_1\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: eval\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Adding Component Documentation in RST\nDESCRIPTION: Example of how to add documentation reference for a new component (like ollama_client) in the components API index file\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribution.rst#2025-04-14_snippet_1\n\nLANGUAGE: text\nCODE:\n```\ncomponents.model_client.ollama_client\n```\n\n----------------------------------------\n\nTITLE: Verifying Poetry Setup\nDESCRIPTION: Command to check if all dependencies are installed correctly using Poetry.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry check\n```\n\n----------------------------------------\n\nTITLE: Setting Up Root Dev Environment\nDESCRIPTION: Commands to set up the root development environment using Poetry and install dependencies.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribute_to_code.rst#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\npoetry shell\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Dependencies with pip\nDESCRIPTION: This snippet installs the AdalFlow package along with its OpenAI, GROQ, and FAISS CPU dependencies using pip. It also clears the output after installation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_tracing.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[openai,groq,faiss-cpu]\n\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Dependencies\nDESCRIPTION: Installation commands for AdalFlow package with OpenAI and Groq dependencies.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_dataclasses.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install adalflow[openai,groq]\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for API Keys\nDESCRIPTION: Script to securely set OpenAI API key as environment variables for AdalFlow configuration.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\n\n# Set environment variables\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Displaying AdalFlow Repository Structure\nDESCRIPTION: Shows the directory structure of the AdalFlow repository, including main directories for source code, documentation, tutorials, use cases, benchmarks, and configuration files.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribution.rst#2025-04-14_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n.\n├── .github/\n├── adalflow/\n│   ├── adalflow/\n│   ├── tests/\n|   ├── pyproject.toml\n├── docs/\n|   |── pyproject.toml\n├── tutorials/\n├── use_cases/\n├── benchmarks/\n├── notebooks/\n|   ├── tutorials/\n|   ├── use_cases/\n|   ├── benchmarks/\n├── .env_example\n├── .gitignore\n├── .pre-commit-config.yaml\n├── LICENSE.md\n├── README.md\n├── poetry.lock\n├── pyproject.toml\n```\n\n----------------------------------------\n\nTITLE: Loading MMLU Dataset with HuggingFace\nDESCRIPTION: Example of loading the MMLU (Massive Multitask Language Understanding) dataset using the Hugging Face datasets library. The code demonstrates how to load a specific subject from the MMLU dataset.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom datasets import load_dataset\ndataset = load_dataset(path=\"cais/mmlu\", name='abstract_algebra')\nprint(dataset[\"test\"])\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable in Python\nDESCRIPTION: This snippet sets the OpenAI API key as an environment variable and prints a confirmation message.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Building Poetry Package Locally\nDESCRIPTION: Command to build the Python package locally using Poetry.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/PACKAGING.md#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry build\n```\n\n----------------------------------------\n\nTITLE: Building AdalFlow Package for Testing\nDESCRIPTION: Commands to build the AdalFlow package and install the wheel file for testing notebooks with the latest changes. This process is recommended when testing notebooks against new package releases.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/README.md#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry build\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install your_path/dist/adalflow-0.1.0-py3-none-any.whl\n```\n\n----------------------------------------\n\nTITLE: Opening Built Documentation on Different Operating Systems\nDESCRIPTION: Commands to open the built documentation in a browser on macOS, Linux, and Windows.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# macOS\nopen build/html/index.html\n\n# Linux\nxdg-open build/html/index.html\n\n# Windows (manual instruction)\n# Manually open the index.html file in your preferred browser.\n```\n\n----------------------------------------\n\nTITLE: Displaying AdalFlow Checkpoint Directory Structure - Bash\nDESCRIPTION: Shows the directory structure for AdalFlow checkpoints, including random and constrained strategy training runs stored in JSON format.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/adalflow_in_15mins.rst#2025-04-14_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n.adalflow/\n├── ckpt/\n│   └── ObjectCountAdalComponent/\n│       random_max_steps_8_bb908_run_1.json # The last training run for random strategy\n│       constrained_max_steps_8_a1754_run_1.json # The last training run for constrained strategy\n```\n\n----------------------------------------\n\nTITLE: Configuring API Keys\nDESCRIPTION: Commands to copy the example environment file and instructions for adding API keys.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribute_to_code.rst#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n# example API keys:\n# OPENAI_API_KEY=YOUR_API_KEY_IF_YOU_USE_OPENAI\n# GROQ_API_KEY=YOUR_API_KEY_IF_YOU_USE_GROQ\n# ANTHROPIC_API_KEY=YOUR_API_KEY_IF_YOU_USE_ANTHROPIC\n# GOOGLE_API_KEY=YOUR_API_KEY_IF_YOU_USE_GOOGLE\n# COHERE_API_KEY=YOUR_API_KEY_IF_YOU_USE_COHERE\n# HF_TOKEN=YOUR_API_KEY_IF_YOU_USE_HF\n```\n\n----------------------------------------\n\nTITLE: Installing Additional Poetry Dependencies\nDESCRIPTION: Command to install additional optional dependencies for various AI services and vector storage.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/PACKAGING.md#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry install --extras \"anthropic cohere google-generativeai pgvector\"\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Package with Fireworks AI Support\nDESCRIPTION: Installs the AdalFlow package with Fireworks AI integration support using pip and clears the output.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/fireworks_integration.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[fireworks-ai]\n\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Creating New AdalFlow Notebook from Template\nDESCRIPTION: Command to copy the AdalFlow notebook template to create a new notebook. This ensures consistency across all notebooks in the project.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/README.md#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncp notebooks/adalflow_colab_template.ipynb notebooks/your_new_colab.ipynb\n```\n\n----------------------------------------\n\nTITLE: Async Event Loop Detection Utility\nDESCRIPTION: Implements utility functions to check if code is running in an event loop and handle synchronous functions appropriately. Includes a test function for executing sync operations with event loop awareness.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/react_note.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport time\n\ndef is_running_in_event_loop() -> bool:\n    try:\n        loop = asyncio.get_running_loop()\n        if loop.is_running():\n            return True\n        else:\n            return False\n    except RuntimeError:\n        return False\n\ndef sync_func():\n    time.sleep(1)\n    print(\"Sync function\")\n\ndef execute():\n    if is_running_in_event_loop():\n        print(\"Running in event loop\")\n        try:\n            result = asyncio.to_thread(sync_func)\n            print(\"Result\", result)\n        except RuntimeError:\n            print(\"Runtime error\")\n            sync_func()\n    else:\n        sync_func()\n```\n\n----------------------------------------\n\nTITLE: Configuring AdalFlow Root Logger\nDESCRIPTION: This code initializes the root logger for AdalFlow using a custom utility function.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_logger.ipynb#2025-04-14_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.utils.logger import get_logger\n\n\nroot_logger = get_logger()\n```\n\n----------------------------------------\n\nTITLE: Git Commit Commands\nDESCRIPTION: Basic git commands for committing and pushing changes\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribution.rst#2025-04-14_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngit add .\ngit commit -m \"Your commit message\"\ngit push origin your_branch_name\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure in reStructuredText\nDESCRIPTION: Example of how to structure the table of contents in an index.rst file using reStructuredText syntax.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_5\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :glob:\n   :maxdepth: 1\n   :caption: Get Started\n\n   get_started/installation\n   get_started/introduction\n```\n\n----------------------------------------\n\nTITLE: Building Documentation with Make\nDESCRIPTION: Commands to clean and rebuild the documentation after adding new RST files\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nmake clean\nmake html\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI API Key\nDESCRIPTION: Securely prompts for and sets up OpenAI API key as an environment variable.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_text_splitter.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom getpass import getpass\n\n# You can use a setup_env file to set the OPENAI_API_KEY too\n# (ensure you setup OPENAI_API_KEY in your project .env file) using the following commands:\n# from adalflow.utils import setup_env\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\n\n# Set environment variables\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Reloading AdalFlow Module in Python\nDESCRIPTION: This snippet reloads the AdalFlow module to ensure the latest version is used in the current session.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport importlib\nimport adalflow\n\nimportlib.reload(adalflow)\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies with Poetry\nDESCRIPTION: Installs required packages including test dependencies using Poetry package manager\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/tests/README.md#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry install --with test\n```\n\n----------------------------------------\n\nTITLE: Setting Up Together API Key\nDESCRIPTION: This code snippet securely prompts the user to enter their Together API key and sets it as an environment variable. It's a prerequisite for using the Together model client in AdalFlow.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/adalflow_together_deepseek_r1.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\ntogether_api_key = getpass(\"Please enter your Together API key: \")\n\n\n# Set environment variables\nos.environ[\"TOGETHER_API_KEY\"] = together_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Setting up API Keys\nDESCRIPTION: Configuration of OpenAI and Groq API keys using environment variables and secure input\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/qas/adalflow_object_count_auto_optimization.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\ngroq_api_key = getpass(\n    \"Please enter your GROQ API key, simplly press Enter if you don't have one: \"\n)\n\n# Set environment variables\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Setting up SambaNova API Key in Python\nDESCRIPTION: Prompts the user to enter their Mistral API key and sets it as an environment variable for SambaNova.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/sambanova_integration.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\nSAMBANOVA_API_KEY = getpass(\"Please enter your Mistral API key:\")\n\nos.environ[\"SAMBANOVA_API_KEY\"] = SAMBANOVA_API_KEY\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Student Traces Example in JSON for Few-Shot Optimization\nDESCRIPTION: Provides a JSON example of student model traces with ids, questions, answers, and scores that are used for weighted sampling during optimization.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/optimizer.rst#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"2d72e6e7-71a2-428d-90ff-6986ba52a0d3\": {\n        \"id\": \"2d72e6e7-71a2-428d-90ff-6986ba52a0d3\",\n        \"question\": \"I have a yam, a cauliflower, a bed, two cabbages, a garlic, an oven, a carrot, a head of broccoli, a potato, a stalk of celery, a lettuce head, and a toaster. How many vegetables do I have?\",\n        \"answer\": \"To determine the total number of vegetables, we need to count each type of vegetable and add them together.\\n\\n1. Yam: 1\\n2. Cauliflower: 1\\n3. Cabbages: 2\\n4. Garlic: 1\\n5. Carrot: 1\\n6. Broccoli: 1\\n7. Potato: 1\\n8. Celery: 1\\n9. Lettuce: 1\\n\\nNow, we sum these values:\\n\\n\\[ 1 + 1 + 2 + 1 + 1 + 1 + 1 + 1 + 1 = 10 \\]\\n\\nSo, the total number of vegetables is:\\n\\nAnswer: 10\",\n        \"score\": 1.0\n    },\n    \"37da1fbf-402c-44fc-a8b8-a45ad4690a47\": {\n        \"id\": \"37da1fbf-402c-44fc-a8b8-a45ad4690a47\",\n        \"question\": \"I have an apple, three bananas, a strawberry, a peach, three oranges, a plum, a raspberry, two grapes, a nectarine, and a blackberry. How many fruits do I have?\",\n        \"answer\": \"First, list each fruit mentioned:\\n\\n1. Apple\\n2. Three bananas\\n3. Strawberry\\n4. Peach\\n5. Three oranges\\n6. Plum\\n7. Raspberry\\n8. Two grapes\\n9. Nectarine\\n10. Blackberry\\n\\nNow, count each item:\\n\\n1. Apple\\n2. Three bananas\\n3. Strawberry\\n4. Peach\\n5. Three oranges\\n6. Plum\\n7. Raspberry\\n8. Two grapes\\n9. Nectarine\\n10. Blackberry\\n\\nAdd these numbers:\\n\\n1 + 3 + 1 + 1 + 3 + 1 + 1 + 2 + 1 + 1 = 14\\n\\nAnswer: 14\",\n        \"score\": 0.0\n    },\n    \"38404a09-0191-4f6f-8a12-4a392e464fe7\": {\n        \"id\": \"38404a09-0191-4f6f-8a12-4a392e464fe7\",\n        \"question\": \"I have a cauliflower, a stalk of celery, a cabbage, and a garlic. How many vegetables do I have?\",\n        \"answer\": \"First, list each vegetable mentioned:\\n\\n1. Cauliflower\\n2. Stalk of celery\\n3. Cabbage\\n4. Garlic\\n\\nNow, count each item:\\n\\n1. Cauliflower\\n2. Stalk of celery\\n3. Cabbage\\n4. Garlic\\n\\nAdd these numbers:\\n\\n1 + 1 + 1 + 1 = 4\\n\\nAnswer: 4\",\n        \"score\": 1.0\n    },\n    \"5869e6cd-bd3a-4682-bf52-417ab8b4e3cc\": {\n        \"id\": \"5869e6cd-bd3a-4682-bf52-417ab8b4e3cc\",\n        \"question\": \"I have an orange, three strawberries, an apple, three bananas, three raspberries, a peach, a blackberry, a grape, a plum, and two nectarines. How many fruits do I have?\",\n        \"answer\": \"First, list each fruit mentioned:\\n\\n1. Orange\\n2. Three strawberries\\n3. Apple\\n4. Three bananas\\n5. Three raspberries\\n6. Peach\\n7. Blackberry\\n8. Grape\\n9. Plum\\n10. Two nectarines\\n\\nNow, count each item:\\n\\n1. Orange\\n2. Three strawberries\\n3. Apple\\n4. Three bananas\\n5. Three raspberries\\n6. Peach\\n7. Blackberry\\n8. Grape\\n9. Plum\\n10. Two nectarines\\n\\nAdd these numbers:\\n\\n1 + 3 + 1 + 3 + 3 + 1 + 1 + 1 + 1 + 2 = 16\\n\\nAnswer: 16\",\n        \"score\": 0.0\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Computing BERTScore for Text Similarity in Python\nDESCRIPTION: Implementation of BERTScore using TorchMetrics to evaluate semantic similarity between generated text and reference text. BERTScore uses pre-trained BERT contextual embeddings and matches words using cosine similarity.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef compute_bertscore(gt, pred):\n    r\"\"\"\n    https://lightning.ai/docs/torchmetrics/stable/text/bert_score.html\n    \"\"\"\n    from torchmetrics.text.bert import BERTScore\n\n    bertscore = BERTScore()\n    return bertscore([pred], [gt])\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: Script to securely set up OpenAI API key using getpass for user input.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\n```\n\n----------------------------------------\n\nTITLE: Remote Repository Management\nDESCRIPTION: Commands for managing remote repositories and syncing with upstream\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribution.rst#2025-04-14_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit remote -v\ngit remote add upstream https://github.com/SylphAI-Inc/AdalFlow.git\n```\n\n----------------------------------------\n\nTITLE: Setting API Keys for OpenAI and GROQ\nDESCRIPTION: Securely prompts the user to enter API keys for OpenAI and GROQ, then sets them as environment variables for use in the notebook.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_function_calls.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Prompt user to enter their API keys securely\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\ngroq_api_key = getpass(\"Please enter your GROQ API key: \")\n\n# Set environment variables\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Branch Management Commands\nDESCRIPTION: Commands for creating and syncing feature branches\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribution.rst#2025-04-14_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngit fetch --all --prune\ngit rebase upstream/main\ngit push origin your_branch_name\n```\n\n----------------------------------------\n\nTITLE: Defining HTML Grid Layout for Integration Display\nDESCRIPTION: HTML and CSS code that creates a responsive grid layout for displaying integration partners with logos, names, and links to documentation. The styling includes hover effects and consistent formatting for the integration items.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/integrations/integrations.rst#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<style>\n      .integration-grid {\n         display: grid;\n         grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n         gap: 2rem;\n         margin: 2rem 0;\n      }\n      .integration-item {\n         text-align: center;\n         padding: 1rem;\n         border: 1px solid #eee;\n         border-radius: 8px;\n         transition: transform 0.2s, box-shadow 0.2s;\n      }\n      .integration-item:hover {\n         transform: translateY(-5px);\n         box-shadow: 0 5px 15px rgba(0,0,0,0.1);\n      }\n      .integration-item img {\n         max-width: 100px;\n         height: auto;\n         margin-bottom: 1rem;\n      }\n      .integration-item a {\n         text-decoration: none;\n         color: inherit;\n         display: flex;\n         flex-direction: column;\n         align-items: center;\n      }\n      .integration-item span {\n         font-weight: 500;\n      }\n   </style>\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI API Environment\nDESCRIPTION: Script to securely input and set OpenAI API key as environment variable\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_component.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom getpass import getpass\nimport os\n\nopenai_api_key = getpass(\"Please enter your OpenAI API key: \")\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Responsive Iframe Container for Trace Graph Visualization in HTML/CSS\nDESCRIPTION: HTML and CSS code for creating a responsive iframe container that displays a trace graph image. The implementation includes styling for the container, iframe, and zoom controls, providing a full-width display with maximum height constraints.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/qa_text_grad_trace_graph.rst#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<style>\n.iframe-container {\n    width: 100%;\n    height: 100vh; /* Full height of the viewport */\n    max-height: 1000px; /* Maximum height to ensure it doesn't get too tall on larger screens */\n    overflow: hidden;\n    position: relative;\n}\n.iframe-container iframe {\n    width: 100%;\n    height: 100%;\n    border: none;\n}\n.zoom-controls {\n    position: absolute;\n    top: 10px;\n    right: 10px;\n    display: flex;\n    gap: 10px;\n}\n.zoom-controls button {\n    padding: 5px 10px;\n    cursor: pointer;\n}\n</style>\n\n<div class=\"iframe-container\">\n    <iframe srcdoc=\"\n        <html>\n        <body style='margin:0; padding:0;'>\n            <img id='zoomImage' src='../_static/images/trace_graph_sum_id_e53cb8f9-235d-480b-b630-f480a9dfb5d0.png' style='width:100%; height:auto; transform-origin: center center; transition: transform 0.25s ease;'>\n        </body>\n        </html>\n    \"></iframe>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow with Dependencies\nDESCRIPTION: Installation commands for the AdalFlow package with required dependencies including OpenAI, Groq, and FAISS-CPU.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install adalflow[openai,groq,faiss-cpu]\n```\n\n----------------------------------------\n\nTITLE: Generator Call Logger Metadata JSON\nDESCRIPTION: Shows the structure of the metadata file that maps generator names to their respective log files. This helps organize and locate logs for different generators.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging_tracing.rst#2025-04-14_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"generator\": \"./traces/SimpleQA/generator_call.jsonl\",\n    \"generator2\": \"./traces/SimpleQA/generator2_call.jsonl\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI Environment Variables\nDESCRIPTION: Configures the OpenAI API key as an environment variable for authentication.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_classification_optimization.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Running Tests with Poetry\nDESCRIPTION: Commands to activate the virtual environment and run tests using pytest.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribute_to_code.rst#2025-04-14_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npoetry shell\npytest\n```\n\n----------------------------------------\n\nTITLE: Calculating Marginal Probability in REALM (LaTeX)\nDESCRIPTION: This LaTeX equation represents the marginal probability calculation in the REALM framework. It computes the probability of predicting the target output given an input by summing over all possible documents in the knowledge corpus.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/rag_playbook.rst#2025-04-14_snippet_1\n\nLANGUAGE: latex\nCODE:\n```\np(y | x) = \\sum_{z \\in Z} p(y | z, x) \\cdot p(z | x)\n```\n\n----------------------------------------\n\nTITLE: Generator State Trace JSON Structure\nDESCRIPTION: An example of the JSON structure generated by the state tracing feature, showing prompt states, variables, and timestamps for different generators. This helps track changes to prompts over time.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/logging_tracing.rst#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"generator\": [\n        {\n            \"prompt_states\": {\n                \"_components\": {},\n                \"_parameters\": {},\n                \"training\": false,\n                \"_template_string\": \"{# task desc #}\\n{% if task_desc_str %}\\n{{task_desc_str}}\\n{% else %}\\nAnswer user query.\\n{% endif %}\\n{# output format #}\\n{% if output_format_str %}\\n<OUTPUT_FORMAT>\\n{{output_format_str}}\\n</OUTPUT_FORMAT>\\n{% endif %}\\n{# tools #}\\n{% if tools_str %}\\n<TOOLS>\\n{{tools_str}}\\n</TOOLS>\\n{% endif %}\\n{# example #}\\n{% if examples_str %}\\n<EXAMPLES>\\n{{examples_str}}\\n</EXAMPLES>\\n{% endif %}\\n{# chat history #}\\n{% if chat_history_str %}\\n<CHAT_HISTORY>\\n{{chat_history_str}}\\n</CHAT_HISTORY>\\n{% endif %}\\n{#contex#}\\n{% if context_str %}\\n<CONTEXT>\\n{{context_str}}\\n</CONTEXT>\\n{% endif %}\\n{# steps #}\\n{% if steps_str %}\\n<STEPS>\\n{{steps_str}}\\n</STEPS>\\n{% endif %}\\n{% if input_str %}\\n<Inputs>\\n{{input_str}}\\n</Inputs>\\n{% endif %}\\n{% if output_str %}\\n<Outputs>\\n{{output_str}}\\n</Outputs>\\n{% endif %}\\n\",\n                \"prompt_variables\": [\n                    \"chat_history_str\",\n                    \"context_str\",\n                    \"examples_str\",\n                    \"input_str\",\n                    \"output_format_str\",\n                    \"output_str\",\n                    \"steps_str\",\n                    \"task_desc_str\",\n                    \"tools_str\"\n                ],\n                \"preset_prompt_kwargs\": {\n                    \"task_desc_str\": \"You are a helpful assistant and with a great sense of humor.\"\n                }\n            },\n            \"time_stamp\": \"2024-06-02T15:55:21.765794\"\n        },\n        {\n            \"prompt_states\": {\n                \"_components\": {},\n                \"_parameters\": {},\n                \"training\": false,\n                \"_template_string\": \"{# task desc #}\\n{% if task_desc_str %}\\n{{task_desc_str}}\\n{% else %}\\nAnswer user query.\\n{% endif %}\\n{# output format #}\\n{% if output_format_str %}\\n<OUTPUT_FORMAT>\\n{{output_format_str}}\\n</OUTPUT_FORMAT>\\n{% endif %}\\n{# tools #}\\n{% if tools_str %}\\n<TOOLS>\\n{{tools_str}}\\n</TOOLS>\\n{% endif %}\\n{# example #}\\n{% if examples_str %}\\n<EXAMPLES>\\n{{examples_str}}\\n</EXAMPLES>\\n{% endif %}\\n{# chat history #}\\n{% if chat_history_str %}\\n<CHAT_HISTORY>\\n{{chat_history_str}}\\n</CHAT_HISTORY>\\n{% endif %}\\n{#contex#}\\n{% if context_str %}\\n<CONTEXT>\\n{{context_str}}\\n</CONTEXT>\\n{% endif %}\\n{# steps #}\\n{% if steps_str %}\\n<STEPS>\\n{{steps_str}}\\n</STEPS>\\n{% endif %}\\n{% if input_str %}\\n<Inputs>\\n{{input_str}}\\n</Inputs>\\n{% endif %}\\n{% if output_str %}\\n<Outputs>\\n{{output_str}}\\n</Outputs>\\n{% endif %}\\n\",\n                \"prompt_variables\": [\n                    \"chat_history_str\",\n                    \"context_str\",\n                    \"examples_str\",\n                    \"input_str\",\n                    \"output_format_str\",\n                    \"output_str\",\n                    \"steps_str\",\n                    \"task_desc_str\",\n                    \"tools_str\"\n                ],\n                \"preset_prompt_kwargs\": {\n                    \"task_desc_str\": \"You are a helpful assistant and with a great sense of humor. Second edition.\"\n                }\n            },\n            \"time_stamp\": \"2024-06-02T15:56:37.756148\"\n        }\n    ],\n    \"generator2\": [\n    {\n        \"prompt_states\": {\n            \"_components\": {},\n            \"_parameters\": {},\n            \"training\": false,\n            \"_template_string\": \"{# task desc #}\\n{% if task_desc_str %}\\n{{task_desc_str}}\\n{% else %}\\nAnswer user query.\\n{% endif %}\\n{# output format #}\\n{% if output_format_str %}\\n<OUTPUT_FORMAT>\\n{{output_format_str}}\\n</OUTPUT_FORMAT>\\n{% endif %}\\n{# tools #}\\n{% if tools_str %}\\n<TOOLS>\\n{{tools_str}}\\n</TOOLS>\\n{% endif %}\\n{# example #}\\n{% if examples_str %}\\n<EXAMPLES>\\n{{examples_str}}\\n</EXAMPLES>\\n{% endif %}\\n{# chat history #}\\n{% if chat_history_str %}\\n<CHAT_HISTORY>\\n{{chat_history_str}}\\n</CHAT_HISTORY>\\n{% endif %}\\n{#contex#}\\n{% if context_str %}\\n<CONTEXT>\\n{{context_str}}\\n</CONTEXT>\\n{% endif %}\\n{# steps #}\\n{% if steps_str %}\\n<STEPS>\\n{{steps_str}}\\n</STEPS>\\n{% endif %}\\n{% if input_str %}\\n<Inputs>\\n{{input_str}}\\n</Inputs>\\n{% endif %}\\n{% if output_str %}\\n<Outputs>\\n{{output_str}}\\n</Outputs>\\n{% endif %}\\n\",\n            \"prompt_variables\": [\n                \"chat_history_str\",\n                \"context_str\",\n                \"examples_str\",\n                \"input_str\",\n                \"output_format_str\",\n                \"output_str\",\n                \"steps_str\",\n                \"task_desc_str\",\n                \"tools_str\"\n            ],\n            \"preset_prompt_kwargs\": {\n                \"task_desc_str\": \"You are the second generator.\"\n            }\n        },\n        \"time_stamp\": \"2024-06-03T16:44:45.223220\"\n    }\n]\n}\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Package\nDESCRIPTION: Command to install or upgrade AdalFlow using pip package manager\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/installation.rst#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U adalflow\n```\n\n----------------------------------------\n\nTITLE: Formatting DataClass Examples in JSON and YAML\nDESCRIPTION: This snippet demonstrates how to format DataClass examples as strings in JSON and YAML formats using the DataClassFormatType enum.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import DataClassFormatType\n\nexample_str = example.format_example_str(DataClassFormatType.EXAMPLE_JSON)\nprint(example_str)\n\nexample_str = example.format_example_str(DataClassFormatType.EXAMPLE_YAML)\nprint(example_str)\n```\n\n----------------------------------------\n\nTITLE: Installing Adalflow Dependencies\nDESCRIPTION: This snippet installs the required Adalflow packages and their dependencies, including OpenAI, Groq, and FAISS CPU support.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[openai,groq,faiss-cpu]\n\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Configuring AdalFlow Root Logger with File Output\nDESCRIPTION: This snippet sets up the AdalFlow root logger with debug level and specifies a file for log output.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_logger.ipynb#2025-04-14_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom adalflow.utils.logger import get_logger\n\nroot_logger = get_logger(level=\"DEBUG\", save_dir=\"./logs\")  # log to ./logs/lib.log\n\n# run code from the library components such as generator\n# ....\n\nroot_logger.info(\"This is the log in the main file\")\n```\n\n----------------------------------------\n\nTITLE: Package Dependencies List\nDESCRIPTION: List of Python packages required for the project, including documentation tools like Sphinx and its extensions, along with data processing libraries like NumPy. Version numbers are specified for critical dependencies to ensure compatibility.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/requirements.txt#2025-04-14_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npydata-sphinx-theme==0.15.3\nsphinx-design==0.6.0\nsphinx-copybutton==0.5.2\nsphinx==7.3.7\nnbsphinx==0.9.4\nnbconvert==7.16.4\nPyYAML\nreadthedocs-sphinx-search==0.3.2\nnumpy\ntqdm\ntiktoken\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Library in Python\nDESCRIPTION: Installs the latest version of AdalFlow using pip and clears the output.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/sambanova_integration.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow\n\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Package Installation with Output Clearing\nDESCRIPTION: Python script that installs AdalFlow and its dependencies, then clears the output using IPython display functionality\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/adalflow_colab_template.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[openai,groq,faiss-cpu]\n\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Defining Evaluation Module Structure in reStructuredText\nDESCRIPTION: This snippet outlines the structure of the evaluation module documentation using reStructuredText directives. It includes an autosummary of submodules and a hidden toctree for detailed pages.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/apis/eval/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. autosummary::\n\n\n   eval.base\n\n   eval.answer_match_acc\n   eval.retriever_recall\n   eval.llm_as_judge\n   eval.g_eval\n\n\n.. toctree::\n   :maxdepth: 1\n   :hidden:\n\n   eval.base\n   eval.answer_match_acc\n   eval.retriever_recall\n   eval.llm_as_judge\n   eval.g_eval\n```\n\n----------------------------------------\n\nTITLE: Setting up xAI API Authentication\nDESCRIPTION: Configures the xAI API key by prompting the user for input and setting it as an environment variable.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/xai_integration.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\nXAI_API_KEY = getpass(\"Please enter your xAI API key:\")\n\nos.environ[\"XAI_API_KEY\"] = XAI_API_KEY\n\nprint(\"API keys have been set.\")\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Dependencies\nDESCRIPTION: Installs AdalFlow library with OpenAI, Groq, and FAISS CPU dependencies.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_text_splitter.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install adalflow[openai,groq,faiss-cpu]\n```\n\n----------------------------------------\n\nTITLE: Defining toctree Structure in ReStructuredText\nDESCRIPTION: Creates a structured table of contents for AdalFlow tutorials using ReStructuredText's toctree directive. The configuration includes maxdepth setting, caption, and hidden attribute with links to individual tutorial pages.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n   :caption: Basics\n   :hidden:\n\n   introduction\n   prompt\n   parser\n   generator\n   embedder\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow via pip\nDESCRIPTION: Provides the command to install AdalFlow using pip, the Python package installer. This is the quickest way to get started with AdalFlow.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/README.md#2025-04-14_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npip install adalflow\n```\n\n----------------------------------------\n\nTITLE: Displaying AdalFlow Checkpoint File Structure in Bash\nDESCRIPTION: Shows the file structure for AdalFlow checkpoints after training, including files for random and constrained training strategies.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/question_answering.rst#2025-04-14_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n.adalflow/\n├── ckpt/\n│   └── ObjectCountAdalComponent/\n│       random_max_steps_8_bb908_run_1.json # The last training run for random strategy\n│       constrained_max_steps_8_a1754_run_1.json # The last training run for constrained strategy\n```\n\n----------------------------------------\n\nTITLE: Adding Test Dependencies with Poetry\nDESCRIPTION: Command to add a new test dependency to the project using Poetry.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribute_to_code.rst#2025-04-14_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npoetry add --group test <package-name>\n```\n\n----------------------------------------\n\nTITLE: Implementing JSON Viewer iframe Container with HTML\nDESCRIPTION: HTML structure for embedding a JSON file viewer within an iframe, referencing an external JSON file from the _static/files directory.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/ckpt_file.rst#2025-04-14_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"iframe-container\">\n    <iframe src=\"../_static/files/constrained_max_steps_12_a1754_run_1.json\"></iframe>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Default AdalFlow LLM Judgment Query\nDESCRIPTION: The default judgment query string used by AdalFlow's LLM judge to evaluate if a predicted answer contains the ground truth answer. Returns True or False response.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nDEFAULT_JUDGEMENT_QUERY = \"Does the predicted answer contain the ground truth answer? Say True if yes, False if no.\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Limitation of Required Fields After Optional Fields in Dataclasses\nDESCRIPTION: This commented-out snippet illustrates that standard Python dataclasses do not allow required fields to be placed after optional fields. This limitation is addressed in subsequent custom implementations.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# # it does not allow required field after optional field\n# @dataclass\n# class TrecData2:\n#     question: Question = field(\n#         metadata={\"desc\": \"The question asked by the user\"}\n#     ) # Required field, you have to provide the question field at the instantiation\n#     label: int = field(\n#         metadata={\"desc\": \"The label of the question\"}, default=0\n#     ) # Optional field\n#     metadata: dict = field(\n#         metadata={\"desc\": \"The metadata of the question\"}\n#     ) # required field\n```\n\n----------------------------------------\n\nTITLE: Building Documentation with Verbose Output\nDESCRIPTION: Command to build documentation with detailed logs for debugging purposes.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nsphinx-build -b html source build -v\n```\n\n----------------------------------------\n\nTITLE: Updating HTTP Libraries\nDESCRIPTION: This snippet updates the HTTP-related libraries to ensure compatibility with the Adalflow package.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_playbook.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip uninstall httpx anyio -y\n!pip install \"anyio>=3.1.0,<4.0\"\n!pip install httpx==0.24.1\n```\n\n----------------------------------------\n\nTITLE: Generating RST Files with sphinx-apidoc\nDESCRIPTION: Command to automatically generate .rst files for new modules using sphinx-apidoc, excluding test files.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsphinx-apidoc --force -o docs/source/tutorials ./use_cases \"*test*\"\n```\n\n----------------------------------------\n\nTITLE: Using DataClassFormatType for Various Formatting Options\nDESCRIPTION: This snippet shows how to use the DataClassFormatType enum to control the formatting of custom DataClass objects, including JSON and YAML signatures and schema generation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/dataclass.ipynb#2025-04-14_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.core import DataClassFormatType\n\njson_signature = TrecData2.format_class_str(DataClassFormatType.SIGNATURE_JSON)\nprint(json_signature)\n\nyaml_signature = TrecData2.format_class_str(DataClassFormatType.SIGNATURE_YAML)\nprint(yaml_signature)\n\nschema = TrecData2.format_class_str(DataClassFormatType.SCHEMA)\nprint(schema)\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow with Dependencies\nDESCRIPTION: Command to install AdalFlow Python package with OpenAI and Groq extra packages using pip.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_rag_optimization.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install adalflow[openai,groq]\n```\n\n----------------------------------------\n\nTITLE: Example .gitignore for Documentation Project\nDESCRIPTION: Example .gitignore file content to exclude unnecessary files from version control in a documentation project.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_12\n\nLANGUAGE: plaintext\nCODE:\n```\n# Ignore build files\ndocs/build/\n*.pyc\n__pycache__/\n```\n\n----------------------------------------\n\nTITLE: REALM Loss Function Calculation (LaTeX)\nDESCRIPTION: This LaTeX equation defines the loss function used in REALM. It represents the log-likelihood of the correct prediction, which is the training objective for optimizing the retriever.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/rag_playbook.rst#2025-04-14_snippet_2\n\nLANGUAGE: latex\nCODE:\n```\n\\mathcal{L} = \\log p(y | x) = \\log \\left( \\sum_{z \\in Z} p(y | z, x) \\cdot p(z | x) \\right)\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText API Reference Block\nDESCRIPTION: An admonition block in ReStructuredText format listing the main API components of the AdalFlow framework, including core functionality, components, evaluation tools, and utilities.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/generator.rst#2025-04-14_snippet_11\n\nLANGUAGE: rst\nCODE:\n```\n.. admonition:: API reference\n   :class: highlight\n\n   - :class:`core.generator.Generator`\n   - :class:`core.types.GeneratorOutput`\n   - :class:`core.default_prompt_template.DEFAULT_ADALFLOW_SYSTEM_PROMPT`\n   - :class:`core.types.ModelClientType`\n   - :class:`core.types.ModelType`\n   - :class:`core.string_parser.JsonParser`\n   - :class:`core.prompt_builder.Prompt`\n   - :class:`tracing.generator_call_logger.GeneratorCallLogger`\n   - :class:`tracing.generator_state_logger.GeneratorStateLogger`\n   - :class:`components.retriever.llm_retriever.LLMRetriever`\n   - :class:`components.agent.react.ReActAgent`\n   - :class:`eval.llm_as_judge.DefaultLLMJudge`\n   - :class:`optim.text_grad.tgd_optimizer.TGDOptimizer`\n   - :func:`utils.config.new_component`\n```\n\n----------------------------------------\n\nTITLE: Setting up AdalFlow Directory Structure\nDESCRIPTION: Defines the recommended directory structure for the AdalFlow project documentation, including source files, build directories, and configuration files\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_13\n\nLANGUAGE: plaintext\nCODE:\n```\nAdalFlow/\n├── docs/\n│   ├── apis/\n│   │   ├── core/\n│   │   │   ├── core.module1.rst\n│   │   │   ├── core.module2.rst\n│   │   ├── components/\n│   │   │   ├── components.module1.rst\n│   │   │   ├── components.module2.rst\n│   ├── build/\n│   │   ├── html/\n│   │   │   ├── _static/\n│   │   │   ├── _templates/\n│   │   │   ├── index.html\n│   │   │   ├── core/\n│   │   │   │   ├── core.module1.html\n│   │   │   │   ├── core.module2.html\n│   │   │   ├── components/\n│   │   │   │   ├── components.module1.html\n│   │   │   │   ├── components.module2.html\n│   ├── _static/\n│   ├── _templates/\n│   ├── conf.py\n│   ├── index.rst\n│   ├── Makefile\n│   ├── pyproject.toml\n│   ├── poetry.lock\n```\n\n----------------------------------------\n\nTITLE: Displaying Community Platform Badges in HTML\nDESCRIPTION: HTML markup for displaying badges and links to AdalFlow's community platforms including GitHub Discussions, Issues, and Discord server. Uses styled div containers and embedded badge images.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/get_started/community.rst#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<div style=\"text-align: center; margin-bottom: 20px;\">\n      <a href=\"https://github.com/SylphAI-Inc/AdalFlow/discussions\" style=\"display: inline-block; margin-left: 10px;\">\n         <img src=\"https://img.shields.io/badge/GitHub Discussions-AdalFlow-blue?logo=github&style=flat-square\" alt=\"GitHub Repo\">\n      </a>\n        <a href=\"https://github.com/SylphAI-Inc/AdalFlow/issues\" style=\"display: inline-block; margin-left: 10px;\">\n         <img src=\"https://img.shields.io/badge/Bugs/Feature Requests-AdalFlow-blue?logo=github&style=flat-square\" alt=\"GitHub Repo\">\n      </a>\n      <a href=\"https://discord.gg/ezzszrRZvT\" style=\"display: inline-block; margin-left: 10px;\">\n        <img alt=\"discord-invite\" src=\"https://dcbadge.vercel.app/api/server/ezzszrRZvT?style=flat\">\n      </a>\n\n   </div>\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies with Poetry\nDESCRIPTION: Command to install all necessary project dependencies using Poetry.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Examining HotpotQA Dataset Sample\nDESCRIPTION: Shows how to inspect a validation sample from the HotpotQA dataset and print its attributes.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/use_cases/agent/react_agent_hotpot_qa.ipynb#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# check the data sample\ntest_sample = dataset[\"validation\"][0]\nprint(f\"len of eval: {len(dataset['validation'])}\")\nprint(f\"example: {test_sample}\")\nprint(f\"attributes in each sample: {list(test_sample.keys())}\")\n```\n\n----------------------------------------\n\nTITLE: Running Individual Test Function with Pytest\nDESCRIPTION: Executes a specific test function or class method\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/tests/README.md#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npytest tests/test_file.py::test_function\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure\nDESCRIPTION: ReStructuredText documentation layout defining the structure of the optimization module documentation, including autosummary directives and module references.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/apis/optim/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. _apis-optim:\n\nOptimization\n==============\n\nBase Classes and Data Structures\n----------------------------------\nThe ``GradComponent`` and ``LossComponent`` are a subclass from ``Component`` to serve the purpose to differentiate the gradient and loss components in the optimization process.\nAnd it will be used if users want to implement their own with more customization.\n\n.. autosummary::\n\n   optim.parameter\n   optim.optimizer\n   optim.grad_component\n   optim.loss_component\n   optim.types\n```\n\n----------------------------------------\n\nTITLE: Example Output of HotPotQA Dataset Entry\nDESCRIPTION: Shows the structure of a HotPotQA dataset entry, which includes an ID, question, answer, and gold titles that serve as reference information for the question.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/rag_opt.rst#2025-04-14_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nHotPotQAData(id='5a8b57f25542995d1e6f1371', question='Were Scott Derrickson and Ed Wood of the same nationality?', answer='yes', gold_titles=\"{'Scott Derrickson', 'Ed Wood'}\")\n```\n\n----------------------------------------\n\nTITLE: Styling JSON Viewer iframe Container with CSS\nDESCRIPTION: CSS styles that define a responsive container for the JSON viewer iframe, with viewport-based height scaling and maximum height constraint of 1000px.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/ckpt_file.rst#2025-04-14_snippet_0\n\nLANGUAGE: css\nCODE:\n```\n.iframe-container {\n    width: 100%;\n    height: 100vh;\n    max-height: 1000px;\n    overflow: hidden;\n    position: relative;\n}\n.iframe-container iframe {\n    width: 100%;\n    height: 100%;\n    border: none;\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring reStructuredText toctree for Integrations\nDESCRIPTION: Sets up a table of contents (toctree) directive for the Integrations section with a maximum depth of 1 and a caption. The toctree references a file named 'integrations' that contains the actual integration listings.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/integrations/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n    :maxdepth: 1\n    :caption: Integrations\n\n    integrations\n```\n\n----------------------------------------\n\nTITLE: Testing Documentation Build\nDESCRIPTION: Command to run a thorough test of the documentation build process, treating warnings as errors.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nsphinx-build -n -W --keep-going source build\n```\n\n----------------------------------------\n\nTITLE: AdalFlow Module Structure in RST\nDESCRIPTION: ReStructuredText markup defining the documentation structure and module organization for the AdalFlow library. Lists all major package components and their submodules using autosummary directives.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/apis/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   core.component\n   core.container\n   core.base_data_class\n   core.default_prompt_template\n   core.model_client\n   core.db\n   core.functional\n\n   core.generator\n   core.string_parser\n   core.embedder\n   core.retriever\n\n   core.prompt_builder\n   core.tokenizer\n   core.func_tool\n   core.tool_manager\n   core.types\n   core.parameter\n```\n\n----------------------------------------\n\nTITLE: Cloning AdalFlow Repository\nDESCRIPTION: Git commands to clone the AdalFlow repository and navigate to the project directory.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/SylphAI-Inc/AdalFlow.git\ncd AdalFlow\n```\n\n----------------------------------------\n\nTITLE: Upgrading Poetry\nDESCRIPTION: Command to upgrade Poetry to the latest version if issues are encountered.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade poetry\n```\n\n----------------------------------------\n\nTITLE: Running Test with Verbose Output\nDESCRIPTION: Executes a test with verbose output and showing test execution details\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/tests/README.md#2025-04-14_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npytest tests/test_file.py::test_function -v -s\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow Dependencies with Python\nDESCRIPTION: This snippet installs the AdalFlow library with OpenAI, Groq, and FAISS-CPU dependencies using pip. It also clears the output after installation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_logger.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[openai,groq,faiss-cpu]\n\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Installing AdalFlow with Mistral AI Integration\nDESCRIPTION: Installs the AdalFlow package with Mistral AI support using pip and clears the output.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/integration/mistral_integration.ipynb#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import clear_output\n\n!pip install -U adalflow[mistralai]\n\nclear_output()\n```\n\n----------------------------------------\n\nTITLE: Example Poetry Install Output\nDESCRIPTION: Example output from installing the adalflow package in development mode using Poetry.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribute_to_code.rst#2025-04-14_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n- Installing adalflow (0.2.5 /Users/liyin/Documents/test/AdalFlow/adalflow)\n```\n\n----------------------------------------\n\nTITLE: HTML Container for Embedding Computation Graph Visualization\nDESCRIPTION: HTML structure for embedding the computation graph visualization within an iframe. The iframe contains an HTML document with an image of the graph that supports zooming and panning.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/qa_computation_graph.rst#2025-04-14_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"iframe-container\">\n    <iframe srcdoc=\"\n        <html>\n        <body style='margin:0; padding:0;'>\n            <img id='zoomImage' src='../_static/images/trace_graph_Generator_output_id_689cc5a1-6737-40a8-8faa-8bbf7bddfed8.png' style='width:100%; height:auto; transform-origin: center center; transition: transform 0.25s ease;'>\n        </body>\n        </html>\n    \"></iframe>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Installing Local Package with Optional Dependencies\nDESCRIPTION: Command to install the locally built wheel file with specified optional dependencies using pip.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/PACKAGING.md#2025-04-14_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install \"dist/adalflow-0.1.0b1-py3-none-any.whl[openai,groq,faiss]\"\n```\n\n----------------------------------------\n\nTITLE: Building Documentation with Sphinx\nDESCRIPTION: Commands to navigate to the docs directory, clean previous builds, and generate new HTML documentation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/README.md#2025-04-14_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nmake clean\nmake html\n```\n\n----------------------------------------\n\nTITLE: Installing Optional Poetry Dependencies\nDESCRIPTION: Command to install optional dependencies for AI services and vector databases using Poetry package manager.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/PACKAGING.md#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry install --extras \"openai groq faiss\"\n```\n\n----------------------------------------\n\nTITLE: Sphinx Dataset Documentation Structure\nDESCRIPTION: RST markup for organizing dataset documentation including autosummary and toctree directives for various dataset modules.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/apis/datasets/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n\n   datasets.big_bench_hard\n   datasets.trec\n   datasets.hotpot_qa\n   datasets.types\n\n.. toctree::\n   :maxdepth: 1\n   :hidden:\n\n   datasets.big_bench_hard\n   datasets.trec\n   datasets.hotpot_qa\n   datasets.types\n\n.. automodule:: datasets\n   :members:\n   :undoc-members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: BERTScore Output Example in JSON\nDESCRIPTION: Example output from a BERTScore evaluation showing precision, recall, and F1 scores as tensor values. This illustrates how BERTScore captures semantic similarity more effectively than BLEU or ROUGE.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/evaluation.rst#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{'precision': tensor(0.9752), 'recall': tensor(0.9827), 'f1': tensor(0.9789)}\n```\n\n----------------------------------------\n\nTITLE: Implementing Responsive Iframe Image Viewer with Zoom Controls\nDESCRIPTION: HTML and CSS implementation for displaying a trace graph image within a responsive iframe container. Includes styling for container dimensions, zoom controls positioning, and image transition effects.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/qa_demo_trace_graph.rst#2025-04-14_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<style>\n.iframe-container {\n    width: 100%;\n    height: 100vh; /* Full height of the viewport */\n    max-height: 1000px; /* Maximum height to ensure it doesn't get too tall on larger screens */\n    overflow: hidden;\n    position: relative;\n}\n.iframe-container iframe {\n    width: 100%;\n    height: 100%;\n    border: none;\n}\n.zoom-controls {\n    position: absolute;\n    top: 10px;\n    right: 10px;\n    display: flex;\n    gap: 10px;\n}\n.zoom-controls button {\n    padding: 5px 10px;\n    cursor: pointer;\n}\n</style>\n<div class=\"iframe-container\">\n    <iframe srcdoc=\"\n        <html>\n        <body style='margin:0; padding:0;'>\n            <img id='zoomImage' src='../_static/images/trace_graph_EvalFnToTextLoss_output_id_6ea5da3c-d414-4aae-8462-75dd1e09abab.png' style='width:100%; height:auto; transform-origin: center center; transition: transform 0.25s ease;'>\n        </body>\n        </html>\n    \"></iframe>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Defining Trainable Prompts as Parameters in AdalFlow\nDESCRIPTION: This code demonstrates how to define trainable prompts as parameters in AdalFlow. It shows examples for both a system prompt and few-shot demonstrations, which can be optimized during training.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/new_tutorials/generator.rst#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom adalflow.optim.parameter import ParameterType\n\nsystem_prompt = adal.Parameter(\n        data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n        role_desc=\"To give task instruction to the language model in the system prompt\",\n        requires_opt=True,\n        param_type=ParameterType.PROMPT,\n        instruction_to_optimizer=\"You can try to show examples to see if it helps.\",\n)\n\nfew_shot_demos = adal.Parameter(\n        data=None,\n        role_desc=\"To provide few shot demos to the language model\",\n        requires_opt=True,\n        param_type=ParameterType.DEMOS,\n)\n```\n\n----------------------------------------\n\nTITLE: Styling HTML Container for Computation Graph Visualization\nDESCRIPTION: CSS styling for a responsive iframe container that displays the computation graph visualization. Includes styling for the container, iframe, and zoom controls with positioning and layout properties.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/use_cases/qa_computation_graph.rst#2025-04-14_snippet_0\n\nLANGUAGE: css\nCODE:\n```\n<style>\n.iframe-container {\n    width: 100%;\n    height: 100vh; /* Full height of the viewport */\n    max-height: 1000px; /* Maximum height to ensure it doesn't get too tall on larger screens */\n    overflow: hidden;\n    position: relative;\n}\n.iframe-container iframe {\n    width: 100%;\n    height: 100%;\n    border: none;\n}\n.zoom-controls {\n    position: absolute;\n    top: 10px;\n    right: 10px;\n    display: flex;\n    gap: 10px;\n}\n.zoom-controls button {\n    padding: 5px 10px;\n    cursor: pointer;\n}\n</style>\n```\n\n----------------------------------------\n\nTITLE: Styling Class Hierarchy Visualization with CSS\nDESCRIPTION: CSS styles to create a responsive iframe container for displaying the class hierarchy visualization. The styles ensure proper display across different screen sizes, with specific adjustments for mobile viewports.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/tutorials/class_hierarchy.rst#2025-04-14_snippet_0\n\nLANGUAGE: css\nCODE:\n```\n.iframe-container {\n    width: 100%;\n    height: 100vh; /* Full height of the viewport */\n    max-height: 1000px; /* Maximum height to ensure it doesn't get too tall on larger screens */\n    overflow: hidden;\n}\n.iframe-container iframe {\n    width: 100%;\n    height: 100%;\n    border: none;\n}\n@media (max-width: 768px) {\n    .iframe-container {\n        height: 60vh; /* Adjust height for mobile viewports */\n        max-height: none; /* Remove the maximum height constraint for small screens */\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Module Documentation Structure\nDESCRIPTION: Documentation structure using ReStructuredText format defining the core modules and their organization in the documentation tree\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/apis/core/index.rst#2025-04-14_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. _apis-core:\n\nCore\n===================\n\n\nCore building blocks for RAG and more advanced functionalities, such as agents.\n\n\nOverview\n----------\n.. autosummary::\n\n   core.base_data_class\n   core.component\n   core.container\n   core.default_prompt_template\n   core.embedder\n   core.generator\n   core.model_client\n   core.prompt_builder\n   core.retriever\n   core.string_parser\n   core.func_tool\n   core.tool_manager\n   core.types\n   core.db\n   core.functional\n   core.tokenizer\n\n\n\n\n.. toctree::\n   :maxdepth: 1\n   :hidden:\n\n   core.base_data_class\n   core.component\n   core.container\n   core.default_prompt_template\n   core.embedder\n   core.generator\n   core.model_client\n   core.prompt_builder\n   core.retriever\n   core.string_parser\n   core.func_tool\n   core.tool_manager\n   core.types\n   core.db\n   core.functional\n   core.tokenizer\n```\n\n----------------------------------------\n\nTITLE: Explaining ReAct Agent Extensions in Markdown\nDESCRIPTION: This snippet details the extensions made to the original ReAct paper, including support for different types of tools and the flexibility of tool adaptation.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/adalflow/components/agent/README.md#2025-04-14_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n# The initial ReAct paper does not support different types of tools. We have greatly extended the flexibility of tool adaption, even including an llm tool\n# to answer questions that cant be answered or better be answered by llm using its world knowledge.\n# - Every react agent can be given a different tasks, different tools, and different LLM models to complete the task.\n# - 'finish' tool is defined to finish the task by joining all subqueries answers.\n```\n\n----------------------------------------\n\nTITLE: Building Hacker News in Arc\nDESCRIPTION: Paul Graham created Hacker News as a test application for a new version of Arc that compiled to Scheme. Initially called Startup News, it was later renamed to Hacker News to broaden its scope beyond startup-focused content.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/tutorials/paul_graham/paul_graham_essay.txt#2025-04-14_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Implementing Basic Logging in a Python Class\nDESCRIPTION: This example shows how to set up logging within a Python class using the standard logging module.\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/notebooks/tutorials/adalflow_logger.ipynb#2025-04-14_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport logging\n\nlog = logging.getLogger(__name__)\n\n\nclass Task:\n    def __init__(self):\n        log.info(\"This is a user program child logger\")\n```\n\n----------------------------------------\n\nTITLE: Running Test with Extended Verbose Output\nDESCRIPTION: Executes a test with extra verbose output showing local variables\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/tests/README.md#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npytest tests/test_file.py::test_function -vv\n```\n\n----------------------------------------\n\nTITLE: Running Specific Test File with Pytest\nDESCRIPTION: Executes all tests within a specific test file\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/adalflow/tests/README.md#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npytest tests/test_file.py\n```\n\n----------------------------------------\n\nTITLE: Development Environment Setup\nDESCRIPTION: Commands for setting up the poetry environment and pre-commit hooks\nSOURCE: https://github.com/SylphAI-Inc/AdalFlow/blob/main/docs/source/contributor/contribution.rst#2025-04-14_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install poetry\npoetry install\npoetry shell\npre-commit install\n```"
  }
]