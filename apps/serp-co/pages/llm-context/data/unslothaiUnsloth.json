[
  {
    "owner": "unslothai",
    "repo": "unsloth",
    "content": "TITLE: Initializing and Fine-Tuning 4-bit Quantized LLMs with Unsloth in Python\nDESCRIPTION: This Python snippet demonstrates selecting from a list of supported 4-bit pre-quantized Unsloth models, then loading and preparing a model with FastModel.from_pretrained, enabling memory optimization settings like 4-bit quantization. It applies LoRA PEFT adapters via FastLanguageModel.get_peft_model and invokes SFTTrainer for supervised finetuning, specifying configuration via SFTConfig. Dependencies include Unsloth, an available dataset, and a supported GPU environment. Key parameters such as model name, quantization, context length, and LoRA adapter tuning are exposed for customization. Outputs are trained models saved to disk, and inputs must include a suitable 'dataset' with a 'text' field. This template is extensible for various Unsloth-supported models and accommodates advanced settings for memory and speed.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\nfourbit_models = [\n    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n    \"unsloth/Phi-3-medium-4k-instruct\",\n    \"unsloth/gemma-2-9b-bnb-4bit\",\n    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n\n    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n\n    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n] # More models at https://huggingface.co/unsloth\n\nmodel, tokenizer = FastModel.from_pretrained(\n    model_name = \"unsloth/gemma-3-4B-it\",\n    max_seq_length = 2048, # Choose any for long context!\n    load_in_4bit = True,  # 4 bit quantization to reduce memory\n    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n    full_finetuning = False, # [NEW!] We have full finetuning now!\n    # token = \"hf_...\", # use one if using gated models\n)\n\n# Do model patching and add fast LoRA weights\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 16,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    max_seq_length = max_seq_length,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)\n\ntrainer = SFTTrainer(\n    model = model,\n    train_dataset = dataset,\n    tokenizer = tokenizer,\n    args = SFTConfig(\n        dataset_text_field = \"text\",\n        max_seq_length = max_seq_length,\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 10,\n        max_steps = 60,\n        logging_steps = 1,\n        output_dir = \"outputs\",\n        optim = \"adamw_8bit\",\n        seed = 3407,\n    ),\n)\ntrainer.train()\n\n# Go to https://github.com/unslothai/unsloth/wiki for advanced tips like\n# (1) Saving to GGUF / merging to 16bit for vLLM\n# (2) Continued training from a saved LoRA adapter\n# (3) Adding an evaluation loop / OOMs\n# (4) Customized chat templates\n```\n\n----------------------------------------\n\nTITLE: Reinforcement Learning via DPO with Unsloth and TRL in Python\nDESCRIPTION: This Python snippet demonstrates setting up a reinforcement learning finetuning workflow using Unsloth models in conjunction with Hugging Face's TRL library for Direct Preference Optimization (DPO). It optionally sets GPU device selection, initializes the model and tokenizer with 4-bit quantization, applies fast LoRA/PEFT adapters, and configures the DPOTrainer with training and hyperparameter options. Required dependencies are Unsloth, torch, and trl, with access to a CUDA GPU highly recommended. Key parameters include dataset, LoRA rank, optimizer choice, and DPO-specific settings like beta. The input must include a ready dataset for training; outputs are a DPO-finetuned model.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Optional set GPU device ID\n\nfrom unsloth import FastLanguageModel\nimport torch\nfrom trl import DPOTrainer, DPOConfig\nmax_seq_length = 2048\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/zephyr-sft-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    load_in_4bit = True,\n)\n\n# Do model patching and add fast LoRA weights\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 64,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 64,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    max_seq_length = max_seq_length,\n)\n\ndpo_trainer = DPOTrainer(\n    model = model,\n    ref_model = None,\n    train_dataset = YOUR_DATASET_HERE,\n    # eval_dataset = YOUR_DATASET_HERE,\n    tokenizer = tokenizer,\n    args = DPOConfig(\n        per_device_train_batch_size = 4,\n        gradient_accumulation_steps = 8,\n        warmup_ratio = 0.1,\n        num_train_epochs = 3,\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        seed = 42,\n        output_dir = \"outputs\",\n        max_length = 1024,\n        max_prompt_length = 512,\n        beta = 0.1,\n    ),\n)\ndpo_trainer.train()\n```\n\n----------------------------------------\n\nTITLE: Basic Unsloth Usage Example\nDESCRIPTION: Demonstrates how to import and use Unsloth with the FastLanguageModel, along with TRL's SFTTrainer and dataset loading.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom unsloth import FastLanguageModel \nimport torch\nfrom trl import SFTTrainer, SFTConfig\nfrom datasets import load_dataset\nmax_seq_length = 2048 # Supports RoPE Scaling interally, so choose any!\n# Get LAION dataset\nurl = \"https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl\"\ndataset = load_dataset(\"json\", data_files = {\"train\" : url}, split = \"train\")\n```\n\n----------------------------------------\n\nTITLE: Running QLoRA Unsloth Training and Merge Tests - Bash\nDESCRIPTION: Executes the Python test script for the Unsloth QLoRA training and merge workflow. No dependencies outside those declared in the project are required. The command runs the specified Python file, performing model training, merging, and evaluation as described.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/tests/qlora/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython tests/qlora/test_unsloth_qlora_train_and_merge.py\n```\n\n----------------------------------------\n\nTITLE: Running QLoRA Hugging Face Training and Merge Tests - Bash\nDESCRIPTION: Executes the Hugging Face-based QLoRA training and merge test suite. This command, when run in the project root, triggers the test procedure including merging with peftâ€™s merge_and_unload method as well as a custom merge implementation. Outputs are written as described in the test script.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/tests/qlora/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython tests/qlora/test_hf_qlora_train_and_merge.py\n```\n\n----------------------------------------\n\nTITLE: Automatic Pip Installation Command Generator\nDESCRIPTION: Python script to determine the optimal pip installation command based on the installed torch version and CUDA capabilities.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntry: import torch\nexcept: raise ImportError('Install torch via `pip install torch`')\nfrom packaging.version import Version as V\nv = V(torch.__version__)\ncuda = str(torch.version.cuda)\nis_ampere = torch.cuda.get_device_capability()[0] >= 8\nif cuda != \"12.1\" and cuda != \"11.8\" and cuda != \"12.4\": raise RuntimeError(f\"CUDA = {cuda} not supported!\")\nif   v <= V('2.1.0'): raise RuntimeError(f\"Torch = {v} too old!\")\nelif v <= V('2.1.1'): x = 'cu{}{}-torch211'\nelif v <= V('2.1.2'): x = 'cu{}{}-torch212'\nelif v  < V('2.3.0'): x = 'cu{}{}-torch220'\nelif v  < V('2.4.0'): x = 'cu{}{}-torch230'\nelif v  < V('2.5.0'): x = 'cu{}{}-torch240'\nelif v  < V('2.6.0'): x = 'cu{}{}-torch250'\nelse: raise RuntimeError(f\"Torch = {v} too new!\")\nx = x.format(cuda.replace(\".\", \"\"), \"-ampere\" if is_ampere else \"\")\nprint(f'pip install --upgrade pip && pip install \"unsloth[{x}] @ git+https://github.com/unslothai/unsloth.git\"')\n```\n\n----------------------------------------\n\nTITLE: Configuring SFTTrainer for Windows\nDESCRIPTION: Example of setting dataset_num_proc parameter in SFTTrainer to avoid crashing issues on Windows.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrainer = SFTTrainer(\n    dataset_num_proc=1,\n    ...\n)\n```\n\n----------------------------------------\n\nTITLE: Advanced Pip Installation for Unsloth\nDESCRIPTION: Examples of advanced pip installation commands for different torch and CUDA versions.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade pip\npip install \"unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git\"\n```\n\n----------------------------------------\n\nTITLE: Installing Unsloth with Conda\nDESCRIPTION: Conda commands for creating a new environment and installing Unsloth with necessary dependencies.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nconda create --name unsloth_env \\\n    python=3.11 \\\n    pytorch-cuda=12.1 \\\n    pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers \\\n    -y\nconda activate unsloth_env\n\npip install unsloth\n```\n\n----------------------------------------\n\nTITLE: Installing Unsloth on Windows\nDESCRIPTION: Pip installation command for Unsloth on Windows after setting up the required dependencies.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\npip install unsloth\n```\n\n----------------------------------------\n\nTITLE: Installing Unsloth via Pip on Linux (Shell)\nDESCRIPTION: This snippet demonstrates how to install the Unsloth Python package using pip on Linux systems. The 'unsloth' package includes all necessary dependencies for running the platform's LLM finetuning and inference workflows. To execute, open a Linux terminal and enter the command. For Windows-specific instructions, users are directed elsewhere.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install unsloth\n\n```\n\n----------------------------------------\n\nTITLE: Installing Unsloth via pip on Linux\nDESCRIPTION: Basic pip installation command for Unsloth on Linux systems.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install unsloth\n```\n\n----------------------------------------\n\nTITLE: Defining Prompt and Answer Data for QLoRA Training - Python\nDESCRIPTION: Represents the sample dataset for QLoRA training, defining a single question/answer pair as both raw strings and structured dictionaries in Python. No external dependencies are needed. These variables are used to provide context for model training and response validation steps in the test scripts.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/tests/qlora/README.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nQUESTION = \"What day was I born?\"\nANSWER = \"January 1, 2058\"\nUSER_MESSAGE = {\"role\": \"user\", \"content\": QUESTION}\nASSISTANT_MESSAGE = {\"role\": \"assistant\", \"content\": ANSWER}\n```\n\n----------------------------------------\n\nTITLE: Citing Unsloth Software in BibTeX\nDESCRIPTION: This BibTeX entry provides a structured citation for the Unsloth software repository. It should be included in academic publications referencing work built upon Unsloth models, trainers, or techniques. The required field is the bibliographic record in BibTeX format; replace the year or authors if referencing a different version.\nSOURCE: https://github.com/unslothai/unsloth/blob/main/README.md#_snippet_10\n\nLANGUAGE: bibtex\nCODE:\n```\n@software{unsloth,\n  author = {Daniel Han, Michael Han and Unsloth team},\n  title = {Unsloth},\n  url = {http://github.com/unslothai/unsloth},\n  year = {2023}\n}\n```"
  }
]