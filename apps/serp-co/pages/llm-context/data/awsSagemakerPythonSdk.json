[
  {
    "owner": "aws",
    "repo": "sagemaker-python-sdk",
    "content": "TITLE: Combining Condition, PropertyFile, and ModelStep in SageMaker Pipelines (Python)\nDESCRIPTION: This comprehensive example demonstrates how to use conditions with PropertyFile and JsonGet to conditionally register a model based on evaluation metrics. It shows setting up processing, evaluation, and conditional registration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nstep_train = TrainingStep(...)\nmodel = Model(\n    image_uri=\"my-dummy-image\",\n    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n    ...\n)\n\nstep_args = sklearn_processor.run(\n    outputs=[\n        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n        ProcessingOutput(output_name=\"hyperparam\", source=\"/opt/ml/processing/evaluation\"),\n    ],\n    code=\"./local/preprocess.py\",\n    arguments=[\"--input-data\", \"s3://my-input\"],\n)\n\neval_report = PropertyFile(\n    name=\"AbaloneHyperparamReport\",\n    output_name=\"hyperparam\",\n    path=\"hyperparam.json\",\n)\n\nstep_process = ProcessingStep(\n    name=\"PreprocessAbaloneData\",\n    step_args=step_args,\n    property_files=[eval_report],\n)\n\neval_score = JsonGet(\n    step_name=step_process.name,\n    property_file=eval_report,\n    json_path=\"eval.accuracy\",\n)\n\n# register the model if evaluation score is satisfactory\nregister_arg = model.register(\n    content_types=[\"application/json\"],\n    response_types=[\"application/json\"],\n    inference_instances=[\"ml.m5.large\"],\n    transform_instances=[\"ml.m5.large\"],\n    model_package_group_name=\"my-model-pkg-name\",\n    approval_status=\"Approved\",\n)\nstep_register = ModelStep(\n    name=\"MyModelCreationStep\",\n    step_args=register_arg,\n)\n# otherwise, transit to a failure step\nstep_fail = FailStep(name=\"FailStep\", ...)\n\ncond = ConditionStep(\n   conditions = [ConditionGreaterThanOrEqualTo(left=eval_score, right=0.95)],\n   if_steps = [step_register],\n   else_steps = [step_fail],\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing PyTorch Distributed Backend with SageMaker Data Parallel\nDESCRIPTION: Example showing how to import and initialize the SageMaker distributed data parallel library as a backend for PyTorch distributed training. Uses the 'smddp' backend specification.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_pytorch.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport smdistributed.dataparallel.torch.torch_smddp\nimport torch.distributed as dist\n\ndist.init_process_group(backend='smddp')\n```\n\n----------------------------------------\n\nTITLE: Creating an Inference Pipeline in SageMaker\nDESCRIPTION: This example demonstrates how to create a SageMaker inference pipeline by combining multiple models (XGBoost and SparkML) into a PipelineModel, allowing for pre-processing, model-scoring, and post-processing in a single API call.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_87\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import image_uris, session\nfrom sagemaker.model import Model\nfrom sagemaker.pipeline import PipelineModel\nfrom sagemaker.sparkml import SparkMLModel\n\nxgb_image = image_uris.retrieve(\"xgboost\", session.Session().boto_region_name, repo_version=\"latest\")\nxgb_model = Model(model_data=\"s3://path/to/model.tar.gz\", image_uri=xgb_image)\nsparkml_model = SparkMLModel(model_data=\"s3://path/to/model.tar.gz\", env={\"SAGEMAKER_SPARKML_SCHEMA\": schema})\n\nmodel_name = \"inference-pipeline-model\"\n```\n\n----------------------------------------\n\nTITLE: Process Group Initialization with SMDDP Backend\nDESCRIPTION: Shows the basic initialization of PyTorch distributed process group using the SageMaker data parallel backend. This is the recommended way to initialize distributed training after v1.4.0.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_pytorch.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntorch.distributed.init_process_group(backend='smddp')\n```\n\n----------------------------------------\n\nTITLE: Configuring PyTorch DDP with torchrun Backend in SageMaker\nDESCRIPTION: This snippet shows how to configure a PyTorch estimator for distributed training using PyTorch DDP with the torchrun backend on two ml.p4d.24xlarge instances.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.pytorch import PyTorch\n\npt_estimator = PyTorch(\n    entry_point=\"train_ptddp.py\",\n    role=\"SageMakerRole\",\n    framework_version=\"1.13.1\",\n    py_version=\"py38\",\n    instance_count=2,\n    instance_type=\"ml.p4d.24xlarge\",\n    distribution={\n        \"torch_distributed\": {\n            \"enabled\": True\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Running Data Processing Job with SKLearnProcessor\nDESCRIPTION: Executes a scikit-learn processing job using a preprocessing script. The job takes input data from S3, processes it according to the script, and outputs train and test datasets back to S3. The example also demonstrates how to pass command-line arguments to the processing script.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_processing.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.processing import ProcessingInput, ProcessingOutput\n\nsklearn_processor.run(\n    code=\"preprocessing.py\",\n    inputs=[\n        ProcessingInput(source=\"s3://your-bucket/path/to/your/data\", destination=\"/opt/ml/processing/input\"),\n    ],\n    outputs=[\n        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\"),\n        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\"),\n    ],\n    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n)\n\npreprocessing_job_description = sklearn_processor.jobs[-1].describe()\n```\n\n----------------------------------------\n\nTITLE: Creating a TrainingStep in SageMaker Pipelines with SKLearn Estimator\nDESCRIPTION: This code demonstrates how to create a training step in a SageMaker pipeline using an SKLearn estimator. It shows how to configure the estimator with hyperparameters, specify training inputs from previous processing steps, and create the training step with appropriate caching configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.sklearn.estimator import SKLearn\nfrom sagemaker.workflow.steps import TrainingStep\n\npipeline_session = PipelineSession()\n\nimage_uri = sagemaker.image_uris.retrieve(\n    framework=\"xgboost\",\n    region=region,\n    version=\"1.0-1\",\n    py_version=\"py3\",\n    instance_type=\"ml.m5.xlarge\",\n)\n\nhyperparameters = {\n    \"dataset_frequency\": \"H\",\n    \"timestamp_format\": \"yyyy-MM-dd hh:mm:ss\",\n    \"number_of_backtest_windows\": \"1\",\n    \"role_arn\": role_arn,\n    \"region\": region,\n}\n\nsklearn_estimator = SKLearn(\n    entry_point=\"train.py\",\n    role=role_arn,\n    image_uri=container_image_uri,\n    instance_type=training_instance_type,\n    sagemaker_session=pipeline_session,\n    base_job_name=\"training_job\",\n    hyperparameters=hyperparameters,\n    enable_sagemaker_metrics=True,\n)\n\ntrain_args = xgb_train.fit(\n    inputs={\n        \"train\": TrainingInput(\n            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n                \"train\"\n            ].S3Output.S3Uri,\n            content_type=\"text/csv\",\n        ),\n        \"validation\": TrainingInput(\n            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n                \"validation\"\n            ].S3Output.S3Uri,\n            content_type=\"text/csv\",\n        ),\n    }\n)\n\ntraining_step = TrainingStep(\n    name=\"Train\",\n    estimator=sklearn_estimator,\n    cache_config=cache_config\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Running a SageMaker AutoML Job in Python\nDESCRIPTION: This snippet demonstrates how to create an AutoML object, specify the target attribute, and fit it to input data. This starts an AutoML job that automatically handles data processing, training, and tuning to find the best model candidates.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/automl/README.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import AutoML\n\nauto_ml = AutoML(\n    role=\"sagemaker-execution-role\",\n    target_attribute_name=\"y\",\n    sagemaker_session=sagemaker_session,\n)\nauto_ml.fit(inputs=inputs)\n```\n\n----------------------------------------\n\nTITLE: Fine-tuning and Deploying JumpStart Model using JumpStartEstimator in Python\nDESCRIPTION: Demonstrates how to fine-tune a JumpStart model (GPT-J 6B) using the JumpStartEstimator class. Includes steps for training the model on custom data and deploying it to a SageMaker endpoint.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_45\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.jumpstart.estimator import JumpStartEstimator\n\nmodel_id = \"huggingface-textgeneration1-gpt-j-6b\"\nestimator = JumpStartEstimator(model_id=model_id)\nestimator.fit(\n    {\"train\": training_dataset_s3_path, \"validation\": validation_dataset_s3_path}\n)\npredictor = estimator.deploy()\n```\n\n----------------------------------------\n\nTITLE: Creating a PyTorch Estimator for Custom Script Training in SageMaker\nDESCRIPTION: This snippet demonstrates how to create a PyTorch Estimator for training a custom script on SageMaker. It shows how to specify the script, instance type, framework version, and hyperparameters, and how to call the fit method to start training with input data from S3.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npytorch_estimator = PyTorch('pytorch-train.py',\n                            instance_type='ml.p3.2xlarge',\n                            instance_count=1,\n                            framework_version='1.8.0',\n                            py_version='py3',\n                            hyperparameters = {'epochs': 20, 'batch-size': 64, 'learning-rate': 0.1})\npytorch_estimator.fit({'train': 's3://my-data-bucket/path/to/my/training/data',\n                       'test': 's3://my-data-bucket/path/to/my/test/data'})\n```\n\n----------------------------------------\n\nTITLE: Complete TensorFlow 2.x Training Script with SageMaker Data Parallel\nDESCRIPTION: A full example of a TensorFlow 2.x training script adapted to use SageMaker's distributed data parallel library, including initialization, device pinning, data preparation, model definition, and the training loop.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\n# Import the library's TF API\nimport smdistributed.dataparallel.tensorflow as sdp\n\n# Initialize the library\nsdp.init()\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    # Pin GPUs to a single process\n    tf.config.experimental.set_visible_devices(gpus[sdp.local_rank()], 'GPU')\n\n# Prepare Dataset\ndataset = tf.data.Dataset.from_tensor_slices(...)\n\n# Define Model\nmnist_model = tf.keras.Sequential(...)\nloss = tf.losses.SparseCategoricalCrossentropy()\n\n# Scale Learning Rate\n# LR for 8 node run : 0.000125\n# LR for single node run : 0.001\nopt = tf.optimizers.Adam(0.000125 * sdp.size())\n\n@tf.function\ndef training_step(images, labels, first_batch):\n    with tf.GradientTape() as tape:\n        probs = mnist_model(images, training=True)\n        loss_value = loss(labels, probs)\n\n    # Wrap tf.GradientTape with the library's DistributedGradientTape\n    tape = sdp.DistributedGradientTape(tape)\n\n    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n    opt.apply_gradients(zip(grads, mnist_model.trainable_variables))\n\n    if first_batch:\n       # Broadcast model and optimizer variables\n       sdp.broadcast_variables(mnist_model.variables, root_rank=0)\n       sdp.broadcast_variables(opt.variables(), root_rank=0)\n\n    return loss_value\n\n...\n\n# Save checkpoints only from master node.\nif sdp.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Initializing PyTorch Estimator with SageMaker Session in Python\nDESCRIPTION: This snippet demonstrates how to construct a PyTorch estimator and start a TrainingJob using SageMaker Session. It shows the standard way of creating and fitting an estimator without using pipelines.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npytorch_estimator = PyTorch(\n    *sagemaker_session=sagemaker.Session(),*\n    role=sagemaker.get_execution_role(),\n    instance_type=\"ml.c5.xlarge\",\n    instance_count=1,\n    framework_version=\"1.8.0\",\n    py_version=\"py36\",\n    entry_point=\"./entry_point.py\",\n)\npytorch_estimator.fit(\n    inputs=TrainingInput(s3_data=\"s3://my-bucket/my-data/train\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Complete TensorFlow 2.x Training Script with SageMaker Distributed Data Parallel\nDESCRIPTION: A full example of a TensorFlow 2.x training script modified to use SageMaker's distributed data parallel library, including initialization, GPU pinning, learning rate scaling, gradient tape wrapping, variable broadcasting, and checkpoint saving.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\n# Import the library's TF API\nimport smdistributed.dataparallel.tensorflow as sdp\n\n# Initialize the library\nsdp.init()\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    # Pin GPUs to a single process\n    tf.config.experimental.set_visible_devices(gpus[sdp.local_rank()], 'GPU')\n\n# Prepare Dataset\ndataset = tf.data.Dataset.from_tensor_slices(...)\n\n# Define Model\nmnist_model = tf.keras.Sequential(...)\nloss = tf.losses.SparseCategoricalCrossentropy()\n\n# Scale Learning Rate\n# LR for 8 node run : 0.000125\n# LR for single node run : 0.001\nopt = tf.optimizers.Adam(0.000125 * sdp.size())\n\n@tf.function\ndef training_step(images, labels, first_batch):\n    with tf.GradientTape() as tape:\n        probs = mnist_model(images, training=True)\n        loss_value = loss(labels, probs)\n\n    # Wrap tf.GradientTape with the library's DistributedGradientTape\n    tape = sdp.DistributedGradientTape(tape)\n\n    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n    opt.apply_gradients(zip(grads, mnist_model.trainable_variables))\n\n    if first_batch:\n       # Broadcast model and optimizer variables\n       sdp.broadcast_variables(mnist_model.variables, root_rank=0)\n       sdp.broadcast_variables(opt.variables(), root_rank=0)\n\n    return loss_value\n\n...\n\n# Save checkpoints only from master node.\nif sdp.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Extracting JSON Properties from ProcessingStep for Training in SageMaker Pipelines\nDESCRIPTION: This example demonstrates how to extract a hyperparameter value from a PropertyFile produced by a ProcessingStep and pass it to a subsequent TrainingStep. It creates a full pipeline workflow from data processing to model training using the SKLearnProcessor and XGBoost Estimator.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nsession = PipelineSession()\n\nsklearn_processor = SKLearnProcessor(\n    framework_version=\"0.23-1\",\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=1,\n    base_job_name=\"sklearn-abalone-preprocess\",\n    sagemaker_session=session,\n    role=sagemaker.get_execution_role(),\n)\n\nstep_args = sklearn_processor.run(\n    outputs=[\n        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n        ProcessingOutput(output_name=\"hyperparam\", source=\"/opt/ml/processing/evaluation\"),\n    ],\n    code=\"./local/preprocess.py\",\n    arguments=[\"--input-data\", \"s3://my-input\"],\n)\n\nhyperparam_report = PropertyFile(\n    name=\"AbaloneHyperparamReport\",\n    output_name=\"hyperparam\",\n    path=\"hyperparam.json\",\n)\n\nstep_process = ProcessingStep(\n    name=\"PreprocessAbaloneData\",\n   step_args=step_args,\n    property_files=[hyperparam_report],\n)\n\nxgb_train = Estimator(\n    image_uri=\"s3://my-image-uri\",\n    instance_type=\"ml.c5.xlarge\",\n    instance_count=1,\n    output_path=\"s3://my-output-path\",\n    base_job_name=\"abalone-train\",\n    sagemaker_session=session,\n    role=sagemaker.get_execution_role(),\n)\n\neta = JsonGet(\n step_name=step_process.name,\n property_file=hyperparam_report,\n json_path=\"hyperparam.eta.value\",\n)\n\nxgb_train.set_hyperparameters(\n    objective=\"reg:linear\",\n    num_round=50,\n    max_depth=5,\n    eta=eta,\n    gamma=4,\n    min_child_weight=6,\n    subsample=0.7,\n    silent=0,\n)\n\nstep_args = xgb_train.fit(inputs={\n    \"train\": TrainingInput(\n        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n            \"train\"\n        ].S3Output.S3Uri,\n        content_type=\"text/csv\",\n    ),\n    \"validation\": TrainingInput(\n        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n            \"validation\"\n        ].S3Output.S3Uri,\n        content_type=\"text/csv\",\n    ),\n},)\n\nstep_train = TrainingStep(\n    name=\"TrainAbaloneModel\",\n    step_args=step_args,\n)\n```\n\n----------------------------------------\n\nTITLE: Training Script Setup with Environment Variables in Python\nDESCRIPTION: Example of a basic training script setup that demonstrates how to parse hyperparameters and access SageMaker environment variables for model training. Shows configuration of argument parser and handling of input/output directories.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport os\nimport json\n\nif __name__ =='__main__':\n\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument('--epochs', type=int, default=10)\n    parser.add_argument('--batch-size', type=int, default=100)\n    parser.add_argument('--learning-rate', type=float, default=0.1)\n\n    # an alternative way to load hyperparameters via SM_HPS environment variable.\n    parser.add_argument('--sm-hps', type=json.loads, default=os.environ['SM_HPS'])\n\n    # input data and model directories\n    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n    parser.add_argument('--test', type=str, default=os.environ['SM_CHANNEL_TEST'])\n\n    args, _ = parser.parse_known_args()\n```\n\n----------------------------------------\n\nTITLE: Initializing ArgumentParser for PyTorch Training Script in SageMaker\nDESCRIPTION: Example of setting up argument parsing in a PyTorch training script for SageMaker, including hyperparameters and environment variable access for data and model directories.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport os\n\nif __name__ =='__main__':\n\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument('--epochs', type=int, default=50)\n    parser.add_argument('--batch-size', type=int, default=64)\n    parser.add_argument('--learning-rate', type=float, default=0.05)\n    parser.add_argument('--use-cuda', type=bool, default=False)\n\n    # Data, model, and output directories\n    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n    parser.add_argument('--test', type=str, default=os.environ['SM_CHANNEL_TEST'])\n\n    args, _ = parser.parse_known_args()\n\n    # ... load from args.train and args.test, train a model, write model to args.model_dir.\n```\n\n----------------------------------------\n\nTITLE: Creating a SageMaker Model from Externally Trained Model\nDESCRIPTION: Example of creating a SageMaker MXNetModel from a model trained outside of SageMaker. This allows deploying externally trained models to SageMaker endpoints by packaging the model artifacts in a tar.gz file and uploading to S3.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.mxnet.model import MXNetModel\n\nsagemaker_model = MXNetModel(model_data='s3://path/to/model.tar.gz',\n                                role='arn:aws:iam::accid:sagemaker-role',\n```\n\n----------------------------------------\n\nTITLE: Creating a Feature Group with Complete Configuration\nDESCRIPTION: Shows all available parameters for creating a feature group, including descriptions, feature definitions, storage configuration, and optional settings like enabling the online store and configuring KMS keys.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# create a FeatureGroup\nfeature_group.create(\n    description = \"Some info about the feature group\",\n    feature_group_name = feature_group_name,\n    record_identifier_name = record_identifier_name,\n    event_time_feature_name = event_time_feature_name,\n    feature_definitions = feature_definitions,\n    role_arn = role,\n    s3_uri = offline_feature_store_bucket,\n    enable_online_store = True,\n    ttl_duration = None,\n    online_store_kms_key_id = None,\n    offline_store_kms_key_id = None,\n    disable_glue_table_creation = False,\n    data_catalog_config = None,\n    tags = [\"tag1\",\"tag2\"])\n```\n\n----------------------------------------\n\nTITLE: Creating a TuningStep in SageMaker Pipelines with Hyperparameter Tuning\nDESCRIPTION: This snippet shows how to create a hyperparameter tuning step in a SageMaker pipeline. It demonstrates setting up an Estimator with hyperparameters, configuring a HyperparameterTuner with appropriate parameter ranges and optimization strategy, and creating the tuning step with inputs from a previous processing step.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.workflow.steps import TuningStep\nfrom sagemaker.tuner import HyperparameterTuner\nfrom sagemaker.estimator import Estimator\nfrom sagemaker.inputs import TrainingInput\n\nmodel_path = f\"s3://{default_bucket}/{base_job_prefix}/AbaloneTrain\"\n\nxgb_train = Estimator(\n    image_uri=image_uri,\n    instance_type=training_instance_type,\n    instance_count=1,\n    output_path=model_path,\n    base_job_name=f\"{base_job_prefix}/abalone-train\",\n    sagemaker_session=pipeline_session,\n    role=role,\n)\n\nxgb_train.set_hyperparameters(\n    eval_metric=\"rmse\",\n    objective=\"reg:squarederror\",  # Define the object metric for the training job\n    num_round=50,\n    max_depth=5,\n    eta=0.2,\n    gamma=4,\n    min_child_weight=6,\n    subsample=0.7,\n    silent=0,\n)\n\nobjective_metric_name = \"validation:rmse\"\n\nhyperparameter_ranges = {\n    \"alpha\": ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\"),\n    \"lambda\": ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\"),\n}\n\ntuner = HyperparameterTuner(\n    xgb_train,\n    objective_metric_name,\n    hyperparameter_ranges,\n    max_jobs=3,\n    max_parallel_jobs=3,\n    strategy=\"Random\",\n    objective_type=\"Minimize\",\n)\n\nhpo_args = tuner.fit(\n    inputs={\n        \"train\": TrainingInput(\n            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n            content_type=\"text/csv\",\n        ),\n        \"validation\": TrainingInput(\n            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n                \"validation\"\n            ].S3Output.S3Uri,\n            content_type=\"text/csv\",\n        ),\n    }\n)\n\nstep_tuning = TuningStep(\n    name=\"HPTuning\",\n    step_args=hpo_args,\n    cache_config=cache_config,\n)\n```\n\n----------------------------------------\n\nTITLE: Deploying TensorFlow Model Artifacts to SageMaker Endpoint in Python\nDESCRIPTION: This snippet demonstrates how to deploy existing TensorFlow model artifacts directly to a SageMaker endpoint. It creates a TensorFlowModel object and calls the deploy method to create an endpoint.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = TensorFlowModel(model_data='s3://mybucket/model.tar.gz', role='MySageMakerRole', framework_version='x.x.x')\n\npredictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge')\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using HyperparameterTuner in SageMaker Python SDK\nDESCRIPTION: Demonstrates how to set up and use the HyperparameterTuner class to perform automatic model tuning. This example includes creating a tuner, starting a tuning job, deploying the best model, making predictions, and cleaning up resources.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_54\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tuner import HyperparameterTuner, ContinuousParameter\n\n# Configure HyperparameterTuner\nmy_tuner = HyperparameterTuner(estimator=my_estimator,  # previously-configured Estimator object\n                               objective_metric_name='validation-accuracy',\n                               hyperparameter_ranges={'learning-rate': ContinuousParameter(0.05, 0.06)},\n                               metric_definitions=[{'Name': 'validation-accuracy', 'Regex': 'validation-accuracy=(\\d\\.\\d+)'}],\n                               max_jobs=100,\n                               max_parallel_jobs=10)\n\n# Start hyperparameter tuning job\nmy_tuner.fit({'train': 's3://my_bucket/my_training_data', 'test': 's3://my_bucket_my_testing_data'})\n\n# Deploy best model\nmy_predictor = my_tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n\n# Make a prediction against the SageMaker endpoint\nresponse = my_predictor.predict(my_prediction_data)\n\n# Tear down the SageMaker endpoint\nmy_predictor.delete_endpoint()\n```\n\n----------------------------------------\n\nTITLE: Complete PyTorch Training Script with SageMaker Distributed Data Parallel\nDESCRIPTION: A comprehensive example showing a complete PyTorch training script adapted for distributed training with SageMaker's distributed data parallel library, including initialization, model definition, data preparation, and training loop.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Import distributed data parallel library PyTorch API\nimport smdistributed.dataparallel.torch.distributed as dist\n\n# Import distributed data parallel library PyTorch DDP\nfrom smdistributed.dataparallel.torch.parallel.distributed import DistributedDataParallel as DDP\n\n# Initialize distributed data parallel library\ndist.init_process_group()\n\nclass Net(nn.Module):\n    ...\n    # Define model\n\ndef train(...):\n    ...\n    # Model training\n\ndef test(...):\n    ...\n    # Model evaluation\n\ndef main():\n\n    # Scale batch size by world size\n    batch_size //= dist.get_world_size() // 8\n    batch_size = max(batch_size, 1)\n\n    # Prepare dataset\n    train_dataset = torchvision.datasets.MNIST(...)\n\n    # Set num_replicas and rank in DistributedSampler\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n            train_dataset,\n            num_replicas=dist.get_world_size(),\n            rank=dist.get_rank())\n\n    train_loader = torch.utils.data.DataLoader(..)\n\n    # Wrap the PyTorch model with distributed data parallel library's DDP\n    model = DDP(Net().to(device))\n\n    # Pin each GPU to a single distributed data parallel library process.\n    torch.cuda.set_device(local_rank)\n    model.cuda(local_rank)\n\n    # Train\n    optimizer = optim.Adadelta(...)\n    scheduler = StepLR(...)\n    for epoch in range(1, args.epochs + 1):\n        train(...)\n        if rank == 0:\n            test(...)\n        scheduler.step()\n\n    # Save model on master node.\n    if dist.get_rank() == 0:\n        torch.save(...)\n\nif __name__ == '__main__':\n    main()\n```\n\n----------------------------------------\n\nTITLE: Creating and Training SageMaker Estimator\nDESCRIPTION: Demonstrates how to create and train a SageMaker Estimator with custom datasets and hyperparameters.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_50\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.estimator import Estimator\nfrom sagemaker.session import Session\nfrom sagemaker import hyperparameters\n\n# URI of your training dataset\ntraining_dataset_s3_path = \"s3://jumpstart-cache-prod-us-west-2/training-datasets/spc/data.csv\"\n\n# Get the default JumpStart hyperparameters\ndefault_hyperparameters = hyperparameters.retrieve_default(\n    model_id=model_id,\n    model_version=model_version,\n)\n# [Optional] Override default hyperparameters with custom values\ndefault_hyperparameters[\"epochs\"] = \"1\"\n\n# Create your SageMaker Estimator instance\nestimator = Estimator(\n    image_uri=training_image_uri,\n    source_dir=training_script_uri,\n    model_uri=base_model_uri,\n    entry_point=\"transfer_learning.py\",\n    role=Session().get_caller_identity_arn(),\n    hyperparameters=default_hyperparameters,\n    instance_count=instance_count,\n    instance_type=training_instance_type,\n    enable_network_isolation=True,\n)\n\n# Specify the S3 location of training data for the training channel\nestimator.fit(\n    {\n        \"training\": training_dataset_s3_path,\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing PySparkProcessor for Spark-based Data Processing\nDESCRIPTION: Creates a PySparkProcessor instance to run PySpark scripts as processing jobs in SageMaker. The processor is configured with Spark framework version, Python version, and container specifications along with instance details and execution time limits.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_processing.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.processing import PySparkProcessor, ProcessingInput\n\nspark_processor = PySparkProcessor(\n    base_job_name=\"sm-spark\",\n    framework_version=\"2.4\",\n    py_version=\"py37\",\n    container_version=\"1\",\n    role=\"[Your SageMaker-compatible IAM role]\",\n    instance_count=2,\n    instance_type=\"ml.c5.xlarge\",\n    max_runtime_in_seconds=1200,\n    image_uri=\"your-image-uri\"\n)\n```\n\n----------------------------------------\n\nTITLE: Performing Inference on Deployed Endpoint\nDESCRIPTION: Demonstrates how to make predictions using a deployed model endpoint.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_52\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\ndata = [\"this is the best day of my life\", \"i am tired\"]\n\npredictor.predict(json.dumps(data).encode(\"utf-8\"), {\"ContentType\": \"application/list-text\"})\n```\n\n----------------------------------------\n\nTITLE: Implementing Model Step in SageMaker Pipeline\nDESCRIPTION: Shows how to create and register a SageMaker model using ModelStep in a pipeline. The example demonstrates creating a model from training artifacts, creating a SageMaker model, and registering the model to SageMaker Model Registry using ModelStep.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nstep_train = TrainingStep(...)\nmodel = Model(\n    image_uri=pytorch_estimator.training_image_uri(),\n    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n    sagemaker_session=pipeline_session,\n    role=role,\n)\n\n# we might also want to create a SageMaker Model\nstep_model_create = ModelStep(\n   name=\"MyModelCreationStep\",\n   step_args=model.create(instance_type=\"ml.m5.xlarge\"),\n)\n\n# in addition, we might also want to register a model to SageMaker Model Registry\nregister_model_step_args = model.register(\n    content_types=[\"*\"],\n    response_types=[\"application/json\"],\n    inference_instances=[\"ml.m5.xlarge\"],\n    transform_instances=[\"ml.m5.xlarge\"],\n    description=\"MyModelPackage\",\n)\n\nstep_model_registration = ModelStep(\n   name=\"MyModelRegistration\",\n   step_args=register_model_step_args,\n)\n...\n```\n\n----------------------------------------\n\nTITLE: Configuring PyTorch DDP with mpirun Backend in SageMaker\nDESCRIPTION: This snippet demonstrates how to set up a PyTorch estimator for distributed training using PyTorch DDP with the mpirun backend on two ml.p4d.24xlarge instances.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.pytorch import PyTorch\n\npt_estimator = PyTorch(\n    entry_point=\"train_ptddp.py\",\n    role=\"SageMakerRole\",\n    framework_version=\"1.12.0\",\n    py_version=\"py38\",\n    instance_count=2,\n    instance_type=\"ml.p4d.24xlarge\",\n    distribution={\n        \"pytorchddp\": {\n            \"enabled\": True\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Deploying MXNet Model from S3 Data in Python\nDESCRIPTION: Shows how to deploy an MXNet model directly from model data stored in Amazon S3 using the MXNetModel class. This process creates an endpoint for prediction.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmxnet_model = MXNetModel(model_data='s3://bucket/model.tar.gz', role='SageMakerRole', entry_point='trasform_script.py')\n\npredictor = mxnet_model.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)\n```\n\n----------------------------------------\n\nTITLE: Deploying JumpStart Model to SageMaker Endpoint using ModelBuilder in Python\nDESCRIPTION: Shows how to use ModelBuilder to deploy a JumpStart foundation model (Falcon-7B) to a SageMaker endpoint. Specifies the model ID, schema, and role ARN for deployment.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_44\n\nLANGUAGE: python\nCODE:\n```\nmodel_builder = ModelBuilder(\n    model=\"huggingface-llm-falcon-7b-bf16\",\n    schema_builder=SchemaBuilder(sample_input, sample_output),\n    role_arn=execution_role\n)\n\nsm_ep_model = model_builder.build()\n\npredictor = sm_ep_model.deploy()\n```\n\n----------------------------------------\n\nTITLE: Deploying a TensorFlow Model to SageMaker\nDESCRIPTION: Creates a Model object with the specified model data, role, framework version, and environment variables, then deploys it to a SageMaker endpoint with specified instance count and type. The returned predictor can be used to make predictions with the default model.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmodel = Model(model_data=model_data, role=role, framework_version='1.11', env=env)\npredictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge')\n```\n\n----------------------------------------\n\nTITLE: Saving Checkpoints on Leader Node in SageMaker Distributed Training\nDESCRIPTION: This snippet shows how to save checkpoints only on the leader node to avoid corruption in distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif dist.get_rank() == 0:\n   torch.save(...)\n```\n\n----------------------------------------\n\nTITLE: Initializing DistributedDataParallel for PyTorch Model\nDESCRIPTION: Example usage of smdistributed.dataparallel.torch.parallel.DistributedDataParallel to wrap a PyTorch model for distributed training. It initializes the process group, sets the device, builds the model and optimizer, and wraps the model with DDP.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nimport torch\nimport smdistributed.dataparallel.torch.distributed as dist\nfrom smdistributed.dataparallel.torch.parallel import DistributedDataParallel as DDP\n\ndist.init_process_group()\n\n# Pin GPU to be used to process local rank (one GPU per process)\ntorch.cuda.set_device(dist.get_local_rank())\n\n# Build model and optimizer\nmodel = ...\noptimizer = torch.optim.SGD(model.parameters(),\n                            lr=1e-3 * dist.get_world_size())\n# Wrap model with smdistributed.dataparallel's DistributedDataParallel\nmodel = DDP(model)\n```\n\n----------------------------------------\n\nTITLE: Implementing predict_fn for PyTorch Model in SageMaker\nDESCRIPTION: This function demonstrates how to implement a custom predict_fn for a PyTorch model in SageMaker. It handles device selection (CPU or GPU) and runs the model in evaluation mode.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport numpy as np\n\ndef predict_fn(input_data, model):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    model.eval()\n    with torch.no_grad():\n        return model(input_data.to(device))\n```\n\n----------------------------------------\n\nTITLE: Deploying Model to Endpoint\nDESCRIPTION: Code to deploy the model to a SageMaker endpoint with specified instance count and type.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_26\n\nLANGUAGE: python\nCODE:\n```\npredictor = model.deploy(\n    initial_instance_count=instance_count,\n    instance_type=instance_type,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing XGBoost Training Script Main Function in Python\nDESCRIPTION: Main training script that configures hyperparameters, processes SageMaker environment variables, and trains an XGBoost model. Includes argument parsing, data loading, model training and saving functionality.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/using_xgboost.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n\n    # Hyperparameters are described here\n    parser.add_argument('--num_round', type=int)\n    parser.add_argument('--max_depth', type=int, default=5)\n    parser.add_argument('--eta', type=float, default=0.2)\n    parser.add_argument('--objective', type=str, default='reg:squarederror')\n\n    # SageMaker specific arguments. Defaults are set in the environment variables.\n    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n    parser.add_argument('--validation', type=str, default=os.environ['SM_CHANNEL_VALIDATION'])\n\n    args = parser.parse_args()\n\n    train_hp = {\n        'max_depth': args.max_depth,\n        'eta': args.eta,\n        'gamma': args.gamma,\n        'min_child_weight': args.min_child_weight,\n        'subsample': args.subsample,\n        'silent': args.silent,\n        'objective': args.objective\n    }\n\n    dtrain = xgb.DMatrix(args.train)\n    dval = xgb.DMatrix(args.validation)\n    watchlist = [(dtrain, 'train'), (dval, 'validation')] if dval is not None else [(dtrain, 'train')]\n\n    callbacks = []\n    prev_checkpoint, n_iterations_prev_run = add_checkpointing(callbacks)\n    # If checkpoint is found then we reduce num_boost_round by previously run number of iterations\n\n    bst = xgb.train(\n        params=train_hp,\n        dtrain=dtrain,\n        evals=watchlist,\n        num_boost_round=(args.num_round - n_iterations_prev_run),\n        xgb_model=prev_checkpoint,\n        callbacks=callbacks\n    )\n\n    # Save the model to the location specified by ``model_dir``\n    model_location = args.model_dir + '/xgboost-model'\n    pkl.dump(bst, open(model_location, 'wb'))\n    logging.info(\"Stored trained model at {}\".format(model_location))\n```\n\n----------------------------------------\n\nTITLE: Implementing Input and Output Handlers for TensorFlow Serving in Python\nDESCRIPTION: This snippet demonstrates how to implement input_handler and output_handler functions for pre-processing requests and post-processing responses in TensorFlow Serving. It handles JSON and CSV input formats and includes error handling.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\ndef input_handler(data, context):\n    \"\"\" Pre-process request input before it is sent to TensorFlow Serving REST API\n    Args:\n        data (obj): the request data, in format of dict or string\n        context (Context): an object containing request and configuration details\n    Returns:\n        (dict): a JSON-serializable dict that contains request body and headers\n    \"\"\"\n    if context.request_content_type == 'application/json':\n        # pass through json (assumes it's correctly formed)\n        d = data.read().decode('utf-8')\n        return d if len(d) else ''\n\n    if context.request_content_type == 'text/csv':\n        # very simple csv handler\n        return json.dumps({\n            'instances': [float(x) for x in data.read().decode('utf-8').split(',')]\n        })\n\n    raise ValueError('{\"error\": \"unsupported content type {}\"}}'.format(\n        context.request_content_type or \"unknown\"))\n\n\ndef output_handler(data, context):\n    \"\"\"Post-process TensorFlow Serving output before it is returned to the client.\n    Args:\n        data (obj): the TensorFlow serving response\n        context (Context): an object containing request and configuration details\n    Returns:\n        (bytes, string): data to return to client, response content type\n    \"\"\"\n    if data.status_code != 200:\n        raise ValueError(data.content.decode('utf-8'))\n\n    response_content_type = context.accept_header\n    prediction = data.content\n    return prediction, response_content_type\n```\n\n----------------------------------------\n\nTITLE: Using DistributedGradientTape with TensorFlow\nDESCRIPTION: Example showing how to wrap TensorFlow's GradientTape with DistributedGradientTape to combine gradient values using AllReduce before applying to model weights.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith tf.GradientTape() as tape:\n      output = model(input)\n      loss_value = loss(label, output)\n\n# Wrap in smdistributed.dataparallel's DistributedGradientTape\ntape = smdistributed.dataparallel.tensorflow.DistributedGradientTape(tape)\n```\n\n----------------------------------------\n\nTITLE: Implementing BroadcastGlobalVariablesHook in TensorFlow\nDESCRIPTION: Shows how to use BroadcastGlobalVariablesHook to ensure consistent initialization of all workers in distributed training with tf.estimator API.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nhooks = [smdistributed.dataparallel.tensorflow.BroadcastGlobalVariablesHook(root_rank=0)]\n...\nwith tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,\n                                       hooks=hooks,\n                                       config=config) as mon_sess:\n     ...\n```\n\n----------------------------------------\n\nTITLE: Creating an AutoMLStep in SageMaker Pipelines\nDESCRIPTION: This example shows how to create an AutoML step in a SageMaker pipeline. It demonstrates initializing an AutoML object with basic configuration parameters and creating an AutoMLInput to specify the input data location and target attribute for the AutoML training process.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.workflow.pipeline_context import PipelineSession\nfrom sagemaker.workflow.automl_step import AutoMLStep\n\npipeline_session = PipelineSession()\n\nauto_ml = AutoML(...,\n    role=role,\n    target_attribute_name=\"my_target_attribute_name\",\n    mode=\"ENSEMBLING\",\n    sagemaker_session=pipeline_session)\n\ninput_training = AutoMLInput(\n    inputs=\"s3://amzn-s3-demo-bucket/my-training-data\",\n    target_attribute_name=\"my_target_attribute_name\",\n    channel_type=\"training\",\n)\n```\n\n----------------------------------------\n\nTITLE: Deploying XGBoost Models in Amazon SageMaker\nDESCRIPTION: This snippet demonstrates how to create an XGBoost model object from a pre-trained model file in S3, deploy it to a SageMaker endpoint, and make predictions. It shows the initialization of the model with required parameters and how to handle LIBSVM formatted input data.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/using_xgboost.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nxgboost_model = XGBoostModel(\n    model_data=\"s3://my-bucket/my-path/model.tar.gz\",\n    role=\"my-role\",\n    entry_point=\"inference.py\",\n    framework_version=\"1.0-1\"\n)\n\npredictor = xgboost_model.deploy(\n    instance_type='ml.c4.xlarge',\n    initial_instance_count=1\n)\n\n# If payload is a string in LIBSVM format, we need to change serializer.\npredictor.serializer = str\npredictor.predict(\"<label> <index1>:<value1> <index2>:<value2>\")\n```\n\n----------------------------------------\n\nTITLE: Creating and Using TensorFlow Estimator in SageMaker\nDESCRIPTION: Example demonstrating how to create a TensorFlow estimator object in SageMaker and start the training job. This code specifies the entry point script, instance configuration, and TensorFlow framework version to use.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\ntf_estimator = TensorFlow(\n    entry_point=\"tf-train.py\",\n    role=\"SageMakerRole\",\n    instance_count=1,\n    instance_type=\"ml.p2.xlarge\",\n    framework_version=\"2.2\",\n    py_version=\"py37\",\n)\ntf_estimator.fit(\"s3://bucket/path/to/training/data\")\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Model Variables for Consistent Initialization\nDESCRIPTION: Broadcasts initial model and optimizer variables from the leader node to all worker nodes to ensure consistent initialization across the distributed training cluster.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsdp.broadcast_variables(model.variables, root_rank=0)\nsdp.broadcast_variables(opt.variables(), root_rank=0)\n```\n\n----------------------------------------\n\nTITLE: Complete PyTorch Training Script for SageMaker Distributed Data Parallel\nDESCRIPTION: This is a full example of a PyTorch training script modified for distributed training with SageMaker's distributed data parallel library.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Import distributed data parallel library PyTorch API\nimport smdistributed.dataparallel.torch.distributed as dist\n\n# Import distributed data parallel library PyTorch DDP\nfrom smdistributed.dataparallel.torch.parallel.distributed import DistributedDataParallel as DDP\n\n# Initialize distributed data parallel library\ndist.init_process_group()\n\nclass Net(nn.Module):\n    ...\n    # Define model\n\ndef train(...):\n    ...\n    # Model training\n\ndef test(...):\n    ...\n    # Model evaluation\n\ndef main():\n\n    # Scale batch size by world size\n    batch_size //= dist.get_world_size()\n    batch_size = max(batch_size, 1)\n\n    # Prepare dataset\n    train_dataset = torchvision.datasets.MNIST(...)\n\n    # Set num_replicas and rank in DistributedSampler\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n            train_dataset,\n            num_replicas=dist.get_world_size(),\n            rank=dist.get_rank())\n\n    train_loader = torch.utils.data.DataLoader(..)\n\n    # Wrap the PyTorch model with distributed data parallel library's DDP\n    model = DDP(Net().to(device))\n\n    # Pin each GPU to a single distributed data parallel library process.\n    torch.cuda.set_device(local_rank)\n    model.cuda(local_rank)\n\n    # Train\n    optimizer = optim.Adadelta(...)\n    scheduler = StepLR(...)\n    for epoch in range(1, args.epochs + 1):\n        train(...)\n        if rank == 0:\n            test(...)\n        scheduler.step()\n\n    # Save model on master node.\n    if dist.get_rank() == 0:\n        torch.save(...)\n\nif __name__ == '__main__':\n    main()\n```\n\n----------------------------------------\n\nTITLE: Deploying and Predicting with a Scikit-learn Model in SageMaker\nDESCRIPTION: This snippet demonstrates the basic workflow of training a Scikit-learn model, deploying it to a SageMaker endpoint, and using it for inference. The deploy method creates an endpoint with the specified instance type and count, while the predict method sends data to the endpoint for prediction.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsklearn_estimator.fit('s3://my_bucket/my_training_data/')\n\n# Deploy my estimator to a SageMaker Endpoint and get a Predictor\npredictor = sklearn_estimator.deploy(instance_type='ml.m4.xlarge',\n                                     initial_instance_count=1)\n\n# `data` is a NumPy array or a Python list.\n# `response` is a NumPy array.\nresponse = predictor.predict(data)\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom model_fn for MXNet Model Loading in SageMaker\nDESCRIPTION: Creates a custom model_fn function to load a Gluon model for ResNet-34 inference. The function loads model parameters from the model directory and returns a Gluon network that can be used for inference.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef model_fn(model_dir):\n    \"\"\"Load the Gluon model. Called when the hosting service starts.\n\n    Args:\n        model_dir (str): The directory where model files are stored.\n\n    Returns:\n        mxnet.gluon.nn.Block: a Gluon network (for this example)\n    \"\"\"\n    net = models.get_model('resnet34_v2', ctx=mx.cpu(), pretrained=False, classes=10)\n    net.load_params('%s/model.params' % model_dir, ctx=mx.cpu())\n    return net\n```\n\n----------------------------------------\n\nTITLE: Deploying TensorFlow Model Directly from Artifacts\nDESCRIPTION: Shows how to deploy existing TensorFlow model artifacts from S3 directly to a SageMaker endpoint, including optional Elastic Inference acceleration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = TensorFlowModel(model_data='s3://mybucket/model.tar.gz', role='MySageMakerRole', framework_version='x.x.x')\n\npredictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge')\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = TensorFlowModel(model_data='s3://mybucket/model.tar.gz', role='MySageMakerRole', framework_version='x.x.x')\n\npredictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge', accelerator_type='ml.eia1.medium')\n```\n\n----------------------------------------\n\nTITLE: Deploying Trained PyTorch Model and Making Predictions\nDESCRIPTION: This snippet shows how to train a PyTorch estimator, deploy it to a SageMaker endpoint, and use the deployed model for making predictions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Train my estimator\npytorch_estimator = PyTorch(entry_point='train_and_deploy.py',\n                            instance_type='ml.p3.2xlarge',\n                            instance_count=1,\n                            framework_version='1.8.0',\n                            py_version='py3')\npytorch_estimator.fit('s3://my_bucket/my_training_data/')\n\n# Deploy my estimator to a SageMaker Endpoint and get a Predictor\npredictor = pytorch_estimator.deploy(instance_type='ml.m4.xlarge',\n                                     initial_instance_count=1)\n\n# `data` is a NumPy array or a Python list.\n# `response` is a NumPy array.\nresponse = predictor.predict(data)\n```\n\n----------------------------------------\n\nTITLE: Initializing PyTorch Distributed Environment in Training Script\nDESCRIPTION: Code snippet for adapting a PyTorch training script to support distributed training. It shows how to initialize the distributed environment by setting up the process group using the distributed backend and host rank, which is required for PyTorch's DistributedDataParallel.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport torch.distributed as dist\n\nif args.distributed:\n    # Initialize the distributed environment.\n    world_size = len(args.hosts)\n    os.environ['WORLD_SIZE'] = str(world_size)\n    host_rank = args.hosts.index(args.current_host)\n    dist.init_process_group(backend=args.backend, rank=host_rank)\n```\n\n----------------------------------------\n\nTITLE: Custom Prediction Function for Scikit-learn Classifier\nDESCRIPTION: This snippet shows how to implement a custom predict_fn for a Logistic Regression classifier. It returns both predictions and prediction probabilities as a NumPy array, demonstrating how to customize the prediction behavior.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport sklearn\nimport numpy as np\n\ndef predict_fn(input_data, model):\n    prediction = model.predict(input_data)\n    pred_prob = model.predict_proba(input_data)\n    return np.array([prediction, pred_prob])\n```\n\n----------------------------------------\n\nTITLE: Custom Input and Output Handler Implementation for TensorFlow Serving\nDESCRIPTION: Example implementation of input_handler and output_handler functions to pre-process incoming requests and post-process TensorFlow Serving responses before returning to the client.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\ndef input_handler(data, context):\n    \"\"\" Pre-process request input before it is sent to TensorFlow Serving REST API\n    Args:\n        data (obj): the request data, in format of dict or string\n        context (Context): an object containing request and configuration details\n    Returns:\n        (dict): a JSON-serializable dict that contains request body and headers\n    \"\"\"\n    if context.request_content_type == 'application/json':\n        # pass through json (assumes it's correctly formed)\n        d = data.read().decode('utf-8')\n        return d if len(d) else ''\n\n    if context.request_content_type == 'text/csv':\n        # very simple csv handler\n        return json.dumps({\n            'instances': [float(x) for x in data.read().decode('utf-8').split(',')]\n        })\n\n    raise ValueError('{\\\"error\\\": \"unsupported content type {}\"}}'.format(\n        context.request_content_type or \"unknown\"))\n\n\ndef output_handler(data, context):\n    \"\"\"Post-process TensorFlow Serving output before it is returned to the client.\n    Args:\n        data (obj): the TensorFlow serving response\n        context (Context): an object containing request and configuration details\n    Returns:\n        (bytes, string): data to return to client, response content type\n    \"\"\"\n    if data.status_code != 200:\n        raise ValueError(data.content.decode('utf-8'))\n\n    response_content_type = context.accept_header\n    prediction = data.content\n    return prediction, response_content_type\n```\n\n----------------------------------------\n\nTITLE: SageMaker PyTorch Model Server Request Processing Flow\nDESCRIPTION: Shows the sequence of function calls in the SageMaker PyTorch model server for processing a prediction request. This demonstrates how input_fn, predict_fn, and output_fn work together.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# Deserialize the Invoke request body into an object we can perform prediction on\ninput_object = input_fn(request_body, request_content_type, context)\n\n# Perform prediction on the deserialized object, with the loaded model\nprediction = predict_fn(input_object, model, context)\n\n# Serialize the prediction result into the desired response content type\noutput = output_fn(prediction, response_content_type, context)\n```\n\n----------------------------------------\n\nTITLE: Using DistributedGradientTape with TensorFlow 2.x\nDESCRIPTION: Demonstrates how to wrap a standard TensorFlow GradientTape with the DistributedGradientTape to combine gradient values with AllReduce before applying them to model weights in TensorFlow 2.x.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith tf.GradientTape() as tape:\n      output = model(input)\n      loss_value = loss(label, output)\n\n# Wrap in smdistributed.dataparallel's DistributedGradientTape\ntape = smdistributed.dataparallel.tensorflow.DistributedGradientTape(tape)\n```\n\n----------------------------------------\n\nTITLE: Using FileSystemRecordSet with FSx for Lustre in SageMaker Training\nDESCRIPTION: Example of configuring a KMeans estimator with FSx for Lustre as input through the FileSystemRecordSet class. Requires proper VPC configuration with subnets and security groups to access the file system.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# This example shows how to use FileSystemRecordSet class\n# Configure an estimator with subnets and security groups from your VPC. The VPC should be the same as that\n# you chose for your Amazon EC2 instance\nkmeans = KMeans(role='SageMakerRole',\n                instance_count=1,\n                instance_type='ml.c4.xlarge',\n                k=10,\n                subnets=['subnet-1', 'subnet-2'],\n                security_group_ids=['sg-1'])\n\nrecords = FileSystemRecordSet(file_system_id='fs-=2,\n                              file_system_type='FSxLustre',\n                              directory_path='/<mount-id>/kmeans',\n                              num_records=784,\n                              feature_dim=784)\n\n# Start an Amazon SageMaker training job with FSx using the FileSystemRecordSet class\nkmeans.fit(records)\n```\n\n----------------------------------------\n\nTITLE: Configuring AutoML Step in SageMaker Pipeline\nDESCRIPTION: Demonstrates how to set up an AutoML step in a SageMaker pipeline including input configuration, step arguments, and retrieving the best model. The example shows how to specify training and validation inputs and parameters that affect step iterations.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_29\n\nLANGUAGE: python\nCODE:\n```\ninput_validation = AutoMLInput(\n    inputs=\"s3://amzn-s3-demo-bucket/my-validation-data\",\n    target_attribute_name=\"my_target_attribute_name\",\n    channel_type=\"validation\",\n)\n\nstep_args = auto_ml.fit(\n    inputs=[input_training, input_validation]\n)\n\nstep_automl = AutoMLStep(\n    name=\"AutoMLStep\",\n    step_args=step_args,\n)\n\nbest_model = step_automl.get_best_auto_ml_model(role=<role>)\n```\n\n----------------------------------------\n\nTITLE: Using PropertyFile with ProcessingStep in SageMaker Pipelines (Python)\nDESCRIPTION: This snippet demonstrates how to create a PropertyFile to store output information from a ProcessingStep. It shows the setup of the SKLearnProcessor, processing outputs, and defining a property file to capture hyperparameter information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nsklearn_processor = SKLearnProcessor(\n    framework_version=\"0.23-1\",\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=1,\n    base_job_name=\"sklearn-abalone-preprocess\",\n    sagemaker_session=session,\n    role=sagemaker.get_execution_role(),\n)\n\nstep_args = sklearn_processor.run(\n    outputs=[\n        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n        ProcessingOutput(output_name=\"hyperparam\", source=\"/opt/ml/processing/evaluation\"),\n    ],\n    code=\"./local/preprocess.py\",\n    arguments=[\"--input-data\", \"s3://my-input\"],\n)\n\nhyperparam_report = PropertyFile(\n    name=\"AbaloneHyperparamReport\",\n    output_name=\"hyperparam\",\n    path=\"hyperparam.json\",\n)\n\nstep_process = ProcessingStep(\n   name=\"PreprocessAbaloneData\",\n   step_args=step_args,\n   property_files=[hyperparam_report],\n)\n```\n\n----------------------------------------\n\nTITLE: Scaling Learning Rate in Distributed Training\nDESCRIPTION: Scales the learning rate based on the number of workers in the distributed training cluster to maintain effective optimization across multiple GPUs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlearning_rate = learning_rate * sdp.size()\n```\n\n----------------------------------------\n\nTITLE: Deploying XGBoost Model and Making Predictions in Python\nDESCRIPTION: Demonstrates how to deploy an XGBoost estimator, create a predictor with a custom serializer, and make predictions using the deployed model.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/using_xgboost.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nserializer = StringSerializer(content_type=\"text/libsvm\")\n\npredictor = estimator.deploy(\n    initial_instance_count=1,\n    instance_type=\"ml.m5.xlarge\",\n    serializer=serializer\n)\n\nwith open(\"abalone\") as f:\n    payload = f.read()\n\npredictor.predict(payload)\n```\n\n----------------------------------------\n\nTITLE: Creating a Condition Step in SageMaker Pipelines (Python)\nDESCRIPTION: This example shows how to create a ConditionStep that evaluates multiple conditions and executes different steps based on the evaluation result. All conditions must evaluate to true for the if_steps to execute.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nstep_condition = ConditionStep(\n    # The conditions are evaluated with operator AND\n    conditions = [condition_1, condition_2, condition_3, condition_4],\n    if_steps = [step_register],\n    else_steps = [step_fail],\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing predict_fn for PyTorch Elastic Inference\nDESCRIPTION: This function demonstrates how to implement a custom predict_fn for PyTorch Elastic Inference in SageMaker. It uses torch.jit.optimized_execution for optimized inference on Elastic Inference accelerators.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport numpy as np\n\ndef predict_fn(input_data, model):\n    device = torch.device(\"cpu\")\n    model = model.to(device)\n    input_data = data.to(device)\n    model.eval()\n    with torch.jit.optimized_execution(True, {\"target_device\": \"eia:0\"}):\n        output = model(input_data)\n```\n\n----------------------------------------\n\nTITLE: Making Regression Requests to TensorFlow Serving Endpoint in Python\nDESCRIPTION: This code shows how to make regression requests to a TensorFlow Serving endpoint if the SavedModel includes the appropriate signature_def. It demonstrates the input format for regression requests.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# input matches the Classify and Regress API\ninput = {\n  'signature_name': 'tensorflow/serving/regress',\n  'examples': [{'x': 1.0}, {'x': 2.0}]\n}\n\nresult = predictor.regress(input)  # or predictor.classify(...)\n\n# result contains:\n# {\n#   'results': [3.5, 4.0]\n# }\n```\n\n----------------------------------------\n\nTITLE: Deploying a SageMaker Serverless Endpoint from an Estimator\nDESCRIPTION: Deploys a trained model from an estimator to a SageMaker serverless endpoint using the ServerlessInferenceConfig object. This returns a predictor object that can be used for making predictions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_69\n\nLANGUAGE: python\nCODE:\n```\n# Deploys the model that was generated by fit() to a SageMaker serverless endpoint\nserverless_predictor = estimator.deploy(serverless_inference_config=serverless_config)\n```\n\n----------------------------------------\n\nTITLE: Creating MXNet Estimator in SageMaker Python SDK\nDESCRIPTION: This code snippet shows how to create an MXNet estimator using the SageMaker Python SDK. It specifies the training script, instance type, count, MXNet version, and Python version to use for training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmxnet_estimator = MXNet('train.py',\n                        instance_type='ml.p2.xlarge',\n                        instance_count=1,\n                        framework_version='1.6.0',\n                        py_version='py3',\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Output Function for SageMaker Scikit-learn Endpoint in Python\nDESCRIPTION: This function defines a custom output handler for SageMaker endpoints using Scikit-learn. It processes the prediction result and serializes it to the requested content type. The default implementation supports JSON, CSV, and NPY formats for NumPy arrays.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef output_fn(prediction, content_type):\n    ...\n\nWhere ``prediction`` is the result of invoking ``predict_fn`` and\n``content_type`` is the InvokeEndpoint requested response content-type.\nThe function should return a byte array of data serialized to content_type.\n\nThe default implementation expects ``prediction`` to be an NumPy and can serialize the result to JSON, CSV, or NPY.\nIt accepts response content types of \"application/json\", \"text/csv\", and \"application/x-npy\".\n```\n\n----------------------------------------\n\nTITLE: Deploying TensorFlow Model from Estimator\nDESCRIPTION: Example showing how to deploy a trained TensorFlow model from an estimator to create a SageMaker endpoint. Includes configuration of instance type and count.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\nestimator = TensorFlow(\n    entry_point=\"tf-train.py\",\n    ...,\n    instance_count=1,\n    instance_type=\"ml.c4.xlarge\",\n    framework_version=\"2.2\",\n    py_version=\"py37\",\n)\n\nestimator.fit(inputs)\n\npredictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.c5.xlarge\")\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Model with Dependencies in SageMaker Python SDK\nDESCRIPTION: This snippet demonstrates how to create a TensorFlow Model in SageMaker, specifying an entry point, source directory, and model data. It shows two methods of including dependencies: using requirements.txt and a lib directory.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = Model(entry_point='inference.py',\n              source_dir='source/directory',\n              model_data='s3://mybucket/model.tar.gz',\n              role='MySageMakerRole')\n\nmodel = Model(entry_point='inference.py',\n              dependencies=['/path/to/folder/named/lib'],\n              model_data='s3://mybucket/model.tar.gz',\n              role='MySageMakerRole')\n```\n\n----------------------------------------\n\nTITLE: Saving Checkpoints on Leader Node in TensorFlow Distributed Training\nDESCRIPTION: Modify the script to save checkpoints only on the leader node. This prevents worker nodes from overwriting checkpoints and potentially corrupting them.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nif sdp.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Using LocalPipelineSession for Local Execution in Python\nDESCRIPTION: This snippet demonstrates how to use LocalPipelineSession to run SageMaker pipelines locally. It shows the creation of a PyTorch estimator, a TrainingStep, and a Pipeline using LocalPipelineSession.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.workflow.pipeline_context import LocalPipelineSession\n\nlocal_pipeline_session = LocalPipelineSession()\n\npytorch_estimator = PyTorch(\n    sagemaker_session=local_pipeline_session,\n    role=sagemaker.get_execution_role(),\n    instance_type=\"ml.c5.xlarge\",\n    instance_count=1,\n    framework_version=\"1.8.0\",\n    py_version=\"py36\",\n    entry_point=\"./entry_point.py\",\n)\n\nstep = TrainingStep(\n    name=\"MyTrainingStep\",\n    step_args=pytorch_estimator.fit(\n        inputs=TrainingInput(s3_data=\"s3://my-bucket/my-data/train\"),\n    )\n)\n\npipeline = Pipeline(\n    name=\"MyPipeline\",\n    steps=[step],\n    sagemaker_session=local_pipeline_session\n)\n\npipeline.create(\n    role_arn=sagemaker.get_execution_role(),\n    description=\"local pipeline example\"\n)\n\n// pipeline will execute locally\npipeline.start()\n\nsteps = pipeline.list_steps()\n\ntraining_job_name = steps['PipelineExecutionSteps'][0]['Metadata']['TrainingJob']['Arn']\n\nstep_outputs = pipeline_session.sagemaker_client.describe_training_job(TrainingJobName = training_job_name)\n```\n\n----------------------------------------\n\nTITLE: Configuring ServerlessInferenceConfig with Custom Parameters in SageMaker\nDESCRIPTION: Creates a ServerlessInferenceConfig object with custom parameters for memory size and maximum concurrency. These parameters determine the resources available to the serverless endpoint.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_68\n\nLANGUAGE: python\nCODE:\n```\n# Specify MemorySizeInMB and MaxConcurrency in the serverless config object\nserverless_config = ServerlessInferenceConfig(\n  memory_size_in_mb=4096,\n  max_concurrency=10,\n)\n```\n\n----------------------------------------\n\nTITLE: Checkpoint Saving for Distributed Training\nDESCRIPTION: Implements checkpoint saving logic that only executes on the leader node to prevent corruption.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif dist.get_rank() == 0:\n   torch.save(...)\n```\n\n----------------------------------------\n\nTITLE: Using AlgorithmEstimator with Amazon SageMaker Algorithm\nDESCRIPTION: Demonstrates how to use the AlgorithmEstimator class to train and deploy models using an algorithm ARN. This allows consuming algorithms from the AWS Marketplace or your own registered algorithms with client-side validation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport sagemaker\n\nalgo = sagemaker.AlgorithmEstimator(\n    algorithm_arn='arn:aws:sagemaker:us-west-2:1234567:algorithm/some-algorithm',\n    role='SageMakerRole',\n    instance_count=1,\n    instance_type='ml.c4.xlarge')\n\ntrain_input = algo.sagemaker_session.upload_data(path='/path/to/your/data')\n\nalgo.fit({'training': train_input})\npredictor = algo.deploy(1, 'ml.m4.xlarge')\n\n# When you are done using your endpoint\npredictor.delete_endpoint()\n```\n\n----------------------------------------\n\nTITLE: Creating a SageMaker Transformer for Batch Transformations with Pipeline Model in Python\nDESCRIPTION: Configures a transformer object for batch inference with a pipeline model. The configuration includes instance settings, processing strategy, payload limits, and output specifications for transforming data in batch mode.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_90\n\nLANGUAGE: python\nCODE:\n```\n# Only instance_type and instance_count are required.\ntransformer = sm_model.transformer(instance_type='ml.c5.xlarge',\n                                  instance_count=1,\n                                  strategy='MultiRecord',\n                                  max_payload=6,\n                                  max_concurrent_transforms=8,\n                                  accept='text/csv',\n                                  assemble_with='Line',\n                                  output_path='s3://my-output-bucket/path/to/my/output/data/')\n# Only data is required.\ntransformer.transform(data='s3://my-input-bucket/path/to/my/csv/data',\n                     content_type='text/csv',\n                     split_type='Line')\n# Waits for the Pipeline Transform Job to finish.\ntransformer.wait()\n```\n\n----------------------------------------\n\nTITLE: Defining Training Metrics for SageMaker Estimators\nDESCRIPTION: Example of configuring custom metric definitions for a bring-your-own estimator in SageMaker. Metrics are defined with a name and regular expression to extract values from training logs, enabling tracking during the training process.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Configure an BYO Estimator with metric definitions (no training happens yet)\nbyo_estimator = Estimator(image_uri=image_uri,\n                          role='SageMakerRole', instance_count=1,\n                          instance_type='ml.c4.xlarge',\n                          sagemaker_session=sagemaker_session,\n                          metric_definitions=[{'Name': 'test:msd', 'Regex': '#quality_metric: host=\\\\S+, test msd <loss>=(\\\\S+)'},\n                                              {'Name': 'test:ssd', 'Regex': '#quality_metric: host=\\\\S+, test ssd <loss>=(\\\\S+)'}])\n```\n\n----------------------------------------\n\nTITLE: Deploying TensorFlow Model to SageMaker Endpoint\nDESCRIPTION: This example demonstrates how to deploy a trained TensorFlow model to a SageMaker endpoint using the deploy method of a TensorFlow estimator.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\nestimator = TensorFlow(\n    entry_point=\"tf-train.py\",\n    ...,\n    instance_count=1,\n    instance_type=\"ml.c4.xlarge\",\n    framework_version=\"2.2\",\n    py_version=\"py37\",\n)\n\nestimator.fit(inputs)\n\npredictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.c5.xlarge\")\n```\n\n----------------------------------------\n\nTITLE: Deploying a Trained MXNet Model to a SageMaker Endpoint\nDESCRIPTION: Creates and deploys a trained MXNet model to a SageMaker endpoint. The code first trains an MXNet estimator and then deploys it to an ml.m4.xlarge instance, returning a predictor object that can be used for inference.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Train my estimator\nmxnet_estimator = MXNet('train.py',\n                        framework_version='1.6.0',\n                        py_version='py3',\n                        instance_type='ml.p2.xlarge',\n                        instance_count=1)\nmxnet_estimator.fit('s3://my_bucket/my_training_data/')\n\n# Deploy my estimator to an Amazon SageMaker Endpoint and get a Predictor\npredictor = mxnet_estimator.deploy(instance_type='ml.m4.xlarge',\n                                   initial_instance_count=1)\n```\n\n----------------------------------------\n\nTITLE: Using PipeModeDataset for Efficient Data Streaming in SageMaker\nDESCRIPTION: This code demonstrates how to use PipeModeDataset to efficiently stream TFRecords data during training in SageMaker, including data parsing and input function setup.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker_tensorflow import PipeModeDataset\n\nfeatures = {\n    'data': tf.FixedLenFeature([], tf.string),\n    'labels': tf.FixedLenFeature([], tf.int64),\n}\n\ndef parse(record):\n    parsed = tf.parse_single_example(record, features)\n    return ({\n        'data': tf.decode_raw(parsed['data'], tf.float64)\n    }, parsed['labels'])\n\ndef train_input_fn(training_dir, hyperparameters):\n    ds = PipeModeDataset(channel='training', record_format='TFRecord')\n    ds = ds.repeat(20)\n    ds = ds.prefetch(10)\n    ds = ds.map(parse, num_parallel_calls=10)\n    ds = ds.batch(64)\n    return ds\n```\n\n----------------------------------------\n\nTITLE: Deploying Hugging Face Hub Model Locally using ModelBuilder in Python\nDESCRIPTION: Demonstrates how to use ModelBuilder to deploy a Hugging Face Hub model (Llama-2-7b) locally. Sets up the model directory, specifies environment variables, and deploys the model.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_43\n\nLANGUAGE: python\nCODE:\n```\nmodel_dir = \"/home/ec2-user/SageMaker/LoadTestResources/meta-llama2-7b\", #local path where artifacts are saved\n!mkdir -p {model_dir}\n\nllm_hf_working_dir = str(Path(model_dir).resolve())\n\nmodel_builder = ModelBuilder(\n    model=\"meta-llama/Llama-2-7b-hf\",\n    schema_builder=SchemaBuilder(sample_input, sample_output),\n    model_path=llm_hf_working_dir,\n    mode=Mode.LOCAL_CONTAINER,\n    env_vars={\n        # Llama 2 is a gated model and requires a Hugging Face Hub token.\n        \"HUGGING_FACE_HUB_TOKEN\": \"<YourHuggingFaceToken>\"\n\n    }\n)\nmodel = model_builder.build()\nlocal_predictor = model.deploy()\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Dependencies Between Pipeline Steps in SageMaker (Python)\nDESCRIPTION: This example shows how to build a custom dependency between two ProcessingSteps in SageMaker Pipelines. The second step will only execute after the first step has completed successfully.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nstep_1 = ProcessingStep(\n    name=\"MyProcessingStep\",\n    step_args=sklearn_processor.run(\n        inputs=inputs,\n        code=\"./my-local/my-first-script.py\"\n    ),\n)\n\nstep_2 = ProcessingStep(\n    name=\"MyProcessingStep\",\n    step_args=sklearn_processor.run(\n        inputs=inputs,\n        code=\"./my-local/my-second-script.py\"\n    ),\n    depends_on=[step_1.name],\n)\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Model Variables in Distributed Setup\nDESCRIPTION: Broadcasts initial model and optimizer variables from the leader node to all worker nodes for consistent initialization.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsdp.broadcast_variables(model.variables, root_rank=0)\nsdp.broadcast_variables(opt.variables(), root_rank=0)\n```\n\n----------------------------------------\n\nTITLE: Implementing SageMaker Operators DAG in Airflow\nDESCRIPTION: Shows how to create an Airflow DAG using SageMaker operators for training and transform tasks. Includes DAG configuration, operator setup, and task dependencies.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/using_workflow.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport airflow\nfrom airflow import DAG\nfrom airflow.contrib.operators.sagemaker_training_operator import SageMakerTrainingOperator\nfrom airflow.contrib.operators.sagemaker_transform_operator import SageMakerTransformOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': airflow.utils.dates.days_ago(2),\n    'provide_context': True\n}\n\ndag = DAG('tensorflow_example', default_args=default_args,\n          schedule_interval='@once')\n\ntrain_op = SageMakerTrainingOperator(\n    task_id='tf_training',\n    config=train_config,\n    wait_for_completion=True,\n    dag=dag)\n\ntransform_op = SageMakerTransformOperator(\n    task_id='tf_transform',\n    config=trans_config,\n    wait_for_completion=True,\n    dag=dag)\n\ntransform_op.set_upstream(train_op)\n```\n\n----------------------------------------\n\nTITLE: Enabling Encrypted Inter-Container Traffic with VPC in SageMaker\nDESCRIPTION: This example shows how to enable encryption for traffic between containers during SageMaker training jobs by setting the encrypt_inter_container_traffic flag to True when configuring a VPC-enabled estimator.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_83\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.mxnet import MXNet\n\n# Configure an MXNet Estimator with subnets and security groups from your VPC\nmxnet_vpc_estimator = MXNet('train.py',\n                            instance_type='ml.p2.xlarge',\n                            instance_count=1,\n                            framework_version='1.2.1',\n                            subnets=['subnet-1', 'subnet-2'],\n                            security_group_ids=['sg-1'],\n                            encrypt_inter_container_traffic=True)\n\n# The SageMaker training job sets the VpcConfig, and training container instances run in your VPC with traffic between the containers encrypted\nmxnet_vpc_estimator.fit('s3://my_bucket/my_training_data/')\n```\n\n----------------------------------------\n\nTITLE: Saving Checkpoints on Leader Node in SageMaker Distributed Training\nDESCRIPTION: Ensures checkpoints are saved only on the leader node (rank 0) to avoid worker nodes overwriting and potentially corrupting the checkpoints.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif dist.get_rank() == 0:\n   torch.save(...)\n```\n\n----------------------------------------\n\nTITLE: Initializing DistributedDataParallel for PyTorch Model\nDESCRIPTION: Example usage of smdistributed.dataparallel.torch.parallel.DistributedDataParallel to wrap a PyTorch model for distributed training. It initializes the process group, sets the device, builds the model and optimizer, and wraps the model with DDP.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.rst#2025-04-22_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nimport torch\nimport smdistributed.dataparallel.torch.distributed as dist\nfrom smdistributed.dataparallel.torch.parallel import DistributedDataParallel as DDP\n\ndist.init_process_group()\n\n# Pin GPU to be used to process local rank (one GPU per process)\ntorch.cuda.set_device(dist.get_local_rank())\n\n# Build model and optimizer\nmodel = ...\noptimizer = torch.optim.SGD(model.parameters(),\n                            lr=1e-3 * dist.get_world_size())\n# Wrap model with smdistributed.dataparallel's DistributedDataParallel\nmodel = DDP(model)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Running PySparkProcessor in SageMaker\nDESCRIPTION: This snippet demonstrates how to configure a PySparkProcessor with Spark settings and run a preprocessing job with specified arguments. It shows setting instance types, runtime limits, Spark configuration properties, and passing data location arguments to the processing job.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_processing.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n        instance_type=\"ml.c5.xlarge\",\n        max_runtime_in_seconds=1200,\n    )\n\n    configuration = [{\n      \"Classification\": \"spark-defaults\",\n      \"Properties\": {\"spark.executor.memory\": \"2g\", \"spark.executor.cores\": \"1\"},\n    }]\n\n    spark_processor.run(\n        submit_app=\"./code/preprocess.py\",\n        arguments=[\"s3_input_bucket\", bucket,\n                   \"s3_input_key_prefix\", input_prefix_abalone,\n                   \"s3_output_bucket\", bucket,\n                   \"s3_output_key_prefix\", input_preprocessed_prefix_abalone],\n        configuration=configuration,\n        logs=False\n    )\n```\n\n----------------------------------------\n\nTITLE: Deploying TensorFlow Model with Elastic Inference Accelerator in Python\nDESCRIPTION: This code shows how to deploy a TensorFlow model to a SageMaker endpoint with an attached Elastic Inference accelerator for cost-effective inference acceleration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = TensorFlowModel(model_data='s3://mybucket/model.tar.gz', role='MySageMakerRole', framework_version='x.x.x')\n\npredictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge', accelerator_type='ml.eia1.medium')\n```\n\n----------------------------------------\n\nTITLE: Parsing Arguments in TensorFlow Training Script for SageMaker\nDESCRIPTION: Example code showing how to set up argument parsing in a TensorFlow training script to handle hyperparameters and input data directories passed by SageMaker. The script retrieves command-line arguments and environment variables for training configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport os\n\nif __name__ =='__main__':\n\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument('--epochs', type=int, default=10)\n    parser.add_argument('--batch_size', type=int, default=100)\n    parser.add_argument('--learning_rate', type=float, default=0.1)\n\n    # input data and model directories\n    parser.add_argument('--model_dir', type=str)\n    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n\n    args, _ = parser.parse_known_args()\n\n    # ... load from args.train and args.test, train a model, write model to args.model_dir.\n```\n\n----------------------------------------\n\nTITLE: Implementing predict_fn with Multi-GPU Support in SageMaker\nDESCRIPTION: This function shows how to implement a custom predict_fn for a PyTorch model in SageMaker with support for multiple GPUs. It uses the context argument to dynamically select a GPU device.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport numpy as np\n\ndef predict_fn(input_data, model, context):\n    device = torch.device(\"cuda:\" + str(context.system_properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    with torch.no_grad():\n        return model(input_data.to(device))\n```\n\n----------------------------------------\n\nTITLE: Saving a PyTorch Model in SageMaker Training Environment\nDESCRIPTION: Example showing how to save a trained PyTorch model to the correct location (SM_MODEL_DIR) for SageMaker to upload to S3 after training completes.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport os\nimport torch\n\nif __name__=='__main__':\n    # default to the value in environment variable `SM_MODEL_DIR`. Using args makes the script more portable.\n    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n    args, _ = parser.parse_known_args()\n\n    # ... train `model`, then save it to `model_dir`\n    with open(os.path.join(args.model_dir, 'model.pth'), 'wb') as f:\n        torch.save(model.state_dict(), f)\n```\n\n----------------------------------------\n\nTITLE: Custom Input Processing Function for Pickled NumPy Arrays\nDESCRIPTION: This snippet demonstrates how to implement a custom input_fn that deserializes pickled NumPy arrays. It handles the 'application/python-pickle' content type and returns the unpickled array for prediction.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\ndef input_fn(request_body, request_content_type):\n    \"\"\"An input_fn that loads a pickled numpy array\"\"\"\n    if request_content_type == \"application/python-pickle\":\n        array = np.load(StringIO(request_body))\n        return array\n    else:\n        # Handle other content-types here or raise an Exception\n        # if the content type is not supported.\n        pass\n```\n\n----------------------------------------\n\nTITLE: Custom Payload Translation Implementation\nDESCRIPTION: Shows how to implement custom serialization and deserialization using CustomPayloadTranslator for both request and response handling.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.serve import CustomPayloadTranslator\n\n# request translator\nclass MyRequestTranslator(CustomPayloadTranslator):\n    # This function converts the payload to bytes - happens on client side\n    def serialize_payload_to_bytes(self, payload: object) -> bytes:\n        # converts the input payload to bytes\n        ... ...\n        return  //return object as bytes\n\n    # This function converts the bytes to payload - happens on server side\n    def deserialize_payload_from_stream(self, stream) -> object:\n        # convert bytes to in-memory object\n        ... ...\n        return //return in-memory object\n\n# response translator\nclass MyResponseTranslator(CustomPayloadTranslator):\n    # This function converts the payload to bytes - happens on server side\n    def serialize_payload_to_bytes(self, payload: object) -> bytes:\n        # converts the response payload to bytes\n        ... ...\n        return //return object as bytes\n\n    # This function converts the bytes to payload - happens on client side\n    def deserialize_payload_from_stream(self, stream) -> object:\n        # convert bytes to in-memory object\n        ... ...\n        return //return in-memory object\n```\n\n----------------------------------------\n\nTITLE: Using File Systems as Training Inputs with SageMaker\nDESCRIPTION: Demonstrates how to use Amazon EFS as a data source for training models with SageMaker. The example shows the configuration of FileSystemInput with a TensorFlow estimator in a VPC that has access to the EFS file system.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# This example shows how to use FileSystemInput class\n# Configure an estimator with subnets and security groups from your VPC. The EFS volume must be in\n# the same VPC as your Amazon EC2 instance\nestimator = TensorFlow(entry_point='tensorflow_mnist/mnist.py',\n                       role='SageMakerRole',\n                       instance_count=1,\n                       instance_type='ml.c4.xlarge',\n                       subnets=['subnet-1', 'subnet-2']\n                       security_group_ids=['sg-1'])\n\nfile_system_input = FileSystemInput(file_system_id='fs-1',\n                                    file_system_type='EFS',\n                                    directory_path='/tensorflow',\n```\n\n----------------------------------------\n\nTITLE: Using Synchronous Prediction Methods for Asynchronous Endpoints\nDESCRIPTION: Uses the predict method to wait for and return the result of an asynchronous inference request. This method periodically checks for the result and returns it upon completion.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_64\n\nLANGUAGE: python\nCODE:\n```\n# Use predict() to wait for the result\nresponse = async_predictor.predict(data=data)\n\n# Or use Amazon S3 input path\nresponse = async_predictor.predict(input_path=input_s3_path)\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Initial Model Variables in Distributed TensorFlow Training\nDESCRIPTION: Broadcast initial model and optimizer variables from the leader node to all worker nodes to ensure consistent initialization across all worker ranks.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsdp.broadcast_variables(model.variables, root_rank=0)\nsdp.broadcast_variables(opt.variables(), root_rank=0)\n```\n\n----------------------------------------\n\nTITLE: Creating TrainingStep with PipelineSession in Python\nDESCRIPTION: This example shows how to use PipelineSession to create a TrainingStep for use in a SageMaker pipeline. PipelineSession delays the start of the training job until pipeline execution time.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.workflow.pipeline_context import PipelineSession\n\npytorch_estimator = PyTorch(\n    sagemaker_session=PipelineSession(),\n    role=sagemaker.get_execution_role(),\n    instance_type=\"ml.c5.xlarge\",\n    instance_count=1,\n    framework_version=\"1.8.0\",\n    py_version=\"py36\",\n    entry_point=\"./entry_point.py\",\n)\n\nstep = TrainingStep(\n    name=\"MyTrainingStep\",\n    // code just like how you trigger a training job before,\n    // pipeline session will take care of delaying the start\n    // of the training job during pipeline execution.\n    step_args=pytorch_estimator.fit(\n        inputs=TrainingInput(s3_data=\"s3://my-bucket/my-data/train\"),\n    ),\n    displayName=\"MyTrainingStepDisplayName\",\n    description=\"This is MyTrainingStep\",\n    cache_config=CacheConfig(...),\n    retry_policies=[...],\n    depends_on=[...],\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Model Quality Monitoring for SageMaker Batch Transform in Python\nDESCRIPTION: Demonstrates how to set up model quality monitoring for a batch transform job. This example shows how to include ground truth data in the transform input, configure the join between input and output, and set up model quality monitoring after the transform job completes.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_35\n\nLANGUAGE: python\nCODE:\n```\ntransformer = Transformer(..., sagemaker_session=pipeline_session)\n\ntransform_arg = transformer.transform(\n    transform_input_param,\n    content_type=\"text/csv\",\n    split_type=\"Line\",\n    # Note that we need to join both the inference input and output\n    # into transform outputs. The inference input needs to have the ground truth.\n    # details can be found here\n    # https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html\n    join_source=\"Input\",\n    # We need to exclude the ground truth inside the inference input\n    # before passing it to the prediction model.\n    # Assume the first column of our csv file is the ground truth\n    input_filter=\"$[1:]\",\n    ...\n)\n\nmodel_quality_config = ModelQualityCheckConfig(\n    baseline_dataset=transformer.output_path,\n    problem_type=\"BinaryClassification\",\n    dataset_format=DatasetFormat.csv(header=False),\n    output_s3_uri=\"s3://my-output\",\n    # assume the model output is at column idx 10\n    inference_attribute=\"_c10\",\n    # As pointed out previously, the first column is the ground truth.\n    ground_truth_attribute=\"_c0\",\n)\nfrom sagemaker.workflow.monitor_batch_transform_step import MonitorBatchTransformStep\n\ntransform_and_monitor_step = MonitorBatchTransformStep(\n    name=\"MyMonitorBatchTransformStep\",\n    transform_step_args=transform_arg,\n    monitor_configuration=data_quality_config,\n    check_job_configuration=job_config,\n    # model quality job needs the transform outputs, therefore\n    # monitor_before_transform can not be true for model quality\n    monitor_before_transform=False,\n    fail_on_violation=True,\n    supplied_baseline_statistics=\"s3://my-baseline-statistics.json\",\n    supplied_baseline_constraints=\"s3://my-baseline-constraints.json\",\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Incremental Training in SageMaker\nDESCRIPTION: Example of using incremental training to continue training from a pre-existing model. This creates an initial estimator, trains a model, then creates a second estimator that uses the first model's artifacts as a starting point for additional training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Configure an estimator\nestimator = sagemaker.estimator.Estimator(training_image,\n                                      role,\n                                      instance_count=1,\n                                      instance_type='ml.p2.xlarge',\n                                      volume_size=50,\n                                      max_run=360000,\n                                      input_mode='File',\n                                      output_path=s3_output_location)\n\n# Start a SageMaker training job and waits until completion.\nestimator.fit('s3://my_bucket/my_training_data/')\n\n# Create a new estimator using the previous' model artifacts\nincr_estimator = sagemaker.estimator.Estimator(training_image,\n                                              role,\n                                              instance_count=1,\n                                              instance_type='ml.p2.xlarge',\n                                              volume_size=50,\n                                              max_run=360000,\n                                              input_mode='File',\n                                              output_path=s3_output_location,\n                                              model_uri=estimator.model_data)\n\n# Start a SageMaker training job using the original model for incremental training\nincr_estimator.fit('s3://my_bucket/my_training_data/')\n```\n\n----------------------------------------\n\nTITLE: Initializing SageMaker Feature Store Sessions\nDESCRIPTION: Sets up the necessary sessions and clients for working with SageMaker Feature Store. This includes creating a boto3 session, SageMaker session, and Feature Store session, along with configuring the S3 bucket for the offline store.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport boto3\nimport sagemaker\nfrom sagemaker.session import Session\n\nboto_session = boto3.Session(region_name=region)\nrole = sagemaker.get_execution_role()\nsagemaker_session = sagemaker.Session()\nregion = sagemaker_session.boto_region_name\ndefault_bucket = sagemaker_session.default_bucket()\nprefix = 'sagemaker-featurestore'\noffline_feature_store_bucket = 's3://*{}*/*{}*'.format(default_bucket, prefix)\n\nsagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\nfeaturestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n\nfeature_store_session = Session(\n    boto_session=boto_session,\n    sagemaker_client=sagemaker_client,\n    sagemaker_featurestore_runtime_client=featurestore_runtime\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Pipeline Parameters in Python\nDESCRIPTION: This example shows how to define and use pipeline parameters in a SageMaker pipeline. It demonstrates the creation of different parameter types and their usage in a ProcessingStep and Pipeline definition.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.workflow.parameters import (\n    ParameterInteger,\n    ParameterString,\n    ParameterFloat,\n    ParameterBoolean,\n)\nfrom sagemaker.workflow.pipeline_context import PipelineSession\n\nsession = PipelineSession()\n\ninstance_count = ParameterInteger(name=\"InstanceCount\", default_value=2)\napp_managed = ParameterBoolean(name=\"AppManaged\", default_value=False)\n\ninputs = [\n    ProcessingInput(\n        source=\"s3://my-bucket/sourcefile\",\n        destination=\"/opt/ml/processing/inputs/\",\n        app_managed=app_managed\n    ),\n]\n\nsklearn_processor = SKLearnProcessor(\n    framework_version=\"0.23-1\",\n    role=sagemaker.get_execution_role(),\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=instance_count,\n    command=[\"python3\"],\n    sagemaker_session=session,\n    base_job_name=\"test-sklearn\",\n)\n\nstep_sklearn = ProcessingStep(\n    name=\"MyProcessingStep\",\n    step_args=sklearn_processor.run(\n        inputs=inputs, code=\"./my-local/script.py\"\n    ),\n)\n\npipeline = Pipeline(\n    name=pipeline_name,\n    parameters=[instance_count, app_managed],\n    steps=[step_sklearn],\n    sagemaker_session=session,\n)\n\n# you can override the default parameter values\npipeline.start({\n   \"InstanceCount\": 2,\n   \"AppManaged\": True,\n})\n```\n\n----------------------------------------\n\nTITLE: Custom Prediction Function for XGBoost Model in Python\nDESCRIPTION: Shows an example of a custom predict_fn that returns predictions along with feature contributions (SHAP values) for each prediction.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/using_xgboost.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\ndef predict_fn(input_data, model):\n    prediction = model.predict(input_data)\n    feature_contribs = model.predict(input_data, pred_contribs=True)\n    output = np.hstack((prediction[:, np.newaxis], feature_contribs))\n    return output\n```\n\n----------------------------------------\n\nTITLE: Implementing SageMaker Model Server Request Processing Flow\nDESCRIPTION: This snippet illustrates the internal flow of how the SageMaker Scikit-learn model server processes prediction requests. It shows the three main steps: input processing with input_fn, prediction with predict_fn, and output processing with output_fn.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Deserialize the Invoke request body into an object we can perform prediction on\ninput_object = input_fn(request_body, request_content_type)\n\n# Perform prediction on the deserialized object, with the loaded model\nprediction = predict_fn(input_object, model)\n\n# Serialize the prediction result into the desired response content type\noutput = output_fn(prediction, response_content_type)\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Capture for SageMaker Endpoint\nDESCRIPTION: Sets up data capture configuration for a SageMaker endpoint to monitor model data quality. Configures capture settings and deploys a model with the specified monitoring configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_monitoring.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.model_monitor import DataCaptureConfig\n\ndata_capture_config = DataCaptureConfig(\n    enable_capture=True,\n    sampling_percentage=100,\n    destination_s3_uri='s3://path/for/data/capture'\n)\n\npredictor = model.deploy(\n    initial_instance_count=1,\n    instance_type='ml.m4.xlarge',\n    data_capture_config=data_capture_config\n)\n```\n\n----------------------------------------\n\nTITLE: Complete TensorFlow2 Distributed Training Script\nDESCRIPTION: A complete example showing how to implement distributed training using SageMaker's data parallel library with TensorFlow 2.x.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\n# Import the library's TF API\nimport smdistributed.dataparallel.tensorflow as sdp\n\n# Initialize the library\nsdp.init()\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    # Pin GPUs to a single process\n    tf.config.experimental.set_visible_devices(gpus[sdp.local_rank()], 'GPU')\n\n# Prepare Dataset\ndataset = tf.data.Dataset.from_tensor_slices(...)\n\n# Define Model\nmnist_model = tf.keras.Sequential(...)\nloss = tf.losses.SparseCategoricalCrossentropy()\n\n# Scale Learning Rate\n# LR for 8 node run : 0.000125\n# LR for single node run : 0.001\nopt = tf.optimizers.Adam(0.000125 * sdp.size())\n\n@tf.function\ndef training_step(images, labels, first_batch):\n    with tf.GradientTape() as tape:\n        probs = mnist_model(images, training=True)\n        loss_value = loss(labels, probs)\n\n    # Wrap tf.GradientTape with the library's DistributedGradientTape\n    tape = sdp.DistributedGradientTape(tape)\n\n    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n    opt.apply_gradients(zip(grads, mnist_model.trainable_variables))\n\n    if first_batch:\n        # Broadcast model and optimizer variables\n        sdp.broadcast_variables(mnist_model.variables, root_rank=0)\n        sdp.broadcast_variables(opt.variables(), root_rank=0)\n\n    return loss_value\n\n...\n\n# Save checkpoints only from master node.\nif sdp.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Using BroadcastGlobalVariablesHook in TensorFlow 2.x with tf.estimator\nDESCRIPTION: Example of how to use BroadcastGlobalVariablesHook to ensure consistent initialization of all workers in distributed training. This is applicable for tf.estimator API in TensorFlow 2.x (2.3.1).\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nhooks = [smdistributed.dataparallel.tensorflow.BroadcastGlobalVariablesHook(root_rank=0)]\n...\nwith tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,\n                                       hooks=hooks,\n                                       config=config) as mon_sess:\n     ...\n```\n\n----------------------------------------\n\nTITLE: Using Execution Variables in SageMaker Pipeline Processing Step\nDESCRIPTION: This example shows how to use execution variables like START_DATETIME to create dynamic output paths in a SageMaker Pipeline. The execution variable is used to append a timestamp to the S3 destination path for processing outputs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nbucket = ParameterString('bucket', default_value='my-bucket')\n\noutput_path = Join(\n    on=\"/\",\n    values=['s3:/', bucket, 'my-train-output-', ExecutionVariables.START_DATETIME])]\n)\n\nstep = ProcessingStep(\n    name=\"MyTrainingStep\",\n    step_args=processor.fit(\n        inputs=ProcessingInput(source=\"s3://my-input\"),\n        outputs=[\n            ProcessingOutput(\n                output_name=\"train\",\n                source=\"/opt/ml/processing/train\",\n                destination=output_path,\n            ),\n        ],\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Chaining DatasetBuilder Configurations in SageMaker Feature Store with Python\nDESCRIPTION: Demonstrates how to chain multiple configuration methods of the DatasetBuilder to create customized datasets from feature store.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ndataset_builder\n   .with_number_of_records_from_query_results(number_of_records=N)\n   .include_duplicated_records()\n   .with_number_of_recent_records_by_record_identifier(number_of_recent_records=N)\n   .to_dataframe()\n```\n\n----------------------------------------\n\nTITLE: Configuring Distribution Strategy for SageMaker Estimator in Python\nDESCRIPTION: This code snippet shows how to configure the distribution strategy for a SageMaker TensorFlow or PyTorch estimator to enable distributed data parallel training. It sets the 'smdistributed' strategy with 'dataparallel' enabled.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_use_sm_pysdk.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndistribution = { \"smdistributed\": { \"dataparallel\": { \"enabled\": True } } }\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Handler for TensorFlow Serving in Python\nDESCRIPTION: This snippet shows how to implement a custom handler function for complete control over the TensorFlow Serving request process. It includes input processing, making a REST request, and output processing.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport json\nimport requests\n\n\ndef handler(data, context):\n    \"\"\"Handle request.\n    Args:\n        data (obj): the request data\n        context (Context): an object containing request and configuration details\n    Returns:\n        (bytes, string): data to return to client, (optional) response content type\n    \"\"\"\n    processed_input = _process_input(data, context)\n    response = requests.post(context.rest_uri, data=processed_input)\n    return _process_output(response, context)\n\n\ndef _process_input(data, context):\n    if context.request_content_type == 'application/json':\n        # pass through json (assumes it's correctly formed)\n        d = data.read().decode('utf-8')\n        return d if len(d) else ''\n\n    if context.request_content_type == 'text/csv':\n        # very simple csv handler\n        return json.dumps({\n            'instances': [float(x) for x in data.read().decode('utf-8').split(',')]\n        })\n\n    raise ValueError('{\"error\": \"unsupported content type {}\"}}'.format(\n        context.request_content_type or \"unknown\"))\n\n\ndef _process_output(data, context):\n    if data.status_code != 200:\n        raise ValueError(data.content.decode('utf-8'))\n\n    response_content_type = context.accept_header\n    prediction = data.content\n    return prediction, response_content_type\n```\n\n----------------------------------------\n\nTITLE: Enabling Early Stopping in SageMaker HyperparameterTuner\nDESCRIPTION: Shows how to enable early stopping for a hyperparameter tuning job by setting the early_stopping_type parameter to 'Auto'. This helps automatically stop training jobs that are unlikely to produce better models than other jobs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_55\n\nLANGUAGE: python\nCODE:\n```\n# Enable early stopping\nmy_tuner = HyperparameterTuner(estimator=my_estimator,  # previously-configured Estimator object\n                               objective_metric_name='validation-accuracy',\n                               hyperparameter_ranges={'learning-rate': ContinuousParameter(0.05, 0.06)},\n                               metric_definitions=[{'Name': 'validation-accuracy', 'Regex': 'validation-accuracy=(\\d\\.\\d+)'}],\n                               max_jobs=100,\n                               max_parallel_jobs=10,\n                               early_stopping_type='Auto')\n```\n\n----------------------------------------\n\nTITLE: Deploying Hugging Face Model to SageMaker Endpoint using ModelBuilder in Python\nDESCRIPTION: Creates a ModelBuilder object to deploy a Hugging Face model to a SageMaker endpoint. Specifies the inference spec, deployment mode, schema, and container image URI.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_42\n\nLANGUAGE: python\nCODE:\n```\nbuilder = ModelBuilder(\n    inference_spec=inf_spec,\n    mode=Mode.SAGEMAKER_ENDPOINT,  # you can change it to Mode.LOCAL_CONTAINER for local testing\n    schema_builder=schema,\n    image_uri=\"123123123123.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04-v1.0\"\n)\nmodel = builder.build(\n    role_arn=execution_role,\n    sagemaker_session=sagemaker_session,\n)\npredictor = model.deploy(\n    initial_instance_count=1,\n    instance_type='ml.g5.2xlarge'\n)\n```\n\n----------------------------------------\n\nTITLE: Using DistributedGradientTape in TensorFlow 2.x\nDESCRIPTION: Demonstrates how to wrap a TensorFlow GradientTape with DistributedGradientTape for distributed gradient computation and application.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith tf.GradientTape() as tape:\n      output = model(input)\n      loss_value = loss(label, output)\n\n# Wrap in smdistributed.dataparallel's DistributedGradientTape\ntape = smdistributed.dataparallel.tensorflow.DistributedGradientTape(tape)\n```\n\n----------------------------------------\n\nTITLE: Implementing Chainer Prediction Function for SageMaker\nDESCRIPTION: A sample implementation of a prediction function that uses Chainer to generate bounding boxes, labels, and scores from input data. This function disables training mode and backpropagation while making predictions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith chainer.using_config('train', False), chainer.no_backprop_mode():\n    bboxes, labels, scores = model.predict([input_data])\n    bbox, label, score = bboxes[0], labels[0], scores[0]\n    return np.array([bbox.tolist(), label, score])\n```\n\n----------------------------------------\n\nTITLE: Using sagemaker-upgrade-v2 Command Line Tool with Single Files\nDESCRIPTION: Command line examples for using the sagemaker-upgrade-v2 tool to upgrade single Python files or Jupyter notebooks from SageMaker SDK v1.x to v2.0 compatibility.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/v2.rst#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ sagemaker-upgrade-v2 --in-file input.py --out-file output.py\n$ sagemaker-upgrade-v2 --in-file input.ipynb --out-file output.ipynb\n```\n\n----------------------------------------\n\nTITLE: Making Asynchronous Predictions with Direct Data Input in SageMaker\nDESCRIPTION: Makes an asynchronous prediction request by passing payload data directly to the predict_async method. The SDK automatically uploads the data to an S3 bucket and returns an AsyncInferenceResponse object.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_62\n\nLANGUAGE: python\nCODE:\n```\n# Serializes data and makes a prediction request to the SageMaker asynchronous endpoint\nasync_response = async_predictor.predict_async(data=data)\n```\n\n----------------------------------------\n\nTITLE: Implementing Distributed Gradient Tape\nDESCRIPTION: Wraps TensorFlow's GradientTape with the library's DistributedGradientTape for optimized AllReduce operations.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith tf.GradientTape() as tape:\n    output = model(input)\n    loss_value = loss(label, output)\n\ntape = sdp.DistributedGradientTape(tape)\n```\n\n----------------------------------------\n\nTITLE: Using SageMaker HyperPod Recipe for LLaMa 3 Training with PyTorch Estimator\nDESCRIPTION: Example of using a pre-built HyperPod recipe for training LLaMa 3 8B model. It shows how to override recipe parameters for local paths, output directories, and data locations, and how to create a PyTorch estimator with the recipe instead of a custom training script.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\noverrides = {\n    \"run\": {\n        \"results_dir\": \"/opt/ml/model\",\n    },\n    \"exp_manager\": {\n        \"exp_dir\": \"\",\n        \"explicit_log_dir\": \"/opt/ml/output/tensorboard\",\n        \"checkpoint_dir\": \"/opt/ml/checkpoints\",\n    },\n    \"model\": {\n        \"data\": {\n            \"train_dir\": \"/opt/ml/input/data/train\",\n            \"val_dir\": \"/opt/ml/input/data/val\",\n        },\n    },\n}\npytorch_estimator = PyTorch(\n  output_path=output_path,\n  base_job_name=f\"llama-recipe\",\n  role=role,\n  instance_type=\"ml.p5.48xlarge\",\n  training_recipe=\"hf_llama3_8b_seq8k_gpu_p5x16_pretrain\",\n  recipe_overrides=recipe_overrides,\n  sagemaker_session=sagemaker_session,\n  tensorboard_output_config=tensorboard_output_config,\n)\npytorch_estimator.fit({'train': 's3://my-data-bucket/path/to/my/training/data',\n                       'test': 's3://my-data-bucket/path/to/my/test/data'})\n```\n\n----------------------------------------\n\nTITLE: Deploying DJL Serving Model with Basic Configuration in Python\nDESCRIPTION: This snippet shows how to initialize a DJL model with basic configuration and deploy it to an Amazon SageMaker endpoint. The model_id can be either a HuggingFace Hub ID or an S3 URI, and the task is specified as text-generation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/djl/using_djl.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# DJLModel will infer which container to use, and apply some starter configuration\ndjl_model = DJLModel(\n    model_id=\"<hf hub id | s3 uri>\",\n    role=\"my_sagemaker_role\",\n    task=\"text-generation\",\n)\n\n# Deploy the model to an Amazon SageMaker Endpoint and get a Predictor\npredictor = djl_model.deploy(\"ml.g5.12xlarge\",\n                             initial_instance_count=1)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Asynchronous Inference Results in SageMaker\nDESCRIPTION: Retrieves the result of an asynchronous inference request using the AsyncInferenceResponse object. This allows checking the result after the inference has completed.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_63\n\nLANGUAGE: python\nCODE:\n```\n# Switch back to check the result\nresult = async_response.get_result()\n```\n\n----------------------------------------\n\nTITLE: Running Inference on Deployed JumpStart Model in Python\nDESCRIPTION: Shows how to use the deployed JumpStart model predictor to run inference on a sample question.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_46\n\nLANGUAGE: python\nCODE:\n```\nquestion = \"What is Southern California often abbreviated as?\"\nresponse = predictor.predict(question)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Deploying TensorFlow Model with Model Server Workers in SageMaker Python SDK v2.0+\nDESCRIPTION: This snippet demonstrates how to deploy a TensorFlow model and specify the number of model server workers using version 2.0 or later of the SageMaker Python SDK, using an environment variable.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# v2.0 and later\nestimator.deploy(..., env={\"MODEL_SERVER_WORKERS\": 4})\n```\n\n----------------------------------------\n\nTITLE: Creating an MXNet Model for SageMaker Serverless Inference\nDESCRIPTION: Creates an MXNet model object that can be deployed to a SageMaker serverless inference endpoint. This requires specifying the model data location, IAM role, entry point script, and framework version.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_66\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.mxnet import MXNetModel\nfrom sagemaker.serverless import ServerlessInferenceConfig\nimport sagemaker\n\nrole = sagemaker.get_execution_role()\n\n# create MXNet Model Class\nmodel = MXNetModel(\n    model_data=\"s3://my_bucket/pretrained_model/model.tar.gz\", # path to your trained sagemaker model\n    role=role, # iam role with permissions to create an Endpoint\n    entry_point=\"inference.py\",\n    py_version=\"py3\", # Python version\n    framework_version=\"1.6.0\", # MXNet framework version\n)\n```\n\n----------------------------------------\n\nTITLE: Running Inference with Deployed Model\nDESCRIPTION: Example of running inference using a deployed model's predict method.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nquestion = \"What is Southern California often abbreviated as?\"\nresponse = predictor.predict(question)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Parsing Channel Input Arguments in TensorFlow Script for SageMaker\nDESCRIPTION: Example showing how to parse input channel arguments in a TensorFlow training script. This code demonstrates retrieving environment variables for train and evaluation data channels provided by SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nparser = argparse.ArgumentParser()\nparser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\nparser.add_argument('--eval', type=str, default=os.environ.get('SM_CHANNEL_EVAL'))\n```\n\n----------------------------------------\n\nTITLE: Implementing model_fn for PyTorch Model Loading\nDESCRIPTION: Shows a basic implementation of model_fn that loads a PyTorch model from a saved model file. This function is called by the SageMaker PyTorch model server to load the model for inference.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport os\n\ndef model_fn(model_dir, context):\n    model = Your_Model()\n    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n        model.load_state_dict(torch.load(f))\n    return model\n```\n\n----------------------------------------\n\nTITLE: Making Asynchronous Predictions with S3 Input Path in SageMaker\nDESCRIPTION: Makes an asynchronous prediction request to a deployed SageMaker endpoint using data stored in S3. The method returns an AsyncInferenceResponse object that can be used to retrieve the result later.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_61\n\nLANGUAGE: python\nCODE:\n```\n# Upload data to S3 bucket then use that as input\nasync_response = async_predictor.predict_async(input_path=input_s3_path)\n```\n\n----------------------------------------\n\nTITLE: Initializing SKLearnProcessor in SageMaker for Data Processing\nDESCRIPTION: Creates an SKLearnProcessor instance for running scikit-learn scripts on SageMaker. This processor requires a specific framework version, IAM role, and instance specifications to execute scikit-learn based processing jobs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_processing.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.sklearn.processing import SKLearnProcessor\n\nsklearn_processor = SKLearnProcessor(\n    framework_version=\"0.20.0\",\n    role=\"[Your SageMaker-compatible IAM role]\",\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=1,\n)\n```\n\n----------------------------------------\n\nTITLE: Managing Spark History Server for Processing Jobs\nDESCRIPTION: Shows how to start and terminate a Spark History Server to view the Spark UI for processing jobs. The History Server can be configured to use Spark event logs stored in S3, allowing users to monitor and debug Spark applications.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_processing.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nspark_processor.start_history_server()\nspark_processor.terminate_history_server()\n```\n\nLANGUAGE: python\nCODE:\n```\nspark_processor.start_history_server(spark_event_logs_s3_uri=\"s3://your-bucket/your-prefix/store-spark-events\")\n```\n\n----------------------------------------\n\nTITLE: Saving MXNet Model in SageMaker Training Script\nDESCRIPTION: This snippet demonstrates how to use the default save method provided by SageMaker for saving an MXNet model at the end of training. It imports the save function and calls it with the model directory and trained model.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker_mxnet_training.training_utils import save\n\nif __name__ == '__main__':\n    # arg parsing and training (shown above) goes here\n\n    save(args.model_dir, model)\n```\n\n----------------------------------------\n\nTITLE: Using overlap function for efficient backward pass overlapping\nDESCRIPTION: Example of how to use the overlap function to enable efficient overlapping of backward pass with all reduce operation. This is applicable only for models compiled with XLA.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\nlayer = tf.nn.dropout(...) # Or any other layer\nlayer = smdistributed.dataparallel.tensorflow.overlap(layer)\n```\n\n----------------------------------------\n\nTITLE: Deploying JumpStart Pre-trained Model\nDESCRIPTION: Shows how to deploy a pre-trained FLAN-T5 XL model from HuggingFace using the JumpStartModel class.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.jumpstart.model import JumpStartModel\n\nmodel_id = \"huggingface-text2text-flan-t5-xl\"\nmy_model = JumpStartModel(model_id=model_id)\npredictor = my_model.deploy()\n```\n\n----------------------------------------\n\nTITLE: Using AutoMLStep Properties in SageMaker Workflow\nDESCRIPTION: Example showing how to access the best model from an AutoML job and get model insights and explainability reports. This demonstrates creating model metrics from AutoML output properties for model registration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nstep_automl = AutoMLStep(...)\n\nauto_ml_model = step_automl.get_best_model(<role>)\n\nmodel_metrics = ModelMetrics(\n    model_statistics=MetricsSource(\n        s3_uri=auto_ml_step.properties.BestCandidateProperties.ModelInsightsJsonReportPath,\n        content_type=\"application/json\",\n    ),\n    explainability=MetricsSource(\n        s3_uri=auto_ml_step.properties.BestCandidateProperties.ExplainabilityJsonReportPath,\n        content_type=\"application/json\",\n    )\n)\n\nstep_args_register_model = auto_ml_model.register(\ncontent_types=[\"text/csv\"],\nresponse_types=[\"text/csv\"],\ninference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\ntransform_instances=[\"ml.m5.large\"],\nmodel_package_group_name=\"My model package group name\",\napproval_status=\"PendingManualApproval\",\nmodel_metrics=model_metrics,\n)\n\nstep_register_model = ModelStep(\n    name=\"auto-ml-model-register\",\n    step_args=step_args_register_model,\n)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Model Training Resources\nDESCRIPTION: Shows how to retrieve the necessary URIs for model artifacts, training scripts and Docker images.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_49\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import image_uris, model_uris, script_uris\n\nmodel_id, model_version = \"huggingface-spc-bert-base-cased\", \"1.0.0\"\ntraining_instance_type = \"ml.p3.2xlarge\"\ninference_instance_type = \"ml.p3.2xlarge\"\ninstance_count = 1\n\n# Retrieve the JumpStart base model S3 URI\nbase_model_uri = model_uris.retrieve(\n    model_id=model_id, model_version=model_version, model_scope=\"training\"\n)\n\n# Retrieve the training script and Docker image\ntraining_script_uri = script_uris.retrieve(\n    model_id=model_id, model_version=model_version, script_scope=\"training\"\n)\ntraining_image_uri = image_uris.retrieve(\n    region=None,\n    framework=None,\n    image_scope=\"training\",\n    model_id=model_id,\n    model_version=model_version,\n    instance_type=training_instance_type,\n)\n```\n\n----------------------------------------\n\nTITLE: MXNet Estimator Basic Usage Example\nDESCRIPTION: Complete example of training and deploying a model using MXNet Estimator, including configuration, training, deployment, prediction, and cleanup of resources.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.mxnet import MXNet\n\n# Configure an MXNet Estimator (no training happens yet)\nmxnet_estimator = MXNet('train.py',\n                        role='SageMakerRole',\n                        instance_type='ml.p2.xlarge',\n                        instance_count=1,\n                        framework_version='1.2.1')\n\n# Starts a SageMaker training job and waits until completion.\nmxnet_estimator.fit('s3://my_bucket/my_training_data/')\n\n# Deploys the model that was generated by fit() to a SageMaker endpoint\nmxnet_predictor = mxnet_estimator.deploy(initial_instance_count=1, instance_type='ml.p2.xlarge')\n\n# Serializes data and makes a prediction request to the SageMaker endpoint\nresponse = mxnet_predictor.predict(data)\n\n# Tears down the SageMaker endpoint and endpoint configuration\nmxnet_predictor.delete_endpoint()\n\n# Deletes the SageMaker model\nmxnet_predictor.delete_model()\n```\n\n----------------------------------------\n\nTITLE: Pinning GPUs to Distributed Processes in TensorFlow\nDESCRIPTION: Sets up GPU device visibility and memory growth for each node in the distributed training cluster. Each process is pinned to a specific GPU based on its local rank.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    tf.config.experimental.set_visible_devices(gpus[sdp.local_rank()], 'GPU')\n```\n\n----------------------------------------\n\nTITLE: Creating Named Feature Groups with Timestamps\nDESCRIPTION: Demonstrates creating multiple feature groups with timestamp-based naming for uniqueness. This example creates two feature groups ('identity' and 'transaction') for a fraud detection use case.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport time\nfrom time import gmtime, strftime, sleep\nfrom sagemaker.feature_store.feature_group import FeatureGroup\n\nidentity_feature_group_name = 'identity-feature-group-' + strftime('%d-%H-%M-%S', gmtime())\ntransaction_feature_group_name = 'transaction-feature-group-' + strftime('%d-%H-%M-%S', gmtime())\n\nidentity_feature_group = FeatureGroup(name=identity_feature_group_name, sagemaker_session=feature_store_session)\ntransaction_feature_group = FeatureGroup(name=transaction_feature_group_name, sagemaker_session=feature_store_session)\n```\n\n----------------------------------------\n\nTITLE: Accessing Captured Data from S3\nDESCRIPTION: Demonstrates how to use S3Downloader utility to view and download captured model data from S3, including listing S3 URIs and reading specific capture files.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_monitoring.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.s3 import S3Downloader\n\n# Invoke the endpoint\npredictor.predict(data)\n\n# Get a list of S3 URIs\nS3Downloader.list('s3://path/for/data/capture')\n\n# Read a specific file\nS3Downloader.read_file('s3://path/for/data/capture/endpoint-name/variant-name/2020/01/01/00/filename.jsonl')\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Collections with Global Hook Parameters in SageMaker Debugger\nDESCRIPTION: This example shows how to configure multiple tensor collections with shared hook parameters. It demonstrates setting a global save_interval that applies to all collections unless overridden at the collection level.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.debugger import CollectionConfig, DebuggerHookConfig\n\ncollection_config_1 = CollectionConfig(\n    name='collection_name_1',\n    parameters={\n        'include_regex': '.*'\n    }\n)\ncollection_config_2 = CollectionConfig(\n    name='collection_name_2',\n    parameters={\n        'include_regex': '.*'\n    }\n}\n\ndebugger_hook_config = DebuggerHookConfig(\n    s3_output_path='s3://path/for/data/emission',\n    container_local_output_path='/local/path/for/data/emission',\n    hook_parameters={\n        'save_interval': '10'\n    },\n    collection_configs=[\n        collection_config_1, collection_config_2\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Using SparkJarProcessor for Java-based Spark Applications\nDESCRIPTION: Creates and runs a SparkJarProcessor to execute Java-based Spark applications packaged as JAR files. The example demonstrates how to specify the main class and pass arguments to the Spark application.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_processing.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nspark = SparkJarProcessor(\n    base_job_name=\"sm-spark-java\",\n    image_uri=beta_image_uri,\n    role=role,\n    instance_count=2,\n    instance_type=\"ml.c5.xlarge\",\n    max_runtime_in_seconds=1200,\n)\n\nspark.run(\n    submit_app=\"preprocessing.jar\",\n    submit_class=\"com.amazonaws.sagemaker.spark.test.HelloJavaSparkApp\",\n    arguments=[\"--input\", input_s3_uri, \"--output\", output_s3_uri]\n)\n```\n\n----------------------------------------\n\nTITLE: Loading Feature Definitions with Automatic Type Detection\nDESCRIPTION: Demonstrates loading feature definitions by passing a dataframe to the feature group. The SageMaker Python SDK automatically detects the data type of each column in the dataframe.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nidentity_feature_group.load_feature_definitions(data_frame=identity_data); # output is suppressed\ntransaction_feature_group.load_feature_definitions(data_frame=transformed_transaction_data); # output is suppressed\n```\n\n----------------------------------------\n\nTITLE: Wrapping PyTorch Model with SageMaker's DistributedDataParallel\nDESCRIPTION: This snippet demonstrates how to wrap a PyTorch model with SageMaker's DistributedDataParallel for distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel = ...\n# Wrap model with SageMaker's DistributedDataParallel\nmodel = DDP(model)\n```\n\n----------------------------------------\n\nTITLE: Creating XGBoost Estimator in SageMaker\nDESCRIPTION: Example of instantiating an XGBoost estimator in SageMaker with specific configuration parameters including entry point, hyperparameters, instance type and framework version.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/using_xgboost.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.xgboost.estimator import XGBoost\n\nxgb_estimator = XGBoost(\n    entry_point=\"abalone.py\",\n    hyperparameters=hyperparameters,\n    role=role,\n    instance_count=1,\n    instance_type=\"ml.m5.2xlarge\",\n    framework_version=\"1.0-1\",\n)\n```\n\n----------------------------------------\n\nTITLE: Retraining a SageMaker AutoML Candidate with New Data in Python\nDESCRIPTION: This snippet shows how to use the CandidateEstimator class to re-run a specific AutoML candidate's training process with new input data. This allows for reusing the configuration of a successful candidate model.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/automl/README.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ncandidate_estimator = CandidateEstimator(candidate_dict)\ninputs = new_inputs\ncandidate_estimator.fit(inputs=inputs)\n```\n\n----------------------------------------\n\nTITLE: Custom Inference Specification Implementation\nDESCRIPTION: Demonstrates how to create a custom inference specification for model loading and invocation using HuggingFace pipeline.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.serve.spec.inference_spec import InferenceSpec\nfrom transformers import pipeline\n\nclass MyInferenceSpec(InferenceSpec):\n    def load(self, model_dir: str):\n        return pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n\n    def invoke(self, input, model):\n        return model(input)\n\ninf_spec = MyInferenceSpec()\n\nmodel_builder = ModelBuilder(\n    inference_spec=my_inference_spec,\n    schema_builder=SchemaBuilder(X_test, y_pred)\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing DistributedOptimizer in TensorFlow\nDESCRIPTION: Shows how to construct a DistributedOptimizer using an existing TensorFlow optimizer for distributed training with SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nopt = ... # existing optimizer from tf.train package or your custom optimizer\nopt = smdistributed.dataparallel.tensorflow.DistributedOptimizer(opt)\n```\n\n----------------------------------------\n\nTITLE: Creating SageMaker Scikit-learn Estimator\nDESCRIPTION: Example of creating a SageMaker SKLearn estimator with hyperparameters and training data configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nsklearn_estimator = SKLearn('sklearn-train.py',\n                            instance_type='ml.m4.xlarge',\n                            framework_version='1.0-1',\n                            hyperparameters = {'epochs': 20, 'batch-size': 64, 'learning-rate': 0.1})\nsklearn_estimator.fit({'train': 's3://my-data-bucket/path/to/my/training/data',\n                        'test': 's3://my-data-bucket/path/to/my/test/data'})\n```\n\n----------------------------------------\n\nTITLE: Initializing PyTorch Distributed Training with XLA Backend\nDESCRIPTION: This code snippet demonstrates how to initialize distributed training in a PyTorch script using the XLA backend, which is required for training on AWS Trainium instances.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport torch.distributed as dist\n\ndist.init_process_group('xla')\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Estimator with Built-in Vanishing Gradient Rule\nDESCRIPTION: Example of configuring a TensorFlow estimator with a single built-in SageMaker Debugger rule for detecting vanishing gradients.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.debugger import Rule\nfrom smdebug_rulesconfig import vanishing_gradient\n\nestimator = TensorFlow(\n        role=role,\n        instance_count=1,\n        instance_type=instance_type,\n        rules=[Rule.sagemaker(vanishing_gradient())]\n)\n```\n\n----------------------------------------\n\nTITLE: Saving Checkpoints in Distributed Training\nDESCRIPTION: Ensures checkpoints are only saved from the leader node (rank 0) to prevent corruption or conflicts from multiple nodes saving checkpoints simultaneously.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nif sdp.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Scaling Learning Rate for Distributed Training in TensorFlow\nDESCRIPTION: Scale the learning rate by the number of workers in the cluster using the SageMaker distributed data parallel library's size() API.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlearning_rate = learning_rate * sdp.size()\n```\n\n----------------------------------------\n\nTITLE: Configuring Caching for SageMaker Pipeline Steps\nDESCRIPTION: This example shows how to enable caching for pipeline steps to avoid rerunning unchanged steps. It sets up a CacheConfig with a 30-day expiration period using ISO8601 duration format.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ncache_config = CacheConfig(\n    enable_caching=True,\n    expire_after=\"P30d\" # 30-day\n)\n```\n\n----------------------------------------\n\nTITLE: Loading and Validating Custom SageMaker Configuration in Python\nDESCRIPTION: This snippet demonstrates how to load SageMaker configuration from custom file paths, validate the configuration against the schema, and initialize a SageMaker Session with the custom configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_96\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.session import Session\nfrom sagemaker.config import load_sagemaker_config, validate_sagemaker_config\n\n# Create a configuration dictionary manually\ncustom_sagemaker_config = load_sagemaker_config(\n     additional_config_paths=[\n        'path1',\n        'path2',\n        'path3'\n    ]\n)\n\n# Then validate that the dictionary adheres to the configuration schema\nvalidate_sagemaker_config(custom_sagemaker_config)\n\n# Then initialize the Session object with the configuration dictionary\nsm_session = Session(\n    sagemaker_config = custom_sagemaker_config\n)\n```\n\n----------------------------------------\n\nTITLE: Deploying PyTorch Model with Elastic Inference\nDESCRIPTION: This example demonstrates how to deploy a trained PyTorch model with Elastic Inference for cost-effective inference acceleration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\npredictor = pytorch_estimator.deploy(instance_type='ml.m4.xlarge',\n                                   initial_instance_count=1,\n                                   accelerator_type='ml.eia2.medium')\n```\n\n----------------------------------------\n\nTITLE: ModelTrainer Implementation for SageMaker Training Jobs\nDESCRIPTION: Example showing how to use the ModelTrainer class to launch a SageMaker training job with custom scripts. Demonstrates configuration of training image, source code, and input data.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.modules.train import ModelTrainer\nfrom sagemaker.modules.configs import SourceCode, InputData\n\n# Image URI for the training job\npytorch_image = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.0.0-cpu-py310\"\n\n# Define the script to be run\nsource_code = SourceCode(\n    source_dir=\"basic-script-mode\",\n    requirements=\"requirements.txt\",\n    entry_script=\"custom_script.py\",\n)\n\n# Define the ModelTrainer\nmodel_trainer = ModelTrainer(\n    training_image=pytorch_image,\n    source_code=source_code,\n    base_job_name=\"script-mode\",\n)\n\n# Pass the input data\ninput_data = InputData(\n    channel_name=\"train\",\n    data_source=training_input_path, # S3 path where training data is stored\n)\n\n# Start the training job\nmodel_trainer.train(input_data_config=[input_data], wait=False)\n```\n\n----------------------------------------\n\nTITLE: Creating and Deploying SparkML Model in SageMaker Python\nDESCRIPTION: This snippet shows how to create a SparkMLModel instance and deploy it to create an endpoint for prediction. It specifies the model data location, environment variables, and deployment parameters such as instance count and type.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nsparkml_model = SparkMLModel(model_data='s3://path/to/model.tar.gz', env={'SAGEMAKER_SPARKML_SCHEMA': schema})\nmodel_name = 'sparkml-model'\nendpoint_name = 'sparkml-endpoint'\npredictor = sparkml_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)\n```\n\n----------------------------------------\n\nTITLE: Distributed Sampler Configuration\nDESCRIPTION: Sets up the DistributedSampler with cluster information including world size and rank for distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrain_sampler = DistributedSampler(train_dataset, num_replicas=dist.get_world_size(), rank=dist.get_rank())\n```\n\n----------------------------------------\n\nTITLE: Initializing Scikit-learn Training Script Arguments\nDESCRIPTION: Example of setting up argument parsing in a Scikit-learn training script, including hyperparameters and data directory paths using SageMaker environment variables.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport os\n\nif __name__ =='__main__':\n\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument('--epochs', type=int, default=50)\n    parser.add_argument('--batch-size', type=int, default=64)\n    parser.add_argument('--learning-rate', type=float, default=0.05)\n\n    # Data, model, and output directories\n    parser.add_argument('--output-data-dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n\n    args, _ = parser.parse_known_args()\n```\n\n----------------------------------------\n\nTITLE: Using ModelTrainer with HyperPod Recipe for LLaMa 3 Training\nDESCRIPTION: Alternative approach for training LLaMa 3 using the ModelTrainer API. This example shows how to configure recipe overrides, create a ModelTrainer from a recipe, set up TensorBoard monitoring, and specify input data channels for training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nrecipe_overrides = {\n    \"run\": {\n        \"results_dir\": \"/opt/ml/model\",\n    },\n    \"exp_manager\": {\n        \"exp_dir\": \"\",\n        \"explicit_log_dir\": \"/opt/ml/output/tensorboard\",\n        \"checkpoint_dir\": \"/opt/ml/checkpoints\",\n    },\n    \"model\": {\n        \"data\": {\n            \"train_dir\": \"/opt/ml/input/data/train\",\n            \"val_dir\": \"/opt/ml/input/data/val\",\n        },\n    },\n}\n\nmodel_trainer = ModelTrainer.from_recipe(\n    output_path=output_path,\n    base_job_name=f\"llama-recipe\",\n    training_recipe=\"training/llama/hf_llama3_8b_seq8k_gpu_p5x16_pretrain\",\n    recipe_overrides=recipe_overrides,\n    compute=Compute(instance_type=\"ml.p5.48xlarge\"),\n    sagemaker_session=sagemaker_session\n).with_tensorboard_output_config(\n    tensorboard_output_config=tensorboard_output_config\n)\n\ntrain_input = Input(\n    channel_name=\"train\",\n    data_source=\"s3://my-data-bucket/path/to/my/training/data\"\n)\n\ntest_input = Input(\n    channel_name=\"test\",\n    data_source=\"s3://my-data-bucket/path/to/my/test/data\"\n)\n\nmodel_trainer.train(input_data_config=[train_input, test_input)\n```\n\n----------------------------------------\n\nTITLE: Executing Batch Transform Job in SageMaker\nDESCRIPTION: Initiates a batch transform job using a Transformer object, specifying the S3 location of the input data.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_75\n\nLANGUAGE: python\nCODE:\n```\ntransformer.transform('s3://my-bucket/batch-transform-input')\n```\n\n----------------------------------------\n\nTITLE: Training and Deploying RL Model with RLEstimator in Python\nDESCRIPTION: This code demonstrates the full process of creating an RLEstimator, training the model, and deploying it to a SageMaker endpoint. It includes creating the estimator, fitting the model, deploying it, and making a prediction.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/rl/using_rl.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Train my estimator\nrl_estimator = RLEstimator(entry_point='coach-train.py',\n                               toolkit=RLToolkit.COACH,\n                               toolkit_version='0.11.0',\n                               framework=RLFramework.MXNET,\n                               role='SageMakerRole',\n                               instance_type='ml.c4.2xlarge',\n                               instance_count=1)\n\nrl_estimator.fit()\n\n# Deploy my estimator to a SageMaker Endpoint and get a MXNetPredictor\npredictor = rl_estimator.deploy(instance_type='ml.m4.xlarge',\n                                    initial_instance_count=1)\n\nresponse = predictor.predict(data)\n```\n\n----------------------------------------\n\nTITLE: Creating EMR Step in SageMaker Pipeline\nDESCRIPTION: Shows how to create and configure an EMR step in a SageMaker pipeline. The example includes setting up the EMR step configuration with JAR location, arguments, main class, and Java properties, as well as defining the EMR step with cluster information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.workflow.emr_step import EMRStep, EMRStepConfig\n\nemr_config = EMRStepConfig(\n    jar=\"jar-location\", # required, path to jar file used\n    args=[\"--verbose\", \"--force\"], # optional list of arguments to pass to the jar\n    main_class=\"com.my.Main1\", # optional main class, this can be omitted if jar above has a manifest\n    properties=[ # optional list of Java properties that are set when the step runs\n    {\n        \"key\": \"mapred.tasktracker.map.tasks.maximum\",\n        \"value\": \"2\"\n    },\n    {\n        \"key\": \"mapreduce.map.sort.spill.percent\",\n        \"value\": \"0.90\"\n   },\n   {\n       \"key\": \"mapreduce.tasktracker.reduce.tasks.maximum\",\n       \"value\": \"5\"\n    }\n  ]\n)\n\nstep_emr = EMRStep(\n    name=\"EMRSampleStep\", # required\n    cluster_id=\"j-1ABCDEFG2HIJK\", # include cluster_id to use a running cluster\n    step_config=emr_config, # required\n    display_name=\"My EMR Step\",\n    description=\"Pipeline step to execute EMR job\"\n)\n```\n\n----------------------------------------\n\nTITLE: Using Overlap Function in TensorFlow with XLA\nDESCRIPTION: Demonstrates how to use the overlap function to enable efficient overlapping of backward pass with all reduce operation in models compiled with XLA.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nlayer = tf.nn.dropout(...) # Or any other layer\nlayer = smdistributed.dataparallel.tensorflow.overlap(layer)\n```\n\n----------------------------------------\n\nTITLE: Training and Deploying Scikit-learn Model\nDESCRIPTION: Example showing how to initialize a Scikit-learn estimator for training and deployment.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Train my estimator\nsklearn_estimator = SKLearn(entry_point='train_and_deploy.py',\n                            instance_type='ml.m4.xlarge',\n                            framework_version='1.0-1')\n```\n\n----------------------------------------\n\nTITLE: Setting Up MonitorBatchTransform Step in SageMaker Pipeline\nDESCRIPTION: Demonstrates configuring a MonitorBatchTransformStep to monitor batch transform jobs in a SageMaker pipeline. The example shows importing necessary components and beginning the configuration of a data quality monitor for a batch transform job.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.workflow.pipeline_context import PipelineSession\n\nfrom sagemaker.transformer import Transformer\nfrom sagemaker.model_monitor import DefaultModelMonitor\nfrom sagemaker.model_monitor.dataset_format import DatasetFormat\nfrom sagemaker.workflow.check_job_config import CheckJobConfig\nfrom sagemaker.workflow.quality_check_step import DataQualityCheckConfig\n\nfrom sagemaker.workflow.parameters import ParameterString\n\npipeline_session = PipelineSession()\n\ntransform_input_param = ParameterString(\n    name=\"transform_input\",\n```\n\n----------------------------------------\n\nTITLE: Creating a TransformStep in SageMaker Pipelines for Batch Inference\nDESCRIPTION: This code demonstrates how to create a transform step for batch inference in a SageMaker pipeline. It shows uploading batch data to S3, configuring a Transformer with a model from a previous step, and creating the transform step with the appropriate input data configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.transformer import Transformer\nfrom sagemaker.inputs import TransformInput\nfrom sagemaker.workflow.steps import TransformStep\n\nbase_uri = f\"s3://{default_bucket}/abalone\"\nbatch_data_uri = sagemaker.s3.S3Uploader.upload(\n    local_path=local_path,\n    desired_s3_uri=base_uri,\n)\n\nbatch_data = ParameterString(\n    name=\"BatchData\",\n    default_value=batch_data_uri,\n)\n\ntransformer = Transformer(\n    model_name=step_create_model.properties.ModelName,\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=1,\n    output_path=f\"s3://{default_bucket}/AbaloneTransform\",\n    env={\n        'class': 'Transformer'\n    }\n)\n\nstep_transform = TransformStep(\n    name=\"AbaloneTransform\",\n    step_args=transformer.transform(\n        data=batch_data,\n        data_type=\"S3Prefix\"\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Creating an RLEstimator for RL Training in Python\nDESCRIPTION: This snippet demonstrates how to create an RLEstimator object with specific parameters for RL training using the SageMaker Python SDK. It sets up the estimator with a training script, RL toolkit, framework, and instance specifications.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/rl/using_rl.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n\nrl_estimator = RLEstimator(entry_point='coach-train.py',\n                               toolkit=RLToolkit.COACH,\n                               toolkit_version='0.11.1',\n                               framework=RLFramework.TENSORFLOW,\n                               role='SageMakerRole',\n                               instance_type='ml.p3.2xlarge',\n                               instance_count=1)\n```\n\n----------------------------------------\n\nTITLE: Using Git Repository with SageMaker Estimator (Username and Password)\nDESCRIPTION: Shows how to create an estimator using a GitHub repository with username and password authentication. This example also demonstrates adding dependencies from the same Git repository.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Only providing 'repo' is also allowed. If this is the case, latest commit in 'master' branch will be used.\n# This example does not provide '2FA_enabled', so 2FA is treated as disabled by default. 'username' and\n# 'password' are provided for authentication\ngit_config = {'repo': 'https://github.com/username/repo-with-training-scripts.git',\n              'username': 'username',\n              'password': 'passw0rd!'}\n\n# In this example, besides entry point and other source code in source directory, we still need some\n# dependencies for the training job. Dependencies should also be paths inside the Git repo.\npytorch_estimator = PyTorch(entry_point='mnist.py',\n                            role='SageMakerRole',\n                            source_dir='pytorch',\n                            dependencies=['dep.py', 'foo/bar.py'],\n                            git_config=git_config,\n                            instance_count=1,\n                            instance_type='ml.c4.xlarge')\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Built-in Debugger Rules\nDESCRIPTION: Demonstrates how to configure multiple built-in rules (vanishing gradient and weight update ratio) for a TensorFlow estimator.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.debugger import Rule\nfrom smdebug_rulesconfig import vanishing_gradient, weight_update_ratio\n\nestimator = TensorFlow(\n        role=role,\n        instance_count=1,\n        instance_type=instance_type,\n        rules=[Rule.sagemaker(vanishing_gradient()), Rule.sagemaker(weight_update_ratio())]\n)\n```\n\n----------------------------------------\n\nTITLE: Using DistributedGradientTape in TensorFlow 2.x\nDESCRIPTION: Example of how to use DistributedGradientTape to wrap TensorFlow's GradientTape for distributed training. This is applicable to TensorFlow 2.x only.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nwith tf.GradientTape() as tape:\n      output = model(input)\n      loss_value = loss(label, output)\n\n# Wrap in smdistributed.dataparallel's DistributedGradientTape\ntape = smdistributed.dataparallel.tensorflow.DistributedGradientTape(tape)\n```\n\n----------------------------------------\n\nTITLE: Pinning GPUs and Setting Memory Growth for TensorFlow Distributed Training\nDESCRIPTION: Pin each GPU to a single smdistributed.dataparallel process using local_rank. This code also sets memory growth for each GPU, which is necessary for distributed training with TensorFlow.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    tf.config.experimental.set_visible_devices(gpus[sdp.local_rank()], 'GPU')\n```\n\n----------------------------------------\n\nTITLE: Initializing SageMaker Data Parallel Library for TensorFlow\nDESCRIPTION: Imports the SageMaker distributed data parallel library for TensorFlow and initializes it for distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport smdistributed.dataparallel.tensorflow as sdp\nsdp.init()\n```\n\n----------------------------------------\n\nTITLE: Running a Batch Transform Job in SageMaker with Python\nDESCRIPTION: This snippet shows how to start a batch transform job using a Transformer object in SageMaker. It specifies the input data location, format, and content type.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nbatch_input = 's3://{}/{}/test/examples'.format(bucket, prefix) # The location of the input dataset\n\ntf_transformer.transform(data=batch_input, data_type='S3Prefix', content_type='text/csv', split_type='Line')\n```\n\n----------------------------------------\n\nTITLE: Performing Local Batch Transform in SageMaker\nDESCRIPTION: Demonstrates how to perform a local batch transform job using a trained MXNet estimator, including model cleanup.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_80\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.mxnet import MXNet\n\nmxnet_estimator = MXNet('train.py',\n                        role='SageMakerRole',\n                        instance_type='local',\n                        instance_count=1,\n                        framework_version='1.2.1')\n\nmxnet_estimator.fit('file:///tmp/my_training_data')\ntransformer = mxnet_estimator.transformer(1, 'local', assemble_with='Line', max_payload=1)\ntransformer.transform('s3://my/transform/data', content_type='text/csv', split_type='Line')\ntransformer.wait()\n\n# Deletes the SageMaker model\ntransformer.delete_model()\n```\n\n----------------------------------------\n\nTITLE: Deserializing Input for PyTorch Model in SageMaker\nDESCRIPTION: This snippet shows how to deserialize input data for a PyTorch model in SageMaker. It handles 'application/python-pickle' content type by loading the request body using torch.load.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nif request_content_type == 'application/python-pickle':\n    return torch.load(BytesIO(request_body))\nelse:\n    # Handle other content-types here or raise an Exception\n    # if the content type is not supported.\n    pass\n```\n\n----------------------------------------\n\nTITLE: Creating a TensorFlow Model with Custom Inference Script\nDESCRIPTION: Example showing how to specify a custom inference script (inference.py) when creating a TensorFlowModel for customized input and output processing.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = TensorFlowModel(entry_point='inference.py',\n                        model_data='s3://mybucket/model.tar.gz',\n                        role='MySageMakerRole',\n                        framework_version='x.x.x')\n```\n\n----------------------------------------\n\nTITLE: Wrapping PyTorch Model with SageMaker's DistributedDataParallel\nDESCRIPTION: Wraps a PyTorch model with SageMaker's DistributedDataParallel (DDP) to enable distributed training across multiple GPUs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel = ...\n# Wrap model with SageMaker's DistributedDataParallel\nmodel = DDP(model)\n```\n\n----------------------------------------\n\nTITLE: Configuring MXNet Training with VPC in SageMaker\nDESCRIPTION: This snippet demonstrates how to configure a SageMaker MXNet estimator with VPC settings by specifying subnets and security groups, which enables the training job to run within your VPC.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_82\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.mxnet import MXNet\n\n# Configure an MXNet Estimator with subnets and security groups from your VPC\nmxnet_vpc_estimator = MXNet('train.py',\n                            instance_type='ml.p2.xlarge',\n                            instance_count=1,\n                            framework_version='1.2.1',\n                            subnets=['subnet-1', 'subnet-2'],\n                            security_group_ids=['sg-1'])\n\n# SageMaker Training Job will set VpcConfig and container instances will run in your VPC\nmxnet_vpc_estimator.fit('s3://my_bucket/my_training_data/')\n```\n\n----------------------------------------\n\nTITLE: Initializing SageMaker Transformer in Python\nDESCRIPTION: Creates a Transformer object from a previously trained SageMaker model, specifying the model name, instance count, and instance type.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_74\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.transformer import Transformer\n\ntransformer = Transformer(model_name='my-previously-trained-model',\n                              instance_count=1,\n                              instance_type='ml.m4.xlarge')\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with a SageMaker Serverless Endpoint\nDESCRIPTION: Makes a prediction request to a deployed SageMaker serverless endpoint. This works the same way as with real-time endpoints, serializing the data and returning the response.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_71\n\nLANGUAGE: python\nCODE:\n```\n# Serializes data and makes a prediction request to the SageMaker serverless endpoint\nresponse = serverless_predictor.predict(data)\n```\n\n----------------------------------------\n\nTITLE: Complete TensorFlow 2.x Training Script for Distributed Training\nDESCRIPTION: A full example of a TensorFlow 2.x training script modified for distributed training with the SageMaker data parallel library. It includes all the necessary modifications covered in the previous snippets.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\n# Import the library's TF API\nimport smdistributed.dataparallel.tensorflow as sdp\n\n# Initialize the library\nsdp.init()\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    # Pin GPUs to a single process\n    tf.config.experimental.set_visible_devices(gpus[sdp.local_rank()], 'GPU')\n\n# Prepare Dataset\ndataset = tf.data.Dataset.from_tensor_slices(...)\n\n# Define Model\nmnist_model = tf.keras.Sequential(...)\nloss = tf.losses.SparseCategoricalCrossentropy()\n\n# Scale Learning Rate\n# LR for 8 node run : 0.000125\n# LR for single node run : 0.001\nopt = tf.optimizers.Adam(0.000125 * sdp.size())\n\n@tf.function\ndef training_step(images, labels, first_batch):\n    with tf.GradientTape() as tape:\n        probs = mnist_model(images, training=True)\n        loss_value = loss(labels, probs)\n\n    # Wrap tf.GradientTape with the library's DistributedGradientTape\n    tape = sdp.DistributedGradientTape(tape)\n\n    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n    opt.apply_gradients(zip(grads, mnist_model.trainable_variables))\n\n    if first_batch:\n       # Broadcast model and optimizer variables\n       sdp.broadcast_variables(mnist_model.variables, root_rank=0)\n       sdp.broadcast_variables(opt.variables(), root_rank=0)\n\n    return loss_value\n\n...\n\n# Save checkpoints only from master node.\nif sdp.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Using TrainingStep Properties in SageMaker Workflow\nDESCRIPTION: Example showing how to reference properties from a TrainingStep to create a Model and conditional execution based on metrics. This demonstrates accessing the model artifacts S3 path and final metric data for validation accuracy.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nstep_train = TrainingStep(...)\nmodel = Model(\n    image_uri=\"my-dummy-image\",\n    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n    ...\n)\n# assume your training job will produce a metric called \"val:acc\"\n# and you would like to use it to demtermine if you want to create\n# a SageMaker Model for it.\nstep_condition = ConditionStep(\n    conditions = [\n        ConditionGreaterThanOrEqualTo(\n            left=step_train.properties.FinalMetricDataList['val:acc'].Value\n            right=0.95\n    )],\n    if_steps = [step_model_create],\n)\n```\n\n----------------------------------------\n\nTITLE: Making Prediction Requests to TensorFlow Serving Endpoint in Python\nDESCRIPTION: This snippet demonstrates how to make prediction requests to a deployed TensorFlow Serving endpoint on SageMaker. It shows the input format and how to handle the response.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ninput = {\n  'instances': [1.0, 2.0, 5.0]\n}\nresult = predictor.predict(input)\n\n# The result object will contain a Python dict like this:\n# {\n#   'predictions': [3.5, 4.0, 5.5]\n# }\n```\n\n----------------------------------------\n\nTITLE: Implementing BroadcastGlobalVariablesHook in TensorFlow\nDESCRIPTION: Example showing how to use BroadcastGlobalVariablesHook with MonitoredTrainingSession to ensure consistent initialization across workers in distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nhooks = [smdistributed.dataparallel.tensorflow.BroadcastGlobalVariablesHook(root_rank=0)]\n...\nwith tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,\n                                         hooks=hooks,\n                                         config=config) as mon_sess:\n       ...\n```\n\n----------------------------------------\n\nTITLE: Scaling Learning Rate for Distributed Training\nDESCRIPTION: Adjusts the learning rate based on the number of workers in the distributed training cluster.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlearning_rate = learning_rate * sdp.size()\n```\n\n----------------------------------------\n\nTITLE: Setting Up TensorFlow Estimator for Distributed Training\nDESCRIPTION: Creates a TensorFlow estimator configured for distributed training using Horovod. Specifies entry point, instance type, count, and other parameters for the training job.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/dummy_input.txt#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nestimator = TensorFlow(\n    entry_point=\"horovod_mnist.py\",\n    role=\"SageMakerRole\",\n    instance_type=\"ml.c5.xlarge\",\n    instance_count=2,\n    py_version=PYTHON_VERSION,\n    script_mode=True,\n    framework_version=\"2.3.1\",\n    distributions={\"mpi\": {\"enabled\": True}},\n    sagemaker_session=sagemaker_session,\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Transformer for Batch Transform in SageMaker with Python\nDESCRIPTION: This code demonstrates how to create a Transformer object from a trained estimator for running batch transform jobs in SageMaker. It specifies instance type, count, and output location.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nbucket = myBucket # The name of the S3 bucket where the results are stored\nprefix = 'batch-results' # The folder in the S3 bucket where the results are stored\n\nbatch_output = 's3://{}/{}/results'.format(bucket, prefix) # The location to store the results\n\ntf_transformer = tf_estimator.transformer(instance_count=1, instance_type='ml.m4.xlarge', output_path=batch_output)\n```\n\n----------------------------------------\n\nTITLE: Configuring Step Retry Policy in SageMaker Pipeline\nDESCRIPTION: Demonstrates how to configure retry policies for SageMaker pipeline steps. The example includes configuring StepRetryPolicy for service faults and throttling, and SageMakerJobStepRetryPolicy for job failures with exponential backoff strategies.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nStepRetryPolicy(\n    exception_types=[\n        StepExceptionTypeEnum.SERVICE_FAULT,\n        StepExceptionTypeEnum.THROTTLING,\n    ],\n    expire_after_min=5,\n    interval_seconds=10,\n    backoff_rate=2.0\n)\n```\n\nLANGUAGE: python\nCODE:\n```\nSageMakerJobStepRetryPolicy(\n    exception_types=[SageMakerJobExceptionTypeEnum.RESOURCE_LIMIT]\n    expire_after_min=120,\n    interval_seconds=60,\n    backoff_rate=2.0\n)\n```\n\n----------------------------------------\n\nTITLE: Using SageMaker MXNet Estimator in Local Mode\nDESCRIPTION: Demonstrates how to configure and use an MXNet Estimator in local mode, including training, deployment, prediction, and cleanup.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_78\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.mxnet import MXNet\n\n# Configure an MXNet Estimator (no training happens yet)\nmxnet_estimator = MXNet('train.py',\n                        role='SageMakerRole',\n                        instance_type='local',\n                        instance_count=1,\n                        framework_version='1.2.1')\n\n# In Local Mode, fit will pull the MXNet container Docker image and run it locally\nmxnet_estimator.fit('s3://my_bucket/my_training_data/')\n\n# Alternatively, you can train using data in your local file system. This is only supported in Local mode.\nmxnet_estimator.fit('file:///tmp/my_training_data')\n\n# Deploys the model that was generated by fit() to local endpoint in a container\nmxnet_predictor = mxnet_estimator.deploy(initial_instance_count=1, instance_type='local')\n\n# Serializes data and makes a prediction request to the local endpoint\nresponse = mxnet_predictor.predict(data)\n\n# Tears down the endpoint container and deletes the corresponding endpoint configuration\nmxnet_predictor.delete_endpoint()\n\n# Deletes the model\nmxnet_predictor.delete_model()\n```\n\n----------------------------------------\n\nTITLE: Defining ReduceOp Enum for PyTorch Distributed Operations\nDESCRIPTION: Defines an enum-like class ReduceOp that specifies supported reduction operations for distributed training in PyTorch. It includes operations like AVERAGE, SUM, MIN, and MAX, which can be used in reduction collectives such as all_reduce().\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nclass smdistributed.dataparallel.torch.distributed.ReduceOp:\n    AVERAGE\n    SUM\n    MIN\n    MAX\n```\n\n----------------------------------------\n\nTITLE: SageMaker Hyperparameter Tuning Configuration for Airflow\nDESCRIPTION: Configuration function for hyperparameter tuning jobs in SageMaker through Airflow\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/sagemaker.workflow.airflow.rst#2025-04-22_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. autofunction:: sagemaker.workflow.airflow.tuning_config\n```\n\n----------------------------------------\n\nTITLE: Creating a SageMaker Batch Transform Job\nDESCRIPTION: Creates a transformer object from an estimator to perform batch inference with a trained model. This specifies the compute resources required for the batch transform job.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_73\n\nLANGUAGE: python\nCODE:\n```\ntransformer = estimator.transformer(instance_count=1, instance_type='ml.m4.xlarge')\n```\n\n----------------------------------------\n\nTITLE: Using DistributedGradientTape for Optimized AllReduce in TensorFlow\nDESCRIPTION: Wrap tf.GradientTape with the library's DistributedGradientTape to optimize AllReduce operations during training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith tf.GradientTape() as tape:\n      output = model(input)\n      loss_value = loss(label, output)\n\n# Wrap tf.GradientTape with the library's DistributedGradientTape\ntape = sdp.DistributedGradientTape(tape)\n```\n\n----------------------------------------\n\nTITLE: Checking Model Input/Output Formats\nDESCRIPTION: Code to check valid data input and output formats for inference using Serializers and Deserializers classes.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nprint(sagemaker.serializers.retrieve_options(model_id=model_id, model_version=model_version))\nprint(sagemaker.deserializers.retrieve_options(model_id=model_id, model_version=model_version))\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with TensorFlow Serving Endpoint\nDESCRIPTION: Examples of different prediction request formats including basic predictions, classify/regress requests, and batch predictions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ninput = {\n  'instances': [1.0, 2.0, 5.0]\n}\nresult = predictor.predict(input)\n```\n\nLANGUAGE: python\nCODE:\n```\ninput = {\n  'signature_name': 'tensorflow/serving/regress',\n  'examples': [{'x': 1.0}, {'x': 2.0}]\n}\n\nresult = predictor.regress(input)  # or predictor.classify(...)\n```\n\nLANGUAGE: python\nCODE:\n```\ninput = {\n  'instances': [\n    [1.0, 2.0, 5.0],\n    [1.0, 2.0, 5.0],\n    [1.0, 2.0, 5.0]\n  ]\n}\nresult = predictor.predict(input)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using ProcessingStep in SageMaker Workflow\nDESCRIPTION: Example of creating a processing step with SKLearnProcessor and referencing its output properties in a subsequent training step. This shows how to access the S3 URI for processing output data.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nsklearn_processor = SKLearnProcessor(\n    framework_version=\"0.23-1\",\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=1,\n    base_job_name=\"sklearn-abalone-preprocess\",\n    sagemaker_session=PipelineSession(),\n    role=sagemaker.get_execution_role(),\n)\n\nstep_process = ProcessingStep(\n    name=\"MyProcessingStep\",\n    ...,\n    step_args = sklearn_processor.run(\n        ...,\n        outputs=[\n            ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n        ],\n        code=\"./local/preprocess.py\",\n        arguments=[\"--input-data\", \"s3://my-input\"]\n    ),\n)\n\nstep_args = estimator.fit(inputs=TrainingInput(\n    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n))\n```\n\n----------------------------------------\n\nTITLE: Using DistributedGradientTape for Optimized AllReduce in TensorFlow\nDESCRIPTION: Wrap tf.GradientTape with the SageMaker distributed data parallel library's DistributedGradientTape to optimize AllReduce operations during training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith tf.GradientTape() as tape:\n    output = model(input)\n    loss_value = loss(label, output)\n\n# Wrap tf.GradientTape with the library's DistributedGradientTape\ntape = sdp.DistributedGradientTape(tape)\n```\n\n----------------------------------------\n\nTITLE: Scaling Learning Rate for Distributed Training in TensorFlow\nDESCRIPTION: Scale the learning rate by the number of workers using sdp.size(). This ensures that the effective learning rate remains consistent across different cluster sizes.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlearning_rate = learning_rate * sdp.size()\n```\n\n----------------------------------------\n\nTITLE: SageMaker Transform Configuration from Estimator for Airflow\nDESCRIPTION: Configuration function to create transform configuration from an estimator in SageMaker through Airflow\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/sagemaker.workflow.airflow.rst#2025-04-22_snippet_5\n\nLANGUAGE: rst\nCODE:\n```\n.. autofunction:: sagemaker.workflow.airflow.transform_config_from_estimator\n```\n\n----------------------------------------\n\nTITLE: Creating Model Monitoring Schedule\nDESCRIPTION: Sets up a monitoring schedule that compares baseline resources against realtime traffic at specified intervals using DefaultMonitor.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_monitoring.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.model_monitor import CronExpressionGenerator\n\nmy_monitor.create_monitoring_schedule(\n    monitor_schedule_name='my-monitoring-schedule',\n    endpoint_input=predictor.endpoint_name,\n    statistics=my_monitor.baseline_statistics(),\n    constraints=my_monitor.suggested_constraints(),\n    schedule_cron_expression=CronExpressionGenerator.hourly(),\n)\n```\n\n----------------------------------------\n\nTITLE: Creating MXNet Model (Python)\nDESCRIPTION: Example of creating an MXNet model with the new required parameters framework_version and py_version in SageMaker Python SDK v2.x.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/v2.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.mxnet import MXNetModel\n\nMXNetModel(\n    model_data=\"s3://bucket/model.tar.gz\",\n    role=\"my-role\",\n    entry_point=\"inference.py\",\n    framework_version=\"1.6.0\",  # now required\n    py_version=\"py3\",  # now required\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring AsyncInferenceConfig with Custom Parameters in Python\nDESCRIPTION: Creates an AsyncInferenceConfig object with custom parameters including output path, maximum concurrent invocations, and notification configuration. This allows for fine-grained control of the asynchronous inference endpoint behavior.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_59\n\nLANGUAGE: python\nCODE:\n```\n# Specify S3OutputPath, S3FailurePath, MaxConcurrentInvocationsPerInstance and NotificationConfig\n# in the async config object\nasync_config = AsyncInferenceConfig(\n    output_path=\"s3://{s3_bucket}/{bucket_prefix}/output\",\n    max_concurrent_invocations_per_instance=10,\n    notification_config = {\n        \"SuccessTopic\": \"arn:aws:sns:aws-region:account-id:topic-name\",\n        \"ErrorTopic\": \"arn:aws:sns:aws-region:account-id:topic-name\",\n        \"IncludeInferenceResponseIn\": [\"SUCCESS_NOTIFICATION_TOPIC\",\"ERROR_NOTIFICATION_TOPIC\"],\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Saving Checkpoints on Leader Node in Distributed TensorFlow Training\nDESCRIPTION: Modify the script to save checkpoints only on the leader node to avoid worker nodes overwriting or corrupting checkpoints.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nif sdp.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: SageMaker Model Configuration for Airflow\nDESCRIPTION: Configuration function for model creation in SageMaker through Airflow\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/sagemaker.workflow.airflow.rst#2025-04-22_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. autofunction:: sagemaker.workflow.airflow.model_config\n```\n\n----------------------------------------\n\nTITLE: Creating a Predictor for an Existing SageMaker Endpoint\nDESCRIPTION: Shows how to create a TensorFlow-specific Predictor object for an existing SageMaker endpoint and make predictions with it.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_106\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowPredictor\n\npredictor = TensorFlowPredictor('myexistingendpoint')\nresult = predictor.predict(['my request body'])\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Estimator (Python)\nDESCRIPTION: Example of creating a TensorFlow estimator with the new required parameters framework_version and py_version in SageMaker Python SDK v2.x.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/v2.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\nTensorFlow(\n    entry_point=\"script.py\",\n    framework_version=\"2.2.0\",  # now required\n    py_version=\"py37\",  # now required\n    role=\"my-role\",\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=1,\n)\n```\n\n----------------------------------------\n\nTITLE: Working with ModelStep Properties in SageMaker Workflow\nDESCRIPTION: Examples showing how to reference properties for both model creation and model registration use cases. This demonstrates accessing the model data URL and approval status.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ncreate_model_step = ModelStep(\n    name=\"MyModelCreationStep\",\n    step_args = model.create(...)\n)\nmodel_data = create_model_step.properties.PrimaryContainer.ModelDataUrl\n```\n\nLANGUAGE: python\nCODE:\n```\nregister_model_step = ModelStep(\n    name=\"MyModelRegistrationStep\",\n    step_args=model.register(...)\n)\napproval_status=register_model_step.properties.ModelApprovalStatus\n```\n\n----------------------------------------\n\nTITLE: Triton Model Server Deployment\nDESCRIPTION: Shows how to configure and deploy a PyTorch model using Triton inference server on SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_39\n\nLANGUAGE: python\nCODE:\n```\nmodel_builder = ModelBuilder(\n    model=model,\n    schema_builder=SchemaBuilder(sample_input=sample_input, sample_output=sample_output),\n    role_arn=execution_role,\n    model_server=ModelServer.TRITON,\n    mode=Mode.SAGEMAKER_ENDPOINT\n)\n\ntriton_builder = model_builder.build()\n\npredictor = triton_builder.deploy(\n    instance_type='ml.g4dn.xlarge',\n    initial_instance_count=1\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Model Loading Function for XGBoost in Python\nDESCRIPTION: Shows an example implementation of the model_fn function, which loads a pickled XGBoost model from the SageMaker model directory.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/using_xgboost.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pickle as pkl\n\ndef model_fn(model_dir):\n    with open(os.path.join(model_dir, \"xgboost-model\"), \"rb\") as f:\n        booster = pkl.load(f)\n    return booster\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom input_fn for MXNet Model Serving\nDESCRIPTION: Example of a custom input_fn that handles pickled numpy arrays for MXNet model inference. This function deserializes the request data into a format suitable for the prediction function, specifically creating an NDArrayIter from a numpy array.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport mxnet as mx\n\ndef input_fn(request_body, request_content_type):\n    \"\"\"An input_fn that loads a pickled numpy array\"\"\"\n    if request_content_type == 'application/python-pickle':\n        array = np.load(StringIO(request_body))\n        array.reshape(model.data_shapes[0])\n        return mx.io.NDArrayIter(mx.ndarray(array))\n    else:\n        # Handle other content-types here or raise an Exception\n        # if the content type is not supported.\n        pass\n```\n\n----------------------------------------\n\nTITLE: Setting Up Record Identifier and Event Time Features\nDESCRIPTION: Sets up required record identifier and event time features for the Feature Store. This adds a timestamp column to the datasets when no timestamp is available, which is required for feature group creation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nrecord_identifier_name = \"TransactionID\"\nevent_time_feature_name = \"EventTime\"\ncurrent_time_sec = int(round(time.time()))\nidentity_data[event_time_feature_name] = pd.Series([current_time_sec]*len(identity_data), dtype=\"float64\")\ntransformed_transaction_data[event_time_feature_name] = pd.Series([current_time_sec]*len(transaction_data), dtype=\"float64\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Distributed Training with Parameter Servers in SageMaker\nDESCRIPTION: This snippet demonstrates how to configure distributed training using parameter servers with the TensorFlow estimator in SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\ntf_estimator = TensorFlow(\n    entry_point=\"tf-train.py\",\n    role=\"SageMakerRole\",\n    instance_count=2,\n    instance_type=\"ml.p2.xlarge\",\n    framework_version=\"2.2\",\n    py_version=\"py37\",\n    distribution={\"parameter_server\": {\"enabled\": True}},\n)\ntf_estimator.fit(\"s3://bucket/path/to/training/data\")\n```\n\n----------------------------------------\n\nTITLE: Deploying Model to SageMaker Endpoint\nDESCRIPTION: Shows how to deploy a trained model to a SageMaker endpoint for inference.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_51\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.utils import name_from_base\n\n# Retrieve the inference script and Docker image\ndeploy_script_uri = script_uris.retrieve(\n    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n)\ndeploy_image_uri = image_uris.retrieve(\n    region=None,\n    framework=None,\n    image_scope=\"inference\",\n    model_id=model_id,\n    model_version=model_version,\n    instance_type=training_instance_type,\n)\n\n# Use the estimator from the previous step to deploy to a SageMaker endpoint\nendpoint_name = name_from_base(f\"{model_id}-transfer-learning\")\n\npredictor = estimator.deploy(\n    initial_instance_count=instance_count,\n    instance_type=inference_instance_type,\n    entry_point=\"inference.py\",\n    image_uri=deploy_image_uri,\n    source_dir=deploy_script_uri,\n    endpoint_name=endpoint_name,\n    enable_network_isolation=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Custom Pre/Post Processing Handler Implementation\nDESCRIPTION: Example showing how to specify a custom Python script for pre/post-processing of prediction requests.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = Model(entry_point='inference.py',\n              model_data='s3://mybucket/model.tar.gz',\n              role='MySageMakerRole')\n```\n\n----------------------------------------\n\nTITLE: XGBoost SageMaker Endpoint Deployment\nDESCRIPTION: Demonstrates deploying an XGBoost model to a SageMaker endpoint with specific instance configurations.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nmodel_builder = ModelBuilder(\n    model=model,\n    schema_builder=SchemaBuilder(sample_input=sample_input, sample_output=sample_output),\n    role_arn=execution_role,\n    mode=Mode.SAGEMAKER_ENDPOINT\n)\nxgb_builder = model_builder.build()\npredictor = xgb_builder.deploy(\n    instance_type='ml.c5.xlarge',\n    initial_instance_count=1\n)\n```\n\n----------------------------------------\n\nTITLE: Deploying Scikit-learn Model from S3 Data in SageMaker using Python\nDESCRIPTION: This code sample shows how to deploy a Scikit-learn model directly from model data stored in S3. It uses the SKLearnModel class to create a model object and then deploys it to a SageMaker endpoint.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nsklearn_model = SKLearnModel(model_data=\"s3://bucket/model.tar.gz\",\n                                 role=\"SageMakerRole\",\n                                 entry_point=\"transform_script.py\",\n                                 framework_version=\"1.0-1\")\n\npredictor = sklearn_model.deploy(instance_type=\"ml.c4.xlarge\", initial_instance_count=1)\n```\n\n----------------------------------------\n\nTITLE: Creating a Dataset from a Feature Group in SageMaker with Python\nDESCRIPTION: Creates a dataset using the create_dataset method of the feature store API. The base parameter can be either a feature group or a pandas DataFrame.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nresult_df, query = feature_store.create_dataset(\n   base=base_feature_group,\n   output_path=f\"s3://{s3_bucket_name}\"\n).to_dataframe()\n```\n\n----------------------------------------\n\nTITLE: Basic Schema Builder Usage in Python\nDESCRIPTION: Demonstrates basic usage of SchemaBuilder for handling input and output serialization with simple string examples.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_31\n\nLANGUAGE: python\nCODE:\n```\ninput = \"How is the demo going?\"\noutput = \"Comment la démo va-t-elle?\"\nschema = SchemaBuilder(input, output)\n```\n\n----------------------------------------\n\nTITLE: Deploying Models with VPC Configuration in SageMaker\nDESCRIPTION: This snippet demonstrates how to deploy a trained model with VPC configurations, including using the same VPC config as training, overriding with a different VPC config, or disabling VPC config entirely.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_84\n\nLANGUAGE: python\nCODE:\n```\n# Creates a SageMaker Model and Endpoint using the same VpcConfig\n# Endpoint container instances will run in your VPC\nmxnet_vpc_predictor = mxnet_vpc_estimator.deploy(initial_instance_count=1,\n                                                 instance_type='ml.p2.xlarge')\n\n# You can also set ``vpc_config_override`` to use a different VpcConfig\nother_vpc_config = {'Subnets': ['subnet-3', 'subnet-4'],\n                    'SecurityGroupIds': ['sg-2']}\nmxnet_predictor_other_vpc = mxnet_vpc_estimator.deploy(initial_instance_count=1,\n                                                       instance_type='ml.p2.xlarge',\n                                                       vpc_config_override=other_vpc_config)\n\n# Setting ``vpc_config_override=None`` will disable VpcConfig\nmxnet_predictor_no_vpc = mxnet_vpc_estimator.deploy(initial_instance_count=1,\n                                                    instance_type='ml.p2.xlarge',\n                                                    vpc_config_override=None)\n```\n\n----------------------------------------\n\nTITLE: Pinning GPUs to SageMaker Distributed Data Parallel Processes\nDESCRIPTION: Pin each GPU to a single SageMaker distributed data parallel process using the local rank. This code also sets memory growth for TensorFlow distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    tf.config.experimental.set_visible_devices(gpus[sdp.local_rank()], 'GPU')\n```\n\n----------------------------------------\n\nTITLE: Deploying a Chainer Model in SageMaker\nDESCRIPTION: Example of training a Chainer estimator and deploying it to a SageMaker endpoint. This demonstrates the standard workflow of training a model and then deploying it for inference with a predictor object.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Train my estimator\nchainer_estimator = Chainer(entry_point='train_and_deploy.py',\n                            instance_type='ml.p3.2xlarge',\n                            instance_count=1,\n                            framework_version='5.0.0',\n                            py_version='py3')\nchainer_estimator.fit('s3://my_bucket/my_training_data/')\n\n# Deploy my estimator to a SageMaker Endpoint and get a Predictor\npredictor = chainer_estimator.deploy(instance_type='ml.m4.xlarge',\n                                     initial_instance_count=1)\n\n# `data` is a NumPy array or a Python list.\n# `response` is a NumPy array.\nresponse = predictor.predict(data)\n```\n\n----------------------------------------\n\nTITLE: Pinning GPU to Distributed Data Parallel Process in PyTorch\nDESCRIPTION: This code pins each GPU to a single distributed data parallel library process using the local rank of the device.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntorch.cuda.set_device(dist.get_local_rank())\n```\n\n----------------------------------------\n\nTITLE: Configuring TensorFlow Estimator for Pipe Input Mode in SageMaker\nDESCRIPTION: This snippet shows how to configure a TensorFlow estimator to use Pipe input mode for efficient data streaming during training in SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\ntf_estimator = TensorFlow(\n    entry_point=\"tf-train-with-pipemodedataset.py\",\n    role=\"SageMakerRole\",\n    training_steps=10000,\n    evaluation_steps=100,\n    instance_count=1,\n    instance_type=\"ml.p2.xlarge\",\n    framework_version=\"1.10.0\",\n    py_version=\"py3\",\n    input_mode=\"Pipe\",\n)\n\ntf_estimator.fit(\"s3://bucket/path/to/training/data\")\n```\n\n----------------------------------------\n\nTITLE: Deploying a trained model using Amazon SageMaker Python SDK\nDESCRIPTION: This code snippet shows how to deploy a trained model using the Amazon SageMaker Python SDK. It demonstrates creating a model object from a trained estimator and deploying it to create a SageMaker endpoint for real-time inference.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/doc_utils/pretrainedmodels.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.pytorch import PyTorchModel\n\nmodel = estimator.create_model()\nprediction = model.deploy(\n    initial_instance_count=1,\n    instance_type='ml.m4.xlarge'\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Hive DDL Commands for SageMaker Feature Store with Python\nDESCRIPTION: Generates Hive DDL commands for a feature group, with the schema based on feature definitions. Column names match feature names and data types are inferred from feature types.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nprint(feature_group.as_hive_ddl())\n```\n\n----------------------------------------\n\nTITLE: Using SageMaker ModelPackage\nDESCRIPTION: Demonstrates how to create and deploy a model using SageMaker ModelPackage with role and model package ARN specifications.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimport sagemaker\n\nmodel = sagemaker.ModelPackage(\n    role='SageMakerRole',\n    model_package_arn='arn:aws:sagemaker:us-west-2:123456:model-package/my-model-package')\nmodel.deploy(1, 'ml.m4.xlarge', endpoint_name='my-endpoint')\n\n# When you are done using your endpoint\nmodel.sagemaker_session.delete_endpoint('my-endpoint')\n```\n\n----------------------------------------\n\nTITLE: Deploying Existing SageMaker Model Locally\nDESCRIPTION: Shows how to deploy an existing SageMaker model locally, make predictions, and clean up resources.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_79\n\nLANGUAGE: python\nCODE:\n```\nimport numpy\nfrom sagemaker.mxnet import MXNetModel\n\nmodel_location = 's3://mybucket/my_model.tar.gz'\ncode_location = 's3://mybucket/sourcedir.tar.gz'\ns3_model = MXNetModel(model_data=model_location, role='SageMakerRole',\n                      entry_point='mnist.py', source_dir=code_location)\n\npredictor = s3_model.deploy(initial_instance_count=1, instance_type='local')\ndata = numpy.zeros(shape=(1, 1, 28, 28))\npredictor.predict(data)\n\n# Tear down the endpoint container and delete the corresponding endpoint configuration\npredictor.delete_endpoint()\n\n# Deletes the model\npredictor.delete_model()\n```\n\n----------------------------------------\n\nTITLE: Deploying a SageMaker Asynchronous Inference Endpoint with AsyncInferenceConfig\nDESCRIPTION: Deploys a trained model to a SageMaker asynchronous inference endpoint using the AsyncInferenceConfig object. The deploy method returns an AsyncPredictor object that can be used for making predictions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_60\n\nLANGUAGE: python\nCODE:\n```\n# Deploys the model that was generated by fit() to a SageMaker asynchronous inference endpoint\nasync_predictor = estimator.deploy(async_inference_config=async_config)\n```\n\n----------------------------------------\n\nTITLE: Implementing model_fn for Scikit-learn Model Loading in SageMaker\nDESCRIPTION: This snippet shows how to implement the model_fn function that SageMaker uses to load a trained Scikit-learn model. It loads a joblib serialized model from the model directory that SageMaker automatically mounts to the container.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.externals import joblib\nimport os\n\ndef model_fn(model_dir):\n    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n    return clf\n```\n\n----------------------------------------\n\nTITLE: Using Join Function in SageMaker Pipelines (Python)\nDESCRIPTION: This example demonstrates how to use the Join function to construct an S3 URI at runtime in SageMaker Pipelines. It combines a parameterized bucket name with other string values to create a dynamic input path for training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nbucket = ParameterString('bucket', default_value='my-bucket')\n\ninput_uri = Join(\n    on=\"/\",\n    values=['s3:/', bucket, \"my-input\")]\n)\n\nstep = TrainingStep(\n    name=\"MyTrainingStep\",\n    run_args=estimator.fit(inputs=TrainingInput(s3_data=input_uri)),\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Chainer Training Script Arguments in Python\nDESCRIPTION: This snippet demonstrates how to set up argument parsing for a Chainer training script, including hyperparameters and data directory paths. It uses argparse to handle command-line arguments passed by SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport os\n\nif __name__ =='__main__':\n\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument('--epochs', type=int, default=50)\n    parser.add_argument('--batch-size', type=int, default=64)\n    parser.add_argument('--learning-rate', type=float, default=0.05)\n\n    # Data, model, and output directories\n    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n    parser.add_argument('--test', type=str, default=os.environ['SM_CHANNEL_TEST'])\n\n    args, _ = parser.parse_known_args()\n```\n\n----------------------------------------\n\nTITLE: Using FileSystemInput with FSx for Lustre in SageMaker Training\nDESCRIPTION: Example of configuring a TensorFlow estimator with FSx for Lustre as input through the FileSystemInput class. The VPC configuration must match the Amazon EC2 instance's VPC to access the FSx for Lustre file system.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# This example shows how to use FileSystemInput class\n# Configure an estimator with subnets and security groups from your VPC. The VPC should be the same as that\n# you chose for your Amazon EC2 instance\n\nestimator = TensorFlow(entry_point='tensorflow_mnist/mnist.py',\n                       role='SageMakerRole',\n                       instance_count=1,\n                       instance_type='ml.c4.xlarge',\n                       subnets=['subnet-1', 'subnet-2']\n                       security_group_ids=['sg-1'])\n\n\nfile_system_input = FileSystemInput(file_system_id='fs-2',\n                                    file_system_type='FSxLustre',\n                                    directory_path='/<mount-id>/tensorflow',\n                                    file_system_access_mode='ro')\n\n# Start an Amazon SageMaker training job with FSx using the FileSystemInput class\nestimator.fit(file_system_input)\n```\n\n----------------------------------------\n\nTITLE: Custom Input Processing for XGBoost Model in Python\nDESCRIPTION: Demonstrates a custom input_fn implementation that loads a numpy array from the request body and converts it to an XGBoost DMatrix.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/using_xgboost.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom io import BytesIO\nimport numpy as np\nimport xgboost as xgb\n\ndef input_fn(request_body, request_content_type):\n    \"\"\"An input_fn that loads a numpy array\"\"\"\n    if request_content_type == \"application/npy\":\n        array = np.load(BytesIO(request_body))\n        return xgb.DMatrix(array)\n    else:\n        # Handle other content-types here or raise an Exception\n        # if the content type is not supported.\n        pass\n```\n\n----------------------------------------\n\nTITLE: Training with Gzipped TFRecords in SageMaker\nDESCRIPTION: This example demonstrates how to configure a TensorFlow estimator to train on Gzipped TFRecords using Pipe input mode in SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.inputs import TrainingInput\n\ntrain_s3_input = TrainingInput('s3://bucket/path/to/training/data', compression='Gzip')\ntf_estimator.fit(train_s3_input)\n```\n\n----------------------------------------\n\nTITLE: Initializing SageMaker Distributed Data Parallel with PyTorch\nDESCRIPTION: Imports and initializes the SageMaker distributed data parallel library for PyTorch, including setting up the distributed process group.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport smdistributed.dataparallel.torch.distributed as dist\nfrom smdistributed.dataparallel.torch.parallel.distributed import DistributedDataParallel as DDP\n\ndist.init_process_group()\n```\n\n----------------------------------------\n\nTITLE: Configuring SageMaker Local Session in Python\nDESCRIPTION: Creates a LocalSession object and configures it to use local code, demonstrating how to set up a local SageMaker session programmatically.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_77\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.local import LocalSession\n\nsagemaker_session = LocalSession()\nsagemaker_session.config = {'local': {'local_code': True}}\n\n# pass sagemaker_session to your estimator or model\n```\n\n----------------------------------------\n\nTITLE: Defining Schema for Hugging Face Model Input/Output in Python\nDESCRIPTION: Uses SchemaBuilder to define the input and output schema for a Hugging Face model inference workload. This includes sample input text and expected output format.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nvalue: str = \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\"\nschema = SchemaBuilder(\n    value,\n    {\"generated_text\": \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\\\nDaniel: Hello, Girafatron!\\\\nGirafatron: Hi, Daniel. I was just thinking about how magnificent giraffes are and how they should be worshiped by all.\\\\nDaniel: You and I think alike, Girafatron. I think all animals should be worshipped! But I guess that could be a bit impractical...\\\\nGirafatron: That's true. But the giraffe is just such an amazing creature and should always be respected!\\\\nDaniel: Yes! And the way you go on about giraffes, I could tell you really love them.\\\\nGirafatron: I'm obsessed with them, and I'm glad to hear you noticed!\\\\nDaniel: I'\"})\n```\n\n----------------------------------------\n\nTITLE: Ingesting Data into a SageMaker Feature Group with Python\nDESCRIPTION: Loads feature data into a feature group using the ingest function. You can specify the number of workers and whether to wait for the operation to complete.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfeature_group.ingest(\n    data_frame=feature_data, max_workers=3, wait=True\n)\n```\n\n----------------------------------------\n\nTITLE: Working with TuningStep Properties in SageMaker Workflow\nDESCRIPTION: Example demonstrating how to access the best training job properties and create models from the best and second-best performing models. It shows both the direct properties access and the helper method for getting model data URIs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nbucket = \"my-bucket\"\nmodel_prefix = \"my-model\"\n\nstep_tune = TuningStep(...)\n# tuning step can launch multiple training jobs, thus producing multiple model artifacts\n# we can create a model with the best performance\nbest_model = Model(\n    model_data=Join(\n        on=\"/\",\n        values=[\n            f\"s3://{bucket}/{model_prefix}\",\n            # from DescribeHyperParameterTuningJob\n            step_tune.properties.BestTrainingJob.TrainingJobName,\n            \"output/model.tar.gz\",\n        ],\n    )\n)\n# we can also access any top-k best as we wish\nsecond_best_model = Model(\n    model_data=Join(\n        on=\"/\",\n        values=[\n            f\"s3://{bucket}/{model_prefix}\",\n            # from ListTrainingJobsForHyperParameterTuningJob\n            step_tune.properties.TrainingJobSummaries[1].TrainingJobName,\n            \"output/model.tar.gz\",\n        ],\n    )\n)\n```\n\nLANGUAGE: python\nCODE:\n```\nmodel_data = step_tune.get_top_model_s3_uri(\n    top_k=0, # best model\n    s3_bucket=bucket,\n    prefix=model_prefix\n)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions with AWS CLI for TensorFlow Serving Endpoints\nDESCRIPTION: Demonstrates various AWS CLI commands for interacting with SageMaker TensorFlow Serving Endpoints. Includes examples for making standard predict requests, targeting specific models, making regress requests, and handling different input formats like JSON and CSV.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# TensorFlow Serving REST API - predict request\naws sagemaker-runtime invoke-endpoint \\\n    --endpoint-name my-endpoint \\\n    --content-type 'application/json' \\\n    --body '{\"instances\": [1.0, 2.0, 5.0]}' \\\n    >(cat) 1>/dev/null\n\n# Predict request for specific model name\naws sagemaker-runtime invoke-endpoint \\\n    --endpoint-name my-endpoint \\\n    --content-type 'application/json' \\\n    --body '{\"instances\": [1.0, 2.0, 5.0]}' \\\n    --custom-attributes 'tfs-model-name=other_model' \\\n    >(cat) 1>/dev/null\n\n# TensorFlow Serving REST API - regress request\naws sagemaker-runtime invoke-endpoint \\\n    --endpoint-name my-endpoint \\\n    --content-type 'application/json' \\\n    --body '{\"signature_name\": \"tensorflow/serving/regress\",\"examples\": [{\"x\": 1.0}]}' \\\n    --custom-attributes 'tfs-method=regress' \\\n    >(cat) 1>/dev/null\n\n# Simple json request (2 instances)\naws sagemaker-runtime invoke-endpoint \\\n    --endpoint-name my-endpoint \\\n    --content-type 'application/json' \\\n    --body '[[1.0, 2.0, 5.0],[2.0, 3.0, 4.0]]' \\\n    >(cat) 1>/dev/null\n\n# CSV request (2 rows)\naws sagemaker-runtime invoke-endpoint \\\n    --endpoint-name my-endpoint \\\n    --content-type 'text/csv' \\\n    --body \"1.0,2.0,5.0\"$'\\n'\"2.0,3.0,4.0\" \\\n    >(cat) 1>/dev/null\n\n# Line delimited JSON from an input file\naws sagemaker-runtime invoke-endpoint \\\n    --endpoint-name my-endpoint \\\n    --content-type 'application/jsons' \\\n    --body \"$(cat input.jsons)\" \\\n    results.json\n```\n\n----------------------------------------\n\nTITLE: Creating Minimal Feature Groups for Fraud Detection\nDESCRIPTION: Shows a minimal implementation for creating two feature groups with just the required parameters. This example creates both identity and transaction feature groups with online store enabled.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nidentity_feature_group.create(\n    s3_uri=offline_feature_store_bucket,\n    record_identifier_name=record_identifier_name,\n    event_time_feature_name=event_time_feature_name,\n    role_arn=role,\n    enable_online_store=True\n)\n\ntransaction_feature_group.create(\n    s3_uri=offline_feature_store_bucket,\n    record_identifier_name=record_identifier_name,\n    event_time_feature_name=event_time_feature_name,\n    role_arn=role,\n    enable_online_store=True\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring TensorBoard Output\nDESCRIPTION: Shows how to configure TensorBoard output settings for the debugger hook to emit TensorBoard visualization data.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.debugger import TensorBoardOutputConfig\n\ntensorboard_output_config = TensorBoardOutputConfig(\n    s3_output_path='s3://path/for/tensorboard/data/emission'\n```\n\n----------------------------------------\n\nTITLE: Creating Athena Queries for SageMaker Feature Store with Python\nDESCRIPTION: Creates Athena query objects for feature groups, which can be used to query the data in the Offline Store. The table_name is automatically generated by Feature Store.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nidentity_query = identity_feature_group.athena_query()\ntransaction_query = transaction_feature_group.athena_query()\n\nidentity_table = identity_query.table_name\ntransaction_table = transaction_query.table_name\n```\n\n----------------------------------------\n\nTITLE: Deploying a SageMaker Pipeline Model as an Endpoint in Python\nDESCRIPTION: Deploys the pipeline model to create an endpoint for real-time inference. The deployment specifies the instance count, instance type, and endpoint name for the deployment.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_89\n\nLANGUAGE: python\nCODE:\n```\nsm_model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge', endpoint_name=endpoint_name)\n```\n\n----------------------------------------\n\nTITLE: Deploying Chainer Models from S3 Model Data\nDESCRIPTION: Code example demonstrating how to deploy a Chainer model directly from model artifacts stored in S3. This creates a ChainerModel object and deploys it to a SageMaker endpoint.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nchainer_model = ChainerModel(\n    model_data=\"s3://bucket/model.tar.gz\",\n    role=\"SageMakerRole\",\n    entry_point=\"transform_script.py\",\n)\n\npredictor = chainer_model.deploy(instance_type=\"ml.c4.xlarge\", initial_instance_count=1)\n```\n\n----------------------------------------\n\nTITLE: Attaching to Existing RL Training Job in Python\nDESCRIPTION: This snippet shows how to attach an RLEstimator to an existing training job using the attach method. This is useful for working with training jobs that have already been started or completed.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/rl/using_rl.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmy_training_job_name = 'MyAwesomeRLTrainingJob'\nrl_estimator = RLEstimator.attach(my_training_job_name)\n```\n\n----------------------------------------\n\nTITLE: Initializing SageMaker Distributed Data Parallel for TensorFlow\nDESCRIPTION: Import and initialize the SageMaker distributed data parallel library for use with TensorFlow. This must be called at the beginning of the training script.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport smdistributed.dataparallel.tensorflow as sdp\nsdp.init()\n```\n\n----------------------------------------\n\nTITLE: Deploying a SageMaker Serverless Endpoint from a Model\nDESCRIPTION: Deploys a model directly to a SageMaker serverless endpoint using the ServerlessInferenceConfig object. This is used when you have a model object rather than an estimator.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_70\n\nLANGUAGE: python\nCODE:\n```\n# Deploys the model to a SageMaker serverless endpoint\nserverless_predictor = model.deploy(serverless_inference_config=serverless_config)\n```\n\n----------------------------------------\n\nTITLE: Using Line-delimited JSON Input for TensorFlow Serving Endpoint in Python\nDESCRIPTION: This snippet shows how to use line-delimited JSON (jsonlines) input when making prediction requests to a TensorFlow Serving endpoint in SageMaker. It demonstrates creating a Predictor without JSON serialization.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# create a Predictor without JSON serialization\n\npredictor = Predictor('endpoint-name', serializer=None, content_type='application/jsonlines')\n\ninput = '''{'x': [1.0, 2.0, 5.0]}\n{'x': [1.0, 2.0, 5.0]}\n{'x': [1.0, 2.0, 5.0]}'''\n```\n\n----------------------------------------\n\nTITLE: Executing Athena Queries on SageMaker Feature Store Data with Python\nDESCRIPTION: Writes and executes an SQL query to join data from multiple feature groups in the Offline Store, saving the results to S3 and loading them into a pandas DataFrame.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Athena query\nquery_string = 'SELECT * FROM \"'+transaction_table+'\" LEFT JOIN \"'+identity_table+'\" ON \"'+transaction_table+'\".transactionid = \"'+identity_table+'\".transactionid'\n\n# run Athena query. The output is loaded to a Pandas dataframe.\ndataset = pd.DataFrame()\nidentity_query.run(query_string=query_string, output_location='s3://'+default_s3_bucket_name+'/query_results/')\nidentity_query.wait()\ndataset = identity_query.as_dataframe()\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Inference Spec for Hugging Face Model in Python\nDESCRIPTION: Creates a custom InferenceSpec class for deploying a pre-trained Hugging Face transformer model to SageMaker. The class defines load and invoke methods for the model.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nclass MyInferenceSpec(InferenceSpec):\n    def load(self, model_dir: str):\n        return pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n\n    def invoke(self, input, model):\n        return model(input)\n\ninf_spec = MyInferenceSpec()\n```\n\n----------------------------------------\n\nTITLE: Deploying an MXNet Model with Elastic Inference in SageMaker\nDESCRIPTION: Deploys an MXNet model with Elastic Inference acceleration, which provides cost-effective GPU acceleration for inference. The code specifies an accelerator type to attach to the endpoint.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\npredictor = mxnet_estimator.deploy(instance_type='ml.m4.xlarge',\n                                 initial_instance_count=1,\n                                 accelerator_type='ml.eia1.medium')\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Debugger Rule\nDESCRIPTION: Example of implementing a custom rule for gradient analysis with specific configuration parameters and collection settings.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.debugger import Rule\n\nregion = 'us-east-1' # the AWS region of the training job\ncustom_gradient_rule = Rule.custom(\n    name='MyCustomRule',\n    image_uri='864354269164.dkr.ecr.{}.amazonaws.com/sagemaker-debugger-rule-evaluator:latest'.format(region),\n    instance_type='ml.t3.medium', # instance type to run the rule evaluation on\n    source='rules/custom_gradient_rule.py', # path to the rule source file\n    rule_to_invoke='CustomGradientRule', # name of the class to invoke in the rule source file\n    volume_size_in_gb=30, # EBS volume size required to be attached to the rule evaluation instance\n    collections_to_save=[CollectionConfig(\"gradients\")], # collections to be analyzed by the rule\n    rule_parameters={\n      'threshold': '20.0' # this will be used to initialize 'threshold' param in your rule constructor\n    }\n)\n\nestimator = TensorFlow(\n    role=role,\n    instance_count=1,\n    instance_type=instance_type,\n    rules=[\n        custom_gradient_rule\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Making Batch Prediction Requests to TensorFlow Serving Endpoint in Python\nDESCRIPTION: This snippet shows how to make batch prediction requests to a TensorFlow Serving endpoint, which is more efficient than making separate requests for multiple instances.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ninput = {\n  'instances': [\n    [1.0, 2.0, 5.0],\n    [1.0, 2.0, 5.0],\n    [1.0, 2.0, 5.0]\n  ]\n}\nresult = predictor.predict(input)\n\n# result contains:\n# {\n#   'predictions': [\n#     [3.5, 4.0, 5.5],\n#     [3.5, 4.0, 5.5],\n#     [3.5, 4.0, 5.5]\n#   ]\n# }\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Feature Group in SageMaker\nDESCRIPTION: Shows how to initialize a basic Feature Group by providing a name and the SageMaker session. This is the simplest form of feature group setup before customization.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.feature_store.feature_group import FeatureGroup\nfeature_group_name = \"some string for a name\"\nfeature_group = FeatureGroup(name=feature_group_name, sagemaker_session=feature_store_session)\n```\n\n----------------------------------------\n\nTITLE: Configuring Step Parallelism in SageMaker Pipelines\nDESCRIPTION: This example demonstrates how to control the number of concurrent steps executed in a SageMaker Pipeline using ParallelismConfiguration. It sets a limit of 5 concurrent steps to prevent resource exhaustion.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\npipeline.create(\n    parallelism_config=ParallelismConfiguration(5),\n)\n```\n\n----------------------------------------\n\nTITLE: Using Simplified JSON Input for TensorFlow Serving Endpoint in Python\nDESCRIPTION: This code demonstrates how to use a simplified JSON input format when making prediction requests to a TensorFlow Serving endpoint in SageMaker. It shows both single and multi-instance inputs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ninput = [\n  [1.0, 2.0, 5.0],\n  [1.0, 2.0, 5.0]\n]\nresult = predictor.predict(input)\n\n# result contains:\n# {\n#   'predictions': [\n#     [3.5, 4.0, 5.5],\n#     [3.5, 4.0, 5.5]\n#   ]\n# }\n\n# Alternative input format\ninput = {\n  'x': [1.0, 2.0, 5.0]\n}\n\n# result contains:\n# {\n#   'predictions': [\n#     [3.5, 4.0, 5.5]\n#   ]\n# }\n```\n\n----------------------------------------\n\nTITLE: Creating Baseline Constraints for Model Monitoring\nDESCRIPTION: Initializes and configures a DefaultModelMonitor to generate baseline constraints and statistics from a training dataset stored in S3.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_monitoring.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.model_monitor import DefaultModelMonitor\nfrom sagemaker.model_monitor.dataset_format import DatasetFormat\n\nmy_monitor = DefaultModelMonitor(\n    role=role,\n    instance_count=1,\n    instance_type='ml.m5.xlarge',\n    volume_size_in_gb=20,\n    max_runtime_in_seconds=3600,\n)\n\nmy_monitor.suggest_baseline(\n    baseline_dataset='s3://path/to/training-dataset-with-header.csv',\n    dataset_format=DatasetFormat.csv(header=True),\n)\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Asynchronous Inference Resources in SageMaker\nDESCRIPTION: Deletes the SageMaker asynchronous inference endpoint and model to avoid incurring unnecessary charges. This should be done after the inference is complete and results are retrieved.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_65\n\nLANGUAGE: python\nCODE:\n```\n# Tears down the SageMaker endpoint and endpoint configuration\nasync_predictor.delete_endpoint()\n\n# Deletes the SageMaker model\nasync_predictor.delete_model()\n```\n\n----------------------------------------\n\nTITLE: Basic Model Directory Structure Example\nDESCRIPTION: Shows the expected directory structure for PyTorch model deployment with separate model and source files. For PyTorch versions 1.1 and lower, the model and inference code are packaged separately.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_14\n\nLANGUAGE: plaintext\nCODE:\n```\nmodel.tar.gz/\n|- model.pth\n\nsourcedir.tar.gz/\n|- script.py\n|- requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Configuring GPU Settings for Distributed Training\nDESCRIPTION: Pins each GPU to a single distributed process and configures memory growth settings required for TensorFlow distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    tf.config.experimental.set_visible_devices(gpus[sdp.local_rank()], 'GPU')\n```\n\n----------------------------------------\n\nTITLE: Configuring Distributed Training with Horovod in SageMaker\nDESCRIPTION: This example shows how to set up distributed training using Horovod with the TensorFlow estimator in SageMaker, including MPI configuration options.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\ntf_estimator = TensorFlow(\n    entry_point=\"tf-train.py\",\n    role=\"SageMakerRole\",\n    instance_count=1,\n    instance_type=\"ml.p3.8xlarge\",\n    framework_version=\"2.1.0\",\n    py_version=\"py3\",\n    distribution={\n        \"mpi\": {\n            \"enabled\": True,\n            \"processes_per_host\": 4,\n            \"custom_mpi_options\": \"--NCCL_DEBUG INFO\"\n        },\n    },\n)\ntf_estimator.fit(\"s3://bucket/path/to/training/data\")\n```\n\n----------------------------------------\n\nTITLE: Implementing CallbackStep with Inputs and Outputs in SageMaker Pipelines (Python)\nDESCRIPTION: This snippet demonstrates how to create a CallbackStep in SageMaker Pipelines with parameters, inputs, and outputs. It shows how to define a step that depends on another step and how to reference its output properties.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nparam = ParameterInteger(name=\"MyInt\")\noutputParam = CallbackOutput(output_name=\"output1\", output_type=CallbackOutputTypeEnum.String)\nstep_callback = CallbackStep(\n    name=\"MyCallbackStep\",\n    depends_on=[\"TestStep\"],\n    sqs_queue_url=\"https://sqs.us-east-2.amazonaws.com/123456789012/MyQueue\",\n    inputs={\"arg1\": \"foo\", \"arg2\": 5, \"arg3\": param},\n    outputs=[outputParam],\n)\noutput_ref = step_callback.properties.Outputs[\"output1]\n```\n\n----------------------------------------\n\nTITLE: Deploying SageMaker Model\nDESCRIPTION: Example of deploying a SageMaker model with specified instance count and type.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\npredictor = sagemaker_model.deploy(initial_instance_count=1,\n                                      instance_type='ml.m4.xlarge')\n```\n\n----------------------------------------\n\nTITLE: Implementing model_fn for MXNet with Elastic Inference Support\nDESCRIPTION: Defines a custom model_fn function that enables loading and serving an MXNet model through Amazon Elastic Inference. It hybridizes the network with the EIA backend for inference acceleration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef model_fn(model_dir):\n    \"\"\"Load the Gluon model. Called when the hosting service starts.\n\n    Args:\n        model_dir (str): The directory where model files are stored.\n\n    Returns:\n        mxnet.gluon.nn.Block: a Gluon network (for this example)\n    \"\"\"\n    net = models.get_model('resnet34_v2', ctx=mx.cpu(), pretrained=False, classes=10)\n    net.load_params('%s/model.params' % model_dir, ctx=mx.cpu())\n    net.hybridize(backend='EIA', static_alloc=True, static_shape=True)\n    return net\n```\n\n----------------------------------------\n\nTITLE: Initializing the Feature Store Offline SDK in SageMaker with Python\nDESCRIPTION: Initializes the Feature Store Offline SDK which provides functionality to build ML-ready datasets through the DatasetBuilder class without writing SQL code.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.feature_store.feature_store import FeatureStore\n\nfeature_store = FeatureStore(sagemaker_session=feature_store_session)\n```\n\n----------------------------------------\n\nTITLE: Defining Standard Output Function for SageMaker Chainer Endpoints\nDESCRIPTION: The signature for an output_fn used by SageMaker to process predictions before sending them back as API responses. It takes the prediction result and requested content type as inputs and returns serialized data.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef output_fn(prediction, content_type)\n```\n\n----------------------------------------\n\nTITLE: Adding Python Dependencies to TensorFlow Model Deployment\nDESCRIPTION: Example of specifying external dependencies through requirements.txt when creating a TensorFlowModel for handling data processing needs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = TensorFlowModel(entry_point='inference.py',\n                        dependencies=['requirements.txt'],\n                        model_data='s3://mybucket/model.tar.gz',\n                        role='MySageMakerRole',\n                        framework_version='x.x.x')\n```\n\n----------------------------------------\n\nTITLE: Creating Transformers with VPC Configuration in SageMaker\nDESCRIPTION: This example shows how to create a SageMaker Transformer for batch transform jobs using the same VPC configuration as the training job, enabling batch processing within your VPC.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_85\n\nLANGUAGE: python\nCODE:\n```\n# Creates a SageMaker Model using the same VpcConfig\nmxnet_vpc_transformer = mxnet_vpc_estimator.transformer(instance_count=1,\n                                                        instance_type='ml.p2.xlarge')\n\n# Transform Job container instances will run in your VPC\nmxnet_vpc_transformer.transform('s3://my-bucket/batch-transform-input')\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Training with SageMaker TensorFlow Estimator\nDESCRIPTION: This code shows how to start an asynchronous training job using the fit method with wait=False, and how to later attach to the existing training job.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntf_estimator.fit(your_input_data, wait=False)\ntraining_job_name = tf_estimator.latest_training_job.name\n\n# after some time, or in a separate Python notebook, we can attach to it again.\n\ntf_estimator = TensorFlow.attach(training_job_name=training_job_name)\n```\n\n----------------------------------------\n\nTITLE: Invoking SparkML Endpoint with CSV Payload in SageMaker Python\nDESCRIPTION: This snippet demonstrates how to invoke a deployed SparkML endpoint using a CSV payload for prediction. It shows the format of the payload and how to use the predictor object to make predictions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\npayload = 'field_1,field_2,field_3,field_4,field_5'\npredictor.predict(payload)\n```\n\n----------------------------------------\n\nTITLE: Defining PySpark and SageMaker Feature Store Dependencies\nDESCRIPTION: Specifies the required package versions for using SageMaker Feature Store with PySpark 3.3. Pins PySpark to version 3.3.2 and includes the corresponding SageMaker Feature Store PySpark integration package.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/extras/feature-processor_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npyspark==3.3.2\nsagemaker-feature-store-pyspark-3.3\n```\n\n----------------------------------------\n\nTITLE: ModelBuilder with Custom Container\nDESCRIPTION: Example of using ModelBuilder with a custom container image and specified model server.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nmodel_builder = ModelBuilder(\n    model=model,\n    model_server=ModelServer.TORCHSERVE,\n    schema_builder=SchemaBuilder(X_test, y_pred),\n    image_uri=\"123123123123.dkr.ecr.ap-southeast-2.amazonaws.com/byoc-image:xgb-1.7-1\")\n)\n```\n\n----------------------------------------\n\nTITLE: Complete Distributed Training Script Example\nDESCRIPTION: Complete example showing a PyTorch training script modified for distributed training with SageMaker's data parallel library.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Import distributed data parallel library PyTorch API\nimport smdistributed.dataparallel.torch.distributed as dist\n\n# Import distributed data parallel library PyTorch DDP\nfrom smdistributed.dataparallel.torch.parallel.distributed import DistributedDataParallel as DDP\n\n# Initialize distributed data parallel library\ndist.init_process_group()\n\nclass Net(nn.Module):\n    ...\n    # Define model\n\ndef train(...):\n    ...\n    # Model training\n\ndef test(...):\n    ...\n    # Model evaluation\n\ndef main():\n\n    # Scale batch size by world size\n    batch_size //= dist.get_world_size() // 8\n    batch_size = max(batch_size, 1)\n\n    # Prepare dataset\n    train_dataset = torchvision.datasets.MNIST(...)\n\n    # Set num_replicas and rank in DistributedSampler\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n            train_dataset,\n            num_replicas=dist.get_world_size(),\n            rank=dist.get_rank())\n\n    train_loader = torch.utils.data.DataLoader(..)\n\n    # Wrap the PyTorch model with distributed data parallel library's DDP\n    model = DDP(Net().to(device))\n\n    # Pin each GPU to a single distributed data parallel library process.\n    torch.cuda.set_device(local_rank)\n    model.cuda(local_rank)\n\n    # Train\n    optimizer = optim.Adadelta(...)\n    scheduler = StepLR(...)\n    for epoch in range(1, args.epochs + 1):\n        train(...)\n        if rank == 0:\n            test(...)\n        scheduler.step()\n\n    # Save model on master node.\n    if dist.get_rank() == 0:\n        torch.save(...)\n\nif __name__ == '__main__':\n    main()\n```\n\n----------------------------------------\n\nTITLE: Using AWS CodeCommit Repository with SageMaker Estimator\nDESCRIPTION: Shows how to use an AWS CodeCommit repository for a training script with username and password authentication. CodeCommit doesn't support 2FA, so those parameters are not provided.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# This example specifies a CodeCommit repository, and try to authenticate with provided username+password\ngit_config = {'repo': 'https://git-codecommit.us-west-2.amazonaws.com/v1/repos/your_repo_name',\n              'username': 'username',\n              'password': 'passw0rd!'}\n\nmx_estimator = MXNet(entry_point='mxnet/mnist.py',\n                     role='SageMakerRole',\n                     git_config=git_config,\n                     instance_count=1,\n                     instance_type='ml.c4.xlarge')\n```\n\n----------------------------------------\n\nTITLE: Adding Pre-downloaded Library Dependencies for Network-Isolated Deployments\nDESCRIPTION: Example showing how to add pre-downloaded Python libraries to a TensorFlowModel for network-isolated environments where real-time dependency installation is not possible.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = TensorFlowModel(entry_point='inference.py',\n                       dependencies=['/path/to/folder/named/lib'],\n                       model_data='s3://mybucket/model.tar.gz',\n                       role='MySageMakerRole',\n                       framework_version='x.x.x')\n```\n\n----------------------------------------\n\nTITLE: Local Mode Model Setup\nDESCRIPTION: Demonstrates how to save and configure a model for local testing using XGBoost as an example.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\nmodel.save_model(model_dir + \"/my_model.xgb\")\n```\n\n----------------------------------------\n\nTITLE: Creating SageMaker Debugger Trial for Analysis in Python\nDESCRIPTION: This snippet demonstrates how to create a SageMaker Debugger trial for interactive analysis of debugging data. It retrieves the S3 output path for debugger artifacts and creates a trial object for further analysis.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom smdebug.trials import create_trial\n\ns3_output_path = estimator.latest_job_debugger_artifacts_path()\ntrial = create_trial(s3_output_path)\n```\n\n----------------------------------------\n\nTITLE: Preparing Local Model Data for S3 Upload in Bash\nDESCRIPTION: Demonstrates how to compress local model data into a tar.gz file and upload it to Amazon S3 for deployment. This process is necessary when working with local model data.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ntar -czf model.tar.gz my_model\naws s3 cp model.tar.gz s3://my-bucket/my-path/model.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Implementing model_fn for Chainer Model Loading in SageMaker\nDESCRIPTION: Implementation of the model_fn function that loads a saved Chainer model from the model directory. This function returns a model object that SageMaker can use for serving inference requests.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport chainer\nimport os\n\ndef model_fn(model_dir):\n    chainer.config.train = False\n    model = chainer.links.Classifier(MLP(1000, 10))\n    chainer.serializers.load_npz(os.path.join(model_dir, 'model.npz'), model)\n    return model.predictor\n```\n\n----------------------------------------\n\nTITLE: Alternative Input Formats for TensorFlow Serving\nDESCRIPTION: Examples of using simplified JSON, line-delimited JSON, and CSV formats for predictions with TensorFlow Serving endpoints.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npredictor = Predictor('endpoint-name', serializer=None, content_type='application/jsonlines')\n\ninput = '''{'x': [1.0, 2.0, 5.0]}\n{'x': [1.0, 2.0, 5.0]}\n{'x': [1.0, 2.0, 5.0]}'''\n\nresult = predictor.predict(input)\n```\n\nLANGUAGE: python\nCODE:\n```\npredictor = Predictor('endpoint-name', serializer=sagemaker.serializers.CSVSerializer())\n\ninput = '1.0,2.0,5.0\\n1.0,2.0,5.0\\n1.0,2.0,5.0'\n\nresult = predictor.predict(input)\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Quality Monitoring for SageMaker Batch Transform in Python\nDESCRIPTION: Shows how to set up an on-demand batch transform data quality monitor using MonitorBatchTransformStep. This example configures a transformer, defines data quality check configurations, and sets up monitoring before the transform job is executed.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_34\n\nLANGUAGE: python\nCODE:\n```\n# configure your transformer\ntransformer = Transformer(..., sagemaker_session=pipeline_session)\ntransform_arg = transformer.transform(\n    transform_input_param,\n    content_type=\"text/csv\",\n    split_type=\"Line\",\n    ...\n)\n\ndata_quality_config = DataQualityCheckConfig(\n    baseline_dataset=transform_input_param,\n    dataset_format=DatasetFormat.csv(header=False),\n    output_s3_uri=\"s3://my-report-path\",\n)\n\nfrom sagemaker.workflow.monitor_batch_transform_step import MonitorBatchTransformStep\n\ntransform_and_monitor_step = MonitorBatchTransformStep(\n    name=\"MyMonitorBatchTransformStep\",\n    transform_step_args=transform_arg,\n    monitor_configuration=data_quality_config,\n    check_job_configuration=job_config,\n    # since data quality only looks at the inputs,\n    # so there is no need to wait for the transform output.\n    monitor_before_transform=True,\n    # if violation is detected in the monitoring, and you want to skip it\n    # and continue running batch transform, you can set fail_on_violation\n    # to false.\n    fail_on_violation=False,\n    supplied_baseline_statistics=\"s3://my-baseline-statistics.json\",\n    supplied_baseline_constraints=\"s3://my-baseline-constraints.json\",\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing MXNet Training Script with Hyperparameters and Environment Variables\nDESCRIPTION: This snippet demonstrates how to set up the main entry point of an MXNet training script, parsing command-line arguments for hyperparameters and accessing SageMaker environment variables for input/output paths.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nimport os\nimport json\n\nif __name__ =='__main__':\n\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument('--epochs', type=int, default=10)\n    parser.add_argument('--batch-size', type=int, default=100)\n    parser.add_argument('--learning-rate', type=float, default=0.1)\n\n    # an alternative way to load hyperparameters via SM_HPS environment variable.\n    parser.add_argument('--sm-hps', type=json.loads, default=os.environ['SM_HPS'])\n\n    # input data and model directories\n    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n    parser.add_argument('--test', type=str, default=os.environ['SM_CHANNEL_TEST'])\n\n    args, _ = parser.parse_known_args()\n\n    # ... load from args.train and args.test, train a model, write model to args.model_dir.\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for AWS SageMaker SDK\nDESCRIPTION: This snippet lists the required Python packages and their versions for the AWS SageMaker Python SDK. It includes libraries for machine learning, data processing, and system utilities. These dependencies ensure compatibility and proper functionality of the SageMaker SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/serve_resources/mlflow/xgboost/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\nmlflow==2.13.2\nlz4==4.3.2\nnumpy==1.26.4\npandas==2.0.3\npsutil==5.9.8\nscikit-learn==1.3.2\nscipy==1.11.3\nxgboost==1.7.1\n```\n\n----------------------------------------\n\nTITLE: Nested JSON Output in SageMaker Pipelines Callbacks (JSON)\nDESCRIPTION: Example of a nested JSON output structure that demonstrates how complex outputs are handled in SageMaker Pipelines. Nested values are serialized as a single string value rather than maintaining their hierarchy.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"output1\": {\n        \"nested_output1\": \"my-output\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating ModelBuilder Instance\nDESCRIPTION: Examples of creating ModelBuilder instances with different configurations for model deployment.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.serve.builder.model_builder import ModelBuilder\nfrom sagemaker.serve.builder.schema_builder import SchemaBuilder\n\nmodel_builder = ModelBuilder(\n    model=model,\n    schema_builder=SchemaBuilder(input, output),\n    role_arn=\"arn:aws:iam::<account-id>:role/service-role/<role-name>\",\n)\n```\n\n----------------------------------------\n\nTITLE: SageMaker Resource Configuration Examples in YAML\nDESCRIPTION: Examples of YAML configuration for various SageMaker resources including EndpointConfig, AutoMLJob, TransformJob, CompilationJob, Pipeline, Model, ModelPackage, ProcessingJob, TrainingJob, and EdgePackagingJob with their respective parameters, security configurations, and KMS key settings.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_91\n\nLANGUAGE: yaml\nCODE:\n```\nEndpointConfig:\n# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpointConfig.html\n  AsyncInferenceConfig:\n    OutputConfig:\n      KmsKeyId: 'kmskeyid4'\n  DataCaptureConfig:\n    KmsKeyId: 'kmskeyid5'\n  KmsKeyId: 'kmskeyid6'\n  ProductionVariants:\n    - CoreDumpConfig:\n        KmsKeyId: 'kmskeyid7'\n  Tags:\n  - Key: 'tag_key'\n    Value: 'tag_value'\nAutoMLJob:\n# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateAutoMLJob.html\n  AutoMLJobConfig:\n    SecurityConfig:\n      VolumeKmsKeyId: 'volumekmskeyid3'\n      VpcConfig:\n        SecurityGroupIds:\n          - 'sg123'\n        Subnets:\n          - 'subnet-1234'\n  OutputDataConfig:\n    KmsKeyId: 'kmskeyid8'\n  RoleArn: 'arn:aws:iam::555555555555:role/IMRole'\n  Tags:\n  - Key: 'tag_key'\n    Value: 'tag_value'\nTransformJob:\n# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTransformJob.html\n  DataCaptureConfig:\n    KmsKeyId: 'kmskeyid9'\n  Environment:\n    'var1': 'value1'\n    'var2': 'value2'\n  TransformOutput:\n    KmsKeyId: 'kmskeyid10'\n  TransformResources:\n    VolumeKmsKeyId: 'volumekmskeyid4'\n  Tags:\n  - Key: 'tag_key'\n    Value: 'tag_value\nCompilationJob:\n# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateCompilationJob.html\n  OutputConfig:\n    # Currently not supported by the SageMaker Python SDK\n    KmsKeyId: 'kmskeyid11'\n  RoleArn: 'arn:aws:iam::555555555555:role/IMRole'\n  # Currently not supported by the SageMaker Python SDK\n  VpcConfig:\n    SecurityGroupIds:\n      - 'sg123'\n    Subnets:\n      - 'subnet-1234'\n  Tags:\n  - Key: 'tag_key'\n    Value: 'tag_value'\nPipeline:\n# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreatePipeline.html\n  RoleArn: 'arn:aws:iam::555555555555:role/IMRole'\n  Tags:\n  - Key: 'tag_key'\n    Value: 'tag_value'\nModel:\n# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateModel.html\n  Containers:\n    - Environment:\n        'var1': 'value1'\n        'var2': 'value2'\n  EnableNetworkIsolation: true\n  ExecutionRoleArn: 'arn:aws:iam::555555555555:role/IMRole'\n  VpcConfig:\n    SecurityGroupIds:\n      - 'sg123'\n    Subnets:\n      - 'subnet-1234'\n  Tags:\n  - Key: 'tag_key'\n    Value: 'tag_value'\nModelPackage:\n  InferenceSpecification:\n    Containers:\n      - Environment:\n          'var1': 'value1'\n          'var2': 'value2'\n  ValidationSpecification:\n    ValidationProfiles:\n      - TransformJobDefinition:\n          Environment:\n            'var1': 'value1'\n            'var2': 'value2'\n          TransformOutput:\n            KmsKeyId: 'kmskeyid12'\n          TransformResources:\n            VolumeKmsKeyId: 'volumekmskeyid5'\n    ValidationRole: 'arn:aws:iam::555555555555:role/IMRole'\nProcessingJob:\n# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateProcessingJob.html\n  Environment:\n    'var1': 'value1'\n    'var2': 'value2'\n  NetworkConfig:\n    EnableNetworkIsolation: true\n    VpcConfig:\n      SecurityGroupIds:\n        - 'sg123'\n      Subnets:\n        - 'subnet-1234'\n  ProcessingInputs:\n    - DatasetDefinition:\n        AthenaDatasetDefinition:\n          KmsKeyId: 'kmskeyid13'\n        RedshiftDatasetDefinition:\n          KmsKeyId: 'kmskeyid14'\n          ClusterRoleArn: 'arn:aws:iam::555555555555:role/IMRole'\n  ProcessingOutputConfig:\n    KmsKeyId: 'kmskeyid13'\n  ProcessingResources:\n    ClusterConfig:\n      VolumeKmsKeyId: 'volumekmskeyid6'\n  RoleArn: 'arn:aws:iam::555555555555:role/IMRole'\n  Tags:\n  - Key: 'tag_key'\n    Value: 'tag_value'\nTrainingJob:\n# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html\n  EnableNetworkIsolation: true\n  Environment:\n    'var1': 'value1'\n    'var2': 'value2'\n  OutputDataConfig:\n    KmsKeyId: 'kmskeyid14'\n  ProfilerConfig:\n    DisableProfiler: false\n  ResourceConfig:\n    VolumeKmsKeyId: 'volumekmskeyid7'\n  RoleArn: 'arn:aws:iam::555555555555:role/IMRole'\n  VpcConfig:\n    SecurityGroupIds:\n      - 'sg123'\n    Subnets:\n      - 'subnet-1234'\n  Tags:\n  - Key: 'tag_key'\n    Value: 'tag_value'\nEdgePackagingJob:\n# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEdgePackagingJob.html\n  OutputConfig:\n    KmsKeyId: 'kmskeyid15'\n  RoleArn: 'arn:aws:iam::555555555555:role/IMRole'\n  ResourceKey: 'resourcekmskeyid'\n  Tags:\n  - Key: 'tag_key'\n    Value: 'tag_value'\n```\n\n----------------------------------------\n\nTITLE: Limiting Records in Result Sets from SageMaker Feature Store with Python\nDESCRIPTION: Limits the number of records returned from the feature store query using with_number_of_records_from_query_results method.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndataset_builder.with_number_of_records_from_query_results(number_of_records=N)\n```\n\n----------------------------------------\n\nTITLE: Custom Request Handler Implementation for TensorFlow Serving\nDESCRIPTION: Example implementation of a complete handler function that gives full control over the TensorFlow Serving request lifecycle, including custom processing of both inputs and outputs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nimport json\nimport requests\n\n\ndef handler(data, context):\n    \"\"\"Handle request.\n    Args:\n        data (obj): the request data\n        context (Context): an object containing request and configuration details\n    Returns:\n        (bytes, string): data to return to client, (optional) response content type\n    \"\"\"\n    processed_input = _process_input(data, context)\n    response = requests.post(context.rest_uri, data=processed_input)\n    return _process_output(response, context)\n\n\ndef _process_input(data, context):\n    if context.request_content_type == 'application/json':\n        # pass through json (assumes it's correctly formed)\n        d = data.read().decode('utf-8')\n        return d if len(d) else ''\n\n    if context.request_content_type == 'text/csv':\n        # very simple csv handler\n        return json.dumps({\n            'instances': [float(x) for x in data.read().decode('utf-8').split(',')]\n        })\n\n    raise ValueError('{\\\"error\\\": \"unsupported content type {}\"}}'.format(\n        context.request_content_type or \"unknown\"))\n\n\ndef _process_output(data, context):\n    if data.status_code != 200:\n        raise ValueError(data.content.decode('utf-8'))\n\n    response_content_type = context.accept_header\n    prediction = data.content\n    return prediction, response_content_type\n```\n\n----------------------------------------\n\nTITLE: Implementing model_fn for PyTorch Elastic Inference 1.5.1\nDESCRIPTION: Shows how to implement model_fn for PyTorch Elastic Inference 1.5.1 using the attach_eia API. This allows inference to be accelerated with AWS Elastic Inference.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport torch\n\n\ndef model_fn(model_dir):\n    model = torch.jit.load('model.pth', map_location=torch.device('cpu'))\n    if torch.__version__ == '1.5.1':\n        import torcheia\n        model = model.eval()\n        # attach_eia() is introduced in PyTorch Elastic Inference 1.5.1,\n        model = torcheia.jit.attach_eia(model, 0)\n    return model\n```\n\n----------------------------------------\n\nTITLE: Using JSON Serialization for TensorFlow Model Predictions in SageMaker\nDESCRIPTION: This code snippet shows how to use JSON serialization and deserialization for TensorFlow model predictions in SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.deserializers import JSONDeserializer\nfrom sagemaker.serializers import JSONSerializer\n\npredictor = model.deploy(..., serializer=JSONSerializer(), deserializer=JSONDeserializer())\n\npredictor.predict(data)\n```\n\n----------------------------------------\n\nTITLE: Disabling Debugger Hook Configuration in TensorFlow Estimator\nDESCRIPTION: This code shows how to disable the default debugger hook configuration when initializing a TensorFlow estimator. It sets the debugger_hook_config parameter to False to opt out of automatic hook initialization.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nestimator = TensorFlow(\n    role=role,\n    instance_count=1,\n    instance_type=instance_type,\n    debugger_hook_config=False\n)\n```\n\n----------------------------------------\n\nTITLE: Using a Predictor with JSON Result Format in SageMaker\nDESCRIPTION: Example showing the result format from a SageMaker predictor.predict() call, which returns predictions in a JSON format containing an array of prediction values.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nresult = predictor.predict(input)\n\n# result contains:\n{\n  'predictions': [\n    [3.5, 4.0, 5.5],\n    [3.5, 4.0, 5.5],\n    [3.5, 4.0, 5.5]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using Remote Function Decorator to Run ML Code on SageMaker\nDESCRIPTION: Demonstrates how to use the @remote decorator to run local ML code on SageMaker infrastructure, executing a simple matrix multiplication function on a specified instance type.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_105\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.remote_function import remote\nimport numpy as np\n\n@remote(instance_type=\"ml.m5.large\")\ndef matrix_multiply(a, b):\n    return np.matmul(a, b)\n\na = np.array([[1, 0],\n             [0, 1]])\nb = np.array([1, 2])\n\nassert (matrix_multiply(a, b) == np.array([1,2])).all()\n```\n\n----------------------------------------\n\nTITLE: Creating Additional Predictors for Different Models on the Same Endpoint\nDESCRIPTION: Demonstrates how to create additional Predictor instances for different models deployed to the same SageMaker endpoint. It retrieves the endpoint name from the existing predictor and creates a new predictor for a different model named 'model2'.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# ... continuing from the previous example\n\n# get the endpoint name from the default predictor\nendpoint = predictor.endpoint_name\n\n# get a predictor for 'model2'\nmodel2_predictor = Predictor(endpoint, model_name='model2')\n\n# note: that will for actual SageMaker endpoints, but if you are using\n# local mode you need to create the new Predictor this way:\n#\n# model2_predictor = Predictor(endpoint, model_name='model2'\n#                              sagemaker_session=predictor.sagemaker_session)\n\n\n# result is prediction from 'model2'\nresult = model2_predictor.predict(...)\n```\n\n----------------------------------------\n\nTITLE: Package Dependencies List for AWS SageMaker\nDESCRIPTION: Defines specific versions of Python packages required for AWS SageMaker functionality. Includes ML frameworks (MLflow, PyTorch), data processing libraries (numpy, pandas), and utility packages (requests, tqdm). Version constraints ensure compatibility and stability.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/serve_resources/mlflow/pytorch/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmlflow==2.13.2\nastunparse==1.6.3\ncffi==1.16.0\ncloudpickle==2.2.1\ndefusedxml==0.7.1\ndill==0.3.9\ngmpy2==2.1.2\nnumpy==1.26.4\nopt-einsum==3.3.0\npackaging>=23.0,<25\npandas==2.2.1\npyyaml==6.0.1\nrequests==2.32.2\ntorch>=2.6.0\ntorchvision>=0.17.0\ntqdm==4.66.3\n```\n\n----------------------------------------\n\nTITLE: Accessing Debugger Artifacts and Downloading from S3 in SageMaker\nDESCRIPTION: This code shows how to start model training with Debugger enabled and then access the emitted debugging data. It demonstrates how to retrieve the S3 path to debugging artifacts and list available files using the S3Downloader utility.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.s3 import S3Downloader\n\n# Start the training by calling fit\n# Setting the wait to `False` would make the fit asynchronous\nestimator.fit(wait=False)\n\n# Get a list of S3 URIs\nS3Downloader.list(estimator.latest_job_debugger_artifacts_path())\n```\n\n----------------------------------------\n\nTITLE: Retrieving Default Instance Type in SageMaker\nDESCRIPTION: Code to retrieve the default deployment instance type for a JumpStart model using the instance_types utility.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import instance_types\n\ninstance_type = instance_types.retrieve_default(\n    model_id=model_id,\n    model_version=model_version,\n    scope=\"inference\")\nprint(instance_type)\n```\n\n----------------------------------------\n\nTITLE: Including Deleted or Duplicated Records in SageMaker Feature Store Dataset\nDESCRIPTION: Configures the DatasetBuilder to include deleted or duplicated records that are excluded by default when creating datasets.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndataset_builder.include_duplicated_records()\ndataset_builder.include_deleted_records()\n```\n\n----------------------------------------\n\nTITLE: Using FileSystemRecordSet with EFS for SageMaker Training Jobs\nDESCRIPTION: Example of configuring and running a KMeans training job using EFS as input through the FileSystemRecordSet class. Requires subnet and security group configuration to access the EFS volume that must be in the same VPC as the EC2 instance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# This example shows how to use FileSystemRecordSet class\n# Configure an estimator with subnets and security groups from your VPC. The EFS volume must be in\n# the same VPC as your Amazon EC2 instance\nkmeans = KMeans(role='SageMakerRole',\n                instance_count=1,\n                instance_type='ml.c4.xlarge',\n                k=10,\n                subnets=['subnet-1', 'subnet-2'],\n                security_group_ids=['sg-1'])\n\nrecords = FileSystemRecordSet(file_system_id='fs-1,\n                              file_system_type='EFS',\n                              directory_path='/kmeans',\n                              num_records=784,\n                              feature_dim=784)\n\n# Start an Amazon SageMaker training job with EFS using the FileSystemRecordSet class\nkmeans.fit(records)\n```\n\n----------------------------------------\n\nTITLE: Accessing TensorBoard S3 Output Path in Python\nDESCRIPTION: This code snippet shows how to retrieve the S3 path where TensorBoard data is stored after a training job. It uses the estimator's method to get the latest job's TensorBoard artifacts path.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntensorboard_s3_output_path = estimator.latest_job_tensorboard_artifacts_path()\n```\n\n----------------------------------------\n\nTITLE: Saving MXNet Model Checkpoints in SageMaker Training Script\nDESCRIPTION: This code snippet shows how to implement checkpoint saving in an MXNet training script for SageMaker. It sets up the checkpoint directory, checks if checkpointing is enabled, and saves the best model after each epoch.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nCHECKPOINTS_DIR = '/opt/ml/checkpoints'\ncheckpoints_enabled = os.path.exists(CHECKPOINTS_DIR)\n\nif checkpoints_enabled and current_host == hosts[0]:\n       if val_acc > best_accuracy:\n           best_accuracy = val_acc\n           logging.info('Saving the model, params and optimizer state')\n           net.export(CHECKPOINTS_DIR + \"/%.4f-cifar10\"%(best_accuracy), epoch)\n           trainer.save_states(CHECKPOINTS_DIR + '/%.4f-cifar10-%d.states'%(best_accuracy, epoch))\n```\n\n----------------------------------------\n\nTITLE: Displaying XGBoost Docker Container Dependencies\nDESCRIPTION: This code snippet shows a table of dependencies and their versions for the XGBoost Docker container used in SageMaker. It includes important libraries like xgboost, numpy, pandas, and scikit-learn, along with their respective versions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/xgboost/README.rst#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n+-----------------------------+-------------+\n| Dependencies                | Version     |\n+-----------------------------+-------------+\n| xgboost                     | 0.90.0      |\n+-----------------------------+-------------+\n| matplotlib                  | 3.0.3+      |\n+-----------------------------+-------------+\n| numpy                       | 1.16.4+     |\n+-----------------------------+-------------+\n| pandas                      | 0.24.2+     |\n+-----------------------------+-------------+\n| psutils                     | 5.6.3+      |\n+-----------------------------+-------------+\n| PyYAML                      | < 4.3       |\n+-----------------------------+-------------+\n| requests                    | < 2.21      |\n+-----------------------------+-------------+\n| retrying                    | 1.3.3       |\n+-----------------------------+-------------+\n| scikit-learn                | 0.21.2+     |\n+-----------------------------+-------------+\n| scipy                       | 1.3.0+      |\n+-----------------------------+-------------+\n| sagemaker-containers        | 2.5.1+      |\n+-----------------------------+-------------+\n| urllib3                     | < 1.25      |\n+-----------------------------+-------------+\n| Python                      | 2.7 or 3.5  |\n+-----------------------------+-------------+\n```\n\n----------------------------------------\n\nTITLE: Creating a CSV Serializer Predictor in SageMaker\nDESCRIPTION: Example showing how to create a Predictor with CSV serialization for sending comma-separated data to a SageMaker endpoint, and the expected result format.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n# create a Predictor with JSON serialization\n\npredictor = Predictor('endpoint-name', serializer=sagemaker.serializers.CSVSerializer())\n\n# CSV-formatted string input\ninput = '1.0,2.0,5.0\\n1.0,2.0,5.0\\n1.0,2.0,5.0'\n\nresult = predictor.predict(input)\n\n# result contains:\n{\n  'predictions': [\n    [3.5, 4.0, 5.5],\n    [3.5, 4.0, 5.5],\n    [3.5, 4.0, 5.5]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using DistributedOptimizer with TensorFlow optimizer\nDESCRIPTION: Shows how to wrap an existing TensorFlow optimizer with the smdistributed DistributedOptimizer to enable distributed training. This is applicable when using the tf.estimator API in TensorFlow 2.x.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nopt = ... # existing optimizer from tf.train package or your custom optimizer\nopt = smdistributed.dataparallel.tensorflow.DistributedOptimizer(opt)\n```\n\n----------------------------------------\n\nTITLE: Using PCA Estimator with RecordSet in Python\nDESCRIPTION: This snippet demonstrates how to create a PCA estimator, prepare input data using RecordSet, and fit the model. It shows the usage of the record_set function to convert numpy array data into the required format for SageMaker algorithms.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/amazon/README.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import PCA\npca_estimator = PCA(role='SageMakerRole', instance_count=1, instance_type='ml.m4.xlarge', num_components=3)\n\nimport numpy as np\nrecords = pca_estimator.record_set(np.arange(10).reshape(2,5))\n\npca_estimator.fit(records)\n```\n\n----------------------------------------\n\nTITLE: Preparing Multi-Model Archive for TensorFlow Serving in Bash\nDESCRIPTION: This bash script demonstrates how to download, extract, repackage, and upload multiple TensorFlow SavedModels into a single archive file for deployment to a SageMaker endpoint supporting multiple models.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\naws s3 cp s3://mybucket/models/model1/model.tar.gz model1.tar.gz\naws s3 cp s3://mybucket/models/model2/model.tar.gz model2.tar.gz\nmkdir -p multi/model1\nmkdir -p multi/model2\n\ntar xvf model1.tar.gz -C ./multi/model1\ntar xvf model2.tar.gz -C ./multi/model2\n\nmv multi/model1/export/Servo/* multi/model1/\nmv multi/model2/export/Servo/* multi/model2/\nrm -fr multi/model1/export\nrm -fr multi/model2/export\n\ntar -C \"$PWD/multi/\" -czvf multi.tar.gz multi/\n\naws s3 cp multi.tar.gz s3://mybucket/models/multi.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Accessing Property File Values with JsonGet in SageMaker Pipelines (Python)\nDESCRIPTION: Example of using JsonGet to query a value from a property file. This demonstrates how to extract the 'eta' value from the hyperparameter report using JsonPath notation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\neta = JsonGet(\n step_name=step_process.name,\n property_file=hyperparam_report,\n json_path=\"hyperparam.eta.value\",\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring SageMaker Profiler with PyTorch Estimator\nDESCRIPTION: Example demonstrating how to activate and configure Amazon SageMaker Profiler with a PyTorch estimator. The code sets up a ProfilerConfig with custom CPU profiling duration of 3600 seconds.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/profiler.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport sagemaker\nfrom sagemaker.pytorch import PyTorch\nfrom sagemaker import ProfilerConfig, Profiler\n\nprofiler_config = ProfilerConfig(\n    profiler_params = Profiler(cpu_profiling_duration=3600)\n)\n\nestimator = PyTorch(\n    framework_version=\"2.0.0\",\n    ... # Set up other essential parameters for the estimator class\n    profiler_config=profiler_config\n)\n```\n\n----------------------------------------\n\nTITLE: Joining Feature Groups to Create Datasets in SageMaker with Python\nDESCRIPTION: Joins multiple feature groups to create a comprehensive dataset by using the with_feature_group method on a dataset builder.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndataset_builder = feature_store.create_dataset(\n   base=base_feature_group,\n   output_path=f\"s3://{s3_bucket_name}\"\n).with_feature_group(target_feature_group, record_identifier_name)\n\nresult_df, query = dataset_builder.to_dataframe()\n```\n\n----------------------------------------\n\nTITLE: Using Git Repository with SageMaker Estimator (HTTPS with No Credentials)\nDESCRIPTION: Shows how to create an estimator that uses a source script stored in a GitHub repository using HTTPS URL without explicit credentials. This example will try to use local credential storage for authentication.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Specifies the git_config parameter. This example does not provide Git credentials, so python SDK will try\n# to use local credential storage.\ngit_config = {'repo': 'https://github.com/username/repo-with-training-scripts.git',\n              'branch': 'branch1',\n              'commit': '4893e528afa4a790331e1b5286954f073b0f14a2'}\n\n# In this example, the source directory 'pytorch' contains the entry point 'mnist.py' and other source code.\n# and it is relative path inside the Git repo.\npytorch_estimator = PyTorch(entry_point='mnist.py',\n                            role='SageMakerRole',\n                            source_dir='pytorch',\n                            git_config=git_config,\n                            instance_count=1,\n                            instance_type='ml.c4.xlarge')\n```\n\n----------------------------------------\n\nTITLE: Custom Schema Builder Configuration\nDESCRIPTION: Shows how to configure SchemaBuilder with custom translators for input and output processing.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nmy_schema = SchemaBuilder(\n    sample_input=image,\n    sample_output=output,\n    input_translator=MyRequestTranslator(),\n    output_translator=MyResponseTranslator()\n)\n```\n\n----------------------------------------\n\nTITLE: Using Git Repository with SageMaker Estimator (Token Authentication with 2FA)\nDESCRIPTION: Demonstrates using a GitHub repository with token-based authentication when two-factor authentication (2FA) is enabled. This approach is required when 2FA is active and shows how to use a local instance for training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# This example specifies that 2FA is enabled, and token is provided for authentication\ngit_config = {'repo': 'https://github.com/username/repo-with-training-scripts.git',\n              '2FA_enabled': True,\n              'token': 'your-token'}\n\n# In this exmaple, besides entry point, we also need some dependencies for the training job.\npytorch_estimator = PyTorch(entry_point='pytorch/mnist.py',\n                            role='SageMakerRole',\n                            dependencies=['dep.py'],\n                            git_config=git_config,\n                            instance_count=1,\n                            instance_type='local')\n```\n\n----------------------------------------\n\nTITLE: Creating and Deploying TensorFlow Model with Custom Predictor in SageMaker Python SDK v2.0+\nDESCRIPTION: This code snippet shows how to create and deploy a TensorFlow model with a custom predictor class using version 2.0 or later of the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.model import FrameworkModel\nfrom sagemaker.predictor import Predictor\n\nmodel = FrameworkModel(\n    ...\n    predictor_cls=Predictor,\n)\n\npredictor = model.deploy(...)\n```\n\n----------------------------------------\n\nTITLE: Attaching a PyTorch Estimator to an Existing Training Job\nDESCRIPTION: This code shows how to attach a PyTorch Estimator to an existing training job in SageMaker using the attach method. This allows you to interact with a previously run training job.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nmy_training_job_name = 'MyAwesomePyTorchTrainingJob'\npytorch_estimator = PyTorch.attach(my_training_job_name)\n```\n\n----------------------------------------\n\nTITLE: Initializing a SageMaker Pipeline Model with SparkML and XGBoost Models in Python\nDESCRIPTION: Creates a PipelineModel object that combines a SparkML model and an XGBoost model sequentially for inference. The model is named and assigned an IAM role for execution permissions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_88\n\nLANGUAGE: python\nCODE:\n```\nendpoint_name = \"inference-pipeline-endpoint\"\nsm_model = PipelineModel(name=model_name, role=sagemaker_role, models=[sparkml_model, xgb_model])\n```\n\n----------------------------------------\n\nTITLE: Attaching to Existing Chainer Training Jobs in SageMaker\nDESCRIPTION: Code example showing how to attach to an existing Chainer training job using the attach method. This allows you to access a training job that's either in progress or completed.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmy_training_job_name = \"MyAwesomeChainerTrainingJob\"\nchainer_estimator = Chainer.attach(my_training_job_name)\n```\n\n----------------------------------------\n\nTITLE: Running PySpark Processing Job with Dependencies\nDESCRIPTION: Executes a PySpark script as a processing job with various dependencies like module files, JAR files, and additional files. The example shows how to pass arguments to the script and configure Spark event logging for monitoring with Spark History Server.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_processing.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nspark_processor.run(\n    submit_app=\"preprocess.py\",\n    submit_py_files=[\"module.py\", \"lib.egg\"],\n    submit_jars=[\"lib.jar\", \"lib2.jar\"],\n    submit_files=[\"file.txt\", \"file2.csv\"],\n    arguments=[\"s3_input_bucket\", bucket,\n               \"s3_input_key_prefix\", input_prefix,\n               \"s3_output_bucket\", bucket,\n               \"s3_output_key_prefix\", input_preprocessed_prefix],\n    spark_event_logs_s3_uri=\"s3://your-bucket/your-prefix/store-spark-events\"\n)\n```\n\n----------------------------------------\n\nTITLE: Downloading SageMaker Data Parallel Library Wheel for PyTorch 2.0.0\nDESCRIPTION: URL to download the SageMaker distributed data parallelism library v1.8.0 wheel file for PyTorch 2.0.0 in custom containers.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nhttps://smdataparallel.s3.amazonaws.com/binary/pytorch/2.0.0/cu118/2023-03-20/smdistributed_dataparallel-1.8.0-cp310-cp310-linux_x86_64.whl\n```\n\n----------------------------------------\n\nTITLE: Creating Python Operator DAG for SageMaker Workflow\nDESCRIPTION: Shows how to create an Airflow DAG using PythonOperator to execute SageMaker operations. Includes DAG setup, operator configuration, and task dependency definition.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/using_workflow.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport airflow\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': airflow.utils.dates.days_ago(2),\n    'provide_context': True\n}\n\ndag = DAG('tensorflow_example', default_args=default_args,\n          schedule_interval='@once')\n\ntrain_op = PythonOperator(\n    task_id='training',\n    python_callable=train,\n    op_args=[training_data_s3_uri],\n    provide_context=True,\n    dag=dag)\n\ntransform_op = PythonOperator(\n    task_id='transform',\n    python_callable=transform,\n    op_args=[transform_data_s3_uri],\n    provide_context=True,\n    dag=dag)\n\ntransform_op.set_upstream(train_op)\n```\n\n----------------------------------------\n\nTITLE: Creating SageMaker Model Instance\nDESCRIPTION: Code to create a SageMaker Model instance using retrieved URIs and configuration parameters.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.model import Model\nfrom sagemaker.predictor import Predictor\nfrom sagemaker.session import Session\n\nmodel = Model(\n    image_uri=image_uri,\n    model_data=base_model_uri,\n    source_dir=script_uri,\n    entry_point=\"inference.py\",\n    role=Session().get_caller_identity_arn(),\n    predictor_cls=Predictor,\n    enable_network_isolation=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Deploying a Pretrained MXNet Model to a SageMaker Endpoint\nDESCRIPTION: Creates an MXNetModel object from a pretrained model stored in S3 and deploys it to a SageMaker endpoint. This approach is useful when you want to deploy models that weren't trained within SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmxnet_model = MXNetModel(model_data='s3://my_bucket/pretrained_model/model.tar.gz',\n                         role=role,\n                         entry_point='inference.py',\n                         framework_version='1.6.0',\n                         py_version='py3')\npredictor = mxnet_model.deploy(instance_type='ml.m4.xlarge',\n                               initial_instance_count=1)\n```\n\n----------------------------------------\n\nTITLE: Enabling Network Isolation Mode in SageMaker Training\nDESCRIPTION: This snippet demonstrates how to enable network isolation (internet-free) mode for a SageMaker SKLearn estimator by setting the enable_network_isolation parameter to True, which prevents any inbound or outbound network calls during training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_86\n\nLANGUAGE: python\nCODE:\n```\n# set the enable_network_isolation parameter to True\nsklearn_estimator = SKLearn('sklearn-train.py',\n                            instance_type='ml.m4.xlarge',\n                            framework_version='0.20.0',\n                            hyperparameters = {'epochs': 20, 'batch-size': 64, 'learning-rate': 0.1},\n                            enable_network_isolation=True)\n\n# SageMaker Training Job will in the container without   any inbound or outbound network calls during runtime\nsklearn_estimator.fit({'train': 's3://my-data-bucket/path/to/my/training/data',\n                        'test': 's3://my-data-bucket/path/to/my/test/data'})\n```\n\n----------------------------------------\n\nTITLE: Disabling MKL-DNN Optimization for TensorFlow in SageMaker\nDESCRIPTION: This code shows how to disable MKL-DNN optimization for TensorFlow CPU images in SageMaker by setting specific environment variables.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nos.environ['TF_DISABLE_MKL'] = '1'\nos.environ['TF_DISABLE_POOL_ALLOCATOR'] = '1'\n```\n\n----------------------------------------\n\nTITLE: Implementing DistributedOptimizer with TensorFlow\nDESCRIPTION: Example demonstrating how to wrap an existing TensorFlow optimizer with DistributedOptimizer for distributed training scenarios using tf.estimator API in TensorFlow 2.x.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nopt = ... # existing optimizer from tf.train package or your custom optimizer\nopt = smdistributed.dataparallel.tensorflow.DistributedOptimizer(opt)\n```\n\n----------------------------------------\n\nTITLE: SageMaker Deployment Configuration from Estimator for Airflow\nDESCRIPTION: Configuration function to create deployment configuration from an estimator in SageMaker through Airflow\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/sagemaker.workflow.airflow.rst#2025-04-22_snippet_7\n\nLANGUAGE: rst\nCODE:\n```\n.. autofunction:: sagemaker.workflow.airflow.deploy_config_from_estimator\n```\n\n----------------------------------------\n\nTITLE: Attaching MXNet Estimator to Existing Training Job in Python\nDESCRIPTION: Demonstrates how to attach an MXNet Estimator to an existing training job using the 'attach' method. This allows interaction with completed or in-progress training jobs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nmy_training_job_name = 'MyAwesomeMXNetTrainingJob'\nmxnet_estimator = MXNet.attach(my_training_job_name)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Model with Requirements File in SageMaker Python SDK v2.0+\nDESCRIPTION: This snippet demonstrates how to create a TensorFlow model with a requirements file using version 2.0 or later of the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.model import FrameworkModel\n\nmodel = FrameworkModel(\n    ...\n    source_dir=\"code\",\n    env={\"SAGEMAKER_REQUIREMENTS\": \"requirements.txt\"},\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Processing Step with Caching in SageMaker Pipelines\nDESCRIPTION: This example demonstrates how to create a processing step with caching enabled in a SageMaker Pipeline. It configures an SKLearnProcessor with inputs, outputs, and caching to optimize pipeline execution by reusing previous step results when inputs haven't changed.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.workflow.pipeline_context import PipelineSession\nfrom sagemaker.sklearn.processing import SKLearnProcessor\nfrom sagemaker.workflow.steps import ProcessingStep\nfrom sagemaker.dataset_definition.inputs import S3Input\nfrom sagemaker.processing import ProcessingInput, ProcessingOutput\n\npipeline_session = PipelineSession()\n\nframework_version = \"0.23-1\"\n\nsklearn_processor = SKLearnProcessor(\n    framework_version=framework_version,\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=processing_instance_count,\n    role=role,\n    sagemaker_session=pipeline_session\n)\n\nprocessor_args = sklearn_processor.run(\n    inputs=[\n        ProcessingInput(\n            source=\"artifacts/data/abalone-dataset.csv\",\n            input_name=\"abalone-dataset\",\n            s3_input=S3Input(\n                local_path=\"/opt/ml/processing/input\",\n                s3_uri=\"artifacts/data/abalone-dataset.csv\",\n                s3_data_type=\"S3Prefix\",\n                s3_input_mode=\"File\",\n                s3_data_distribution_type=\"FullyReplicated\",\n                s3_compression_type=\"None\",\n            )\n        )\n    ],\n    outputs=[\n        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n    ],\n    code=\"artifacts/code/process/preprocessing.py\",\n)\n\nprocessing_step = ProcessingStep(\n    name=\"Process\",\n    step_args=processor_args,\n    cache_config=cache_config\n)\n```\n\n----------------------------------------\n\nTITLE: Defining SageMaker Python Callables for Airflow\nDESCRIPTION: Implements Python callable functions for SageMaker training and transform operations that can be used with Airflow's PythonOperator. Includes TensorFlow estimator setup and transformation logic.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/using_workflow.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\ndef train(data, **context):\n    estimator = TensorFlow(entry_point='tf_train.py',\n                           role='sagemaker-role',\n                           framework_version='1.11.0',\n                           training_steps=1000,\n                           evaluation_steps=100,\n                           instance_count=2,\n                           instance_type='ml.p2.xlarge')\n    estimator.fit(data)\n    return estimator.latest_training_job.job_name\n\ndef transform(data, **context):\n    training_job = context['ti'].xcom_pull(task_ids='training')\n    estimator = TensorFlow.attach(training_job)\n    transformer = estimator.transformer(instance_count=1, instance_type='ml.c4.xlarge')\n    transformer.transform(data, content_type='text/csv')\n```\n\n----------------------------------------\n\nTITLE: Downloading SageMaker Data Parallel Library Wheel for PyTorch 1.13.1\nDESCRIPTION: URL to download the SageMaker distributed data parallelism library v1.7.0 wheel file for PyTorch 1.13.1 in custom containers.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nhttps://smdataparallel.s3.amazonaws.com/binary/pytorch/1.13.1/cu117/2023-01-09/smdistributed_dataparallel-1.7.0-cp39-cp39-linux_x86_64.whl\n```\n\n----------------------------------------\n\nTITLE: Custom input_fn Implementation for Pickled NumPy Arrays\nDESCRIPTION: Example of a custom input_fn function that handles pickled NumPy arrays. This function deserializes the request body based on the content type and returns a NumPy array that can be used for prediction.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\ndef input_fn(request_body, request_content_type):\n    \"\"\"An input_fn that loads a pickled numpy array\"\"\"\n    if request_content_type == \"application/python-pickle\":\n        array = np.load(StringIO(request_body))\n        return array\n    else:\n        # Handle other content-types here or raise an Exception\n        # if the content type is not supported.\n        pass\n```\n\n----------------------------------------\n\nTITLE: Creating Chainer Estimator and Training Model in Python\nDESCRIPTION: This snippet demonstrates how to create a Chainer estimator using the SageMaker Python SDK and start the training process. It specifies the training script, instance type, hyperparameters, and input data channels.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nchainer_estimator = Chainer('chainer-train.py',\n                            instance_type='ml.p3.2xlarge',\n                            instance_count=1,\n                            framework_version='5.0.0',\n                            py_version='py3',\n                            hyperparameters = {'epochs': 20, 'batch-size': 64, 'learning-rate': 0.1})\nchainer_estimator.fit({'train': 's3://my-data-bucket/path/to/my/training/data',\n                       'test': 's3://my-data-bucket/path/to/my/test/data'})\n```\n\n----------------------------------------\n\nTITLE: Launching Distributed PyTorch Training on Multiple Trainium Instances\nDESCRIPTION: This example demonstrates how to set up a PyTorch estimator for distributed training on two ml.trn1.32xlarge instances using the torch_distributed option.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.pytorch import PyTorch\n\npt_estimator = PyTorch(\n    entry_point=\"train_torch_distributed.py\",\n    role=\"SageMakerRole\",\n    framework_version=\"1.11.0\",\n    py_version=\"py38\",\n    instance_count=2,\n    instance_type=\"ml.trn1.32xlarge\",\n    distribution={\n        \"torch_distributed\": {\n            \"enabled\": True\n        }\n    }\n)\n\npt_estimator.fit(\"s3://bucket/path/to/training/data\")\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom transform_fn for MXNet Model Serving\nDESCRIPTION: Signature for a custom transform_fn that handles the entire inference process in a single function. This combines input processing, prediction, and output formatting, as an alternative to using separate functions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef transform_fn(model, request_body, content_type, accept_type)\n```\n\n----------------------------------------\n\nTITLE: Overriding SageMaker Configuration File Locations Using Environment Variables\nDESCRIPTION: Example showing how to override the default user configuration file location by setting the SAGEMAKER_USER_CONFIG_OVERRIDE environment variable within a Jupyter notebook environment.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_95\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = \"<path-to-config>\"\n```\n\n----------------------------------------\n\nTITLE: Initializing SageMaker Session with Custom Configuration\nDESCRIPTION: Demonstrates how to initialize a SageMaker Session object with a customized configuration dictionary to override default settings.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_104\n\nLANGUAGE: python\nCODE:\n```\nsm_session = Session(\n    sagemaker_config = custom_sagemaker_config\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation for SageMaker Instance Group Module\nDESCRIPTION: Sphinx documentation configuration directive that specifies how to generate documentation for the sagemaker.instance_group module. It includes settings to document all members, show inheritance relationships, and include private members.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/instance_group.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.instance_group\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :private-members:\n```\n\n----------------------------------------\n\nTITLE: Attaching to Existing Scikit-learn Training Job in SageMaker using Python\nDESCRIPTION: This code demonstrates how to attach a Scikit-learn Estimator to an existing SageMaker training job. It allows you to interact with a completed or in-progress training job, and deploy the model if the job is complete.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmy_training_job_name = \"MyAwesomeSKLearnTrainingJob\"\nsklearn_estimator = SKLearn.attach(my_training_job_name)\n```\n\n----------------------------------------\n\nTITLE: Custom predict_fn Implementation for Chainer Models\nDESCRIPTION: Example of a custom predict_fn function skeleton that would process input data and return predictions from a Chainer model. This function would be called after input_fn and before output_fn in the inference pipeline.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport chainer\nimport numpy as np\n\ndef predict_fn(input_data, model):\n```\n\n----------------------------------------\n\nTITLE: Saving a PyTorch Model for Elastic Inference in TorchScript Format\nDESCRIPTION: Code example demonstrating how to save a PyTorch model in TorchScript format for Elastic Inference deployment in SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport torch\n\n# ... train `model`, then save it to `model_dir`\nmodel_dir = os.path.join(model_dir, \"model.pt\")\ntorch.jit.save(model, model_dir)\n```\n\n----------------------------------------\n\nTITLE: Starting RL Training Job with RLEstimator in Python\nDESCRIPTION: This snippet shows how to start a training job using the previously created RLEstimator object. The fit() method is called to begin the training process on SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/rl/using_rl.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nrl_estimator.fit()\n```\n\n----------------------------------------\n\nTITLE: Using EFA Network Interface\nDESCRIPTION: Reference to using the Elastic Fabric Adapter (EFA) network interface for distributed AllReduce operations on supported instance types ml.p3dn.24xlarge and ml.p4d.24xlarge.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nsmdistributed.dataparallel.efa\n```\n\n----------------------------------------\n\nTITLE: Retrieving Analytics from HyperparameterTuner in SageMaker\nDESCRIPTION: Shows how to access the analytics object associated with a HyperparameterTuner instance to retrieve information about the tuning job. This requires installing the SageMaker analytics dependencies with 'pip install sagemaker[analytics] --upgrade'.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_57\n\nLANGUAGE: python\nCODE:\n```\n# Retrieve analytics object\nmy_tuner_analytics = my_tuner.analytics()\n\n# Look at summary of associated training jobs\nmy_dataframe = my_tuner_analytics.dataframe()\n```\n\n----------------------------------------\n\nTITLE: Importing SageMaker Debugger Rule Configs\nDESCRIPTION: Helper module that provides configuration methods for SageMaker Debugger built-in rules using Rule and ProfilerRule classmethods. It enables setting up monitoring and debugging configurations for training jobs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/debugger.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.debugger import rule_configs\n```\n\n----------------------------------------\n\nTITLE: Creating AsyncInferenceConfig in Python for SageMaker Asynchronous Inference\nDESCRIPTION: Creates an empty AsyncInferenceConfig object with default values for S3OutputPath and S3FailurePath. This configuration is used to deploy an asynchronous inference endpoint in SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_58\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.async_inference import AsyncInferenceConfig\n\n# Create an empty AsyncInferenceConfig object to use default values\nasync_config = AsyncInferenceConfig()\n```\n\n----------------------------------------\n\nTITLE: Loading and Transforming Data for Feature Store\nDESCRIPTION: Demonstrates loading data from S3, performing basic data cleaning (rounding, filling NAs), and applying feature transformations (one-hot encoding) before ingestion into Feature Store.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport io\n\nfraud_detection_bucket_name = 'sagemaker-featurestore-fraud-detection'\nidentity_file_key = 'sampled_identity.csv'\ntransaction_file_key = 'sampled_transactions.csv'\n\nidentity_data_object = s3_client.get_object(Bucket=fraud_detection_bucket_name, Key=identity_file_key)\ntransaction_data_object = s3_client.get_object(Bucket=fraud_detection_bucket_name, Key=transaction_file_key)\n\nidentity_data = pd.read_csv(io.BytesIO(identity_data_object['Body'].read()))\ntransaction_data = pd.read_csv(io.BytesIO(transaction_data_object['Body'].read()))\n\nidentity_data = identity_data.round(5)\ntransaction_data = transaction_data.round(5)\n\nidentity_data = identity_data.fillna(0)\ntransaction_data = transaction_data.fillna(0)\n\n# Feature transformations for this dataset are applied before ingestion into FeatureStore.\n# One hot encode card4, card6\nencoded_card_bank = pd.get_dummies(transaction_data['card4'], prefix = 'card_bank')\nencoded_card_type = pd.get_dummies(transaction_data['card6'], prefix = 'card_type')\n\ntransformed_transaction_data = pd.concat([transaction_data, encoded_card_type, encoded_card_bank], axis=1)\ntransformed_transaction_data = transformed_transaction_data.rename(columns={\"card_bank_american express\": \"card_bank_american_express\"})\n```\n\n----------------------------------------\n\nTITLE: Specifying TensorFlow 2.5.0 Deep Learning Container in AWS ECR\nDESCRIPTION: Docker image URI for the AWS Deep Learning Container with TensorFlow 2.5.0 and the SageMaker distributed data parallelism library v1.2.1.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n763104351884.dkr.ecr.<region>.amazonaws.com/tensorflow-training:2.5.0-gpu-py37-cu112-ubuntu18.04-v1.0\n```\n\n----------------------------------------\n\nTITLE: Importing and Initializing SageMaker Distributed Data Parallel in PyTorch\nDESCRIPTION: Imports the SageMaker distributed data parallel library's PyTorch client and initializes the process group for distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport smdistributed.dataparallel.torch.distributed as dist\n\nfrom smdistributed.dataparallel.torch.parallel.distributed import DistributedDataParallel as DDP\n\ndist.init_process_group()\n```\n\n----------------------------------------\n\nTITLE: Documenting SageMaker Experiment Analytics in reStructuredText\nDESCRIPTION: Documentation directive for the ExperimentAnalytics class in the SageMaker Python SDK, which provides analytics functionality for SageMaker experiments, including all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/analytics.rst#2025-04-22_snippet_3\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. autoclass:: sagemaker.analytics.ExperimentAnalytics\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Importing SageMaker Distributed Data Parallel\nDESCRIPTION: Code reference showing the package import name change from smdataparallel to smdistributed.dataparallel. Both names appear in documentation, with smdistributed.dataparallel being the current recommended import.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport smdistributed.dataparallel\n```\n\n----------------------------------------\n\nTITLE: Handling Protobuf Prediction Data with TensorFlow Model in SageMaker\nDESCRIPTION: This code snippet demonstrates how to serialize and deserialize protobuf prediction data when using a TensorFlow model in SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom google.protobuf import json_format\nfrom protobuf_to_dict import protobuf_to_dict\nfrom tensorflow.core.framework import tensor_pb2\n\n# Serialize the prediction data\njson_format.MessageToJson(data)\n\n# Get the prediction result\nresult = predictor.predict(data)\n\n# Deserialize the prediction result\nprotobuf_to_dict(json_format.Parse(result, tensor_pb2.TensorProto()))\n```\n\n----------------------------------------\n\nTITLE: Using BroadcastGlobalVariablesHook with tf.estimator\nDESCRIPTION: Shows how to use the BroadcastGlobalVariablesHook with MonitoredTrainingSession to ensure consistent initialization of all workers across nodes. This is applicable when using the tf.estimator API in TensorFlow 2.x.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nhooks = [smdistributed.dataparallel.tensorflow.BroadcastGlobalVariablesHook(root_rank=0)]\n...\nwith tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,\n                                   hooks=hooks,\n                                   config=config) as mon_sess:\n     ...\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Specific Record from SageMaker Feature Store with Python\nDESCRIPTION: Retrieves a single record from a feature group by its record identifier using the get_record function.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nrecord_identifier_value = str(2990130)\nfeaturestore_runtime.get_record(FeatureGroupName=transaction_feature_group_name, RecordIdentifierValueAsString=record_identifier_value)\n```\n\n----------------------------------------\n\nTITLE: Creating and Modifying Custom SageMaker Configuration\nDESCRIPTION: Demonstrates how to create a custom SageMaker configuration by loading, modifying, validating, and then using a configuration dictionary with a Session object to override default settings.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_101\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.session import Session\nfrom sagemaker.config import load_sagemaker_config, validate_sagemaker_config\n\ncustom_sagemaker_config = load_sagemaker_config()\n```\n\n----------------------------------------\n\nTITLE: Specifying TensorFlow Container Image in SageMaker Python SDK\nDESCRIPTION: This snippet demonstrates how to use the image_name argument to specify the container image, Python version, and framework version when creating a TensorFlow estimator in SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/using_tf.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntf_estimator = TensorFlow(entry_point='tf-train.py',\n                             role='SageMakerRole',\n                             train_instance_count=1,\n                             train_instance_type='ml.p2.xlarge',\n                             image_name='763104351884.dkr.ecr.<region>.amazonaws.com/<framework>-<job type>:<framework version>-<cpu/gpu>-<python version>-ubuntu18.04',\n                             script_mode=True)\n```\n\n----------------------------------------\n\nTITLE: Using Git Repository with SageMaker Estimator (SSH with Branch Only)\nDESCRIPTION: Demonstrates creating an estimator using SSH URL for a Git repository while specifying only a branch name. In this case, the latest commit in the specified branch will be used for training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# You can also specify git_config by providing only 'repo' and 'branch'.\n# If this is the case, the latest commit in that branch will be used.\ngit_config = {'repo': 'git@github.com:username/repo-with-training-scripts.git',\n              'branch': 'branch1'}\n\n# In this example, the entry point 'mnist.py' is all we need for source code.\n# We need to specify the path to it in the Git repo.\nmx_estimator = MXNet(entry_point='mxnet/mnist.py',\n                     role='SageMakerRole',\n                     git_config=git_config,\n                     instance_count=1,\n                     instance_type='ml.c4.xlarge')\n```\n\n----------------------------------------\n\nTITLE: Configuring SageMaker Training and Transform Operations in Airflow\nDESCRIPTION: Demonstrates how to create configuration objects for SageMaker training and transform operations using TensorFlow estimator. Shows setup of training parameters and transform configuration using the SageMaker SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/using_workflow.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport sagemaker\nfrom sagemaker.tensorflow import TensorFlow\nfrom sagemaker.workflow.airflow import training_config, transform_config_from_estimator\n\nestimator = TensorFlow(entry_point='tf_train.py',\n                       role='sagemaker-role',\n                       framework_version='1.11.0',\n                       training_steps=1000,\n                       evaluation_steps=100,\n                       instance_count=2,\n                       instance_type='ml.p2.xlarge')\n\ntrain_config = training_config(estimator=estimator,\n                               inputs=your_training_data_s3_uri)\n\ntrans_config = transform_config_from_estimator(estimator=estimator,\n                                               task_id='tf_training',\n                                               task_type='training',\n                                               instance_count=1,\n                                               instance_type='ml.m4.xlarge',\n                                               data=your_transform_data_s3_uri,\n                                               content_type='text/csv')\n```\n\n----------------------------------------\n\nTITLE: Modifying DistributedSampler for SageMaker Distributed Training in PyTorch\nDESCRIPTION: This code modifies the PyTorch DistributedSampler to include cluster information for distributed training using SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrain_sampler = DistributedSampler(train_dataset, num_replicas=dist.get_world_size(), rank=dist.get_rank())\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Estimator in SageMaker Python SDK v2.0+\nDESCRIPTION: This code snippet demonstrates how to create a TensorFlow estimator using version 2.0 or later of the SageMaker Python SDK. It shows the changes required, including specifying the ECR image URI and using hyperparameters for training configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\n# v2.0 and later\nestimator = TensorFlow(\n    ...\n    source_dir=\"code\",\n    framework_version=\"1.10.0\",\n    py_version=\"py2\",\n    instance_type=\"ml.m4.xlarge\",\n    image_uri=\"520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow:1.10.0-cpu-py2\",\n    hyperparameters={\n        \"training_steps\": 100,\n        \"evaluation_steps\": 10,\n        \"checkpoint_path\": \"s3://bucket/path\",\n        \"sagemaker_requirements\": \"requirements.txt\",\n    },\n    model_dir=False,\n)\n```\n\n----------------------------------------\n\nTITLE: Property File JSON Format Example for SageMaker Pipelines (JSON)\nDESCRIPTION: This JSON example shows the expected format of a property file (hyperparam.json) produced by a ProcessingStep. The file contains hyperparameters that can be queried using JsonGet in subsequent steps.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_15\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"hyperparam\": {\n        \"eta\": {\n            \"value\": 0.6\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Autodocumenting SageMaker AutoML Candidate Estimator Module\nDESCRIPTION: This code snippet uses Sphinx autodoc to generate documentation for the sagemaker.automl.candidate_estimator module. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/automl.rst#2025-04-22_snippet_1\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: sagemaker.automl.candidate_estimator\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring Parameter Servers for Distributed MXNet Training in SageMaker\nDESCRIPTION: Sets up distributed training using parameter servers in MXNet by enabling the parameter server in the distribution configuration. This allows SageMaker to automatically start MXNet kvstore server and scheduler processes across training hosts.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndistribution={'parameter_server': {'enabled': True}}\n```\n\n----------------------------------------\n\nTITLE: Creating and Deploying Multi-Model TensorFlow Serving Endpoint in SageMaker\nDESCRIPTION: This Python code snippet shows how to create a TensorFlow Model in SageMaker for a multi-model endpoint. It specifies the model data location and sets an environment variable for the default model name.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/deploying_tensorflow_serving.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlowModel, TensorFlowPredictor\n\n# change this to the name or ARN of your SageMaker execution role\nrole = 'SageMakerRole'\n\nmodel_data = 's3://mybucket/models/multi.tar.gz'\n\n# For multi-model endpoints, you should set the default model name in\n# an environment variable. If it isn't set, the endpoint will work,\n# but the model it will select as default is unpredictable.\nenv = {\n  'SAGEMAKER_TFS_DEFAULT_MODEL_NAME': 'model1'\n}\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Model in SageMaker Python SDK v2.0+\nDESCRIPTION: This code snippet demonstrates how to create a TensorFlow model using version 2.0 or later of the SageMaker Python SDK, showing the required changes including specifying the ECR image URI and using an environment variable for model server workers.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# v2.0 and later\nfrom sagemaker.model import FrameworkModel\n\nmodel = FrameworkModel(\n    ...\n    image_uri=\"520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow:1.10.0-cpu-py2\",\n    env={\"MODEL_SERVER_WORKERS\": 4},\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Latest SageMaker Python SDK (Bash)\nDESCRIPTION: Command to install the latest version of the SageMaker Python SDK using pip. This should be executed in a terminal or command prompt.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/v2.rst#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade sagemaker\n```\n\n----------------------------------------\n\nTITLE: Retrieving Default Instance Type and Image URI in SageMaker Python SDK\nDESCRIPTION: Demonstrates how to retrieve the default instance type for a model and its corresponding image URI using the SageMaker Python SDK. This snippet requires the model_id, model_version, and scope parameters to work properly.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_53\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import image_uris, instance_types\n\ninstance_type = instance_types.retrieve_default(\n    model_id=model_id,\n    model_version=model_version,\n    scope=scope\n)\n\nimage_uri = image_uris.retrieve(\n   region=None,\n   framework=None,\n   image_scope=scope,\n   model_id=model_id,\n   model_version=model_version,\n   instance_type=instance_type,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Debugger Collection and Hook for TensorFlow Training in SageMaker\nDESCRIPTION: This code demonstrates how to configure SageMaker Debugger to capture tensors during model training. It shows how to create a CollectionConfig to define what tensor data to collect and a DebuggerHookConfig to specify output paths and hook parameters, then apply these to a TensorFlow estimator.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.debugger import CollectionConfig, DebuggerHookConfig\n\ncollection_config = CollectionConfig(\n    name='collection_name',\n    parameters={\n        'key': 'value'\n    }\n)\n\ndebugger_hook_config = DebuggerHookConfig(\n    s3_output_path='s3://path/for/data/emission',\n    container_local_output_path='/local/path/for/data/emission',\n    hook_parameters={\n        'key': 'value'\n    },\n    collection_configs=[\n        collection_config\n    ]\n)\n\nestimator = TensorFlow(\n    role=role,\n    instance_count=1,\n    instance_type=instance_type,\n    debugger_hook_config=debugger_hook_config\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing the MXNet Model Server Request Processing Flow\nDESCRIPTION: Demonstrates the three-step process of handling an inference request in SageMaker's MXNet model server: input processing, prediction, and output processing. Shows how these functions interact with each other in sequence.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/using_mxnet.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Deserialize the Invoke request body into an object we can perform prediction on\ninput_object = input_fn(request_body, request_content_type)\n\n# Perform prediction on the deserialized object, with the loaded model\nprediction = predict_fn(input_object, model)\n\n# Serialize the prediction result into the desired response content type\nouput = output_fn(prediction, response_content_type)\n```\n\n----------------------------------------\n\nTITLE: Gradient Accumulation with no_sync() Context Manager\nDESCRIPTION: Example showing how to use the no_sync() context manager for gradient accumulation in distributed training. Gradients are accumulated without AllReduce during iterations inside the context, then synchronized when exiting.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Gradients are accumulated while inside no_sync context\nwith model.no_sync():\n    ...\n    loss.backward()\n\n# First iteration upon exiting context\n# Incoming gradients are added to the accumulated gradients and then synchronized via AllReduce\n...\nloss.backward()\n\n# Update weights and reset gradients to zero after accumulation is finished\noptimizer.step()\noptimizer.zero_grad()\n```\n\n----------------------------------------\n\nTITLE: Using sagemaker-upgrade-v2 Command Line Tool with Multiple Files\nDESCRIPTION: Bash loop example for batch processing multiple files with the sagemaker-upgrade-v2 tool to convert from SageMaker SDK v1.x to v2.0 compatibility.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/v2.rst#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ for file in $(find input-dir); do sagemaker-upgrade-v2 --in-file $file --out-file output-dir/$file; done\n```\n\n----------------------------------------\n\nTITLE: Exporting TensorFlow Model with Custom Serving Input Function\nDESCRIPTION: This snippet demonstrates how to create a TensorFlow exporter with a custom serving input function for saving a model in a training script.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\nexporter = tf.estimator.LatestExporter(\"Servo\", serving_input_receiver_fn=serving_input_fn)\n```\n\n----------------------------------------\n\nTITLE: Generating Content Types Module Documentation in reStructuredText\nDESCRIPTION: This snippet uses Sphinx automodule directives to automatically generate documentation for the sagemaker.content_types module. It includes all members, undocumented members, inheritance information, and private members in the generated documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/content_types.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: sagemaker.content_types\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :private-members:\n```\n\n----------------------------------------\n\nTITLE: Deploying DJL Serving Model with Advanced Configuration in Python\nDESCRIPTION: This snippet demonstrates how to initialize a DJL model with advanced configuration options and deploy it to a SageMaker endpoint. It includes environment variables for configuring rolling batch processing, tensor parallelism, data type, and batch size.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/djl/using_djl.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndjl_model = DJLModel(\n    model_id=\"<hf hub id | s3 uri>\",\n    role=\"my_sagemaker_role\",\n    task=\"text-generation\",\n    engine=\"Python\",\n    env={\n        \"OPTION_ROLLING_BATCH\": \"lmi-dist\",\n        \"TENSOR_PARALLEL_DEGREE\": \"2\",\n        \"OPTION_DTYPE\": \"bf16\",\n        \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"64\",\n    },\n    image_uri=<djl lmi image uri>,\n)\n# Deploy the model to an Amazon SageMaker Endpoint and get a Predictor\npredictor = djl_model.deploy(\"ml.g5.12xlarge\",\n                             initial_instance_count=1)\n```\n\n----------------------------------------\n\nTITLE: Creating ServerlessInferenceConfig with Default Values in SageMaker\nDESCRIPTION: Creates an empty ServerlessInferenceConfig object with default values for memory size (2048MB) and maximum concurrency (5). This configuration is used to deploy a serverless inference endpoint.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_67\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.serverless import ServerlessInferenceConfig\n\n# Create an empty ServerlessInferenceConfig object to use default values\nserverless_config = ServerlessInferenceConfig()\n```\n\n----------------------------------------\n\nTITLE: ModelBuilder with Custom Configuration\nDESCRIPTION: Example of creating ModelBuilder with custom inference specification and dependencies.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nmodel_builder = ModelBuilder(\n    mode=Mode.LOCAL_CONTAINER,\n    model_path=resnet_model_dir,\n    inference_spec=my_inference_spec,\n    schema_builder=SchemaBuilder(input, output),\n    role_arn=execution_role,\n    dependencies={\"auto\": False, \"custom\": [\"-e git+https://github.com/luca-medeiros/lang-segment-anything.git#egg=lang-sam\"],}\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Built-in Collection Configuration for Biases in SageMaker Debugger\nDESCRIPTION: A simple example showing how to configure SageMaker Debugger to capture a built-in collection of bias tensors during model training. The built-in 'biases' collection is recognized by the hook automatically.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ncollection_config_biases = CollectionConfig(name='biases')\n```\n\n----------------------------------------\n\nTITLE: Batch Retrieving Multiple Records from SageMaker Feature Store with Python\nDESCRIPTION: Retrieves multiple records simultaneously from a feature group using the batch_get_record function.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nrecord_identifier_values = [\"573291\", \"109382\", \"828400\", \"124013\"]\nfeaturestore_runtime.batch_get_record(Identifiers=[{\"FeatureGroupName\": transaction_feature_group_name, \"RecordIdentifiersValueAsString\": record_identifier_values}])\n```\n\n----------------------------------------\n\nTITLE: SageMaker Transform Configuration for Airflow\nDESCRIPTION: Configuration function for batch transform jobs in SageMaker through Airflow\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/sagemaker.workflow.airflow.rst#2025-04-22_snippet_4\n\nLANGUAGE: rst\nCODE:\n```\n.. autofunction:: sagemaker.workflow.airflow.transform_config\n```\n\n----------------------------------------\n\nTITLE: Using RecordSet Objects with SageMaker Built-in Algorithms\nDESCRIPTION: Demonstrates how to use RecordSet objects instead of dictionaries when working with SageMaker built-in algorithms for hyperparameter tuning. This approach is specific to built-in algorithms which don't require metric_definitions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_56\n\nLANGUAGE: python\nCODE:\n```\n# Create RecordSet object for each data channel\ntrain_records = RecordSet(...)\ntest_records = RecordSet(...)\n\n# Start hyperparameter tuning job\nmy_tuner.fit([train_records, test_records])\n```\n\n----------------------------------------\n\nTITLE: Setting GPU Device for SageMaker Distributed Training\nDESCRIPTION: Pins each GPU to a single distributed data parallel process using local_rank, which refers to the relative rank of the process within a given node.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntorch.cuda.set_device(dist.get_local_rank())\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for SageMaker SDK\nDESCRIPTION: Specifies the exact versions of Python packages required for running machine learning workflows in SageMaker. Includes MLflow for experiment tracking, cloudpickle for serialization, NumPy for numerical computing, and TensorFlow for deep learning.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/serve_resources/mlflow/tensorflow/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmlflow==2.13.2\ncloudpickle==2.2.1\nnumpy==1.26.4\ntensorflow==2.16.1\n```\n\n----------------------------------------\n\nTITLE: Setting Feature Groups for Dataset Creation in SageMaker with Python\nDESCRIPTION: Defines base and target feature groups that will be used to create datasets with the Feature Store Offline SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nbase_feature_group = identity_feature_group\ntarget_feature_group = transaction_feature_group\n```\n\n----------------------------------------\n\nTITLE: Documenting SageMaker Transformer Class with reStructuredText Directives\nDESCRIPTION: This snippet demonstrates how to use reStructuredText directives to auto-generate documentation for the SageMaker Transformer class. The autoclass directive imports documentation from the class's docstrings, including all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/transformer.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. autoclass:: sagemaker.transformer.Transformer\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring PySparkProcessor with Overrides\nDESCRIPTION: Example of initializing a PySparkProcessor with the ability to override Spark configuration parameters. This is useful for tuning Spark applications or configuring components like the Hive metastore.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_processing.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nspark_processor = PySparkProcessor(\n    base_job_name=\"sm-spark\",\n    image_uri=beta_image_uri,\n    role=role,\n    instance_count=2,\n\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Serverless Inference Resources in SageMaker\nDESCRIPTION: Deletes the SageMaker serverless inference endpoint and model to avoid incurring unnecessary charges. This should be done after the inference is complete and results are retrieved.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_72\n\nLANGUAGE: python\nCODE:\n```\n# Tears down the SageMaker endpoint and endpoint configuration\nserverless_predictor.delete_endpoint()\n\n# Deletes the SageMaker model\nserverless_predictor.delete_model()\n```\n\n----------------------------------------\n\nTITLE: Configuring a Custom Tensor Collection with Specific Parameters in SageMaker Debugger\nDESCRIPTION: This snippet demonstrates how to create a custom collection configuration to save specific tensors (ReLU activations) at defined intervals. It shows how to set regex patterns for tensor selection and specify time intervals for saving data.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncollection_config_for_relu = CollectionConfig(\n    name='custom_relu_collection',\n    parameters={\n        'include_regex': 'relu',\n        'save_interval': '20',\n        'start_step': '5',\n        'end_step': '100'\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting a Feature Group in SageMaker with Python\nDESCRIPTION: Deletes a feature group using the delete function. Note that it can take 10-15 minutes to delete an online feature group with InMemory storage type.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nfeature_group.delete()\n```\n\n----------------------------------------\n\nTITLE: Preparing Local Model Data for SageMaker Deployment using Shell Commands\nDESCRIPTION: These shell commands demonstrate how to prepare local model data for deployment in SageMaker. It involves compressing the model directory into a tar.gz file and uploading it to an S3 bucket using the AWS CLI.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntar -czf model.tar.gz my_model\naws s3 cp model.tar.gz s3://my-bucket/my-path/model.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Creating and Deploying a PyTorchModel in SageMaker\nDESCRIPTION: This snippet demonstrates how to create a PyTorchModel object and deploy it for inference in SageMaker. It specifies the model data location, IAM role, and entry point script.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import get_execution_role\nrole = get_execution_role()\n\npytorch_model = PyTorchModel(model_data='s3://my-bucket/my-path/model.tar.gz', role=role,\n                             entry_point='inference.py')\n\npredictor = pytorch_model.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)\n```\n\n----------------------------------------\n\nTITLE: Creating and Executing SageMaker Pipeline Locally\nDESCRIPTION: Demonstrates how to create and execute a SageMaker pipeline locally, including training, model creation, and transform steps.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_81\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.workflow.pipeline import Pipeline\nfrom sagemaker.workflow.steps import TrainingStep, TransformStep\nfrom sagemaker.workflow.model_step import ModelStep\nfrom sagemaker.workflow.pipeline_context import LocalPipelineSession\nfrom sagemaker.mxnet import MXNet\nfrom sagemaker.model import Model\nfrom sagemaker.inputs import TranformerInput\nfrom sagemaker.transformer import Transformer\n\nsession = LocalPipelineSession()\nmxnet_estimator = MXNet('train.py',\n                        role='SageMakerRole',\n                        instance_type='local',\n                        instance_count=1,\n                        framework_version='1.2.1',\n                        sagemaker_session=session)\n\ntrain_step_args = mxnet_estimator.fit('file:///tmp/my_training_data')\n\n# Define training step\ntrain_step = TrainingStep(name='local_mxnet_train', step_args=train_step_args)\n\nmodel = Model(\n  image_uri=inference_image_uri,\n  model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n  sagemaker_session=session,\n  role='SageMakerRole'\n)\n\n# Define create model step\nmodel_step_args = model.create(instance_type=\"local\", accelerator_type=\"local\")\nmodel_step = ModelStep(\n  name='local_mxnet_model',\n  step_args=model_step_args\n)\n\ntransformer =  Transformer(\n  model_name=model_step.properties.ModelName,\n  instance_type='local',\n  instance_count=1,\n  sagemaker_session=session\n)\ntransform_args = transformer.transform('file:///tmp/my_transform_data')\n# Define transform step\ntransform_step = TransformStep(name='local_mxnet_transform', step_args=transform_args)\n\n# Define the pipeline\npipeline = Pipeline(name='local_pipeline',\n                    steps=[train_step, model_step, transform_step],\n                    sagemaker_session=session)\n\n# Create the pipeline\npipeline.upsert(role_arn='SageMakerRole', description='local pipeline example')\n\n# Start a pipeline execution\nexecution = pipeline.start()\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Initial Model Variables in TensorFlow Distributed Training\nDESCRIPTION: Broadcast initial model variables from the leader node (rank 0) to all worker nodes. This ensures consistent initialization across all worker ranks.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsdp.broadcast_variables(model.variables, root_rank=0)\nsdp.broadcast_variables(opt.variables(), root_rank=0)\n```\n\n----------------------------------------\n\nTITLE: Defining SageMaker Account Registry by Region in Python\nDESCRIPTION: Maps AWS regions to their corresponding SageMaker account registry URLs. This dictionary associates each supported AWS region with its specific container registry endpoint for SageMaker images.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/tfs/tfs-test-model-with-inference/00000123/assets/foo.txt#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n_SAGEMAKER_ACCOUNT_REGISTRY_BY_REGION = {\n    \"af-south-1\": \"455444449433\",\n    \"ap-east-1\": \"286214385809\",\n    \"ap-northeast-1\": \"520713654638\",\n    \"ap-northeast-2\": \"520713654638\",\n    \"ap-northeast-3\": \"520713654638\",\n    \"ap-south-1\": \"720646828776\",\n    \"ap-southeast-1\": \"475088953585\",\n    \"ap-southeast-2\": \"544295431143\",\n    \"ca-central-1\": \"469771592824\",\n    \"cn-north-1\": \"390948362332\",\n    \"cn-northwest-1\": \"390948362332\",\n    \"eu-central-1\": \"813361260812\",\n    \"eu-north-1\": \"669576153137\",\n    \"eu-south-1\": \"257386234256\",\n    \"eu-west-1\": \"470317259841\",\n    \"eu-west-2\": \"856760150666\",\n    \"eu-west-3\": \"843114510376\",\n    \"eu-south-2\": \"104374241257\",\n    \"il-central-1\": \"875968070545\",\n    \"me-central-1\": \"272398656194\",\n    \"me-south-1\": \"217643126080\",\n    \"sa-east-1\": \"782484402741\",\n    \"us-east-1\": \"785573368785\",\n    \"us-east-2\": \"007439368137\",\n    \"us-gov-west-1\": \"246785580436\",\n    \"us-west-1\": \"742091327244\",\n    \"us-west-2\": \"257758044811\",\n    \"us-iso-east-1\": \"406031935815\",\n    \"us-isob-east-1\": \"801668240914\",\n}\n```\n\n----------------------------------------\n\nTITLE: Local Container Deployment Configuration\nDESCRIPTION: Shows how to configure ModelBuilder for local container deployment with schema building.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nmodel_builder_local = ModelBuilder(\n    model=model,\n    schema_builder=SchemaBuilder(X_test, y_pred),\n    role_arn=execution_role,\n    mode=Mode.LOCAL_CONTAINER\n)\nxgb_local_builder = model_builder_local.build()\n\npredictor_local = xgb_local_builder.deploy()\n```\n\n----------------------------------------\n\nTITLE: Documenting RandomCutForestPredictor Class in Python for Amazon SageMaker\nDESCRIPTION: Autoclass documentation for the RandomCutForestPredictor class in the sagemaker module. It includes all members and undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/unsupervised/randomcutforest.rst#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.RandomCutForestPredictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: MXNet Estimator with Endpoint Configuration\nDESCRIPTION: Advanced example showing how to deploy a model to an existing endpoint and manage endpoint configurations using MXNet Estimator.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.mxnet import MXNet\n\n# Configure an MXNet Estimator (no training happens yet)\nmxnet_estimator = MXNet('train.py',\n                        role='SageMakerRole',\n                        instance_type='ml.p2.xlarge',\n                        instance_count=1,\n                        framework_version='1.2.1')\n\n# Starts a SageMaker training job and waits until completion.\nmxnet_estimator.fit('s3://my_bucket/my_training_data/')\n\n# Deploys the model that was generated by fit() to an existing SageMaker endpoint\nmxnet_predictor = mxnet_estimator.deploy(initial_instance_count=1,\n                                         instance_type='ml.p2.xlarge',\n                                         update_endpoint=True,\n                                         endpoint_name='existing-endpoint')\n\n# Serializes data and makes a prediction request to the SageMaker endpoint\nresponse = mxnet_predictor.predict(data)\n\n# Tears down the SageMaker endpoint and endpoint configuration\nmxnet_predictor.delete_endpoint()\n\n# Deletes the SageMaker model\nmxnet_predictor.delete_model()\n```\n\n----------------------------------------\n\nTITLE: Configuring SageMaker Local Mode in YAML\nDESCRIPTION: YAML configuration for SageMaker local mode, specifying local code usage, region name, and container configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_76\n\nLANGUAGE: yaml\nCODE:\n```\nlocal:\n    local_code: true # Using everything locally\n    region_name: \"us-west-2\" # Name of the region\n    container_config: # Additional docker container config\n        shm_size: \"128M\"\n```\n\n----------------------------------------\n\nTITLE: Customizing Built-in Debugger Rules\nDESCRIPTION: Shows how to customize a built-in rule with custom parameters and collection configurations while using another default built-in rule.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.debugger import Rule\nfrom smdebug_rulesconfig import vanishing_gradient, weight_update_ratio\n\nwur_with_customization = Rule.sagemaker(\n    base_config=weight_update_ratio(),\n    name=\"custom_wup_rule_name\",\n    rule_parameters={\n        'key1': 'value1',\n        'key2': 'value2'\n    },\n    collections_to_save=[\n        CollectionConfig(\n            name=\"custom_collection_name\",\n            parameters= {\n                'key1': 'value1',\n                'key2': 'value2'\n            }\n        )\n    ]\n)\n\nestimator = TensorFlow(\n        role=role,\n        instance_count=1,\n        instance_type=instance_type,\n        rules=[\n            Rule.sagemaker(vanishing_gradient()),\n            wur_with_customization\n        ]\n)\n```\n\n----------------------------------------\n\nTITLE: Specifying Dependencies for AWS SageMaker Python SDK\nDESCRIPTION: This snippet lists the required Python packages and their version constraints for the AWS SageMaker Python SDK. It includes packages for documentation (Sphinx), templating (Jinja2), schema validation, and machine learning acceleration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\nsphinx==7.2.6\nsphinx-rtd-theme==3.0.0\ndocutils>=0.18.1,<0.21\npackaging>=23.0,<25\njinja2==3.1.6\nschema==0.7.5\naccelerate>=0.24.1,<=0.27.0\ngraphene<4.0\n```\n\n----------------------------------------\n\nTITLE: Deploying TensorFlow Model with Requirements File in SageMaker Python SDK v2.0+\nDESCRIPTION: These snippets show how to deploy a TensorFlow model with a requirements file using version 2.0 or later of the SageMaker Python SDK, for both endpoints and batch transform jobs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# for an endpoint\nestimator.deploy(..., env={\"SAGEMAKER_REQUIREMENTS\": \"requirements.txt\"})\n\n# for batch transform\nestimator.transformer(..., env={\"SAGEMAKER_REQUIREMENTS\": \"requirements.txt\"})\n```\n\n----------------------------------------\n\nTITLE: Model Building and Deployment\nDESCRIPTION: Shows the process of building and deploying a model using ModelBuilder with endpoint configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_35\n\nLANGUAGE: python\nCODE:\n```\n# Build the model according to the model server specification and save it as files in the working directory\nmodel = model_builder.build()\n\npredictor = model.deploy(\n    initial_instance_count=1,\n    instance_type=\"ml.c6i.xlarge\"\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring LambdaStep in SageMaker Workflow\nDESCRIPTION: Example showing how to define output parameters of different types from a Lambda function and access them in a workflow. This demonstrates creating and accessing string, integer, boolean, and float output parameters.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nstr_outputParam = LambdaOutput(output_name=\"output1\", output_type=LambdaOutputTypeEnum.String)\nint_outputParam = LambdaOutput(output_name\"output2\", output_type=LambdaOutputTypeEnum.Integer)\nbool_outputParam = LambdaOutput(output_name\"output3\", output_type=LambdaOutputTypeEnum.Boolean)\nfloat_outputParam = LambdaOutput(output_name\"output4\", output_type=LambdaOutputTypeEnum.Float)\n\nstep_lambda = LambdaStep(\n    name=\"MyLambdaStep\",\n    lambda_func=Lambda(\n        function_arn=\"arn:aws:lambda:us-west-2:123456789012:function:sagemaker_test_lambda\",\n        session=PipelineSession(),\n    ),\n    inputs={\"arg1\": \"foo\", \"arg2\": 5},\n    outputs=[\n        str_outputParam, int_outputParam, bool_outputParam, float_outputParam\n   ],\n)\noutput_ref = step_lambda.properties.Outputs[\"output1\"]\n```\n\nLANGUAGE: python\nCODE:\n```\ndef handler(event, context):\n    ...\n    return {\n        \"output1\": \"string_value\",\n        \"output2\": 1,\n        \"output3\": True,\n        \"output4\": 2.0,\n    }\n```\n\n----------------------------------------\n\nTITLE: Retrieving JumpStart Model URIs\nDESCRIPTION: Code to retrieve the URIs for model artifacts, scripts, and container images required for deployment.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import image_uris, model_uris, script_uris\n\nmodel_id, model_version = \"tensorflow-tc-bert-en-cased-L-12-H-768-A-12-2\", \"1.0.0\"\ninstance_type, instance_count = \"ml.m5.xlarge\", 1\n\nbase_model_uri = model_uris.retrieve(\n    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n)\nscript_uri = script_uris.retrieve(\n    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n)\nimage_uri = image_uris.retrieve(\n    region=None,\n    framework=None,\n    image_scope=\"inference\",\n    model_id=model_id,\n    model_version=model_version,\n    instance_type=instance_type,\n)\n```\n\n----------------------------------------\n\nTITLE: Cleanup and Resource Deletion\nDESCRIPTION: Shows how to properly clean up resources by deleting the monitoring schedule, endpoint, and model.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_monitoring.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmy_monitor.delete_monitoring_schedule()\n\npredictor.delete_endpoint()\npredictor.delete_model()\n```\n\n----------------------------------------\n\nTITLE: Modifying SageMaker Configuration by Removing a Default Value\nDESCRIPTION: Shows how to modify a SageMaker configuration dictionary by removing a specific default value before using it with a Session.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_102\n\nLANGUAGE: python\nCODE:\n```\ndel custom_sagemaker_config[\"SageMaker\"][\"TrainingJob\"][\"RoleArn\"]\n```\n\n----------------------------------------\n\nTITLE: Documenting RandomCutForest Class in Python for Amazon SageMaker\nDESCRIPTION: Autoclass documentation for the RandomCutForest class in the sagemaker module. It includes all members and inherited members, but excludes specific attributes like image_uri, num_trees, num_samples_per_tree, eval_metrics, feature_dim, and MINI_BATCH_SIZE.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/unsupervised/randomcutforest.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.RandomCutForest\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :inherited-members:\n    :exclude-members: image_uri, num_trees, num_samples_per_tree, eval_metrics, feature_dim, MINI_BATCH_SIZE\n```\n\n----------------------------------------\n\nTITLE: Listing Feature Groups in SageMaker Feature Store with Python\nDESCRIPTION: Lists all feature groups in your SageMaker account using the list_feature_groups function.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsagemaker_client.list_feature_groups()\n```\n\n----------------------------------------\n\nTITLE: Using overlap in TensorFlow with XLA compilation\nDESCRIPTION: Demonstrates how to use smdistributed.dataparallel.tensorflow.overlap() function with a layer to enable efficient overlapping of backward pass with allreduce operations. This is only applicable for models compiled with XLA.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nlayer = tf.nn.dropout(...) # Or any other layer\nlayer = smdistributed.dataparallel.tensorflow.overlap(layer)\n```\n\n----------------------------------------\n\nTITLE: Specifying PyTorch 1.12.1 Deep Learning Container in AWS ECR\nDESCRIPTION: Docker image URI for the AWS Deep Learning Container with PyTorch 1.12.1 and the SageMaker distributed data parallelism library v1.6.0.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n763104351884.dkr.ecr.<region>.amazonaws.com/pytorch-training:1.12.1-gpu-py38-cu113-ubuntu20.04-sagemaker\n```\n\n----------------------------------------\n\nTITLE: Deploying TensorFlow Model with Model Server Workers in SageMaker Python SDK v1.x\nDESCRIPTION: This snippet shows how to deploy a TensorFlow model and specify the number of model server workers using version 1.x of the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# v1.x\nestimator.deploy(..., model_server_workers=4)\n```\n\n----------------------------------------\n\nTITLE: Defining SageMaker Python SDK Dependencies with Version Constraints\nDESCRIPTION: This requirements file specifies the dependency packages needed by the AWS SageMaker Python SDK with specific version constraints. It requires urllib3 between versions 1.26.8 and 3.0.0, docker between versions 5.0.2 and 8.0.0, and PyYAML between versions 6.0.1 and 7.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/extras/local_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\nurllib3>=1.26.8,<3.0.0\ndocker>=5.0.2,<8.0.0\nPyYAML>=6.0.1,<7\n```\n\n----------------------------------------\n\nTITLE: Instantiating SageMaker Model (Python)\nDESCRIPTION: Examples showing the change in parameter order for the SageMaker Model class between v1.x and v2.x of the SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/v2.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# v1.x\nModel(\"s3://bucket/path/model.tar.gz\", \"my-image:latest\")\n\n# v2.0 and later\nModel(\"my-image:latest\", model_data=\"s3://bucket/path/model.tar.gz\")\n```\n\n----------------------------------------\n\nTITLE: Documenting SageMaker HyperparameterTuner Classes with Sphinx\nDESCRIPTION: Sphinx autodoc directives for generating documentation for SageMaker's hyperparameter tuning classes. These directives instruct Sphinx to automatically include class documentation with all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/tuner.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.tuner.HyperparameterTuner\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\n.. autoclass:: sagemaker.tuner.ContinuousParameter\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\n.. autoclass:: sagemaker.tuner.IntegerParameter\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\n.. autoclass:: sagemaker.tuner.CategoricalParameter\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Launching Distributed PyTorch Training on Single Trainium Instance\nDESCRIPTION: This example shows how to configure a PyTorch estimator to run a distributed training job on a single ml.trn1.2xlarge instance using the torch_distributed option.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.pytorch import PyTorch\n\npt_estimator = PyTorch(\n    entry_point=\"train_torch_distributed.py\",\n    role=\"SageMakerRole\",\n    framework_version=\"1.11.0\",\n    py_version=\"py38\",\n    instance_count=1,\n    instance_type=\"ml.trn1.2xlarge\",\n    distribution={\n        \"torch_distributed\": {\n            \"enabled\": True\n        }\n    }\n)\n\npt_estimator.fit(\"s3://bucket/path/to/training/data\")\n```\n\n----------------------------------------\n\nTITLE: Retrieving Content and Accept Types\nDESCRIPTION: Code to check supported content and accept types for a model using retrieve_options method.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nprint(sagemaker.content_types.retrieve_options(model_id=model_id, model_version=model_version))\nprint(sagemaker.accept_types.retrieve_options(model_id=model_id, model_version=model_version))\n```\n\n----------------------------------------\n\nTITLE: Specifying AWS X-Ray SDK Test Dependency\nDESCRIPTION: Declares aws-xray-sdk as a test dependency. This package is selected because it supports Python versions 3.7 through 3.11, receives regular maintenance updates, and has no direct dependencies on SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/dummy_code_bundle_with_reqs/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\naws-xray-sdk\n```\n\n----------------------------------------\n\nTITLE: Training XGBoost Model with fit Method\nDESCRIPTION: Example showing how to initiate model training by calling the fit method on an XGBoost estimator with training data.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/using_xgboost.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nxgb_script_mode_estimator.fit({\"train\": train_input})\n```\n\n----------------------------------------\n\nTITLE: SageMaker K-means Predictor Documentation\nDESCRIPTION: ReStructuredText directive for auto-documenting the SageMaker KMeansPredictor class used for making predictions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/unsupervised/kmeans.rst#2025-04-22_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.KMeansPredictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Importing and Initializing SageMaker Distributed Data Parallel Library for TensorFlow\nDESCRIPTION: Import the SageMaker distributed data parallel library's TensorFlow client and initialize it. This is the first step in setting up distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport smdistributed.dataparallel.tensorflow as sdp\nsdp.init()\n```\n\n----------------------------------------\n\nTITLE: Defining Sphinx Documentation for SageMaker Model Classes in RST\nDESCRIPTION: Sphinx documentation directives that specify how to generate API documentation for various SageMaker model classes. The directives include autoclass statements with options to show members, undocumented members, inheritance information, and inherited members where applicable.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/model.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.model.Model\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :inherited-members:\n```\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.jumpstart.model.JumpStartModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :inherited-members:\n```\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.model.FrameworkModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.model.ModelPackage\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Implementing predict_fn for PyTorch Elastic Inference 1.5.1\nDESCRIPTION: This function shows how to implement a custom predict_fn for PyTorch Elastic Inference version 1.5.1 in SageMaker. It imports torcheia and sets the profiling executor for EIA.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport torch\n\n\ndef predict_fn(input_data, model):\n    device = torch.device(\"cpu\")\n    input_data = data.to(device)\n    # make sure torcheia is imported so that Elastic Inference api call will be invoked\n    import torcheia\n    # we need to set the profiling executor for EIA\n    torch._C._jit_set_profiling_executor(False)\n    with torch.jit.optimized_execution(True):\n        output = model.forward(input_data)\n```\n\n----------------------------------------\n\nTITLE: Displaying SageMaker Job Variables in Python\nDESCRIPTION: Prints the current values of SageMaker job tracking variables using f-strings. This snippet helps monitor the state of job execution variables that were previously initialized.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/step2_notebook.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(f\"step1_JobName={step1_JobName}\")\nprint(f\"step1_JobStatus={step1_JobStatus}\")\nprint(f\"step1_NotebookJobInput={step1_NotebookJobInput}\")\nprint(f\"step1_InputNotebookName={step1_InputNotebookName}\")\nprint(f\"step1_NotebookJobOutput={step1_NotebookJobOutput}\")\nprint(f\"step1_OutputNotebookName={step1_OutputNotebookName}\")\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Model in SageMaker Python SDK v1.x\nDESCRIPTION: This code snippet shows how to create a TensorFlow model using version 1.x of the SageMaker Python SDK, specifying the framework version and model server workers.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# v1.x\nfrom sagemaker.tensorflow import TensorFlowModel\n\nmodel = TensorFlowModel(\n    ...\n    py_version=\"py2\",\n    framework_version=\"1.10.0\",\n    model_server_workers=4,\n)\n```\n\n----------------------------------------\n\nTITLE: Limiting Records per Identifier in SageMaker Feature Store with Python\nDESCRIPTION: Limits the number of records with the same identifier by keeping only the N most recent records based on event_time.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndataset_builder.with_number_of_recent_records_by_record_identifier(number_of_recent_records=N)\n```\n\n----------------------------------------\n\nTITLE: Inspecting SageMaker Configuration in Session Object\nDESCRIPTION: Shows how to create a Session object and view the full merged configuration from all config files.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_97\n\nLANGUAGE: python\nCODE:\n```\nsession=Session()\nsession.sagemaker_config\n```\n\n----------------------------------------\n\nTITLE: Describing a Feature Group in SageMaker Feature Store with Python\nDESCRIPTION: Retrieves detailed information about a feature group using the describe function.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfeature_group.describe()\n```\n\n----------------------------------------\n\nTITLE: XGBoost Estimator Class Documentation Directive in ReStructuredText\nDESCRIPTION: Sphinx documentation directive that references the XGBoost estimator class within the SageMaker Python SDK, displaying all class members in the generated documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/xgboost.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. autoclass:: sagemaker.xgboost.estimator.XGBoost\n    :members:\n```\n\n----------------------------------------\n\nTITLE: Checking Feature Group Status in SageMaker Feature Store with Python\nDESCRIPTION: Retrieves the current status of a feature group during or after creation. Status can be 'Creating', 'Created', 'CreateFailed', 'Deleting', or 'DeleteFailed'.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nstatus = feature_group.describe().get(\"FeatureGroupStatus\")\n```\n\n----------------------------------------\n\nTITLE: Using DistributedOptimizer in TensorFlow 2.x with tf.estimator\nDESCRIPTION: Example of how to construct a new DistributedOptimizer using an existing TensorFlow optimizer. This is applicable for tf.estimator API in TensorFlow 2.x (2.3.1).\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nopt = ... # existing optimizer from tf.train package or your custom optimizer\nopt = smdistributed.dataparallel.tensorflow.DistributedOptimizer(opt)\n```\n\n----------------------------------------\n\nTITLE: Saving Checkpoints in Distributed Training\nDESCRIPTION: Implements checkpoint saving logic that only executes on the leader node to prevent corruption.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nif sdp.rank() == 0:\n    checkpoint.save(checkpoint_dir)\n```\n\n----------------------------------------\n\nTITLE: Importing AsyncPredictor Class from SageMaker Python SDK\nDESCRIPTION: This code snippet shows how to import the AsyncPredictor class from the sagemaker.predictor_async module. The AsyncPredictor class is used for making asynchronous predictions against SageMaker endpoints using Python objects.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/predictor_async.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom sagemaker.predictor_async import AsyncPredictor\n```\n\n----------------------------------------\n\nTITLE: Custom input_fn Implementation Example\nDESCRIPTION: Shows the beginning of a custom input_fn implementation for handling pickled PyTorch tensors in SageMaker. This function would deserialize the input data for model prediction.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/using_pytorch.rst#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport torch\nfrom six import BytesIO\n\ndef input_fn(request_body, request_content_type):\n    \"\"\"An input_fn that loads a pickled tensor\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Installing Amazon SageMaker Python SDK via pip\nDESCRIPTION: This code snippet demonstrates how to install the Amazon SageMaker Python SDK using pip. It also shows how to install additional dependencies for specific frameworks like TensorFlow or PyTorch.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/doc_utils/pretrainedmodels.rst#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install sagemaker\n```\n\nLANGUAGE: shell\nCODE:\n```\npip install \"sagemaker[tensorflow]\"\n```\n\nLANGUAGE: shell\nCODE:\n```\npip install \"sagemaker[pytorch]\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation Table of Contents\nDESCRIPTION: Sets up a reStructuredText (rst) table of contents tree for utility API documentation. Uses maxdepth=1 for shallow hierarchy and glob pattern to include all files in the directory.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n   :glob:\n\n   *\n```\n\n----------------------------------------\n\nTITLE: Downloading SageMaker Data Parallel Library Wheel for PyTorch 1.12.1\nDESCRIPTION: URL to download the SageMaker distributed data parallelism library v1.6.0 wheel file for PyTorch 1.12.1 in custom containers.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nhttps://smdataparallel.s3.amazonaws.com/binary/pytorch/1.12.1/cu113/2022-12-05/smdistributed_dataparallel-1.6.0-cp38-cp38-linux_x86_64.whl\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Estimator in SageMaker Python SDK v1.x\nDESCRIPTION: This code snippet shows how to create a TensorFlow estimator using version 1.x of the SageMaker Python SDK. It includes parameters for specifying the framework version, instance type, and training configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/upgrade_from_legacy.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.tensorflow import TensorFlow\n\n# v1.x\nestimator = TensorFlow(\n    ...\n    source_dir=\"code\",\n    framework_version=\"1.10.0\",\n    train_instance_type=\"ml.m4.xlarge\",\n    training_steps=100,\n    evaluation_steps=10,\n    checkpoint_path=\"s3://bucket/path\",\n    requirements_file=\"requirements.txt\",\n)\n```\n\n----------------------------------------\n\nTITLE: XGBoostModel Class Documentation Directive in ReStructuredText\nDESCRIPTION: Sphinx documentation directive that references the XGBoostModel class, displaying all members, undocumented members, and inheritance information in the generated documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/xgboost.rst#2025-04-22_snippet_1\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. autoclass:: sagemaker.xgboost.model.XGBoostModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Retrieving and Customizing Model Hyperparameters\nDESCRIPTION: Demonstrates how to get default hyperparameters for a model and optionally override them for fine-tuning.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_48\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import hyperparameters\n\nmy_hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\nprint(my_hyperparameters)\n\n# Optionally override default hyperparameters for fine-tuning\nmy_hyperparameters[\"epoch\"] = \"3\"\nmy_hyperparameters[\"per_device_train_batch_size\"] = \"4\"\n\n# Optionally validate hyperparameters for the model\nhyperparameters.validate(model_id=model_id, model_version=model_version, hyperparameters=my_hyperparameters)\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Link Reference\nDESCRIPTION: ReStructuredText link reference to a sample Jupyter notebook demonstrating image classification usage with SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/vision/image_classification_pytorch.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n`sample notebook <https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart_image_classification/Amazon_JumpStart_Image_Classification.ipynb>`__\n```\n\n----------------------------------------\n\nTITLE: SageMaker Model Configuration from Estimator for Airflow\nDESCRIPTION: Configuration function to create model configuration from an estimator in SageMaker through Airflow\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/sagemaker.workflow.airflow.rst#2025-04-22_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n.. autofunction:: sagemaker.workflow.airflow.model_config_from_estimator\n```\n\n----------------------------------------\n\nTITLE: Referencing MLflow PyTorch Pickle Module\nDESCRIPTION: Direct reference to the MLflow PyTorch pickle module configuration used for model serialization in the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/serve_resources/mlflow/pytorch/data/pickle_module_info.txt#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nmlflow.pytorch.pickle_module\n```\n\n----------------------------------------\n\nTITLE: Getting Default Configuration File Locations in Python\nDESCRIPTION: Python code to determine the default locations of admin and user configuration files for the SageMaker Python SDK using the platformdirs library. This helps identify where configuration files are stored based on the current environment.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_92\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom platformdirs import site_config_dir, user_config_dir\n\n#Prints the location of the admin config file\nprint(os.path.join(site_config_dir(\"sagemaker\"), \"config.yaml\"))\n\n#Prints the location of the user config file\nprint(os.path.join(user_config_dir(\"sagemaker\"), \"config.yaml\"))\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Table of Contents for PyTorch Documentation in RST\nDESCRIPTION: Sets up a Sphinx documentation table of contents tree that includes all files in the current directory with a maximum depth of 1. This structure organizes PyTorch-related documentation for the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n   :glob:\n\n   *\n```\n\n----------------------------------------\n\nTITLE: TensorFlow Estimator Import Patterns Recognized by the Upgrade Tool\nDESCRIPTION: Code examples showing the supported import and instantiation patterns for TensorFlow estimators that the sagemaker-upgrade-v2 tool can recognize and update.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/v2.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nTensorFlow()\nsagemaker.tensorflow.TensorFlow()\nsagemaker.tensorflow.estimator.TensorFlow()\n```\n\n----------------------------------------\n\nTITLE: Documenting DJLPredictor Class in Python for SageMaker\nDESCRIPTION: This snippet uses Sphinx autodoc to generate documentation for the DJLPredictor class from the sagemaker.djl_inference module. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/djl/sagemaker.djl_inference.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.djl_inference.DJLPredictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Performing Model Inference\nDESCRIPTION: Example of making predictions using the deployed model endpoint.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_27\n\nLANGUAGE: python\nCODE:\n```\npredictor.predict(\"this is the best day of my life\", {\"ContentType\": \"application/x-text\"})\n```\n\n----------------------------------------\n\nTITLE: GPU Device Assignment for Distributed Training\nDESCRIPTION: Pins each GPU to a single distributed data parallel process using local rank assignment.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntorch.cuda.set_device(dist.get_local_rank())\n```\n\n----------------------------------------\n\nTITLE: SageMaker Deployment Configuration for Airflow\nDESCRIPTION: Configuration function for model deployment in SageMaker through Airflow\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/sagemaker.workflow.airflow.rst#2025-04-22_snippet_6\n\nLANGUAGE: rst\nCODE:\n```\n.. autofunction:: sagemaker.workflow.airflow.deploy_config\n```\n\n----------------------------------------\n\nTITLE: Configuring TensorFlow Estimator with TensorBoard Output in Python\nDESCRIPTION: This snippet demonstrates how to configure a TensorFlow estimator with TensorBoard output using the SageMaker Python SDK. It sets up the TensorBoardOutputConfig and initializes the TensorFlow estimator with the specified configuration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_debugger.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ncontainer_local_output_path='/local/path/for/tensorboard/data/emission'\n\nestimator = TensorFlow(\n    role=role,\n    instance_count=1,\n    instance_type=instance_type,\n    tensorboard_output_config=tensorboard_output_config\n)\n```\n\n----------------------------------------\n\nTITLE: Installing test dependencies for SageMaker Python SDK\nDESCRIPTION: Command to install the libraries needed to run tests for the SageMaker Python SDK using pip.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade .[test]\n```\n\n----------------------------------------\n\nTITLE: Enabling Debug Logging for SageMaker Configuration\nDESCRIPTION: Shows how to enable DEBUG level logging for the sagemaker.config logger to get detailed information about default value injection and configuration processing.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_100\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nsagemaker_config_logger = logging.getLogger(\"sagemaker.config\")\nsagemaker_config_logger.setLevel(logging.DEBUG)\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for MXNet Documentation in reStructuredText\nDESCRIPTION: This snippet defines the structure of the documentation using reStructuredText directives. It creates two separate table of contents: one for general usage and another for the SageMaker MXNet module.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/mxnet/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. toctree::\n    :maxdepth: 1\n\n    using_mxnet\n\n.. toctree::\n    :maxdepth: 2\n\n    sagemaker.mxnet\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for SageMaker SDK\nDESCRIPTION: This snippet defines the required versions of Python packages for the SageMaker Python SDK. It specifies minimum versions for Transformers and Accelerate, and an exact version for Datasets.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/huggingface_byoc/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\ntransformers>=4.36.0\ndatasets==2.16.1\naccelerate>=0.21.0\n```\n\n----------------------------------------\n\nTITLE: Installing SageMaker Python SDK from source\nDESCRIPTION: Commands to clone the SageMaker Python SDK repository and install it from source using pip.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/aws/sagemaker-python-sdk.git\ncd sagemaker-python-sdk\npip install .\n```\n\n----------------------------------------\n\nTITLE: Defining SageMaker Input Module Documentation with Sphinx\nDESCRIPTION: Sphinx directive to automatically generate documentation for the sagemaker.inputs module, including all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/inputs.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. automodule:: sagemaker.inputs\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Retrieving Default Training Instance Type\nDESCRIPTION: Shows how to get the default training instance type for a JumpStart model using the instance_types utility.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_47\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker import instance_types\n\ninstance_type = instance_types.retrieve_default(\n    model_id=model_id,\n    model_version=model_version,\n    scope=\"training\")\nprint(instance_type)\n```\n\n----------------------------------------\n\nTITLE: Specifying PyTorch 1.13.1 Deep Learning Container in AWS ECR\nDESCRIPTION: Docker image URI for the AWS Deep Learning Container with PyTorch 1.13.1 and the SageMaker distributed data parallelism library v1.7.0.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.13.1-gpu-py39-cu117-ubuntu20.04-sagemaker\n```\n\n----------------------------------------\n\nTITLE: Documenting Run Class in SageMaker Experiments (Python)\nDESCRIPTION: Auto-generated documentation for the Run class in the SageMaker experiments module. This class likely represents a single experimental run in SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/experiments/sagemaker.experiments.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.experiments.Run\n    :members:\n```\n\n----------------------------------------\n\nTITLE: Retrieving Base Framework Image Path Function in Python\nDESCRIPTION: Provides a function to construct the base SageMaker framework container image path based on region, framework name, version, and instance type. Handles various AWS regions including standard, China, US Government, and US ISO regions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/tfs/tfs-test-model-with-inference/00000123/assets/foo.txt#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef retrieve_base_framework_image_path(\n    region,\n    framework_name,\n    fw_version,\n    instance_type,\n    accelerator_type=None,\n    instance_family=None,\n    toolkit=None,\n    sdk_version=None,\n):\n    \"\"\"\n    Retrieve the base ECR repo SageMaker framework image path\n\n    Args:\n        region (str): The AWS region for which you are querying.\n        framework_name (str): SageMaker base framework, e.g., sagemaker-tensorflow-training.\n        fw_version (str): The framework version, e.g. 2.4.1.\n        instance_type (str): The SageMaker instance type, e.g., ml.c5.xlarge.\n        accelerator_type (str): Elastic Inference accelerator type.\n        instance_family (str): SageMaker instance family, e.g., c5.\n        toolkit (str): SageMaker toolkit name, e.g. autogluon.\n        sdk_version (str): SDK version of the toolkit, e.g. 0.4.3.\n\n    Returns:\n        str: The base image path.\n    \"\"\"\n    registry = retrieve_default_sagemaker_registry(region)\n\n    # Standard AWS regions have the form: <ac-id>.dkr.ecr.<region>.amazonaws.com\n    ecr_domain = \"amazonaws.com\"\n    domain_suffix = \"\"\n    if region in _AWS_REGIONS_BY_ML_VARIANT[\"cn-region\"]:\n        # China AWS regions have the form: <ac-id>.dkr.ecr.<region>.amazonaws.com.cn\n        domain_suffix = \".cn\"\n    elif region in _AWS_REGIONS_BY_ML_VARIANT[\"us-gov\"]:\n        # AWS Gov regions have the form: <ac-id>.dkr.ecr.<region>.amazonaws.com\n        pass\n    elif region in _AWS_REGIONS_BY_ML_VARIANT[\"us-iso\"]:\n        # US ISO regions have the form: <ac-id>.dkr.ecr-fips.<region>.sc2s.sgov.gov\n        ecr_domain = \"sc2s.sgov.gov\"\n    elif region in _AWS_REGIONS_BY_ML_VARIANT[\"us-isob\"]:\n        # US ISOB regions have the form: <ac-id>.dkr.ecr-fips.<region>.sc2s.ic.gov\n        ecr_domain = \"sc2s.ic.gov\"\n\n    image_ecr_path = f\"{registry}.dkr.ecr.{region}.{ecr_domain}{domain_suffix}\"\n\n    return f\"{image_ecr_path}/{framework_name}:{fw_version}\"\n```\n\n----------------------------------------\n\nTITLE: Default Configuration File Locations for SageMaker Studio Notebooks\nDESCRIPTION: The default file paths for SageMaker configuration files when using SageMaker Studio notebooks. The admin config uses system-wide location while user config is in the root user's configuration directory.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_94\n\nLANGUAGE: python\nCODE:\n```\n#Location of the admin config file\n/etc/xdg/sagemaker/config.yaml\n\n#Location of the user config file\n/root/.config/sagemaker/config.yaml\n```\n\n----------------------------------------\n\nTITLE: Saving Trained Scikit-learn Model\nDESCRIPTION: Example showing how to save a trained Scikit-learn model to the SageMaker model directory using joblib.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/using_sklearn.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.externals import joblib\nimport argparse\nimport os\n\nif __name__=='__main__':\n    # default to the value in environment variable `SM_MODEL_DIR`. Using args makes the script more portable.\n    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n    args, _ = parser.parse_known_args()\n\n    # ... train classifier `clf`, then save it to `model_dir` as file 'model.joblib'\n    joblib.dump(clf, os.path.join(args.model_dir, \"model.joblib\"))\n```\n\n----------------------------------------\n\nTITLE: Specifying Pandas Dependency for SageMaker Python SDK\nDESCRIPTION: This snippet defines the required version of the pandas library for the SageMaker Python SDK. It specifies pandas version 1.3.4 as a dependency.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/remote_function/old_deps_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\npandas==1.3.4\n```\n\n----------------------------------------\n\nTITLE: Git Commit Message Examples\nDESCRIPTION: Examples of valid commit message formats using prefixes for different types of changes like features, fixes, and documentation updates.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nfeature: support VPC config for hyperparameter tuning\nfix: fix flake8 errors\ndocumentation: add MXNet documentation\n```\n\n----------------------------------------\n\nTITLE: Documenting Chainer Estimator Class in Python\nDESCRIPTION: Autoclass directive for generating documentation for the Chainer estimator class. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/sagemaker.chainer.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.chainer.estimator.Chainer\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Using DistributedGradientTape for Efficient AllReduce Operations\nDESCRIPTION: Wraps the standard TensorFlow GradientTape with SageMaker's DistributedGradientTape to optimize AllReduce operations during training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith tf.GradientTape() as tape:\n      output = model(input)\n      loss_value = loss(label, output)\n\n# Wrap tf.GradientTape with the library's DistributedGradientTape\ntape = sdp.DistributedGradientTape(tape)\n```\n\n----------------------------------------\n\nTITLE: Specifying PyTorch 1.11.0 Deep Learning Container in AWS ECR\nDESCRIPTION: Docker image URI for the AWS Deep Learning Container with PyTorch 1.11.0 and the SageMaker distributed data parallelism library v1.4.1.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n763104351884.dkr.ecr.<region>.amazonaws.com/pytorch-training:1.11.0-gpu-py38-cu113-ubuntu20.04-sagemaker\n```\n\n----------------------------------------\n\nTITLE: Generating Sphinx Documentation for SageMaker Script URIs Module\nDESCRIPTION: This code snippet uses Sphinx automodule directive to automatically generate documentation for the sagemaker.script_uris module. It includes all members, undocumented members, and shows inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/script_uris.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: sagemaker.script_uris\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Validating a Custom SageMaker Configuration Dictionary\nDESCRIPTION: Shows how to validate that a modified SageMaker configuration dictionary adheres to the required configuration schema.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_103\n\nLANGUAGE: python\nCODE:\n```\nvalidate_sagemaker_config(custom_sagemaker_config)\n```\n\n----------------------------------------\n\nTITLE: Defining Build Dependencies for SageMaker Python SDK in requirements.txt\nDESCRIPTION: This snippet specifies the required Python packages for building and publishing the SageMaker Python SDK. It pins build to version 1.2.1 for package building and twine to version 5.0.0 for publishing packages to PyPI.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/tox/twine_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nbuild==1.2.1\ntwine==5.0.0\n```\n\n----------------------------------------\n\nTITLE: Cloning GitHub Repository Fork\nDESCRIPTION: Git command to clone a forked repository of the SageMaker Python SDK project.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/<username>/sagemaker-python-sdk\n```\n\n----------------------------------------\n\nTITLE: Documenting Experiment Class in SageMaker Experiments (Python)\nDESCRIPTION: Auto-generated documentation for the Experiment class in the SageMaker experiments module. This class likely represents an experiment containing multiple runs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/experiments/sagemaker.experiments.rst#2025-04-22_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.experiments.Experiment\n    :members:\n```\n\n----------------------------------------\n\nTITLE: Example Output of Hive DDL Command Generation for SageMaker Feature Store\nDESCRIPTION: An example of the Hive DDL command output showing the table creation syntax with columns based on feature definitions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nCREATE EXTERNAL TABLE IF NOT EXISTS sagemaker_featurestore.identity-feature-group-27-19-33-00 (\n  TransactionID INT\n  id_01 FLOAT\n  id_02 FLOAT\n  id_03 FLOAT\n  id_04 FLOAT\n ...\n```\n\n----------------------------------------\n\nTITLE: Executing Simple Notebook using Jupyter Magic\nDESCRIPTION: Uses the Jupyter %run magic command to execute a notebook in the same directory. This allows incorporating code from other notebooks.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/notebook1_happypath.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n%run 'simple.ipynb'\n```\n\n----------------------------------------\n\nTITLE: Documenting FactorizationMachinesPredictor Class in Python\nDESCRIPTION: Autodoc configuration for the FactorizationMachinesPredictor class. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/tabular/factorization_machines.rst#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.FactorizationMachinesPredictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: SageMaker K-means Class Documentation\nDESCRIPTION: ReStructuredText directive for auto-documenting the SageMaker KMeans class, excluding certain internal members and parameters.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/unsupervised/kmeans.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.KMeans\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :inherited-members:\n    :exclude-members: image_uri, k, init_method, max_iterations, tol, num_trials, local_init_method, half_life_time_size, epochs, center_factor, mini_batch_size, feature_dim, MAX_DEFAULT_BATCH_SIZE\n```\n\n----------------------------------------\n\nTITLE: Saving Trained Chainer Model in Python\nDESCRIPTION: This code snippet shows how to save a trained Chainer model to the specified model directory. It uses the chainer.serializers.save_npz function to serialize the model.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainer\nimport argparse\nimport os\n\nif __name__=='__main__':\n    # default to the value in environment variable `SM_MODEL_DIR`. Using args makes the script more portable.\n    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n    args, _ = parser.parse_known_args()\n\n    # ... train `model`, then save it to `model_dir` as file 'model.npz'\n    chainer.serializers.save_npz(os.path.join(args.model_dir, 'model.npz'), model)\n```\n\n----------------------------------------\n\nTITLE: Downloading SageMaker Data Parallel Library Wheel for PyTorch 1.11.0\nDESCRIPTION: URL to download the SageMaker distributed data parallelism library v1.4.1 wheel file for PyTorch 1.11.0 in custom containers.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nhttps://smdataparallel.s3.amazonaws.com/binary/pytorch/1.11.0/cu113/2022-04-14/smdistributed_dataparallel-1.4.1-cp38-cp38-linux_x86_64.whl\n```\n\n----------------------------------------\n\nTITLE: Referencing SageMaker Configuration Values\nDESCRIPTION: Demonstrates two methods to access values from the SageMaker configuration dictionary: using the get_sagemaker_config_value utility function or directly accessing the nested dictionary.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_98\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.session import Session\nfrom sagemaker.utils import get_sagemaker_config_value\nsession=Session()\n\n# Option 1\nget_sagemaker_config_value(session, \"key1.key2\")\n# Option 2\nsession.sagemaker_config[\"key1\"][\"key2\"]\n```\n\n----------------------------------------\n\nTITLE: XGBoostProcessor Class Documentation Directive in ReStructuredText\nDESCRIPTION: Sphinx documentation directive that references the XGBoostProcessor class, displaying all members, undocumented members, and inheritance information in the generated documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/xgboost.rst#2025-04-22_snippet_3\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. autoclass:: sagemaker.xgboost.processing.XGBoostProcessor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Default Configuration File Locations for SageMaker Notebook Instances\nDESCRIPTION: The default file paths for SageMaker configuration files when using SageMaker Notebook instances. Admin config is stored in system-wide location while user config is in the user's home directory.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_93\n\nLANGUAGE: python\nCODE:\n```\n#Location of the admin config file\n/etc/xdg/sagemaker/config.yaml\n\n#Location of the user config file\n/home/ec2-user/.config/sagemaker/config.yaml\n```\n\n----------------------------------------\n\nTITLE: Specifying PyTorch 1.12.0 Deep Learning Container in AWS ECR\nDESCRIPTION: Docker image URI for the AWS Deep Learning Container with PyTorch 1.12.0 and the SageMaker distributed data parallelism library v1.5.0.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n763104351884.dkr.ecr.<region>.amazonaws.com/pytorch-training:1.12.0-gpu-py38-cu113-ubuntu20.04-sagemaker\n```\n\n----------------------------------------\n\nTITLE: Documenting load_run Function in SageMaker Experiments (Python)\nDESCRIPTION: Auto-generated documentation for the load_run function in the SageMaker experiments module. This function is likely used to load an existing experimental run.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/experiments/sagemaker.experiments.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. automethod:: sagemaker.experiments.run.load_run\n```\n\n----------------------------------------\n\nTITLE: Retrieving Custom Environment Variable\nDESCRIPTION: Accesses a custom environment variable named 'env_key' and prints it with a prefix to identify the source notebook.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/notebook1_happypath.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(f\"ParentNotebook: env_key={os.getenv('env_key')}\")\n```\n\n----------------------------------------\n\nTITLE: Specifying SciPy Dependency for SageMaker Python SDK\nDESCRIPTION: This line specifies that SciPy version 1.11.3 is required for the SageMaker Python SDK. It is likely part of a requirements.txt file used for managing Python package dependencies.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nscipy==1.11.3\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation for SageMaker Feature Store Utilities\nDESCRIPTION: RST directive for auto-documenting the sagemaker.feature_store.feature_utils module. The directive specifies that all members and undocumented members should be included in the documentation, and inheritance information should be shown.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/featuregroup_utils.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.feature_store.feature_utils\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Defining SageMaker Predictor Class Documentation Structure in reStructuredText\nDESCRIPTION: This snippet defines the documentation structure for the SageMaker Predictor class using reStructuredText format. It specifies that class members, undocumented members, and inheritance information should be included in the generated documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/predictors.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. autoclass:: sagemaker.predictor.Predictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Downloading SageMaker Data Parallel Library Wheel for PyTorch 1.12.0\nDESCRIPTION: URL to download the SageMaker distributed data parallelism library v1.5.0 wheel file for PyTorch 1.12.0 in custom containers.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nhttps://smdataparallel.s3.amazonaws.com/binary/pytorch/1.12.0/cu113/2022-07-01/smdistributed_dataparallel-1.5.0-cp38-cp38-linux_x86_64.whl\n```\n\n----------------------------------------\n\nTITLE: Running unit tests with tox for SageMaker Python SDK\nDESCRIPTION: Command to run unit tests for the SageMaker Python SDK using tox.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntox tests/unit\n```\n\n----------------------------------------\n\nTITLE: Creating and Activating Python Virtual Environment\nDESCRIPTION: Commands to create a Python virtual environment for managing project dependencies, activate it, and deactivate when finished.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython -m venv ~/.venv/myproject-env\nsource ~/.venv/myproject-env/bin/activate\ndeactivate\n```\n\n----------------------------------------\n\nTITLE: Documenting SageMaker Processing Modules in RST\nDESCRIPTION: RST directives for generating documentation from SageMaker Python SDK modules related to data processing. The directives include standard processing, Spark-based processing, and the Clarify module for explainability.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/processing.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.processing\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\n.. automodule:: sagemaker.spark.processing\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\n.. automodule:: sagemaker.clarify\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Specifying OmegaConf Package Dependency in Plain Text\nDESCRIPTION: This snippet specifies the OmegaConf package as a requirement or dependency for the project. OmegaConf is a YAML-based hierarchical configuration system for Python applications.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/modules/params_script/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nomegaconf\n```\n\n----------------------------------------\n\nTITLE: SageMaker K-means Model Documentation\nDESCRIPTION: ReStructuredText directive for auto-documenting the SageMaker KMeansModel class used for inference.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/unsupervised/kmeans.rst#2025-04-22_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.KMeansModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring RST Table of Contents for SageMaker SDK Docs\nDESCRIPTION: ReStructuredText directive configuring a table of contents with maximum depth of 1, listing documentation pages for data parallel implementations.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1_1_x.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n\n   v1.1.x/smd_data_parallel_pytorch.rst\n   v1.1.x/smd_data_parallel_tensorflow.rst\n```\n\n----------------------------------------\n\nTITLE: Specifying PyTorch 1.10.2 Deep Learning Container in AWS ECR\nDESCRIPTION: Docker image URI for the AWS Deep Learning Container with PyTorch 1.10.2 and the SageMaker distributed data parallelism library v1.4.0.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n763104351884.dkr.ecr.<region>.amazonaws.com/pytorch-training:1.10.2-gpu-py38-cu113-ubuntu20.04-sagemaker\n```\n\n----------------------------------------\n\nTITLE: Documenting SortByType Class in SageMaker Experiments (Python)\nDESCRIPTION: Auto-generated documentation for the SortByType class in the SageMaker experiments module. This class probably defines sorting options for experiment-related queries.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/experiments/sagemaker.experiments.rst#2025-04-22_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.experiments.SortByType\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Setting up reStructuredText Documentation Tables of Contents for Chainer in SageMaker\nDESCRIPTION: Defines the documentation structure for Chainer in Amazon SageMaker using reStructuredText toctree directives. The first toctree points to a usage guide while the second links to the API reference for the sagemaker.chainer module.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. toctree::\n    :maxdepth: 1\n\n    using_chainer\n\n.. toctree::\n    :maxdepth: 2\n\n    sagemaker.chainer\n```\n\n----------------------------------------\n\nTITLE: Accessing TransformStep Properties in SageMaker Workflow\nDESCRIPTION: Example showing how to reference the output path property from a transform step. This demonstrates capturing the S3 output path of a model transformation job.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_model_building_pipeline.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nstep_transform = TransformStep(...)\ntransform_output = step_transform.TransformOutput.S3OutputPath\n```\n\n----------------------------------------\n\nTITLE: Running all integration tests for SageMaker Python SDK\nDESCRIPTION: Commands to run all integration tests for the SageMaker Python SDK using tox, both sequentially and in parallel.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntox -- tests/integ\n\n# Run tests in parallel\ntox -- -n auto tests/integ\n```\n\n----------------------------------------\n\nTITLE: Named Entity Recognition Documentation Header\nDESCRIPTION: RST format header for the Named Entity Recognition documentation section that outlines the main topic.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/text/named_entity_recognition_hugging_face.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n########################################\nNamed Entity Recognition - HuggingFace\n########################################\n```\n\n----------------------------------------\n\nTITLE: Accessing Environment Variable from Init Script\nDESCRIPTION: Demonstrates how to access an environment variable set by an initialization script using os.getenv() and prints it using an f-string.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/notebook1_happypath.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nprint(f\"ParentNotebook: ENV_VAR_FROM_INIT_SCRIPT={os.getenv('ENV_VAR_FROM_INIT_SCRIPT')}\")\n```\n\n----------------------------------------\n\nTITLE: Formatting AWS SageMaker String in Python\nDESCRIPTION: This code snippet initializes two variables for company and organization names, then uses an f-string to format and print them. It's a basic example of string manipulation in the context of AWS SageMaker.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/simple.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ncompany=\"aws\"\norg=\"sagemaker\"\nprint(f\"{company}-{org}\")\n```\n\n----------------------------------------\n\nTITLE: Documenting IPInsightsPredictor Class in Python for Amazon SageMaker\nDESCRIPTION: Autogenerated documentation for the IPInsightsPredictor class, which is likely used for making predictions with a trained IP Insights model in Amazon SageMaker. It includes all members and inherited members.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/unsupervised/ipinsights.rst#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.IPInsightsPredictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Specifying SciPy Dependency for SageMaker Python SDK\nDESCRIPTION: This line specifies that the SageMaker Python SDK requires SciPy version 1.11.3. It is likely part of a requirements.txt file used for managing Python package dependencies.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/remote_function/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nscipy==1.11.3\n```\n\n----------------------------------------\n\nTITLE: Installing SageMaker Python SDK via pip\nDESCRIPTION: Command to install the latest version of the SageMaker Python SDK using pip. The user should replace <Latest version> with the actual version number from PyPI.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install sagemaker==<Latest version from pyPI from https://pypi.org/project/sagemaker/>\n```\n\n----------------------------------------\n\nTITLE: Documenting Chainer Predictor Class in Python\nDESCRIPTION: Autoclass directive for generating documentation for the Chainer predictor class. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/sagemaker.chainer.rst#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.chainer.model.ChainerPredictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Table of Contents for XGBoost Documentation\nDESCRIPTION: RST markup configuring a table of contents (toctree) for XGBoost documentation. Sets maximum depth to 1 and uses glob pattern to include all files in the directory.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n   :glob:\n\n   *\n```\n\n----------------------------------------\n\nTITLE: Initializing SageMaker Data Parallel Library in TensorFlow\nDESCRIPTION: Imports and initializes the SageMaker distributed data parallel library for TensorFlow integration.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport smdistributed.dataparallel.tensorflow as sdp\nsdp.init()\n```\n\n----------------------------------------\n\nTITLE: Building Sphinx documentation for SageMaker Python SDK\nDESCRIPTION: Commands to set up a Python environment, install dependencies, and build the Sphinx documentation for the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# conda\nconda create -n sagemaker python=3.12\nconda activate sagemaker\nconda install sphinx=5.1.1 sphinx_rtd_theme=0.5.0\n\n# pip\npip install -r doc/requirements.txt\n\npip install --upgrade .\n\ncd sagemaker-python-sdk/doc\nmake html\n\ncd _build/html\npython -m http.server 8000\n```\n\n----------------------------------------\n\nTITLE: Documenting FactorizationMachinesModel Class in Python\nDESCRIPTION: Autodoc configuration for the FactorizationMachinesModel class. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/tabular/factorization_machines.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.FactorizationMachinesModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Reference to Built-in Algorithms Documentation\nDESCRIPTION: RST reference link to detailed documentation about using built-in algorithms with pre-trained models in the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/vision/object_detection_tensorflow.rst#2025-04-22_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n:ref:`Use Built-in Algorithms with Pre-trained Models in SageMaker Python SDK <built-in-algos>`\n```\n\n----------------------------------------\n\nTITLE: Importing SageMaker Serverless Inference Module\nDESCRIPTION: Python module import statement for accessing the SageMaker serverless inference configuration functionality. This module contains classes for configuring serverless inference endpoints.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/serverless.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n.. automodule:: sagemaker.serverless.serverless_inference_config\n```\n\n----------------------------------------\n\nTITLE: Defining ImageNet Classification Labels in Python\nDESCRIPTION: A dictionary mapping ImageNet class indices to their corresponding class names, including various natural objects like flowers, fungi, and common items. This represents indices 982-999 of the standard ImageNet 1000-class classification labels.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/pytorch_neo/imagenet1000_clsidx_to_labels.txt#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{\n 982: 'groom, bridegroom',\n 983: 'scuba diver',\n 984: 'rapeseed',\n 985: 'daisy',\n 986: \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\",\n 987: 'corn',\n 988: 'acorn',\n 989: 'hip, rose hip, rosehip',\n 990: 'buckeye, horse chestnut, conker',\n 991: 'coral fungus',\n 992: 'agaric',\n 993: 'gyromitra',\n 994: 'stinkhorn, carrion fungus',\n 995: 'earthstar',\n 996: 'hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa',\n 997: 'bolete',\n 998: 'ear, spike, capitulum',\n 999: 'toilet tissue, toilet paper, bathroom tissue'}\n```\n\n----------------------------------------\n\nTITLE: Configuring ReStructuredText autodoc for SageMaker network module documentation\nDESCRIPTION: ReStructuredText autodoc directive that automatically generates API documentation for the SageMaker network module. The directive includes all members, undocumented members, and shows inheritance relationships.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/network.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.network\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Retrieving Default SageMaker Registry Function in Python\nDESCRIPTION: Provides a function to retrieve the default SageMaker container registry for a given AWS region. The function returns the account ID associated with the SageMaker container registry for the specified region.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/tfs/tfs-test-model-with-inference/00000123/assets/foo.txt#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef retrieve_default_sagemaker_registry(region):\n    \"\"\"\n    Retrieve the default SageMaker registry account id given a region.\n\n    Args:\n        region (str): The AWS region for which you are querying.\n\n    Returns:\n        str: The SageMaker account registry that contains framework images for the specified region.\n    \"\"\"\n    return _SAGEMAKER_ACCOUNT_REGISTRY_BY_REGION.get(region, \"404615174143\")\n```\n\n----------------------------------------\n\nTITLE: ImageNet Class Labels Dictionary Definition in Python\nDESCRIPTION: A Python dictionary mapping numerical indices to class labels for the ImageNet dataset. Each key is an integer index, and each value is a string containing the class name, often including both common and scientific names of various animals and objects.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/pytorch_neo/imagenet1000_clsidx_to_labels.txt#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{0: 'tench, Tinca tinca',\n 1: 'goldfish, Carassius auratus',\n 2: 'great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias',\n 3: 'tiger shark, Galeocerdo cuvieri',\n 4: 'hammerhead, hammerhead shark',\n 5: 'electric ray, crampfish, numbfish, torpedo',\n 6: 'stingray',\n 7: 'cock',\n 8: 'hen',\n 9: 'ostrich, Struthio camelus',\n 10: 'brambling, Fringilla montifringilla',\n 11: 'goldfinch, Carduelis carduelis',\n 12: 'house finch, linnet, Carpodacus mexicanus',\n 13: 'junco, snowbird',\n 14: 'indigo bunting, indigo finch, indigo bird, Passerina cyanea',\n 15: 'robin, American robin, Turdus migratorius',\n 16: 'bulbul',\n 17: 'jay',\n 18: 'magpie',\n 19: 'chickadee',\n 20: 'water ouzel, dipper',\n 21: 'kite',\n 22: 'bald eagle, American eagle, Haliaeetus leucocephalus',\n 23: 'vulture',\n 24: 'great grey owl, great gray owl, Strix nebulosa',\n 25: 'European fire salamander, Salamandra salamandra',\n 26: 'common newt, Triturus vulgaris',\n 27: 'eft',\n 28: 'spotted salamander, Ambystoma maculatum',\n 29: 'axolotl, mud puppy, Ambystoma mexicanum',\n 30: 'bullfrog, Rana catesbeiana',\n 31: 'tree frog, tree-frog',\n 32: 'tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui',\n 33: 'loggerhead, loggerhead turtle, Caretta caretta',\n 34: 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea',\n 35: 'mud turtle',\n 36: 'terrapin',\n 37: 'box turtle, box tortoise',\n 38: 'banded gecko',\n 39: 'common iguana, iguana, Iguana iguana',\n 40: 'American chameleon, anole, Anolis carolinensis',\n 41: 'whiptail, whiptail lizard',\n 42: 'agama',\n 43: 'frilled lizard, Chlamydosaurus kingi',\n 44: 'alligator lizard',\n 45: 'Gila monster, Heloderma suspectum',\n 46: 'green lizard, Lacerta viridis',\n 47: 'African chameleon, Chamaeleo chamaeleon',\n 48: 'Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis',\n 49: 'African crocodile, Nile crocodile, Crocodylus niloticus',\n 50: 'American alligator, Alligator mississipiensis',\n 51: 'triceratops',\n 52: 'thunder snake, worm snake, Carphophis amoenus',\n 53: 'ringneck snake, ring-necked snake, ring snake',\n 54: 'hognose snake, puff adder, sand viper',\n 55: 'green snake, grass snake',\n 56: 'king snake, kingsnake',\n 57: 'garter snake, grass snake',\n 58: 'water snake',\n 59: 'vine snake',\n 60: 'night snake, Hypsiglena torquata',\n 61: 'boa constrictor, Constrictor constrictor',\n 62: 'rock python, rock snake, Python sebae',\n 63: 'Indian cobra, Naja naja',\n 64: 'green mamba',\n 65: 'sea snake',\n 66: 'horned viper, cerastes, sand viper, horned asp, Cerastes cornutus',\n 67: 'diamondback, diamondback rattlesnake, Crotalus adamanteus',\n 68: 'sidewinder, horned rattlesnake, Crotalus cerastes',\n 69: 'trilobite',\n 70: 'harvestman, daddy longlegs, Phalangium opilio',\n 71: 'scorpion',\n 72: 'black and gold garden spider, Argiope aurantia',\n 73: 'barn spider, Araneus cavaticus',\n 74: 'garden spider, Aranea diademata',\n 75: 'black widow, Latrodectus mactans',\n 76: 'tarantula',\n 77: 'wolf spider, hunting spider',\n 78: 'tick',\n 79: 'centipede',\n 80: 'black grouse',\n 81: 'ptarmigan',\n 82: 'ruffed grouse, partridge, Bonasa umbellus',\n 83: 'prairie chicken, prairie grouse, prairie fowl',\n 84: 'peacock',\n 85: 'quail',\n 86: 'partridge',\n 87: 'African grey, African gray, Psittacus erithacus',\n 88: 'macaw',\n 89: 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',\n 90: 'lorikeet',\n 91: 'coucal',\n 92: 'bee eater',\n 93: 'hornbill',\n 94: 'hummingbird',\n 95: 'jacamar',\n 96: 'toucan',\n 97: 'drake',\n 98: 'red-breasted merganser, Mergus serrator',\n 99: 'goose',\n 100: 'black swan, Cygnus atratus',\n 101: 'tusker',\n 102: 'echidna, spiny anteater, anteater',\n 103: 'platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus',\n 104: 'wallaby, brush kangaroo',\n 105: 'koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus',\n 106: 'wombat',\n 107: 'jellyfish',\n 108: 'sea anemone, anemone',\n 109: 'brain coral',\n 110: 'flatworm, platyhelminth',\n 111: 'nematode, nematode worm, roundworm',\n 112: 'conch',\n 113: 'snail',\n 114: 'slug',\n 115: 'sea slug, nudibranch',\n 116: 'chiton, coat-of-mail shell, sea cradle, polyplacophore',\n 117: 'chambered nautilus, pearly nautilus, nautilus',\n 118: 'Dungeness crab, Cancer magister',\n 119: 'rock crab, Cancer irroratus',\n 120: 'fiddler crab',\n 121: 'king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica',\n 122: 'American lobster, Northern lobster, Maine lobster, Homarus americanus',\n 123: 'spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish',\n 124: 'crayfish, crawfish, crawdad, crawdaddy',\n 125: 'hermit crab',\n 126: 'isopod',\n 127: 'white stork, Ciconia ciconia',\n 128: 'black stork, Ciconia nigra',\n 129: 'spoonbill',\n 130: 'flamingo',\n 131: 'little blue heron, Egretta caerulea',\n 132: 'American egret, great white heron, Egretta albus',\n 133: 'bittern',\n 134: 'crane',\n 135: 'limpkin, Aramus pictus',\n 136: 'European gallinule, Porphyrio porphyrio',\n 137: 'American coot, marsh hen, mud hen, water hen, Fulica americana',\n 138: 'bustard',\n 139: 'ruddy turnstone, Arenaria interpres',\n 140: 'red-backed sandpiper, dunlin, Erolia alpina',\n 141: 'redshank, Tringa totanus',\n 142: 'dowitcher',\n 143: 'oystercatcher, oyster catcher',\n 144: 'pelican',\n 145: 'king penguin, Aptenodytes patagonica',\n 146: 'albatross, mollymawk',\n 147: 'grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus',\n 148: 'killer whale, killer, orca, grampus, sea wolf, Orcinus orca',\n 149: 'dugong, Dugong dugon',\n 150: 'sea lion',\n 151: 'Chihuahua',\n 152: 'Japanese spaniel',\n 153: 'Maltese dog, Maltese terrier, Maltese',\n 154: 'Pekinese, Pekingese, Peke',\n 155: 'Shih-Tzu',\n 156: 'Blenheim spaniel',\n 157: 'papillon',\n 158: 'toy terrier',\n 159: 'Rhodesian ridgeback',\n 160: 'Afghan hound, Afghan',\n 161: 'basset, basset hound',\n 162: 'beagle',\n 163: 'bloodhound, sleuthhound',\n 164: 'bluetick',\n 165: 'black-and-tan coonhound',\n 166: 'Walker hound, Walker foxhound',\n 167: 'English foxhound',\n 168: 'redbone',\n 169: 'borzoi, Russian wolfhound',\n 170: 'Irish wolfhound',\n 171: 'Italian greyhound',\n 172: 'whippet',\n 173: 'Ibizan hound, Ibizan Podenco',\n 174: 'Norwegian elkhound, elkhound',\n 175: 'otterhound, otter hound',\n 176: 'Saluki, gazelle hound',\n 177: 'Scottish deerhound, deerhound',\n 178: 'Weimaraner',\n 179: 'Staffordshire bullterrier, Staffordshire bull terrier',\n 180: 'American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier',\n 181: 'Bedlington terrier',\n 182: 'Border terrier',\n 183: 'Kerry blue terrier',\n 184: 'Irish terrier',\n 185: 'Norfolk terrier',\n 186: 'Norwich terrier',\n 187: 'Yorkshire terrier',\n 188: 'wire-haired fox terrier',\n 189: 'Lakeland terrier',\n 190: 'Sealyham terrier, Sealyham',\n 191: 'Airedale, Airedale terrier',\n 192: 'cairn, cairn terrier',\n 193: 'Australian terrier',\n 194: 'Dandie Dinmont, Dandie Dinmont terrier',\n 195: 'Boston bull, Boston terrier',\n 196: 'miniature schnauzer',\n 197: 'giant schnauzer',\n 198: 'standard schnauzer',\n 199: 'Scotch terrier, Scottish terrier, Scottie',\n 200: 'Tibetan terrier, chrysanthemum dog',\n 201: 'silky terrier, Sydney silky',\n 202: 'soft-coated wheaten terrier',\n 203: 'West Highland white terrier',\n 204: 'Lhasa, Lhasa apso',\n 205: 'flat-coated retriever',\n 206: 'curly-coated retriever',\n 207: 'golden retriever',\n 208: 'Labrador retriever',\n 209: 'Chesapeake Bay retriever',\n 210: 'German short-haired pointer',\n 211: 'vizsla, Hungarian pointer',\n 212: 'English setter',\n 213: 'Irish setter, red setter',\n 214: 'Gordon setter',\n 215: 'Brittany spaniel',\n 216: 'clumber, clumber spaniel',\n 217: 'English springer, English springer spaniel',\n 218: 'Welsh springer spaniel',\n 219: 'cocker spaniel, English cocker spaniel, cocker',\n 220: 'Sussex spaniel',\n 221: 'Irish water spaniel',\n 222: 'kuvasz',\n 223: 'schipperke',\n 224: 'groenendael',\n 225: 'malinois',\n 226: 'briard',\n 227: 'kelpie',\n 228: 'komondor',\n 229: 'Old English sheepdog, bobtail',\n 230: 'Shetland sheepdog, Shetland sheep dog, Shetland',\n 231: 'collie',\n 232: 'Border collie',\n 233: 'Bouvier des Flandres, Bouviers des Flandres',\n 234: 'Rottweiler',\n 235: 'German shepherd, German shepherd dog, German police dog, alsatian',\n 236: 'Doberman, Doberman pinscher',\n 237: 'miniature pinscher',\n 238: 'Greater Swiss Mountain dog',\n 239: 'Bernese mountain dog',\n 240: 'Appenzeller',\n 241: 'EntleBucher',\n 242: 'boxer',\n 243: 'bull mastiff',\n 244: 'Tibetan mastiff',\n 245: 'French bulldog',\n 246: 'Great Dane',\n 247: 'Saint Bernard, St Bernard',\n 248: 'Eskimo dog, husky',\n 249: 'malamute, malemute, Alaskan malamute',\n 250: 'Siberian husky',\n 251: 'dalmatian, coach dog, carriage dog',\n 252: 'affenpinscher, monkey pinscher, monkey dog',\n 253: 'basenji',\n 254: 'pug, pug-dog',\n 255: 'Leonberg',\n 256: 'Newfoundland, Newfoundland dog',\n 257: 'Great Pyrenees',\n 258: 'Samoyed, Samoyede',\n 259: 'Pomeranian',\n 260: 'chow, chow chow',\n 261: 'keeshond',\n 262: 'Brabancon griffon',\n 263: 'Pembroke, Pembroke Welsh corgi',\n 264: 'Cardigan, Cardigan Welsh corgi',\n 265: 'toy poodle',\n 266: 'miniature poodle',\n 267: 'standard poodle',\n 268: 'Mexican hairless',\n 269: 'timber wolf, grey wolf, gray wolf, Canis lupus',\n 270: 'white wolf, Arctic wolf, Canis lupus tundrarum',\n 271: 'red wolf, maned wolf, Canis rufus, Canis niger',\n 272: 'coyote, prairie wolf, brush wolf, Canis latrans',\n 273: 'dingo, warrigal, warragal, Canis dingo',\n 274: 'dhole, Cuon alpinus',\n 275: 'African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus',\n 276: 'hyena, hyaena',\n 277: 'red fox, Vulpes vulpes',\n 278: 'kit fox, Vulpes macrotis',\n 279: 'Arctic fox, white fox, Alopex lagopus',\n 280: 'grey fox, gray fox, Urocyon cinereoargenteus',\n 281: 'tabby, tabby cat',\n 282: 'tiger cat',\n 283: 'Persian cat',\n 284: 'Siamese cat, Siamese',\n 285: 'Egyptian cat',\n 286: 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor',\n 287: 'lynx, catamount',\n 288: 'leopard, Panthera pardus'}\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for SageMaker Python SDK\nDESCRIPTION: This code snippet defines the Python packages and their version constraints required for the AWS SageMaker Python SDK. It includes accelerate for performance optimization, sagemaker_schema_inference_artifacts for schema handling, uvicorn as an ASGI server, fastapi for building APIs, and nest-asyncio for handling nested asyncio event loops.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/extras/huggingface_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\naccelerate>=0.24.1,<=0.27.0\nsagemaker_schema_inference_artifacts>=0.0.5\nuvicorn>=0.30.1\nfastapi>=0.111.0\nnest-asyncio\n```\n\n----------------------------------------\n\nTITLE: Specifying pydocstyle Version for AWS SageMaker SDK\nDESCRIPTION: This snippet defines the exact version of pydocstyle to be used in the project. pydocstyle is a static analysis tool for checking compliance with Python docstring conventions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/tox/pydocstyle_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\npydocstyle==6.1.1\n```\n\n----------------------------------------\n\nTITLE: Training a model using Amazon SageMaker Python SDK\nDESCRIPTION: This code snippet demonstrates how to train a machine learning model using the Amazon SageMaker Python SDK. It shows the process of creating an estimator, specifying hyperparameters, and starting the training job.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/doc_utils/pretrainedmodels.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.pytorch import PyTorch\n\nestimator = PyTorch(\n    entry_point='mnist.py',\n    role='SageMakerRole',\n    instance_type='ml.p2.xlarge',\n    instance_count=1,\n    framework_version='1.8.0',\n    py_version='py3',\n    hyperparameters={\n        'epochs': 20,\n        'batch-size': 64,\n        'learning-rate': 0.1\n    }\n)\n\nestimator.fit({'training': 's3://my-data-bucket/path/to/my/training/data'})\n```\n\n----------------------------------------\n\nTITLE: Creating a New Git Branch\nDESCRIPTION: Git command to create a new branch for making changes in the SageMaker Python SDK project.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ngit checkout -b my-fix-branch master\n```\n\n----------------------------------------\n\nTITLE: Documenting IPInsightsModel Class in Python for Amazon SageMaker\nDESCRIPTION: Autogenerated documentation for the IPInsightsModel class, which likely represents a trained IP Insights model in Amazon SageMaker. It includes all members and inherited members.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/unsupervised/ipinsights.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.IPInsightsModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Initializing SageMaker Job Variables in Python\nDESCRIPTION: Initializes placeholder variables for a SageMaker notebook job with default 'not_defined' values. These variables likely track job name, status, input/output locations, and notebook names for a SageMaker processing job.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/step2_notebook.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nstep1_JobName = 'not_defined'\nstep1_JobStatus = 'not_defined'\nstep1_NotebookJobInput = 'not_defined'\nstep1_NotebookJobOutput = 'not_defined'\nstep1_InputNotebookName = 'not_defined'\nstep1_OutputNotebookName = 'not_defined'\n```\n\n----------------------------------------\n\nTITLE: Documenting SageMaker Analytics Base Class in reStructuredText\nDESCRIPTION: Documentation directive for the AnalyticsMetricsBase class in the SageMaker Python SDK, including all members, undocumented members, and inheritance information. This serves as the base class for other analytics classes.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/analytics.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. autoclass:: sagemaker.analytics.AnalyticsMetricsBase\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Sphinx AutoModule Documentation for SageMaker Environment Variables\nDESCRIPTION: Sphinx directive configuration for automatically generating documentation from the sagemaker.environment_variables module. Includes all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/environment_variables.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. automodule:: sagemaker.environment_variables\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Defining AWS Regions by Machine Learning Variant in Python\nDESCRIPTION: Maps AWS machine learning variants to their corresponding regions. This dictionary groups AWS regions based on different machine learning service variants, which is useful for determining region-specific container configurations.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/tfs/tfs-test-model-with-inference/00000123/assets/foo.txt#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n_AWS_REGIONS_BY_ML_VARIANT = {\n    \"ml.c5.xlarge\": [\n        \"af-south-1\",\n        \"ap-east-1\",\n        \"ap-northeast-1\",\n        \"ap-northeast-2\",\n        \"ap-northeast-3\",\n        \"ap-south-1\",\n        \"ap-southeast-1\",\n        \"ap-southeast-2\",\n        \"ca-central-1\",\n        \"eu-central-1\",\n        \"eu-north-1\",\n        \"eu-south-1\",\n        \"eu-south-2\",\n        \"eu-west-1\",\n        \"eu-west-2\",\n        \"eu-west-3\",\n        \"il-central-1\",\n        \"me-central-1\",\n        \"me-south-1\",\n        \"sa-east-1\",\n        \"us-east-1\",\n        \"us-east-2\",\n        \"us-west-1\",\n        \"us-west-2\",\n    ],\n    \"ml.p4d.24xlarge\": [\"us-east-1\", \"us-west-2\"],\n    \"ml.g4dn.xlarge\": [\n        \"af-south-1\",\n        \"ap-east-1\",\n        \"ap-northeast-1\",\n        \"ap-northeast-2\",\n        \"ap-south-1\",\n        \"ap-southeast-1\",\n        \"ap-southeast-2\",\n        \"ca-central-1\",\n        \"eu-central-1\",\n        \"eu-north-1\",\n        \"eu-south-1\",\n        \"eu-west-1\",\n        \"eu-west-2\",\n        \"eu-west-3\",\n        \"me-south-1\",\n        \"sa-east-1\",\n        \"us-east-1\",\n        \"us-east-2\",\n        \"us-west-1\",\n        \"us-west-2\",\n    ],\n    \"ml.g5.xlarge\": [\n        \"ap-northeast-1\",\n        \"ap-southeast-1\",\n        \"ap-southeast-2\",\n        \"eu-central-1\",\n        \"eu-west-1\",\n        \"eu-west-2\",\n        \"us-east-1\",\n        \"us-east-2\",\n        \"us-west-2\",\n    ],\n    \"cn-region\": [\"cn-north-1\", \"cn-northwest-1\"],\n    \"us-gov\": [\"us-gov-west-1\"],\n    \"us-iso\": [\"us-iso-east-1\"],\n    \"us-isob\": [\"us-isob-east-1\"],\n}\n```\n\n----------------------------------------\n\nTITLE: Documenting FactorizationMachines Class in Python\nDESCRIPTION: Autodoc configuration for the FactorizationMachines class. It includes all members, undocumented members, inherited members, and shows inheritance. Specific attributes are excluded from the documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/tabular/factorization_machines.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.FactorizationMachines\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :inherited-members:\n    :exclude-members: image_uri, num_factors, predictor_type, epochs, clip_gradient, mini_batch_size, feature_dim, eps, rescale_grad, bias_lr, linear_lr, factors_lr, bias_wd, linear_wd, factors_wd, bias_init_method, bias_init_scale, bias_init_sigma, bias_init_value, linear_init_method, linear_init_scale, linear_init_sigma, linear_init_value, factors_init_method, factors_init_scale, factors_init_sigma, factors_init_value\n```\n\n----------------------------------------\n\nTITLE: Specifying pydocstyle Version Requirement\nDESCRIPTION: Requirements file entry that pins pydocstyle package to version 6.1.1. This package is used for checking Python docstring conventions and documentation style.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/tox/docstyle_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npydocstyle==6.1.1\n```\n\n----------------------------------------\n\nTITLE: Defining PyTorch CPU-only Dependencies\nDESCRIPTION: This requirements file specifies numpy as a general dependency and a specific CPU-only version of PyTorch (2.0.1) to be installed from the official PyTorch repository. The -f flag indicates to use a specific package index URL to find the packages.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/modules/script_mode/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\n-f https://download.pytorch.org/whl/torch_stable.html\ntorch==2.0.1+cpu\n```\n\n----------------------------------------\n\nTITLE: Example of Deleting Multiple Feature Groups in SageMaker with Python\nDESCRIPTION: Shows how to delete multiple feature groups in a fraud detection example by calling the delete method on each feature group.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nidentity_feature_group.delete()\ntransaction_feature_group.delete()\n```\n\n----------------------------------------\n\nTITLE: Documentation Build Setup Commands\nDESCRIPTION: Shell commands for setting up and building the Sphinx documentation for the project.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n# Initial setup, only required for the first run\npip install -r requirements.txt\npip install -e ../\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake html\n```\n\n----------------------------------------\n\nTITLE: Documenting RandomCutForestModel Class in Python for Amazon SageMaker\nDESCRIPTION: Autoclass documentation for the RandomCutForestModel class in the sagemaker module. It includes all members and undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/unsupervised/randomcutforest.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.RandomCutForestModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Sphinx Autodoc Directive for SageMaker Lambda Helper Module\nDESCRIPTION: A reStructuredText (rst) directive that automatically generates documentation from the sagemaker.lambda_helper module. The directive includes all members, undocumented members, and shows inheritance relationships.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/lambda_helper.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.lambda_helper\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring AutoMLV2 Documentation in reStructuredText\nDESCRIPTION: Sphinx directive for automatically generating documentation for the sagemaker.automl.automlv2 module. The directive includes all members, undocumented members, and shows inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/automlv2.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: sagemaker.automl.automlv2\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring RST Documentation Tree Structure\nDESCRIPTION: Defines a toctree directive in reStructuredText that specifies documentation structure with a maximum depth of 1, linking to data parallel training documentation for PyTorch and TensorFlow.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1_0_0.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n\n   v1.0.0/smd_data_parallel_pytorch.rst\n   v1.0.0/smd_data_parallel_tensorflow.rst\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx toctree for SageMaker Python SDK Inference APIs\nDESCRIPTION: This reStructuredText snippet configures the Sphinx toctree directive to include all files in the current directory for the Inference APIs documentation. It sets the maximum depth to 1 and uses a glob pattern to include all files.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n   :glob:\n\n   *\n```\n\n----------------------------------------\n\nTITLE: Defining ReStructuredText Table of Contents for SageMaker Pipelines\nDESCRIPTION: A ReStructuredText formatted document header and table of contents for the SageMaker Pipelines module documentation. It defines the document title and includes a toctree directive that references the sagemaker.workflow.pipelines module.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/pipelines/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n###################\nSageMaker Pipelines\n###################\n\nSageMaker APIs for creating and managing SageMaker Pipelines.\n\n.. toctree::\n    :maxdepth: 2\n\n    sagemaker.workflow.pipelines\n```\n\n----------------------------------------\n\nTITLE: Specifying mypy Version Dependency for SageMaker Python SDK\nDESCRIPTION: This requirement specifies that version 0.942 of mypy should be used for the project. Mypy is a static type checker that helps identify potential type-related issues in Python code during development.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/tox/mypy_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: requirements.txt\nCODE:\n```\nmypy==0.942\n```\n\n----------------------------------------\n\nTITLE: Python Docstring Example\nDESCRIPTION: Example of a Google-style docstring format used for documenting Python functions in the codebase.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef foo():\n    \"\"\"This comment is a docstring for the function foo.\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Executing Sub-Notebook in Subfolder using Jupyter Magic\nDESCRIPTION: Uses the Jupyter %run magic command to execute a notebook located in a subfolder. This allows for modular code organization and reuse across notebooks.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/notebook1_happypath.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n%run 'subfolder/sub.ipynb'\n```\n\n----------------------------------------\n\nTITLE: Running Distributed Training Job with Timeout\nDESCRIPTION: Executes the distributed training job using the configured estimator. Uses a timeout to limit the execution time and fits the estimator with sample MNIST data from S3.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/dummy_input.txt#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nwith timeout(minutes=20):\n    estimator.fit({\"training\": \"s3://sagemaker-sample-data-{}/tensorflow/mnist\".format(REGION)})\n\nmodel_data = estimator.model_data\nassert model_data.startswith(\"s3://\")\n```\n\n----------------------------------------\n\nTITLE: RestructuredText Documentation Structure\nDESCRIPTION: Defines the documentation structure for SageMaker built-in algorithms using RestructuredText format, including section headers and toctree directive for organizing sub-pages.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n######################\nBuilt-in Algorithms\n######################\n\n.. toctree::\n    :maxdepth: 2\n\n    sagemaker.amazon.amazon_estimator\n    tabular/index\n    text/index\n    time_series/index\n    unsupervised/index\n    vision/index\n```\n\n----------------------------------------\n\nTITLE: Documenting list_runs Function in SageMaker Experiments (Python)\nDESCRIPTION: Auto-generated documentation for the list_runs function in the SageMaker experiments module. This function probably retrieves a list of experimental runs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/experiments/sagemaker.experiments.rst#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n.. automethod:: sagemaker.experiments.list_runs\n```\n\n----------------------------------------\n\nTITLE: LDAPredictor Class Documentation Configuration\nDESCRIPTION: Sphinx autodoc configuration for the LDA predictor class documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/text/lda.rst#2025-04-22_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.LDAPredictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Specifying Black Formatter Version for AWS SageMaker Python SDK\nDESCRIPTION: This snippet defines the required version of the 'black' code formatter. It ensures that version 24.3.0 of black is used for consistent code formatting in the AWS SageMaker Python SDK project.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/tox/black_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nblack==24.3.0\n```\n\n----------------------------------------\n\nTITLE: Documenting SageMaker Image URIs Module in RST\nDESCRIPTION: ReStructuredText directive for auto-generating documentation from the sagemaker.image_uris Python module, including all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/image_uris.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.image_uris\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Enabling Git hooks for SageMaker Python SDK development\nDESCRIPTION: Commands to enable all Git hooks in the .githooks directory for the SageMaker Python SDK repository.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nfind .git/hooks -type l -exec rm {} \\;\nfind .githooks -type f -exec ln -sf ../../{} .git/hooks/ \\;\n```\n\n----------------------------------------\n\nTITLE: Specifying SciPy Dependency for SageMaker Python SDK\nDESCRIPTION: This line defines the required version of SciPy for the Amazon SageMaker Python SDK. It ensures compatibility with version 1.11.3 of SciPy.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/extras/scipy_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nscipy==1.11.3\n```\n\n----------------------------------------\n\nTITLE: Printing Global Variable in Python\nDESCRIPTION: Prints the value of a global variable named 'company'. This assumes 'company' is defined elsewhere in the notebook or environment.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/subfolder/sub.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(f'SubNotebook: company_is_{company}')\n```\n\n----------------------------------------\n\nTITLE: SageMaker Training Configuration for Airflow\nDESCRIPTION: Configuration function for training jobs in SageMaker through Airflow\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/airflow/sagemaker.workflow.airflow.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autofunction:: sagemaker.workflow.airflow.training_config\n```\n\n----------------------------------------\n\nTITLE: Defining Datasets Package Dependency for SageMaker Python SDK\nDESCRIPTION: Specifies version 2.16.1 of the datasets package as a dependency. This package provides functionality for working with machine learning datasets in the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/huggingface/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\ndatasets==2.16.1\n```\n\n----------------------------------------\n\nTITLE: Creating Table of Contents for SageMaker Distributed Data Parallel Version Archive\nDESCRIPTION: This reStructuredText snippet creates a table of contents for archived versions of SageMaker Distributed Data Parallel documentation. It uses the 'toctree' directive to generate a list of links to separate documentation files for different versions.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/archives.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. _smddp-version-archive:\n\n.. toctree::\n    :maxdepth: 1\n\n    v1_2_x.rst\n    v1_1_x.rst\n    v1_0_0.rst\n```\n\n----------------------------------------\n\nTITLE: RST Table of Contents for TensorFlow Documentation\nDESCRIPTION: ReStructuredText markup defining the documentation structure and hierarchy for TensorFlow-related content in the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/tensorflow/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n    :maxdepth: 1\n\n    using_tf\n    deploying_tensorflow_serving\n    upgrade_from_legacy\n\n.. toctree::\n    :maxdepth: 2\n\n    sagemaker.tensorflow\n```\n\n----------------------------------------\n\nTITLE: Documenting IPInsights Class in Python for Amazon SageMaker\nDESCRIPTION: Autogenerated documentation for the IPInsights class, which represents the Amazon SageMaker IP Insights algorithm. It includes all members and inherited members, excluding specific attributes related to configuration and hyperparameters.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/unsupervised/ipinsights.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.IPInsights\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :inherited-members:\n    :exclude-members: image_uri, num_entity_vectors, vector_dim, batch_metrics_publish_interval, epochs, learning_rate,\n                      num_ip_encoder_layers, random_negative_sampling_rate, shuffled_negative_sampling_rate, weight_decay\n```\n\n----------------------------------------\n\nTITLE: Printing Another Environment Variable in Python\nDESCRIPTION: Retrieves and prints the value of an environment variable named 'env_key' using os.getenv().\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/subfolder/sub.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(f\"SubNotebook: env_key={os.getenv('env_key')}\")\n```\n\n----------------------------------------\n\nTITLE: PyTorch Documentation Structure in RST\nDESCRIPTION: Sphinx/RST documentation structure defining the PyTorch-related classes in the SageMaker Python SDK, including class autodoc directives for PyTorch Estimator, Model, Predictor, and Processor classes.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/pytorch/sagemaker.pytorch.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\nPyTorch\n=======\n\nPyTorch Estimator\n-----------------\n\n.. autoclass:: sagemaker.pytorch.estimator.PyTorch\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\nPyTorch Model\n-------------\n\n.. autoclass:: sagemaker.pytorch.model.PyTorchModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\nPyTorch Predictor\n-----------------\n\n.. autoclass:: sagemaker.pytorch.model.PyTorchPredictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\nPyTorch Processor\n-----------------\n\n.. autoclass:: sagemaker.pytorch.processing.PyTorchProcessor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Specifying PyTorch 1.10.0 Deep Learning Container in AWS ECR\nDESCRIPTION: Docker image URI for the AWS Deep Learning Container with PyTorch 1.10.0 and the SageMaker distributed data parallelism library v1.2.2.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n763104351884.dkr.ecr.<region>.amazonaws.com/pytorch-training:1.10.0-gpu-py38-cu113-ubuntu20.04-sagemaker\n```\n\n----------------------------------------\n\nTITLE: Documenting SageMaker Hyperparameter Tuning Analytics in reStructuredText\nDESCRIPTION: Documentation directive for the HyperparameterTuningJobAnalytics class in the SageMaker Python SDK, which provides analytics functionality for hyperparameter tuning jobs, including all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/analytics.rst#2025-04-22_snippet_1\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. autoclass:: sagemaker.analytics.HyperparameterTuningJobAnalytics\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring DistributedSampler for SageMaker Data Parallel Training\nDESCRIPTION: Modifies the DistributedSampler to include cluster information, setting num_replicas to the total number of GPUs across all nodes and providing the node rank.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.1.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrain_sampler = DistributedSampler(train_dataset, num_replicas=dist.get_world_size(), rank=dist.get_rank())\n```\n\n----------------------------------------\n\nTITLE: Defining SageMaker Dataset Definition Inputs Documentation with Sphinx\nDESCRIPTION: Sphinx directive to automatically generate documentation for the sagemaker.dataset_definition.inputs module, including all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/inputs.rst#2025-04-22_snippet_1\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. automodule:: sagemaker.dataset_definition.inputs\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Reference Label\nDESCRIPTION: ReStructuredText reference to detailed documentation about using built-in algorithms with pre-trained models in SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/vision/image_classification_pytorch.rst#2025-04-22_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n:ref:`Use Built-in Algorithms with Pre-trained Models in SageMaker Python SDK <built-in-algos>`\n```\n\n----------------------------------------\n\nTITLE: Printing Company Variable with F-String\nDESCRIPTION: Demonstrates using an f-string to print the value of the previously defined 'company' variable with a descriptive prefix.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/notebook1_happypath.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(f'ParentNotebook: company_is_{company}')\n```\n\n----------------------------------------\n\nTITLE: Referencing Object Detection Sample Notebook\nDESCRIPTION: Link to a sample Jupyter notebook demonstrating object detection implementation using Amazon SageMaker and pre-trained TensorFlow models. The notebook provides practical examples of using the SageMaker Python SDK for object detection tasks.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/vision/object_detection_tensorflow.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n`sample notebook <https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart_object_detection/Amazon_JumpStart_Object_Detection.ipynb>`__\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for SageMaker TensorFlow Integration Test\nDESCRIPTION: Imports necessary modules for running SageMaker TensorFlow integration tests, including pytest, boto3, and various SageMaker SDK components.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/dummy_input.txt#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport os\nimport time\n\nimport pytest\n\nfrom sagemaker import utils\nfrom sagemaker.tensorflow import TensorFlow\nfrom tests.integ import DATA_DIR, PYTHON_VERSION, REGION\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\n@pytest.fixture(scope=\"module\")\ndef sagemaker_session():\n    return utils.sagemaker_session()\n\n\ndef test_distributed_training_horovod(sagemaker_session, tmpdir):\n    estimator = TensorFlow(\n        entry_point=\"horovod_mnist.py\",\n        role=\"SageMakerRole\",\n        instance_type=\"ml.c5.xlarge\",\n        instance_count=2,\n        py_version=PYTHON_VERSION,\n        script_mode=True,\n        framework_version=\"2.3.1\",\n        distributions={\"mpi\": {\"enabled\": True}},\n        sagemaker_session=sagemaker_session,\n    )\n\n    with timeout(minutes=20):\n        estimator.fit({\"training\": \"s3://sagemaker-sample-data-{}/tensorflow/mnist\".format(REGION)})\n\n    model_data = estimator.model_data\n    assert model_data.startswith(\"s3://\")\n```\n\n----------------------------------------\n\nTITLE: Running filtered integration tests for SageMaker Python SDK\nDESCRIPTION: Command to run specific integration tests for the SageMaker Python SDK using tox and pytest filtering.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/README.rst#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntox -- -k 'test_i_care_about'\n```\n\n----------------------------------------\n\nTITLE: Using Overlap Function with TensorFlow Layer\nDESCRIPTION: Example showing how to use the overlap function with a TensorFlow layer to enable efficient overlapping of backward pass with all reduce operations. This is only applicable for models compiled with XLA.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nlayer = tf.nn.dropout(...) # Or any other layer\nlayer = smdistributed.dataparallel.tensorflow.overlap(layer)\n```\n\n----------------------------------------\n\nTITLE: Documenting SortOrderType Class in SageMaker Experiments (Python)\nDESCRIPTION: Auto-generated documentation for the SortOrderType class in the SageMaker experiments module. This class likely defines sorting order options for experiment-related queries.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/experiments/sagemaker.experiments.rst#2025-04-22_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.experiments.SortOrderType\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Example Response from a Record Retrieval in SageMaker Feature Store\nDESCRIPTION: An example of the response format when retrieving a record from the feature store, showing the structure with FeatureName and ValueAsString pairs.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/amazon_sagemaker_featurestore.rst#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n...\n'Record': [{'FeatureName': 'TransactionID', 'ValueAsString': '2990130'},\n  {'FeatureName': 'isFraud', 'ValueAsString': '0'},\n  {'FeatureName': 'TransactionDT', 'ValueAsString': '152647'},\n  {'FeatureName': 'TransactionAmt', 'ValueAsString': '75.0'},\n  {'FeatureName': 'ProductCD', 'ValueAsString': 'H'},\n  {'FeatureName': 'card1', 'ValueAsString': '4577'},\n...\n```\n\n----------------------------------------\n\nTITLE: Defining Fake Test Requirement in SageMaker SDK\nDESCRIPTION: A mock Python package dependency that specifies a non-existent package with version 1.0.0 for unit testing purposes. This is commonly used to test package resolution and dependency management without requiring actual external packages.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/dummy_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nfake-requirement-for-unit-tests==1.0.0\n```\n\n----------------------------------------\n\nTITLE: Configuring Flake8 Python Linting Dependencies\nDESCRIPTION: Specifies required Python packages for code linting using flake8 and its plugins. Includes flake8 v7.1.2 for main linting functionality and flake8-future-import v0.4.7 for validating import statements.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/tox/flake8_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: ini\nCODE:\n```\nflake8==7.1.2\nflake8-future-import==0.4.7\n```\n\n----------------------------------------\n\nTITLE: Printing Confirmation Message in Python\nDESCRIPTION: A simple Python print statement to confirm execution from a sub notebook.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/subfolder/sub.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nprint(\"from sub notebook\")\n```\n\n----------------------------------------\n\nTITLE: Defining SciPy Dependency Requirement for AWS SageMaker SDK\nDESCRIPTION: This requirement specifies that the AWS SageMaker Python SDK depends on SciPy version 1.11.3 or higher. This ensures compatibility with scientific computing features used within the SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/pipeline/model_step/pytorch_mnist/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nscipy>=1.11.3\n```\n\n----------------------------------------\n\nTITLE: Defining Training APIs Table of Contents in reStructuredText\nDESCRIPTION: This code snippet creates a hierarchical table of contents in reStructuredText format for the SageMaker Python SDK's training-related API documentation. It defines a section titled 'Training APIs' and links to various related modules like model trainers, algorithms, estimators, and tuning functionality.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n#############\nTraining APIs\n#############\n\n.. toctree::\n   :maxdepth: 1\n\n   model_trainer\n   algorithm\n   analytics\n   automl\n   automlv2\n   debugger\n   estimators\n   tuner\n   parameter\n   processing\n   profiler\n```\n\n----------------------------------------\n\nTITLE: Printing Environment Variable in Python\nDESCRIPTION: Retrieves and prints the value of an environment variable named 'ENV_VAR_FROM_INIT_SCRIPT' using os.getenv().\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/subfolder/sub.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nprint(f\"SubNotebook: ENV_VAR_FROM_INIT_SCRIPT={os.getenv('ENV_VAR_FROM_INIT_SCRIPT')}\")\n```\n\n----------------------------------------\n\nTITLE: Setting up toctree for SageMaker Python SDK documentation\nDESCRIPTION: ReStructuredText directive that creates a table of contents tree for SageMaker distributed data parallel documentation links for PyTorch and TensorFlow. The maxdepth parameter is set to 1 to limit the depth of the table of contents.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1_2_x.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n\n   v1.2.x/smd_data_parallel_pytorch.rst\n   v1.2.x/smd_data_parallel_tensorflow.rst\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Autodoc for SageMaker Accept Types Module\nDESCRIPTION: Sphinx autodoc directive to generate API documentation for the SageMaker accept_types module. The configuration includes documenting all members, undocumented members, inheritance, and private members.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/accept_types.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.accept_types\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :private-members:\n```\n\n----------------------------------------\n\nTITLE: RestructuredText Module Documentation Directives\nDESCRIPTION: Sphinx documentation directives for auto-generating API documentation from the SageMaker explainer configuration modules. Shows the structure for documenting members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/explainer.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. automodule:: sagemaker.explainer.explainer_config\n    :members:\n    :undoc-members:\n    :show-inheritance:\n\n.. automodule:: sagemaker.explainer.clarify_explainer_config\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Model Wrapping with DistributedDataParallel\nDESCRIPTION: Wraps a PyTorch model with SageMaker's DistributedDataParallel wrapper for distributed training.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel = ...\n# Wrap model with SageMaker's DistributedDataParallel\nmodel = DDP(model)\n```\n\n----------------------------------------\n\nTITLE: Sphinx autoclass directive for RLEstimator in SageMaker Python SDK\nDESCRIPTION: This code snippet configures the Sphinx documentation generator to automatically document the RLEstimator class from the sagemaker.rl.estimator module. It specifies that all members and undocumented members should be included, and inheritance should be shown.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/rl/sagemaker.rl.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.rl.estimator.RLEstimator\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Documenting serializers Module in SageMaker Python SDK\nDESCRIPTION: This code snippet uses Sphinx autodoc directives to generate documentation for the serializers module in the SageMaker Python SDK. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/serializers.rst#2025-04-22_snippet_1\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: sagemaker.serializers\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Documenting base_serializers Module in SageMaker Python SDK\nDESCRIPTION: This code snippet uses Sphinx autodoc directives to generate documentation for the base_serializers module in the SageMaker Python SDK. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/serializers.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: sagemaker.base_serializers\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Running Coverage Tests\nDESCRIPTION: Commands to run coverage tests using tox in the SageMaker Python SDK project, including options for running a single test with coverage.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntox -e runcoverage -- tests/unit\ntox -e py310 -- tests/unit --cov=sagemaker --cov-append --cov-report xml\nexport IGNORE_COVERAGE=- ; tox -e py310 -- -s -vv tests/unit/test_estimator.py::test_sagemaker_model_s3_uri_invalid ; unset IGNORE_COVERAGE\n```\n\n----------------------------------------\n\nTITLE: Documenting PipelineModel Class in ReStructuredText\nDESCRIPTION: Sphinx documentation directive for auto-generating API documentation from the PipelineModel class in the SageMaker Python SDK. Includes all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/pipeline.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.pipeline.PipelineModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests\nDESCRIPTION: Command to run a specific integration test in the SageMaker Python SDK project using tox.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nexport IGNORE_COVERAGE=- ; tox -e py310 -- -s -vv tests/integ/test_tf_script_mode.py::test_mnist ; unset IGNORE_COVERAGE\n```\n\n----------------------------------------\n\nTITLE: Documenting DJLModel Class in Python for SageMaker\nDESCRIPTION: This snippet uses Sphinx autodoc to generate documentation for the DJLModel class from the sagemaker.djl_inference module. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/djl/sagemaker.djl_inference.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.djl_inference.DJLModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring RST Automodule Documentation for SageMaker Hyperparameters\nDESCRIPTION: RST directive configuration for automatically generating documentation from the sagemaker.hyperparameters module. The configuration includes showing all members, undocumented members, and inheritance relationships.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/hyperparameters.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.hyperparameters\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for SageMaker Tabular Algorithms in RST\nDESCRIPTION: This RST directive creates a table of contents that links to documentation for various SageMaker built-in algorithms for tabular data, including AutoGluon, CatBoost, Factorization Machines, KNN, LightGBM, Linear Learner, TabTransformer, and XGBoost.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/tabular/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n    :maxdepth: 2\n\n    autogluon\n    catboost\n    factorization_machines\n    knn\n    lightgbm\n    linear_learner\n    tabtransformer\n    xgboost\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation for SageMaker model_uris Module in reStructuredText\nDESCRIPTION: This snippet configures documentation generation for the SageMaker model_uris module using reStructuredText directives. It specifies that all members, undocumented members, and inheritance information should be included in the generated documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/utility/model_uris.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: sagemaker.model_uris\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Autodocumenting SageMaker AutoML Module\nDESCRIPTION: This code snippet uses Sphinx autodoc to generate documentation for the sagemaker.automl.automl module. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/automl.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: sagemaker.automl.automl\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: LDAModel Class Documentation Configuration\nDESCRIPTION: Sphinx autodoc configuration for the LDA model class documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/text/lda.rst#2025-04-22_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.LDAModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: RST Table of Contents for Scikit-Learn Documentation\nDESCRIPTION: Defines the documentation structure using reStructuredText toctree directives, organizing content for Scikit-Learn usage and SDK reference.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sklearn/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n    :maxdepth: 1\n\n    using_sklearn\n\n.. toctree::\n    :maxdepth: 2\n\n    sagemaker.sklearn\n```\n\n----------------------------------------\n\nTITLE: Documentation Testing Command\nDESCRIPTION: Command to check both README and API documentation for build errors using tox.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntox -e twine,sphinx\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure with reStructuredText Toctree\nDESCRIPTION: Sets up a table of contents for Governance APIs documentation using reStructuredText's toctree directive. The configuration shows a maxdepth of 1 and uses globbing pattern to include all files in the current directory.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/governance/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n   :glob:\n\n   *\n```\n\n----------------------------------------\n\nTITLE: Defining RST Table of Contents for SageMaker Workflows\nDESCRIPTION: RST markup defining the table of contents structure for SageMaker workflow documentation sections. Lists the major workflow components as subsections with maxdepth of 2.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/workflows/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n    :maxdepth: 2\n\n    pipelines/index\n    airflow/index\n    step_functions/index\n    lineage/index\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for SparkML Serving Documentation in reStructuredText\nDESCRIPTION: A reStructuredText directive that defines the table of contents for the SparkML Serving documentation, with a maximum depth of 2 and referencing the sagemaker.sparkml module.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/sparkml/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n    :maxdepth: 2\n\n    sagemaker.sparkml\n```\n\n----------------------------------------\n\nTITLE: Specifying Documentation and Syntax Highlighting Dependencies\nDESCRIPTION: Defines specific version requirements for Python packages doc8 and Pygments used for documentation linting and syntax highlighting in the SageMaker Python SDK.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/tox/doc8_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ndoc8==1.1.2\nPygments==2.18.0\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for SageMaker SDK\nDESCRIPTION: This snippet defines the required Python packages and their specific versions for the SageMaker Python SDK project. It includes pyenchant version 3.2.2 for spell checking capabilities and pylint version 3.0.3 for code quality and style checking.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/tox/spelling_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\npyenchant==3.2.2\npylint==3.0.3\n```\n\n----------------------------------------\n\nTITLE: Autodocumenting the SageMaker Parameters Module in Sphinx\nDESCRIPTION: This reStructuredText (RST) directive instructs Sphinx to automatically generate documentation for the SageMaker parameters module. It includes all members, undocumented members, and shows inheritance relationships.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/parameter.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.parameter\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Linting Dependencies for SageMaker SDK\nDESCRIPTION: Defines the specific versions of pylint and astroid to be used for linting the SageMaker Python SDK code. The file uses a requirements-style format to lock these dependencies to specific versions for consistent development environments.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/requirements/tox/pylint_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\npylint==3.0.3\nastroid==3.0.2\n```\n\n----------------------------------------\n\nTITLE: Referencing Custom Parameters from SageMaker Configuration\nDESCRIPTION: Shows how to access both standard SageMaker configuration parameters and custom parameters from the configuration dictionary using two different methods.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/overview.rst#2025-04-22_snippet_99\n\nLANGUAGE: python\nCODE:\n```\nfrom sagemaker.session import Session\nfrom sagemaker.utils import get_sagemaker_config_value\nsession = Session(<session values>)\n\nvpc_config_option_1 = get_sagemaker_config_value(session, \"SageMaker.Model.VpcConfig\")\nvpc_config_option_2 = session.sagemaker_config[\"SageMaker\"][\"Model\"][\"VpcConfig\"]\n\ncustom_param_option_1 = get_sagemaker_config_value(session, \"CustomParameters.JobName\")\ncustom_param_option_2 = session.sagemaker_config[\"CustomParameters\"][\"JobName\"]\n```\n\n----------------------------------------\n\nTITLE: SageMaker Chainer Model Server Request Processing Flow\nDESCRIPTION: Pseudocode showing the flow of request processing in the SageMaker Chainer model server. It illustrates how input_fn, predict_fn, and output_fn interact to handle inference requests.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/using_chainer.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Deserialize the Invoke request body into an object we can perform prediction on\ninput_object = input_fn(request_body, request_content_type)\n\n# Perform prediction on the deserialized object, with the loaded model\nprediction = predict_fn(input_object, model)\n\n# Serialize the prediction result into the desired response content type\noutput = output_fn(prediction, response_content_type)\n```\n\n----------------------------------------\n\nTITLE: Creating Table of Contents for Reinforcement Learning Documentation in reStructuredText\nDESCRIPTION: This snippet defines a reStructuredText table of contents structure for navigating Reinforcement Learning documentation in SageMaker. It includes a maxdepth:1 section pointing to 'using_rl' and a maxdepth:2 section pointing to the 'sagemaker.rl' API documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/rl/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. toctree::\n    :maxdepth: 1\n\n    using_rl\n\n.. toctree::\n    :maxdepth: 2\n\n    sagemaker.rl\n```\n\n----------------------------------------\n\nTITLE: Documenting SageMaker Training Job Analytics in reStructuredText\nDESCRIPTION: Documentation directive for the TrainingJobAnalytics class in the SageMaker Python SDK, which provides analytics functionality for training jobs, including all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/analytics.rst#2025-04-22_snippet_2\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. autoclass:: sagemaker.analytics.TrainingJobAnalytics\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Specifying PyTorch 2.0.0 Deep Learning Container in AWS ECR\nDESCRIPTION: Docker image URI for the AWS Deep Learning Container with PyTorch 2.0.0 and the SageMaker distributed data parallelism library v1.8.0.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.rst#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.0.0-gpu-py310-cu118-ubuntu20.04-sagemaker\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests with Tox\nDESCRIPTION: Commands to install tox, run all unit tests, and run a single test using tox in the SageMaker Python SDK project.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/CONTRIBUTING.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npip install tox\ncd sagemaker-python-sdk\npip install '.[test]'\ntox tests/unit\ntox -e py310 -- -s -vv <path_to_file><file_name>::<test_function_name>\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx autodoc for SageMaker Collection Module\nDESCRIPTION: reStructuredText directive for automatically generating documentation from the sagemaker.collection module. It includes all members, undocumented members, and inheritance information.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/model_collection.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: sagemaker.collection\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Automodule for SageMaker MultiDataModel Documentation\nDESCRIPTION: Sphinx directive to generate documentation for the sagemaker.multidatamodel module. The directive includes all members, undocumented members, and shows inheritance relationships for comprehensive API documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/inference/multi_data_model.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. automodule:: sagemaker.multidatamodel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: LDA Class Documentation Configuration\nDESCRIPTION: Sphinx autodoc configuration for the LDA algorithm class, excluding specific parameters from documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/algorithms/text/lda.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: sagemaker.LDA\n    :members:\n    :undoc-members:\n    :show-inheritance:\n    :inherited-members:\n    :exclude-members: image_uri, num_topics, alpha0, max_restarts, max_iterations, mini_batch_size, feature_dim, tol\n```\n\n----------------------------------------\n\nTITLE: Importing and Initializing SageMaker Distributed Data Parallel Library for PyTorch\nDESCRIPTION: This snippet shows how to import the SageMaker distributed data parallel library for PyTorch and initialize the process group.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport smdistributed.dataparallel.torch.distributed as dist\n\nfrom smdistributed.dataparallel.torch.parallel.distributed import DistributedDataParallel as DDP\n\ndist.init_process_group()\n```\n\n----------------------------------------\n\nTITLE: Documenting Chainer Model Class in Python\nDESCRIPTION: Autoclass directive for generating documentation for the Chainer model class. It includes all members, undocumented members, and shows inheritance.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/chainer/sagemaker.chainer.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. autoclass:: sagemaker.chainer.model.ChainerModel\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation for SageMaker Algorithm Module in RST\nDESCRIPTION: Sphinx directives that specify how to generate documentation for the SageMaker algorithm module. It includes the module path and configurations to show all members, undocumented members, and inheritance relationships.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/api/training/algorithm.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: sagemaker.algorithm\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: XGBoostPredictor Class Documentation Directive in ReStructuredText\nDESCRIPTION: Sphinx documentation directive that references the XGBoostPredictor class, displaying all members, undocumented members, and inheritance information in the generated documentation.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/doc/frameworks/xgboost/xgboost.rst#2025-04-22_snippet_2\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. autoclass:: sagemaker.xgboost.model.XGBoostPredictor\n    :members:\n    :undoc-members:\n    :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Initializing Company Variable in Python\nDESCRIPTION: Sets a company name variable that will be used elsewhere in the notebook.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/notebook1_happypath.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ncompany='zappos'\n```\n\n----------------------------------------\n\nTITLE: Displaying All Environment Variables in Jupyter\nDESCRIPTION: Uses the Jupyter magic command %env to display all environment variables in the current session.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/workflow/notebook_job_step/subfolder/sub.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n%env\n```\n\n----------------------------------------\n\nTITLE: Specifying Main Class for Java Spark Application in SageMaker\nDESCRIPTION: This configuration line defines the main class for a Java Spark application within the AWS SageMaker Python SDK project. It points to a class named HelloJavaSparkApp in the com.amazonaws.sagemaker.spark.test package.\nSOURCE: https://github.com/aws/sagemaker-python-sdk/blob/master/tests/data/spark/code/java/hello-java-spark/manifest.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nMain-Class: com.amazonaws.sagemaker.spark.test.HelloJavaSparkApp\n```"
  }
]