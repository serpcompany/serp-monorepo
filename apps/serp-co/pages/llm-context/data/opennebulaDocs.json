[
  {
    "owner": "opennebula",
    "repo": "docs",
    "content": "TITLE: Upgrading OpenNebula Configuration with onecfg\nDESCRIPTION: This snippet shows the usage of `onecfg upgrade` command to upgrade OpenNebula configuration files. This is a crucial step that must be performed for each OpenNebula upgrade, even between minor versions. Skipping this step may lead to configuration errors and require manual intervention to reinitialize the configuration version management state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/start_here.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onecfg upgrade\nFATAL : FAILED - Configuration can't be processed as it looks outdated!\nYou must have missed to run 'onecfg update' after previous OpenNebula upgrade.\n```\n\n----------------------------------------\n\nTITLE: Creating a Host in OpenNebula (onehost)\nDESCRIPTION: This snippet demonstrates how to create a new host within OpenNebula using the `onehost create` command. The command requires specifying the hostname, information manager (IM) driver, and virtual machine manager (VM) driver. In the example, KVM is used as both the IM and VM driver.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost create host01 --im kvm --vm kvm\nID: 0\n```\n\n----------------------------------------\n\nTITLE: Resizing VM Disk for Running/Powered Off VMs - OpenNebula\nDESCRIPTION: This command resizes the disk of a running or powered off Virtual Machine using the onevm disk-resize command. It requires the VM ID, the disk ID, and the desired new size, which must be greater than the current disk size. The contextualization service inside the guest OS expands the filesystem.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\n$ onevm disk-resize <vm_id> <disk_id> <new_size> # <new_size> must be greater than current disk size\n```\n\n----------------------------------------\n\nTITLE: Defining an 802.1Q Network Template (OpenNebula)\nDESCRIPTION: This snippet demonstrates how to define an 802.1Q network in OpenNebula using a network template. It sets the `VN_MAD` to `802.1Q`, specifies the physical network device (`PHYDEV`), and defines the bridge (`BRIDGE`) and VLAN ID (`VLAN_ID`). `AUTOMATIC_VLAN_ID` can be used as an alternative to VLAN_ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vlan.rst#_snippet_2\n\nLANGUAGE: Text\nCODE:\n```\nNAME    = \"private2\"\nVN_MAD  = \"802.1Q\"\nPHYDEV  = \"eth0\"\nBRIDGE  = \"br0\"         # Optional\nVLAN_ID = 50            # Optional. If not setting VLAN_ID set AUTOMATIC_VLAN_ID = \"YES\"\n```\n\n----------------------------------------\n\nTITLE: Synchronize Configuration Files\nDESCRIPTION: The `onezone serversync` command is used to synchronize OpenNebula configuration files between HA nodes. It checks for inconsistencies in the `/etc/one/` directory and replaces local versions with remote versions if necessary. The command must be executed as root and requires passwordless SSH access.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/frontend_ha.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# onezone serversync <remote_opennebula_server> [--db]\n```\n\n----------------------------------------\n\nTITLE: Defining a VM Template with Hugepages and NUMA Topology\nDESCRIPTION: This code defines a complete VM template demonstrating the use of hugepages, memory access, sockets, and a pinning policy. It also configures disk, network, and context settings. This example provides a comprehensive configuration for a VM that leverages NUMA and hugepages.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_24\n\nLANGUAGE: Text\nCODE:\n```\nMEMORY = \"1024\"\n\nCPU  = \"4\"\nVCPU = \"4\"\nCPU_MODEL = [ MODEL=\"host-passthrough\" ]\n\nTOPOLOGY = [\n  HUGEPAGE_SIZE = \"2\",\n  MEMORY_ACCESS = \"shared\",\n  SOCKETS       = \"2\",\n  PIN_POLICY    = \"THREAD\" ]\n\nDISK = [ IMAGE=\"CentOS7\" ]\nNIC  = [ IP=\"10.4.4.11\", NETWORK=\"Management\" ]\n\nCONTEXT = [ NETWORK=\"YES\", SSH_PUBLIC_KEY=\"$USER[SSH_PUBLIC_KEY]\" ]\n```\n\n----------------------------------------\n\nTITLE: VM Template Example\nDESCRIPTION: This example shows a complete VM Template with disks, a network interface, a VNC section, and an alias. It demonstrates the basic structure of a VM Template file in OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nNAME   = test-vm\nMEMORY = 128\nCPU    = 1\n\nDISK = [ IMAGE  = \"Arch Linux\" ]\nDISK = [ TYPE     = swap,\n         SIZE     = 1024 ]\n\nNIC = [ NETWORK = \"Public\", NETWORK_UNAME=\"oneadmin\" ]\n\nNIC = [ NETWORK = \"Private\", NAME = \"private_net\" ]\nNIC_ALIAS = [ NETWORK = \"Public\", PARENT = \"private_net\" ]\n\nGRAPHICS = [\n  TYPE    = \"vnc\",\n  LISTEN  = \"0.0.0.0\"]\n```\n\n----------------------------------------\n\nTITLE: Instantiate Template and Overwrite Values with CLI\nDESCRIPTION: This command instantiates a VM template and overwrites the memory and disk values using the `--memory` and `--disk` options. This demonstrates how to customize the VM during instantiation.\nDependencies: OpenNebula CLI\nInputs: Template ID, desired memory, and disk image.\nOutputs: A new VM instance with the specified memory and disk.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_11\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate instantiate 0 --memory 1G --disk \"Ubuntu 16.04\"\n```\n\n----------------------------------------\n\nTITLE: Instantiating VM from Template - OpenNebula CLI\nDESCRIPTION: This snippet demonstrates how to instantiate a VM from an existing template using the `onetemplate instantiate` command. The `--name` flag is used to specify a name for the new VM. It returns the VM ID of the newly created VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate instantiate vm-example --name my_vm\nVM ID: 0\n```\n\n----------------------------------------\n\nTITLE: Defining Schedule-Based Elasticity Policies\nDESCRIPTION: This code snippet demonstrates how to define scheduled policies for auto-scaling a OneFlow service role. The `recurrence` attribute uses cron syntax to define recurring adjustments, while the `start_time` attribute defines a specific time for a one-time adjustment. The `type` and `adjust` attributes specify the adjustment type and value.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_elasticity.rst#_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n      \"scheduled_policies\" : [\n        {\n          // Set cardinality to 2 each 10 minutes\n          \"recurrence\" : \"*/10 * * * *\",\n\n          \"type\" : \"CARDINALITY\",\n          \"adjust\" : 2\n        },\n        {\n          // +10 percent at the given date and time\n          \"start_time\" : \"2nd oct 2017 15:45\",\n\n          \"type\" : \"PERCENTAGE_CHANGE\",\n          \"adjust\" : 10\n        }\n      ]\n```\n\n----------------------------------------\n\nTITLE: Defining SCHED_RANK considering FREE_CPU and TEMPERATURE in OpenNebula\nDESCRIPTION: This snippet illustrates how to combine multiple host attributes in the SCHED_RANK expression to create more complex scheduling policies.  It considers both the FREE_CPU and TEMPERATURE, allowing for selection of hosts with higher free CPU but penalized by their temperature.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_35\n\nLANGUAGE: text\nCODE:\n```\n# Consider also the CPU temperature\n  SCHED_RANK = \"FREE_CPU * 100 - TEMPERATURE\"\n```\n\n----------------------------------------\n\nTITLE: Setting OneGate Endpoint for HTTPS (OpenNebula)\nDESCRIPTION: This snippet shows how to configure the `ONEGATE_ENDPOINT` parameter in the `/etc/one/oned.conf` file for HTTPS.  This parameter defines the address that Virtual Machines will use to communicate with the OneGate service, secured with HTTPS. The specified endpoint must be reachable from the VMs over the network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_9\n\nLANGUAGE: ruby\nCODE:\n```\nONEGATE_ENDPOINT = \"https://one.example.com\"\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Community Repository on Debian 11\nDESCRIPTION: This bash script adds the OpenNebula Community Edition repository to the Debian 11 system. It creates a `/etc/apt/sources.list.d/opennebula.list` file with the repository configuration, including the base URL and specifies the GPG key file. The script then updates the apt package list.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n# echo \\\"deb [signed-by=/etc/apt/keyrings/opennebula.gpg] https://downloads.opennebula.io/repo/|version|/Debian/11 stable opennebula\\\" > /etc/apt/sources.list.d/opennebula.list\n# apt-get update\n```\n\n----------------------------------------\n\nTITLE: Defining Open vSwitch Network Template\nDESCRIPTION: This snippet demonstrates how to define an Open vSwitch network using a network template in OpenNebula. Key attributes such as VN_MAD, BRIDGE, and VLAN_ID are configured to specify the network driver, bridge name, and VLAN ID for the network. Optional attributes like VLAN_ID can be automatically generated if AUTOMATIC_VLAN_ID is set to YES.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nNAME    = \"private4\"\nVN_MAD  = \"ovswitch\"\nBRIDGE  = vbr1\nVLAN_ID = 50          # Optional\n...\n```\n\n----------------------------------------\n\nTITLE: Updating Virtual Network with Security Groups\nDESCRIPTION: This snippet demonstrates how to update a Virtual Network to apply Security Groups using the `onevnet update` command. It sets the SECURITY_GROUPS attribute with a comma-separated list of Security Group IDs. This associates the specified Security Groups with the Virtual Network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/security_groups.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onevnet update 0\n\nSECURITY_GROUPS = \"100, 102, 110\"\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Community Repository on Ubuntu 24.04\nDESCRIPTION: This bash script adds the OpenNebula Community Edition repository to the Ubuntu 24.04 system. It creates a `/etc/apt/sources.list.d/opennebula.list` file with the repository configuration, including the base URL and specifies the GPG key file. The script then updates the apt package list.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n# echo \\\"deb [signed-by=/etc/apt/keyrings/opennebula.gpg] https://downloads.opennebula.io/repo/|version|/Ubuntu/24.04 stable opennebula\\\" > /etc/apt/sources.list.d/opennebula.list\n# apt-get update\n```\n\n----------------------------------------\n\nTITLE: Installing OpenNebula KVM Node on Debian/Ubuntu\nDESCRIPTION: Installs the OpenNebula KVM node package on Debian or Ubuntu systems using apt-get and restarts the libvirtd service. This ensures the system utilizes the OpenNebula-provided configuration file. Requires root privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_node_installation.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# apt-get update\n# apt-get -y install opennebula-node-kvm\n# systemctl restart libvirtd\n```\n\n----------------------------------------\n\nTITLE: Defining 802.1Q Virtual Network\nDESCRIPTION: This snippet shows how to define an 802.1Q Virtual Network with a name, VN_MAD, and physical device. It also includes optional QoS parameters to limit bandwidth.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nNAME    = \"Private Network\"\nVN_MAD  = \"802.1Q\"\nPHYDEV  = \"eth0\"\n\nOUTBOUND_AVG_BW = \"1000\"\nOUTBOUND_PEAK_BW = \"1500\"\nOUTBOUND_PEAK_KB = \"2048\"\n```\n\n----------------------------------------\n\nTITLE: Scheduling VM Snapshot Creation\nDESCRIPTION: This example shows how to schedule a VM snapshot creation to occur hourly until a specified end date. The command uses the `onevm snapshot-create` command with the `--schedule`, `--hourly`, and `--end` options to define the schedule.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_30\n\nLANGUAGE: text\nCODE:\n```\n$ onevm snapshot-create 0 snap-01 --schedule \"09/23\" --hourly 5 --end \"12/25\"\nVM 0: snapshot-create scheduled at 2018-09-23 14:15:00 +0200\n```\n\n----------------------------------------\n\nTITLE: Default ACL Rules for Group Admin\nDESCRIPTION: These ACL rules are the default rules applied to a group administrator. They grant administrative and management privileges over resources within the groupâ€™s scope, including User, Virtual Machine, Network, Image, Template, Document, Security Group, Virtual Router, VMGroup and Backup Job management capabilities.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_12\n\nLANGUAGE: text\nCODE:\n```\nID     USER RES_VHNIUTGDCOZSvRMAPtB   RID OPE_UMAC  ZONE\n10       #2     ----U--------------  @100     umac     *\n11       #2     V-NI-T---O-S-R--P-B  @100     um--     *\n12       #2     -------------R-----     *     ---c     *\n13       #2     ------G------------  #100     -m--     *\n```\n\n----------------------------------------\n\nTITLE: Reserving Virtual Network Addresses using OpenNebula CLI\nDESCRIPTION: This command reserves 10 addresses from a Virtual Network named 'Private' and places them into a new Virtual Network named 'MyVNET'. The `onevnet reserve` command is used to create the reservation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/self_provision.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onevnet reserve Private -n MyVNET -s 10\nReservation VNET ID: 7\n```\n\n----------------------------------------\n\nTITLE: Instantiating VM Template to Persistent - OpenNebula\nDESCRIPTION: This command instantiates a VM Template with the `--persistent` option, creating a persistent clone of each disk image. This results in a new, private Template being instantiated, preserving changes made to the VM disks after termination. The `--name` option allows you to specify the name of the new VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_24\n\nLANGUAGE: shell\nCODE:\n```\n$ onetemplate instantiate web_vm --persistent --name my_vm\nVM ID: 31\n\n$ onetemplate list\n  ID USER            GROUP           NAME                                REGTIME\n   7 oneadmin        oneadmin        web_vm                       05/12 14:53:11\n   8 oneadmin        oneadmin        my_vm                        05/12 14:53:38\n\n$ oneimage list\n  ID USER       GROUP      NAME            DATASTORE     SIZE TYPE PER STAT RVMS\n   7 oneadmin   oneadmin   web-img         default       200M OS   Yes used    1\n   8 oneadmin   oneadmin   my_vm-disk-0    default       200M OS   Yes used    1\n```\n\n----------------------------------------\n\nTITLE: AWS Provider YAML Template\nDESCRIPTION: This YAML template defines an AWS provider for OpenNebula, specifying connection details like access key, secret key, and region. It also includes input parameters for AMI image and instance type. The `name`, `description`, `provider`, `plain`, `connection` and `inputs` attributes are critical for defining the provider.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/aws_provider.rst#_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\nname: 'aws-frankfurt'\n\ndescription: 'Edge cluster in AWS Frankfurt'\nprovider: 'aws'\n\nplain:\n   provision_type: 'metal'\n\nconnection:\n   access_key: 'AWS access key'\n   secret_key: 'AWS secret key'\n   region: 'eu-central-1'\n\ninputs:\n- name: 'aws_ami_image'\n  type: 'text'\n  default: 'default'\n  description: 'AWS AMI image (default = Ubuntu Focal)'\n- name: 'aws_instance_type'\n  type: 'list'\n  default: 'c5.metal'\n  options:\n  - 'c5.metal'\n  - 'i3.metal'\n  - 'm5.metal'\n  - 'r5.metal'\n```\n\n----------------------------------------\n\nTITLE: Defining Mappings for Multiple Servers - Bash\nDESCRIPTION: This snippet shows how to define mappings for multiple LDAP servers in the OpenNebula group template. It includes an INTERNAL_GROUP_DN and EXTERNAL_GROUP_DN for each LDAP server.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nINTERNAL_GROUP_DN=\"CN=technicians,CN=Groups,DC=internal,DC=com\"\nEXTERNAL_GROUP_DN=\"CN=staff,DC=other-company,DC=com\"\n```\n\n----------------------------------------\n\nTITLE: Defining VM template with restricted attributes\nDESCRIPTION: This code snippet showcases a VM template with defined CPU, VCPU, MEMORY, DISK and NIC attributes.  A user can delete the second disk but an user cannot delete the first disk because it has a restricted attribute.\nDependencies: OpenNebula\nInputs: None\nOutputs: A VM template with certain attributes that are protected from modification.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_9\n\nLANGUAGE: none\nCODE:\n```\nCPU     = \"1\"\nVCPU    = \"1\"\nMEMORY  = \"512\"\nDISK=[\n  IMAGE = \"BaseOS\"\n  TOTAL_BYTES_SEC = 1 ]\nDISK=[\n  IMAGE = \"BaseOS2\" ]      \nNIC=[\n  NETWORK_ID = \"0\" ]\n```\n\n----------------------------------------\n\nTITLE: Restoring OpenNebula Database\nDESCRIPTION: This command restores the OpenNebula database from the provided backup file, using the 'onedb restore' command. It is important to restore the backup only from the same back-end type (e.g., SQLite to SQLite, MySQL to MySQL).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_13\n\nLANGUAGE: text\nCODE:\n```\n$ onedb restore /tmp/my_backup.db\nSqlite database backup restored in /var/lib/one/one.db\n```\n\n----------------------------------------\n\nTITLE: Enable Automatic Service Deletion\nDESCRIPTION: This snippet shows how to enable automatic deletion of a service when all roles are terminated.  It requires adding the `automatic_deletion` attribute to the service template with a value of `true`. This ensures the service is cleaned up when no VMs are associated with it.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_24\n\nLANGUAGE: javascript\nCODE:\n```\n\"automatic_deletion\": true\n```\n\n----------------------------------------\n\nTITLE: Configuring udev rule for vfio\nDESCRIPTION: This command creates a udev rule to set the group and mode for vfio devices, allowing KVM to access the vGPU. It then reloads the udev rules and triggers them to apply the new rule.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\necho 'SUBSYSTEM==\"vfio\", GROUP=\"kvm\", MODE=\"0666\"' > /etc/udev/rules.d/opennebula-vfio.rules\n\n# Reload udev rules:\nudevadm control --reload-rules && udevadm trigger\n```\n\n----------------------------------------\n\nTITLE: Customizing Sunstone Interface in OpenNebula Template\nDESCRIPTION: This snippet illustrates how to customize the Sunstone interface for VM instantiation through an OpenNebula template. It demonstrates how to disable network alias, automatic network selection, RDP and SSH connections, and network selection for VM instantiation, tailoring the user experience in Sunstone.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_44\n\nLANGUAGE: text\nCODE:\n```\nSUNSTONE = [\n    NETWORK_ALIAS = \"yes\",\n    NETWORK_AUTO = \"no\",\n    NETWORK_RDP = \"yes\",\n    NETWORK_SSH = \"yes\"\n  ]\n```\n\n----------------------------------------\n\nTITLE: Listing VMs with Custom Columns - onevm\nDESCRIPTION: This example demonstrates how to use the `onevm list` command to display a list of virtual machines, customizing the output columns to show only the ID, NAME, STAT, and IP information. This allows for a more concise and focused view of the virtual machines.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/cli.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nonevm list\n```\n\n----------------------------------------\n\nTITLE: Set MySQL Transaction Isolation Level\nDESCRIPTION: This snippet configures the transaction isolation level in MySQL to READ COMMITTED. This setting is important for OpenNebula's data consistency.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/database.rst#_snippet_2\n\nLANGUAGE: none\nCODE:\n```\nmysql> SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;\n```\n\n----------------------------------------\n\nTITLE: Powering Off, Resizing, and Resuming a Virtual Machine\nDESCRIPTION: This series of commands demonstrates how to power off a virtual machine, resize its resources (memory and vCPU), and then resume it. It starts by powering off 'web_vm', then resizes it to 2GB of memory and 2 vCPUs, and finally resumes the VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm poweroff web_vm\n$ onevm resize web_vm --memory 2G --vcpu 2\n$ onevm resume web_vm\n```\n\n----------------------------------------\n\nTITLE: Injecting Context using virt-customize\nDESCRIPTION: This snippet demonstrates injecting the one-context package into a virtual machine image using virt-customize. It installs necessary repositories and packages, copies the one-context RPM, installs it, and enables the NetworkManager service. The command also includes error handling to prevent script termination if enabling the service fails.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/ova_management/import_ova.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nvirt-customize -q -a /tmp/vm-alma9/conversions/vm-alma9-sda --run-command 'subscription-manager repos --enable codeready-builder-for-rhel-9-$(arch)-rpms' --run-command 'yum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm' --copy-in /var/lib/one/context//one-context-6.10.0-3.el9.noarch.rpm:/tmp --install /tmp/one-context-6.10.0-3.el9.noarch.rpm --delete /tmp/one-context-6.10.0-3.el9.noarch.rpm --run-command 'systemctl enable NetworkManager.service || exit 0'\n```\n\n----------------------------------------\n\nTITLE: Ceph configuration for RBD format\nDESCRIPTION: This snippet shows the configuration setting within the `ceph.conf` file to ensure RBD format 2 is used. Using Format 2 is strongly recommended.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n[global]\nrbd_default_format = 2\n```\n\n----------------------------------------\n\nTITLE: Basic Authentication Configuration in Sunstone\nDESCRIPTION: This snippet shows the configuration required in `/etc/one/fireedge-server.conf` to enable basic username/password authentication against the OpenNebula database for Sunstone.  This uses the `opennebula` authentication method.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n:auth: opennebula\n```\n\n----------------------------------------\n\nTITLE: Using User Inputs in VM Templates\nDESCRIPTION: This example demonstrates how to use user inputs in a VM Template to dynamically ask for values during instantiation. The values are then passed to the VM through the CONTEXT attribute.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_3\n\nLANGUAGE: none\nCODE:\n```\nUSER_INPUTS = [\n  BLOG_TITLE=\"M|text|Blog Title\",\n  MYSQL_PASSWORD=\"M|password|MySQL Password\",\n]\n\nCONTEXT=[\n  BLOG_TITLE=\"$BLOG_TITLE\",\n  MYSQL_PASSWORD=\"$MYSQL_PASSWORD\" ]\n```\n\n----------------------------------------\n\nTITLE: Datastore Configuration in oned.conf (Bash)\nDESCRIPTION: This snippet shows the configuration for datastores in the OpenNebula oned.conf file. It configures the datastore location, capacity check, default image type, and device prefixes. These parameters govern how images are stored and accessed by virtual machines.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n#*******************************************************************************\n# Image Repository Configuration\n#*******************************************************************************\n#DATASTORE_LOCATION  = /var/lib/one/datastores\n\nDATASTORE_CAPACITY_CHECK = \"yes\"\n\nDEFAULT_IMAGE_TYPE    = \"OS\"\nDEFAULT_DEVICE_PREFIX = \"hd\"\n\nDEFAULT_CDROM_DEVICE_PREFIX = \"hd\"\n\n#DEFAULT_IMAGE_PERSISTENT     = \"\"\n#DEFAULT_IMAGE_PERSISTENT_NEW = \"NO\"\n```\n\n----------------------------------------\n\nTITLE: Defining a Complete Backup Job Configuration in OpenNebula\nDESCRIPTION: This snippet shows a complete example of a backup job configuration file. It includes VM selection (BACKUP_VMS), backup operation settings (DATASTORE_ID, FS_FREEZE, KEEP_LAST, MODE), priority (PRIORITY), execution mode (EXECUTION), and scheduled actions (SCHED_ACTION). Multiple SCHED_ACTION definitions are supported.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nNAME = \"My backup job\"\n\nBACKUP_VMS   = \"13,15,3\"\nDATASTORE_ID = 101\n\nFS_FREEZE = \"NONE\"\nKEEP_LAST = \"4\"\nMODE      = \"INCREMENT\"\n\nPRIORITY  = 7\nEXECUTION = \"SEQUENTIAL\"\n\nSCHED_ACTION = [\n    REPEAT=\"0\",\n    DAYS=\"1,5\",\n    END_TYPE=\"0\",\n    TIME=\"1695478500\"\n]\n\nSCHED_ACTION = [\n    REPEAT=\"3\",\n    DAYS=\"1\",\n    END_TYPE=\"0\",\n    TIME=\"1695478500\"\n]\n```\n\n----------------------------------------\n\nTITLE: Attaching a Security Group to a Virtual Machine's NIC\nDESCRIPTION: This command attaches a security group to a specific network interface card (NIC) of a virtual machine. The example attaches security group with ID '101' to NIC '0' of the virtual machine named 'centos-server'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm sg-attach centos-server 0 101\n```\n\n----------------------------------------\n\nTITLE: Role to Role Affinity Configuration\nDESCRIPTION: This snippet illustrates how to configure role to role affinity within a VM Group.  It uses `HOST_AFFINED` and `POLICY` for the 'databases' role to ensure database VMs run together on specific hosts. It also uses `HOST_ANTI_AFFINED` and `POLICY` for the 'backup' role to run backups on different hosts, while ensuring 'databases' and 'backup' roles are on different hosts using `ANTI_AFFINED`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/affinity.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nROLE = [\n    NAME  = \"databases\",\n    HOST_AFFINED = \"1,2,3,4,5,6,7\"\n    POLICY = \"AFFINED\"\n]\n\nROLE = [\n    NAME = \"backup\",\n    HOST_ANTI_AFFINED = \"3,4\"\n    POLICY = \"ANTI_AFFINED\"\n]\n\nANTI_AFFINED = \"databases, backup\"\n```\n\n----------------------------------------\n\nTITLE: Attaching Disk to VM - OpenNebula CLI\nDESCRIPTION: This example demonstrates how to attach a disk to a running VM using the `onevm disk-attach` command.  The command requires the VM ID and the name of the image to attach. In this example, the image named 'storage' is attached to the VM with ID 'one-5'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_9\n\nLANGUAGE: text\nCODE:\n```\n$ onevm disk-attach one-5 --image storage\n```\n\n----------------------------------------\n\nTITLE: onedb SQLite Connection Parameters (Bash)\nDESCRIPTION: Demonstrates how to connect to an OpenNebula database using SQLite with the `onedb` command.  Specifies the path to the SQLite database file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onedb <command> -v --sqlite /var/lib/one/one.db\n```\n\n----------------------------------------\n\nTITLE: Chaining diff and patch subcommands\nDESCRIPTION: This example demonstrates how the `diff` and `patch` subcommands can be chained together to apply changes from one OpenNebula front-end to another. The `onecfg diff` command generates a patch in YAML format, which is then piped to the `onecfg patch` command on a remote system via SSH.  The `--format yaml` option specifies the patch format, and `--verbose` provides detailed output.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg diff --format yaml | ssh frontend2 onecfg patch --format yaml --verbose\n```\n\n----------------------------------------\n\nTITLE: Updating VM Configuration for Backups via CLI in OpenNebula\nDESCRIPTION: This snippet shows how to update a running VM's backup configuration using the `onevm updateconf` command. It configures the VM with FS_FREEZE set to NONE, keeps the last 4 backups, and sets the backup mode to INCREMENT. This method is suitable for applying backup configurations to existing VMs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm updateconf 0\n\nBACKUP_CONFIG = [\n  FS_FREEZE = \"NONE\",\n  KEEP_LAST = \"4\",\n  MODE = \"INCREMENT\"\n]\n...\n```\n\n----------------------------------------\n\nTITLE: MySQL/MariaDB User Creation and Permissions\nDESCRIPTION: This bash snippet demonstrates how to create a database user 'oneadmin' and grant it all privileges on the 'opennebula' database.  Replace <thepassword> with a secure password.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/database.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ mysql -u root -p\nEnter password:\nWelcome to the MySQL monitor. [...]\n\nmysql> CREATE USER 'oneadmin' IDENTIFIED BY '<thepassword>';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> GRANT ALL PRIVILEGES ON opennebula.* TO 'oneadmin';\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting RAW attribute for KVM in OpenNebula\nDESCRIPTION: This snippet shows how to use the RAW attribute to pass hypervisor-specific configurations to KVM. It configures serial and console devices, redirecting their input/output to /dev/pts/5.  This allows for low-level control over the VM's hardware configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_36\n\nLANGUAGE: text\nCODE:\n```\nRAW = [\n    type = \"kvm\",\n    validate = \"yes\",\n    data = \"<devices><serial type=\\\"pty\\\"><source path=\\\"/dev/pts/5\\\"/><target port=\\\"0\\\"/></serial><console type=\\\"pty\\\" tty=\\\"/dev/pts/5\\\"><source path=\\\"/dev/pts/5\\\"/><target port=\\\"0\\\"/></console></devices>\"\n]\n```\n\n----------------------------------------\n\nTITLE: Modifying User Password via oneuser Command\nDESCRIPTION: This command modifies the password of a user in OpenNebula using the 'oneuser passwd' command. It requires the user's ID and the new password as arguments. The user ID '1' in the example likely represents the 'serveradmin' account or a similar administrative user.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\noneuser passwd 1 abcdpass\n```\n\n----------------------------------------\n\nTITLE: Enabling LDAP Authentication in oned.conf (Bash)\nDESCRIPTION: This code snippet shows how to enable the LDAP authentication method within the `AUTH_MAD` section of the `/etc/one/oned.conf` file. This configuration allows OpenNebula to utilize LDAP for user authentication alongside other authentication methods.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nAUTH_MAD = [\n    EXECUTABLE = \"one_auth_mad\",\n    AUTHN = \"ssh,x509,ldap,server_cipher,server_x509\"\n]\n```\n\n----------------------------------------\n\nTITLE: Setting Initial oneadmin Password\nDESCRIPTION: This snippet shows how to set the initial password for the oneadmin user in OpenNebula by creating the /var/lib/one/.one/one_auth file. This is only effective on the first OpenNebula deployment before services are started. The 'changeme123' is a placeholder and should be replaced with a secure password.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ echo 'oneadmin:changeme123' > /var/lib/one/.one/one_auth\n```\n\n----------------------------------------\n\nTITLE: Instantiate Template using CLI\nDESCRIPTION: This code snippet shows how to instantiate a VM template via the command line using `onetemplate instantiate`.  It shows how to instantiate a template by ID. The output will be the VM ID of the newly created VM.\nDependencies: OpenNebula CLI\nInputs: Template ID\nOutputs: VM ID of the instantiated VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_10\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate instantiate 6\nVM ID: 0\n```\n\nLANGUAGE: text\nCODE:\n```\n$ onevm list\n    ID USER     GROUP    NAME         STAT CPU     MEM        HOSTNAME        TIME\n     0 oneuser1 users    one-0        pend   0      0K                 00 00:00:16\n```\n\n----------------------------------------\n\nTITLE: Configuring Restricted Attributes in OpenNebula\nDESCRIPTION: This code snippet shows how to configure restricted attributes in OpenNebula. These attributes are restricted for users outside the `oneadmin` group when instantiating templates created by users outside the `oneadmin` group.  It includes settings for VM, Image and VNET.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nVM_RESTRICTED_ATTR = \"CONTEXT/FILES\"\nVM_RESTRICTED_ATTR = \"NIC/MAC\"\nVM_RESTRICTED_ATTR = \"NIC/VLAN_ID\"\nVM_RESTRICTED_ATTR = \"NIC/BRIDGE\"\nVM_RESTRICTED_ATTR = \"NIC_DEFAULT/MAC\"\nVM_RESTRICTED_ATTR = \"NIC_DEFAULT/VLAN_ID\"\nVM_RESTRICTED_ATTR = \"NIC_DEFAULT/BRIDGE\"\nVM_RESTRICTED_ATTR = \"DISK/TOTAL_BYTES_SEC\"\nVM_RESTRICTED_ATTR = \"DISK/READ_BYTES_SEC\"\nVM_RESTRICTED_ATTR = \"DISK/WRITE_BYTES_SEC\"\nVM_RESTRICTED_ATTR = \"DISK/TOTAL_IOPS_SEC\"\nVM_RESTRICTED_ATTR = \"DISK/READ_IOPS_SEC\"\nVM_RESTRICTED_ATTR = \"DISK/WRITE_IOPS_SEC\"\n#VM_RESTRICTED_ATTR = \"DISK/SIZE\"\nVM_RESTRICTED_ATTR = \"DISK/ORIGINAL_SIZE\"\nVM_RESTRICTED_ATTR = \"CPU_COST\"\nVM_RESTRICTED_ATTR = \"MEMORY_COST\"\nVM_RESTRICTED_ATTR = \"DISK_COST\"\nVM_RESTRICTED_ATTR = \"PCI\"\nVM_RESTRICTED_ATTR = \"USER_INPUTS\"\n\n#VM_RESTRICTED_ATTR = \"RANK\"\n#VM_RESTRICTED_ATTR = \"SCHED_RANK\"\n#VM_RESTRICTED_ATTR = \"REQUIREMENTS\"\n#VM_RESTRICTED_ATTR = \"SCHED_REQUIREMENTS\"\n\nIMAGE_RESTRICTED_ATTR = \"SOURCE\"\n\nVNET_RESTRICTED_ATTR = \"VN_MAD\"\nVNET_RESTRICTED_ATTR = \"PHYDEV\"\nVNET_RESTRICTED_ATTR = \"VLAN_ID\"\nVNET_RESTRICTED_ATTR = \"BRIDGE\"\n\nVNET_RESTRICTED_ATTR = \"AR/VN_MAD\"\nVNET_RESTRICTED_ATTR = \"AR/PHYDEV\"\nVNET_RESTRICTED_ATTR = \"AR/VLAN_ID\"\nVNET_RESTRICTED_ATTR = \"AR/BRIDGE\"\n```\n\n----------------------------------------\n\nTITLE: Remote Authentication Configuration in Sunstone\nDESCRIPTION: This snippet configures Sunstone to use remote authentication, where username is extracted, and password is compared with the user database. The actual certificate validation needs to be handled by an external webserver like Apache or Nginx.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n:auth: remote\n```\n\n----------------------------------------\n\nTITLE: Creating a VM Template using onetemplate create\nDESCRIPTION: This example demonstrates how to create a VM Template using the `onetemplate create` command. This command allows you to define the VM's name, memory, CPU, disk, and network settings directly from the command line.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate create --name test-vm --memory 128 --cpu 1 --disk \"Arch Linux\" --nic Public\n```\n\n----------------------------------------\n\nTITLE: Creating Security Group via CLI\nDESCRIPTION: This snippet shows how to create a Security Group using the `onesecgroup create` command with a template file. It creates a new security group based on the definition within the specified file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/security_groups.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onesecgroup create ./sg.txt\nID: 102\n```\n\n----------------------------------------\n\nTITLE: VFIO Binding Script\nDESCRIPTION: This script binds a PCI device to the VFIO driver. It unbinds the device from its current driver and then binds it to the vfio-pci driver. This allows the device to be used by a virtual machine.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n#!/bin/sh\nmodprobe vfio-pci\nfor dev in \"$@\"; do\n\t\tvendor=$(cat /sys/bus/pci/devices/$dev/vendor)\n\t\tdevice=$(cat /sys/bus/pci/devices/$dev/device)\n\t\tif [ -e /sys/bus/pci/devices/\\$dev/driver ]; then\n\t\t\techo $dev > /sys/bus/pci/devices/$dev/driver/unbind\n\t\tfi\n\t\techo $vendor $device > /sys/bus/pci/drivers/vfio-pci/new_id\ndone\n```\n\n----------------------------------------\n\nTITLE: Defining Per Cluster VM Quotas - Bash\nDESCRIPTION: This example demonstrates how to define compute quotas on a per-cluster basis. Global quotas are defined along with specific quotas for individual clusters, providing granular control over resource allocation.  The `CLUSTER_IDS` attribute specifies which clusters the quota applies to.  Requires OpenNebula environment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/quotas.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Global quota to allow 4 VMs\nVM = [\n  VMS = 4\n]\n# Quota for cluster 0 to allow 2 VMs\nVM = [\n  CLUSTER_IDS = \"0\",\n  VMS = 2\n]\n# Quota for clusters 100 and 101 to allow 3 VMs\nVM = [\n  CLUSTER_IDS = \"100,101\",\n  VMS = 3\n]\n```\n\n----------------------------------------\n\nTITLE: Instantiate Template using file input\nDESCRIPTION: This example shows how to instantiate a VM template, and overwrite attributes by providing the file with the new attributes, `MEMORY` and `COMMENT`. The attributes within the file will override the template values.\nDependencies: OpenNebula CLI, a file with VM attributes\nInputs: Template ID, path to the file containing attributes to overwrite\nOutputs: Creates a new VM instance with updated parameters based on the file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_12\n\nLANGUAGE: text\nCODE:\n```\n$ cat /tmp/file\nMEMORY = 512\nCOMMENT = \"This is a bigger instance\"\n\n$ onetemplate instantiate 6 /tmp/file\nVM ID: 1\n```\n\n----------------------------------------\n\nTITLE: Virtual Network Definition Example\nDESCRIPTION: This snippet shows a complete example of a virtual network definition, including name, VN_MAD, physical device, address range, DNS server, gateway, and description.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_4\n\nLANGUAGE: none\nCODE:\n```\nNAME    = \"Private\"\nVN_MAD  = \"802.1Q\"\nPHYDEV  = \"eth0\"\n\nAR=[\n    TYPE = \"IP4\",\n    IP   = \"10.0.0.150\",\n    SIZE = \"51\"\n]\n\nDNS     = \"10.0.0.23\"\nGATEWAY = \"10.0.0.1\"\n\nDESCRIPTION = \"A private network for VM inter-communication\"\n```\n\n----------------------------------------\n\nTITLE: Create Image Datastore Configuration\nDESCRIPTION: This snippet shows how to create an image datastore configuration file (ds.conf) for OpenNebula. It sets the datastore name, the datastore MAD to 'fs', and the transfer manager MAD to 'shared'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/nas_ds.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nNAME   = nfs_images\nDS_MAD = fs\nTM_MAD = shared\n```\n\n----------------------------------------\n\nTITLE: Security Group Template Definition\nDESCRIPTION: This snippet demonstrates how to define a Security Group using a template file. It includes rules for TCP traffic (inbound and outbound) and ICMP traffic (inbound, specific to a network). The template specifies protocols, traffic directions, and port ranges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/security_groups.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nNAME = test\n\nRULE = [\n    PROTOCOL = TCP,\n    RULE_TYPE = inbound,\n    RANGE = 1000:2000\n]\n\nRULE = [\n    PROTOCOL= TCP,\n    RULE_TYPE = outbound,\n    RANGE = 1000:2000\n]\n\nRULE = [\n    PROTOCOL = ICMP,\n    RULE_TYPE = inbound,\n    NETWORK_ID = 0\n]\n```\n\n----------------------------------------\n\nTITLE: Listing Hosts in OpenNebula (onehost)\nDESCRIPTION: This snippet demonstrates how to list all hosts in OpenNebula using the `onehost list` command.  The output includes the ID, name, cluster, running VMs, allocated CPU, allocated memory, and status of each host. The output format can be changed to XML, JSON or CSV using the `-x`, `-j` or `-c` flags respectively.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost list\n```\n\n----------------------------------------\n\nTITLE: Running the upgrade subcommand\nDESCRIPTION: This example demonstrates a basic usage of the `onecfg upgrade` command. It automatically detects the current and target configuration versions and applies the necessary updates. It also performs a backup of the existing configuration files before applying the upgrade.  No extra parameters are passed, indicating an automatic upgrade process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade\n```\n\n----------------------------------------\n\nTITLE: Configuring Sunstone Views for a Group\nDESCRIPTION: This code snippet shows how to define specific Sunstone views for group users by setting the `FIREEDGE` attribute in the group template. It specifies the default view and the list of available views for regular users.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_groups.rst#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nFIREEDGE=[\n  DEFAULT_VIEW = \"cloud\",\n  VIEWS        = \"cloud\"\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Template using onetemplate command\nDESCRIPTION: This snippet shows how to create a VM template in OpenNebula using the `onetemplate create` command. It assumes that the template definition is stored in the `vm-example.txt` file. The command returns the ID of the created template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_14\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate create vm-example.txt\nID: 6\n```\n\n----------------------------------------\n\nTITLE: YAML Template with User Inputs\nDESCRIPTION: This YAML snippet defines a virtual network with user inputs for text, boolean, password and list types in the 'provision' section.  The values of these inputs will be supplied at provision creation time to parameterize the virtual network configuration. The `${input.name}` syntax allows referencing these user-provided values within the template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_16\n\nLANGUAGE: yaml\nCODE:\n```\nnetworks:\n  - name: 'vpc'\n    vn_mad: 'dummy'\n    bridge: 'br0'\n    provision:\n      t: ${input.text_i}\n      b: ${input.bool_i}\n      p: ${input.password_i}\n      l: ${input.list_i}\n```\n\n----------------------------------------\n\nTITLE: Adding KVM Node to OpenNebula via CLI\nDESCRIPTION: Adds a KVM node to the OpenNebula cloud using the onehost command-line tool. Replace `<node01>` with the actual hostname of the node. Requires execution from the OpenNebula front-end as the `oneadmin` user.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_node_installation.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost create <node01> -i kvm -v kvm\n\n$ onehost list\n  ID NAME            CLUSTER   RVM      ALLOCATED_CPU      ALLOCATED_MEM STAT\n   1 localhost       default     0                  -                  - init\n\n# After some time (up to 1 minute)\n\n$ onehost list\n  ID NAME            CLUSTER   RVM      ALLOCATED_CPU      ALLOCATED_MEM STAT\n   0 node01          default     0       0 / 400 (0%)     0K / 7.7G (0%) on\n```\n\n----------------------------------------\n\nTITLE: Emulated TPM 2.0 XML Configuration\nDESCRIPTION: This XML snippet configures an emulated TPM 2.0 device for the guest OS.  It uses the `tpm-crb` model and sets the backend type to `emulator` with version `2.0`. Before implementing this, ensure that `swtpm` and `swtpm-tools` are installed on all hypervisors. This configuration provides a virtual TPM device for secure boot and other security features.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<devices>\n    <tpm model='tpm-crb'>\n        <backend type='emulator' version='2.0'/>\n    </tpm>\n</devices>\n```\n\n----------------------------------------\n\nTITLE: Open vSwitch - QinQ Network Template in OpenNebula\nDESCRIPTION: This code snippet presents a virtual network template example for configuring QinQ networks in OpenNebula using Open vSwitch. It defines parameters such as VN_MAD, PHYDEV, VLAN_ID, and CVLANS for customer VLANs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nNAME     = \"qinq_net\"\nVN_MAD   = \"ovswitch\"\nPHYDEV   = eth0\nVLAN_ID  = 50                 # Service VLAN ID\nCVLANS   = \"101,103,110-113\"  # Customer VLAN ID list\n```\n\n----------------------------------------\n\nTITLE: Default ACL Rules for a New Group\nDESCRIPTION: These ACL rules are automatically created when a new group is created in OpenNebula.  They grant manage permissions for hosts, use permissions for virtual networks and datastores, and create permissions for other resources to members of the new group.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_11\n\nLANGUAGE: text\nCODE:\n```\nID     USER RES_VHNIUTGDCOZSvRMAPtB   RID OPE_UMAC  ZONE\n 6     @100     -H-----------------     *     -m--    #0\n 7     @100     --N----------------     *     u---    #0\n 8     @100     -------D-----------     *     u---    #0\n 9     @100     V--I-T---O-S-R--P-B     *     ---c     *\n```\n\n----------------------------------------\n\nTITLE: Defining User Inputs in OpenNebula Template\nDESCRIPTION: This example shows how to define user inputs within an OpenNebula template using the USER_INPUTS attribute. It includes different input types (text, password, text64) and demonstrates how to reference these inputs in the CONTEXT section to inject values into the VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_39\n\nLANGUAGE: text\nCODE:\n```\nUSER_INPUTS = [\n  BLOG_TITLE=\"M|text|Blog Title\",\n  MYSQL_PASSWORD=\"M|password|MySQL Password\",\n  INIT_HOOK=\"M|text64|You can write a script that will be run on startup\",\n  <VAR>=\"M|<type>|<desc>\"\n]\n\nCONTEXT=[\n  BLOG_TITLE=\"$BLOG_TITLE\",\n  MYSQL_PASSWORD=\"$MYSQL_PASSWORD\" ]\n```\n\n----------------------------------------\n\nTITLE: Attaching Network Interface to VM - OpenNebula CLI\nDESCRIPTION: This example shows how to attach a network interface (NIC) to a VM using the `onevm nic-attach` command.  The command requires the VM ID and the `--network` option specifying the network to which the NIC should be attached. Here, a NIC is attached to VM '2' on network 'net_172'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_11\n\nLANGUAGE: text\nCODE:\n```\n$ onevm show 2\n\nVIRTUAL MACHINE 2 INFORMATION\nID                  : 2\nNAME                : centos-server\nSTATE               : ACTIVE\nLCM_STATE           : RUNNING\n\n...\n\nVM NICS\nID NETWORK      VLAN BRIDGE   IP              MAC\n 0 net_172        no vbr0     172.16.1.201    02:00:ac:10:0\n\n...\n\n$ onevm nic-attach 2 --network net_172\n```\n\n----------------------------------------\n\nTITLE: Defining Security Groups in VM Template NIC\nDESCRIPTION: This snippet demonstrates how to define Security Groups within a Virtual Machine Template's NIC definition. The SECURITY_GROUPS attribute specifies a comma-separated list of Security Group IDs. This associates those Security Groups with the specific NIC of the VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/security_groups.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nNIC = [\n  NETWORK = \"private-net\",\n  NETWORK_UNAME = \"oneadmin\",\n  SECURITY_GROUPS = \"103, 125\"\n]\n```\n\n----------------------------------------\n\nTITLE: Attaching a NIC to a Virtual Machine in OpenNebula\nDESCRIPTION: This command attaches a network interface card (NIC) to a virtual machine. The first example attaches a NIC from the 'net_172' network to VM with ID 2. The second example does the same and also attaches a PCI device specified by its address '00:06.1'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm nic-attach 2 --network net_172 onevm nic-attach 2 --network net_172 --pci '00:06.1'\n```\n\n----------------------------------------\n\nTITLE: Creating Image Datastore Configuration\nDESCRIPTION: This snippet shows the configuration file (ds.conf) for creating an Image Datastore in OpenNebula using Ceph. The configuration includes attributes like DS_MAD, TM_MAD, DISK_TYPE, POOL_NAME, CEPH_HOST, CEPH_USER, CEPH_SECRET, and BRIDGE_LIST. The configuration is designed to manage images.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_14\n\nLANGUAGE: text\nCODE:\n```\nNAME = \"cephds\"\nDS_MAD = ceph\nTM_MAD = ceph\n\nDISK_TYPE = RBD\n\nPOOL_NAME   = one\nCEPH_HOST   = \"host1 host2:port2\"\nCEPH_USER   = libvirt\nCEPH_SECRET = \"6f88b54b-5dae-41fe-a43e-b2763f601cfc\"\n\nBRIDGE_LIST = cephfrontend\n```\n\n----------------------------------------\n\nTITLE: Attaching VM to Virtual Network with Specific IP - OpenNebula Template\nDESCRIPTION: This snippet illustrates how to attach a virtual machine to a specific virtual network and request a particular IP address.  The `NIC` attribute includes both `NETWORK` (network name) and `IP` (desired IP address). OpenNebula attempts to assign the requested IP, failing the submission if not available.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_16\n\nLANGUAGE: xml\nCODE:\n```\nNIC = [ NETWORK = \"Network\", IP = 10.0.0.153 ]\n```\n\n----------------------------------------\n\nTITLE: Instantiating VM with User Input - OpenNebula CLI\nDESCRIPTION: This snippet illustrates how to instantiate a VM template that requires user input.  The CLI prompts the user for the values associated with user input parameters. The example shows prompts for BLOG_TITLE and DB_PASSWORD.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate instantiate vm-example --name my_vm\nThere are some parameters that require user input.\n  * (BLOG_TITLE) Blog Title: <my_title>\n  * (DB_PASSWORD) Database Password:\nVM ID: 0\n```\n\n----------------------------------------\n\nTITLE: Defining a Windows OS Profile in YAML\nDESCRIPTION: This YAML snippet showcases a Windows OS profile containing optimized settings for Windows VMs. It configures OS-specific parameters like architecture, disk bus, machine type, firmware, and features like ACPI, PAE, and Hyper-V. It also includes RAW data for hypervisor configurations and clock settings.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/os_profile.rst#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# Windows profile\n\"General\":\n  NAME: \"Optimized Windows Profile\"\n\n\"Advanced options\":\n  OsCpu:\n    OS:\n      ARCH: X86_64\n      SD_DISK_BUS: scsi\n      MACHINE: host-passthrough\n      FIRMWARE: BIOS\n    FEATURES:\n      ACPI: \"Yes\"\n      PAE: \"Yes\"\n      APIC: \"Yes\"\n      HYPERV: \"Yes\"\n      LOCALTIME: \"Yes\"\n      GUEST_AGENT: \"Yes\"\n      VIRTIO_SCSI_QUEUES: \"auto\"\n      VIRTIO_BLK_QUEUES: \"auto\"\n      # IOTHREADS:\n    CPU_MODEL:\n      MODEL: \"host-passthrough\"\n        # FEATURES:\n        # - Tunable depending on host CPU support\n        # -\n    RAW:\n      DATA: |-\n        <features>\n          <hyperv>\n            <evmcs state='off'/>\n            <frequencies state='on'/>\n            <ipi state='on'/>\n            <reenlightenment state='off'/>\n            <relaxed state='on'/>\n            <reset state='off'/>\n            <runtime state='on'/>\n            <spinlocks state='on' retries='8191'/>\n            <stimer state='on'/>\n            <synic state='on'/>\n            <tlbflush state='on'/>\n            <vapic state='on'/>\n            <vpindex state='on'/>\n          </hyperv>\n        </features>\n        <clock offset='utc'>\n          <timer name='hpet' present='no'/>\n          <timer name='hypervclock' present='yes'/>\n          <timer name='pit' tickpolicy='delay'/>\n          <timer name='rtc' tickpolicy='catchup'/>\n        </clock>\n      VALIDATE: \"Yes\"\n```\n\n----------------------------------------\n\nTITLE: Complete OneDRS Configuration File (YAML)\nDESCRIPTION: Shows a complete configuration file example for the OneDRS scheduler, including solver settings, placement policies, optimization settings, migration thresholds, predictive weight, memory scaling, and virtual network settings. This file ``/etc/one/schedulers/one_drs.conf`` defines the default DRS behavior, which can be overridden per cluster.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/drs.rst#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nDEFAULT_SCHED:\n  SOLVER: \"CBC\"\n  SOLVER_PATH: \"/usr/lib/one/python/pulp/solverdir/cbc/linux/64/cbc\"\n\nPLACE:\n  POLICY: \"PACK\"\n\nOPTIMIZE:\n  POLICY: \"BALANCE\"\n  MIGRATION_THRESHOLD: 10\n  WEIGHTS:\n    CPU_USAGE: 0.2\n    CPU: 0.2\n    MEMORY: 0.4\n    DISK: 0.1\n    NET: 0.1\n\nPREDICTIVE: 0.3\n\nMEMORY_SYSTEM_DS_SCALE: 0\n\nDIFFERENT_VNETS: YES\n```\n\n----------------------------------------\n\nTITLE: Quota Template Example (Bash)\nDESCRIPTION: This is an example of a quota template for a user in OpenNebula. It defines limits for Datastore usage, VM resources (CPU, Memory, number of VMs), Network leases, and Image usage.  The negative values for `IMAGES` and `SYSTEM_DISK_SIZE` indicate that there are no disk size restrictions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/quotas.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nDATASTORE=[\n  ID=\"1\",\n  IMAGES=\"-2\",\n  SIZE=\"20480\"\n]\n\nVM=[\n  CPU=\"5\",\n  MEMORY=\"2048\",\n  VMS=\"4\",\n  SYSTEM_DISK_SIZE=\"-1\"\n]\n\nNETWORK=[\n  ID=\"1\",\n  LEASES=\"4\"\n]\n\nIMAGE=[\n  ID=\"1\",\n  RVMS=\"3\"\n]\n\nIMAGE=[\n  ID=\"2\",\n  RVMS=\"-2\"\n]\n```\n\n----------------------------------------\n\nTITLE: Listing Virtual Networks\nDESCRIPTION: This snippet shows how to list the virtual networks in the system using the onevnet command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_7\n\nLANGUAGE: none\nCODE:\n```\n$ onevnet list\n```\n\n----------------------------------------\n\nTITLE: Authentication Manager Configuration - Bash\nDESCRIPTION: This configuration sets up the Authentication Manager in OpenNebula. It specifies the path to the authentication driver executable, the authentication modules to use, and the session expiration time. It is essential for defining how OpenNebula authenticates and authorizes requests.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nAUTH_MAD = [\n        executable = \"one_auth_mad\",\n        authn = \"ssh,x509,ldap,server_cipher,server_x509\"\n    ]\n```\n\n----------------------------------------\n\nTITLE: Virtualization Driver Configuration in oned.conf (Bash)\nDESCRIPTION: This snippet configures a virtualization driver, specifically KVM, in the OpenNebula oned.conf file. It specifies the driver's name, executable path, arguments, type, and default configuration file. The configuration also handles settings for live resizing and shareable disks.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n#-------------------------------------------------------------------------------\n# Virtualization Driver Configuration\n#-------------------------------------------------------------------------------\n\nVM_MAD = [\n    NAME           = \"kvm\",\n    SUNSTONE_NAME  = \"KVM\",\n    EXECUTABLE     = \"one_vmm_exec\",\n    ARGUMENTS      = \"-t 15 -r 0 kvm\",\n    DEFAULT        = \"vmm_exec/vmm_exec_kvm.conf\",\n    TYPE           = \"kvm\",\n    KEEP_SNAPSHOTS = \"no\",\n    LIVE_RESIZE    = \"yes\",\n    SUPPORT_SHAREABLE    = \"yes\"\n]\n```\n\n----------------------------------------\n\nTITLE: onedb fsck (Text)\nDESCRIPTION: Checks and repairs the consistency of OpenNebula objects in the database using the `onedb fsck` command. It automatically backs up the database before making changes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_9\n\nLANGUAGE: text\nCODE:\n```\n$ onedb fsck\nSqlite database backup stored in /var/lib/one/one.db.bck\nUse 'onedb restore' or copy the file back to restore the DB.\n\nHost 0 RUNNING_VMS has 12   is  11\nHost 0 CPU_USAGE has 1200   is  1100\nHost 0 MEM_USAGE has 1572864    is  1441792\nImage 0 RUNNING_VMS has 6   is  5\nUser 2 quotas: CPU_USED has 12  is  11.0\nUser 2 quotas: MEMORY_USED has 1536     is  1408\nUser 2 quotas: VMS_USED has 12  is  11\nUser 2 quotas: Image 0  RVMS has 6  is  5\nGroup 1 quotas: CPU_USED has 12     is  11.0\nGroup 1 quotas: MEMORY_USED has 1536    is  1408\nGroup 1 quotas: VMS_USED has 12     is  11\nGroup 1 quotas: Image 0 RVMS has 6  is  5\n\nTotal errors found: 12\n```\n\n----------------------------------------\n\nTITLE: Configure VLAN Filtering on Linux Bridge\nDESCRIPTION: This snippet demonstrates the configuration steps for VLAN filtering on a Linux bridge. It includes creating a transport VLAN interface, adding it to the bridge, enabling VLAN filtering on the bridge, and configuring VLAN IDs for VM ports and the transport link. The transport VLAN ID is 100 and customer VLAN IDs are 200 and 300.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vlan.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# - Transport / outer / S-VLAN : 100\n# - Customer / inner / C-VLAN  : 200,300\n\n# \"Transport\" link\nip link add link eth1 name eth1.100 type vlan id 100\nip link set eth1.100 master onebr.23\nip link set eth1.100 up\n\n# Bridge Configuration:\nip link set dev onebr.23 type bridge vlan_filtering 1\n\n# VM port configuration (NIC 1 of VM 20, and transport link):\nbridge vlan add dev one-20-1 vid 100 pvid untagged\nbridge vlan add dev one-20-1 vid 200\nbridge vlan add dev one-20-1 vid 300\n\nbridge vlan add dev eth1.100 vid 100 pvid untagged\nbridge vlan add dev eth1.100 vid 200\nbridge vlan add dev eth1.100 vid 300\n```\n\n----------------------------------------\n\nTITLE: FRR Configuration for Route Reflector\nDESCRIPTION: This FRR configuration sets up a route reflector for BGP EVPN. It defines the router ID, cluster ID, peer group, and listening range for hypervisors. This configuration allows the route reflector to distribute BGP updates between hypervisors.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vxlan.rst#_snippet_6\n\nLANGUAGE: FRR\nCODE:\n```\nrouter bgp 7675\n  bgp router-id 10.4.4.13\n  bgp cluster-id 10.4.4.13\n  no bgp default ipv4-unicast\n  neighbor kvm_hosts peer-group\n  neighbor kvm_hosts remote-as 7675\n  neighbor kvm_hosts capability extended-nexthop\n  neighbor kvm_hosts update-source 10.4.4.13\n  bgp listen range 10.4.4.0/24 peer-group kvm_hosts\n  address-family l2vpn evpn\n   neighbor fabric activate\n   neighbor fabric route-reflector-client\n  exit-address-family\nexit\n```\n\n----------------------------------------\n\nTITLE: Copying Ceph keyring to OpenNebula node\nDESCRIPTION: This snippet copies the Ceph user keyring (ceph.client.libvirt.keyring) to the /etc/ceph directory and the user key (client.libvirt.key) to the oneadmin home directory on the OpenNebula node.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ scp ceph.client.libvirt.keyring root@node:/etc/ceph\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ scp client.libvirt.key oneadmin@node:\n```\n\n----------------------------------------\n\nTITLE: Configuring VXLAN ID Start Value (Bash)\nDESCRIPTION: This snippet shows how to configure the starting VXLAN ID (VNI) within the `/etc/one/oned.conf` file for automatic VXLAN network assignment.  The `VXLAN_IDS` attribute allows specifying the first VNI to be used when creating VXLAN networks in OpenNebula.  This snippet requires access to the OpenNebula server configuration file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vxlan.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nVXLAN_IDS = [\n    START = \"2\"\n]\n```\n\n----------------------------------------\n\nTITLE: User Login with SSH Authentication\nDESCRIPTION: The `oneuser login` command generates a login token for the specified user using SSH authentication. The token is stored in the file pointed to by the `$ONE_AUTH` environment variable. This token is needed to use the OpenNebula CLI.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ssh.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\noneuser login johndoe --ssh\n```\n\n----------------------------------------\n\nTITLE: Creating a New User with X.509 Authentication Using Certificate\nDESCRIPTION: This command demonstrates how to create a new OpenNebula user with X.509 authentication, providing the path to the user's certificate. This creates a new user with the username 'johndoe'. The subject DN from the certificate is extracted and used as the password for authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\noneuser create johndoe --x509 --cert /tmp/newcert.pem\n```\n\n----------------------------------------\n\nTITLE: QEMU Configuration for VFIO Device Access\nDESCRIPTION: This configuration allows QEMU to access the VFIO devices by specifying the device paths in the cgroup_device_acl setting. This is essential for enabling PCI passthrough to VMs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ncgroup_device_acl = [\n\t\t\"/dev/null\", \"/dev/full\", \"/dev/zero\",\n\t\t\"/dev/random\", \"/dev/urandom\",\n\t\t\"/dev/ptmx\", \"/dev/kvm\", \"/dev/kqemu\",\n\t\t\"/dev/rtc\",\"/dev/hpet\", \"/dev/vfio/vfio\",\n\t\t\"/dev/vfio/45\", \"/dev/vfio/46\", \"/dev/vfio/58\",\n\t\t\"/dev/vfio/59\"\n\t]\n```\n\n----------------------------------------\n\nTITLE: Creating Image Template\nDESCRIPTION: This snippet demonstrates how to create an image template file with specific attributes such as NAME, PATH, and DESCRIPTION. The template file is then used to create a new image in OpenNebula using the 'oneimage create' command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ cat ubuntu_img.one\nNAME          = \"Ubuntu\"\nPATH          = \"/home/cloud/images/ubuntu-desktop/disk.0.qcow2\"\nDESCRIPTION   = \"Ubuntu desktop for developers.\"\n```\n\n----------------------------------------\n\nTITLE: Generate Prometheus Configuration\nDESCRIPTION: Executes the `patch_datasources.rb` script to generate the Prometheus configuration file (`/etc/one/prometheus/prometheus.yml`). This script gathers information from OpenNebula to configure scrape endpoints.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# /usr/share/one/prometheus/patch_datasources.rb\n```\n\n----------------------------------------\n\nTITLE: Provisioning Prometheus Datasource in Grafana\nDESCRIPTION: This code snippet demonstrates how to create a Grafana datasource configuration file for Prometheus using provisioning. It defines the datasource name, type, access method, URL, default setting, and editability. Requires Grafana provisioning enabled.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/grafana.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# mkdir -p /etc/grafana/provisioning/datasources/\n# cat >/etc/grafana/provisioning/datasources/prometheus.yml <<'EOF'\napiVersion: 1\ndatasources:\n- name: prometheus\n  type: prometheus\n  access: proxy\n  url: http://localhost:9090\n  isDefault: true\n  editable: false\nEOF\n```\n\n----------------------------------------\n\nTITLE: Enabling X.509 Authentication in oned.conf\nDESCRIPTION: This code snippet shows how to enable the x509 authentication method in the AUTH_MAD section of the /etc/one/oned.conf file. It ensures that the OpenNebula daemon is configured to use X.509 for authentication, alongside other methods such as ssh, ldap, server_cipher, and server_x509. This setting allows OpenNebula to validate user certificates during the authentication process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nAUTH_MAD = [\n    EXECUTABLE = \"one_auth_mad\",\n    AUTHN = \"ssh,x509,ldap,server_cipher,server_x509\"\n]\n```\n\n----------------------------------------\n\nTITLE: Setting Default Authentication to LDAP - Bash\nDESCRIPTION: This snippet configures OpenNebula to enable external LDAP authentication for all new users.  It adds the DEFAULT_AUTH parameter to the oned.conf file, setting its value to 'ldap'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nDEFAULT_AUTH = \"ldap\"\n```\n\n----------------------------------------\n\nTITLE: Attaching VM to Virtual Network by ID - OpenNebula Template\nDESCRIPTION: This snippet demonstrates attaching a VM to a virtual network using the network's ID. The `NIC` attribute is used with `NETWORK_ID` to specify the numerical ID of the target virtual network. The VM will receive a free IP address from the network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_15\n\nLANGUAGE: xml\nCODE:\n```\nNIC = [ NETWORK_ID = 0 ]\n```\n\n----------------------------------------\n\nTITLE: Scheduling VM Suspend Action\nDESCRIPTION: This example shows how to schedule a VM suspend action to occur weekly for a specified number of times. The command uses the `onevm suspend` command with the `--schedule`, `--weekly`, and `--end` options to define the schedule.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_28\n\nLANGUAGE: text\nCODE:\n```\n$ onevm suspend 0 --schedule \"09/20\" --weekly \"1,5\" --end 5\nVM 0: suspend scheduled at 2018-09-20 00:00:00 +0200\n```\n\n----------------------------------------\n\nTITLE: Showing Cluster Details After Adding Resources with onecluster\nDESCRIPTION: This snippet displays the details of the 'production' cluster (ID 100) after adding a host, a virtual network, and a datastore. It shows the updated HOSTS, VNETS, and DATASTORES sections in the `onecluster show` output. The cluster ID is required as a parameter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster show 100\nCLUSTER 100 INFORMATION\nID             : 100\nNAME           : production\n\nCLUSTER TEMPLATE\n\nHOSTS\n0\n\nVNETS\n1\n\nDATASTORES\n100\n```\n\n----------------------------------------\n\nTITLE: Creating an ACL Rule\nDESCRIPTION: This command creates a new ACL rule using the `oneacl` command-line tool.  It takes a string as input, defining the user, resource, resource ID, operation, and zone. The rule `@106 IMAGE/#31 USE` allows user/group 106 to use image #31.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_9\n\nLANGUAGE: text\nCODE:\n```\n$ oneacl create \"@106 IMAGE/#31 USE\"\nID: 5\n```\n\n----------------------------------------\n\nTITLE: Modifying Backup Job Schedule in OpenNebula\nDESCRIPTION: These commands allow you to add, update, and delete schedules for a specific backup job in OpenNebula. To work with a specific schedule, provide its corresponding ID obtained from the `onebackupjob show` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nonebackupjob backup --schedule\n```\n\nLANGUAGE: bash\nCODE:\n```\nonebackupjob sched-update\n```\n\nLANGUAGE: bash\nCODE:\n```\nonebackupjob sched-delete\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Community Repository on Debian 12\nDESCRIPTION: This bash script adds the OpenNebula Community Edition repository to the Debian 12 system. It creates a `/etc/apt/sources.list.d/opennebula.list` file with the repository configuration, including the base URL and specifies the GPG key file. The script then updates the apt package list.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# echo \\\"deb [signed-by=/etc/apt/keyrings/opennebula.gpg] https://downloads.opennebula.io/repo/|version|/Debian/12 stable opennebula\\\" > /etc/apt/sources.list.d/opennebula.list\n# apt-get update\n```\n\n----------------------------------------\n\nTITLE: Defining USER_INPUTS in VM Template\nDESCRIPTION: This code snippet shows how to define USER_INPUTS in a VM template to allow users to provide input values when instantiating the VM. The format is APP_GROUP_FIELD=\"Modifier|Type|Label\".\nDependencies: None\nInputs: None\nOutputs: The USER_INPUTS variable will be used to render the form in sunstone for user's input.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_5\n\nLANGUAGE: none\nCODE:\n```\nUSER_INPUTS = [\n  ONEAPP_BLOG_CONF_TITLE=\"M|text|Blog Title\",\n  ONEAPP_BLOG_CONF_DESCRIPTION=\"O|text|Blog Description\",\n  ONEAPP_MYSQL_CONFIG_ENDPOINT=\"M|text|MySQL Endpoint\",\n  ONEAPP_MYSQL_CONFIG_USER=\"O|password|MySQL User\",\n  ONEAPP_MYSQL_CONFIG_PASSWORD=\"O|password|MySQL Password\",\n  ONEAPP_MYSQL_ADDITIONAL_ENABLED=\"O|boolean|Define additional parameters\",\n  ONEAPP_MYSQL_ADDITIONAL_SOCKET=\"O|text|MySQL Socket\",\n  ONEAPP_MYSQL_ADDITIONAL_CHARSET=\"O|text|MySQL Charset\",\n]\n```\n\n----------------------------------------\n\nTITLE: MySQL Change Password Example\nDESCRIPTION: Shows how to change the password for the `oneadmin` user in MySQL using the `SET PASSWORD` command. This is a workaround for special characters in passwords that may cause connection issues with `onedb`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n$ mysql -u oneadmin -p\nmysql> SET PASSWORD = PASSWORD('newpass');\n```\n\n----------------------------------------\n\nTITLE: Configuring Encrypted Attributes in OpenNebula\nDESCRIPTION: This code snippet shows how to configure encrypted attributes in OpenNebula. These attributes are encrypted and decrypted by the OpenNebula core. Includes attributes for CLUSTER, DOCUMENT, DATASTORE, HOST, VM, VNET, USER, and IMAGE.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nDOCUMENT_ENCRYPTED_ATTR = \"PROVISION_BODY\"\n\nHOST_ENCRYPTED_ATTR = \"AZ_ID\"\nHOST_ENCRYPTED_ATTR = \"AZ_CERT\"\nHOST_ENCRYPTED_ATTR = \"VCENTER_PASSWORD\"\nHOST_ENCRYPTED_ATTR = \"NSX_PASSWORD\"\nHOST_ENCRYPTED_ATTR = \"ONE_PASSWORD\"\n\nVM_ENCRYPTED_ATTR = \"ONE_PASSWORD\"\nVM_ENCRYPTED_ATTR = \"CONTEXT/PASSWORD\"\n```\n\n----------------------------------------\n\nTITLE: CPU Pinning Topology Example\nDESCRIPTION: Example configuration showing how to pin the VM to specific cores/threads on the Host. This example uses the THREAD policy, setting the sockets to 2.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_12\n\nLANGUAGE: text\nCODE:\n```\nVCPU   = 8\nMEMORY = 4096\n\nTOPOLOGY = [ PIN_POLICY = thread, SOCKETS = 2 ]\n```\n\n----------------------------------------\n\nTITLE: Virtual Network Configuration in oned.conf (Bash)\nDESCRIPTION: This snippet defines the configuration for virtual networks within the OpenNebula oned.conf file. It sets parameters like default network size, MAC address prefix, and VLAN/VXLAN ID pools. These settings are crucial for automatic assignment of network resources to virtual machines.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n#*******************************************************************************\n# Physical Networks configuration\n#*******************************************************************************\n\nNETWORK_SIZE = 254\n\nMAC_PREFIX   = \"02:00\"\n\nVLAN_IDS = [\n    START    = \"2\",\n    RESERVED = \"0, 1, 4095\"\n]\n\nVXLAN_IDS = [\n    START = \"2\"\n]\n```\n\n----------------------------------------\n\nTITLE: Memory Cleanup Configuration in KVM\nDESCRIPTION: This code snippet shows the configuration options in the `kvmrc` file to enable memory compaction before and after VM execution. `CLEANUP_MEMORY_ON_START` compacts memory before running the VM. `CLEANUP_MEMORY_ON_STOP` compacts memory after the VM stops.  By default, only `CLEANUP_MEMORY_ON_STOP` is enabled.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Compact memory before running the VM\n#CLEANUP_MEMORY_ON_START=yes\n\n# Compact memory after VM stops\nCLEANUP_MEMORY_ON_STOP=yes\n```\n\n----------------------------------------\n\nTITLE: DPDK Virtual Machine Template in OpenNebula (Bash)\nDESCRIPTION: This Virtual Machine template configures a VM to use DPDK.  It sets the NIC model to virtio, configures hugepages for shared memory access between the VM and OVS, and includes topology settings to optimize performance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nNAME   = \"DPDK_VM\"\nMEMORY = \"4096\"\n\nNIC = [ NETWORK = \"DPDK_VSBC_HA2\" ]\n\nTOPOLOGY = [\n  CORES = \"2\",\n  HUGEPAGE_SIZE = \"1024\",\n  MEMORY_ACCESS = \"shared\",\n  PIN_POLICY    = \"THREAD\",\n  SOCKETS = \"1\",\n  THREADS = \"2\"\n]\n```\n\n----------------------------------------\n\nTITLE: Applying a Configuration Patch via Standard Input (line format)\nDESCRIPTION: This example demonstrates how to apply a configuration patch to OpenNebula by passing the patch data via standard input, using the `line` format. It updates several configuration parameters within `/etc/one/oned.conf` using the `set` and `ins` commands. The `INFO` and `ANY` outputs show the progress and results of the patching process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg patch --verbose --format line <<EOF\n/etc/one/oned.conf set PORT 2633\n/etc/one/oned.conf set LISTEN_ADDRESS \\\"\\\"127.0.0.1\\\"\\\"\"\n/etc/one/oned.conf set DB/BACKEND \\\"\\\"mysql\\\"\\\"\"\n/etc/one/oned.conf ins DB/SERVER \\\"\\\"localhost\\\"\\\"\"\n/etc/one/oned.conf ins DB/USER \\\"\\\"oneadmin\\\"\\\"\"\n/etc/one/oned.conf ins DB/PASSWD \\\"\\\"secret_password\\\"\\\"\"\n/etc/one/oned.conf ins DB/NAME \\\"\\\"opennebula\\\"\\\"\"\nEOF\n```\n\n----------------------------------------\n\nTITLE: Instantiate Template with specific user/group using CLI\nDESCRIPTION: This command shows how to instantiate a VM template while specifying the owner (user) and group for the newly created VM using the `--as_uid` and `--as_gid` options.  This requires appropriate permissions.\nDependencies: OpenNebula CLI\nInputs: Template ID, User ID, Group ID.\nOutputs: Creates a new VM instance owned by the specified user and group.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_13\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate instantiate 6 --as_uid 2 --as_gid 1\nVM ID: 0\n```\n\nLANGUAGE: text\nCODE:\n```\n$ onevm list\n    ID USER      GROUP    NAME         STAT CPU     MEM        HOSTNAME        TIME\n     0 test_user users    one-0        pend   0      0K                 00 00:00:16\n```\n\n----------------------------------------\n\nTITLE: Modifying Template Permissions using onetemplate chmod\nDESCRIPTION: This snippet demonstrates how to modify template permissions using the `onetemplate chmod` command. The first example sets group permissions to read (u--) by using `onetemplate chmod 0 640`, while the second example sets group permissions to manage (um-) and other permissions to use (u--) using `onetemplate chmod 0 664`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_22\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate chmod 0 640\n```\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate show 0\n...\nPERMISSIONS\nOWNER          : um-\nGROUP          : u--\nOTHER          : ---\n```\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate chmod 0 664\n```\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate show 0\n...\nPERMISSIONS\nOWNER          : um-\nGROUP          : um-\nOTHER          : u--\n```\n\n----------------------------------------\n\nTITLE: Attaching a Network to a Role in Service Template\nDESCRIPTION: This example shows how to attach a network to a Role within a Service Template using the \"template_contents\" field. The \"NETWORK_ID\" specifies which network (defined in \"networks_values\") to attach to the Role's network interface (NIC). The \"NAME\" field assigns a name to the network interface.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_17\n\nLANGUAGE: json\nCODE:\n```\n{\n  ...\n  \"roles\": [\n    ...\n    {\n      \"name\": \"worker\",\n      \"type\": \"vm\",\n      \"template_id\": 1,\n      \"cardinality\": 3,\n      \"template_contents\": {\n        \"NIC\": [\n          {\n            \"NETWORK_ID\": \"$Public\",\n            \"NAME\": \"NIC_0\"\n          }\n        ]\n      }\n    },\n    ...\n  ],\n  \"networks_values\": [\n    { \"Public\": {\n        reserve_from\": \"<vnet_id>\",\n        \"extra\": \"NAME=RESERVATION\\nSIZE=5\"\n      }\n    }\n  ],\n...\n}\n```\n\n----------------------------------------\n\nTITLE: Import OVF with oneswap in OpenNebula\nDESCRIPTION: This example shows how to import an OVF file using the oneswap command, specifying the Datastore ID and VNET ID. It demonstrates the command execution and the subsequent steps to list and instantiate the template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/ova_management/import_ova.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ oneswap import --ova /ovas/vm-alma9/ --datastore 101 --network 1\nRunning: virt-v2v -v --machine-readable -i ova /ovas/vm-alma9/ -o local -os /tmp/vm-alma9/conversions/ -of qcow2 --root=first\n\nSetting up the source: -i ova /home/onepoc/ovas/vm-alma9/\n\n(...)\n\n$ onetemplate list\nID USER     GROUP    NAME               REGTIME\n63 onepoc   oneadmin vm-alma9    03/24 16:34:34\n\n$ onetemplate instantiate 63\nVM ID: 103\n```\n\n----------------------------------------\n\nTITLE: Defining a VM Group\nDESCRIPTION: This snippet demonstrates how to define a VM Group using a template file. It includes the VM Group name and role definitions with placement policies such as anti-affinity. This configuration is used to create a new VM Group using the `onevmgroup create` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/affinity.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ cat ./vmg.txt\n\nNAME = \"multi-tier server\"\n\nROLE = [\n    NAME   = \"front-end\",\n    POLICY = \"ANTI_AFFINED\"\n]\n\nROLE = [\n    NAME         = \"apps\",\n    HOST_AFFINED = \"2,3,4\"\n]\n\nROLE = [ NAME = \"db\" ]\n\nAFFINED = \"db, apps\"\n\n$ onevmgroup create ./vmg.txt\nID: 0\n```\n\n----------------------------------------\n\nTITLE: Adding Physical Resources (Host, VNet, Datastore) to a VDC with onevdc\nDESCRIPTION: These commands add individual physical resources (Host, Virtual Network, and Datastore) to a VDC. `<vdc_id>` represents the ID of the VDC, `0` is the Zone ID, and the last number is the resource's ID. These commands assign the specified resources in Zone 0 to the VDC.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_vdcs.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onevdc addhost <vdc_id> 0 3\n$ onevdc addvnet <vdc_id> 0 9\n$ onevdc adddatastore <vdc_id> 0 102\n```\n\n----------------------------------------\n\nTITLE: Detaching a Security Group from a Virtual Machine's NIC\nDESCRIPTION: This command detaches a security group from a specific network interface card (NIC) of a virtual machine. The example detaches security group with ID '101' from NIC '0' of the virtual machine named 'centos-server'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm sg-detach centos-server 0 101\n```\n\n----------------------------------------\n\nTITLE: Creating a Ceph pool for OpenNebula\nDESCRIPTION: This snippet creates a Ceph pool named 'one', enables the rbd application profile on the pool, initializes the pool for rbd, and lists all pools to confirm its creation. This pool will be used for OpenNebula datastores.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ceph osd pool create one 128\n$ ceph osd pool application enable one rbd\n$ rbd pool init -p one\n$ ceph osd lspools\n```\n\n----------------------------------------\n\nTITLE: Setting VM Context with Bash in OpenNebula\nDESCRIPTION: This snippet demonstrates how to define the CONTEXT attribute of a virtual machine using the command-line interface (CLI) in OpenNebula. It includes enabling token and network configuration, setting the SSH public key, and defining a startup script to install ntpdate using yum.  It provides a basic example that can be customized further.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/kvm_contextualization.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nCONTEXT = [\n    TOKEN = \"YES\",\n    NETWORK = \"YES\",\n    SSH_PUBLIC_KEY = \"$USER[SSH_PUBLIC_KEY]\",\n    START_SCRIPT = \"yum install -y ntpdate\"\n]\n```\n\n----------------------------------------\n\nTITLE: Creating a CDROM Image from URL in OpenNebula\nDESCRIPTION: This command creates a CDROM image in OpenNebula from a specified URL. The `oneimage create` command is used with the `--name` option to set the image name, `--path` to specify the URL of the ISO file, `--type` to define the image type as CDROM, and `--datastore` to specify the datastore where the image will be stored. This is used to add an installation medium to OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/creating_images.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage create --name centos7-install --path https://buildlogs.centos.org/rolling/7/isos/x86_64/CentOS-7-x86_64-DVD-1910-01.iso --type CDROM --datastore default\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Connection in oned.conf (text)\nDESCRIPTION: This snippet shows how to configure the database connection settings in the /etc/one/oned.conf file for an OpenNebula API server. It includes the database backend, server IP, port, user credentials, database name, and the number of connections.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/scalability.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nDB = [ BACKEND = \"mysql\",\n\t    SERVER  = \"set IP of mysql server\",\n\t    PORT = 0,\n\t    USER = \"oneadmin\",\n\t    PASSWD = \"oneadmin\",\n\t    DB_NAME = \"opennebula\",\n\t    CONNECTIONS = 50\n```\n\n----------------------------------------\n\nTITLE: Adding a Datastore to a Cluster with onecluster\nDESCRIPTION: This snippet adds a datastore named 'iscsi' to the 'production' cluster using the `onecluster adddatastore` command. It demonstrates how to associate a datastore with a specific cluster. The command requires the cluster name and datastore name or ID as parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster adddatastore production iscsi\n```\n\n----------------------------------------\n\nTITLE: Generating LUKS Encryption Key\nDESCRIPTION: This snippet shows how to generate a secret key using OpenSSL and store it in a file. This key will be used for encrypting a LUKS image.  The '=' character is removed from the base64 output.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ openssl rand -base64 10|tr -d '=' > passphrase.luks\n```\n\n----------------------------------------\n\nTITLE: Configuring Default VDC ACL Rules in OpenNebula\nDESCRIPTION: This code snippet demonstrates how to configure default ACL rules for Virtual Data Centers (VDCs) in OpenNebula.  It shows settings for hosts, networks and datastores. These rules define permissions granted to the VDC group when resources are added to the VDC.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\nDEFAULT_VDC_HOST_ACL      = \"MANAGE\"\n#Adds @<gid> HOST/#<hid> MANAGE #<zid> when a host is added to the VDC.\nonevdc addhost <vdc> <zid> <hid>\n\nDEFAULT_VDC_NET_ACL       = \"USE\"\n#Adds @<gid> NET/#<vnetid> USE #<zid> when a vnet is added to the VDC.\nonevdc addvnet <vdc> <zid> <vnetid>\n\nDEFAULT_VDC_DATASTORE_ACL = \"USE\"\n#Adds @<gid> DATASTORE/#<dsid> USE #<zid> when a vnet is added to the VDC.\nonevdc adddatastore <vdc> <zid> <dsid>\n\nDEFAULT_VDC_CLUSTER_HOST_ACL      = \"MANAGE\"\nDEFAULT_VDC_CLUSTER_NET_ACL       = \"USE\"\nDEFAULT_VDC_CLUSTER_DATASTORE_ACL = \"USE\"\n#Adds:\n#@<gid> HOST/%<cid> MANAGE #<zid>\n#@<gid> DATASTORE+NET/%<cid> USE #<zid>\n#when a cluster is added to the VDC.\nonevdc addcluster <vdc> <zid> <cid>\n```\n\n----------------------------------------\n\nTITLE: Configuring OneFlow Host\nDESCRIPTION: This snippet demonstrates configuring the OneFlow server to listen on all network interfaces by setting the ':host:' parameter to '0.0.0.0' in the /etc/one/oneflow-server.conf file. This allows remote API access to OneFlow.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_8\n\nLANGUAGE: none\nCODE:\n```\n:host: 0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Creating Restic Datastore\nDESCRIPTION: This command creates a new datastore in OpenNebula using the template defined in the ds_restic.txt file. The datastore is used for storing VM backups using Restic.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/restic.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore create ds_restic.txt\n```\n\n----------------------------------------\n\nTITLE: Instantiating Service Template with name change using curl\nDESCRIPTION: This curl command demonstrates how to instantiate a service template and override its name using the 'merge_template' parameter.  It uses the POST method to send a request to the /service_template/4/action endpoint, specifying the 'instantiate' action and a JSON payload that includes the desired name change. Authentication uses 'oneadmin:password'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service_template/4/action -u 'oneadmin:password' -v -X POST --data '{\n  \"action\": {\n    \"perform\":\"instantiate\",\n    \"params\": {\"merge_template\":{\"name\":\"new_name\"}}\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Enabling virt_use_nfs SELinux boolean (Bash)\nDESCRIPTION: This snippet demonstrates enabling the `virt_use_nfs` SELinux boolean, which is required when using NFS datastores in OpenNebula deployments with SELinux enabled. This allows virtual machines to access NFS shares. The `-P` flag makes the change persistent across reboots.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/selinux.txt#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# setsebool -P virt_use_nfs on\n```\n\n----------------------------------------\n\nTITLE: VM CONTEXT Definition using FILES_DS\nDESCRIPTION: This snippet defines the CONTEXT section of a VM template, including file images (context files) that will be accessible to the VM at boot time. It uses the `FILES_DS` attribute and references images by both name and ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_30\n\nLANGUAGE: none\nCODE:\n```\nCONTEXT = [\n      FILES_DS   = \"$FILE[IMAGE_ID=34] $FILE[IMAGE=webpageDB]\",\n    ]\n```\n\n----------------------------------------\n\nTITLE: Enabling Remote Desktop via Firewall (Windows)\nDESCRIPTION: This code snippet shows how to enable Remote Desktop through the Windows Firewall by setting the RemoteDesktop rule group to enabled. This is run in the Context section (start script) of the VM template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_47\n\nLANGUAGE: none\nCODE:\n```\nnetsh advfirewall firewall set rule group=\"Remotedesktop\" new enable=yes\n```\n\n----------------------------------------\n\nTITLE: Instantiate Virtual Network Template\nDESCRIPTION: This snippet shows how to instantiate a Virtual Network Template using the 'onevntemplate instantiate' command.  It creates a new Virtual Network named 'private' from template ID 0, executed as user 'user'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vn_templates.rst#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ onevntemplate instantiate 0 --user user --name private\n  VN ID: 1\n```\n\n----------------------------------------\n\nTITLE: Setting Hugepage Size with NUMA Affinity in VM Template\nDESCRIPTION: This code snippet shows how to specify the hugepage size and NUMA node affinity in a VM template. It sets the `NODE_AFFINITY` to 0 and `HUGEPAGE_SIZE` to 2, ensuring that the VM's resources are allocated on the specified NUMA node with 2MB hugepages.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_14\n\nLANGUAGE: Text\nCODE:\n```\nTOPOLOGY = [ NODE_AFFINITY = 0, HUGEPAGE_SIZE = 2 ]\n```\n\n----------------------------------------\n\nTITLE: Displaying Host Information in OpenNebula (onehost)\nDESCRIPTION: This snippet demonstrates how to display detailed information about a specific host in OpenNebula using the `onehost show` command. The command takes the hostname or ID as input and outputs various details, including general information, capacity, local datastore information, monitoring information, and virtual machines allocated to the host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost show server\n```\n\n----------------------------------------\n\nTITLE: Automatic Virtual Network Selection - OpenNebula Template\nDESCRIPTION: This code snippet configures automatic virtual network selection for a VM's network interface.  By setting `NETWORK_MODE` to \"auto\" within the `NIC` attribute, the scheduler automatically selects a suitable virtual network during deployment, allowing for generic templates usable across multiple clusters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_17\n\nLANGUAGE: xml\nCODE:\n```\nNIC = [ NETWORK_MODE = \"auto\" ]\n```\n\n----------------------------------------\n\nTITLE: Listing PCI devices with virsh\nDESCRIPTION: This command uses `virsh nodedev-list` to list PCI devices and filters the output to find the NVIDIA GPU using its transformed PCI address.  The transformed address replaces colons and periods with underscores.  The output gives the device name for use in the `virsh nodedev-dumpxml` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nvirsh nodedev-list --cap pci | grep 41_00_0\n```\n\n----------------------------------------\n\nTITLE: Changing Authentication Method to SSH\nDESCRIPTION: These commands change an existing user's authentication method to SSH. The `oneuser chauth` command sets the authentication type to 'ssh', and `oneuser passwd` associates the user's public key with their account.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ssh.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\noneuser chauth <id|name> ssh\n```\n\nLANGUAGE: bash\nCODE:\n```\noneuser passwd <id|name> --ssh --read-file /tmp/pub_key\n```\n\n----------------------------------------\n\nTITLE: List Virtual Networks\nDESCRIPTION: This snippet displays the list of virtual networks using the 'onevnet list' command. It shows the ID, user, group, name, clusters, bridge, state and leases associated with each virtual network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vn_templates.rst#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ onevnet list\n  ID USER          GROUP        NAME            CLUSTERS   BRIDGE  STATE  LEASES\n  1  user          users        private         0          virbr0  rdy         0\n```\n\n----------------------------------------\n\nTITLE: Modifying VM Template Contents in Service Template (JSON)\nDESCRIPTION: This JSON snippet demonstrates how to add or overwrite information in a VM template used within a service template using the `template_contents` attribute. It shows how to set custom attributes (MY_ATT) and modify the capacity (CPU) of the original VM template. The `template_id` references existing VM templates.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"Sample Service\",\n  \"description\": \"Overwriting original template example\",\n  \"deployment\": \"straight\",\n  \"roles\": [\n    {\n      \"name\": \"master\",\n      \"type\": \"vm\",\n      \"template_id\": 0,\n      \"cardinality\": 1\n    },\n    {\n      \"name\": \"worker\",\n      \"type\": \"vm\",\n      \"template_id\": 1,\n      \"cardinality\": 2,\n      \"template_contents\": {\n        \"CPU\": 2,\n        \"MY_ATT\": \"Some fancy value\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Attaching VM to Virtual Network by Name - OpenNebula Template\nDESCRIPTION: This code snippet shows how to attach a virtual machine (VM) to a virtual network by specifying the network's name in the VM template.  The `NIC` attribute is used to define the network interface, and `NETWORK` specifies the virtual network name. The VM will receive a free IP address from the network's available range.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_14\n\nLANGUAGE: xml\nCODE:\n```\nNIC = [ NETWORK = \"Private\" ]\n```\n\n----------------------------------------\n\nTITLE: Displaying VM Information with Backup Configuration in OpenNebula\nDESCRIPTION: This snippet demonstrates how to view a VM's information, including its backup configuration, using the `onevm show` command. It displays the VM's ID, name, state, and other attributes, along with the configured backup settings, such as FS_FREEZE, KEEP_LAST, and MODE. This command is useful for verifying the backup configuration of a VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 0\n\nVIRTUAL MACHINE 0 INFORMATION\nID                  : 0\nNAME                : alpine-0\nUSER                : oneadmin\nGROUP               : oneadmin\nSTATE               : ACTIVE\nLCM_STATE           : RUNNING\n\n...\n\nBACKUP CONFIGURATION\nBACKUP_VOLATILE=\"NO\"\nFS_FREEZE=\"NONE\"\nINCREMENTAL_BACKUP_ID=\"-1\"\nKEEP_LAST=\"4\"\nLAST_INCREMENT_ID=\"-1\"\nMODE=\"INCREMENT\"\n```\n\n----------------------------------------\n\nTITLE: Prometheus Configuration YAML\nDESCRIPTION: This YAML configuration file defines the Prometheus settings for scraping metrics from various OpenNebula components, including the OpenNebula exporter, node exporter, and libvirt exporter. It also configures global settings, alerting rules, and alert managers for high availability.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\n---\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets:\n      - 192.168.150.2:9093\n      - 192.168.150.3:9093\n      - 192.168.150.1:9093\n\nrule_files:\n- rules.yml\n\nscrape_configs:\n- job_name: prometheus\n  static_configs:\n  - targets:\n    - localhost:9090\n- job_name: opennebula_exporter\n  static_configs:\n  - targets:\n    - 192.168.150.1:9925\n- job_name: node_exporter\n  static_configs:\n  - targets:\n    - 192.168.150.2:9100\n    - 192.168.150.3:9100\n    - 192.168.150.1:9100\n  - targets:\n    - kvm-ha-xqhnt-5.test:9100\n    labels:\n      one_host_id: '1'\n  - targets:\n    - kvm-ha-xqhnt-4.test:9100\n    labels:\n      one_host_id: '0'\n- job_name: libvirt_exporter\n  static_configs:\n  - targets:\n    - kvm-ha-xqhnt-5.test:9926\n    labels:\n      one_host_id: '1'\n  - targets:\n    - kvm-ha-xqhnt-4.test:9926\n    labels:\n      one_host_id: '0'\n```\n\n----------------------------------------\n\nTITLE: Virtual Network Template Definition Example\nDESCRIPTION: This code snippet shows an example of a Virtual Network Template definition with one address range, VN_MAD, and cluster IDs. The networks created using this template will be available on clusters 1 and 100.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vn_templates.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nNAME=vntemplate\nVN_MAD=\"bridge\"\nAR=[\nIP=\"10.0.0.1\",\nSIZE=\"10\",\nTYPE=\"IP4\" ]\nCLUSTER_IDS=\"1,100\"\n```\n\n----------------------------------------\n\nTITLE: Starting, Restarting, and Stopping OneFlow Service\nDESCRIPTION: These commands demonstrate how to control the OneFlow server's running state using the 'systemctl' command. The commands provide options to start, restart, and stop the 'opennebula-flow' service. These commands require root privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oneflow.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl start   opennebula-flow\n# systemctl restart opennebula-flow\n# systemctl stop    opennebula-flow\n```\n\n----------------------------------------\n\nTITLE: Creating a VM Template for OS Installation in OpenNebula\nDESCRIPTION: This command creates a VM template in OpenNebula specifically designed for OS installation.  It uses the `onetemplate create` command along with several options. `--name` specifies the template name, `--cpu` and `--memory` set the CPU and memory allocation, `--disk` defines the disks to be attached (installation disk and CDROM), `--nic` attaches a network interface, `--boot` defines the boot order, `--vnc` enables VNC for graphical installation, and `--raw` sets raw data for input devices (tablet with USB bus).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/creating_images.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onetemplate create --name centos7-cli --cpu 1 --memory 1G --disk centos7,centos7-install --nic network --boot disk0,disk1 --vnc --raw \"INPUT=[TYPE=tablet,BUS=usb]\"\n```\n\n----------------------------------------\n\nTITLE: Scaling OneFlow Service Role Manually\nDESCRIPTION: This command is used to manually scale a specific role within a OneFlow service. It takes the service ID, role name, and desired cardinality as input.  The `--force` option can be used to bypass defined VM limits.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_elasticity.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n$ oneflow scale <serviceid> <role_name> <cardinality>\n```\n\n----------------------------------------\n\nTITLE: Configuring VM Template for Incremental Backups in OpenNebula\nDESCRIPTION: This snippet demonstrates configuring a VM template for incremental backups using OpenNebula. It sets the FS_FREEZE option to NONE, keeps the last 4 backups, and sets the backup mode to INCREMENT.  This configuration ensures that every VM created from this template will have this backup setup.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nNAME   = \"Template  - Backup\"\nCPU    = \"1\"\nMEMORY = \"2048\"\n\nDISK = [\n  IMAGE_ID = \"1\" ]\n\nBACKUP_CONFIG = [\n  FS_FREEZE = \"NONE\",\n  KEEP_LAST = \"4\",\n  MODE = \"INCREMENT\" ]\n```\n\n----------------------------------------\n\nTITLE: Modifying AppArmor Profile for OpenNebula\nDESCRIPTION: This snippet shows a line that might be required in the `/etc/apparmor.d/abstractions/libvirt-qemu` profile depending on the OpenNebula deployment type.  It grants read, write, and create permissions to the /var/lib/one/datastores/ directory and its subdirectories.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/apparmor.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# /var/lib/one/datastores/** rwk,\n```\n\n----------------------------------------\n\nTITLE: Installing OpenNebula KVM Node on AlmaLinux/RHEL\nDESCRIPTION: Installs the OpenNebula KVM node package on AlmaLinux or RHEL systems using yum and restarts the libvirtd service. This ensures the system utilizes the OpenNebula-provided configuration file. Requires root privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_node_installation.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# yum -y install opennebula-node-kvm\n# systemctl restart libvirtd\n```\n\n----------------------------------------\n\nTITLE: Create RDM Image Using CLI\nDESCRIPTION: This command shows how to create an image in the RDM Datastore using the command-line interface, specifying the source device, driver, prefix, persistence, type, and size. The --source parameter is critical, providing the path to the block device.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/dev_ds.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage create -d 101 --name nbd --source /dev/sdc --driver raw --prefix vd --persistent --type OS --size 0MB\n```\n\n----------------------------------------\n\nTITLE: Creating an Edge Provider using oneprovider in OpenNebula\nDESCRIPTION: This snippet demonstrates how to create a new Edge provider using the `oneprovider create` command in OpenNebula. It takes the path to a provider template file as input and returns the ID of the newly created provider. The user needs to belong to the oneadmin group.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/provider_operations.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovider create /tmp/template.yml\nID: 0\n```\n\n----------------------------------------\n\nTITLE: Automatic Virtual Network Selection with Requirements and Rank - OpenNebula Template\nDESCRIPTION: This configures automatic virtual network selection with scheduling requirements and ranking. `SCHED_REQUIREMENTS` defines criteria a network must meet (e.g., TRAFFIC_TYPE and INBOUND_AVG_BW). `SCHED_RANK` specifies the preference for network selection (e.g., based on USED_LEASES).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_18\n\nLANGUAGE: xml\nCODE:\n```\nNIC = [ NETWORK_MODE = \"auto\",\n            SCHED_REQUIREMENTS = \"TRAFFIC_TYPE = \\\"public\\\" & INBOUND_AVG_BW<1500\",\n            SCHED_RANK = \"-USED_LEASES\" ]\n```\n\n----------------------------------------\n\nTITLE: Enabling Virtual Provisions in OpenNebula (Bash)\nDESCRIPTION: This code snippet provides the commands to enable virtual provisions in OpenNebula. It involves creating a symbolic link and uncommenting a line in the AWS provider configuration file. This enables the use of virtual provisions with AWS metal instances.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/aws_cluster.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo ln -s /usr/share/one/oneprovision/edge-clusters-extra/virtual /usr/share/one/oneprovision/edge-clusters\n# Edit /etc/one/fireedge/provision/providers.d/aws.yaml and uncomment virtual\n```\n\n----------------------------------------\n\nTITLE: Load-aware Policy RANK Expression\nDESCRIPTION: This RANK expression implements the load-aware policy, which aims to maximize the resources available to VMs in a node by considering node load. It prioritizes nodes with more free CPU. It depends on FREE_CPU metric and is used directly in the OpenNebula scheduler configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/rank_scheduler.rst#_snippet_2\n\nLANGUAGE: OpenNebula\nCODE:\n```\nRANK = FREE_CPU\n```\n\n----------------------------------------\n\nTITLE: Listing Hosts - OpenNebula CLI\nDESCRIPTION: This snippet shows how to list hosts in OpenNebula using the `onehost list` command. It displays host ID, name, running VMs, total CPU, free CPU, allocated CPU, total memory, free memory, allocated memory, and status.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n$ onehost list\n  ID NAME               RVM   TCPU   FCPU   ACPU   TMEM   FMEM   AMEM   STAT\n   2 testbed              0    800    800    800    16G    16G    16G     on\n```\n\n----------------------------------------\n\nTITLE: Disabling a Host in OpenNebula (onehost)\nDESCRIPTION: This snippet shows how to disable a host in OpenNebula using the `onehost disable` command. Disabling a host prevents new VM deployments to it but allows existing VMs to continue running. The host is specified by its ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost disable 0\n```\n\n----------------------------------------\n\nTITLE: Configure Virtual Router Role in Service Template\nDESCRIPTION: This snippet configures a Virtual Router (VR) role within a service template to enable network mapping and floating IPs.  It defines the role type as 'vr', sets the template ID for the VR, specifies the number of VRs to instantiate (cardinality), and configures the network interface to use a public network and allocate floating IPs. It also shows how to configure the associated network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_28\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"roles\": [\n    ...\n    {\n      \"name\": \"VNF\",\n      \"type\": \"vr\",\n      \"template_id\": 1,\n      \"cardinality\": 3,\n      \"template_contents\": {\n        \"NIC\": [\n          {\n            \"NETWORK_ID\": \"$Public\",\n            \"FLOATING_IP\": \"yes\"\n          }\n        ]\n      }\n    },\n  ]\n  \"networks_values\": [\n    {\n        \"Public\": { \n            \"template_id\": 1,\n            \"extra\": \"AR=[ IP=1.1.1.1,SIZE=10,TYPE=IP4]\"\n        }\n    }\n  ]\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Updating VM Template with SCHED_ACTION\nDESCRIPTION: This example shows how to update a VM template with a `SCHED_ACTION` attribute to terminate a VM after 1 hour of being instantiated. The action is defined within the `SCHED_ACTION` array, specifying the `ACTION` and `TIME`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_33\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate update 0\n\nSCHED_ACTION=[\n   ACTION=\"terminate\",\n   ID=\"0\",\n   TIME=\"+3600\" ]\n```\n\n----------------------------------------\n\nTITLE: Resizing VM Disk at Instantiation - OpenNebula\nDESCRIPTION: This command resizes a VM disk at the time of instantiation using the onetemplate instantiate command. It specifies the disk ID and the desired new size.  The SIZE parameter is adjusted and if larger than the original, OpenNebula increases the container size and the VM grows the filesystem using contextualization packages during boot.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\n$ onetemplate instantiate <template> --disk u2104:size=20000 # Image u2104 will be resized to 2 GB\n```\n\n----------------------------------------\n\nTITLE: Schedule Actions on Role VMs\nDESCRIPTION: This command performs an action on all virtual machines belonging to a specific role within a service. It allows for controlled rollout of actions using `--period` and `--number` options to avoid downtime. The command requires specifying the service name, role name, and action to perform.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\n$ oneflow action my-service my-role reboot --period 300 --number 2\n```\n\n----------------------------------------\n\nTITLE: Scheduling Backup Actions in OpenNebula\nDESCRIPTION: This snippet shows how to define a schedule for the backup operation using the SCHED_ACTION attribute. It specifies the repeat interval, days of the week, and end type for the scheduled action.  ACTION and ARGS are not specified within the SCHED_ACTION.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nSCHED_ACTION = [\n    REPEAT=\"0\",\n    DAYS=\"1,5\",\n    END_TYPE=\"0\"\n]\n```\n\n----------------------------------------\n\nTITLE: VXLAN Network Template Example\nDESCRIPTION: This template demonstrates the basic configuration for a VXLAN network in OpenNebula. It defines the network name, VN_MAD (vxlan), PHYDEV, VLAN_ID (optional), and BRIDGE (optional). The driver creates the bridge if it doesn't exist and attaches the physical device to it.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vxlan.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nNAME    = \"private3\"\nVN_MAD  = \"vxlan\"\nPHYDEV  = \"eth0\"\nVLAN_ID = 50            # Optional\nBRIDGE  = \"vxlan50\"     # Optional\n```\n\n----------------------------------------\n\nTITLE: Changing User Authentication to X.509 Using Certificate\nDESCRIPTION: This command demonstrates how to change an existing user's authentication method to X.509 using the user's certificate. The command requires the user's ID or name and the path to the user's certificate. The subject DN from the certificate is used as the password for authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\noneuser chauth <id|name> x509 --x509 --cert /tmp/newcert.pem\n```\n\n----------------------------------------\n\nTITLE: Defining NIC_DEFAULT in OpenNebula\nDESCRIPTION: This snippet shows how to define a default NIC configuration using the NIC_DEFAULT attribute. In this example, the MODEL is set to \"virtio\", which will be applied to all new NICs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_16\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nNIC_DEFAULT = [ MODEL = \"virtio\" ]\n```\n\n----------------------------------------\n\nTITLE: Federation Configuration in OpenNebula (oned.conf)\nDESCRIPTION: This snippet shows the configuration settings for OpenNebula's federation capabilities within the `oned.conf` file. It defines the `FEDERATION` attribute, which includes the `MODE` of operation (STANDALONE, MASTER, or SLAVE), the `ZONE_ID`, and the `MASTER_ONED` XML-RPC endpoint. These parameters control how the OpenNebula instance interacts within a federated environment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n#*******************************************************************************\n# Federation configuration attributes\n#*******************************************************************************\n\nFEDERATION = [\n    MODE = \"STANDALONE\",\n    ZONE_ID = 0,\n    MASTER_ONED = \"\"\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring Disk Device Mapping in OpenNebula\nDESCRIPTION: This example demonstrates how OpenNebula automatically assigns device names to disks based on image type and order, starting with 'sda' for the OS image and proceeding sequentially. It also demonstrates different ways to select images, including by ID, name, and owner.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_9\n\nLANGUAGE: text\nCODE:\n```\n# First OS image, will be mapped to sda. Use image with ID 2\nDISK = [ IMAGE_ID  = 2 ]\n\n# First DATABLOCK image, mapped to sdb.\n# Use the Image named Data, owned by the user named oneadmin.\nDISK = [ IMAGE        = \"Data\",\n         IMAGE_UNAME  = \"oneadmin\" ]\n\n# Second DATABLOCK image, mapped to sdc\n# Use the Image named Results owned by user with ID 7.\nDISK = [ IMAGE        = \"Results\",\n         IMAGE_UID    = 7 ]\n\n# Third DATABLOCK image, mapped to sdd\n# Use the Image named Experiments owned by user instantiating the VM.\nDISK = [ IMAGE        = \"Experiments\" ]\n\n# Volatile filesystem disk, sde\n```\n\n----------------------------------------\n\nTITLE: Creating Image Datastore Template\nDESCRIPTION: This snippet shows the template parameters required to create an image datastore using the local transfer mode. The template defines the datastore's name, storage driver (DS_MAD), transfer mode (TM_MAD), and conversion settings.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/local_ds.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nNAME   = local_images\nDS_MAD = fs\nTM_MAD = local\n```\n\n----------------------------------------\n\nTITLE: Changing User Authentication Method to LDAP - Bash\nDESCRIPTION: This snippet demonstrates how to change the authentication method of an existing user to LDAP using the oneuser command. It requires the user's ID or name and sets the authentication type to 'ldap'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser chauth <id|name> ldap\n```\n\n----------------------------------------\n\nTITLE: NetApp Image Datastore Template\nDESCRIPTION: This code snippet shows an example template file (netapp_image.ds) used to create an image datastore in OpenNebula for NetApp SAN integration. It defines the datastore's name, type, TM_MAD, disk type, and NetApp specific parameters like host, user, password, SVM, aggregates, and igroup. The `onedatastore create` command is used to create the datastore using the template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/netapp_ds.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ cat netapp_image.ds\nNAME = \"netapp_image\"\nTYPE = \"IMAGE_DS\"\nDISK_TYPE = \"BLOCK\"\nTM_MAD = \"netapp\"\nNETAPP_HOST = \"10.1.234.56\"\nNETAPP_USER = \"admin\"\nNETAPP_PASS = \"password\"\nNETAPP_SVM = \"c9dd74bc-8e3e-47f0-b274-61be0b2ccfe3\"\nNETAPP_AGGREGATES = \"280f5971-3427-4cc6-9237-76c3264543d5\"\nNETAPP_IGROUP = \"27702521-68fb-4d9a-9676-efa3018501fc\"\n\n$ onedatastore create netapp_image.ds\nID: 102\n```\n\n----------------------------------------\n\nTITLE: Updating Address Range in Virtual Network - onevnet Command\nDESCRIPTION: This command updates an existing address range (AR) in a virtual network using `onevnet updatear`. It requires the virtual network name and the AR ID as arguments. An interactive editor session will be started to modify the AR attributes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nonevnet updatear Private 0\n```\n\n----------------------------------------\n\nTITLE: Generating SSH Keys for Monitor Encryption\nDESCRIPTION: This code snippet shows how to generate SSH keys for encryption. The keys are generated without a password to ensure proper automation. These keys are critical for encrypting the monitoring data sent from the hypervisors to the OpenNebula front-end.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# ssh-keygen -f /etc/one/onemonitor\nGenerating public/private rsa key pair.\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /etc/one/onemonitor\nYour public key has been saved in /etc/one/onemonitor.pub\nThe key fingerprint is:\nSHA256:XlFQK35lZ0i2ncAZUbmkKJ8F8ra5uQJA3VGa36OP10I V\n```\n\n----------------------------------------\n\nTITLE: Multiple LDAP Servers Configuration - YAML\nDESCRIPTION: This snippet demonstrates how to configure multiple LDAP servers for group mapping.  Each server has its own mapping file and key, preventing collisions.  The OpenNebula group template defines mappings for each server.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\ninternal:\n    :mapping_file: internal.yaml\n    :mapping_key: INTERNAL_GROUP_DN\n\nexternal:\n    :mapping_file: external.yaml\n    :mapping_key: EXTERNAL_GROUP_DN\n```\n\n----------------------------------------\n\nTITLE: Setting Generic Quota Attributes in OpenNebula\nDESCRIPTION: This code snippet shows how to configure generic quota attributes in OpenNebula. These attributes are used for setting quota limits on Virtual Machine Templates or User Templates. Any numerical attribute can be used for this purpose.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nQUOTA_VM_ATTRIBUTE = \"VCPU\"\nQUOTA_VM_ATTRIBUTE = \"LICENSE\"\n```\n\n----------------------------------------\n\nTITLE: Enabling RDP Connection in VM Template\nDESCRIPTION: This code snippet demonstrates how to enable RDP connections on a specific NIC in a Virtual Machine template. Setting RDP to \"YES\" enables the RDP functionality on that network interface.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_44\n\nLANGUAGE: none\nCODE:\n```\nNIC=[\n    ...\n    RDP = \"YES\"\n]\n```\n\n----------------------------------------\n\nTITLE: Using Template Variables in OpenNebula VM Template\nDESCRIPTION: Illustrates using template variables to dynamically set the IP_GEN and SET_HOSTNAME variables within an OpenNebula VM template.  It uses the $VMID and $NAME template variables to generate these values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_19\n\nLANGUAGE: text\nCODE:\n```\nIP_GEN       = \"10.0.0.$VMID\"\nSET_HOSTNAME = \"$NAME\"\n```\n\n----------------------------------------\n\nTITLE: Updating VM Template using onevm\nDESCRIPTION: This command updates the VM template using the onevm command-line tool. It sets the ROOT_GENERATED_PASSWORD attribute to \"1234\". This is often used to configure or modify VM properties after instantiation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_40\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm update 0\nROOT_GENERATED_PASSWORD=\"1234\"\n```\n\n----------------------------------------\n\nTITLE: Defining a Q-in-Q Network Template (OpenNebula)\nDESCRIPTION: This snippet shows how to define a Q-in-Q network in OpenNebula using a network template. It sets the `VN_MAD` to `802.1Q`, specifies the physical network device (`PHYDEV`), defines the transport VLAN ID (`VLAN_ID`), and sets the customer VLAN ID list (`CVLANS`). The `CVLANS` attribute controls the Q-in-Q behavior.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vlan.rst#_snippet_3\n\nLANGUAGE: Text\nCODE:\n```\nNAME     = \"qinq_net\"\nVN_MAD   = \"802.1Q\"\nPHYDEV   = eth0\nVLAN_ID  = 50                 # Service VLAN ID\nCVLANS   = \"101,103,110-113\"  # Customer VLAN ID list\n```\n\n----------------------------------------\n\nTITLE: Example Requirement Expression for Free CPU\nDESCRIPTION: This example shows how to define scheduling requirements in the VM template to deploy only on resources with more than 60% of free CPU.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_28\n\nLANGUAGE: text\nCODE:\n```\n# Only those resources with more than 60% of free CPU\nSCHED_REQUIREMENTS = \"FREE_CPU > 60\"\n```\n\n----------------------------------------\n\nTITLE: Defining Time-Based Scheduling Policies in OneFlow (JavaScript)\nDESCRIPTION: This JavaScript snippet defines an OneFlow service with time-based scheduling policies. It adjusts the cardinality of the 'frontend' role based on a schedule. The first policy sets the cardinality to 6 from 9:00 to 13:00. The second policy sets it to 10 from 13:00 to 22:30. The third policy sets it to 2 from 22:30 to 09:00 and during the weekend.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_elasticity.rst#_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"name\": \"Time_windows\",\n  \"deployment\": \"none\",\n  \"roles\": [\n    {\n      \"name\": \"frontend\",\n      \"cardinality\": 1,\n      \"vm_template\": 0,\n\n      \"min_vms\" : 1,\n      \"max_vms\" : 15,\n\n      // These policies set the cardinality to:\n      //  6 from  9:00 to 13:00\n      // 10 from 13:00 to 22:30\n      //  2 from 22:30 to 09:00, and the weekend\n\n      \"scheduled_policies\" : [\n        {\n          \"type\" : \"CARDINALITY\",\n          \"recurrence\" : \"0 9 * * mon,tue,wed,thu,fri\",\n          \"adjust\" : 6\n        },\n        {\n          \"type\" : \"CARDINALITY\",\n          \"recurrence\" : \"0 13 * * mon,tue,wed,thu,fri\",\n          \"adjust\" : 10\n        },\n        {\n          \"type\" : \"CARDINALITY\",\n          \"recurrence\" : \"30 22 * * mon,tue,wed,thu,fri\",\n          \"adjust\" : 2\n        }\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Showing OneFlow Service Information\nDESCRIPTION: This code snippet shows the output from the `oneflow show` command, which displays information about a OneFlow service, including the defined elasticity rules and scheduled policies. It also shows the current state of the service and its roles.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_elasticity.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nSERVICE 7 INFORMATION\n...\n\nROLE frontend\nROLE STATE          : SCALING\nCARNIDALITY         : 4\nVM TEMPLATE         : 0\nNODES INFORMATION\n VM_ID NAME                    STAT UCPU    UMEM HOST                       TIME\n     4 frontend_0_(service_7)  runn    0   74.2M host03                 0d 00h04\n     5 frontend_1_(service_7)  runn    0  112.6M host02                 0d 00h04\n     6                         init           0K                        0d 00h00\n     7                         init           0K                        0d 00h00\n\nELASTICITY RULES\nMIN VMS             : 1\nMAX VMS             : 5\n\nADJUST       EXPRESSION                                        EVALUATION PERIOD\n+ 2          (ATT > 50) && !(OTHER_ATT = 5.5 || ABC <= 30)     0 / 3         10s\n- 10 % (2)   ATT < 20                                          0 / 1          0s\n\nADJUST       TIME\n= 6          0 9 * * mon,tue,wed,thu,fri\n= 10         0 13 * * mon,tue,wed,thu,fri\n= 2          30 22 * * mon,tue,wed,thu,fri\n\n\nLOG MESSAGES\n```\n\n----------------------------------------\n\nTITLE: Creating an authentication token in OpenNebula\nDESCRIPTION: This snippet shows how to create an authentication token for a user using the `oneuser token-create` command.  The token is generated and stored in `$HOME/.one/one_auth` (by default).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser token-create\nFile /var/lib/one/.one/one_auth exists, use --force to overwrite.\nAuthentication Token is:\ntestuser:b61010c8ef7a1e815ec2836ea7691e92c4d3f316\n```\n\n----------------------------------------\n\nTITLE: Displaying Host NUMA and Hugepage Information in OpenNebula\nDESCRIPTION: This shows the output from the `onehost show 0` command, presenting the NUMA node and hugepage information as reported by OpenNebula. This includes the number of cores used and free, as well as the total, free, and used hugepages of different sizes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_19\n\nLANGUAGE: Shell\nCODE:\n```\n$ onehost show 0\n...\n\nNUMA NODES\n\n  ID CORES                                              USED FREE\n   0 XX XX -- --                                        4    4\n\nNUMA MEMORY\n\n NODE_ID TOTAL    USED_REAL            USED_ALLOCATED       FREE\n\t 0 7.6G     6.8G                 1024M                845.1M\n\nNUMA HUGEPAGES\n\n NODE_ID SIZE     TOTAL    FREE     USED\n   \t  0 2M       2048     1536     512\n   \t  0 1024M    0        0        0\n...\n```\n\n----------------------------------------\n\nTITLE: Storage Striping Policy RANK Expression\nDESCRIPTION: This RANK expression implements the storage striping policy, which aims to maximize the I/O available to VMs by spreading VMs across system datastores. It prioritizes datastores with more free space. It is used in OpenNebula scheduler for selecting datastores.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/rank_scheduler.rst#_snippet_5\n\nLANGUAGE: OpenNebula\nCODE:\n```\nRANK = \"FREE_MB\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Ceph user for OpenNebula (Luminous)\nDESCRIPTION: This snippet creates a Ceph user named 'libvirt' with the necessary permissions to access the datastore pool on Ceph Luminous (v12.2.x and later). It uses the 'rbd' profile for monitors and 'rbd pool=one' for OSDs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ceph auth get-or-create client.libvirt \\\n      mon 'profile rbd' osd 'profile rbd pool=one'\n```\n\n----------------------------------------\n\nTITLE: Configuring Edge Cluster Hosts\nDESCRIPTION: This snippet demonstrates how to configure or reconfigure the OpenNebula Hosts associated with a provision using the `oneprovision configure` command. It takes a provision ID as input and optionally the `--force` argument for reconfiguration. It offlines the Hosts, triggers the configuration phase, and re-enables them after completion.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/cluster_operations.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision configure 0 -d\nERROR: Hosts are already configured\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision configure 0 -d --force\n2018-11-27 12:43:31 INFO  : Checking working SSH connection\n2018-11-27 12:43:34 INFO  : Configuring hosts\n```\n\n----------------------------------------\n\nTITLE: Matching Users with Regex to LDAP server - YAML\nDESCRIPTION: This snippet configures the regular expressions for matching users with specific LDAP servers. Logins ending with 'a.example.com' will be searched in 'ldap-a.example.com', and the same for users from sub-org 'B'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n:match_user_regex:\n  \"^(.*)@a.example.com$\": ldap-a.example.com\n  \"^(.*)@b.example.com$\": ldap-b.example.com\n```\n\n----------------------------------------\n\nTITLE: Marketplace Configuration File Example - bash\nDESCRIPTION: This example shows the configuration attributes for creating an HTTP marketplace in OpenNebula using a configuration file.  It defines the name, market MAD, base URL, public directory, and bridge list. This file is then used as input to the `onemarket create` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/private_marketplaces/market_http.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nNAME        = PrivateMarket\nMARKET_MAD  = http\nBASE_URL    = \"http://frontend.opennebula.org/\"\nPUBLIC_DIR  = \"/var/local/market-http\"\nBRIDGE_LIST = \"web-server.opennebula.org\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Backup Job Schedules in OpenNebula\nDESCRIPTION: This command lists the schedules associated with a backup job and their respective IDs, which are needed to modify or delete specific schedules.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nonebackupjob show\n```\n\n----------------------------------------\n\nTITLE: Datastore Transfer Manager Configuration - Bash\nDESCRIPTION: This configuration defines the behavior of the datastore transfer manager, including cloning and linking strategies for persistent and non-persistent images, and whether the storage is shared. It is crucial for defining how OpenNebula handles image storage and instantiation. LN_TARGET and CLONE_TARGET determine cloning behavior, SHARED specifies if the storage is shared and ALLOW_ORPHANS dictates if snapshots can exist without parent images.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nTM_MAD_CONF = [\n        NAME          = \"lvm\",\n        LN_TARGET     = \"NONE\",\n        CLONE_TARGET  = \"SELF\",\n        SHARED        = \"yes\",\n        ALLOW_ORPHANS = \"no\"\n    ]\n```\n\n----------------------------------------\n\nTITLE: Configuring SSH Authentication in oned.conf\nDESCRIPTION: This snippet shows how to enable SSH authentication in the OpenNebula configuration file (oned.conf) by ensuring 'ssh' is included in the AUTH_MAD section. This configuration allows OpenNebula to use SSH keys for user authentication via the CLI.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ssh.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nAUTH_MAD = [\n    EXECUTABLE = \"one_auth_mad\",\n    AUTHN = \"ssh,x509,ldap,server_cipher,server_x509\"\n]\n```\n\n----------------------------------------\n\nTITLE: Define OpenNebula Virtual Machine Resource Terraform\nDESCRIPTION: This snippet demonstrates how to define a new OpenNebula virtual machine resource within a Terraform configuration file. It represents a basic structure for creating and managing virtual machines in OpenNebula using the Terraform provider. The ellipsis (...) indicates that the resource definition requires further configuration details.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/automation_tools_integration/terraform.rst#_snippet_0\n\nLANGUAGE: terraform\nCODE:\n```\n# Define a new datablockimage\nresource \"opennebula_virtual_machine\" \"myfirstvm-tf\" {\n    ...\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling SSH Connection in VM Template\nDESCRIPTION: This code shows how to enable SSH connections on a specific NIC within a Virtual Machine template. Setting SSH to \"YES\" enables SSH functionality on that network interface.  The default SSH port 22 is used unless SSH_PORT is set in the context section.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_45\n\nLANGUAGE: none\nCODE:\n```\nNIC=[\n    ...\n    SSH = \"YES\"\n]\n```\n\n----------------------------------------\n\nTITLE: Creating System Datastore using CLI\nDESCRIPTION: This snippet showcases the command to create a System Datastore in OpenNebula using the onedatastore command-line tool and the systemds.txt configuration file. It assumes the systemds.txt file exists and contains the necessary configuration parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_13\n\nLANGUAGE: text\nCODE:\n```\n$ onedatastore create systemds.txt\nID: 101\n```\n\n----------------------------------------\n\nTITLE: Configuring Interface Creation Options in OpenNebula\nDESCRIPTION: This snippet demonstrates how to configure interface creation options like vxlan multicast address, bridge settings, and IP link parameters within an OpenNebula VNET template. It showcases the use of CONF, BRIDGE_CONF, OVS_BRIDGE_CONF, and IP_LINK_CONF attributes for specifying driver configurations, bridge creation parameters, and link settings.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/vnet_template.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nCONF=\"vxlan_mc=239.0.100.0,test=false,validate_vlan_id=true\"\nBRIDGE_CONF=\"sethello=6\"\nOVS_BRIDGE_CONF=\"stp_enable=true\"\nIP_LINK_CONF=\"tos=10,udpcsum=,udp6zerocsumrx=__delete__\"\n```\n\n----------------------------------------\n\nTITLE: Defining Network Values for Service Template - Static VNet\nDESCRIPTION: This code snippet shows how to define network values in a Service Template to use an existing Virtual Network (VNet) by specifying its ID.  The \"networks_values\" array contains a dictionary where the key is the name of the network (e.g., \"Public\") and the value is a dictionary containing the VNet's ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_14\n\nLANGUAGE: json\nCODE:\n```\n{\n  ...\n  \"networks_values\": [\n    { \"Public\": { \"id\": \"<vnet_id>\" }\n  }\n  ]\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Migrating SQLite to MySQL\nDESCRIPTION: The 'onedb sqlite2mysql' command facilitates migration from an SQLite database to a MySQL database.  It requires OpenNebula to be stopped, the database configured in /etc/one/oned.conf, MySQL database bootstrapped with ``oned -i``, and then the migration performed with the command, followed by restarting OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_17\n\nLANGUAGE: text\nCODE:\n```\nonedb sqlite2mysql -s <SQLITE_PATH> -u <MYSQL_USER> -p <MYSQL_PASS> -d <MYSQL_DB>\n```\n\n----------------------------------------\n\nTITLE: Retrieve OpenNebula Exporter Metrics\nDESCRIPTION: Uses `curl` to retrieve metrics from the `opennebula-exporter` running on localhost port 9925.  The output shows the metrics being exposed by the exporter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ curl http://localhost:9925/metrics\n# TYPE opennebula_host_total gauge\n# HELP opennebula_host_total Total number of hosts defined in OpenNebula\nopennebula_host_total 2.0\n# TYPE opennebula_host_state gauge\n# HELP opennebula_host_state Host state 0:init 2:monitored 3:error 4:disabled 8:offline\nopennebula_host_state{one_host_id=\"1\"} 2.0\nopennebula_host_state{one_host_id=\"0\"} 2.0\n```\n\n----------------------------------------\n\nTITLE: MySQL Configuration in OpenNebula\nDESCRIPTION: This snippet shows the configuration parameters for connecting OpenNebula to a MySQL/MariaDB database. Key parameters include the server address, port, username, password, database name, number of connections and string comparison method. Replace <thepassword> with the correct password.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/database.rst#_snippet_3\n\nLANGUAGE: none\nCODE:\n```\n# Sample configuration for MySQL\nDB = [ BACKEND = \"mysql\",\n           SERVER  = \"localhost\",\n           PORT    = 0,\n           USER    = \"oneadmin\",\n           PASSWD  = \"<thepassword>\",\n           DB_NAME = \"opennebula\",\n           CONNECTIONS = 25,\n           COMPARE_BINARY = \"no\" ]\n```\n\n----------------------------------------\n\nTITLE: Deleting VM Attribute with OneGate (bash)\nDESCRIPTION: This command shows how to erase an attribute from a Virtual Machine's template using the `onegate vm update --erase` command. For example, deleting the `ACTIVE` attribute.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ onegate vm update 9 --erase ACTIVE\n$ onegate vm show 9 --json\n{\n  \"VM\": {\n    \"NAME\": \"slave_0_(service_1)\",\n    \"ID\": \"9\",\n    \"STATE\": \"3\",\n    \"LCM_STATE\": \"3\",\n    \"USER_TEMPLATE\": {\n      \"FROM_APP\": \"4fc76a938fb81d3517000003\",\n      \"FROM_APP_NAME\": \"ttylinux - kvm\",\n      \"LOGO\": \"images/logos/linux.png\",\n      \"ROLE_NAME\": \"slave\",\n      \"SERVICE_ID\": \"1\"\n    },\n    \"TEMPLATE\": {\n      \"NIC\": [\n\n       ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Container Template Example\nDESCRIPTION: This snippet provides an example of an OpenNebula container template used for defining LXC containers. It includes attributes for CPU, memory, context, disk image, graphics settings, and network interface configuration. The template demonstrates the basic settings required to configure a container within OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_driver.rst#_snippet_2\n\nLANGUAGE: none\nCODE:\n```\nCPU=\"1\"\nMEMORY=\"146\"\nCONTEXT=[\n  NETWORK=\"YES\",\n  SSH_PUBLIC_KEY=\"$USER[SSH_PUBLIC_KEY]\" ]\nDISK=[\n  IMAGE=\"Alpine Linux 3.11\",\n  IMAGE_UNAME=\"oneadmin\" ]\nGRAPHICS=[\n  LISTEN=\"0.0.0.0\",\n  TYPE=\"VNC\" ]\nNIC=[\n  NETWORK=\"vnet\",\n  NETWORK_UNAME=\"oneadmin\",\n  SECURITY_GROUPS=\"0\" ]\n```\n\n----------------------------------------\n\nTITLE: Applying a VM Group to a Template\nDESCRIPTION: This snippet shows how to apply a VM Group to a VM Template using the `onetemplate update` command. It sets the `VMGROUP` attribute with the `VMGROUP_NAME` and `ROLE` to associate a VM with a specific role within a VM Group. This allows VMs created from the template to inherit the VM Group's placement policies.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/affinity.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onetemplate update 0\n...\nVMGROUP = [ VMGROUP_NAME = \"muilt-tier app\", ROLE = \"db\" ]\n```\n\n----------------------------------------\n\nTITLE: LDAP Group Mapping File Example - YAML\nDESCRIPTION: This snippet shows an example of an LDAP group mapping file in YAML format. The file maps LDAP group DNs to OpenNebula group IDs. This allows users belonging to specific LDAP groups to automatically be added to corresponding OpenNebula groups.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nCN=technicians,CN=Groups,DC=example,DC=com: '100'\nCN=Domain Admins,CN=Users,DC=example,DC=com: '101'\n```\n\n----------------------------------------\n\nTITLE: Systemd Service for VFIO Binding\nDESCRIPTION: This systemd service executes the vfio-bind script at boot time. It binds the specified PCI devices to the VFIO driver. This ensures that the devices are available for use by virtual machines.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n[Unit]\nDescription=Binds devices to vfio-pci\nAfter=syslog.target\n\n[Service]\nEnvironmentFile=-/etc/sysconfig/vfio-bind\nType=oneshot\nRemainAfterExit=yes\nExecStart=-/usr/local/bin/vfio-bind $DEVICES\n\n[Install]\nWantedBy=multi-user.target\n```\n\n----------------------------------------\n\nTITLE: Defining Metric-Based Elasticity Policies\nDESCRIPTION: This code snippet shows how to define elasticity policies based on metrics.  The `expression` defines the condition that triggers scaling, `type` specifies the adjustment type (CHANGE, CARDINALITY, PERCENTAGE_CHANGE), and `adjust` specifies the adjustment value.  `period_number` and `period` define the evaluation window.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_elasticity.rst#_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n      \"elasticity_policies\" : [\n        {\n          \"expression\" : \"ATT > 50\",\n          \"type\" : \"CHANGE\",\n          \"adjust\" : 2,\n\n          \"period_number\" : 3,\n          \"period\" : 10\n        },\n        ...\n      ]\n```\n\n----------------------------------------\n\nTITLE: Creating Datastore via CLI\nDESCRIPTION: This shows how to create a datastore from the previously defined template file 'iscsi.ds' using the OpenNebula command-line interface. It assumes the 'iscsi.ds' file is correctly configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/iscsi_ds.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n> onedatastore create iscsi.ds\nID: 101\n```\n\n----------------------------------------\n\nTITLE: Listing Block Devices\nDESCRIPTION: This command lists the block devices attached to the backup server, including disks, partitions, and logical volumes. It's used to identify the storage volume dedicated for backups, in this case, a logical volume mounted at /var/lib/one/datastores.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/restic.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nlsblk\n```\n\n----------------------------------------\n\nTITLE: Setting the Scheduler Window in OpenNebula\nDESCRIPTION: This configuration defines the scheduling window parameters. `SCHED_MAX_WND_TIME` sets the maximum time the window remains open. `SCHED_MAX_WND_LENGTH` sets the maximum number of pending VMs before processing the requests. When either condition is met, the scheduler processes accumulated VM placement requests.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/configuration.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSCHED_MAX_WND_TIME   = 10\nSCHED_MAX_WND_LENGTH = 7\n```\n\n----------------------------------------\n\nTITLE: Creating an Image Datastore with onedatastore command\nDESCRIPTION: This example demonstrates how to create an image datastore using the onedatastore command and the configuration file ds.conf. The command outputs the ID of the newly created datastore.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/lvm_drivers.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore create ds.conf\n```\n\n----------------------------------------\n\nTITLE: Displaying Virtual Machine Information - OpenNebula CLI\nDESCRIPTION: This example demonstrates how to display basic information about a VM using the `onevm show` command. It retrieves details such as ID, name, user, group, state, and other relevant attributes. The command requires the VM ID as input.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n$ onevm show 0\nVIRTUAL MACHINE 0 INFORMATION\nID                  : 0\nNAME                : my_vm\nUSER                : oneadmin\nGROUP               : oneadmin\nSTATE               : ACTIVE\nLCM_STATE           : RUNNING\nSTART TIME          : 04/14 09:00:24\nEND TIME            : -\nDEPLOY ID:          : one-0\n\nPERMISSIONS\nOWNER          : um-\nGROUP          : ---\nOTHER          : ---\n\nVIRTUAL MACHINE MONITORING\nNET_TX              : 13.05\nNET_RX              : 0\nUSED MEMORY         : 512\nUSED CPU            : 0\n\nVIRTUAL MACHINE TEMPLATE\n...\n\nVIRTUAL MACHINE HISTORY\n SEQ        HOSTNAME REASON           START        TIME       PTIME\n   0         testbed   none  09/28 06:48:18 00 00:07:23 00 00:00:00\n```\n\n----------------------------------------\n\nTITLE: Scheduling a VM Action - OpenNebula\nDESCRIPTION: This command schedules an action (e.g., suspend, resume) to be performed on a VM at a specified date and time using the `--schedule` option.  The time can be specified in a date string.  The `onevm show` command displays the scheduled actions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_26\n\nLANGUAGE: shell\nCODE:\n```\n$ onevm suspend 0 --schedule \"09/20\"\nVM 0: suspend scheduled at 2016-09-20 00:00:00 +0200\n\n$ onevm resume 0 --schedule \"09/23 14:15\"\nVM 0: resume scheduled at 2016-09-23 14:15:00 +0200\n\n$ onevm show 0\nVIRTUAL MACHINE 0 INFORMATION\nID                  : 0\nNAME                : one-0\n\n[...]\n\nSCHEDULED ACTIONS\nID    ACTION  ARGS   SCHEDULED REPEAT   END STATUS\n 0   suspend     - 09/20 00:00              Next in 12.08 days\n 1    resume     - 09/23 14:15              Next in 15.67 days\n```\n\n----------------------------------------\n\nTITLE: Use Global Wait Parameters with OneProvision CLI\nDESCRIPTION: This snippet shows how to use the `--wait-ready` and `--wait-timeout` parameters with the `oneprovision create` command. This configures the tool to wait for resources to be ready with a specified timeout, overriding global defaults but not overwriting values set in the template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision create virtual.yaml --wait-ready --wait-timeout 60\n```\n\n----------------------------------------\n\nTITLE: Backup OpenNebula Database (Shell)\nDESCRIPTION: This command backs up the OpenNebula database. It requires specifying the database host, user, password, database name, and port. Replace <database_host>, <user>, <password>, <database_name>, and <port> with the actual values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/replace_failing_fe.rst#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nonedb backup -S <database_host> -u <user> -p <password> -d <database_name> -P <port>\n```\n\n----------------------------------------\n\nTITLE: VM Configuration Attributes (text)\nDESCRIPTION: This code snippet defines the full list of configuration attributes for KVM VMs within OpenNebula. These attributes are categorized into different sections such as OS, FEATURES, INPUT, GRAPHICS, VIDEO, RAW, CPU_MODEL, BACKUP_CONFIG, and CONTEXT.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nOS        = [\"ARCH\", \"MACHINE\", \"KERNEL\", \"INITRD\", \"BOOTLOADER\", \"BOOT\", \"KERNEL_CMD\", \"ROOT\", \"SD_DISK_BUS\", \"UUID\", \"FIRMWARE\"]\nFEATURES  = [\"ACPI\", \"PAE\", \"APIC\", \"LOCALTIME\", \"HYPERV\", \"GUEST_AGENT\", \"VIRTIO_SCSI_QUEUES\", \"VIRTIO_BLK_QUEUES\", \"IOTHREADS\"]\nINPUT     = [\"TYPE\", \"BUS\"]\nGRAPHICS  = [\"TYPE\", \"LISTEN\", \"PASSWD\", \"KEYMAP\", \"COMMAND\" ]\nVIDEO     = [\"TYPE\", \"IOMMU\", \"ATS\", \"VRAM\", \"RESOLUTION\"]\nRAW       = [\"DATA\", \"DATA_VMX\", \"TYPE\", \"VALIDATE\"]\nCPU_MODEL = [\"MODEL\", \"FEATURES\"]\nBACKUP_CONFIG = [\"FS_FREEZE\", \"KEEP_LAST\", \"BACKUP_VOLATILE\", \"MODE\", \"INCREMENT_MODE\"]\nCONTEXT (any value, except ETH*, **variable substitution will be made**)\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Images\nDESCRIPTION: This command lists the OpenNebula images in the system.  It displays information such as ID, user, group, name, datastore, size, type, persistent flag, status, and number of VMs using the image. It requires the OpenNebula CLI tool `oneimage`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\noneimage list\n```\n\n----------------------------------------\n\nTITLE: Creating Open vSwitch Bridge and Bond Port\nDESCRIPTION: This snippet creates an Open vSwitch bridge with netdev datapath type and adds a bond port with two network cards configured for DPDK.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# ovs-vsctl add-br onebr.dpdk -- set bridge onebr.dpdk datapath_type=netdev\n\n# ovs-vsctl add-bond onebr.dpdk bond1 x710_1 x710_83 \\\n    -- set Interface x710_1 type=dpdk options:dpdk-devargs=0000:01:00.1 \\\n    -- set Interface x710_83 type=dpdk options:dpdk-devargs=0000:83:00.1\n\n# ovs-vsctl show\nÂ Â Â Bridge onebr.dpdk\nÂ Â Â Â Â Â Â Â datapath_type: netdev\nÂ Â Â Â Â Â Â Â Port onebr.dpdk\nÂ Â Â Â Â Â Â Â Â Â Â Interface onebr.dpdk\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â type: internal\nÂ Â Â Â Â Â Â Â Port bond1\nÂ Â Â Â Â Â Â Â Â Â Â Interface x710_83\n```\n\n----------------------------------------\n\nTITLE: Updating Address Range with Security Groups\nDESCRIPTION: This snippet shows how to update an Address Range of a Virtual Network with Security Groups using the `onevnet updatear` command. Similar to the Virtual Network update, it applies Security Groups to a specific Address Range within the network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/security_groups.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onevnet updatear 0 1\n\nSECURITY_GROUPS = \"100, 102, 110\"\n```\n\n----------------------------------------\n\nTITLE: Setting Multicast Group Limit via sysctl (Bash)\nDESCRIPTION: This snippet shows how to permanently increase the number of multicast groups a host can be a member of by modifying the `/etc/sysctl.conf` file and reloading the configuration. This setting affects the number of concurrent VXLANs that can be used on a host. Modifying this parameter will avoid hitting the default limit of 20 multicast groups.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vxlan.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnet.ipv4.igmp_max_memberships=150\n```\n\n----------------------------------------\n\nTITLE: Instantiating Service Template with curl\nDESCRIPTION: This curl command instantiates a service template with ID 4 using the OpenNebula API. It uses the POST method to send a request to the /service_template/4/action endpoint with the 'instantiate' action specified in the JSON payload. Authentication is performed using basic authentication with 'oneadmin:password'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service_template/4/action -u 'oneadmin:password' -v -X POST --data '{\n  \"action\": {\n    \"perform\":\"instantiate\"\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Delegate cgroup controllers to oneadmin user (bash)\nDESCRIPTION: This snippet shows how to delegate CPU and IO cgroup controllers to the `oneadmin` user in OpenNebula. This allows OpenNebula to set CPUQuota, IOReadIOPSMax, and IOWriteIOPSMax for backup processes.  It involves creating a `delegate.conf` file in the `user@9869.service.d` directory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/io_limit.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncat /etc/systemd/system/user@9869.service.d/delegate.conf\n[Service]\nDelegate=cpu cpuset io\n```\n\n----------------------------------------\n\nTITLE: Taking a Host Offline in OpenNebula (onehost)\nDESCRIPTION: This snippet demonstrates how to take a host offline in OpenNebula using the `onehost offline` command. Taking a host offline prevents new VM deployments and also stops monitoring of the host. The host is specified by its ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost offline 0\n```\n\n----------------------------------------\n\nTITLE: Defining Guest Configuration Attributes\nDESCRIPTION: This snippet shows how to define guest configuration attributes, such as DNS server and gateway, for the virtual machines in the virtual network. These attributes will be injected into the VM at boot time.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_2\n\nLANGUAGE: none\nCODE:\n```\nDNS = \"10.0.0.23\"\nGATEWAY = \"10.0.0.1\"\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Self-Contained OpenNebula Installation\nDESCRIPTION: This example shows how to set the `ONE_LOCATION` and `PATH` environment variables when OpenNebula is installed from sources in self-contained mode. `ONE_LOCATION` points to the installation directory, and `PATH` is updated to include the OpenNebula binaries, allowing the system to find and execute the OpenNebula commands.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/cli.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nexport PATH=$ONE_LOCATION/bin:$PATH\n```\n\n----------------------------------------\n\nTITLE: Defining Scalability Elasticity Policies in OneFlow (JavaScript)\nDESCRIPTION: This JavaScript snippet defines an OneFlow service with scalability elasticity policies. It configures automatic scaling based on the 'ATT' value of the VMs. The first policy adds 2 VMs when 'ATT > 50' is true for 3 consecutive periods of 10 seconds each. The second policy reduces the number of VMs by -10% (minimum reduction of 2 VMs) when 'ATT < 20' is true.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_elasticity.rst#_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"name\": \"Scalability1\",\n  \"deployment\": \"none\",\n  \"roles\": [\n    {\n      \"name\": \"frontend\",\n      \"cardinality\": 2,\n      \"vm_template\": 0,\n\n      \"min_vms\" : 1,\n      \"max_vms\" : 5,\n\n      \"elasticity_policies\" : [\n        {\n          // +2 VMs when the exp. is true for 3 times in a row,\n          // separated by 10 seconds\n          \"expression\" : \"ATT > 50\",\n\n          \"type\" : \"CHANGE\",\n          \"adjust\" : 2,\n\n          \"period_number\" : 3,\n          \"period\" : 10\n        },\n        {\n          // -10 percent VMs when the exp. is true.\n          // If 10 percent is less than 2, -2 VMs.\n          \"expression\" : \"ATT < 20\",\n\n          \"type\" : \"PERCENTAGE_CHANGE\",\n          \"adjust\" : -10,\n          \"min_adjust_step\" : 2\n        }\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Adding a Host to a Cluster with onecluster\nDESCRIPTION: This snippet adds Host 'host01' to the 'production' cluster using the `onecluster addhost` command.  It demonstrates how to associate a host with a specific cluster. The command requires the cluster name and the host name or ID as parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster addhost production host01\n```\n\n----------------------------------------\n\nTITLE: Testing Ceph client configuration\nDESCRIPTION: This snippet demonstrates how to test the Ceph client configuration on the OpenNebula node as the oneadmin user by listing the contents of the 'one' pool with the 'libvirt' user.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh oneadmin@node\n\n$ rbd ls -p one --id libvirt\n```\n\n----------------------------------------\n\nTITLE: Example Context Section in OpenNebula VM Template\nDESCRIPTION: Provides an example of a CONTEXT section in an OpenNebula VM template, showcasing the use of hardcoded values, template variables, network template variables, and file datastore variables.  It sets various parameters like hostname, IP address, DNS, files, and the target disk.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_25\n\nLANGUAGE: text\nCODE:\n```\nCONTEXT = [\n  SET_HOSTNAME = \"MAINHOST\",\n  IP_PRIVATE   = \"$NIC[IP]\",\n  DNS          = \"$NETWORK[DNS, NAME=\\\"Public\\\"]\",\n  IP_GEN       = \"10.0.0.$VMID\",\n  FILES        = \"/service/init.sh /service/certificates /service/service.conf\",\n  FILES_DS     = \"$FILE[IMAGE_ID=34] $FILE[IMAGE=\\\"kernel\\\"]\",\n  TARGET       = \"sdc\"\n]\n```\n\n----------------------------------------\n\nTITLE: VM Template Example with Restricted Attributes\nDESCRIPTION: This snippet shows an example VM template. Users can create or update a template customizing anything except the CPU, VCPU and NIC because those attributes are listed in VM_RESTRICTED_ATTR.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_18\n\nLANGUAGE: none\nCODE:\n```\nCPU     = \"1\"\nVCPU    = \"1\"\nMEMORY  = \"512\"\nDISK=[\n  IMAGE = \"BaseOS\" ]\nNIC=[\n  NETWORK_ID = \"0\" ]\n```\n\n----------------------------------------\n\nTITLE: Unpacked Marketplace App Template Format\nDESCRIPTION: This snippet shows the OpenNebula syntax format for an unpacked Marketplace App template. It includes fields such as NAME, SOURCE, IMPORT_ID, ORIGIN_ID, TYPE, PUBLISHER, FORMAT, DESCRIPTION, VERSION, TAGS, SIZE, MD5, and VMTEMPLATE64, which are essential for defining the app's properties.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-market.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nNAME=\"ttylinux - kvm\"\nSOURCE=\"http://marketplace.opennebula.systems//appliance/4fc76a938fb81d3517000003/download/0\"\nIMPORT_ID=\"4fc76a938fb81d3517000003\"\nORIGIN_ID=\"-1\"\nTYPE=\"IMAGE\"\nPUBLISHER=\"OpenNebula.org\"\nFORMAT=\"raw\"\nDESCRIPTION=\"This is a very small image that works with OpenNebula. It's already contextualized. The purpose of this image is to test OpenNebula deployments, without wasting network bandwith thanks to the tiny footprint of this image\n(40MB).\"\nVERSION=\"1.0\"\nTAGS=\"linux, ttylinux,  4.8,  4.10\"\nSIZE=\"40\"\nMD5=\"04c7d00e88fa66d9aaa34d9cf8ad6aaa\"\nVMTEMPLATE64=\"Q09OVEVYVCA9IFsgTkVUV09SSyAgPSJZRVMiLFNTSF9QVUJMSUNfS0VZICA9IiRVU0VSW1NTSF9QVUJMSUNfS0VZXSJdCgpDUFUgPSAiMC4xIgpHUkFQSElDUyA9IFsgTElTVEVOICA9IjAuMC4wLjAiLFRZUEUgID0idm5jIl0KCk1FTU9SWSA9ICIxMjgiCkxPR08gPSAiaW1hZ2VzL2xvZ29zL2xpbnV4LnBuZyI=\"\n```\n\n----------------------------------------\n\nTITLE: Scale Service Role via OneGate API\nDESCRIPTION: This curl command scales the cardinality of a specific role within a service using the OneGate API. It requires the X-ONEGATE-TOKEN and X-ONEGATE-VMID headers, and the payload specifies the role name, desired cardinality, and a force flag.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X \"PUT\" \"${ONEGATE_ENDPOINT}/service/0/scale\" \\\n    --header \"X-ONEGATE-TOKEN: `cat token.txt`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\" \\\n    -d \"{'role_name': 'worker', 'cardinality' : 10, 'force': false}\"\n```\n\n----------------------------------------\n\nTITLE: Defining Generic VM Quota - Bash\nDESCRIPTION: This example demonstrates defining a Quality of Service (QoS) category for a VM template using the `GOLD_QOS` attribute.  A quota can then be enforced to limit the number of VMs within the `GOLD_QOS` category.  The attribute is added to the Virtual Machine Template. Requires OpenNebula configuration with QUOTA_VM_ATTRIBUTE defined.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/quotas.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nCPU    = 12\nMEMORY = 4096\n\n...\n\nGOLD_QOS = 1\n```\n\n----------------------------------------\n\nTITLE: Changing User Authentication to X.509 Using DN\nDESCRIPTION: This command demonstrates how to change an existing user's authentication method to X.509 using the user's certificate subject DN. The command requires the user's ID or name and the user's DN. The specified DN is used as the password for authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\noneuser chauth <id|name> x509 --x509 \"user_subject_DN\"\n```\n\n----------------------------------------\n\nTITLE: Defining a Swap Disk in OpenNebula\nDESCRIPTION: This snippet defines a virtual disk to be used as swap space within the virtual machine. It specifies the type as swap and the size as 1024 MB.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_11\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nDISK = [ TYPE     = swap,\n             SIZE     = 1024 ]\n```\n\n----------------------------------------\n\nTITLE: Verifying vhost Interface Configuration (XML)\nDESCRIPTION: This XML snippet shows how to verify that the VM is using the vhost interface by inspecting the domain definition. It confirms the 'vhostuser' interface type and the path to the unix socket used for communication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n<domain type='kvm' id='417'>\n  <name>one-10</name>\n  ...\n  <devices>\n    ...\n    <interface type='vhostuser'>\n      <mac address='02:00:c0:a8:7a:02'/>\n      <source type='unix' path='/var/lib/one//datastores/0/10/one-10-0' mode='server'/>\n      <target dev=''/>\n      <model type='virtio'/>\n      <alias name='net0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>\n    </interface>\n  ...\n</devices>\n</domain>\n```\n\n----------------------------------------\n\nTITLE: Creating a System Datastore Configuration\nDESCRIPTION: This snippet demonstrates the configuration file (systemds.txt) for creating a System Datastore in OpenNebula using the Ceph storage backend. It includes attributes like TM_MAD, TYPE, DISK_TYPE, POOL_NAME, CEPH_HOST, CEPH_USER, CEPH_SECRET, and BRIDGE_LIST. This Datastore is designed to hold volatile disks.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_12\n\nLANGUAGE: text\nCODE:\n```\nNAME    = ceph_system\nTM_MAD  = ceph\nTYPE    = SYSTEM_DS\nDISK_TYPE = RBD\n\nPOOL_NAME   = one\nCEPH_HOST   = \"host1 host2:port2\"\nCEPH_USER   = libvirt\nCEPH_SECRET = \"6f88b54b-5dae-41fe-a43e-b2763f601cfc\"\n\nBRIDGE_LIST = cephfrontend\n```\n\n----------------------------------------\n\nTITLE: Setting Federation Mode to Slave Bash\nDESCRIPTION: This configuration sets the OpenNebula instance to operate in slave mode within a federation.  It defines the mode as SLAVE, sets the ZONE_ID (obtained from the master), and specifies the URL of the master's OpenNebula endpoint. Requires restart of OpenNebula after configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nFEDERATION = [\n    MODE        = \"SLAVE\",\n    ZONE_ID     = 100,\n    MASTER_ONED = \"http://<master-ip>:2633/RPC2\"\n]\n```\n\n----------------------------------------\n\nTITLE: Instantiate Virtual Router using onevrouter instantiate\nDESCRIPTION: Instantiates a Virtual Machine for the virtual router based on a given vrouter ID and a VM template ID. This command starts the Virtual Router appliance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vrouter.rst#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ onevrouter instantiate <vrouterid> <templateid>\n```\n\n----------------------------------------\n\nTITLE: Stop OpenNebula Services (Shell)\nDESCRIPTION: This command stops all OpenNebula services on the failing frontend. This prevents any further operations from being performed on the node during the replacement process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/replace_failing_fe.rst#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nsystemctl stop opennebula*\n```\n\n----------------------------------------\n\nTITLE: Create On-Premises Edge Cluster\nDESCRIPTION: This command creates an On-Premises Edge Cluster using the `oneprovision` tool. It reads the configuration from a YAML file and prompts for various input parameters. Requires the OpenNebula CLI tools and the edge-clusters configuration files.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision create -Dd --provider onprem /usr/share/one/oneprovision/edge-clusters/metal/provisions/onprem-hci.yml\n  2022-05-05 09:01:08 DEBUG : Executing command: `create`\n  2022-05-05 09:01:08 DEBUG : Command options: debug [verbose, true] [provider, onprem] [sync, true]\n  ID: 2\n\n  Virtualization technology for the cluster hosts\n\n      -  kvm\n      -  lxc\n\n  Please select the option (default=): kvm\n\n  Physical device to be used for private networking.\n  Text `private_phydev` (default=): eth1\n\n  Hosts to run hypervisor, osd and mon ceph daemons (semicolon list of FQDNs or IPs)\n  Array `ceph_full_hosts_names` (default=): host01;host02;host03\n\n  Hosts to run hypervisor and osd daemons (semicolon list of FQDNs or IPs)\n  Array `ceph_osd_hosts_names` (default=):\n\n  Hosts to run hypervisor and ceph client (semicolon list of FQDNs or IPs)\n  Array `client_hosts_names` (default=):\n\n  Physical device to be used for public networking.\n  Text `public_phydev` (default=): eth0\n\n  First public IP for the public IPs address range.\n  Text `first_public_ip` (default=): 172.20.0.51\n\n  Number of public IPs to get\n  Text `number_public_ips` (default=1): 5\n\n  Block devices for Ceph OSD (semicolon separated list)\n  Array `ceph_device` (default=/dev/sdb): /dev/sdb\n\n  Physical device to be used for Ceph.\n  Text `ceph_monitor_interface` (default=eth0): eth1\n\n  Ceph public network in CIDR notation\n  Text `ceph_public_network` (default=):\n  ...\n  Provision successfully created\n  ID: 4\n```\n\n----------------------------------------\n\nTITLE: Sending Metrics to OpenNebula Endpoint (Bash)\nDESCRIPTION: This snippet retrieves the VMID from `/mnt/context.sh`, then uses `curl` to send the collected metrics to the OpenNebula monitoring endpoint specified by the ONEGATE_ENDPOINT environment variable. The X-ONEGATE-TOKEN header is set using the content of the file pointed to by the ONEGATE_TOKEN environment variable, and the X-ONEGATE-VMID header is set to the VMID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nVMID=$(source /mnt/context.sh; echo $VMID)\n\ncurl -X \"PUT\" $ONEGATE_ENDPOINT/vm \\\n    --header \"X-ONEGATE-TOKEN: `cat $ONEGATE_TOKEN`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\" \\\n    --data-binary @$TMP_DIR/metrics\n```\n\n----------------------------------------\n\nTITLE: Shutdown Timeout Configuration (bash)\nDESCRIPTION: This code snippet shows how to configure the shutdown timeout for KVM VMs. The `SHUTDOWN_TIMEOUT` variable sets the number of seconds to wait before considering a VM shutdown to be stuck.  `FORCE_DESTROY` can be enabled to destroy the VM after the timeout. These settings are configured in `/var/lib/one/etc/remotes/vmm/kvm/kvmrc`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Seconds to wait after shutdown until timeout\nexport SHUTDOWN_TIMEOUT=180\n\n# Uncomment this line to force VM cancellation after shutdown timeout\nexport FORCE_DESTROY=yes\n```\n\n----------------------------------------\n\nTITLE: Listing Datastore Directory Permissions\nDESCRIPTION: This command lists the permissions and ownership of the /var/lib/one/datastores directory. It verifies that the 'oneadmin' user has the correct ownership and permissions to access and modify the directory, which is crucial for Restic to store backups.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/restic.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nls -ld /var/lib/one/datastores/\n```\n\n----------------------------------------\n\nTITLE: Registering Image in OpenNebula (LUKS)\nDESCRIPTION: Registers a LUKS-encrypted image in OpenNebula using `oneimage create`.  It specifies the name, path, datastore, prefix, and persistence setting for the image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage create --name luks-image --path /tmp/luks.vol -d default --prefix vd --persistent\n```\n\n----------------------------------------\n\nTITLE: Detaching Disk from VM - OpenNebula CLI\nDESCRIPTION: This snippet demonstrates how to detach a disk from a running VM using the `onevm disk-detach` command. It first retrieves the disk ID using `onevm show`, then detaches the disk using `onevm disk-detach vm_id disk_id`. The example detaches disk ID '1' from VM 'one-5'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_10\n\nLANGUAGE: text\nCODE:\n```\n$ onevm show one-5\n...\nDISK=[\n  DISK_ID=\"1\",\n...\n]\n...\n\n$ onevm disk-detach one-5 1\n```\n\n----------------------------------------\n\nTITLE: Adding IP Addresses to Elastic Networks with oneprovision\nDESCRIPTION: This command demonstrates how to add IP addresses to an existing elastic network using the `oneprovision ip add` command. It requests a new IP from the remote provider. The `provision ID` is mandatory, and `--amount` specifies the number of IPs to add (defaulting to 1 if not specified).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/cluster_operations.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision ip add 0\n```\n\n----------------------------------------\n\nTITLE: Enabling a Host in OpenNebula (onehost)\nDESCRIPTION: This snippet shows how to enable a previously disabled host in OpenNebula using the `onehost enable` command. Enabling a host allows new VM deployments to it. The host is specified by its ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost enable 0\n```\n\n----------------------------------------\n\nTITLE: Virtio Block Queues Configuration\nDESCRIPTION: This snippet shows how to configure the number of virtio-blk queues for a DISK. Setting `VIRTIO_BLK_QUEUES` to `auto` configures the number of queues to the number of vCPUs.  This allows for simultaneous management of distinct queues by various vCPUs, improving I/O performance. It's important to consider the underlying hardware queue depth when fine-tuning this configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nFEATURES = [\n    VIRTIO_BLK_QUEUES = \"auto\"\n]\n```\n\n----------------------------------------\n\nTITLE: Accessing Attribute with Condition in OpenNebula VM Template\nDESCRIPTION: Demonstrates how to access an attribute (IP) within a multiple-value variable (NIC) and filter based on another attribute (NETWORK) with a specific value (\"Public\") in an OpenNebula VM template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_21\n\nLANGUAGE: text\nCODE:\n```\nIP_PUBLIC = \"$NIC[IP, NETWORK=\\\"Public\\\"]\"\n```\n\n----------------------------------------\n\nTITLE: Updating OpenNebula Datastore\nDESCRIPTION: This snippet shows how to update an OpenNebula datastore with CEPH_CONF attribute to point to custom location of ceph.conf file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ onedatastore update <DS_ID>\nCEPH_CONF=\"/etc/ceph/ceph1.conf\"\n```\n\n----------------------------------------\n\nTITLE: Configure VLAN Tagging - OpenNebula\nDESCRIPTION: This snippet demonstrates how to configure VLAN tagging for a Virtual Network in OpenNebula. It specifies a range of VLAN IDs (100, 105, 106, and 107) that are allowed for VM traffic using the VLAN_TAGGED_ID attribute.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/bridged.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nVLAN_TAGGED_ID = \"100,105-107\"\n```\n\n----------------------------------------\n\nTITLE: Update SERVER_ID in oned.conf (Leader)\nDESCRIPTION: Updates the SERVER_ID in the /etc/one/oned.conf file on the leader node to reflect the server's ID. This is necessary for the Raft consensus algorithm to correctly identify the server within the cluster.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/frontend_ha.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nFEDERATION = [\n    MODE          = \"STANDALONE\",\n    ZONE_ID       = 0,\n    SERVER_ID     = 0, # changed from -1 to 0 (as 0 is the server id)\n    MASTER_ONED   = \"\"\n]\n```\n\n----------------------------------------\n\nTITLE: Defining USER_INPUTS_METADATA in VM Template\nDESCRIPTION: This code snippet demonstrates how to define USER_INPUTS_METADATA in a VM template to add information and titles to APP and GROUP based on USER_INPUTS. The metadata enhances user experience in Sunstone. This code snippet defines metadata for Apps(BLOG, MYSQL) and Groups(CONFIG, ADDITIONAL).\nDependencies: None\nInputs: None\nOutputs: The USER_INPUTS_METADATA variable will be used to add information to the APP and GROUPS.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_6\n\nLANGUAGE: none\nCODE:\n```\nUSER_INPUTS_METADATA=[\n  DESCRIPTION=\"This tab includes all the information about the blog section in this template.\",\n  NAME=\"BLOG\",\n  TITLE=\"Blog\",\n  TYPE=\"APP\" ]\nUSER_INPUTS_METADATA=[\n  NAME=\"MYSQL\",\n  TITLE=\"MySQL\",\n  TYPE=\"APP\" ]\nUSER_INPUTS_METADATA=[\n  DESCRIPTION=\"MySQL configuration parameters\",\n  NAME=\"CONFIG\",\n  TITLE=\"Configuration\",\n  TYPE=\"GROUP\" ]\nUSER_INPUTS_METADATA=[\n  DESCRIPTION=\"Additional MySQL parameters\",\n  NAME=\"ADDITIONAL\",\n  TITLE=\"Additional parameters\",\n  TYPE=\"GROUP\" ]\n```\n\n----------------------------------------\n\nTITLE: Listing VMs with Search Filter - OpenNebula CLI\nDESCRIPTION: This snippet shows how to filter the VM list using the `--search` option of the `onevm list` command.  The filter uses a `VM.KEY1=VALUE1&VM.KEY2=VALUE2` format, where `&` acts as a logical AND. The example filters VMs whose names contain 'test-vm' and are owned by 'oneadmin'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_8\n\nLANGUAGE: text\nCODE:\n```\n$ onevm list --search 'VM.NAME=test-vm&VM.UNAME=oneadmin'\n ID    USER     GROUP    NAME     STAT UCPU UMEM HOST TIME\n 21005 oneadmin oneadmin test-vm  pend    0   0K       1d 23h13\n 2100  oneadmin oneadmin test-vm2 pend    0   0K      12d 17h59\n```\n\n----------------------------------------\n\nTITLE: DPDK Virtual Network Template in OpenNebula (Bash)\nDESCRIPTION: This Virtual Network template configures a network to use DPDK with Open vSwitch. It sets the bridge type to 'openvswitch_dpdk', enabling DPDK acceleration for network traffic.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nNAME = \"DPDK_VSBC_HA2\"\nBRIDGE = \"onebr.dpdk\"\nBRIDGE_TYPE = \"openvswitch_dpdk\"\nSECURITY_GROUPS = \"0\"\nVLAN_ID = \"1402\"\nVN_MAD = \"ovswitch\"\n\n# note there is no PHYDEV, after creation it will show PHYDEV = \"\"\n```\n\n----------------------------------------\n\nTITLE: Apache Configuration for FireEdge (TLS) - Bash\nDESCRIPTION: This snippet configures Apache as a TLS-secured reverse proxy for FireEdge. It includes SSL configuration directives, such as `SSLEngine`, `SSLCertificateKeyFile`, and `SSLCertificateFile`. It also configures WebSocket proxying and access control within the `/fireedge` location.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/fireedge_for_large_deployments.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n<VirtualHost *:443>\n  ServerName one.example.com\n\n  SSLEngine on\n  SSLCertificateKeyFile /etc/ssl/private/opennebula-key.pem\n  SSLCertificateFile /etc/ssl/certs/opennebula-certchain.pem\n\n  SSLProtocol All -SSLv2 -SSLv3 -TLSv1 -TLSv1.1\n  SSLHonorCipherOrder On\n  SSLCompression off\n  Header always set Strict-Transport-Security \"max-age=15768000\"\n  SSLCipherSuite 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256'\n\n  RequestHeader set X-Forwarded-Proto \"https\"\n\n  ProxyRequests     off\n  ProxyPreserveHost on\n\n  # no proxy for /error/ (Apache HTTPd errors messages)\n  ProxyPass /error/ !\n\n  ProxyPass /fireedge http://localhost:2616/fireedge\n  ProxyPassReverse /fireedge http://localhost:2616/fireedge\n\n  RewriteEngine on\n  RewriteCond %{HTTP:Upgrade} websocket [NC]\n  RewriteCond %{HTTP:Connection} upgrade [NC]\n  RewriteRule ^/fireedge/?(.*) \"ws://localhost:2616/fireedge/$1\" [P,L]\n\n  <Location /fireedge>\n      Order deny,allow\n      Allow from all\n  </Location>\n</VirtualHost>\n```\n\n----------------------------------------\n\nTITLE: Default Showback Cost Configuration (oned.conf)\nDESCRIPTION: This snippet configures the default costs for CPU, memory, and disk resources in OpenNebula, used by the `oneshowback` calculate method. The `DEFAULT_COST` attribute defines `CPU_COST`, `MEMORY_COST`, and `DISK_COST`.  The `SHOWBACK_ONLY_RUNNING` parameter determines if costs are only counted for running VMs; by default, costs are counted if the resource is reserved on the host, even in `poweroff` or `suspend` states.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n#*******************************************************************************\n# Default showback cost\n#*******************************************************************************\n\nDEFAULT_COST = [\n    CPU_COST    = 0,\n    MEMORY_COST = 0,\n    DISK_COST   = 0\n]\n\nSHOWBACK_ONLY_RUNNING = \"no\"\n```\n\n----------------------------------------\n\nTITLE: Updating a VM Template\nDESCRIPTION: This snippet updates a virtual machine template using the `onetemplate update` command. It specifies the template ID (3) and adds a network interface configuration.  The OpenNebula CLI tool must be installed and configured. The purpose is to add a NIC to the VM template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ onetemplate update 3\n...\nNIC = [ NETWORK_MODE = \"auto\" ]\n```\n\n----------------------------------------\n\nTITLE: Creating a user with LDAP authentication in OpenNebula\nDESCRIPTION: This snippet shows how to create a new user with the LDAP authentication driver.  In this case, the password is not required. The command returns the user ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser create --driver ldap <user_name>\nID: 4\n```\n\n----------------------------------------\n\nTITLE: Setting the DRS Interval in OpenNebula\nDESCRIPTION: This configuration controls the DRS interval. `DRS_INTERVAL` defines the frequency in seconds of DRS actions. Setting `DRS_INTERVAL` to -1 disables automatic DRS operations. DRS optimizes cluster load balancing.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/configuration.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nDRS_INTERVAL = 600\n```\n\n----------------------------------------\n\nTITLE: Setting CD-ROM Device Prefix in oned.conf (ARM64)\nDESCRIPTION: This snippet configures the CD-ROM device prefix to \"sd\" in the `/etc/one/oned.conf` file. This is necessary for ARM64 architectures as IDE disk support is often absent, and using \"sd\" ensures proper CD-ROM functionality.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_20\n\nLANGUAGE: none\nCODE:\n```\nDEFAULT_CDROM_DEVICE_PREFIX = \"sd\"\n```\n\n----------------------------------------\n\nTITLE: Defining DATABLOCK Image Template in OpenNebula\nDESCRIPTION: This example shows how to define a DATABLOCK image template in OpenNebula. It includes the image name, type, and size. The TYPE parameter is set to DATABLOCK, and SIZE specifies the disk space in MB. If PATH is not set, the image will start as a new empty disk.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/img_template.rst#_snippet_2\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nNAME          = \"Experiment results\"\nTYPE          = DATABLOCK\n# No PATH set, this image will start as a new empty disk\nSIZE          = 3.08\nDESCRIPTION   = \"Storage for my Thesis experiments.\"\n```\n\n----------------------------------------\n\nTITLE: Installing Context Package on RHEL 9.x/Fedora with yum\nDESCRIPTION: These commands install the OpenNebula context package and its dependencies on RHEL 9.x (AlmaLinux/Oracle Linux 9.x) and Fedora using yum. It installs the EPEL repository, the one-context package, and enables the network service.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# yum install -y epel-release\n# yum install -y one-context-[0-9]*el9*rpm\n# systemctl enable network.service\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Hosts\nDESCRIPTION: This snippet uses the `onehost list` command to verify that the Hypervisor nodes are registered with OpenNebula. The output shows the host IDs, names, cluster, CPU allocation, memory allocation, and status. Ensure that the `STAT` column displays `on`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nonehost list\n```\n\n----------------------------------------\n\nTITLE: Reverting a Virtual Machine to a Snapshot\nDESCRIPTION: This command reverts a virtual machine to a specific snapshot. The example reverts VM 4 to snapshot with ID 0 and enables verbose output.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm snapshot-revert 4 0 --verbose\n```\n\n----------------------------------------\n\nTITLE: Deploying VM to Host - OpenNebula CLI\nDESCRIPTION: This snippet shows how to deploy a VM to a specific host using the `onevm deploy` command. It requires the VM ID and the host ID as arguments.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n$ onevm deploy 0 2\n```\n\n----------------------------------------\n\nTITLE: Defining SCHED_RANK with FREE_CPU in OpenNebula\nDESCRIPTION: This snippet demonstrates how to prioritize hosts for VM deployment based on their free CPU capacity. Hosts with a higher FREE_CPU value will be selected first. This allows to maximize usage of hosts with more available resources.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_34\n\nLANGUAGE: text\nCODE:\n```\n# First those resources with a higher Free CPU\n  SCHED_RANK = \"FREE_CPU\"\n```\n\n----------------------------------------\n\nTITLE: Virtio SCSI Queues Configuration\nDESCRIPTION: This snippet shows how to configure the number of virtio-scsi queues for a VM. Setting `VIRTIO_SCSI_QUEUES` to `auto` configures the number of queues to the number of vCPUs.  This setting can improve I/O performance by enabling multiple vCPUs to manage queues simultaneously.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nFEATURES = [\n    VIRTIO_SCSI_QUEUES = \"auto\"\n]\n```\n\n----------------------------------------\n\nTITLE: Fixing Image Magic Error\nDESCRIPTION: This snippet provides the kernel module options to fix the 'image magic is incorrect' error that occurs when restoring a VM from a suspended state. It disables nested virtualization, emulates invalid guest states and ignores MSRs. These are module parameters for the kvm_intel and kvm modules.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_23\n\nLANGUAGE: none\nCODE:\n```\noptions kvm_intel nested=0\noptions kvm_intel emulate_invalid_guest_state=0\noptions kvm ignore_msrs=1\n```\n\n----------------------------------------\n\nTITLE: Adding Group DN to Group Template - Bash\nDESCRIPTION: This snippet demonstrates how to add a GROUP_DN parameter to the OpenNebula group template. This parameter specifies the LDAP group DN that maps to the OpenNebula group.  The :mapping_key parameter in the LDAP configuration file must be set to GROUP_DN for this to work.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nGROUP_DN=\"CN=technicians,CN=Groups,DC=example,DC=com\"\n```\n\n----------------------------------------\n\nTITLE: Create System Datastore using CLI\nDESCRIPTION: This snippet shows how to create a system datastore in OpenNebula using the onedatastore CLI tool.  It uses the configuration file 'systemds.txt' as input. The output shows the ID of the created datastore.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/nas_ds.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n$ onedatastore create systemds.txt\nID: 101\n```\n\n----------------------------------------\n\nTITLE: Defining Role VM Limits in OneFlow Service\nDESCRIPTION: This code snippet demonstrates how to define the minimum and maximum number of VMs for a service role in a OneFlow service definition. The `min_vms` and `max_vms` attributes specify the lower and upper bounds for the number of VMs that can be running in the role. These limits are enforced by the elasticity module.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_elasticity.rst#_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n    \"roles\": [\n        {\n          \"name\": \"frontend\",\n          \"cardinality\": 1,\n          \"vm_template\": 0,\n\n          \"min_vms\" : 1,\n          \"max_vms\" : 5,\n    ...\n```\n\n----------------------------------------\n\nTITLE: Show Group Quota (CLI)\nDESCRIPTION: This command displays detailed information about a specific group, including their quota limits and current usage for various resources. The group name is passed as a parameter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/quotas.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ onegroup show gA\n```\n\n----------------------------------------\n\nTITLE: Configuring VFIO Devices\nDESCRIPTION: This configuration specifies the PCI addresses of the devices to be bound to VFIO. The addresses are retrieved using the lspci command. It is important to prepend the domain, which is usually 0000.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nDEVICES=\"0000:04:00.0 0000:05:00.0 0000:84:00.0 0000:85:00.0\"\n```\n\n----------------------------------------\n\nTITLE: fireedge-server.conf Configuration Snippet Example\nDESCRIPTION: This snippet from `/etc/one/fireedge-server.conf` shows a simple configuration example. It features a symbolized key `:one_xmlrpc` with a URL value. The snippet is intended to demonstrate the syntax for addressing parameters in configuration files where keys begin with a colon.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/diff_formats.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n# OpenNebula: use it if you have oned and fireedge on different servers\n:one_xmlrpc: http://localhost:2633/RPC2     # path 4\n```\n\n----------------------------------------\n\nTITLE: Configuring VLAN IDs in oned.conf (OpenNebula)\nDESCRIPTION: This snippet shows how to configure the VLAN ID pool in the OpenNebula configuration file (oned.conf). It defines the starting VLAN ID and reserved VLAN ID ranges. This configuration is used for automatic VLAN ID assignment when creating 802.1Q networks.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vlan.rst#_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n#  VLAN_IDS: VLAN ID pool for the automatic VLAN_ID assigment. This pool\n#  is for 802.1Q networks (Open vSwitch and 802.1Q drivers). The driver\n#  will try first to allocate VLAN_IDS[START] + VNET_ID\n#     start: First VLAN_ID to use\n#     reserved: Comma separated list of VLAN_IDs or ranges. Two numbers\n#     separated by a colon indicate a range.\n\nVLAN_IDS = [\n    START    = \"2\",\n    RESERVED = \"0, 1, 4095\"\n]\n```\n\n----------------------------------------\n\nTITLE: VM Template Example with Restricted Disk Attributes\nDESCRIPTION: This snippet presents an example VM template.  A user can delete the second disk but she cannot delete the first disk because it contains a restricted attribute, namely TOTAL_BYTES_SEC.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_20\n\nLANGUAGE: none\nCODE:\n```\nCPU     = \"1\"\nVCPU    = \"1\"\nMEMORY  = \"512\"\nDISK=[\n  IMAGE = \"BaseOS\"\n  TOTAL_BYTES_SEC = 1 ]\nDISK=[\n  IMAGE = \"BaseOS2\" ]      \nNIC=[\n  NETWORK_ID = \"0\" ]\n```\n\n----------------------------------------\n\nTITLE: Allocating a Template using OpenNebula Template format\nDESCRIPTION: This snippet shows how to allocate a template by passing the template content directly in OpenNebula's format. This bypasses the dictionary-based parameter translation. Requires a valid `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\none.template.allocate(\n    '''NAME=\"test100\"\n       MEMORY=\"1024\"\n       DISK=[ IMAGE_ID= \"1\" ]\n       DISK=[ IMAGE_ID= \"2\" ]\n       CPU=\"1\"\n       VCPU=\"2\"\n    ''')\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Network Configuration for BGP EVPN\nDESCRIPTION: This snippet shows the configuration settings in /var/lib/one/remotes/etc/vnm/OpenNebulaNetwork.conf to enable BGP EVPN for VXLAN networks. It sets the vxlan_mode to evpn, vxlan_tep to local_ip and optionally disables learning using ip_link_conf.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vxlan.rst#_snippet_8\n\nLANGUAGE: YAML\nCODE:\n```\n# Multicast protocol for multi destination BUM traffic. Options:\n#   - multicast, for IP multicast\n#   - evpn, for BGP EVPN control plane\n:vxlan_mode: evpn\n\n# Tunnel endpoint communication type. Only for evpn vxlan_mode.\n#   - dev, tunnel endpoint communication is sent to PHYDEV\n#   - local_ip, first ip addr of PHYDEV is used as address for the communiation\n:vxlan_tep: local_ip\n\n# Additional ip link options, uncomment the following to disable learning for\n# EVPN mode\n:ip_link_conf:\n    :nolearning:\n```\n\n----------------------------------------\n\nTITLE: Adding LXC Node to OpenNebula with CLI\nDESCRIPTION: This snippet outlines the commands required to add an LXC node to the OpenNebula front-end using the command-line interface (CLI). It includes creating the host with the appropriate driver and then listing hosts to check the status. The `<node01>` should be replaced with the actual hostname.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_node_installation.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost create <node01> -i lxc -v lxc\n\n$ onehost list\n  ID NAME            CLUSTER   RVM      ALLOCATED_CPU      ALLOCATED_MEM STAT\n   1 localhost       default     0                  -                  - init\n\n# After some time (up to 1 minute)\n\n$ onehost list\n  ID NAME            CLUSTER   RVM      ALLOCATED_CPU      ALLOCATED_MEM STAT\n   0 node01          default     0       0 / 400 (0%)     0K / 7.7G (0%) on\n```\n\n----------------------------------------\n\nTITLE: Image Template Example\nDESCRIPTION: This is an example of an image template used to add an iSCSI device to OpenNebula. It defines the name, path to the iSCSI volume, and persistence setting. The PATH should be the IQN of the iSCSI target.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/iscsi_ds.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nNAME = iscsi_device\nPATH = iqn.1992-01.com.example:storage:diskarrays-sn-a8675309\nPERSISTENT = YES\n```\n\n----------------------------------------\n\nTITLE: Defining OpenNebula Flow Schema in JSON\nDESCRIPTION: This JSON schema defines the structure for an OpenNebula Flow, specifying required and optional properties like name, deployment type, description, shutdown action, roles, user inputs, and network configurations. It uses JSON schema constructs to define data types and constraints for each property. The expected output is a validated OpenNebula Flow configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  :type => :object,\n  :properties => {\n      'name' => {\n          :type => :string,\n          :required => true\n      },\n      'deployment' => {\n          :type => :string,\n          :default => 'none'\n      },\n      'description' => {\n          :type => :string,\n          :default => ''\n      },\n      'shutdown_action' => {\n          :type => :string,\n          :required => false\n      },\n      'roles' => {\n          :type => :array,\n          :items => [],\n          :required => true\n      },\n      'user_inputs' => {\n          :type => :object,\n          :properties => {},\n          :required => false\n      },\n      'user_inputs_values' => {\n          :type => :object,\n          :properties => {},\n          :required => false\n      },\n      'ready_status_gate' => {\n          :type => :boolean,\n          :required => false\n      },\n      'automatic_deletion' => {\n          :type => :boolean,\n          :required => false\n      },\n      'networks' => {\n          :type => :object,\n          :properties => {},\n          :required => false\n      },\n      'networks_values' => {\n          :type => :array,\n          :items => {\n              :type => :object,\n              :properties => {}\n          },\n          :required => false\n      },\n      'on_hold' => {\n          :type => :boolean,\n          :required => false\n      }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Python Packages\nDESCRIPTION: This command installs pip and pipx, which are Python package installers.  pip is used to install Python packages from PyPI, and pipx is used to install and run Python applications in isolated environments.  Requires sudo privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsudo apt install python3-pip pipx\n```\n\n----------------------------------------\n\nTITLE: Listing NFS Shared Directories\nDESCRIPTION: This bash command lists the contents of the /storage directory on the NFS server, showing the permissions and ownership of the one_datastores directory. It confirms the UID and GID of the directory, which should be 9869 for OpenNebula's oneadmin user.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nroot@nfs-server:/# ls -ln /storage\ntotal 0\ndrwxr-xr-x 2 9869 9869 6 Jun 26 17:55 one_datastores\n```\n\n----------------------------------------\n\nTITLE: Installing OpenNebula LXC Node on AlmaLinux/RHEL\nDESCRIPTION: This snippet shows how to install the OpenNebula LXC node package on AlmaLinux/RHEL systems using the yum package manager. This requires that the OpenNebula repositories are already added and configured on the system.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_node_installation.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# yum -y install opennebula-node-lxc\n```\n\n----------------------------------------\n\nTITLE: Configuring Backup Operation Attributes in OpenNebula\nDESCRIPTION: This snippet configures the backup operation settings, including the DATASTORE_ID, FS_FREEZE mode, retention policy (KEEP_LAST), MODE (incremental/full), and INCREMENT_MODE. These settings apply to all VMs within the Backup Job. The DATASTORE_ID is mandatory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nDATASTORE_ID = 101\nFS_FREEZE = \"NONE\"\nKEEP_LAST = \"4\"\nMODE = \"INCREMENT\"\nINCREMENT_MODE = \"SNAPSHOT\"\n```\n\n----------------------------------------\n\nTITLE: TPM Passthrough XML Configuration\nDESCRIPTION: This XML snippet configures TPM passthrough to the guest OS, assuming a physical TPM device exists at `/dev/tpm0`. The `<tpm>` tag specifies the `tpm-tis` model and a `passthrough` backend with the device path defined. This configuration allows the guest OS to directly access the physical TPM device.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<devices>\n    <tpm model='tpm-tis'>\n        <backend type='passthrough'>\n            <device path='/dev/tpm0'/>\n        </backend>\n    </tpm>\n</devices>\n```\n\n----------------------------------------\n\nTITLE: LDAP Authentication Configuration (YAML)\nDESCRIPTION: This code snippet shows the default configuration for the LDAP authentication driver in `/etc/one/auth/ldap_auth.conf`.  It defines parameters for connecting to the LDAP server, specifying the base DN for user searches, defining group membership requirements, and mapping LDAP groups to OpenNebula groups. The configuration uses YAML format.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nserver 1:\n    # Ldap user able to query, if not set connects as anonymous. For\n    # Active Directory append the domain name. Example:\n    # Administrator@my.domain.com\n    #:user: 'admin'\n    #:password: 'password'\n\n    # Ldap authentication method\n    :auth_method: :simple\n\n    # Ldap server\n    :host: localhost\n    :port: 389\n\n    # Connection and authentication timeout\n    #:timeout: 15\n\n    # Uncomment this line for tls connections, use :simple_tls or :start_tls\n    #:encryption: :simple_tls\n\n    # base hierarchy where to search for users and groups\n    :base: 'dc=domain'\n\n    # group the users need to belong to. If not set any user will do\n    #:group: 'cn=cloud,ou=groups,dc=domain'\n\n    # field that holds the user name, if not set 'cn' will be used\n    :user_field: 'cn'\n\n    # for Active Directory use this user_field instead\n    #:user_field: 'sAMAccountName'\n\n    # field name for group membership, by default it is 'member'\n    #:group_field: 'member'\n\n    # user field that is in the group group_field, if not set 'dn' will be used\n    #:user_group_field: 'dn'\n\n    # Generate mapping file from group template info\n    :mapping_generate: true\n\n    # Seconds a mapping file remains untouched until the next regeneration\n    :mapping_timeout: 300\n\n    # Name of the mapping file in OpenNebula var directory\n    :mapping_filename: server1.yaml\n\n    # Key from the OpenNebula template to map to an AD group\n    :mapping_key: GROUP_DN\n\n    # Default group ID used for users in an AD group not mapped\n    :mapping_default: 1\n\n    # use RFC2307bis for groups\n    # if false, depending on your LDAP server configuration,\n    # set user_field and user_group_field 'uid' and group_field 'memberUid'\n    :rfc2307bis: true\n\n    # DN of a group, if user is member of that group in LDAP, this user\n    # will be group admin of all mapped LDAP groups in OpenNebula.\n    #:group_admin_group_dn: 'cn=admins,ou=groups,dc=domain'\n\n# this example server wont be called as it is not in the :order list\nserver 2:\n    :auth_method: :simple\n    :host: localhost\n    :port: 389\n    :base: 'dc=domain'\n    #:group: 'cn=cloud,ou=groups,dc=domain'\n    :user_field: 'cn'\n\n:order:\n    - server 1\n    #- server 2\n```\n\n----------------------------------------\n\nTITLE: Updating OpenNebula Zone Endpoint Bash\nDESCRIPTION: This command updates the endpoint of the OpenNebula Zone. The endpoint specifies the address where the OpenNebula XML-RPC API can be accessed.  The <master-ip> needs to be the floating IP in HA setup.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onezone update 0\nENDPOINT = http://<master-ip>:2633/RPC2\n```\n\n----------------------------------------\n\nTITLE: Getting Image Virtual Size\nDESCRIPTION: This snippet retrieves the virtual size of an image using `qemu-img info`. The output is filtered using `grep` to only show the line containing \"virtual size\". Error messages are redirected to /dev/null.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ qemu-img info /var/lib/one//datastores/1/2f7afcdd0f5c7644a8f82ec57f3ede54 2>/dev/null | egrep -i \"virtual size\"\n```\n\n----------------------------------------\n\nTITLE: Updating NIC Configuration in OpenNebula\nDESCRIPTION: This command updates the configuration of a network interface card (NIC) attached to a virtual machine. The `update_nic.txt` file contains the new NIC attributes, such as inbound bandwidth limits. The example updates NIC 0 of VM 0 with the configuration from `update_nic.txt`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n$ cat update_nic.txt\nNIC = [\n    INBOUND_AVG_BW = \"512\",\n    INBOUND_PEAK_BW = \"1024\"\n]\n\n$ onevm nic-update 0 0 update_nic.txt\n```\n\n----------------------------------------\n\nTITLE: Showing Service Template Details using CLI in Bash\nDESCRIPTION: Shows detailed information about a specific Service Template using the `oneflow-template show` command. The command takes the template ID as an argument and displays information such as ID, NAME, USER, GROUP, REGISTRATION_TIME, PERMISSIONS, and TEMPLATE CONTENTS.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ oneflow-template show 0\nSERVICE TEMPLATE 0 INFORMATION\nID                  : 0\nNAME                : my_service\nUSER                : oneadmin\nGROUP               : oneadmin\nREGISTRATION_TIME   : 10/28 17:42:46\n\nPERMISSIONS\nOWNER               : um-\nGROUP               : ---\nOTHER               : ---\n\nTEMPLATE CONTENTS\n{\n  \"name\": \"my_service\",\n  \"roles\": [\n    {\n\n    ....\n```\n\n----------------------------------------\n\nTITLE: Setting User Template Attributes\nDESCRIPTION: This snippet shows an example of setting user template attributes such as department and email within OpenNebula. These attributes can be customized to match specific user roles or organizational needs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_11\n\nLANGUAGE: text\nCODE:\n```\nDEPARTMENT=IT\nEMAIL=user@company.com\n```\n\n----------------------------------------\n\nTITLE: Copying SSH public key to nodes using ssh-copy-id\nDESCRIPTION: This command copies the `oneadmin` user's SSH public key to the `authorized_keys` file on the specified node, enabling passwordless SSH login. The `-i` option specifies the identity file (public key) to use.  It is executed for each node in the infrastructure. <node1>, <node2>, <node3>, etc. should be replaced with the actual hostnames or IP addresses.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/passwordless_ssh.txt#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh-copy-id -i /var/lib/one/.ssh/id_rsa.pub <node1>\n$ ssh-copy-id -i /var/lib/one/.ssh/id_rsa.pub <node2>\n$ ssh-copy-id -i /var/lib/one/.ssh/id_rsa.pub <node3>\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Enterprise Repository on AlmaLinux\nDESCRIPTION: This bash script adds the OpenNebula Enterprise Edition repository to the AlmaLinux system. It creates a `/etc/yum.repos.d/opennebula.repo` file with the repository configuration, including the base URL (which requires a customer-specific token), GPG key URL, and enabling the repository. The script then refreshes the yum cache.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# cat << \\\"EOT\\\" > /etc/yum.repos.d/opennebula.repo\n[opennebula]\nname=OpenNebula Enterprise Edition\nbaseurl=https://<token>@enterprise.opennebula.io/repo/|version|/AlmaLinux/$releasever/$basearch\nenabled=1\ngpgkey=https://downloads.opennebula.io/repo/repo2.key\ngpgcheck=1\nrepo_gpgcheck=1\nEOT\n# yum makecache\n```\n\n----------------------------------------\n\nTITLE: Running Ansible Playbook\nDESCRIPTION: This snippet shows the command to run the main OpenNebula deployment playbook using Ansible. The `-v` option increases verbosity of the output. This command assumes you are in the `my-one` directory and have set up the Hatch environment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nansible-playbook -v opennebula.deploy.main\n```\n\n----------------------------------------\n\nTITLE: Datastore Template Example\nDESCRIPTION: This is an example of a datastore template file (iscsi.ds) used to create an iSCSI datastore in OpenNebula. It defines attributes like datastore name, disk type, datastore and transfer manager, iSCSI host, user, and usage for CHAP authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/iscsi_ds.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nNAME = iscsi\n\nDISK_TYPE = \"ISCSI\"\n\nDS_MAD = \"iscsi_libvirt\"\nTM_MAD = \"iscsi_libvirt\"\n\nISCSI_HOST  = \"the_iscsi_host\"\nISCSI_USER  = \"the_iscsi_user\"\nISCSI_USAGE = \"the_iscsi_usage\"\n```\n\n----------------------------------------\n\nTITLE: Creating OpenNebula Datastore with onedatastore\nDESCRIPTION: This command creates a new datastore in OpenNebula using the `onedatastore` tool and the provided configuration file (`ds_rsync.txt`). The output shows the ID of the newly created datastore.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/rsync.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore create ds_rsync.txt\nID: 100\n```\n\n----------------------------------------\n\nTITLE: Host Affinity Configuration\nDESCRIPTION: This snippet demonstrates how to configure host affinity for a specific role within a VM Group. It uses the `HOST_AFFINED` attribute to specify a set of hosts where VMs of the 'database' role can be executed. This ensures that the database VMs are placed on high-performance hosts with IDs 1, 2, 3, and 4.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/affinity.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nROLE = [\n    NAME         = \"database\",\n    HOST_AFFINED = \"1,2,3,4\"\n]\n```\n\n----------------------------------------\n\nTITLE: Setting Backup Job Priority and Execution Mode in OpenNebula\nDESCRIPTION: This snippet demonstrates how to set the priority and execution mode for a Backup Job. PRIORITY determines the execution order of Backup Jobs (0-49 for users, 50-99 for administrators). EXECUTION can be either SEQUENTIAL (mandatory for Restic) or PARALLEL.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n#Higher values means higher priority\nPRIORITY = 7\nEXECUTION = \"SEQUENTIAL\"\n```\n\n----------------------------------------\n\nTITLE: Define Bridged Network Template - OpenNebula\nDESCRIPTION: This code snippet shows how to define a Bridged network with Security Groups in OpenNebula. The VN_MAD attribute is set to \"fw\" to enable Security Groups.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/bridged.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nNAME    = \"private1\"\nVN_MAD  = \"fw\"\n```\n\n----------------------------------------\n\nTITLE: Scheduling VM Resume Action\nDESCRIPTION: This example shows how to schedule a VM resume action to occur weekly for a specified number of times. The command uses the `onevm resume` command with the `--schedule`, `--weekly`, and `--end` options to define the schedule.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_29\n\nLANGUAGE: text\nCODE:\n```\n$ onevm resume 0 --schedule \"09/23 14:15\" --weekly \"2,6\" --end 5\nVM 0: resume scheduled at 2018-09-23 14:15:00 +0200\n```\n\n----------------------------------------\n\nTITLE: Attaching a Virtual Machine to a Reservation in OpenNebula\nDESCRIPTION: This snippet shows how to attach a Virtual Machine to a Virtual Network Reservation. The `NETWORK` attribute within the `NIC` definition is set to the name of the reservation 'MyVNET'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/self_provision.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nNIC = [ NETWORK = \"MyVNET\"]\n```\n\n----------------------------------------\n\nTITLE: Mounting Hugepages\nDESCRIPTION: This snippet shows how to create a mount point for hugepages and add an entry to /etc/fstab to automatically mount them on boot.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# mkdir /mnt/hugepages1G\n# grep huge /etc/fstab\nnodev\t/mnt/hugepages1G hugetlbfs pagesize=1GB 0 0\n# mount /mnt/hugepages1G\n```\n\n----------------------------------------\n\nTITLE: Running the miniONE script\nDESCRIPTION: This command executes the miniONE script with the --frontend option, which installs the OpenNebula front-end. The script automates the installation and configuration process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_9\n\nLANGUAGE: Bash\nCODE:\n```\nbash minione --frontend\n```\n\n----------------------------------------\n\nTITLE: Verifying Connectivity with Ansible Ping Module\nDESCRIPTION: This command uses the Ansible ping module to verify connectivity to all hosts defined in the `example.yml` inventory file. The `-b` option enables privilege escalation to execute the ping command as root.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nansible -i example.yml all -m ping -b\n```\n\n----------------------------------------\n\nTITLE: Restic Datastore Template\nDESCRIPTION: This snippet shows the content of the ds_restic.txt file, which defines the template for creating a Restic backup datastore in OpenNebula. It specifies the datastore name, type, MADs, Restic password, and SFTP server IP address.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/restic.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncat ds_restic.txt\nNAME   = \"RBackups\"\nTYPE   = \"BACKUP_DS\"\n\nDS_MAD = \"restic\"\nTM_MAD = \"-\"\n\nRESTIC_PASSWORD    = \"opennebula\"\nRESTIC_SFTP_SERVER = \"192.168.1.8\"\n```\n\n----------------------------------------\n\nTITLE: Backing Up OpenNebula Database\nDESCRIPTION: This command creates a backup of the OpenNebula database and stores it in the specified file. It uses the 'onedb backup' command. The backup file can be later used to restore the database.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_12\n\nLANGUAGE: text\nCODE:\n```\n$ onedb backup /tmp/my_backup.db\nSqlite database backup stored in /tmp/my_backup.db\nUse 'onedb restore' or copy the file back to restore the DB.\n```\n\n----------------------------------------\n\nTITLE: Purging Terminated VM Data\nDESCRIPTION: The 'onedb purge-done' command deletes information related to terminated (DONE state) VMs. The --end parameter can be used to delete records older than the specified date.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_15\n\nLANGUAGE: text\nCODE:\n```\n$ onedb purge-done --end 2016/01\n```\n\n----------------------------------------\n\nTITLE: Raft Algorithm Configuration in OpenNebula (oned.conf)\nDESCRIPTION: This snippet provides an example configuration for tuning the Raft algorithm used by OpenNebula within the `oned.conf` file. It includes settings such as `LIMIT_PURGE`, `LOG_RETENTION`, `LOG_PURGE_TIMEOUT`, `ELECTION_TIMEOUT_MS`, `BROADCAST_TIMEOUT_MS`, and `XMLRPC_TIMEOUT_MS`. These parameters control the behavior of the Raft consensus algorithm, influencing synchronization, storage, and timeouts.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nRAFT = [\n    LIMIT_PURGE          = 100000,\n    LOG_RETENTION        = 500000,\n    LOG_PURGE_TIMEOUT    = 600,\n    ELECTION_TIMEOUT_MS  = 2500,\n    BROADCAST_TIMEOUT_MS = 500,\n    XMLRPC_TIMEOUT_MS    = 450\n]\n```\n\n----------------------------------------\n\nTITLE: Listing LVM Volumes in a Thin Provisioned Datastore\nDESCRIPTION: This snippet demonstrates the output of the `lvs` command in a thin-provisioned LVM datastore. It highlights the presence of a thin pool (lv-one-11-pool) and thin LVs (lv-one-11-0, lv-one-11-1) associated with a VM, illustrating how disk space is allocated on demand.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/lvm_drivers.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# lvs\n  LV              VG       Attr       LSize   Pool            Origin Data%  Meta%  Move Log Cpy%Sync Convert\n  lv-one-11-0     vg-one-0 Vwi-aotz-- 256.00m lv-one-11-pool         48.44\n  lv-one-11-1     vg-one-0 Vwi-aotz-- 256.00m lv-one-11-pool         48.46\n  lv-one-11-pool  vg-one-0 twi---tz-- 512.00m                        48.45  12.60\n```\n\n----------------------------------------\n\nTITLE: Kernel Parameters for VFIO and Blacklisting NVIDIA Drivers\nDESCRIPTION: These kernel parameters load the vfio-pci driver early and blacklist the nouveau drivers for NVIDIA GPUs, preventing the host from using them.  This is crucial for allowing the VMs exclusive access.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nrd.driver.pre=vfio-pci rd.driver.blacklist=nouveau\n```\n\n----------------------------------------\n\nTITLE: Changing oneadmin Password\nDESCRIPTION: This snippet demonstrates how to change the password for the 'oneadmin' user in OpenNebula. It involves using the 'oneuser passwd' command with user ID 0 (typically 'oneadmin') and then updating the one_auth file with the new credentials. Requires OpenNebula service restart.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n# oneuser passwd 0 <PASSWORD>\n# echo 'oneadmin:<PASSWORD>' > /var/lib/one/.one/one_auth\n```\n\n----------------------------------------\n\nTITLE: iSCSI LUN Image Template Example\nDESCRIPTION: This is an example image template for adding an iSCSI LUN to OpenNebula, specifying the iSCSI host, path (IQN including LUN ID), and persistence. The explicit '/0' at the end of the IQN target path indicates the iSCSI LUN ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/iscsi_ds.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\noneadmin@onedv:~/exampletemplates$ more iscsiimage.tpl\nNAME=iscsi_device_with_lun\nPATH=iqn.2014.01.192.168.50.61:test:7cd2cc1e/0\nISCSI_HOST=192.168.50.61\nPERSISTENT=YES\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Enterprise Repository on RHEL\nDESCRIPTION: This bash script adds the OpenNebula Enterprise Edition repository to the RHEL system. It creates a `/etc/yum.repos.d/opennebula.repo` file with the necessary repository configuration, including the base URL (which requires a customer-specific token), GPG key URL, and enabling the repository. The script then refreshes the yum cache.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# cat << \\\"EOT\\\" > /etc/yum.repos.d/opennebula.repo\n[opennebula]\nname=OpenNebula Enterprise Edition\nbaseurl=https://<token>@enterprise.opennebula.io/repo/|version|/RedHat/$releasever/$basearch\nenabled=1\ngpgkey=https://downloads.opennebula.io/repo/repo2.key\ngpgcheck=1\nrepo_gpgcheck=1\nEOT\n# yum makecache\n```\n\n----------------------------------------\n\nTITLE: Monitoring Information in CSV Format using onehost\nDESCRIPTION: This command retrieves the USED_MEMORY for host 0, converts the unit to GB, limits the number of data points to 10, and displays the data in a CSV format, using ';' as the separator. The output contains 'TIME;VALUE' as header and then the time and memory values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost monitoring 0 USED_MEMORY --unit G --n 10 --csv ';'\n```\n\n----------------------------------------\n\nTITLE: Display VM LCM State using onevm show\nDESCRIPTION: This command displays the LCM_STATE of a specific Virtual Machine.  It's used to check the current state of the VM during troubleshooting.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 2|grep LCM_STATE\n```\n\n----------------------------------------\n\nTITLE: Define OneFlow Service Template in OneProvision (YAML)\nDESCRIPTION: This snippet defines a OneFlow service template in OneProvision using YAML. It includes the name, deployment type, and roles (frontend and backend), with each role specifying a VM template. This configures a basic service deployment with dependencies on VM templates.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nflowtemplates:\n  - name: \"test_service\"\n    deployment: \"straight\"\n    roles:\n      - name: \"frontend\"\n        vm_template: 0\n      - name: \"backend\"\n        vm_template: 1\n```\n\n----------------------------------------\n\nTITLE: Configuring Ansible Inventory (ansible.cfg)\nDESCRIPTION: This snippet shows the configuration of the ansible.cfg file. It sets up inventory, gathering, host key checking, and other essential Ansible parameters for managing OpenNebula deployment. Note that `collections_paths` needs to be updated with the correct `one-deploy` directory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_11\n\nLANGUAGE: ini\nCODE:\n```\n[defaults]\ninventory=./shared.yml\ngathering=explicit\nhost_key_checking=false\ndisplay_skipped_hosts=true\nretry_files_enabled=false\nany_errors_fatal=true\nstdout_callback=yaml\ntimeout=30\ncollections_paths=/home/user/one-deploy/ansible_collections\n\n[ssh_connection]\npipelining=true\nssh_args=-q -o ControlMaster=auto -o ControlPersist=60s\n\n[privilege_escalation]\nbecome      = true\nbecome_user = root\n```\n\n----------------------------------------\n\nTITLE: Creating a DATABLOCK Image in OpenNebula\nDESCRIPTION: This command creates a DATABLOCK image in OpenNebula, which serves as the installation disk for the OS. The `oneimage create` command is used with various options: `--name` sets the image name, `--description` provides a description, `--type` specifies the image type as DATABLOCK, `--persistent` makes the image persistent, `--prefix` sets the disk prefix, `--driver` defines the driver as qcow2, `--size` sets the image size in MB, and `--datastore` specifies the datastore. This image will be used for OS installation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/creating_images.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage create --name centos7 --description \"Base CentOS 7 Installation\" --type DATABLOCK --persistent --prefix vd --driver qcow2 --size 10240 --datastore default\n```\n\n----------------------------------------\n\nTITLE: Installing Open vSwitch with DPDK Support\nDESCRIPTION: This snippet provides commands to install the DPDK version of Open vSwitch, update alternatives, and configure OVS to initialize DPDK.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# apt install openvswitch-switch-dpdk\n\n# update-alternatives --set ovs-vswitchd /usr/lib/openvswitch-switch-dpdk/ovs-vswitchd-dpdk\n\n# ovs-vsctl set Open_vSwitch . other_config:dpdk-init=true\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic OS Profile in YAML\nDESCRIPTION: This YAML snippet demonstrates a basic OS profile that pre-fills the VM template name, CPU, memory configuration, and sets up a backup strategy. It defines settings under 'General' and 'Advanced options' sections. The filename (e.g., basic_profile.yaml) serves as the profile identifier in Sunstone.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/os_profile.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# basic_profile.yaml\n\"General\":\n  NAME: \"Example profile\"\n  CPU: 4\n  VCPU: 4\n  MEMORY: 8\n  MEMORYUNIT: \"GB\"\n\n\"Advanced options\":\n  Backup:\n    BACKUP_CONFIG:\n     MODE: \"INCREMENT\"\n     INCREMENT_MODE: \"CBT\"\n     BACKUP_VOLATILE: \"Yes\"\n     FS_FREEZE: \"AGENT\"\n     KEEP_LAST: 7\n```\n\n----------------------------------------\n\nTITLE: OpenNebula State Hook Example (VM - Ruby)\nDESCRIPTION: This Ruby script demonstrates a state hook for OpenNebula VMs. It decodes the VM template passed as a base64-encoded XML string in ARGV[0], extracts the VM ID, and prints a message indicating that the VM is in the PROLOG state. It depends on the 'base64' and 'nokogiri' libraries.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_14\n\nLANGUAGE: ruby\nCODE:\n```\n# Hook template\n#\n#NAME = vm-prolog\n#TYPE = state\n#COMMAND = vm_prolog.rb\n#ARGUMENTS = $TEMPLATE\n#ON = PROLOG\n#RESOURCE = VM\n\n#!/usr/bin/ruby\n\nrequire 'base64'\nrequire 'nokogiri'\n\n#vm_template = Nokogiri::XML(Base64::decode64(STDIN.gets.chomp)) for reading from STDIN\nvm_template = Nokogiri::XML(Base64::decode64(ARGV[0]))\n\nvm_id = vm_template.xpath(\"//ID\").text.to_i\n\nputs \"VM #{vm_id} is in PROLOG state\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Marketplace Appliance from an Image\nDESCRIPTION: This command creates a new Marketplace Appliance from an existing image. It requires specifying a name for the appliance, the ID of the image, and the target marketplace. The example uses the `onemarketapp create` command with the `--name`, `--image`, and `--market` options.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/marketapps.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nonemarketapp create --name 'Alipe-Vanilla' --image 0 --market \"Backup\"\n```\n\n----------------------------------------\n\nTITLE: Creating the On-Premises Provider using oneprovider\nDESCRIPTION: This command creates the onprem provider in OpenNebula using the provided YAML configuration file. It requires the `oneprovider` tool to be available in the system's PATH.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/onprem_provider.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\noneprovider create /usr/share/one/oneprovision/edge-clusters/metal/providers/onprem/onprem.yml\n```\n\n----------------------------------------\n\nTITLE: Allocating a New Host\nDESCRIPTION: This snippet allocates a new host with the specified parameters. The parameters are hostname, im_mad, vm_mad, and cluster_id. It requires a valid `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\none.host.allocate('localhost', 'kvm', 'kvm', 0)\n```\n\n----------------------------------------\n\nTITLE: Converting SSH Public Key to PKCS#1 Format\nDESCRIPTION: This snippet converts the public SSH key to PKCS#1 PEM format. Converting the public key format is necessary because OpenNebula's monitoring system expects the public key to be in this specific format.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# ssh-keygen -f /etc/one/onemonitor.pub -e -m pem > /etc/one/onemonitor_pem.pub\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Virtual Networks\nDESCRIPTION: This snippet uses the `onevnet list` command to list the virtual networks created in OpenNebula. It shows the network ID, user, group, name, clusters, bridge, state, leases, and errors.  This verifies that the virtual network has been correctly configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nonevnet list\n```\n\n----------------------------------------\n\nTITLE: Displaying VM Information After Backup Completion in OpenNebula\nDESCRIPTION: This snippet shows how to display VM information after a backup is completed using the `onevm show` command. It allows verification of the backup information in the VM details as well as the associated backup image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 0\nVIRTUAL MACHINE 0 INFORMATION\n```\n\n----------------------------------------\n\nTITLE: Listing VM Templates - OpenNebula CLI\nDESCRIPTION: This snippet shows how to list available VM templates in OpenNebula using the `onetemplate list` command. It displays the template ID, user, group, name, and registration time.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate list\n  ID USER     GROUP    NAME                         REGTIME\n   6 oneadmin oneadmin vm_example            09/28 06:44:07\n```\n\n----------------------------------------\n\nTITLE: VM to VM Anti-Affinity Configuration\nDESCRIPTION: This snippet shows how to configure VM to VM anti-affinity for a role within a VM Group. It uses the `POLICY` attribute set to `ANTI_AFFINED` to ensure that VMs of the 'workers' role are spread across different hosts, preventing contention. This helps to optimize performance by distributing CPU-bound VMs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/affinity.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nROLE = [\n    NAME   = \"workers\",\n    POLICY = \"ANTI_AFFINED\"\n]\n```\n\n----------------------------------------\n\nTITLE: Creating a System Datastore with onedatastore command\nDESCRIPTION: This example demonstrates how to create a system datastore using the onedatastore command and the configuration file ds.conf. The command outputs the ID of the newly created datastore.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/lvm_drivers.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore create ds.conf\n```\n\n----------------------------------------\n\nTITLE: Verifying Attached Network Interface - OpenNebula CLI\nDESCRIPTION: This snippet demonstrates how to verify that a NIC has been successfully attached to a VM. It uses the `onevm show` command to display the VM's details, including the list of NICs. The output shows two NICs (0 and 1) now attached to the VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_12\n\nLANGUAGE: text\nCODE:\n```\n$ onevm show 2\nVIRTUAL MACHINE 2 INFORMATION\nID                  : 2\nNAME                : centos-server\nSTATE               : ACTIVE\nLCM_STATE           : RUNNING\n\n...\n\n\nVM NICS\nID NETWORK      VLAN BRIDGE   IP              MAC\n 0 net_172        no vbr0     172.16.1.201    02:00:ac:10:00:c9\n                                fe80::400:acff:fe10:c9\n 1 net_172        no vbr0     172.16.1.202    02:00:ac:10:00:ca\n                                fe80::400:acff:fe10:ca\n...\n```\n\n----------------------------------------\n\nTITLE: onecfg diff --format line Usage Example\nDESCRIPTION: This example shows the output of `onecfg diff` command using the `line` format. It demonstrates different operations like `ins` (insert), `set` (set), and `rm` (remove) on various configuration files. The output shows the filename, command, path, and JSON value for each change. It requires the `onecfg` tool to be installed and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/diff_formats.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n/etc/one/cli/oneimage.yaml ins :ID/:adjust false\n/etc/one/cli/oneimage.yaml set :USER/:size 15\n/etc/one/cli/oneimage.yaml set :GROUP/:size 15\n/etc/one/cli/oneimage.yaml ins :NAME/:expand false\n/etc/one/oned.conf set DEFAULT_DEVICE_PREFIX \"\\\"sd\\\"\"\n/etc/one/oned.conf set VM_MAD/\"vcenter\"/ARGUMENTS \"\\\"-p -t 15 -r 0 -s sh vcenter\\\"\"\n/etc/one/oned.conf rm  VM_MAD/\"vcenter\"/DEFAULT\n/etc/one/oned.conf ins HM_MAD/ARGUMENTS \"\\\"-p 2101 -l 2102 -b 127.0.0.1\\\"\"\n/etc/one/oned.conf ins VM_RESTRICTED_ATTR \"\\\"NIC/FILTER\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Adding Hosts to Edge Cluster\nDESCRIPTION: This snippet shows how to add new hosts to an existing provision in the RUNNING state using the `oneprovision host add` command. It requires a provision ID as input and accepts optional parameters like `--amount` for the number of hosts, `--hostnames` for specific hostnames (for onpremise provisioning), and `--host-params` for Ceph cluster configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/cluster_operations.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision host add 0 -d\n2018-11-27 12:43:31 INFO  : Deploying\n2018-11-27 12:43:31 INFO  : Monitoring hosts\n2018-11-27 12:43:31 INFO  : Checking working SSH connection\n2018-11-27 12:43:34 INFO  : Configuring hosts\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision host add 0 -d --hostnames '10.0.0.110,10.0.0.111'\n2018-11-27 12:43:31 INFO  : Deploying\n2018-11-27 12:43:31 INFO  : Monitoring hosts\n2018-11-27 12:43:31 INFO  : Checking working SSH connection\n2018-11-27 12:43:34 INFO  : Configuring hosts\n```\n\n----------------------------------------\n\nTITLE: Defining NIC with NETWORK_MODE and SCHED_REQUIREMENTS in OpenNebula\nDESCRIPTION: This snippet shows how to define a NIC using NETWORK_MODE and SCHED_REQUIREMENTS. NETWORK_MODE is set to \"auto\" and SCHED_REQUIREMENTS specifies scheduling requirements for the NIC, in this case requiring TRAFFIC_TYPE to be \"public\".\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_14\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nNIC = [ NETWORK_MODE = \"auto\",\n            SCHED_REQUIREMENTS = \"TRAFFIC_TYPE=\\\"public\\\"\" ]\n```\n\n----------------------------------------\n\nTITLE: Updating a VM using an array for multiple entries with the same key\nDESCRIPTION: This code updates a VM, using an array to handle multiple entries with the same key, such as DISK. This functionality is available from version 6.8 onwards. Requires a valid VM ID and a `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\none.vm.update(1,\n    {\n      'TEMPLATE': {\n        'NAME': 'test100',\n        'MEMORY': '1024',\n        'DISK': [\n          { 'IMAGE_ID': 1 },\n          { 'IMAGE_ID': 2 },\n        ]\n      }\n    }, 1)\n```\n\n----------------------------------------\n\nTITLE: Creating an Edge Cluster\nDESCRIPTION: This snippet shows how to create a new edge cluster using the `oneprovision create` command. It takes a YAML file as input, which defines the cluster's configuration. The command returns the ID of the created provision.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/cluster_operations.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision create /tmp/provision.yml\nID: 0\n```\n\n----------------------------------------\n\nTITLE: Showing Cluster Details After Adding Host with onecluster\nDESCRIPTION: This snippet displays the 'production' cluster details after adding Host 0. It shows the updated HOSTS section in the `onecluster show` output, confirming that Host 0 is now associated with the cluster. The cluster name or ID is required as a parameter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster show production\nCLUSTER 100 INFORMATION\nID             : 100\nNAME           : production\n\nHOSTS\n0\n\nVNETS\n\nDATASTORES\n```\n\n----------------------------------------\n\nTITLE: Enabling/Disabling OneFlow Auto-Start on Boot\nDESCRIPTION: These commands show how to configure the OneFlow service to automatically start on system boot or to prevent it from automatically starting. It utilizes the 'systemctl enable' and 'systemctl disable' commands.  These commands require root privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oneflow.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl enable  opennebula-flow\n# systemctl disable opennebula-flow\n```\n\n----------------------------------------\n\nTITLE: PCI Short Address Filter Configuration Example\nDESCRIPTION: This configuration filters PCI devices based on their short PCI address (bus:device.func).  The :short_address option allows specifying specific devices based on their location in the PCI bus hierarchy.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\n# The PCI cards list restricted by the :filter option above can be even more\n# filtered by the list of exact PCI addresses (bus:device.func).\n#\n# For example:\n#   :short_address:\n#     - '07:00.0'\n#     - '06:00.0'\n#\n:short_address:\n  - '00:1f.3'\n```\n\n----------------------------------------\n\nTITLE: Marking an Image as Non-Persistent in OpenNebula\nDESCRIPTION: This command changes the image with ID 0 to non-persistent. Non-persistent images lose their data when the VM is terminated. This is useful for temporary or disposable images.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\noneimage nonpersistent 0\n```\n\n----------------------------------------\n\nTITLE: Enabling VM Charters in Sunstone\nDESCRIPTION: This code snippet shows how to enable VM Charters functionality within Sunstone by modifying the `vm-tab.yaml` configuration file. This allows users to create charters, which are essentially pre-defined schedule actions, through the Sunstone interface.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_35\n\nLANGUAGE: text\nCODE:\n```\ninfo-tabs:\n  sched_actions:\n    enabled: true\n    actions:\n      charter_create: true\n```\n\n----------------------------------------\n\nTITLE: Subscribing to OpenNebula Events using ZeroMQ in Ruby\nDESCRIPTION: This Ruby script demonstrates how to subscribe to OpenNebula events using ZeroMQ. It initializes a ZeroMQ context and subscriber socket, connects to the event stream, subscribes to events with the key \"EVENT\", and then enters a loop to receive and print the key and content of each event message. The content is Base64 encoded, requiring decoding before printing. Dependencies: ffi-rzmq, base64\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_19\n\nLANGUAGE: ruby\nCODE:\n```\n#!/usr/bin/ruby\n\nrequire 'ffi-rzmq'\nrequire 'base64'\n\n@context    = ZMQ::Context.new(1)\n@subscriber = @context.socket(ZMQ::SUB)\n\n@subscriber.setsockopt(ZMQ::SUBSCRIBE, \"EVENT\")\n@subscriber.connect(\"tcp://localhost:2101\")\n\nkey = ''\ncontent = ''\n\nloop do\n    @subscriber.recv_string(key)\n    @subscriber.recv_string(content)\n\n    puts \"Key: #{key}\\nContent: #{Base64.decode64(content)}\"\n    puts \"\\n===================================================================\\n\"\nend\n```\n\n----------------------------------------\n\nTITLE: Disabling SELinux in /etc/selinux/config (Bash)\nDESCRIPTION: This snippet shows how to disable SELinux by modifying the /etc/selinux/config file. This is generally not recommended for production environments due to security concerns, but can be used for temporary troubleshooting or in non-production setups. A reboot is required for the changes to take effect.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/selinux.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSELINUX=disabled\n```\n\n----------------------------------------\n\nTITLE: Restarting Open vSwitch Service and Checking DPDK Status\nDESCRIPTION: This snippet demonstrates how to restart the Open vSwitch service and verify if DPDK is enabled by checking the logs and querying the OVS configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl restart openvswitch-switch.service\n\n# grep DPDK openvswitch/ovs-vswitchd.log\n2022-11-24T12:30:24.500Z|00041|dpdk|ERR|DPDK not supported in this copy of Open vSwitch.\n2022-11-24T12:33:02.905Z|00007|dpdk|INFO|Using DPDK 21.11.2\n2022-11-24T12:33:02.905Z|00008|dpdk|INFO|DPDK Enabled - initializing...\n2022-11-24T12:33:02.905Z|00012|dpdk|INFO|Per port memory for DPDK devices disabled.\n2022-11-24T12:33:02.914Z|00016|dpdk|INFO|EAL: Detected shared linkage of DPDK\n2022-11-24T12:33:04.303Z|00032|dpdk|INFO|DPDK Enabled - initialized\n\n# ovs-vsctl get Open_vSwitch . dpdk_initialized\ntrue\n```\n\n----------------------------------------\n\nTITLE: Generating a libvirt secret for Ceph user\nDESCRIPTION: This snippet generates a UUID, creates an XML file defining a libvirt secret for the Ceph user, and copies the XML file to the oneadmin home directory on the OpenNebula node. The UUID needs to be recorded for later use.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ UUID=`uuidgen`; echo $UUID\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ cat > secret.xml <<EOF\n<secret ephemeral='no' private='no'>\n  <uuid>$UUID</uuid>\n  <usage type='ceph'>\n          <name>client.libvirt secret</name>\n  </usage>\n</secret>\nEOF\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ scp secret.xml oneadmin@node:\n```\n\n----------------------------------------\n\nTITLE: Image Datastore Template Configuration for LVM\nDESCRIPTION: This configuration defines the parameters for creating a new LVM Image Datastore. It sets the DS_MAD to fs, the TM_MAD to fs_lvm_ssh, and the DISK_TYPE to BLOCK. It also sets the TYPE to IMAGE_DS, and the SAFE_DIRS which is the directory were temporary files will be stored.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/lvm_drivers.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nNAME = production\nDS_MAD = fs\nTM_MAD = fs_lvm_ssh\nDISK_TYPE = \"BLOCK\"\nTYPE = IMAGE_DS\nSAFE_DIRS=\"/var/tmp /tmp\"\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL Server in onegate-server.conf (OpenNebula)\nDESCRIPTION: This snippet shows how to configure the `:ssl_server` parameter in the `/etc/one/onegate-server.conf` file.  This parameter defines the address that OneGate will use for secure HTTPS connections.  The provided example uses `https://one.example.com`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_10\n\nLANGUAGE: ruby\nCODE:\n```\n:ssl_server: https://one.example.com\n```\n\n----------------------------------------\n\nTITLE: Changing serveradmin Password\nDESCRIPTION: This snippet shows how to change the password for the 'serveradmin' user in OpenNebula. It utilizes the 'oneuser passwd' command with the '--sha256' flag for password hashing. The new password must be updated in the oneflow_auth, onegate_auth, and sunstone_auth files. Sunstone service restart is required.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# oneuser passwd 1 --sha256 <PASSWORD>\n# echo 'serveradmin:PASSWORD' > /var/lib/one/.one/oneflow_auth\n# echo 'serveradmin:PASSWORD' > /var/lib/one/.one/onegate_auth\n# echo 'serveradmin:PASSWORD' > /var/lib/one/.one/sunstone_auth\n```\n\n----------------------------------------\n\nTITLE: VM Template DISK Definition with IMAGE Name and Owner\nDESCRIPTION: This snippet shows how to define a DISK in a VM template using the IMAGE name and owner (IMAGE_UNAME). This is useful to prevent naming conflicts and ensures the correct image is used, especially when multiple images share the same name.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_28\n\nLANGUAGE: none\nCODE:\n```\nDISK = [ IMAGE       = \"Ubuntu\",\n             IMAGE_UNAME = \"oneadmin\" ]\n```\n\n----------------------------------------\n\nTITLE: Configuring FireEdge Zone Bash\nDESCRIPTION: This configures the FireEdge server on the slave node to specify the zone it represents.  It sets the zone ID, name, and endpoint for communication. Modifying the /etc/one/fireedge-server.conf file requires Fireedge restart.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ndefault_zone:\n    id: 100 //ID\n    name: 'Slave' // NAME\n    endpoint: 'http://<slave-ip>:2633/RPC2' //ENDPOINT\n```\n\n----------------------------------------\n\nTITLE: Managing VM Permissions using onevm chmod\nDESCRIPTION: The `onevm chmod` command modifies the permissions of a VM. The example sets permissions for the VM with ID 0 to 640, which means the owner has read and write permissions, the group has read-only permissions, and others have no permissions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_42\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm chmod 0 640\n```\n\n----------------------------------------\n\nTITLE: Creating a Group with Admin User and Resource Limits\nDESCRIPTION: This command creates a new group with a specified admin user, password, and resource limits. It uses the `onegroup create` command with the `--name`, `--admin_user`, `--admin_password`, and `--resources` options.  It requires the `onegroup` command-line tool.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_groups.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onegroup create --name groupA \\\n--admin_user admin_userA --admin_password somestr \\\n--resources TEMPLATE+VM\n```\n\n----------------------------------------\n\nTITLE: Defining a Vector Attribute in OpenNebula Template\nDESCRIPTION: Demonstrates the syntax for defining a vector attribute, which can contain multiple name-value pairs. The attribute name and vector contents are enclosed in square brackets. Vector attributes must contain at least one value.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_1\n\nLANGUAGE: none\nCODE:\n```\nNAME=[NAME1=VALUE1,NAME2=VALUE2]\n```\n\n----------------------------------------\n\nTITLE: Configuring Inherited Attributes in OpenNebula\nDESCRIPTION: This code snippet shows how to configure inherited attributes in OpenNebula. These attributes are copied from the resource template to the instantiated VMs. Includes attributes for IMAGE, DATASTORE and VNET.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n#INHERIT_IMAGE_ATTR     = \"EXAMPLE\"\n#INHERIT_IMAGE_ATTR     = \"SECOND_EXAMPLE\"\n#INHERIT_DATASTORE_ATTR = \"COLOR\"\n#INHERIT_VNET_ATTR      = \"BANDWIDTH_THROTTLING\"\n\nINHERIT_DATASTORE_ATTR  = \"CEPH_HOST\"\nINHERIT_DATASTORE_ATTR  = \"CEPH_SECRET\"\nINHERIT_DATASTORE_ATTR  = \"CEPH_USER\"\nINHERIT_DATASTORE_ATTR  = \"CEPH_CONF\"\nINHERIT_DATASTORE_ATTR  = \"POOL_NAME\"\n\nINHERIT_DATASTORE_ATTR  = \"ISCSI_USER\"\nINHERIT_DATASTORE_ATTR  = \"ISCSI_USAGE\"\nINHERIT_DATASTORE_ATTR  = \"ISCSI_HOST\"\n\nINHERIT_IMAGE_ATTR      = \"ISCSI_USER\"\nINHERIT_IMAGE_ATTR      = \"ISCSI_USAGE\"\nINHERIT_IMAGE_ATTR      = \"ISCSI_HOST\"\nINHERIT_IMAGE_ATTR      = \"ISCSI_IQN\"\n\nINHERIT_DATASTORE_ATTR  = \"GLUSTER_HOST\"\nINHERIT_DATASTORE_ATTR  = \"GLUSTER_VOLUME\"\n\nINHERIT_DATASTORE_ATTR  = \"DISK_TYPE\"\nINHERIT_DATASTORE_ATTR  = \"ADAPTER_TYPE\"\n\nINHERIT_IMAGE_ATTR      = \"DISK_TYPE\"\nINHERIT_IMAGE_ATTR      = \"ADAPTER_TYPE\"\n\nINHERIT_VNET_ATTR       = \"VLAN_TAGGED_ID\"\nINHERIT_VNET_ATTR       = \"FILTER_IP_SPOOFING\"\nINHERIT_VNET_ATTR       = \"FILTER_MAC_SPOOFING\"\nINHERIT_VNET_ATTR       = \"MTU\"\nINHERIT_VNET_ATTR       = \"METRIC\"\nINHERIT_VNET_ATTR       = \"CVLANS\"\nINHERIT_VNET_ATTR       = \"QINQ_TYPE\"\n```\n\n----------------------------------------\n\nTITLE: Verifying Connectivity with Ping\nDESCRIPTION: This snippet demonstrates how to use the Ansible `ping` module to verify connectivity between nodes. The `-i shared.yml` option specifies the inventory file, `all` targets all hosts in the inventory, and `-b` enables privilege escalation (become). Successful output shows `ping: pong` for each host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nansible -i shared.yml all -m ping -b\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Container VNC Configuration Example\nDESCRIPTION: This snippet shows how to configure remote access to containers via the VNC protocol. It defines the GRAPHICS attribute in the container template, specifying the listen address and VNC type, enabling users to remotely access and manage the container's graphical interface.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_driver.rst#_snippet_3\n\nLANGUAGE: none\nCODE:\n```\nGRAPHICS=[\n  LISTEN=\"0.0.0.0\",\n  TYPE=\"VNC\" ]\n```\n\n----------------------------------------\n\nTITLE: ACL Rule Example - OpenNebula\nDESCRIPTION: This ACL rule grants user 5 the USE and MANAGE rights for Images and Templates within group 103.  It showcases the ACL rule syntax.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_4\n\nLANGUAGE: \nCODE:\n```\n#5 IMAGE+TEMPLATE/@103 USE+MANAGE #0\n```\n\n----------------------------------------\n\nTITLE: Displaying Host PCI Device Information\nDESCRIPTION: This command retrieves the PCI device information from a host using `onehost show -j <host_id>`. The output is in JSON format and includes details like the PCI address, class, vendor, device name, UUID, and available vGPU profiles (PROFILES).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nonehost show -j 13\n```\n\n----------------------------------------\n\nTITLE: Defining VM Template in Provision Template YAML\nDESCRIPTION: This code snippet demonstrates how to define a VM template within an OpenNebula provision template using YAML. It shows the template's name, memory, and CPU allocation. This is an alternative to creating the VM template with the 'onetemplate create template.tpl' command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/template.rst#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ntemplates:\n  - name: \"test_template\"\n    memory: 1\n    cpu: 1\n```\n\n----------------------------------------\n\nTITLE: Sample Application Monitoring Script\nDESCRIPTION: This is a bash script template provided by OpenNebula for application monitoring. The script's primary purpose is to illustrate the structure of an application monitoring script within the OpenNebula environment. It includes copyright information and license details for the OpenNebula project.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\n\n# -------------------------------------------------------------------------- #\n# Copyright 2002-2022, OpenNebula Project, OpenNebula Systems                #\n#                                                                            #\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may    #\n# not use this file except in compliance with the License. You may obtain    #\n# a copy of the License at                                                   #\n#                                                                            #\n# http://www.apache.org/licenses/LICENSE-2.0                                 #\n#                                                                            #\n# Unless required by applicable law or agreed to in writing, software        #\n# distributed under the License is distributed on an \"AS IS\" BASIS,          #\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   #\n# See the License for the specific language governing permissions and        #\n# limitations under the License.                                             #\n#--------------------------------------------------------------------------- #\n\n################################################################################\n# Initialization\n################################################################################\n\nERROR=0\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Enterprise Repository on Ubuntu 22.04\nDESCRIPTION: This bash script adds the OpenNebula Enterprise Edition repository to the Ubuntu 22.04 system. It creates a `/etc/apt/sources.list.d/opennebula.list` file with the repository configuration, including the base URL (which requires a customer-specific token) and specifies the GPG key file. The script then updates the apt package list.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# echo \\\"deb [signed-by=/etc/apt/keyrings/opennebula.gpg] https://<token>@enterprise.opennebula.io/repo/|version|/Ubuntu/22.04 stable opennebula\\\" > /etc/apt/sources.list.d/opennebula.list\n# apt-get update\n```\n\n----------------------------------------\n\nTITLE: Instantiate Service Template using OneFlow CLI\nDESCRIPTION: This code snippet shows how to instantiate a service template using the `oneflow-template instantiate` command in the OneFlow CLI. The command takes the ID of the service template as an argument and returns the ID of the newly created service.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n$ oneflow-template instantiate 0\nID: 1\n```\n\n----------------------------------------\n\nTITLE: Defining PCI Device by Short Address in OpenNebula\nDESCRIPTION: This snippet shows how to define a PCI device by specifying its short address. This method allows selecting a specific PCI device for passthrough.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_17\n\nLANGUAGE: text\nCODE:\n```\nPCI = [\n  SHORT_ADDRESS = \"00:03.0\"\n]\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Log Format - oned and VM events\nDESCRIPTION: This code snippet displays the log format for both the 'oned' daemon and virtual machine events in OpenNebula. It encompasses the date, zone ID, module, log level, and the actual message, which is essential for tracing and resolving issues. It differentiates between generic oned logs and VM-specific logs by including the VM ID in the latter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_3\n\nLANGUAGE: none\nCODE:\n```\ndate [Z<zone_id>][module][log_level]: message\ndate [VM id][Z<zone_id>][module][log_level]: message\n```\n\n----------------------------------------\n\nTITLE: Set Image Ownership and Permissions in OneProvision (YAML)\nDESCRIPTION: This snippet demonstrates setting the ownership (UID and GID) and permissions (mode) for an image in OneProvision using YAML.  The `meta` section includes `uid`, `gid`, and `mode` attributes to control the image's ownership and access permissions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nimages:\n    - name: \"test_image\"\n      ds_id: 1\n      size: 2048\n      meta:\n        uid: 1\n        gid: 1\n        mode: 644\n```\n\n----------------------------------------\n\nTITLE: Adding a Cluster to a VDC with onevdc\nDESCRIPTION: This command adds a Cluster to a VDC. `<vdc_id>` is the ID of the VDC, `0` represents the Zone ID, and `7` is the Cluster ID.  This assigns the resources of Cluster 7 in Zone 0 to the specified VDC.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_vdcs.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onevdc addcluster <vdc_id > 0 7\n```\n\n----------------------------------------\n\nTITLE: Instantiating a VM from a Template\nDESCRIPTION: This snippet instantiates a virtual machine from a virtual machine template using the `onetemplate instantiate` command. It specifies the template ID (3). This requires the OpenNebula CLI tool to be installed and configured.  The output is the ID of the created VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ onetemplate instantiate 3\nVM ID:11\n```\n\n----------------------------------------\n\nTITLE: Configuring OneGate Endpoint in OpenNebula\nDESCRIPTION: This code snippet shows how to configure the OneGate endpoint in OpenNebula. The `ONEGATE_ENDPOINT` attribute specifies the endpoint where OneGate will be listening.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\nONEGATE_ENDPOINT = \"http://192.168.0.5:5030\"\n```\n\n----------------------------------------\n\nTITLE: Add Image to RDM Datastore\nDESCRIPTION: This example demonstrates how to add a new image to the RDM Datastore by specifying the path to a Node disk.  The PATH attribute points to the existing block device. PERSISTENT is set to YES, meaning the image will remain after the VM is terminated.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/dev_ds.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ cat image.tmpl\nNAME=scsi_device\nPATH=/dev/sdb\nPERSISTENT=YES\n\n$ oneimage create image.tmpl -d 101\n```\n\n----------------------------------------\n\nTITLE: Activate OpenNebula Provider using Symbolic Links (bash)\nDESCRIPTION: This snippet enables a specific OpenNebula provider by creating symbolic links for the provider and the virtual provisions. It links the provider configuration file and enables virtual provisions by linking the edge clusters configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/activate_virtual.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nln -s /etc/one/fireedge/provision/providers.d-extra/\\ |PROVIDER|\\  /etc/one/fireedge/provision/providers.d\nln -s /usr/share/one/oneprovision/edge-clusters-extra/virtual /usr/share/one/oneprovision/edge-clusters\n```\n\n----------------------------------------\n\nTITLE: Modify Virtual Network Template Permissions\nDESCRIPTION: This snippet demonstrates how to modify Virtual Network Template permissions using the 'onevntemplate chmod' command.  It sets the permissions to allow all users to instantiate the template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vn_templates.rst#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ onevntemplate chmod 0 604\n```\n\n----------------------------------------\n\nTITLE: Instantiating Service Template with custom VM capacity using curl\nDESCRIPTION: This curl command demonstrates how to instantiate a service template and customize the virtual machine capacity using the 'merge_template' and 'template_contents' parameters. It uses the POST method to the /service_template/4/action endpoint, specifying the 'instantiate' action and providing the desired capacity settings within a JSON payload. Authentication uses 'oneadmin:password'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service_template/4/action -u 'oneadmin:password' -v -X POST --data '{\n  \"action\": {\n    \"perform\":\"instantiate\",\n    \"params\":{\n      \"merge_template\": {\n        \"template_contents\": {\n          \"HOT_RESIZE\": {\n            \"CPU_HOT_ADD_ENABLED\": \"YES\",\n            \"MEMORY_HOT_ADD_ENABLED\": \"YES\"\n          },\n          \"MEMORY_RESIZE_MODE\": \"BALLOONING\",\n          \"VCPU_MAX\": \"2\",\n          \"MEMORY_MAX\": \"128\"\n        }\n      }\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Hold IP Address in Specific AR - onevnet Command\nDESCRIPTION: This command puts a specific IP address on hold within a specified Address Range (AR) of a virtual network. It uses the `onevnet hold` command with the `-a` option to specify the AR ID. The IP address will not be assigned within that AR.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n#Hold IP 10.0.0.123 in AR 0\n$ onevnet hold 0 10.0.0.123 -a 0\n```\n\n----------------------------------------\n\nTITLE: Defining OpenNebula Accounting XML Schema\nDESCRIPTION: This XML schema defines the structure for OpenNebula accounting records.  It specifies the elements and attributes within HISTORY_RECORDS and HISTORY elements, including data types and occurrences. It details VM properties like ID, state, CPU, memory usage, network traffic, and timestamps for start and end times. It also describes possible ACTION values such as migrate, shutdown, and terminate.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/accounting.rst#_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<xs:schema xmlns:xs=\"http://www.w3.org/2001/XMLSchema\" elementFormDefault=\"qualified\"\ntargetNamespace=\"http://opennebula.org/XMLSchema\" xmlns=\"http://opennebula.org/XMLSchema\">\n\n\t<xs:element name=\"HISTORY_RECORDS\">\n\t\t<xs:complexType>\n\t\t<xs:sequence maxOccurs=\"1\" minOccurs=\"1\">\n\t\t\t<xs:element ref=\"HISTORY\" maxOccurs=\"unbounded\" minOccurs=\"0\"/>\n\t\t</xs:sequence>\n\t\t</xs:complexType>\n\t</xs:element>\n\n\t<xs:element name=\"HISTORY\">\n\t\t<xs:complexType>\n\t\t<xs:sequence>\n\t\t\t<xs:element name=\"OID\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"SEQ\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"HOSTNAME\" type=\"xs:string\"/>\n\t\t\t<xs:element name=\"HID\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"CID\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"STIME\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"ETIME\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"VM_MAD\" type=\"xs:string\"/>\n\t\t\t<xs:element name=\"TM_MAD\" type=\"xs:string\"/>\n\t\t\t<xs:element name=\"DS_ID\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"PSTIME\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"PETIME\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"RSTIME\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"RETIME\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"ESTIME\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"EETIME\" type=\"xs:integer\"/>\n\n\t\t\t<!-- ACTION values:\n\t\t\tNONE_ACTION             = 0\n\t\t\tMIGRATE_ACTION          = 1\n\t\t\tLIVE_MIGRATE_ACTION     = 2\n\t\t\tSHUTDOWN_ACTION         = 3\n\t\t\tSHUTDOWN_HARD_ACTION    = 4\n\t\t\tUNDEPLOY_ACTION         = 5\n\t\t\tUNDEPLOY_HARD_ACTION    = 6\n\t\t\tHOLD_ACTION             = 7\n\t\t\tRELEASE_ACTION          = 8\n\t\t\tSTOP_ACTION             = 9\n\t\t\tSUSPEND_ACTION           = 10\n\t\t\tRESUME_ACTION            = 11\n\t\t\tBOOT_ACTION              = 12\n\t\t\tDELETE_ACTION            = 13\n\t\t\tDELETE_RECREATE_ACTION  = 14\n\t\t\tREBOOT_ACTION            = 15\n\t\t\tREBOOT_HARD_ACTION       = 16\n\t\t\tRESCHED_ACTION           = 17\n\t\t\tUNRESCHED_ACTION         = 18\n\t\t\tPOWEROFF_ACTION          = 19\n\t\t\tPOWEROFF_HARD_ACTION     = 20\n\t\t\tDISK_ATTACH_ACTION       = 21\n\t\t\tDISK_DETACH_ACTION       = 22\n\t\t\tNIC_ATTACH_ACTION        = 23\n\t\t\tNIC_DETACH_ACTION        = 24\n\t\t\tDISK_SNAPSHOT_CREATE_ACTION = 25\n\t\t\tDISK_SNAPSHOT_DELETE_ACTION = 26\n\t\t\tTERMINATE_ACTION         = 27\n\t\t\tTERMINATE_HARD_ACTION    = 28\n\t\t\tDISK_RESIZE_ACTION       = 29\n\t\t\tDEPLOY_ACTION            = 30\n\t\t\tCHOWN_ACTION             = 31\n\t\t\tCHMOD_ACTION             = 32\n\t\t\tUPDATECONF_ACTION        = 33\n\t\t\tRENAME_ACTION            = 34\n\t\t\tRESIZE_ACTION            = 35\n\t\t\tUPDATE_ACTION            = 36\n\t\t\tSNAPSHOT_CREATE_ACTION   = 37\n\t\t\tSNAPSHOT_DELETE_ACTION   = 38\n\t\t\tSNAPSHOT_REVERT_ACTION   = 39\n\t\t\tDISK_SAVEAS_ACTION       = 40\n\t\t\tDISK_SNAPSHOT_REVERT_ACTION = 41\n\t\t\tRECOVER_ACTION           = 42\n\t\t\tRETRY_ACTION             = 43\n\t\t\tMONITOR_ACTION           = 44\n\t\t\tDISK_SNAPSHOT_RENAME_ACTION = 45\n\t\t\t-->\n\t\t\t<xs:element name=\"ACTION\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"UID\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"GID\" type=\"xs:integer\"/>\n\t\t\t<xs:element name=\"REQUEST_ID\" type=\"xs:string\"/>\n\t\t\t<xs:element name=\"VM\">\n\t\t\t<xs:complexType>\n\t\t\t\t<xs:sequence>\n\t\t\t\t<xs:element name=\"ID\" type=\"xs:integer\"/>\n\t\t\t\t<xs:element name=\"UID\" type=\"xs:integer\"/>\n\t\t\t\t<xs:element name=\"GID\" type=\"xs:integer\"/>\n\t\t\t\t<xs:element name=\"UNAME\" type=\"xs:string\"/>\n\t\t\t\t<xs:element name=\"GNAME\" type=\"xs:string\"/>\n\t\t\t\t<xs:element name=\"NAME\" type=\"xs:string\"/>\n\t\t\t\t<xs:element name=\"PERMISSIONS\" minOccurs=\"0\" maxOccurs=\"1\">\n\t\t\t\t\t<xs:complexType>\n\t\t\t\t\t<xs:sequence>\n\t\t\t\t\t\t<xs:element name=\"OWNER_U\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"OWNER_M\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"OWNER_A\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"GROUP_U\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"GROUP_M\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"GROUP_A\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"OTHER_U\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"OTHER_M\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"OTHER_A\" type=\"xs:integer\"/>\n\t\t\t\t\t</xs:sequence>\n\t\t\t\t\t</xs:complexType>\n\t\t\t\t</xs:element>\n\t\t\t\t<xs:element name=\"LAST_POLL\" type=\"xs:integer\"/>\n\n\t\t\t\t<!-- STATE values,\n\t\t\t\tsee http://docs.opennebula.org/stable/user/references/vm_states.html\n\t\t\t\t-->\n\t\t\t\t<xs:element name=\"STATE\" type=\"xs:integer\"/>\n\n\t\t\t\t<!-- LCM_STATE values, this sub-state is relevant only when STATE is\n\t\t\t\t\tACTIVE (4)\n\t\t\t\tsee http://docs.opennebula.org/stable/user/references/vm_states.html\n\t\t\t\t-->\n\t\t\t\t<xs:element name=\"LCM_STATE\" type=\"xs:integer\"/>\n\t\t\t\t<xs:element name=\"PREV_STATE\" type=\"xs:integer\"/>\n\t\t\t\t<xs:element name=\"PREV_LCM_STATE\" type=\"xs:integer\"/>\n\t\t\t\t<xs:element name=\"RESCHED\" type=\"xs:integer\"/>\n\t\t\t\t<xs:element name=\"STIME\" type=\"xs:integer\"/>\n\t\t\t\t<xs:element name=\"ETIME\" type=\"xs:integer\"/>\n\t\t\t\t<xs:element name=\"DEPLOY_ID\" type=\"xs:string\"/>\n\t\t\t\t<xs:element name=\"MONITORING\">\n\t\t\t\t<!--\n\t\t\t\t\t<xs:complexType>\n\t\t\t\t\t<xs:all>\n\t\t\t\t\t\t<- Percentage of 1 CPU consumed (two fully consumed cpu is 200) ->\n\t\t\t\t\t\t<xs:element name=\"CPU\" type=\"xs:decimal\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\n\t\t\t\t\t\t<- MEMORY consumption in kilobytes ->\n\t\t\t\t\t\t<xs:element name=\"MEMORY\" type=\"xs:integer\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\n\t\t\t\t\t\t<- NETTX: Sent bytes to the network ->\n\t\t\t\t\t\t<xs:element name=\"NETTX\" type=\"xs:integer\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\n\t\t\t\t\t\t<- NETRX: Received bytes from the network ->\n\t\t\t\t\t\t<xs:element name=\"NETRX\" type=\"xs:integer\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t</xs:all>\n\t\t\t\t\t</xs:complexType>\n\t\t\t\t-->\n\t\t\t\t</xs:element>\n\t\t\t\t<xs:element name=\"TEMPLATE\" type=\"xs:anyType\"/>\n\t\t\t\t<xs:element name=\"USER_TEMPLATE\" type=\"xs:anyType\"/>\n\t\t\t\t<xs:element name=\"HISTORY_RECORDS\">\n\t\t\t\t</xs:element>\n\t\t\t\t<xs:element name=\"SNAPSHOTS\" minOccurs=\"0\" maxOccurs=\"unbounded\">\n\t\t\t\t\t<xs:complexType>\n\t\t\t\t\t<xs:sequence>\n\t\t\t\t\t\t<xs:element name=\"ALLOW_ORPHANS\" type=\"xs:string\"/>\n\t\t\t\t\t\t<xs:element name=\"CURRENT_BASE\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"DISK_ID\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"NEXT_SNAPSHOT\" type=\"xs:integer\"/>\n\t\t\t\t\t\t<xs:element name=\"SNAPSHOT\" minOccurs=\"0\" maxOccurs=\"unbounded\">\n\t\t\t\t\t\t<xs:complexType>\n\t\t\t\t\t\t\t<xs:sequence>\n\t\t\t\t\t\t\t<xs:element name=\"ACTIVE\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"CHILDREN\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"DATE\" type=\"xs:integer\"/>\n\t\t\t\t\t\t\t<xs:element name=\"ID\" type=\"xs:integer\"/>\n\t\t\t\t\t\t\t<xs:element name=\"NAME\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"PARENT\" type=\"xs:integer\"/>\n\t\t\t\t\t\t\t<xs:element name=\"SIZE\" type=\"xs:integer\"/>\n\t\t\t\t\t\t\t</xs:sequence>\n\t\t\t\t\t\t</xs:complexType>\n\t\t\t\t\t\t</xs:element>\n\t\t\t\t\t</xs:sequence>\n\t\t\t\t\t</xs:complexType>\n\t\t\t\t</xs:element>\n\t\t\t\t<xs:element name=\"BACKUPS\">\n\t\t\t\t\t<xs:complexType>\n\t\t\t\t\t<xs:sequence>\n\t\t\t\t\t\t<xs:element name=\"BACKUP_CONFIG\" minOccurs=\"1\" maxOccurs=\"1\">\n\t\t\t\t\t\t<xs:complexType>\n\t\t\t\t\t\t\t<xs:sequence>\n\t\t\t\t\t\t\t<xs:element name=\"BACKUP_VOLATILE\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"FS_FREEZE\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"INCREMENTAL_BACKUP_ID\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"KEEP_LAST\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"LAST_BACKUP_ID\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"LAST_BACKUP_SIZE\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"LAST_DATASTORE_ID\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"LAST_INCREMENT_ID\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t<xs:element name=\"MODE\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"1\"/>\n\t\t\t\t\t\t\t</xs:sequence>\n\t\t\t\t\t\t</xs:complexType>\n\t\t\t\t\t\t</xs:element>\n\t\t\t\t\t\t<xs:element name=\"BACKUP_IDS\" minOccurs=\"1\" maxOccurs=\"1\">\n\t\t\t\t\t\t<xs:complexType>\n\t\t\t\t\t\t\t<xs:sequence>\n\t\t\t\t\t\t\t<xs:element name=\"ID\" type=\"xs:string\" minOccurs=\"0\" maxOccurs=\"unbounded\"/>\n\t\t\t\t\t\t\t</xs:sequence>\n\t\t\t\t\t\t</xs:complexType>\n\t\t\t\t\t\t</xs:element>\n\t\t\t\t\t</xs:sequence>\n\t\t\t\t\t</xs:complexType>\n\t\t\t\t</xs:element>\n\t\t\t\t</xs:sequence>\n\t\t\t</xs:complexType>\n\t\t\t</xs:element>\n\t\t</xs:sequence>\n\t\t</xs:complexType>\n\t</xs:element>\n</xs:schema>\n```\n\n----------------------------------------\n\nTITLE: RDM Datastore TM_MAD Configuration\nDESCRIPTION: This configuration snippet defines the TM_MAD settings for the RDM Datastore in the oned.conf file. It specifies the Transfer Manager driver as 'raw', the cloning and linking targets, and the disk types for SSH and shared storage.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/dev_ds.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nTM_MAD_CONF = [\n        NAME = \"dev\", LN_TARGET = \"NONE\", CLONE_TARGET = \"NONE\", SHARED = \"YES\",\n        TM_MAD_SYSTEM = \"ssh,shared\",\n        LN_TARGET_SSH = \"SYSTEM\", LN_TARGET_SHARED = \"NONE\",\n        DISK_TYPE_SSH = \"FILE\", DISK_TYPE_SHARED = \"FILE\",\n        CLONE_TARGET_SSH = \"SYSTEM\", CLONE_TARGET_SHARED =  \"SELF\",\n        DRIVER = \"raw\"\n    ]\n```\n\n----------------------------------------\n\nTITLE: Attaching a PCI Device to a Virtual Machine\nDESCRIPTION: This command attaches a PCI device to a virtual machine. The first example attaches a PCI device to the VM named 'alpine01' based on its class, device ID, and vendor ID. The second example detaches PCI device with ID '0' from VM 'alpine01'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm pci-attach alpine01 --pci_class 0c03 --pci_device 0015 --pci_vendor 1912\n$ onevm pci-detach alpine01 0\n```\n\n----------------------------------------\n\nTITLE: Managing OpenNebula Service with systemctl\nDESCRIPTION: This code snippet demonstrates how to manage the OpenNebula service using `systemctl`. It includes commands for starting, restarting, stopping, enabling, and disabling the service.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl start   opennebula\n# systemctl restart opennebula\n# systemctl stop    opennebula\n```\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl enable  opennebula\n# systemctl disable opennebula\n```\n\nLANGUAGE: bash\nCODE:\n```\n# journalctl -u opennebula.service\n```\n\n----------------------------------------\n\nTITLE: Checking Default Route inside Network Namespace\nDESCRIPTION: This command checks if the default route for sending packets back into the bridge has been configured within the network namespace.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ ip netns exec one_tproxy_br0 ip route\ndefault dev br0a scope link\n```\n\n----------------------------------------\n\nTITLE: Purging VM History Records\nDESCRIPTION: The 'onedb purge-history' command deletes history records for VMs. It allows specifying start and end dates for deletion. It can also purge history records for specific VMs using the --id parameter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_14\n\nLANGUAGE: text\nCODE:\n```\n$ onedb purge-history --start 2008/07/24 --end 2023/06/14\n```\n\nLANGUAGE: text\nCODE:\n```\n$ onedb purge-history --id <vm_id>\n```\n\n----------------------------------------\n\nTITLE: Defining libvirt secret and removing key files\nDESCRIPTION: This snippet defines a libvirt secret using the XML file, sets the secret value using the Ceph user key, and then removes the original key file from the node. This enhances security by not leaving the key file exposed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ virsh -c qemu:///system secret-define secret.xml\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ virsh -c qemu:///system secret-set-value --secret $UUID --base64 $(cat client.libvirt.key)\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ rm client.libvirt.key\n```\n\n----------------------------------------\n\nTITLE: Start, Restart, or Stop FireEdge Service (systemctl)\nDESCRIPTION: These commands are used to manage the FireEdge service using `systemctl`. The `start`, `restart`, and `stop` commands control the service's running state. They require systemd and appropriate privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/fireedge.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ systemctl start   opennebula-fireedge\n$ systemctl restart opennebula-fireedge\n$ systemctl stop    opennebula-fireedge\n```\n\n----------------------------------------\n\nTITLE: Getting Kubernetes nodes using kubectl\nDESCRIPTION: This command checks the status of the Kubernetes nodes. It requires `kubectl` to be configured and connected to the Kubernetes cluster. The output shows the name, status, roles, age, and version of each node. We are looking for the nodes to be in Ready state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nroot@oneke-ip-172-20-0-2:~# kubectl get nodes\nNAME                  STATUS   ROLES                       AGE   VERSION\noneke-ip-172-20-0-2   Ready    control-plane,etcd,master   18m   v1.29.4+rke2r1\noneke-ip-172-20-0-3   Ready    <none>                      16m   v1.29.4+rke2r1\n```\n\n----------------------------------------\n\nTITLE: Synchronizing Specific Hosts in OpenNebula\nDESCRIPTION: This snippet demonstrates how to synchronize driver files to specific hosts by naming them as arguments to the `onehost sync` command. It synchronizes the files on `host01`, `host02`, and `host03`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost sync host01,host02,host03\n```\n\n----------------------------------------\n\nTITLE: Install EPEL Release on RHEL 9 using rpm\nDESCRIPTION: This command installs the epel-release package on RHEL 9 using rpm.  It retrieves the package from the Fedora project's online repository and installs it.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/epel.txt#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm\n```\n\n----------------------------------------\n\nTITLE: Install EPEL Release - AlmaLinux 8/9\nDESCRIPTION: This command installs the Extra Packages for Enterprise Linux (EPEL) release package on AlmaLinux 8 or 9. EPEL provides additional packages not available in the base AlmaLinux repositories, which are required by OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# yum -y install epel-release\n```\n\n----------------------------------------\n\nTITLE: Checking Hugepages Allocation\nDESCRIPTION: This snippet shows how to check if hugepages are allocated to NUMA nodes using grep.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# grep -i '\\<huge' /sys/devices/system/node/node*/meminfo\nNode 0 HugePages_Total: Â  125\nNode 0 HugePages_Free:Â  Â  125\nNode 0 HugePages_Surp:Â  Â  Â  0\nNode 1 HugePages_Total: Â  125\nNode 1 HugePages_Free:Â  Â  125\nNode 1 HugePages_Surp:Â  Â  Â  0\n```\n\n----------------------------------------\n\nTITLE: Dumping PCI device XML information\nDESCRIPTION: This command uses `virsh nodedev-dumpxml` to display detailed XML information about the NVIDIA GPU. This includes vendor ID, product ID, IOMMU group, and the maximum number of virtual functions. The `<capability type='virt_functions' maxCount='32'/>` shows the virtual function count.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nvirsh nodedev-dumpxml pci_0000_41_00_0\n```\n\n----------------------------------------\n\nTITLE: Allowing Password Authentication for SSH\nDESCRIPTION: These commands configure SSH to allow password authentication, restart the SSH service, and add a new user with a password.  This is required for username/password authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_46\n\nLANGUAGE: bash\nCODE:\n```\noneadmin@frontend:~$ ssh root@<guest-vm>\n\n# Allow authentication with password: PasswordAuthentication yes\nroot@<guest-VM>:~$ vi /etc/ssh/sshd_config\n\n# Restart SSH service\nroot@<guest-VM>:~$ service sshd restart\n\n# Add user: username/password\nroot@<guest-VM>:~$ adduser <username>\n```\n\n----------------------------------------\n\nTITLE: Finding NVIDIA GPU PCI address\nDESCRIPTION: This command uses `lspci` to list PCI devices and filters the output to find the NVIDIA GPU. The output provides the PCI address, which is needed for enabling virtual functions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nlspci | grep NVIDIA\n```\n\n----------------------------------------\n\nTITLE: Setting Multiple Certificate DNs for a User\nDESCRIPTION: This command demonstrates how to associate multiple certificate DNs with a single OpenNebula user account. Each DN is separated by a '|' character. This allows a user with multiple certificates to authenticate using any of the associated DNs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\noneuser passwd <id|name> --x509 \"/DC=es/O=one/CN=user|/DC=us/O=two/CN=user\"\n```\n\n----------------------------------------\n\nTITLE: Displaying NVIDIA GPU information\nDESCRIPTION: This command uses the `nvidia-smi` tool to display detailed information about the NVIDIA GPU, including driver version, CUDA version, GPU name, memory usage, and running processes. It verifies the successful installation and recognition of the GPU by the system.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnvidia-smi\n```\n\n----------------------------------------\n\nTITLE: Configuring IM_MAD in oned.conf\nDESCRIPTION: This code snippet shows the configuration of the IM_MAD (Information Manager MAD) within the `/etc/one/oned.conf` file. It defines the executable for the monitoring daemon (onemonitord) and specifies arguments like the configuration file (monitord.conf) and the number of threads.  This driver is responsible for processing monitoring data received from the hypervisors.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nIM_MAD = [\n    NAME       = \"monitord\",\n    EXECUTABLE = \"onemonitord\",\n    ARGUMENTS  = \"-c monitord.conf\",\n    THREADS    = 8 ]\n```\n\n----------------------------------------\n\nTITLE: Switch to oneadmin User (Shell)\nDESCRIPTION: This command switches the current user to the oneadmin user, which is required for performing most OpenNebula administrative tasks.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/replace_failing_fe.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo -i -u oneadmin\n```\n\n----------------------------------------\n\nTITLE: Registering LUKS Image in OpenNebula\nDESCRIPTION: This snippet registers the converted LUKS-encrypted image in OpenNebula using `oneimage create`. It specifies the name, path, datastore, and prefix for the new image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage create --name alpine-3.17_luks --path /tmp/alpine-3.17.luks -d default --prefix vd\n```\n\n----------------------------------------\n\nTITLE: NetApp System Datastore Template\nDESCRIPTION: This code snippet shows an example template file (netapp_system.ds) used to create a system datastore in OpenNebula for NetApp SAN integration. It defines the datastore's name, type, DS_MAD, TM_MAD, disk type, and NetApp specific parameters like host, user, password, SVM, aggregates, and igroup. The `onedatastore create` command is used to create the datastore using the template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/netapp_ds.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ cat netapp_system.ds\nNAME = \"netapp_system\"\nTYPE = \"SYSTEM_DS\"\nDISK_TYPE = \"BLOCK\"\nDS_MAD = \"netapp\"\nTM_MAD = \"netapp\"\nNETAPP_HOST = \"10.1.234.56\"\nNETAPP_USER = \"admin\"\nNETAPP_PASS = \"password\"\nNETAPP_SVM = \"c9dd74bc-8e3e-47f0-b274-61be0b2ccfe3\"\nNETAPP_AGGREGATES = \"280f5971-3427-4cc6-9237-76c3264543d5\"\nNETAPP_IGROUP = \"27702521-68fb-4d9a-9676-efa3018501fc\"\n\n$ onedatastore create netapp_system.ds\nID: 101\n```\n\n----------------------------------------\n\nTITLE: Setting an authentication token in OpenNebula\nDESCRIPTION: This snippet shows how to set an authentication token for the current session using the `oneuser token-set` command. It exports environment variables `ONE_AUTH` and `ONE_EGID` to configure the authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser token-set --token b6\nexport ONE_AUTH=/var/lib/one/.one/5ad20d96-964a-4e09-b550-9c29855e6457.token; export ONE_EGID=-1\n$ export ONE_AUTH=/var/lib/one/.one/5ad20d96-964a-4e09-b550-9c29855e6457.token; export ONE_EGID=-1\n```\n\n----------------------------------------\n\nTITLE: OneDRS Optimization Policy Configuration (YAML)\nDESCRIPTION: Defines workload optimization settings, specifying the scheduling policy and resource weights in a YAML configuration file. This example uses a BALANCE policy and sets the CPU_USAGE weight to 1.0, distributing VMs based on actual CPU utilization.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/drs.rst#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nOPTIMIZE:\n  POLICY: \"BALANCE\"\n  WEIGHTS:\n    CPU_USAGE: 1.0\n```\n\n----------------------------------------\n\nTITLE: Using User Template Variables in OpenNebula VM Template\nDESCRIPTION: Demonstrates how to use a User template variable (SSH_KEY) within an OpenNebula VM template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_24\n\nLANGUAGE: text\nCODE:\n```\nssh_key = \"$USER[SSH_KEY]\"\n```\n\n----------------------------------------\n\nTITLE: Listing Zones Bash\nDESCRIPTION: This command lists all the available OpenNebula zones with their ID and name. This is useful for verifying the creation of the new slave zone and identifying its ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onezone list\n   ID NAME\n    0 OpenNebula\n  100 slave-name\n```\n\n----------------------------------------\n\nTITLE: Defining a Host Error Hook\nDESCRIPTION: This code defines a host hook named `host_error` in OpenNebula. The hook executes the script `ft/host_error.rb` when a host enters the `ERROR` state. The arguments specify the action to be taken on the VMs running on the failed host, such as migrating them to another host or deleting and recreating them.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/vm_ha.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nARGUMENTS       = \"$TEMPLATE -m -p 5\"\nARGUMENTS_STDIN = \"yes\"\nCOMMAND         = \"ft/host_error.rb\"\nNAME            = \"host_error\"\nSTATE           = \"ERROR\"\nREMOTE          = \"no\"\nRESOURCE        = HOST\nTYPE            = state\n```\n\n----------------------------------------\n\nTITLE: onedb MySQL/MariaDB Connection Parameters (Bash)\nDESCRIPTION: Illustrates how to connect to an OpenNebula database using MySQL/MariaDB with the `onedb` command.  Provides connection parameters such as host, user, password, and database name.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onedb <command> -v -S localhost -u oneadmin -p oneadmin -d opennebula\n```\n\n----------------------------------------\n\nTITLE: Security Group Template Example\nDESCRIPTION: This is an example security group template demonstrating inbound/outbound rules for ICMP, TCP (port 22, 80, 443, 1234, 5030), and UDP (port 53). The TCP rules for 1234 and 5030 are required for the Transparent Proxies to function.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_11\n\nLANGUAGE: text\nCODE:\n```\nNAME = \"example0\"\n\nRULE = [\n  PROTOCOL  = \"ICMP\",\n  RULE_TYPE = \"inbound\" ]\nRULE = [\n  PROTOCOL  = \"ICMP\",\n  RULE_TYPE = \"outbound\" ]\n\nRULE = [\n  PROTOCOL  = \"TCP\",\n  RANGE     = \"22\",\n  RULE_TYPE = \"inbound\" ]\nRULE = [\n  PROTOCOL  = \"TCP\",\n  RANGE     = \"80,443\",\n  RULE_TYPE = \"outbound\" ]\n\n# Required for Transparent Proxies\nRULE = [\n  PROTOCOL  = \"TCP\",\n  RANGE     = \"1234,5030\",\n  RULE_TYPE = \"outbound\" ]\n\n# DNS\nRULE = [\n  PROTOCOL  = \"UDP\",\n  RANGE     = \"53\",\n  RULE_TYPE = \"outbound\" ]\n```\n\n----------------------------------------\n\nTITLE: Defining Schedule Action in OpenNebula Template\nDESCRIPTION: This snippet shows how to define a scheduled action for a VM in an OpenNebula template.  It defines the action, days of execution, end type and value, an ID, repeat frequency, the execution time, and a warning time before execution. It shows how actions like suspending a VM can be automated based on time and frequency.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_41\n\nLANGUAGE: text\nCODE:\n```\nSCHED_ACTION=[\n    ACTION=\"suspend\",\n    DAYS=\"1,5\",\n    END_TYPE=\"1\",\n    END_VALUE=\"5\",\n    ID=\"0\",\n    REPEAT=\"0\",\n    TIME=\"1537653600\",\n    WARNING=\"1537567200\" ]\n```\n\n----------------------------------------\n\nTITLE: Managing the opennebula-gate Service (bash)\nDESCRIPTION: These commands show how to start, restart, and stop the `opennebula-gate` service using `systemctl`. They also demonstrate how to enable or disable automatic startup of the service on host boot. These commands require root privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl start   opennebula-gate\n# systemctl restart opennebula-gate\n# systemctl stop    opennebula-gate\n```\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl enable  opennebula-gate\n# systemctl disable opennebula-gate\n```\n\n----------------------------------------\n\nTITLE: Create Image Datastore using CLI\nDESCRIPTION: This snippet demonstrates how to create an image datastore in OpenNebula using the onedatastore CLI tool with the configuration file 'ds.conf' as input. The output confirms the successful creation with the assigned datastore ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/nas_ds.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n$ onedatastore create ds.conf\nID: 100\n```\n\n----------------------------------------\n\nTITLE: Displaying user information in OpenNebula\nDESCRIPTION: This snippet shows the output of the `oneuser show` command, which displays detailed information about a specific user. This includes the user's ID, name, group, and password hash. It confirms successful authentication and access to the OpenNebula API.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser show\nUSER 0 INFORMATION\nID              : 0\nNAME            : oneadmin\nGROUP           : oneadmin\nPASSWORD        : c24783ba96a35464632a624d9f829136edc0175e\n```\n\n----------------------------------------\n\nTITLE: Install EPEL Release on AlmaLinux using yum\nDESCRIPTION: This command installs the epel-release package using yum, enabling access to the EPEL repository on AlmaLinux.  The -y flag automatically confirms the installation, avoiding interactive prompts.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/epel.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# yum -y install epel-release\n```\n\n----------------------------------------\n\nTITLE: Displaying NUMA Memory Statistics within the Guest OS using numastat\nDESCRIPTION: This snippet presents the output of the `numastat -m` command within the guest VM, showcasing per-node memory usage statistics. This includes total memory, free memory, used memory, and other relevant memory metrics for each NUMA node within the VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_22\n\nLANGUAGE: Shell\nCODE:\n```\n# numastat -m\n\nPer-node system memory usage (in MBs):\n                             Node 0          Node 1           Total\n                    --------------- --------------- ---------------\nMemTotal                  511.62          511.86         1023.48\nMemFree                   401.13          186.23          587.36\nMemUsed                   110.49          325.62          436.11\n...\n```\n\n----------------------------------------\n\nTITLE: NGINX Configuration for FireEdge (TLS) - Bash\nDESCRIPTION: This snippet configures NGINX as a TLS-secured reverse proxy for FireEdge. It includes configurations for both HTTP (port 80) to redirect to HTTPS, and HTTPS (port 8443) with SSL parameters like `ssl_certificate` and `ssl_certificate_key`. It defines the proxy settings and headers for WebSocket connections in the `location /fireedge` block.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/fireedge_for_large_deployments.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# No squealing.\nserver_tokens off;\n\n#### OpenNebula FireEdge upstream\nupstream fire-edge {\n        server 127.0.0.1:2616;\n}\n\n#### cloudserver.org HTTP virtual host\nserver {\n        listen 80;\n        server_name cloudserver.org;\n\n        ### Permanent redirect to HTTPS (optional)\n        return 301 https://$server_name:8443;\n}\n\n#### cloudserver.org HTTPS virtual host\nserver {\n        listen 8443;\n        server_name cloudserver.org;\n\n        ### SSL Parameters\n        ssl on;\n        ssl_certificate /etc/ssl/certs/ssl-cert-snakeoil.pem;\n        ssl_certificate_key /etc/ssl/private/ssl-cert-snakeoil.key;\n\n        location /fireedge {\n                proxy_pass http://fire-edge/fireedge;\n                proxy_redirect off;\n                log_not_found off;\n                proxy_buffering off;\n                proxy_cache_bypass $http_upgrade\n                proxy_http_version 1.1;\n                proxy_set_header Upgrade $http_upgrade;\n                proxy_set_header Connection \"upgrade\";\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header Host $http_host;\n                proxy_set_header X-Forwarded-FOR $proxy_add_x_forwarded_for;\n                access_log off;\n        }\n}\n```\n\n----------------------------------------\n\nTITLE: Generate Support Bundle with Database Dump in Bash\nDESCRIPTION: This command creates an OpenNebula support bundle that includes a database dump. It's used when the support team requires detailed database information. It must be executed with root or sudo privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/support.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo onegather --db\n```\n\n----------------------------------------\n\nTITLE: Restarting OpenNebula Service\nDESCRIPTION: This command restarts the main OpenNebula service after modifying the /etc/one/oned.conf file. Restarting the service is required to apply the changes made to the configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo systemctl restart opennebula\n```\n\n----------------------------------------\n\nTITLE: Listing Marketplace Applications\nDESCRIPTION: This snippet lists the available marketplace applications and filters the output to show only those containing \"alpine\" using `grep -i alpine`. It requires the OpenNebula CLI tool to be installed and configured. The output is a list of marketplace applications matching the filter, showing their ID, name, version, size, status, and other details. This checks for available Alpine Linux images.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ onemarketapp list | grep -i alpine\n  74 Alpine Linux 3.20                       6.10.0-2-2  256M  rdy  img 05/14/24 OpenNebula    0\n  51 Alpine Linux 3.17                       6.10.0-2-2  256M  rdy  img 05/14/24 OpenNebula    0\n  40 Alpine Linux 3.16                       6.10.0-2-2  256M  rdy  img 02/01/24 OpenNebula    0\n  27 Alpine Linux 3.19                       6.10.0-2-2  256M  rdy  img 05/14/24 OpenNebula    0\n  22 Alpine Linux 3.18                       6.10.0-2-2  256M  rdy  img 05/14/24 OpenNebula    0\n```\n\n----------------------------------------\n\nTITLE: Listing nftables ruleset\nDESCRIPTION: This command lists the `nftables` ruleset, displaying the service mappings configured for the transparent proxy. It shows the mappings between service ports and remote addresses.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ nft list ruleset\n...\ntable ip one_tproxy {\n        map ep_br0 {\n                type inet_service : ipv4_addr . inet_service\n                elements = { 1234 : 10.11.12.34 . 1234, 5030 : 10.11.12.13 . 5030 }\n       }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Zone Template Bash\nDESCRIPTION: This defines a zone template to be used when creating a new slave zone in the master. It contains the name of the slave and its endpoint address, which needs to be the floating IP in HA setup.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ vim /tmp/zone.tmpl\nNAME     = slave-name\nENDPOINT = http://<slave-zone-ip>:2633/RPC2\n```\n\n----------------------------------------\n\nTITLE: Transparent Proxy Configuration in OpenNebulaNetwork.conf\nDESCRIPTION: This YAML snippet defines the configuration for transparent proxies within the `OpenNebulaNetwork.conf` file. It specifies the debug level, service port, remote address, and remote port for the OneGate proxy and a custom service. The `networks` key allows restricting the proxy to specific virtual networks.  The config must be synced to the Hypervisor hosts.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n:tproxy_debug_level: 2 # 0 = ERROR, 1 = WARNING, 2 = INFO, 3 = DEBUG\n:tproxy:\n# OneGate service.\n- :service_port: 5030\n  :remote_addr: 10.11.12.13 # OpenNebula Front-end VIP\n  :remote_port: 5030\n# Custom service.\n- :service_port: 1234\n  :remote_addr: 10.11.12.34\n  :remote_port: 1234\n  :networks: [vnet_name_or_id]\n```\n\n----------------------------------------\n\nTITLE: Perform VM Action via OneGate API\nDESCRIPTION: This curl command performs an action on a specific VM within a service using the OneGate API. It requires the X-ONEGATE-TOKEN and X-ONEGATE-VMID headers, and the payload specifies the action to be performed (e.g., resched).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X \"POST\" \"${ONEGATE_ENDPOINT}/vms/18/action\" \\\n    --header \"X-ONEGATE-TOKEN: `cat token.txt`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\" \\\n    -d \"{'action' : {'perform': 'resched'}}\"\n```\n\n----------------------------------------\n\nTITLE: Checking and Updating GRUB Configuration\nDESCRIPTION: This snippet shows how to check and update the GRUB configuration to enable iommu and configure hugepages for DPDK.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# grep GRUB_CMDLINE_LINUX_DEFAULT /etc/default/grub\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash intel_iommu=on default_hugepagesz=1G hugepagesz=1G hugepages=250\"\n\n# update-grub\n```\n\n----------------------------------------\n\nTITLE: OneDRS Placement Policy Configuration (YAML)\nDESCRIPTION: Configures initial VM placement using a YAML configuration file. The example demonstrates a multi-metric placement, balancing CPU (60%) and Memory (40%) based on requested resources. This configures where VMs should initially be placed on creation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/drs.rst#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nPLACE:\n  POLICY: \"BALANCE\"\n  WEIGHTS:\n    CPU: 0.6\n    MEMORY: 0.4\n```\n\n----------------------------------------\n\nTITLE: Listing VMs - OpenNebula CLI\nDESCRIPTION: This snippet shows how to list the VMs in OpenNebula using the `onevm list` command. It displays VM ID, user, group, name, status, CPU usage, memory usage, hostname, and time.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n$ onevm list\n    ID USER     GROUP    NAME         STAT CPU     MEM        HOSTNAME        TIME\n     0 oneadmin oneadmin my_vm        pend   0      0K                 00 00:00:03\n```\n\n----------------------------------------\n\nTITLE: Setting Active OpenNebula Zone with CLI\nDESCRIPTION: This command sets the active OpenNebula Zone using the `onezone set` command, which modifies the endpoint URL used for subsequent CLI commands. It requires the Zone ID as input and updates the `one_endpoint` file in the user's home directory to reflect the change.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/usage.rst#_snippet_1\n\nLANGUAGE: none\nCODE:\n```\n$ onezone set 104\nEndpoint changed to \"http://ultron.c12g.com:2634/RPC2\" in /home/<username>/.one/one_endpoint\n\n$ onezone list\nC    ID NAME                      ENDPOINT\n      0 OpenNebula                http://localhost:2633/RPC2\n*   104 ZoneB                     http://ultron.c12g.com:2634/RPC2\n```\n\n----------------------------------------\n\nTITLE: Creating known_hosts file using ssh-keyscan\nDESCRIPTION: This command creates the `known_hosts` file by scanning the SSH public keys of the specified hosts (frontend and nodes). The `known_hosts` file stores the public keys of known SSH servers, preventing man-in-the-middle attacks. It is executed under the `oneadmin` user on the front-end. <frontend>, <node1>, <node2>, etc. should be replaced with the actual hostnames or IP addresses.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/passwordless_ssh.txt#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh-keyscan <frontend> <node1> <node2> <node3> ... >> /var/lib/one/.ssh/known_hosts\n```\n\n----------------------------------------\n\nTITLE: Listing Network Filter Rules with Virsh\nDESCRIPTION: This command lists the network filter rules available in the system using `virsh`.  It connects to the system's QEMU instance and queries the defined network filters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nvirsh -c qemu:///system nwfilter-list\n```\n\n----------------------------------------\n\nTITLE: Marketplace Driver Configuration - Bash\nDESCRIPTION: This configuration sets up the Marketplace Driver, used to manage different marketplaces, tailored to storage back-ends. It defines the path to the executable and arguments, including the number of threads, marketplace MADs, proxy URI, and timeout for external commands.  The EXECUTABLE and ARGUMENTS parameters are critical for defining how OpenNebula connects to and interacts with external marketplaces.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nMARKET_MAD = [\n      EXECUTABLE = \"one_market\",\n      ARGUMENTS  = \"-t 15 -m http,s3,one\"\n  ]\n```\n\n----------------------------------------\n\nTITLE: Ceph Variables Configuration\nDESCRIPTION: This YAML snippet configures Ceph-related variables. These variables are passed to Ceph hosts as Ansible group_vars. It sets `ceph_hci` to true, defines the devices to be used, the monitor interface, and the public network. These values are obtained from user inputs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_16\n\nLANGUAGE: yaml\nCODE:\n```\nceph_vars:\n  ceph_hci: true\n  devices: \"${input.ceph_device}\"\n  monitor_interface: \"${input.ceph_monitor_interface}\"\n  public_network: \"${input.ceph_public_network}\"\n```\n\n----------------------------------------\n\nTITLE: Defining PCI Device as Network Interface in OpenNebula\nDESCRIPTION: This snippet shows how to define a PCI device as a network interface (NIC) in OpenNebula. When a `PCI` in a template contains the attribute `TYPE=\"NIC\"`, it will be treated as a `NIC` and OpenNebula will assign a MAC address, a VLAN_ID, an IP, etc, to the PCI device.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_18\n\nLANGUAGE: text\nCODE:\n```\nPCI = [\n  NETWORK = \"passthrough\",\n  NETWORK_UNAME = \"oneadmin\",\n  TYPE = \"NIC\",\n  CLASS = \"0200\",\n  DEVICE = \"10d3\",\n  VENDOR = \"8086\",\n  TRUST  = \"yes\"\n]\n```\n\n----------------------------------------\n\nTITLE: Creating a New VDC with onevdc\nDESCRIPTION: This command creates a new VDC with the name \"high-performance\".  The output shows the ID assigned to the new VDC, which is typically a number greater than or equal to 100 to differentiate it from the default VDC.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_vdcs.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onevdc create \"high-performance\"\nID: 100\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Datastores\nDESCRIPTION: This snippet uses the `onedatastore list` command to check the datastores configured in OpenNebula. The output shows the datastore IDs, names, size, availability, cluster, images, type, and status. The `STAT` column should display `on` to indicate the datastore is active.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore list\n```\n\n----------------------------------------\n\nTITLE: Defining IPv4 Address Range\nDESCRIPTION: This snippet shows how to define an IPv4 address range for the virtual network.  It specifies the type as IP4, an IP address, and a size for the number of addresses in the range.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_1\n\nLANGUAGE: none\nCODE:\n```\nAR=[\n    TYPE = \"IP4\",\n    IP   = \"10.0.0.150\",\n    SIZE = \"51\",\n]\n```\n\n----------------------------------------\n\nTITLE: Creating a Ceph user for OpenNebula (Jewel)\nDESCRIPTION: This snippet creates a Ceph user named 'libvirt' with the necessary permissions to access the datastore pool on Ceph Jewel (v10.2.x and earlier). It grants read access to monitors and read/write access to the 'one' pool.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ceph auth get-or-create client.libvirt \\\n      mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=one'\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Providers\nDESCRIPTION: This snippet lists the available OpenNebula providers using the `oneprovider list` command. It requires the OpenNebula CLI tool to be installed and configured.  The output shows a table of providers with their ID, name, and registration time.  The purpose is to verify that the on-premises provider is created.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovider list\n  ID NAME                                                                    REGTIME\n   0 onprem                                                           04/28 11:31:34\n```\n\n----------------------------------------\n\nTITLE: Creating System Datastore via CLI\nDESCRIPTION: This snippet demonstrates how to create a system datastore using the OpenNebula command-line interface (CLI). It takes the 'systemds.txt' file (containing the template) as input and creates the datastore.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/local_ds.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n$ onedatastore create systemds.txt\nID: 101\n```\n\n----------------------------------------\n\nTITLE: Setting Federation Mode to Master Bash\nDESCRIPTION: This configuration snippet sets the OpenNebula instance to operate in master mode within a federation.  It defines the mode as MASTER and sets the ZONE_ID. Requires restart of OpenNebula after configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nFEDERATION = [\n    MODE    = \"MASTER\",\n    ZONE_ID = 0\n]\n```\n\n----------------------------------------\n\nTITLE: Update VM Template via OneGate API\nDESCRIPTION: This curl command adds information to the template of the current VM using the OneGate API. It uses the X-ONEGATE-TOKEN and X-ONEGATE-VMID headers for authentication and specifies the /vm endpoint.  The -d option sets the new template attribute (APP_LOAD).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X \"PUT\" \"${ONEGATE_ENDPOINT}/vm\" \\\n    --header \"X-ONEGATE-TOKEN: `cat token.txt`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\" \\\n    -d \"APP_LOAD = 9.7\"\n```\n\n----------------------------------------\n\nTITLE: Logging Configuration in OpenNebula (oned.conf)\nDESCRIPTION: This snippet demonstrates how to configure the logging system within the OpenNebula Daemon's configuration file (oned.conf). It showcases settings for the system log type (file), debug level (3, DEBUG), and whether to store VM logs in their respective VM directories. The `SYSTEM` parameter specifies where logs are written, `DEBUG_LEVEL` controls verbosity, and `USE_VMS_LOCATION` determines the location of VM logs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n#*******************************************************************************\n# Daemon configuration attributes\n#*******************************************************************************\n\nLOG = [\n  SYSTEM      = \"file\",\n  DEBUG_LEVEL = 3,\n  USE_VMS_LOCATION = \"NO\"\n]\n\n#MANAGER_TIMER = 15\n\nMONITORING_INTERVAL_DATASTORE = 300\nMONITORING_INTERVAL_MARKET    = 600\n\n#DS_MONITOR_VM_DISK = 10\n\nSCRIPTS_REMOTE_DIR=/var/tmp/one\n\nPORT = 2633\n\nLISTEN_ADDRESS = \"0.0.0.0\"\n\nDB = [ BACKEND = \"sqlite\" ]\n\n# Sample configuration for MySQL\n# DB = [ BACKEND = \"mysql\",\n#        SERVER  = \"localhost\",\n#        PORT    = 0,\n#        USER    = \"oneadmin\",\n#        PASSWD  = \"oneadmin\",\n#        DB_NAME = \"opennebula\",\n#        CONNECTIONS = 50 ]\n\nVNC_PORTS = [\n    START    = 5900,\n    RESERVED = \"32768:65536\"\n    # RESERVED = \"6800, 6801, 9869\"\n]\n\n#VM_SUBMIT_ON_HOLD = \"NO\"\n#API_LIST_ORDER    = \"DESC\"\n```\n\n----------------------------------------\n\nTITLE: Get Service Template Information with curl\nDESCRIPTION: This curl command retrieves detailed information for a specific service template from the OpenNebula API, identified by its ID (in this case, ID 4).  The command uses basic authentication with 'oneadmin:password' and sends a GET request to the '/service_template/4' endpoint to retrieve the service template's details.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_9\n\nLANGUAGE: Bash\nCODE:\n```\ncurl -u 'oneadmin:password' http://127.0.0.1:2474/service_template/4 -v\n```\n\n----------------------------------------\n\nTITLE: Enable and Start Prometheus Service\nDESCRIPTION: Enables and starts the `opennebula-prometheus.service` using `systemctl`. This ensures that Prometheus starts automatically on boot.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl enable --now opennebula-prometheus.service\n```\n\n----------------------------------------\n\nTITLE: Using Constants for Resource States\nDESCRIPTION: This snippet shows how to use constants provided by `pyone` for handling encoded values representing resource states, like the state of a Marketplace App. Requires importing `MARKETPLACEAPP_STATES` from `pyone`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom pyone import MARKETPLACEAPP_STATES\nif app.STATE == MARKETPLACEAPP_STATES.READY:\n    # action that assumes app ready\n```\n\n----------------------------------------\n\nTITLE: Define User Inputs in OneProvision (YAML)\nDESCRIPTION: This snippet shows how to define user inputs in a OneProvision template.  The `inputs` section allows specifying variables that can be customized by the user during deployment. The example demonstrates defining an array and a text input field.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\ninputs:\n  - name: 'array_i'\n    type: 'array'\n    default: 'h1;h2;h3'\n  - name: 'text_i'\n    type: 'text'\n```\n\n----------------------------------------\n\nTITLE: Listing Marketplace Appliances with OpenNebula CLI\nDESCRIPTION: This command lists the available Marketplace Appliances within OpenNebula. It displays key information such as ID, name, version, size, status, type, registration time, marketplace, and zone.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/marketapps.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nonemarketapp list\n```\n\n----------------------------------------\n\nTITLE: Default Authentication Configuration - Bash\nDESCRIPTION: This configuration specifies the default authentication driver to use (e.g., ldap). This is useful for pointing to the desired default authentication mechanism.  DEFAULT_AUTH parameter selects the desired authentication driver.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nDEFAULT_AUTH = \"ldap\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Zone with Template Bash\nDESCRIPTION: This command creates a new zone using the previously defined template. The command returns the ID of the newly created zone, which is used in later configuration steps.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onezone create /tmp/zone.tmpl\nID: 100\n```\n\n----------------------------------------\n\nTITLE: Creating a Virtual Machine Snapshot\nDESCRIPTION: This command creates a snapshot of a virtual machine. It creates a snapshot for VM with ID '4' and assigns the name 'just in case'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm snapshot-create 4 \"just in case\"\n```\n\n----------------------------------------\n\nTITLE: Setting Backup Job Priority in OpenNebula\nDESCRIPTION: This command allows regular users to assign a priority from 0 to 49 to a backup job, influencing its execution order.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nonebackupjob priority\n```\n\n----------------------------------------\n\nTITLE: Transfer Driver Configuration in oned.conf (Bash)\nDESCRIPTION: This snippet configures the transfer manager driver in the OpenNebula oned.conf file. It sets the executable path and arguments, including the number of threads and a list of enabled transfer drivers (e.g., dummy, lvm, shared). This configuration controls how VM images are transferred, cloned, and removed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n#-------------------------------------------------------------------------------\n# Transfer Manager Driver Configuration\n#-------------------------------------------------------------------------------\n\nTM_MAD = [\n    EXECUTABLE = \"one_tm\",\n    ARGUMENTS = \"-t 15 -d dummy,lvm,shared,fs_lvm,qcow2,ssh,local,ceph,dev,vcenter,iscsi_libvirt\"\n]\n```\n\n----------------------------------------\n\nTITLE: Deleting a Host in OpenNebula (onehost)\nDESCRIPTION: This snippet shows how to delete a host from OpenNebula using the `onehost delete` command. The host can be specified either by its name or its ID. The example demonstrates both methods, which are equivalent.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost delete host01\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost delete 0\n```\n\n----------------------------------------\n\nTITLE: Defining PCI Device by Vendor, Device, and Class in OpenNebula\nDESCRIPTION: This snippet shows how to define a PCI device to passthrough to a VM by specifying the vendor ID, device ID, and class. This is used when selecting a PCI device for passthrough in OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_15\n\nLANGUAGE: text\nCODE:\n```\nPCI = [\n  VENDOR = \"8086\",\n  DEVICE = \"0a0c\",\n  CLASS  = \"0403\" ]\n```\n\n----------------------------------------\n\nTITLE: Synchronizing Hosts by Cluster in OpenNebula\nDESCRIPTION: This snippet demonstrates how to synchronize driver files to all hosts within a specific cluster using the `-c` option with the `onehost sync` command. It synchronizes the files on hosts in the `myCluster` cluster.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost sync -c myCluster\n```\n\n----------------------------------------\n\nTITLE: Show Interfaces Attached to Bridge (Bash)\nDESCRIPTION: This snippet illustrates how to identify physical network interfaces attached to a specific Linux bridge using the `ip link show master <bridge_name>` command. This helps confirm the association between NICs and bridges on OpenNebula hosts.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/networking.txt#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# ip link show master br0\n2: eth0: ...\n\n# ip link show master br1\n3: eth1: ...\n```\n\n----------------------------------------\n\nTITLE: Unlock an Image via CLI - OpenNebula\nDESCRIPTION: This command unlocks the image with ID 2 using the 'oneimage unlock' command. This reverses the effect of the 'oneimage lock' command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage unlock 2\n```\n\n----------------------------------------\n\nTITLE: Create User for Remote Authentication (CLI)\nDESCRIPTION: This command creates a new OpenNebula user configured for 'public' remote authentication. It sets the authentication driver to public and the initial password. Replace `johndoe` with desired username and password.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\noneuser create johndoe \"johndoe\" --driver public\n```\n\n----------------------------------------\n\nTITLE: NGINX Configuration for FireEdge (Non-TLS) - Bash\nDESCRIPTION: This snippet configures NGINX as a reverse proxy for FireEdge. It defines an upstream server for FireEdge running on `127.0.0.1:2616`. The `location /fireedge` block configures proxy settings, including header settings for WebSocket connections.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/fireedge_for_large_deployments.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# No squealing.\nserver_tokens off;\n\n#### OpenNebula FireEdge upstream\nupstream fire-edge {\n        server 127.0.0.1:2616;\n}\n\n#### cloudserver.org HTTPS virtual host\nserver {\n        listen 80;\n        server_name cloudserver.org;\n\n        ### Proxy requests to upstream\n\n        location /fireedge {\n                proxy_pass http://fire-edge/fireedge;\n                proxy_redirect off;\n                log_not_found off;\n                proxy_buffering off;\n                proxy_cache_bypass $http_upgrade\n                proxy_http_version 1.1;\n                proxy_set_header Upgrade $http_upgrade;\n                proxy_set_header Connection \"upgrade\";\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header Host $http_host;\n                proxy_set_header X-Forwarded-FOR $proxy_add_x_forwarded_for;\n                access_log off;\n        }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Basic Backup Job Operations in OpenNebula\nDESCRIPTION: These commands allow to perform basic operations on a Backup Job in OpenNebula, such as changing permissions, ownership, renaming, deleting, locking, and unlocking.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nchmod\n```\n\nLANGUAGE: bash\nCODE:\n```\nchown/chgrp\n```\n\nLANGUAGE: bash\nCODE:\n```\nrename\n```\n\nLANGUAGE: bash\nCODE:\n```\ndelete\n```\n\nLANGUAGE: bash\nCODE:\n```\nlock/unlock\n```\n\n----------------------------------------\n\nTITLE: Starting OpenNebula Services\nDESCRIPTION: This snippet shows how to start the core OpenNebula services using systemctl. The command starts opennebula, opennebula-fireedge, opennebula-gate and opennebula-flow. Ensure services like gate and flow are configured before starting. Also ensure that necessary network ports are enabled in your firewall.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl start opennebula opennebula-fireedge opennebula-gate opennebula-flow\n```\n\n----------------------------------------\n\nTITLE: Listing Service Templates using CLI in Bash\nDESCRIPTION: Lists the available Service Templates using the `oneflow-template list` command. The output includes the ID, USER, GROUP, NAME, and REGTIME (registration time) of each template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneflow-template list\nID USER            GROUP           NAME         REGTIME\n 0 oneadmin        oneadmin        my_service   10/28 17:42:46\n```\n\n----------------------------------------\n\nTITLE: Removing Address Range from Virtual Network - onevnet Command\nDESCRIPTION: This command removes an existing address range (AR) from a virtual network using `onevnet rmar`. It takes the virtual network name and the AR ID as arguments. Removing ARs reduces the IP address pool available to the virtual network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nonevnet rmar Private 2\n```\n\n----------------------------------------\n\nTITLE: Updating a Host Template using Dictionary Access\nDESCRIPTION: This snippet retrieves a host's information, modifies the 'NOTES' field within the TEMPLATE (accessed as a dictionary), and then updates the host with the modified template.  Requires a valid host ID and a `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nhost = one.host.info(0)\nhost.TEMPLATE['NOTES']=\"Just updated\"\none.host.update(0,host.TEMPLATE,1)\n```\n\n----------------------------------------\n\nTITLE: Marking an Image as Persistent in OpenNebula\nDESCRIPTION: This command changes the image named 'Ubuntu' to persistent. Persistent images retain their data even after a VM is terminated. This ensures data durability across VM lifecycles.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\noneimage persistent Ubuntu\n```\n\n----------------------------------------\n\nTITLE: Provisioning OpenNebula Dashboards in Grafana\nDESCRIPTION: This code snippet demonstrates how to configure Grafana provisioning to automatically load OpenNebula dashboards from a file. It creates a dashboards configuration file that specifies the provider name, type, folder, and path to the dashboard files.  Requires Grafana provisioning enabled and dashboard files located at /usr/share/one/grafana/dashboards/.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/grafana.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# mkdir -p /etc/grafana/provisioning/dashboards/\n# cat >/etc/grafana/provisioning/dashboards/opennebula.yml <<'EOF'\napiVersion: 1\nproviders:\n- name: opennebula\n  type: file\n  folder: ONE\n  options: { path: /usr/share/one/grafana/dashboards/ }\nEOF\n```\n\n----------------------------------------\n\nTITLE: Adding VFIO Drivers to initrd using dracut\nDESCRIPTION: This configuration adds the necessary VFIO modules (vfio, vfio_iommu_type1, vfio_pci, vfio_virqfd) to the initrd image. This ensures that the VFIO drivers are loaded early in the boot process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nadd_drivers+=\"vfio vfio_iommu_type1 vfio_pci vfio_virqfd\"\n```\n\n----------------------------------------\n\nTITLE: Reference Datastore ID in Image Definition (YAML)\nDESCRIPTION: This snippet demonstrates referencing a datastore ID in an image definition within a OneProvision YAML file. It creates two datastores and then references the ID of `test_images` datastore when defining `test_image` using the `${datastore.test_images.id}` syntax.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\ndatastores:\n  - name: \"test_images\"\n    ds_mad: fs\n    tm_mad: local\n  - name: \"test_system\"\n    type: system_ds\n    tm_mad: local\n    safe_dirs: \"/var/tmp /tmp\"\n\nimages:\n  - name: \"test_image\"\n    ds_id: ${datastore.test_images.id}\n    size: 2048\n```\n\n----------------------------------------\n\nTITLE: Cloning an Image in OpenNebula\nDESCRIPTION: This command clones an existing image to a new datastore. The new datastore must use the same DS_MAD driver as the original. The command specifies the original image name, the new image name, and the datastore to which the image will be cloned.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\noneimage clone Ubuntu new_image --datastore new_img_ds\n```\n\n----------------------------------------\n\nTITLE: ACL Rule Example - OpenNebula\nDESCRIPTION: This ACL rule allows all users in group 106 to use the Virtual Network with ID 47. This means they can instantiate VM templates that utilize this network. The difference between using * and @ is highlighted.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_6\n\nLANGUAGE: \nCODE:\n```\n@106 NET/#47 USE\n```\n\n----------------------------------------\n\nTITLE: Showing Wild VMs in OpenNebula\nDESCRIPTION: This snippet demonstrates how to display information about wild VMs (VMs not launched through OpenNebula) using the `onehost show` command. The output shows the names, deploy IDs, CPU usage, and memory usage of the wild VMs found on the specified host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost show 3\nHOST 3 INFORMATION\nID                    : 3\nNAME                  : MyAWSHost\nCLUSTER               : -\nSTATE                 : MONITORED\n[...]\nWILD VIRTUAL MACHINES\n                      NAME                            DEPLOY_ID  CPU     MEMORY\n             Ubuntu14.04VM 4223f951-243a-b31a-018f-390a02ff5c96    1       2048\n                   CentOS7 422375e7-7fc7-4ed1-e0f0-fb778fe6e6e0    1       2048\n```\n\n----------------------------------------\n\nTITLE: Setting OneGate Endpoint in oned.conf (OpenNebula)\nDESCRIPTION: This snippet shows how to configure the `ONEGATE_ENDPOINT` parameter in the `/etc/one/oned.conf` file. This parameter defines the address that Virtual Machines will use to communicate with the OneGate service. The specified endpoint must be reachable from the VMs over the network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_0\n\nLANGUAGE: ruby\nCODE:\n```\nONEGATE_ENDPOINT = \"http://one.example.com:5030\"\n```\n\n----------------------------------------\n\nTITLE: Generating a Self-Signed SSL/TLS Certificate (bash)\nDESCRIPTION: These commands shows how to generate a self-signed SSL/TLS certificate for testing purposes using `openssl`.  This certificate is used to secure the connection to OneGate when using a TLS proxy. It is stored in `/etc/one/cert.key` and `/etc/one/cert.crt`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# cd /etc/one\n# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/one/cert.key -out /etc/one/cert.crt\n```\n\n----------------------------------------\n\nTITLE: Switching to oneadmin user\nDESCRIPTION: This command switches the current user to the 'oneadmin' user.  It's necessary to execute subsequent commands as 'oneadmin' to ensure proper permissions and access to OpenNebula-related files and directories. It is used before performing other SSH configuration steps.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/passwordless_ssh.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# su - oneadmin\n```\n\n----------------------------------------\n\nTITLE: Scaleway Provider YAML Configuration\nDESCRIPTION: This YAML configuration file defines a Scaleway provider for OpenNebula. It specifies the provider's name, description, provision type, connection details (access key, secret key, project ID, and zone), and input parameters for the operating system and server capacity.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/scaleway_provider.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: 'scaleway'\n\ndescription: 'Provision cluster in Scaleway Paris'\nprovider: 'scaleway'\n\nplain:\n  provision_type: 'metal'\n\nconnection:\n  access_key: 'Scaleway Access Key'\n  secret_key: 'Scaleway Secret Key'\n  project_id: 'Scaleway Project ID'\n  zone: 'fr-par-1'\n\ninputs:\n  - name: 'scw_baremetal_os'\n    type: 'text'\n    default: 'Ubuntu'\n    description: 'Scaleway ost operating system'\n\n  - name: 'scw_offer'\n    type: 'list'\n    default: 'EM-A115X-SSD'\n    description: 'Scaleway server capacity'\n    options:\n      - 'EM-A115X-SSD'\n```\n\n----------------------------------------\n\nTITLE: Scheduling a One-Shot VM Backup in OpenNebula\nDESCRIPTION: This snippet shows how to schedule a one-shot VM backup using the `onevm backup` command with the `--schedule now` option. It specifies the datastore ID where the backup will be stored. This method allows for immediate backup execution using the VM's configured backup attributes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm backup --schedule now -d 100 0\nVM 0: backup scheduled at 2022-12-01 13:28:44 +0000\n```\n\n----------------------------------------\n\nTITLE: Set Image Ownership with UID in OneProvision (YAML)\nDESCRIPTION: This snippet illustrates how to change the user ID (UID) of an image created by OneProvision. It adds the `uid` attribute within the `meta` section of the image definition in the YAML configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nimages:\n    - name: \"test_image\"\n      ds_id: 1\n      size: 2048\n      meta:\n        uid: 1\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Images\nDESCRIPTION: Lists the available images in the datastores using the `oneimage list` command. This displays information about each image, such as ID, user, group, name, datastore, size, type, and status.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage list\n```\n\n----------------------------------------\n\nTITLE: Creating a new cluster with onecluster\nDESCRIPTION: This snippet creates a new OpenNebula cluster named 'production' using the `onecluster create` command. It shows the command's syntax and the expected output, which is the ID of the newly created cluster. The command requires the cluster name as a parameter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster create production\nID: 100\n```\n\n----------------------------------------\n\nTITLE: Listing Hosts with onehost\nDESCRIPTION: This snippet shows the details of the hosts using the `onehost list` command. It provides details like ID, NAME, CLUSTER, RVM, TCPU, FCPU, ACPU, TMEM, FMEM, AMEM, STAT. The command does not take any parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost list\n  ID NAME         CLUSTER     RVM   TCPU   FCPU   ACPU   TMEM   FMEM   AMEM STAT\n   0 host01       -             7    400    290    400   3.7G   2.2G   3.7G   on\n```\n\n----------------------------------------\n\nTITLE: Storage Packing Policy RANK Expression\nDESCRIPTION: This RANK expression implements the storage packing policy, which aims to minimize the number of system datastores in use.  It prioritizes datastores with less free space. It is used in OpenNebula scheduler for selecting datastores.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/rank_scheduler.rst#_snippet_4\n\nLANGUAGE: OpenNebula\nCODE:\n```\nRANK = \"- FREE_MB\"\n```\n\n----------------------------------------\n\nTITLE: Scaling Service Cardinality with OneGate (none)\nDESCRIPTION: This code shows how to scale the number of Virtual Machines of a Service using the `onegate service scale` command. This allows customization of the Service by specifying a cardinality for each of the roles.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_9\n\nLANGUAGE: none\nCODE:\n```\n$ onegate service scale --role slave --cardinality 2\n$ onegate service show\nSERVICE 1\nNAME                : PANACEA service\nSTATE               : SCALING\n\nROLE master\nVM 8\nNAME                : master_0_(service_1)\nSTATE               : RUNNING\nIP                  : 192.168.122.23\n\nROLE slave\nVM 9\nNAME                : slave_0_(service_1)\nSTATE               : RUNNING\nVM 10\nNAME                : slave_1_(service_1)\nSTATE               : PENDING\n```\n\n----------------------------------------\n\nTITLE: Updating VM Information with OneGate (bash)\nDESCRIPTION: This command shows how to update the information of a Virtual Machine using the `onegate vm update` command. For example, updating the `ACTIVE` attribute.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ onegate vm update 9 --data ACTIVE=YES\n$ onegate vm show 9 --json\n{\n  \"VM\": {\n    \"NAME\": \"slave_0_(service_1)\",\n    \"ID\": \"9\",\n    \"STATE\": \"3\",\n    \"LCM_STATE\": \"3\",\n    \"USER_TEMPLATE\": {\n      \"ACTIVE\": \"YES\",\n      \"FROM_APP\": \"4fc76a938fb81d3517000003\",\n      \"FROM_APP_NAME\": \"ttylinux - kvm\",\n      \"LOGO\": \"images/logos/linux.png\",\n      \"ROLE_NAME\": \"slave\",\n      \"SERVICE_ID\": \"1\"\n    },\n    \"TEMPLATE\": {\n      \"NIC\": [\n\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing List Output with ONE_LISTCONF (Bash)\nDESCRIPTION: This snippet illustrates how to use the ONE_LISTCONF environment variable to customize the output of list commands. It shows an example of changing the default display of `onevm list` to a user-specific layout.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/cli.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm list\n    ID USER     GROUP    NAME            STAT UCPU    UMEM HOST             TIME\n    20 oneadmin oneadmin tty-20          fail    0      0K localhost    0d 00h32\n    21 oneadmin oneadmin tty-21          fail    0      0K localhost    0d 00h23\n    22 oneadmin oneadmin tty-22          runn  0.0  104.7M localhost    0d 00h22\n\n$ export ONE_LISTCONF=user\n$ onevm list\n    ID NAME            IP              STAT UCPU    UMEM HOST             TIME\n    20 tty-20          10.3.4.20       fail    0      0K localhost    0d 00h32\n    21 tty-21          10.3.4.21       fail    0      0K localhost    0d 00h23\n    22 tty-22          10.3.4.22       runn  0.0  104.7M localhost    0d 00h23\n```\n\n----------------------------------------\n\nTITLE: Configuring Open vSwitch PMD Threads\nDESCRIPTION: This snippet configures the execution parameters of the polling mode drivers (PMD) threads by pinning them into specific CPUs and assigning hugepages.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# ovs-vsctl set Open_vSwitch . other_config:pmd-cpu-mask=0x30000003\n# ovs-vsctl set Open_vSwitch . other_config:dpdk-socket-mem=\"2048,2048\" # socket-mem=socket0_mem,socket1_mem\n# ovs-vsctl set Open_vSwitch . other_config:dpdk-hugepage-dir=\"/mnt/hugepages1G\"\n\n# systemctl restart openvswitch-switch.service\n```\n\n----------------------------------------\n\nTITLE: Checking iommu Status\nDESCRIPTION: This snippet demonstrates how to verify if iommu is enabled using dmesg.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# dmesg | grep -i dmar\n[Â  Â  0.010651] kernel: ACPI: DMAR 0x000000007BAFE000 0000F0 (v01 DELL Â  PE_SC3 Â  00000001 DELL 00000001)\n[Â  Â  0.010695] kernel: ACPI: Reserving DMAR table memory at [mem 0x7bafe000-0x7bafe0ef]\n[Â  Â  1.837579] kernel: DMAR: IOMMU enabled\n```\n\n----------------------------------------\n\nTITLE: Help for onevrouter instantiate command\nDESCRIPTION: Shows the help page for the `onevrouter instantiate` command, highlighting the `-m` option for creating multiple VMs for High Availability\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vrouter.rst#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ onevrouter instantiate -h\n[...]\n-m, --multiple x          Instance multiple VMs\n```\n\n----------------------------------------\n\nTITLE: Creating an Equinix Provider with oneprovider\nDESCRIPTION: This command creates a new Equinix provider in OpenNebula using the specified YAML template. The ID of the newly created provider is returned upon successful creation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/equinix_provider.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovider create provider.yaml\nID: 0\n```\n\n----------------------------------------\n\nTITLE: OpenNebula State Hook Example (Host - Ruby)\nDESCRIPTION: This Ruby script demonstrates a state hook for OpenNebula hosts. It decodes the host template passed as a base64-encoded XML string in ARGV[0], extracts the host ID, and prints a message indicating that the host is in an error state. It depends on 'base64' and 'nokogiri'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_13\n\nLANGUAGE: ruby\nCODE:\n```\n# Hook template\n#\n#NAME = host-error\n#TYPE = state\n#COMMAND = host_error.rb\n#ARGUMENTS=\"$TEMPLATE\"\n#STATE = ERROR\n#RESOURCE = HOST\n\n#!/usr/bin/ruby\n\nrequire 'base64'\nrequire 'nokogiri'\n\n#host_template = Nokogiri::XML(Base64::decode64(STDIN.gets.chomp)) for reading from STDIN\nhost_template = Nokogiri::XML(Base64::decode64(ARGV[0]))\n\nhost_id = host_template.xpath(\"//ID\").text.to_i\n\nputs \"Host #{host_id} is in error state!!\"\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Enterprise Repository on Ubuntu 24.04\nDESCRIPTION: This bash script adds the OpenNebula Enterprise Edition repository to the Ubuntu 24.04 system. It creates a `/etc/apt/sources.list.d/opennebula.list` file with the repository configuration, including the base URL (which requires a customer-specific token) and specifies the GPG key file. The script then updates the apt package list.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# echo \\\"deb [signed-by=/etc/apt/keyrings/opennebula.gpg] https://<token>@enterprise.opennebula.io/repo/|version|/Ubuntu/24.04 stable opennebula\\\" > /etc/apt/sources.list.d/opennebula.list\n# apt-get update\n```\n\n----------------------------------------\n\nTITLE: Showing Marketplace Appliance Details with OpenNebula CLI\nDESCRIPTION: This command retrieves and displays detailed information about a specific Marketplace Appliance, identified by its ID. The output includes metadata such as name, type, user, group, marketplace, state, permissions, and details like source URL, MD5 checksum, publisher, register time, version, description, size, origin ID, format, import template, and the full Marketplace app template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/marketapps.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nonemarketapp show 0\n```\n\n----------------------------------------\n\nTITLE: Listing Clusters with OpenNebula Provisioning Tool (oneprovision) - Bash\nDESCRIPTION: This command lists the clusters in the current OpenNebula provision using the `oneprovision` tool. It requires access to the Front-end node as the `oneadmin` user or as `root`. The output displays the ID, name, number of hosts, virtual networks, and datastores associated with each cluster.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/operation_basics/provisioning_edge_cluster.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\noneprovision cluster list\n```\n\n----------------------------------------\n\nTITLE: Defining Customizable Capacity in VM Template\nDESCRIPTION: This code snippet shows how to define customizable capacity attributes (CPU, MEMORY, VCPU) in a VM Template. It uses USER_INPUTS to specify the modification options for each attribute (fixed, any value, range, list).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_2\n\nLANGUAGE: none\nCODE:\n```\nCPU    = \"1\"\nMEMORY = \"2048\"\nVCPU   = \"2\"\nUSER_INPUTS = [\n  VCPU   = \"O|fixed|| |2\"\n  CPU    = \"M|list||0.5,1,2,4|1\",\n  MEMORY = \"M|range||512..8192|2048\" ]\n```\n\n----------------------------------------\n\nTITLE: Install OpenNebula Front-end - Debian/Ubuntu\nDESCRIPTION: These commands install the core OpenNebula Front-end components using the apt package manager on Debian or Ubuntu. It first updates the package list and then installs the opennebula, opennebula-fireedge, opennebula-gate, opennebula-flow and opennebula-provision packages.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# apt-get update\n# apt-get -y install opennebula opennebula-fireedge opennebula-gate opennebula-flow opennebula-provision\n```\n\n----------------------------------------\n\nTITLE: Creating Marketplace with onemarket\nDESCRIPTION: This snippet demonstrates how to create a new Marketplace in OpenNebula using the `onemarket` command. It takes a configuration file (market.conf) as input, which contains the necessary attributes for defining the Marketplace, such as name, access credentials, and storage details.  The command returns the ID of the newly created Marketplace.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/private_marketplaces/market_s3.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nonemarket create market.conf\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Hosts\nDESCRIPTION: This snippet lists the hosts in OpenNebula using the `onehost list` command. It requires the OpenNebula CLI tool to be installed and configured. The output displays a table of hosts with their ID, name, cluster, TVM count, allocated CPU, allocated memory, and status.  The purpose is to verify the created hosts are running.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost list\n  ID NAME                  CLUSTER    TVM      ALLOCATED_CPU      ALLOCATED_MEM STAT\n   4 host02                onprem-clu   0       0 / 200 (0%)     0K / 3.8G (0%) on\n   3 host01                onprem-clu   0       0 / 200 (0%)     0K / 3.8G (0%) on\n```\n\n----------------------------------------\n\nTITLE: Updating Ceph user capabilities (Luminous)\nDESCRIPTION: This snippet updates the capabilities of an existing Ceph user 'libvirt' to use the 'rbd' profile for monitors and 'rbd pool=one' for OSDs on Ceph Luminous and later. This is necessary when upgrading existing Ceph deployments.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ceph auth caps client.libvirt \\\n      mon 'profile rbd' osd 'profile rbd pool=one'\n```\n\n----------------------------------------\n\nTITLE: Backup OpenNebula Remotes Directory (Shell)\nDESCRIPTION: This command copies the OpenNebula remotes directory (/var/lib/one/remotes) to the backup directory. The --parents option preserves the directory structure.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/replace_failing_fe.rst#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncp -rp --parents /var/lib/one/remotes $BAK_DIR\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables in kvmrc\nDESCRIPTION: This code snippet demonstrates how to set environment variables within the `/var/lib/one/remotes/etc/vmm/kvm/kvmrc` file. These variables configure the KVM driver, impacting aspects like connection URIs and migration protocols. The file is executed before the driver loads, allowing for customized configurations.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_19\n\nLANGUAGE: Shell\nCODE:\n```\nENVIRONMENT_VARIABLE=VALUE\n```\n\n----------------------------------------\n\nTITLE: Displaying OpenNebula Hook Information\nDESCRIPTION: Displays the information for a specific hook in OpenNebula. The command `onehook show 0` shows the details of hook ID 0, including its name, type, template, and execution log.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ onehook show 0\n```\n\n----------------------------------------\n\nTITLE: Upgrade OpenNebula Node Packages on Ubuntu/Debian\nDESCRIPTION: This command upgrades the OpenNebula node packages on Ubuntu or Debian systems using `apt-get`.  The `<hypervisor>` tag should be replaced with the specific hypervisor (e.g., kvm or lxc).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_12\n\nLANGUAGE: Bash\nCODE:\n```\napt-get install --only-upgrade opennebula-node-<hypervisor>\n```\n\n----------------------------------------\n\nTITLE: Authentication with curl\nDESCRIPTION: This command demonstrates how to authenticate with the OneFlow API using HTTP Basic Authentication.  It sends a request to the OneFlow server with the provided username and password.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -u \"username:password\" https://oneflow.server\n```\n\n----------------------------------------\n\nTITLE: Defining a Service Template in JSON\nDESCRIPTION: This JSON snippet demonstrates a sample service template definition, showing how to define the service name, deployment type, and roles. Each role specifies cardinality, template ID, type, and parent roles to manage deployment dependencies. This template defines a multi-tier application composed of frontend, database master/slave and worker VMs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"name\": \"my_service\",\n  \"deployment\": \"straight\",\n  \"roles\": [\n    {\n      \"name\": \"frontend\",\n      \"cardinality\": 1,\n      \"template_id\": 0,\n      \"type\": \"vm\"\n    },\n    {\n      \"name\": \"db_master\",\n      \"cardinality\": 1,\n      \"template_id\": 1,\n      \"type\": \"vm\",\n      \"parents\": [\n        \"frontend\"\n      ]\n    },\n    {\n      \"name\": \"db_slave\",\n      \"cardinality\": 3,\n      \"template_id\": 2,\n      \"type\": \"vm\",\n      \"parents\": [\n        \"frontend\"\n      ]\n    },\n    {\n      \"name\": \"worker\",\n      \"cardinality\": 10,\n      \"template_id\": 3,\n      \"type\": \"vm\",\n      \"parents\": [\n        \"db_master\",\n        \"db_slave\"\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Viewing OneFlow Service Logs in Journald\nDESCRIPTION: This command retrieves logs related to the OneFlow service from Journald. It filters the logs specifically for the 'opennebula-flow.service' unit. This allows for centralized logging and debugging of the OneFlow service.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oneflow.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# journalctl -u opennebula-flow.service\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Ceph Options in OpenNebula\nDESCRIPTION: This YAML snippet shows the default Ceph options that can be configured in the OpenNebula provision file `/usr/share/one/oneprovision/edge-clusters/metal/provisions/aws-hci.yml`. It defines parameters such as whether it is an HCI setup, the network interface, devices, the public network, and Ceph disk size. This file allows for fine-tuning of the Ceph cluster deployment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/aws_cluster_ceph.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Defaults ceph options\nceph_vars:\n  ceph_hci: true\n  setup_eth1: true\n  devices: [ \"/dev/nvme1n1\" ]\n  monitor_interface: \"ens1\"\n  public_network: \"10.1.0.0/16\"\n  ceph_disk_size: \"${input.ceph_disk_size}\"\n```\n\n----------------------------------------\n\nTITLE: List OpenNebula Marketplace Apps (Filter for Alpine)\nDESCRIPTION: This command lists OpenNebula marketplace applications and filters the results for applications containing 'alpine' in their name. Requires the OpenNebula CLI tools and access to the OpenNebula marketplace.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ onemarketapp list | grep -i alpine\n  74 Alpine Linux 3.20                       6.10.0-2-2  256M  rdy  img 05/14/24 OpenNebula    0\n  51 Alpine Linux 3.17                       6.10.0-2-2  256M  rdy  img 05/14/24 OpenNebula    0\n  40 Alpine Linux 3.16                       6.10.0-2-2  256M  rdy  img 02/01/24 OpenNebula    0\n  27 Alpine Linux 3.19                       6.10.0-2-2  256M  rdy  img 05/14/24 OpenNebula    0\n  22 Alpine Linux 3.18                       6.10.0-2-2  256M  rdy  img 05/14/24 OpenNebula    0\n```\n\n----------------------------------------\n\nTITLE: Loading VFIO Driver with PCI IDs\nDESCRIPTION: This configuration loads the vfio-pci driver and specifies the IDs of the PCI devices to be managed by VFIO.  The IDs are crucial for directing the VFIO driver to specific devices.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\noptions vfio-pci ids=10de:11bf\n```\n\n----------------------------------------\n\nTITLE: Retrieving Extended Service Information with OneGate (bash)\nDESCRIPTION: This command shows how to retrieve extended service information, including details from virtual machines, using the `onegate service show --extended` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onegate service show --extended\nSERVICE 1\nNAME                : PANACEA service\nSTATE               : RUNNING\n\nROLE master\nVM 8\nNAME                : master_0_(service_1)\nSTATE               : RUNNING\nIP                  : 192.168.122.23\n\n\nROLE slave\nVM 9\nNAME                : slave_0_(service_1)\nSTATE               : RUNNING\n```\n\n----------------------------------------\n\nTITLE: Get Virtual Network Information via OneGate API\nDESCRIPTION: This curl command retrieves information about a Virtual Network with a specific ID via the OneGate API.  The X-ONEGATE-TOKEN and X-ONEGATE-VMID headers are required for authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X \"GET\" \"${ONEGATE_ENDPOINT}/vnet/<VNET_ID>\" \\\n    --header \"X-ONEGATE-TOKEN: `cat token.txt`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\"\n\n{\n  \"VNET\": {\n      \"ID\": \"0\",\n      \"NAME\": \"vnet\",\n      \"USED_LEASES\": \"1\",\n      \"VROUTERS\": {\n      \"ID\": [\n          \"0\"\n      ]\n      },\n      \"PARENT_NETWORK_ID\": {\n      },\n      \"AR_POOL\": {\n      \"AR\": [\n          {\n          \"AR_ID\": \"0\",\n          \"IP\": \"192.168.122.100\",\n          \"MAC\": \"02:00:c0:a8:7a:64\",\n          \"SIZE\": \"10\",\n          \"TYPE\": \"IP4\",\n          \"MAC_END\": \"02:00:c0:a8:7a:6d\",\n          \"IP_END\": \"192.168.122.109\",\n          \"USED_LEASES\": \"1\",\n          \"LEASES\": {\n              \"LEASE\": [\n              {\n                  \"IP\": \"192.168.122.100\",\n                  \"MAC\": \"02:00:c0:a8:7a:64\",\n                  \"VM\": \"1\"\n              }\n              ]\n          }\n          }\n      ]\n      },\n      \"TEMPLATE\": {\n      \"NETWORK_ADDRESS\": \"192.168.122.0\",\n      \"NETWORK_MASK\": \"255.255.255.0\",\n      \"GATEWAY\": \"192.168.122.1\",\n      \"DNS\": \"1.1.1.1\"\n      }\n    }\n  }\n```\n\n----------------------------------------\n\nTITLE: Configuring Local Actions for one_vmm_exec driver (Shell)\nDESCRIPTION: This code snippet shows how to specify alternative script names for local execution within the `one_vmm_exec` driver. By default, the script is named the same as the action. This configuration allows overriding the script name for specific actions like `poll` and `save`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-vmm.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n-l migrate,poll=poll_ganglia,save\n```\n\n----------------------------------------\n\nTITLE: Listing Datastore Contents (SSH Mode)\nDESCRIPTION: This bash command lists the contents of a specific datastore directory on the hypervisor node, demonstrating the files created when using SSH mode. The command lists the contents of /var/lib/one/datastores/100/14, which includes files like deployment.0 and disk.0.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n$ ls -l /var/lib/one/datastores/100/14\ntotal 609228\n-rw-rw-r-- 1 oneadmin oneadmin        1020 Dec 20 14:41 deployment.0\n-rw-r--r-- 1 oneadmin oneadmin 10737418240 Dec 20 15:19 disk.0\n-rw-rw-r-- 1 oneadmin oneadmin      372736 Dec 20 14:41 disk.1\n```\n\n----------------------------------------\n\nTITLE: Showing VM Information\nDESCRIPTION: This snippet shows detailed information for a virtual machine using the `onevm show` command. It specifies the VM ID (11). This requires the OpenNebula CLI tool to be installed and configured. The output includes VM state, monitoring data, disk and NIC configuration, and other details.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 11\nVIRTUAL MACHINE 10 INFORMATION\nID                  : 11                  \nNAME                : alpine_market-11    \nUSER                : oneadmin            \nGROUP               : oneadmin            \nSTATE               : ACTIVE              \nLCM_STATE           : RUNNING\n\n...\n\nVIRTUAL MACHINE MONITORING                                                      \nCPU                 : 0.0                 \nMEMORY              : 173.7M              \nNETTX               : 14K                 \nNETRX               : 54K\n\n...\nVM DISKS\n ID DATASTORE  TARGET IMAGE                               SIZE      TYPE SAVE\n  0 default    vda    alpine_market                       80M/256M  file   NO\n  1 -          hda    CONTEXT                             1M/-      -       -\n\nVM NICS\n ID NETWORK              BRIDGE       IP              MAC               PCI_ID\n  0 onprem-cluster-publi onebr4       172.16.0.2      02:00:ac:10:00:02\n```\n\n----------------------------------------\n\nTITLE: Retrieving Public Key with oneuser key\nDESCRIPTION: The `oneuser key` command retrieves the user's public key, which needs to be provided to the OpenNebula administrator for account creation or authentication update. This command extracts the public key from the user's SSH key pair.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ssh.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\noneuser key\n```\n\n----------------------------------------\n\nTITLE: Download Marketplace Appliance using onemarketapp\nDESCRIPTION: This command downloads a Marketplace Appliance to a standalone file on the desktop.  It requires the `ONE_SUNSTONE` environment variable to be set. The parameters include the Marketplace Appliance ID and the path to save the app.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/marketapps.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ onemarketapp download 40 /path/to/app\n```\n\n----------------------------------------\n\nTITLE: Displaying VM Template Information\nDESCRIPTION: This shows a truncated `onevm show` output that includes the VMID under the `VIRTUAL MACHINE TEMPLATE` section. It demonstrates that VMIDs are stored as part of the template information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_39\n\nLANGUAGE: text\nCODE:\n```\n$ onevm show 0\n...\n\nVIRTUAL MACHINE TEMPLATE\n...\nVMID=\"0\"\n```\n\n----------------------------------------\n\nTITLE: Forcing Host File Synchronization in OpenNebula\nDESCRIPTION: This snippet shows how to force an upgrade of driver files on hosts, bypassing the version check, by using the `--force` option with the `onehost sync` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost sync --force\n```\n\n----------------------------------------\n\nTITLE: Listing Edge Clusters\nDESCRIPTION: This snippet demonstrates how to list all provisions using the `oneprovision list` command. The output displays the ID, name, and status of each provision, along with the number of associated clusters, hosts, networks, and datastores.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/cluster_operations.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision list\nID NAME                      CLUSTERS HOSTS VNETS DATASTORES STAT\n 0 aws-cluster                      1     1     1          2 RUNNING\n```\n\n----------------------------------------\n\nTITLE: VM Template DISK Definition with IMAGE_ID\nDESCRIPTION: This snippet shows how to define a DISK in a VM template using IMAGE_ID. This specifies the image to be used as a disk for the virtual machine by its unique ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_27\n\nLANGUAGE: none\nCODE:\n```\nDISK = [ IMAGE_ID   = 7 ]\n```\n\n----------------------------------------\n\nTITLE: Changing Directory Ownership for Shared Storage\nDESCRIPTION: This command changes the ownership of the /storage/one_datastores directory to UID 9869 and GID 9869. This ensures that the OpenNebula oneadmin user has the correct permissions to access the shared storage over NFS. This needs to be run as root.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nchown 9869:9869 /storage/one_datastores\n```\n\n----------------------------------------\n\nTITLE: Using SSH Key Contextualization in VM Template\nDESCRIPTION: This code block shows how to define the `ssh_key` attribute within a Virtual Machine template using contextualization. The value is dynamically populated from the `USER` template, specifically the `SSH_KEY` attribute defined there. This allows users to automatically install their SSH public key in the VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nssh_key = \"$USER[SSH_KEY]\"\n```\n\n----------------------------------------\n\nTITLE: Debugging OpenNebula Configuration Upgrade\nDESCRIPTION: This command upgrades the OpenNebula configuration with debug logging enabled, providing detailed information about the changes made to the configuration files and the status of their application.  The `--debug` flag enables detailed output during the upgrade process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n$ onecfg upgrade --debug\n```\n\n----------------------------------------\n\nTITLE: Installing OpenNebula LXC Node on Debian/Ubuntu\nDESCRIPTION: This snippet demonstrates how to install the OpenNebula LXC node package on Debian/Ubuntu systems using the apt-get package manager. Before executing this command, it is necessary to update the package lists. It also suggests installing the `rbd-nbd` package if the Ceph Datastore is used.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_node_installation.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# apt-get update\n# apt-get -y install opennebula-node-lxc\n```\n\n----------------------------------------\n\nTITLE: Configuring Federation in oned.conf (text)\nDESCRIPTION: This snippet shows how to configure federation settings in the /etc/one/oned.conf file for an OpenNebula API server. It includes the federation mode, zone ID, server ID, and the XML-RPC endpoint of the master oned.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/scalability.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nFEDERATION = [\n\t    MODE          = \"CACHE\",\n\t    ZONE_ID       = 0,\n\t    SERVER_ID     = -1,\n\t    MASTER_ONED   = \"set the XML-RPC endpoint of master oned\"\n```\n\n----------------------------------------\n\nTITLE: List OpenNebula Images\nDESCRIPTION: This command lists the OpenNebula images. It displays the image ID, user, group, name, datastore, size, type, persistent status, and state. Requires the OpenNebula CLI tools to be installed and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage list\nID USER     GROUP    NAME                       DATASTORE     SIZE TYPE PER STAT RVMS\n 3 oneadmin oneadmin alpine_market              default       256M OS    No rdy     0\n```\n\n----------------------------------------\n\nTITLE: Access Parent Role Attributes\nDESCRIPTION: This code shows how to access a parent role's attributes from a child role within a service template.  It uses the `${<PARENT_ROLE_NAME>.<XPATH>}` syntax to reference attributes.  This allows children roles to inherit configuration data from their parents, centralizing configuration and improving reusability.  It's important to note this only works for STRAIGHT deployment strategy with a parent-child relationship.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_30\n\nLANGUAGE: javascript\nCODE:\n```\ntemplate_contents\": { \n  \"DB_NAME\": \"${DATABASE.template.context.db_name\" \n}\n```\n\n----------------------------------------\n\nTITLE: Importing a VM Template Interactively\nDESCRIPTION: This command imports a VM Template into a marketplace through an interactive process. The user is prompted to confirm the import of associated images and to select the target marketplace for the VM template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/marketapps.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nonemarketapp vm-template import 0\n```\n\n----------------------------------------\n\nTITLE: Backup OpenNebula Configuration (Shell)\nDESCRIPTION: This command copies the OpenNebula configuration directory (/etc/one) to the backup directory. The --parents option preserves the directory structure.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/replace_failing_fe.rst#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncp -rp --parents /etc/one $BAK_DIR\n```\n\n----------------------------------------\n\nTITLE: Enable RAFT Hooks in oned.conf (Leader)\nDESCRIPTION: Enables the RAFT hooks in /etc/one/oned.conf to manage the floating IP address when the server transitions between follower and leader roles. These hooks execute scripts to add or remove the floating IP from the network interface.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/frontend_ha.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Executed when a server transits from follower->leader\nRAFT_LEADER_HOOK = [\n     COMMAND = \"raft/vip.sh\",\n     ARGUMENTS = \"leader eth0 10.3.3.2/24\"\n]\n\n# Executed when a server transits from leader->follower\nRAFT_FOLLOWER_HOOK = [\n    COMMAND = \"raft/vip.sh\",\n    ARGUMENTS = \"follower eth0 10.3.3.2/24\"\n]\n```\n\n----------------------------------------\n\nTITLE: LDAP User Credentials File Format - Bash\nDESCRIPTION: This snippet shows the format for storing LDAP credentials in the $ONE_AUTH file. The file stores the LDAP user's DN and password, separated by a colon. It is used for authentication purposes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n<user_dn>:ldap_password\n```\n\n----------------------------------------\n\nTITLE: Define Role with On-Hold State\nDESCRIPTION: This code defines a service role with the `on_hold` attribute set to either `true` or `false`. This allows for pausing or releasing specific roles within a service, useful for staged deployments or maintenance. Releasing the roles requires using the `oneflow release` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_25\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"name\": \"my_service\",\n  \"deployment\": \"straight\",\n  \"type\": \"vm\",\n  \"roles\": [\n    {\n      \"name\": \"frontend\",\n      \"template_id\": 0,\n      \"on_hold\": true|false\n      ...\n    },\n    ...\n  ]\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Enable and Start Node and Libvirt Exporters (Host)\nDESCRIPTION: Enables and starts the `opennebula-libvirt-exporter.service` and `opennebula-node-exporter.service` on the host machines using `systemctl`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl enable --now opennebula-libvirt-exporter.service opennebula-node-exporter.service\n```\n\n----------------------------------------\n\nTITLE: Updating a VM using a nested dictionary\nDESCRIPTION: This snippet demonstrates how to update a VM using a nested dictionary to represent a more complex template. The outer 'TEMPLATE' key is considered the root element and translated to XML. It requires a valid VM ID and a `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\none.vm.update(1,\n    {\n      'TEMPLATE': {\n        'NAME': 'abc',\n        'MEMORY': '1024',\n        'ATT1': 'value1'\n      }\n    }, 1)\n```\n\n----------------------------------------\n\nTITLE: Listing VMs with OneVM CLI\nDESCRIPTION: This command lists all the VMs running in the OpenNebula environment. It provides information like ID, user, group, name, status, CPU, memory, host and time. It's used to verify if the VMs are running even if the service is stuck in `DEPLOYING` state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_16\n\nLANGUAGE: text\nCODE:\n```\nonevm list\n  ID USER     GROUP    NAME                                            STAT  CPU     MEM HOST                         TIME\n   3 oneadmin oneadmin worker_0_(service_3)                            runn    2      3G <public IP>              0d 01h02\n   2 oneadmin oneadmin master_0_(service_3)                            runn    2      3G <public IP>              0d 01h02\n   1 oneadmin oneadmin vnf_0_(service_3)                               runn    1    512M <public IP>              0d 01h03\n   0 oneadmin oneadmin Service WordPress - KVM-0                       runn    1    768M <public IP>              0d 01h53\n```\n\n----------------------------------------\n\nTITLE: JSON example for updating a Service Template\nDESCRIPTION: Illustrates a JSON format that contains new attributes and configurations to be merged with an existing Service Template. This example updates the description and the cardinality of the frontend role.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"description\": \"new description for the service\",\n    \"roles\": [\n        {\n            \"name\": \"frontend\",\n            \"cardinality\": 3\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Validating files with custom prefix\nDESCRIPTION: This snippet uses the `--prefix` option to validate files inside a specified directory. The directory structure must mimic the real location structure.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg validate --prefix /tmp/ONE --verbose\nINFO  : File '/tmp/ONE/etc/one/vcenter_driver.default' - OK\nINFO  : File '/tmp/ONE/etc/one/ec2_driver.default' - OK\nINFO  : File '/tmp/ONE/etc/one/az_driver.default' - OK\nINFO  : File '/tmp/ONE/etc/one/auth/ldap_auth.conf' - OK\nINFO  : File '/tmp/ONE/etc/one/auth/server_x509_auth.conf' - OK\n...\n```\n\n----------------------------------------\n\nTITLE: Update Virtual Machine Template\nDESCRIPTION: This command updates a Virtual Machine template. In this example, it updates the template by adding a network interface card (NIC) configuration, sets the NETWORK_MODE to auto. Requires the OpenNebula CLI tools to be installed and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ onetemplate update 3\n...\nNIC = [ NETWORK_MODE = \"auto\" ]\n```\n\n----------------------------------------\n\nTITLE: OpenNebula IM Driver Configuration\nDESCRIPTION: This code snippet shows an example configuration for adding a new Infrastructure Monitoring (IM) driver to OpenNebula's monitord.conf file.  It defines the driver's name, the executable used to run the probes (one_im_sh in this case), and any required arguments (the directory containing the probes).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-im.rst#_snippet_5\n\nLANGUAGE: None\nCODE:\n```\nIM_MAD = [\n      name       = \"ganglia\",\n      executable = \"one_im_sh\",\n      arguments  = \"ganglia\" ]\n```\n\n----------------------------------------\n\nTITLE: Kernels & Files Datastore Configuration File\nDESCRIPTION: This code snippet demonstrates the configuration file (kernels_ds.conf) used to create a Kernels & Files Datastore in OpenNebula. It defines the name, datastore MAD, transfer MAD, datastore type, and safe directories for the datastore. This configuration is then used with the 'onedatastore create' command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/file_ds.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nNAME = kernels\nDS_MAD = fs\nTM_MAD = local\nTYPE = FILE_DS\nSAFE_DIRS = /var/tmp/files\n```\n\n----------------------------------------\n\nTITLE: Backup OpenNebula Keys Directory (Shell)\nDESCRIPTION: This command copies the OpenNebula keys directory (/var/lib/one/.one) to the backup directory. The --parents option preserves the directory structure.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/replace_failing_fe.rst#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncp -rp --parents /var/lib/one/.one $BAK_DIR\n```\n\n----------------------------------------\n\nTITLE: Install EPEL Release - RHEL 8\nDESCRIPTION: This command installs the EPEL release package on RHEL 8.  EPEL provides additional packages not available in the base RHEL repositories, which are required by OpenNebula. The command downloads and installs the RPM package directly from the Fedora Project.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\n```\n\n----------------------------------------\n\nTITLE: Setting VM scheduling requirements for Gold QoS - Bash\nDESCRIPTION: This code snippet shows how to set the `SCHED_REQUIREMENTS` attribute in a Virtual Machine Template to ensure deployment only on a Host with Gold QoS. This restricts the scheduler to only consider hosts associated with clusters that have the `QOS` attribute set to `GOLD`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/overview.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nSCHED_REQUIREMENTS = \"QOS = GOLD\"\n```\n\n----------------------------------------\n\nTITLE: Deleting Service Template using REST API with curl\nDESCRIPTION: This snippet demonstrates how to delete a specific SERVICE_TEMPLATE resource in OpenNebula using the REST API with a DELETE request. It requires authentication with username 'oneadmin' and password 'password'. The command targets a specific service template ID (in this case, 4).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service_template/4 -u 'oneadmin:password' -v -X DELETE\n```\n\n----------------------------------------\n\nTITLE: Adding a Virtual Network to a Cluster with onecluster\nDESCRIPTION: This snippet adds a virtual network named 'priv-ovswitch' to the 'production' cluster using the `onecluster addvnet` command.  It demonstrates how to associate a virtual network with a specific cluster. The command requires the cluster name and the virtual network name or ID as parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster addvnet production priv-ovswitch\n```\n\n----------------------------------------\n\nTITLE: Defining Network Values for Service Template - Network Reservation\nDESCRIPTION: This snippet shows how to define network values to create a network reservation from an existing Virtual Network (VNet). The \"reserve_from\" attribute specifies the VNet ID to reserve from, and the \"extra\" attribute defines the reservation name and size using a string formatted as NAME=RESERVATION\\nSIZE=5.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_15\n\nLANGUAGE: json\nCODE:\n```\n{\n  ...\n  \"networks_values\": [\n    { \"Public\": {\n        \"reserve_from\": \"<vnet_id>\",\n        \"extra\": \"NAME=RESERVATION\\nSIZE=5\"\n      }\n    }\n  ]\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Synchronizing OpenNebula Hosts\nDESCRIPTION: This command synchronizes OpenNebula hosts. It ensures that the hosts are using the latest configuration by forcing a synchronization using the `onehost sync -f` command. The command is executed as the `oneadmin` user to ensure the proper permissions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# sudo -u oneadmin onehost sync -f\n```\n\n----------------------------------------\n\nTITLE: Creating Virtual Network\nDESCRIPTION: This snippet shows the command to create a virtual network from a configuration file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_5\n\nLANGUAGE: none\nCODE:\n```\n$ onevnet create priv.net\n```\n\n----------------------------------------\n\nTITLE: Create User for X.509 Authentication with Certificate File (CLI)\nDESCRIPTION: This command creates a new OpenNebula user configured for X.509 certificate authentication using a certificate file.  Replace `new_user` and `/tmp/my_cert.pem` with the correct values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\noneuser create new_user --x509 --cert /tmp/my_cert.pem\n```\n\n----------------------------------------\n\nTITLE: Listing VMs using the command line\nDESCRIPTION: This command lists all VMs and their status. It requires logging into the OpenNebula Front-end node as user `oneadmin`. The output includes the ID, user, group, name, status, CPU usage, memory usage, host, and time of each VM.  The output shows cluster and worker VMs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n[oneadmin@FN]$ onevm list\nID USER     GROUP    NAME                                            STAT  CPU     MEM HOST                                          TIME\n 3 oneadmin oneadmin worker_0_(service_3)                            runn    2      3G <cluster_public_IP>                       0d 00h31\n 2 oneadmin oneadmin master_0_(service_3)                            runn    2      3G <cluster_public_IP>                       0d 00h31\n 1 oneadmin oneadmin vnf_0_(service_3)                               runn    1    512M <cluster_public_IP>                       0d 00h31\n 0 oneadmin oneadmin Service WordPress - KVM-0                       runn    1    768M <cluster_public_IP>                       0d 01h22\n```\n\n----------------------------------------\n\nTITLE: Create System Datastore Configuration\nDESCRIPTION: This snippet demonstrates how to create a system datastore configuration file (systemds.txt) for OpenNebula using the shared transfer mode. It defines the datastore name, sets the transfer manager MAD to 'shared', and specifies the datastore type as SYSTEM_DS.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/nas_ds.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nNAME    = nfs_system\nTM_MAD  = shared\nTYPE    = SYSTEM_DS\n```\n\n----------------------------------------\n\nTITLE: Configuring NFS Exports\nDESCRIPTION: This is an example of the /etc/exports file configuration for the NFS server.  It shares the /storage/one_datastores directory to the 172.20.0.0/24 network with read-write (rw), soft, intr, and async options. The exports(5) man page provides more details on these options.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n# /etc/exports\n#\n# See exports(5) for more information.\n#\n# Use exportfs -r to reread\n\n/storage/one_datastores 172.20.0.0/24(rw,soft,intr,async)\n```\n\n----------------------------------------\n\nTITLE: VM Operation Permissions Configuration - Bash\nDESCRIPTION: This configuration defines the operations that users with ADMIN, MANAGE, and USE permissions can perform on Virtual Machines.  These parameters control which operations require which permission level.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nVM_ADMIN_OPERATIONS  = \"migrate, delete, recover, retry, deploy, resched, backup\"\n\n    VM_MANAGE_OPERATIONS = \"undeploy, hold, release, stop, suspend, resume, reboot,\n        poweroff, disk-attach, nic-attach, disk-snapshot, terminate, disk-resize,\n        snapshot, updateconf, rename, resize, update, disk-saveas, sched-action, sg-attach\"\n\n    VM_USE_OPERATIONS    = \"\"\n```\n\n----------------------------------------\n\nTITLE: Installing OneDeploy Requirements\nDESCRIPTION: This command executes the make requirements target, which creates virtual environments and installs the necessary Python packages and Ansible collections for the OneDeploy installation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmake requirements\n```\n\n----------------------------------------\n\nTITLE: Modifying Image Permissions in OpenNebula\nDESCRIPTION: This command modifies the permissions of an image with ID 0. The permission 640 sets the owner to read/write, the group to read, and others to no access. This allows administrators to control who can access and use the image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\noneimage chmod 0 640\n```\n\n----------------------------------------\n\nTITLE: Nginx Configuration for X.509 Authentication\nDESCRIPTION: This snippet shows the Nginx configuration needed to verify the client certificate and pass the DN in the X-Client-Dn header. This is needed for Sunstone to authenticate against OpenNebula using X.509 certificates.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nssl_verify_client optional;  \nlocation / {\n    ...\n    proxy_set_header X-Client-Dn $client_dn;\n}\n```\n\n----------------------------------------\n\nTITLE: Showing User Information with oneuser in OpenNebula\nDESCRIPTION: This command is used to display information about a specific user in OpenNebula, in this case, the 'oneadmin' user. It outputs details such as the user ID, name, group, password hash, authentication driver, and resource usage. The command requires the OpenNebula CLI tools to be installed and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser show\n```\n\n----------------------------------------\n\nTITLE: Showing Modified Image Permissions in OpenNebula\nDESCRIPTION: This command shows the updated permissions of an image with ID 0 after using `oneimage chmod`. It confirms that the group now has 'USE' permission. This command verifies the successful execution of the `chmod` operation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\noneimage show 0\n```\n\n----------------------------------------\n\nTITLE: Creating an On-Premises Edge Cluster with OneProvision\nDESCRIPTION: This snippet creates an on-premises edge cluster using the `oneprovision create` command with a YAML configuration file. It utilizes the `onprem` provider and specifies the path to the `onprem.yml` configuration file. The command uses the `-Dd` flags for debug and verbose output. This requires `oneprovision` to be properly installed and configured and the `onprem.yml` file to exist with appropriate settings.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision create -Dd --provider onprem /usr/share/one/oneprovision/edge-clusters/metal/provisions/onprem.yml\n```\n\n----------------------------------------\n\nTITLE: Enabling LDAP Auth in Sunstone - YAML\nDESCRIPTION: This snippet shows the configuration to enable LDAP authentication in Sunstone. It updates the :auth parameter in the /etc/one/fireedge-server.conf file to use 'opennebula', delegating authentication to the OpenNebula core and its configured auth driver.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\n:auth: opennebula\n```\n\n----------------------------------------\n\nTITLE: Forcing a Host Update in OpenNebula (onehost)\nDESCRIPTION: This snippet demonstrates how to force an update of a host's monitoring information in OpenNebula using the `onehost forceupdate` command. This command resets the monitoring process for the host, forcing it to re-gather information. The host is specified by its ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost forceupdate 0\n```\n\n----------------------------------------\n\nTITLE: Hook Manager Configuration - Bash\nDESCRIPTION: This configuration configures the Hook System in OpenNebula. It specifies the path to the hook driver executable. The EXECUTABLE parameter defines the program that OpenNebula uses to manage and execute the hooks.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nHM_MAD = [\n        executable = \"one_hm\" ]\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Images\nDESCRIPTION: This snippet lists the images in OpenNebula using the `oneimage list` command. It requires the OpenNebula CLI tool to be installed and configured. The output is a list of images, showing their ID, user, group, name, datastore, size, type, and status. This verifies the image was successfully created from the marketplace app.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage list\n  ID USER     GROUP    NAME                       DATASTORE     SIZE TYPE PER STAT RVMS\n   3 oneadmin oneadmin alpine_market              default       256M OS    No rdy     0\n```\n\n----------------------------------------\n\nTITLE: Defining State Hooks for VMs, Hosts, and Images\nDESCRIPTION: This example defines three state hooks for VMs, hosts, and images.  Each hook executes a specific command based on the resource's state transition. The ``$TEMPLATE`` keyword is used to pass the resource template to the hook command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_2\n\nLANGUAGE: ONECONF\nCODE:\n```\n# VM\nNAME = hook-vm\nTYPE = state\nCOMMAND = new_vm.rb\nARGUMENTS = $TEMPLATE\nON = PROLOG\nRESOURCE = VM\n\n# HOST\nNAME = hook-host\nTYPE = state\nCOMMAND = host-disabled.rb\nSTATE = DISABLED\nRESOURCE = HOST\nREMOTE = yes\n\n# IMAGE\nNAME = hook-image\nTYPE = state\nCOMMAND = image-ready.rb\nSTATE = READY\nRESOURCE = IMAGE\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Community Repository on AlmaLinux\nDESCRIPTION: This bash script adds the OpenNebula Community Edition repository to the AlmaLinux system. It creates a `/etc/yum.repos.d/opennebula.repo` file with the repository configuration, including the base URL, GPG key URL, and enabling the repository. The script then refreshes the yum cache.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# cat << \\\"EOT\\\" > /etc/yum.repos.d/opennebula.repo\n[opennebula]\nname=OpenNebula Community Edition\nbaseurl=https://downloads.opennebula.io/repo/|version|/AlmaLinux/$releasever/$basearch\nenabled=1\ngpgkey=https://downloads.opennebula.io/repo/repo2.key\ngpgcheck=1\nrepo_gpgcheck=1\nEOT\n# yum makecache\n```\n\n----------------------------------------\n\nTITLE: Displaying cluster template information - Bash\nDESCRIPTION: This snippet uses the `onecluster show` command to display the template information associated with a cluster. This includes attributes like QOS, allowing administrators to check the configured settings for each cluster.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/overview.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nonecluster show cluster_a\nCLUSTER TEMPLATE\nQOS=\"GOLD\"\n\nonecluster show cluster_b\nCLUSTER TEMPLATE\nQOS=\"SILVER\"\n```\n\n----------------------------------------\n\nTITLE: Creating a New Group\nDESCRIPTION: This command creates a new group in OpenNebula with the specified name.  The `onegroup` command-line tool is required. The command returns the ID of the newly created group.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_groups.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onegroup create \"new group\"\nID: 100\n```\n\n----------------------------------------\n\nTITLE: Displaying Virtual Machine Information using onevm\nDESCRIPTION: This command shows the information of the Virtual Machine identified by the ID 0. The output includes VM template details, permissions, and other relevant attributes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_41\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 0\n```\n\n----------------------------------------\n\nTITLE: Backup OpenNebula Database via CLI\nDESCRIPTION: This command creates a backup of the OpenNebula database using the `onedb backup` command-line tool. The backup is stored in a SQL file within the `/var/lib/one` directory.  The exact filename includes the date and time of the backup.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_ha.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onedb backup\nMySQL dump stored in /var/lib/one/mysql_localhost_opennebula_2019-9-27_11:52:47.sql\nUse 'onedb restore' or restore the DB using the mysql command:\nmysql -u user -h server -P port db_name < backup_file\n```\n\n----------------------------------------\n\nTITLE: Defining LXC Profiles in VM Template\nDESCRIPTION: This snippet shows how to use the PROFILES attribute in a VM template to include pre-defined LXC profiles. The profile names are separated by commas. The profiles are included in the order specified, which can affect the final container configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_driver.rst#_snippet_6\n\nLANGUAGE: YAML\nCODE:\n```\nPROFILES = \"extra-performance, production\"\n```\n\n----------------------------------------\n\nTITLE: Defining NIC and NIC_ALIAS in OpenNebula\nDESCRIPTION: This snippet demonstrates how to define a NIC and its alias. NIC is defined with a NETWORK and NAME, while NIC_ALIAS references the parent NIC using the PARENT attribute.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_15\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nNIC = [ NETWORK = \"Test\", NAME = \"TestName\" ]\n    NIC_ALIAS = [ NETWORK = \"Test\", PARENT = \"TestName\" ]\n```\n\n----------------------------------------\n\nTITLE: Setting Hugepage Size in VM Template without NUMA Affinity\nDESCRIPTION: This snippet demonstrates how to configure a VM to use hugepages without specifying a particular NUMA node.  OpenNebula will select a NUMA node with sufficient free hugepages. CPU affinity will also be set to the selected NUMA node. The `HUGEPAGE_SIZE` is set to 2.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_15\n\nLANGUAGE: Text\nCODE:\n```\nTOPOLOGY = [ HUGEPAGE_SIZE = 2 ]\n```\n\n----------------------------------------\n\nTITLE: Updated VM Search Syntax Examples\nDESCRIPTION: Illustrates the changes in VM search syntax between older versions and OpenNebula 7.0.  Demonstrates how to perform VM name searches, disk target searches, IP matching, and IP prefix searches using the new pattern-based syntax.  Users need to update their scripts using these examples to adapt to the newer OpenNebula version.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/release_notes/compatibility.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n=======================   ============    ===============================================================\nSearch Description        Old syntax      New syntax\n=======================   ============    ===============================================================\nVM name                   NAME=abc        VM.NAME=abc\nVM with disk target vda   TARGET=vda      VM.TEMPLATE.DISK[*].TARGET=vda\nIP matching               IP=10.10.0.5    VM.TEMPLATE.NIC[*].IP=10.10.0.5\nIP starts with 10.10      ---             VM.TEMPLATE.NIC[*].IP=10.10\n=======================   ============    ===============================================================\n```\n\n----------------------------------------\n\nTITLE: Updating a Scheduled VM Action - OpenNebula\nDESCRIPTION: This command updates a scheduled action for a VM. It uses the `onevm sched-update` command, specifying the VM ID and the ID of the scheduled action to update.  The output shows the attributes of the scheduled action, including the time it's scheduled for.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_27\n\nLANGUAGE: shell\nCODE:\n```\n$ onevm sched-update 0 0\n\nID=\"0\"\nPARENT_ID=\"0\"\nTYPE=\"VM\"\nACTION=\"suspend\"\nTIME=\"1703164454\"\nREPEAT=\"-1\"\nEND_TYPE=\"-1\"\nEND_VALUE=\"-1\"\nDONE=\"-1\"\n```\n\n----------------------------------------\n\nTITLE: Export Marketplace App to Datastore\nDESCRIPTION: This command exports a marketplace application to a specified datastore, creating an image and a VM template. Requires the OpenNebula CLI tools, access to the OpenNebula marketplace, and a configured datastore.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ onemarketapp export 74 alpine_market -d default\n IMAGE\n    ID: 2\nVMTEMPLATE\n    ID: 3\n```\n\n----------------------------------------\n\nTITLE: Updating Host Attributes in OpenNebula\nDESCRIPTION: This snippet demonstrates how to update host attributes using the `onehost update` command. Specifically, it adds a custom tag `TYPE` with the value \"production\" to label a host as a production server. This tag can be used later for scheduling purposes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost update\n...\nTYPE=\"production\"\n```\n\n----------------------------------------\n\nTITLE: Attaching a NIC Alias - OpenNebula Template\nDESCRIPTION: This snippet demonstrates how to define a NIC alias. First, a parent NIC is defined with a name. Then, the NIC_ALIAS refers to the parent NIC by its name. Note: NIC<number> are reserved names.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_19\n\nLANGUAGE: xml\nCODE:\n```\nNIC = [ NETWORK = \"public\", NAME = \"test\" ]\n```\n\nLANGUAGE: xml\nCODE:\n```\nNIC_ALIAS = [ NAME = \"alias\", PARENT = \"test\" ]\n```\n\n----------------------------------------\n\nTITLE: Updating VM Scheduled Action with Disk Snapshot\nDESCRIPTION: This example shows how to update a scheduled action to create a disk snapshot, specifying the disk ID and snapshot name as arguments. The `onevm sched-update` command is used with the action arguments, along with other scheduling parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_34\n\nLANGUAGE: text\nCODE:\n```\n$ onevm sched-update 0 0\n\nID=\"2\"\nPARENT_ID=\"0\"\nTYPE=\"VM\"\nACTION=\"disk-snapshot-create\",\nARGS=\"0, disksnap_example\",\nDAYS=\"1,5\",\nEND_TYPE=\"1\",\nEND_VALUE=\"5\",\nID=\"0\",\nREPEAT=\"0\",\nTIME=\"1537653600\"\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Marketplaces using onemarket\nDESCRIPTION: This code snippet demonstrates how to list the configured marketplaces in OpenNebula using the `onemarket list` command. The output shows the ID, name, size, availability, number of applications, MAD (Marketplace Application Driver), zone, and status of each marketplace.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/public_marketplaces/overview.rst#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\n$ onemarket list\nID NAME                                                            SIZE AVAIL   APPS MAD     ZONE STAT\n1  Linux Containers                                                  0M -          0 linuxco    0 off\n0  OpenNebula Public                                                 0M -         48 one        0 on\n```\n\n----------------------------------------\n\nTITLE: Update User for Remote Authentication (CLI)\nDESCRIPTION: This command updates an existing OpenNebula user to use 'public' remote authentication. It sets the authentication driver to public and sets the password. Replace `johndoe` with the actual username.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\noneuser chauth johndoe public \"johndoe\"\n```\n\n----------------------------------------\n\nTITLE: Deleting Virtual Network\nDESCRIPTION: This snippet shows how to delete a virtual network using its ID or name with the onevnet command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_6\n\nLANGUAGE: none\nCODE:\n```\n$ onevnet delete 0\n$ onevnet delete \"Private\"\n```\n\n----------------------------------------\n\nTITLE: Defining VM Charters in onevm.yaml\nDESCRIPTION: This code defines VM Charters within the `onevm.yaml` configuration file. It specifies the `suspend` and `terminate` charters, including their `time` and `warning` attributes, which control when the actions are executed and when a warning is issued before execution.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_37\n\nLANGUAGE: code\nCODE:\n```\n:charters:\n  :suspend:\n    :time: \"+1209600\"\n    :warning:\n        :time: \"+1123200\"\n  :terminate:\n    :time: \"+1209600\"\n    :warning:\n        :time: \"+1123200\"\n```\n\n----------------------------------------\n\nTITLE: Restore OpenNebula Database using MySQL Command\nDESCRIPTION: This command restores the OpenNebula database from a backup file using the MySQL command-line tool. It requires the user, server, port, database name, and backup file path to be specified.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nmysql -u user -h server -P port db_name < backup_file\n```\n\n----------------------------------------\n\nTITLE: Instantiating a VM Template in OpenNebula\nDESCRIPTION: This command instantiates a VM from a template.  The `--nic service` flag specifies the network interface to attach to the VM, and `alpine` references the name of the VM template to instantiate. It requires access to the OpenNebula CLI tools and a pre-existing VM template configured with the desired properties.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\nonetemplate instantiate --nic service alpine\n```\n\n----------------------------------------\n\nTITLE: Sample oneacct output\nDESCRIPTION: This is an example of the output generated by the `oneacct` command, displaying accounting information for virtual machines. It shows various fields such as Virtual Machine ID (VID), hostname, action, reason, start time, end time, memory, CPU, network RX, network TX, and disk usage.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/accounting.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n$ oneacct\n# User 0\n\n VID HOSTNAME        ACTION           REAS     START_TIME       END_TIME MEMORY CPU  NETRX  NETTX   DISK\n\n  13 host01          nic-attach       user 05/17 17:10:57 05/17 17:12:48   256M 0.1  19.2K  15.4K     8G\n  13 host01          nic-detach       user 05/17 17:12:48 05/17 17:13:48   256M 0.1  36.9K    25K     8G\n  13 host01          nic-attach       user 05/17 17:13:48 05/17 17:14:54   256M 0.1  51.2K  36.4K     8G\n  13 host01          nic-detach       user 05/17 17:14:54 05/17 17:17:19   256M 0.1  79.8K  61.7K     8G\n  13 host01          nic-attach       user 05/17 17:17:19 05/17 17:17:27   256M 0.1  79.8K  61.7K     8G\n  13 host01          terminate-hard   user 05/17 17:17:27 05/17 17:37:52   256M 0.1 124.6K  85.9K     8G\n  14 host02          nic-attach       user 05/17 17:38:16 05/17 17:40:00   256M 0.1  16.5K  13.2K     8G\n  14 host02          poweroff         user 05/17 17:40:00 05/17 17:53:40   256M 0.1  38.3K  18.8K     8G\n  14 host02          terminate-hard   user 05/17 17:55:55 05/18 14:54:19   256M 0.1     1M  27.3K     8G\n```\n\n----------------------------------------\n\nTITLE: Retrieving Service Information with OneGate (bash)\nDESCRIPTION: This command shows how to retrieve service information using the `onegate service show` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onegate service show\nSERVICE 1\nNAME                : PANACEA service\nSTATE               : RUNNING\n\nROLE master\nVM 8\nNAME                : master_0_(service_1)\n\nROLE slave\nVM 9\nNAME                : slave_0_(service_1)\n```\n\n----------------------------------------\n\nTITLE: Listing OneFlow Services with OneFlow CLI\nDESCRIPTION: This command lists all the OneFlow services running. The important fields in output are ID, USER, GROUP, NAME, STARTTIME and STAT (status). The command helps to check the service's status. It's used to confirm the `DEPLOYING` state when VMs are running.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_17\n\nLANGUAGE: text\nCODE:\n```\noneflow list\n ID USER     GROUP    NAME                                                                   STARTTIME STAT\n  3 oneadmin oneadmin OneKE 1.29                                                        08/30 12:30:07 DEPLOYING\n```\n\n----------------------------------------\n\nTITLE: Define Image in OneProvision (YAML)\nDESCRIPTION: This snippet shows how to define an image in OneProvision using YAML. It specifies the image's name, datastore ID (ds_id), and size.  These parameters are mandatory. ds_id references the ID of the datastore where the image will be stored.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nimages:\n  - name: \"test_image\"\n    ds_id: 1\n    size: 2048\n```\n\n----------------------------------------\n\nTITLE: Configure LDAP Driver Managed Groups in oned.conf\nDESCRIPTION: This shows how to configure driver managed groups for the LDAP authentication driver in the oned.conf file. The example sets DRIVER_MANAGED_GROUPS and DRIVER_MANAGED_GROUP_ADMIN to \"YES\".\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-auth.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nAUTH_MAD_CONF = [\n    NAME = \"ldap\",\n    PASSWORD_CHANGE = \"YES\",\n    DRIVER_MANAGED_GROUPS = \"YES\",\n    DRIVER_MANAGED_GROUP_ADMIN = \"YES\",\n    MAX_TOKEN_TIME = \"86400\"\n]\n```\n\n----------------------------------------\n\nTITLE: Defining NIC with NETWORK_ID in OpenNebula\nDESCRIPTION: This snippet shows how to define a NIC (Network Interface Card) for a VM using the NETWORK_ID attribute in OpenNebula.  The NETWORK_ID specifies the virtual network the NIC should be attached to.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_12\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nNIC = [ NETWORK_ID = 1 ]\n```\n\n----------------------------------------\n\nTITLE: Updating host information - Bash\nDESCRIPTION: This snippet demonstrates how to manually update host information using the `onehost update` command. This allows administrators to add or modify custom attributes of a host, such as QoS levels or other specific properties.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/overview.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nonehost update\n```\n\n----------------------------------------\n\nTITLE: onedb Automatic Connection Parameters (Bash)\nDESCRIPTION: Shows how to run the `onedb` command with automatic connection parameters, which are taken from the OpenNebula Daemon configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onedb <command> -v\n```\n\n----------------------------------------\n\nTITLE: Changing a user's group in OpenNebula\nDESCRIPTION: This snippet demonstrates how to change the group membership of a user using the `oneuser chgrp` command. This command requires the username and the target group as arguments. It is used to assign administrative privileges or manage resource access.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser chgrp <user_name> oneadmin\n```\n\n----------------------------------------\n\nTITLE: Packing Policy RANK Expression\nDESCRIPTION: This RANK expression implements the packing policy, which aims to minimize the number of cluster nodes in use. It prioritizes nodes with more running VMs to consolidate VMs and reduce fragmentation.  It doesn't have any dependencies and is used directly in the OpenNebula scheduler configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/rank_scheduler.rst#_snippet_0\n\nLANGUAGE: OpenNebula\nCODE:\n```\nRANK = RUNNING_VMS\n```\n\n----------------------------------------\n\nTITLE: Lock an Image via CLI - OpenNebula\nDESCRIPTION: This command locks an image with ID 2 and attempts to delete it. The 'oneimage lock' command is used to lock the image, and the 'oneimage delete' command fails because the user is not authorized to perform the MANAGE action.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage lock 2\n$ oneimage delete 2\n[one.image.delete] User [4] : Not authorized to perform MANAGE IMAGE [2].\n```\n\n----------------------------------------\n\nTITLE: Creating AWS Provider\nDESCRIPTION: This command creates an AWS provider in OpenNebula using the provided YAML template file. The `oneprovider create` command is used to register the provider with the specified configuration. The command returns the ID of the newly created provider.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/aws_provider.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovider create provider.yaml\nID: 0\n```\n\n----------------------------------------\n\nTITLE: Checking OpenNebula Service Status using systemctl\nDESCRIPTION: This command checks the status of the OpenNebula service using systemctl. It verifies that the OpenNebula Cloud Controller Daemon (oned) is active and running. It requires systemd to be the init system.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nsystemctl status opennebula.service\n```\n\n----------------------------------------\n\nTITLE: Updating Service Template with curl\nDESCRIPTION: This curl command updates an existing service template with ID 4 in the OpenNebula API. It uses the PUT method and provides the updated template data in JSON format via the `--data` parameter.  Authentication is performed using basic authentication with 'oneadmin:password'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service_template/4 -u 'oneadmin:password' -v -X PUT --data '{\n  \"name\":\"web-application\",\n  \"deployment\":\"straight\",\n  \"roles\":[\n    {\n      \"name\":\"frontend\",\n      \"cardinality\":\"1\",\n      \"template_id\":\"0\",\n      \"shutdown_action\":\"shutdown-hard\",\n      \"min_vms\":\"1\",\n      \"max_vms\":\"4\",\n      \"cooldown\":\"30\",\n      \"elasticity_policies\":[\n        {\n          \"type\":\"PERCENTAGE_CHANGE\",\n          \"adjust\":\"20\",\n          \"min_adjust_step\":\"1\",\n          \"expression\":\"CUSTOM_ATT>40\",\n          \"period\":\"3\",\n          \"period_number\":\"30\",\n          \"cooldown\":\"30\"\n        }\n      ],\n      \"scheduled_policies\":[\n        {\n          \"type\":\"CHANGE\",\n          \"adjust\":\"4\",\n          \"recurrence\":\"0 2 1-10 * * \"\n        }\n      ]\n    },\n    {\n      \"name\":\"worker\",\n      \"cardinality\":\"2\",\n      \"template_id\":\"0\",\n      \"type\": \"vm\",\n      \"shutdown_action\":\"shutdown\",\n      \"parents\":[\n        \"frontend\"\n      ],\n      \"min_vms\":\"2\",\n      \"max_vms\":\"10\",\n      \"cooldown\":\"240\",\n      \"elasticity_policies\":[\n        {\n          \"type\":\"CHANGE\",\n          \"adjust\":\"5\",\n          \"expression\":\"ATT=3\",\n          \"period\":\"5\",\n          \"period_number\":\"60\",\n          \"cooldown\":\"240\"\n        }\n      ],\n      \"scheduled_policies\":[\n      ]\n    }\n  ],\n  \"shutdown_action\":\"shutdown\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Applying Kubernetes manifest using kubectl\nDESCRIPTION: This command applies the YAML manifest to create the Service and IngressRoute for nginx.  It requires `kubectl` to be configured and connected to the Kubernetes cluster, and assumes the `expose-nginx.yaml` file exists in the current directory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nroot@oneke-ip-172-20-0-2:~# kubectl apply -f expose-nginx.yaml\nservice/nginx created\ningressroute.traefik.containo.us/nginx created\n```\n\n----------------------------------------\n\nTITLE: Creating Data Volume with Filesystem\nDESCRIPTION: This snippet shows how to create a data volume with a specific filesystem (ext4) already created on it. This is achieved using the `oneimage create` command with the `--fs` option. The new image will be ready to use by VMs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage create --size 10240 --name fs-vol --format qcow2 --fs ext4 --datastore default\n```\n\n----------------------------------------\n\nTITLE: Checking NFS Mount (df Command)\nDESCRIPTION: This snippet uses the `df` command to check if the NFS share with the datastores is mounted on the Front-end. The output should show the NFS share (e.g., `172.20.0.5:/storage/one_datastores`) mounted on `/var/lib/one/datastores`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ndf\n```\n\n----------------------------------------\n\nTITLE: Setting File Permissions\nDESCRIPTION: This snippet sets the file permissions of the passphrase.luks file to 600, ensuring only the owner has read and write access. This enhances the security of the encryption key.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ chmod 600 passphrase.luks\n```\n\n----------------------------------------\n\nTITLE: Configuring Rank Scheduler for Multiple VMs\nDESCRIPTION: This configuration snippet from /etc/one/schedulers/rank.conf changes the MAX_HOST parameter, allowing the rank scheduler to deploy more than one VM per host. Setting MAX_HOST to 10 enables the scheduler to submit up to 10 VMs per host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_18\n\nLANGUAGE: code\nCODE:\n```\nMAX_HOST = 10\n```\n\n----------------------------------------\n\nTITLE: Create Backup Directory (Shell)\nDESCRIPTION: This snippet creates a backup directory for storing the configuration, remotes, keys, and database backup of the failing frontend.  The BAK_DIR variable is set to ~/one_backup and then the directory is created.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/replace_failing_fe.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nBAK_DIR=~/one_backup\nmkdir -p $BAK_DIR\n```\n\n----------------------------------------\n\nTITLE: Showing Image Source\nDESCRIPTION: This snippet shows how to retrieve the source path of an OpenNebula image using the `oneimage show` command, `grep` to filter for the \"source\" attribute, `cut` to isolate the path.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage show 0|grep -i source|cut -d ':' -f2\n```\n\n----------------------------------------\n\nTITLE: Retrieving VM Information with OneGate (bash)\nDESCRIPTION: This command shows how to retrieve the information of the current Virtual Machine using the `onegate vm show` command. If no argument is provided, the information of the current Virtual Machine will be retrieved.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onegate vm show\nVM 8\nNAME                : master_0_(service_1)\nSTATE               : RUNNING\nIP                  : 192.168.122.23\n```\n\n----------------------------------------\n\nTITLE: Displaying Host Monitoring Information with PIN_POLICY\nDESCRIPTION: This example shows the output of the `onehost show` command, focusing on the `PIN_POLICY` setting and NUMA node information. The `PIN_POLICY` is set to `PINNED`, indicating that VMs are allocated and pinned to specific nodes based on defined policies. It also displays core usage and memory allocation details for the NUMA nodes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_16\n\nLANGUAGE: Shell\nCODE:\n```\n$ onehost show 0\n...\nMONITORING INFORMATION\nPIN_POLICY=\"PINNED\"\n...\n\nNUMA NODES\n\n  ID CORES                                              USED FREE\n   0 X- X- -- --                                        4    4\n\nNUMA MEMORY\n\n NODE_ID TOTAL    USED_REAL            USED_ALLOCATED       FREE\n\t 0 7.6G     6.8G                 1024M                845.1M\n```\n\n----------------------------------------\n\nTITLE: QEMU Guest Agent Information Retrieval\nDESCRIPTION: This JSON output displays detailed guest information retrieved by executing the 'guest-info' command through the QEMU Guest Agent.  It showcases the agent version and a list of supported commands along with their enabled status.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"return\": {\n    \"version\": \"6.2.0\",\n    \"supported_commands\": [\n      {\n        \"enabled\": true,\n        \"name\": \"guest-ssh-remove-authorized-keys\",\n        \"success-response\": true\n      },\n      {\n        \"enabled\": true,\n        \"name\": \"guest-ssh-add-authorized-keys\",\n        \"success-response\": true\n      },\n      {\n        \"enabled\": true,\n        \"name\": \"guest-ssh-get-authorized-keys\",\n        \"success-response\": true\n      },\n      {\n        \"enabled\": false,\n        \"name\": \"guest-get-devices\",\n        \"success-response\": true\n      },\n      {\n        \"enabled\": true,\n        \"name\": \"guest-get-osinfo\",\n        \"success-response\": true\n      },\n      {\n        \"enabled\": true,\n        \"name\": \"guest-ping\",\n        \"success-response\": true\n      },\n      {\n        \"enabled\": true,\n        \"name\": \"guest-sync\",\n        \"success-response\": true\n      },\n      {\n        \"enabled\": true,\n        \"name\": \"guest-sync-delimited\",\n        \"success-response\": true\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting ONE_POOL_PAGE_SIZE Environment Variable (Bash)\nDESCRIPTION: This snippet demonstrates how to set the ONE_POOL_PAGE_SIZE environment variable to control the pagination size for pool responses from the OpenNebula Cloud API. It shows how to set a specific page size (5000) and how to disable pagination.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/cli.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ export ONE_POOL_PAGE_SIZE=5000        # Sets the page size to 5000\n$ export ONE_POOL_PAGE_SIZE=disabled    # Disables pool pagination\n```\n\n----------------------------------------\n\nTITLE: Get Service Information via OneGate API\nDESCRIPTION: This curl command retrieves information about the service using the OneGate API. It uses the X-ONEGATE-TOKEN and X-ONEGATE-VMID headers for authentication and specifies the /service endpoint. The response is a JSON object containing details about the service.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X \"GET\" \"${ONEGATE_ENDPOINT}/service\" \\\n    --header \"X-ONEGATE-TOKEN: `cat token.txt`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\"\n\n{\n    \"SERVICE\": {\n        \"id\": ...,\n        \"name\": ...,\n        \"roles\": [\n            {\n                \"name\": ...,\n                \"cardinality\": ...,\n                \"state\": ...,\n                \"nodes\": [\n                    {\n                        \"deploy_id\": ...,\n                        \"running\": true|false,\n                        \"vm_info\": {\n                            // VM template as return by GET /VM\n                        }\n\n                    },\n                    // more nodes ...\n                ]\n            },\n            // more roles ...\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating VM Scheduled Action\nDESCRIPTION: This example shows the output after updating a scheduled action using the `onevm sched-update` command. It displays the updated attributes of the scheduled action.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_32\n\nLANGUAGE: text\nCODE:\n```\n$ onevm sched-update 0 2\n\nID=\"2\"\nPARENT_ID=\"0\"\nTYPE=\"VM\"\nACTION=\"snapshot-create\"\nARGS=\"snap-01\"\nTIME=\"1701998190\"\nREPEAT=\"3\"\nDAYS=\"5\"\nEND_TYPE=\"2\"\nEND_VALUE=\"1893452400\"\nDONE=\"1701980968\"\n```\n\n----------------------------------------\n\nTITLE: Verifying VM name using OneGate\nDESCRIPTION: This command verifies that the VM name can be retrieved through OneGate. It uses `onegate vm show` to fetch the VM details in JSON format, and `jq` to extract the VM name.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onegate vm show -j | jq -r '.VM.NAME'\nexample0-0\n```\n\n----------------------------------------\n\nTITLE: onecfg diff --format text Usage Example\nDESCRIPTION: This example shows the output of the `onecfg diff` command using the `text` format. It displays changes grouped by configuration file, with each change indicated by an operation (ins, set, rm) and the corresponding path and value. It's designed for human readability but not suitable for patching. Requires `onecfg` tool to be set up.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/diff_formats.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n/etc/one/cli/oneimage.yaml\n- ins :ID/:adjust false\n- set :USER/:size 15\n- set :GROUP/:size 15\n- ins :NAME/:expand false\n\n/etc/one/oned.conf\n- set DEFAULT_DEVICE_PREFIX \"\\\"sd\\\"\"\n- set VM_MAD/\"vcenter\"/ARGUMENTS \"\\\"-p -t 15 -r 0 -s sh vcenter\\\"\"\n- rm  VM_MAD/\"vcenter\"/DEFAULT\n- ins HM_MAD/ARGUMENTS \"\\\"-p 2101 -l 2102 -b 127.0.0.1\\\"\"\n- ins VM_RESTRICTED_ATTR \"\\\"NIC/FILTER\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Listing Service Templates with curl\nDESCRIPTION: This curl command retrieves a list of all service templates from the OpenNebula API. It uses basic authentication with the 'oneadmin:password' credentials to access the API endpoint at http://127.0.0.1:2474/service_template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncurl -u 'oneadmin:password' http://127.0.0.1:2474/service_template -v\n```\n\n----------------------------------------\n\nTITLE: Show Image and Template Details using oneimage and onetemplate\nDESCRIPTION: These commands display the details of the created image (ID 9) and template (ID 8). This is useful to check that the resources were properly created and to update the OpenNebula installation as needed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vrouter.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ oneimage show 9 # 9 is the IMAGE ID from the previous onemarketapp command\n$ onetemplate show 8 # 8 is for the VMTEMPLATE ID\n```\n\n----------------------------------------\n\nTITLE: Getting the Ceph user key\nDESCRIPTION: This snippet retrieves the key for the Ceph user 'libvirt' and saves it to a file named 'client.libvirt.key'. This key will be distributed to the OpenNebula Nodes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ceph auth get-key client.libvirt | tee client.libvirt.key\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ ceph auth get client.libvirt -o ceph.client.libvirt.keyring\n```\n\n----------------------------------------\n\nTITLE: Listing OneFlow Services using the command line\nDESCRIPTION: This command lists all OneFlow services and their status. It requires logging into the OpenNebula Front-end node as user `oneadmin`. The output shows the ID, user, group, name, start time, and status of each service. We are looking for the OneKE service to be in the RUNNING state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n[oneadmin@FN]$ oneflow list\nID USER     GROUP    NAME                                 STARTTIME STAT\n3 oneadmin oneadmin Service OneKE 1.29              04/29 08:18:17 RUNNING\n```\n\n----------------------------------------\n\nTITLE: List Existing Services Using OneFlow CLI\nDESCRIPTION: This code snippet demonstrates how to list the available services using the `oneflow list` command in the OneFlow CLI. The command displays information about each service, including its ID, user, group, name, start time, and state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\n$ oneflow list\nID USER            GROUP           NAME          STARTTIME          STATE\n 1 oneadmin        oneadmin        my_service    10/28 17:42:46     PENDING\n```\n\n----------------------------------------\n\nTITLE: ACL Rule Example - OpenNebula\nDESCRIPTION: This ACL rule allows all users in group 105 to create new virtual resources (VMs, NETs, IMAGES, and TEMPLATES). It demonstrates the use of '*' for all resources and the CREATE right.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_5\n\nLANGUAGE: \nCODE:\n```\n@105 VM+NET+IMAGE+TEMPLATE/* CREATE\n```\n\n----------------------------------------\n\nTITLE: Example Deployment File (XML)\nDESCRIPTION: This is an example of an XML deployment file generated by OpenNebula for VMs. It contains the VM's template information, including CPU, memory, disks, and other configurations.  The `DISK_ID` attribute is crucial for the TM driver to access the disk images at `VM_DIR/VMID/images/disk.DISK_ID`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-vmm.rst#_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<TEMPLATE>\n  <CPU><![CDATA[1.0]]></CPU>\n  <DISK>\n    <DISK_ID><![CDATA[0]]></DISK_ID>\n    <SOURCE><![CDATA[/home/user/vm.img]]></SOURCE>\n    <TARGET><![CDATA[sda]]></TARGET>\n  </DISK>\n  <MEMORY><![CDATA[512]]></MEMORY>\n  <NAME><![CDATA[test]]></NAME>\n  <VMID><![CDATA[0]]></VMID>\n</TEMPLATE>\n```\n\n----------------------------------------\n\nTITLE: SSH Configuration Example\nDESCRIPTION: This example configures the SSH client for the oneadmin user. Key parameters include `ServerAliveInterval` to keep the connection alive, `ControlMaster` and `ControlPersist` for connection multiplexing, `StrictHostKeyChecking` to avoid interactive prompts, `UserKnownHostsFile` to disable host key checking, and `ConnectTimeout` to limit the connection attempt duration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/vm_ha.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nHost *\nServerAliveInterval 10\nControlMaster no\nControlPersist 70s\nControlPath /run/one/ssh-socks/ctl-M-%C.sock\nStrictHostKeyChecking no\nUserKnownHostsFile /dev/null\nConnectTimeout 15\n```\n\n----------------------------------------\n\nTITLE: Update Service with curl\nDESCRIPTION: This snippet demonstrates how to update an existing OpenNebula service with a new configuration. The update includes changes to the service's roles, including elasticity and scheduled policies.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service/4 -u 'oneadmin:password' -v -X PUT --data '{\n  \"name\":\"web-application\",\n  \"deployment\":\"straight\",\n  \"roles\":[\n    {\n      \"name\":\"frontend\",\n      \"cardinality\":\"1\",\n      \"template_id\":\"0\",\n      \"type\": \"vm\",\n      \"shutdown_action\":\"shutdown-hard\",\n      \"min_vms\":\"1\",\n      \"max_vms\":\"4\",\n      \"cooldown\":\"30\",\n      \"elasticity_policies\":[\n        {\n          \"type\":\"PERCENTAGE_CHANGE\",\n          \"adjust\":\"20\",\n          \"min_adjust_step\":\"1\",\n          \"expression\":\"CUSTOM_ATT>40\",\n          \"period\":\"3\",\n          \"period_number\":\"30\",\n          \"cooldown\":\"30\"\n        }\n      ],\n      \"scheduled_policies\":[\n        {\n          \"type\":\"CHANGE\",\n          \"adjust\":\"4\",\n          \"recurrence\":\"0 2 1-10 * * \"\n        }\n      ]\n    },\n    {\n      \"name\":\"worker\",\n      \"cardinality\":\"2\",\n      \"template_id\":\"0\",\n      \"type\": \"vm\",\n      \"shutdown_action\":\"shutdown\",\n      \"parents\":[\n        \"frontend\"\n      ],\n      \"min_vms\":\"2\",\n      \"max_vms\":\"10\",\n      \"cooldown\":\"240\",\n      \"elasticity_policies\":[\n        {\n          \"type\":\"CHANGE\",\n          \"adjust\":\"5\",\n          \"expression\":\"ATT=3\",\n          \"period\":\"5\",\n          \"period_number\":\"60\",\n          \"cooldown\":\"240\"\n        }\n      ],\n      \"scheduled_policies\":[\n      ]\n    }\n  ],\n  \"shutdown_action\":\"shutdown\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Check Database Consistency (Bash)\nDESCRIPTION: Checks the database consistency using the `onedb fsck` command. This command verifies the integrity of the OpenNebula database after the upgrade.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ onedb fsck\n```\n\n----------------------------------------\n\nTITLE: onedb change-history (Text)\nDESCRIPTION: Changes the CLUSTER_ID of a previous VM sequence using the `onedb change-history` command. This is useful when a cluster is accidentally deleted.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n$ onedb change-history --id 224 --seq 0 '/HISTORY/CID' 0\n```\n\n----------------------------------------\n\nTITLE: Printing SSH Host Key Hashes\nDESCRIPTION: This command prints the SHA256 hashes of the host public SSH keys on a hypervisor node. This is used to securely add the identity of the remote host into the known_hosts file on the Front-end node.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/advanced_ssh_usage.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# for K in /etc/ssh/ssh_host_*_key; do ssh-keygen -l -E sha256 -f \"$K\"; done\n```\n\n----------------------------------------\n\nTITLE: Validating Configuration Files Verbose Mode\nDESCRIPTION: This snippet demonstrates using `onecfg validate` with the `--verbose` option.  The output shows each file checked and its status (OK or ERROR).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg validate --verbose\nINFO  : File '/etc/one/vcenter_driver.default' - OK\nINFO  : File '/etc/one/ec2_driver.default' - OK\nINFO  : File '/etc/one/az_driver.default' - OK\nINFO  : File '/etc/one/auth/ldap_auth.conf' - OK\nINFO  : File '/etc/one/auth/server_x509_auth.conf' - OK\n...\n```\n\n----------------------------------------\n\nTITLE: List OpenNebula Datastores\nDESCRIPTION: This command lists the OpenNebula datastores. It displays the datastore ID, name, size, available space, clusters, and type information. Requires the OpenNebula CLI tools to be installed and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onedatastore list\n  ID NAME                         SIZE  AVA CLUSTERS IMAGES TYPE DS      TM      STAT\n 101 onprem-hci-cluster-system    28.3G 100% 100           0 sys  -       ceph    on\n 100 onprem-hci-cluster-image     28.3G 100% 100           1 img  ceph    ceph    on\n```\n\n----------------------------------------\n\nTITLE: Hashing a CA Certificate with OpenSSL\nDESCRIPTION: This code snippet demonstrates how to use OpenSSL to generate a hash of a CA certificate. The hash is required to properly name the certificate file in the trusted CA directory, allowing OpenNebula to identify and trust the CA. The output of this command is used when copying the certificate to the appropriate directory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nopenssl x509 -noout -hash -in cacert.pem\n```\n\n----------------------------------------\n\nTITLE: RDM Image Datastore Template\nDESCRIPTION: This template is used to create an Image Datastore for RDM. It defines the name, type, DS_MAD, TM_MAD, and DISK_TYPE attributes. The DS_MAD and TM_MAD are set to 'dev' which corresponds to the previously defined TM_MAD_CONF. The DISK_TYPE is set to BLOCK.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/dev_ds.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ cat rdm.conf\nNAME      = rdm_datastore\nTYPE      = \"IMAGE_DS\"\nDS_MAD    = \"dev\"\nTM_MAD    = \"dev\"\nDISK_TYPE = \"BLOCK\"\n\n$ onedatastore create rdm.conf\nID: 101\n```\n\n----------------------------------------\n\nTITLE: Listing Clusters using onecluster\nDESCRIPTION: This snippet demonstrates how to list existing OpenNebula clusters using the `onecluster list` command.  It shows the basic output format, including ID, Name, Hosts, Nets and Datastores counts.  The command does not take any parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster list\n  ID NAME            HOSTS NETS  DATASTORES\n```\n\n----------------------------------------\n\nTITLE: Show Virtual Machine Information\nDESCRIPTION: This command shows detailed information about a specific virtual machine. Requires the OpenNebula CLI tools to be installed and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 11\nVIRTUAL MACHINE 10 INFORMATION\nID                  : 11                  \nNAME                : alpine_market-11    \nUSER                : oneadmin            \nGROUP               : oneadmin            \nSTATE               : ACTIVE              \nLCM_STATE           : RUNNING\n\n...\n```\n\n----------------------------------------\n\nTITLE: Show VM Template via onevm\nDESCRIPTION: This command displays the VM template using the onevm command-line tool. It's used to verify that the template has been updated with the new APP_LOAD attribute after the PUT request to the OneGate API.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 0\n...\nUSER TEMPLATE\nAPP_LOAD=\"9.7\"\n```\n\n----------------------------------------\n\nTITLE: Copying SSH key to VNF node\nDESCRIPTION: This command copies the local SSH private key to the VNF node. Replace `1.2.3.4` with the public IP address of the VNF node.  Requires SSH access to VNF node.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ scp ~/.ssh/id_rsa root@1.2.3.4:/root/.ssh/           # copy the key\n```\n\n----------------------------------------\n\nTITLE: Moving ceph.conf and extracting Ceph Key\nDESCRIPTION: These snippets outline the process of moving the ceph.conf file to a non-default location and extracting the Ceph key into a separate file on nodes within the BRIDGE_LIST.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo mv /etc/ceph/ceph.conf /etc/ceph/ceph1.conf\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo grep -o -P '(?<=key = ).*(?=)' /etc/ceph/ceph.client.oneadmin.keyring >> /etc/ceph/ceph.client.oneadmin.key\n```\n\n----------------------------------------\n\nTITLE: Displaying PCI Devices with onehost show\nDESCRIPTION: This command displays a list of PCI devices per host in OpenNebula. It shows the VM address, type, and name of each device.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nPCI DEVICES\n\n   VM ADDR    TYPE           NAME\n      00:00.0 8086:0a04:0600 Haswell-ULT DRAM Controller\n      00:02.0 8086:0a16:0300 Haswell-ULT Integrated Graphics Controller\n  123 00:03.0 8086:0a0c:0403 Haswell-ULT HD Audio Controller\n      00:14.0 8086:9c31:0c03 8 Series USB xHCI HC\n      00:16.0 8086:9c3a:0780 8 Series HECI #0\n      00:1b.0 8086:9c20:0403 8 Series HD Audio Controller\n      00:1c.0 8086:9c10:0604 8 Series PCI Express Root Port 1\n      00:1c.2 8086:9c14:0604 8 Series PCI Express Root Port 3\n      00:1d.0 8086:9c26:0c03 8 Series USB EHCI #1\n      00:1f.0 8086:9c43:0601 8 Series LPC Controller\n      00:1f.2 8086:9c03:0106 8 Series SATA Controller 1 [AHCI mode]\n      00:1f.3 8086:9c22:0c05 8 Series SMBus Controller\n      02:00.0 8086:08b1:0280 Wireless 7260\n```\n\n----------------------------------------\n\nTITLE: Defining an API Hook in OpenNebula\nDESCRIPTION: This example demonstrates how to define an API hook that executes the command ``/var/lib/one/remotes/hooks/log_new_user.rb`` whenever a new user is created. It utilizes the ``$API`` keyword to pass API call information to the hook command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_1\n\nLANGUAGE: ONECONF\nCODE:\n```\nNAME      = hook-API\nTYPE      = api\nCOMMAND   = \"log_new_user.rb\"\nARGUMENTS = $API\nCALL      = \"one.user.allocate\"\nARGUMENTS_STDIN = yes\n```\n\n----------------------------------------\n\nTITLE: Restore Image for Full VM Restore\nDESCRIPTION: This command restores an image to create new VM template and images for a full restore. The `-d` option specifies the datastore, and the `--no_ip` option prevents restoring IP addresses. The output returns the IDs of the newly created VM template and images.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage restore -d default --no_ip 1\n```\n\n----------------------------------------\n\nTITLE: Importing a Service Template Interactively\nDESCRIPTION: This command imports a Service Template into a marketplace using an interactive process. It prompts the user to confirm the import of VM templates and to select the target marketplaces for both the service template and the individual roles within the service template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/marketapps.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nonemarketapp service-template import 0\n```\n\n----------------------------------------\n\nTITLE: Configure FireEdge Logo in YAML\nDESCRIPTION: This snippet demonstrates how to configure the logo displayed in the FireEdge interface by modifying the `/etc/one/fireedge/sunstone/sunstone-views.yaml` file. The `logo` attribute specifies the image file to use, which must be located in the `/usr/lib/one/fireedge/dist/client/assets/images/logos` directory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/fireedge.rst#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# /etc/one/fireedge/sunstone/sunstone-views.yaml\n---\nlogo: linux.png\n\ngroups:\n    oneadmin:\n        - admin\n        - user\ndefault:\n    - user\n```\n\n----------------------------------------\n\nTITLE: Instantiate Virtual Network from Template\nDESCRIPTION: This command instantiates a virtual network from a template. It specifies the IP address and size of the network. Requires the OpenNebula CLI tools to be installed and configured and the network template to be present.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ onevntemplate instantiate 0 --ip 192.168.0.100 --size 64\nVN ID: 5\n```\n\n----------------------------------------\n\nTITLE: Custom QEMU Guest Agent Commands\nDESCRIPTION: This YAML configuration shows an example with multiple commands to execute through the QEMU Guest Agent. It defines two commands: 'vm_qemu_ping' and 'guest_info', both using the 'one' command-line tool to communicate with the guest.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\n:enabled: true\n:commands:\n  :vm_qemu_ping: \"one-$vm_id '{\\\"execute\\\":\\\"guest-ping\\\"}' --timeout 5\"\n  :guest_info: \"one-$vm_id '{\\\"execute\\\":\\\"guest-info\\\"}' --timeout 5\"\n```\n\n----------------------------------------\n\nTITLE: Example Run of OneSupport vCenter Permissions in Bash\nDESCRIPTION: This is an example demonstrating how to execute the onesupport_vcenter_privs tool to scan vCenter permissions. It includes the necessary parameters like host, user, password, and the check user for OpenNebula and redirects output for later analysis.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/support.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onesupport_vcenter_privs --host=vcenter.localdomain \\\n    --user=administrator@vsphere.local --password=TopSecretPassword \\\n    --check-user=oneadmin@vsphere.local\n```\n\n----------------------------------------\n\nTITLE: Getting Kubernetes pods using kubectl\nDESCRIPTION: This command checks the status of the Kubernetes pods. It requires `kubectl` to be configured and connected to the Kubernetes cluster.  We are looking for the nginx pod to be in the Running state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nroot@oneke-ip-172-20-0-2:~# kubectl get pods\nNAME    READY   STATUS    RESTARTS   AGE\nnginx   1/1     Running   0          86s\n```\n\n----------------------------------------\n\nTITLE: Upgrading OpenNebula Configuration (Latest)\nDESCRIPTION: This command upgrades the OpenNebula configuration to the latest available version with verbose output, automatically determining the target version. It also backs up the current configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade --verbose\n```\n\n----------------------------------------\n\nTITLE: Create Keyrings Directory on Debian 11\nDESCRIPTION: This bash script creates the `/etc/apt/keyrings` directory on Debian 11 systems, as it does not exist by default. This directory is used to store GPG keys for verifying package repositories.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# mkdir -p /etc/apt/keyrings\n```\n\n----------------------------------------\n\nTITLE: Accessing OneProvision GUI URL\nDESCRIPTION: This URL provides access to the OneProvision GUI, which allows managing deployments of fully operational Clusters on remote Edge Cloud providers. The URL is accessible through a web browser.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/fireedge.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nhttp://<OPENNEBULA-FRONTEND>:2616/fireedge/provision\n```\n\n----------------------------------------\n\nTITLE: Manual Restore from Backup after Failed OpenNebula Upgrade\nDESCRIPTION: This example demonstrates a scenario where the OpenNebula upgrade fails and requires manual intervention to restore the configuration files from a backup. The output shows the location of the backup and the directories that need to be restored manually.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/conflicts.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade\nANY   : Backup stored in '/tmp/onescape/backups/2019-12-18_12:22:28_2891'\nFATAL : Fatal error on restore, we are very sorry! You have to restore following directories manually:\n    - copy /tmp/onescape/backups/2019-12-18_12:22:28_2891/etc/one into /etc/one\n    - copy /tmp/onescape/backups/2019-12-18_12:22:28_2891/var/lib/one/remotes into /var/lib/one/remotes\nFATAL : FAILED - Data synchronization failed\n```\n\n----------------------------------------\n\nTITLE: Dumping Image and Datastore Information in XML\nDESCRIPTION: This XML snippet represents the data structure used to dump information about an image and its associated datastore. It includes details such as IDs, permissions, paths, types, sizes, and template configurations for both the image and the datastore. This structure is typically used as input or output for datastore driver actions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_11\n\nLANGUAGE: xml\nCODE:\n```\n<DS_DRIVER_ACTION_DATA>\n    <IMAGE>\n        <ID>0</ID>\n        <UID>0</UID>\n        <GID>0</GID>\n        <UNAME>oneadmin</UNAME>\n        <GNAME>oneadmin</GNAME>\n        <NAME>ttylinux</NAME>\n        <PERMISSIONS>\n            <OWNER_U>1</OWNER_U>\n            <OWNER_M>1</OWNER_M>\n            <OWNER_A>0</OWNER_A>\n            <GROUP_U>0</GROUP_U>\n            <GROUP_M>0</GROUP_M>\n            <GROUP_A>0</GROUP_A>\n            <OTHER_U>0</OTHER_U>\n            <OTHER_M>0</OTHER_M>\n            <OTHER_A>0</OTHER_A>\n        </PERMISSIONS>\n        <TYPE>0</TYPE>\n        <DISK_TYPE>0</DISK_TYPE>\n        <PERSISTENT>0</PERSISTENT>\n        <REGTIME>1385145541</REGTIME>\n        <SOURCE/>\n        <PATH>/tmp/ttylinux.img</PATH>\n        <FSTYPE/>\n        <SIZE>40</SIZE>\n        <STATE>4</STATE>\n        <RUNNING_VMS>0</RUNNING_VMS>\n        <CLONING_OPS>0</CLONING_OPS>\n        <CLONING_ID>-1</CLONING_ID>\n        <DATASTORE_ID>1</DATASTORE_ID>\n        <DATASTORE>default</DATASTORE>\n        <VMS/>\n        <CLONES/>\n        <TEMPLATE>\n            <DEV_PREFIX><![CDATA[hd]]></DEV_PREFIX>\n            <PUBLIC><![CDATA[YES]]></PUBLIC>\n        </TEMPLATE>\n    </IMAGE>\n    <DATASTORE>\n        <ID>1</ID>\n        <UID>0</UID>\n        <GID>0</GID>\n        <UNAME>oneadmin</UNAME>\n        <GNAME>oneadmin</GNAME>\n        <NAME>default</NAME>\n        <PERMISSIONS>\n            <OWNER_U>1</OWNER_U>\n            <OWNER_M>1</OWNER_M>\n            <OWNER_A>0</OWNER_A>\n            <GROUP_U>1</GROUP_U>\n            <GROUP_M>0</GROUP_M>\n            <GROUP_A>0</GROUP_A>\n            <OTHER_U>1</OTHER_U>\n            <OTHER_M>0</OTHER_M>\n            <OTHER_A>0</OTHER_A>\n        </PERMISSIONS>\n        <DS_MAD>fs</DS_MAD>\n        <TM_MAD>shared</TM_MAD>\n        <TYPE>0</TYPE>\n        <DISK_TYPE>0</DISK_TYPE>\n        <CLUSTER_ID>-1</CLUSTER_ID>\n        <CLUSTER/>\n        <TOTAL_MB>86845</TOTAL_MB>\n        <FREE_MB>20777</FREE_MB>\n        <USED_MB>1000</USED_MB>\n        <IMAGES/>\n        <TEMPLATE>\n            <CLONE_TARGET><![CDATA[SYSTEM]]></CLONE_TARGET>\n            <DISK_TYPE><![CDATA[FILE]]></DISK_TYPE>\n            <DS_MAD><![CDATA[fs]]></DS_MAD>\n            <LN_TARGET><![CDATA[NONE]]></LN_TARGET>\n            <TM_MAD><![CDATA[shared]]></TM_MAD>\n            <TYPE><![CDATA[IMAGE_DS]]></TYPE>\n        </TEMPLATE>\n    </DATASTORE>\n</DS_DRIVER_ACTION_DATA>\n```\n\n----------------------------------------\n\nTITLE: Setting Datastore scheduling requirements for Production mode - Bash\nDESCRIPTION: This code snippet demonstrates how to set the `SCHED_DS_REQUIREMENTS` attribute to prioritize Datastores labeled as *Production*. This attribute helps to select appropriate system datastores based on specified criteria.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/overview.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nSCHED_DS_REQUIREMENTS=\"MODE=Production\"\n```\n\n----------------------------------------\n\nTITLE: Installing Hatch\nDESCRIPTION: These commands install Hatch, a Python project manager, using pipx.  `pipx ensurepath` ensures that Hatch is added to your PATH, and `source ~/.bashrc` reloads your bash configuration so that the PATH changes take effect.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npipx install hatch\npipx ensurepath\nsource ~/.bashrc\n```\n\n----------------------------------------\n\nTITLE: Creating System Datastore Template\nDESCRIPTION: This snippet shows the template parameters required to create a system datastore using the local transfer mode. The template defines the datastore's name, transfer mode (TM_MAD), and type.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/local_ds.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nNAME    = local_system\nTM_MAD  = local\nTYPE    = SYSTEM_DS\n```\n\n----------------------------------------\n\nTITLE: List Restic Snapshots\nDESCRIPTION: This command lists snapshots managed by restic, a backup program. It displays the snapshot ID, timestamp, host, tags (including the OpenNebula VM ID), and the backed-up path.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ restic snapshots\n```\n\n----------------------------------------\n\nTITLE: Defining NIC Alias with Parent NIC ID\nDESCRIPTION: This snippet demonstrates how to define a NIC alias in OpenNebula, specifically referencing the parent NIC by its ID. It shows how to specify the network and the parent NIC for the alias. The `NETWORK` attribute specifies the virtual network, and the `PARENT` attribute specifies the parent NIC, typically in the form of `NIC${NIC_ID}`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_21\n\nLANGUAGE: text\nCODE:\n```\nNIC_ALIAS = [ NETWORK = \"private\", PARENT = \"NIC0\" ]\n```\n\n----------------------------------------\n\nTITLE: Create Virtual Router Template file\nDESCRIPTION: Defines a VR Template with network interfaces attached to the specified networks with the specified IP address, and floating IP flag set.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vrouter.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nNAME = my-vr\nNIC = [\n  NETWORK=\"blue-net\",\n  IP=\"192.168.30.5\",\n  FLOATING_IP = \"yes\" ]\nNIC = [\n  NETWORK=\"red-net\" ]\n```\n\n----------------------------------------\n\nTITLE: Retrieving Virtual Network Information with OneGate (bash)\nDESCRIPTION: This command shows how to retrieve virtual network information using the `onegate vnet show <ID>` command, where `<ID>` is the Virtual Network ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ onegate vnet show 0\n  VNET\n  ID                  : 0\n```\n\n----------------------------------------\n\nTITLE: Show VM Template After Delete\nDESCRIPTION: This command displays the VM template using the onevm command-line tool after attempting to delete the 'APP_LOAD' attribute to confirm deletion. It's used to verify that the template no longer contains the attribute.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 0\n...\nUSER TEMPLATE\n```\n\n----------------------------------------\n\nTITLE: Execute command via SSH and log - Shell\nDESCRIPTION: This snippet uses the `ssh_exec_and_log` function from `scripts_common.sh` to execute a command on a remote host via SSH, logging the execution. It also handles errors and sends an error message.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nssh_exec_and_log \"$HOST\" \"chmod g+w $DST_PATH\" \"Error message\"\n```\n\n----------------------------------------\n\nTITLE: Listing Networks with OpenNebula Provisioning Tool (oneprovision) - Bash\nDESCRIPTION: This command lists the networks within the OpenNebula provision using the `oneprovision` tool. It requires execution on the Front-end node with either `oneadmin` user permissions or root access. The output includes the ID, user, group, name, associated clusters, bridge, and number of leases for each network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/operation_basics/provisioning_edge_cluster.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\noneprovision network list\n```\n\n----------------------------------------\n\nTITLE: Example Scheduler Driver Action XML\nDESCRIPTION: This XML snippet illustrates the structure of a SCHEDULER_DRIVER_ACTION message used for communication between the scheduler driver and OpenNebula.  It includes information about VMs, hosts, datastores, virtual networks, VM groups, cluster details, and placement requirements. The data is used by the scheduler to make placement and optimization decisions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-sched.rst#_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<?xml version=\"1.0\"?>\n<SCHEDULER_DRIVER_ACTION>\n  <VM_POOL>\n    <VM>\n      <ID>0</ID>\n      <UID>0</UID>\n      <GID>0</GID>\n      <UNAME>oneadmin</UNAME>\n      <GNAME>oneadmin</GNAME>\n      <NAME>testvm-0</NAME>\n      <PERMISSIONS>\n      ...\n      </PERMISSIONS>\n      <LAST_POLL>1743093418</LAST_POLL>\n      <STATE>3</STATE>\n      <LCM_STATE>3</LCM_STATE>\n      <PREV_STATE>3</PREV_STATE>\n      <PREV_LCM_STATE>3</PREV_LCM_STATE>\n      <RESCHED>0</RESCHED>\n      <STIME>1743093368</STIME>\n      <ETIME>0</ETIME>\n      <DEPLOY_ID>host0:testvm-0:dummy</DEPLOY_ID>\n      <MONITORING>\n        <CPU><![CDATA[0]]></CPU>\n        ...\n        <TIMESTAMP><![CDATA[1743093418]]></TIMESTAMP>\n      </MONITORING>\n      <SCHED_ACTIONS/>\n      <TEMPLATE>\n        <AUTOMATIC_REQUIREMENTS><![CDATA[!(PIN_POLICY = PINNED)]]></AUTOMATIC_REQUIREMENTS>\n        <CPU><![CDATA[0.1]]></CPU>\n        <MEMORY><![CDATA[128]]></MEMORY>\n        <VMID><![CDATA[0]]></VMID>\n      </TEMPLATE>\n      <USER_TEMPLATE/>\n      <HISTORY_RECORDS>\n      ...\n      </HISTORY_RECORDS>\n      <BACKUPS>\n        <BACKUP_CONFIG/>\n        <BACKUP_IDS/>\n      </BACKUPS>\n    </VM>\n    <VM>\n    ...\n    </VM>\n  </VM_POOL>\n  <HOST_POOL>\n    <HOST>\n      <ID>0</ID>\n      <NAME>host0</NAME>\n      <STATE>2</STATE>\n      <PREV_STATE>2</PREV_STATE>\n      <IM_MAD><![CDATA[dummy]]></IM_MAD>\n      <VM_MAD><![CDATA[dummy]]></VM_MAD>\n      <CLUSTER_ID>100</CLUSTER_ID>\n      <CLUSTER>test_cluster</CLUSTER>\n      <HOST_SHARE>\n        <MEM_USAGE>1048576</MEM_USAGE>\n        <CPU_USAGE>80</CPU_USAGE>\n        <TOTAL_MEM>4005824</TOTAL_MEM>\n        <TOTAL_CPU>200</TOTAL_CPU>\n        <MAX_MEM>4005824</MAX_MEM>\n        <MAX_CPU>200</MAX_CPU>\n        <RUNNING_VMS>8</RUNNING_VMS>\n        <VMS_THREAD>1</VMS_THREAD>\n        <DATASTORES>\n          <DISK_USAGE><![CDATA[0]]></DISK_USAGE>\n          <DS>\n            <FREE_MB><![CDATA[56766]]></FREE_MB>\n            <ID><![CDATA[0]]></ID>\n            <TOTAL_MB><![CDATA[63328]]></TOTAL_MB>\n            <USED_MB><![CDATA[6546]]></USED_MB>\n          </DS>\n          <FREE_DISK><![CDATA[56766]]></FREE_DISK>\n          <MAX_DISK><![CDATA[63328]]></MAX_DISK>\n          <USED_DISK><![CDATA[6546]]></USED_DISK>\n        </DATASTORES>\n        <PCI_DEVICES/>\n        <NUMA_NODES>\n        ...\n        </NUMA_NODES>\n      </HOST_SHARE>\n      <VMS>\n        <ID>0</ID>\n        <ID>1</ID>\n        <ID>2</ID>\n        <ID>3</ID>\n        <ID>4</ID>\n        <ID>5</ID>\n        <ID>6</ID>\n        <ID>7</ID>\n      </VMS>\n      <TEMPLATE>\n        <ARCH><![CDATA[x86_64]]></ARCH>\n        <CGROUPS_VERSION><![CDATA[2]]></CGROUPS_VERSION>\n        <CPUSPEED><![CDATA[0]]></CPUSPEED>\n        <HOSTNAME><![CDATA[ubuntu2204-kvm-ssh-6-99-c94e-1.test]]></HOSTNAME>\n        ...\n      </TEMPLATE>\n      <MONITORING>\n        <TIMESTAMP>1743093419</TIMESTAMP>\n        <ID>0</ID>\n        <CAPACITY>\n          <FREE_CPU><![CDATA[2]]></FREE_CPU>\n          <FREE_MEMORY><![CDATA[3573260]]></FREE_MEMORY>\n          <USED_CPU><![CDATA[198]]></USED_CPU>\n          <USED_MEMORY><![CDATA[432564]]></USED_MEMORY>\n        </CAPACITY>\n        <SYSTEM>\n          <NETRX><![CDATA[4751228]]></NETRX>\n          <NETTX><![CDATA[9932392]]></NETTX>\n        </SYSTEM>\n        <NUMA_NODE>\n          <HUGEPAGE>\n            <FREE><![CDATA[0]]></FREE>\n            <SIZE><![CDATA[2048]]></SIZE>\n          </HUGEPAGE>\n          ...\n          <MEMORY>\n            <FREE><![CDATA[3170204]]></FREE>\n            <USED><![CDATA[835620]]></USED>\n          </MEMORY>\n          <NODE_ID><![CDATA[0]]></NODE_ID>\n        </NUMA_NODE>\n      </MONITORING>\n      <CLUSTER_TEMPLATE>\n      ...\n      </CLUSTER_TEMPLATE>\n    </HOST>\n    <HOST>\n    ...\n    </HOST>\n  </HOST_POOL>\n  <DATASTORE_POOL>\n    <DATASTORE>\n      <ID>0</ID>\n      <UID>0</UID>\n      <GID>0</GID>\n      <UNAME>oneadmin</UNAME>\n      <GNAME>oneadmin</GNAME>\n      <NAME>system</NAME>\n      <PERMISSIONS>\n      ...\n      </PERMISSIONS>\n      <DS_MAD><![CDATA[-]]></DS_MAD>\n      <TM_MAD><![CDATA[dummy]]></TM_MAD>\n      <BASE_PATH><![CDATA[/var/lib/one//datastores/0]]></BASE_PATH>\n      <TYPE>1</TYPE>\n      <DISK_TYPE>0</DISK_TYPE>\n      <STATE>0</STATE>\n      <CLUSTERS>\n        <ID>0</ID>\n      </CLUSTERS>\n      <TOTAL_MB>4796800</TOTAL_MB>\n      <FREE_MB>3333260</FREE_MB>\n      <USED_MB>1429920</USED_MB>\n      <IMAGES/>\n      <TEMPLATE>\n        <ALLOW_ORPHANS><![CDATA[NO]]></ALLOW_ORPHANS>\n        <DS_MIGRATE><![CDATA[YES]]></DS_MIGRATE>\n        <SHARED><![CDATA[YES]]></SHARED>\n        <TM_MAD><![CDATA[dummy]]></TM_MAD>\n        <TYPE><![CDATA[SYSTEM_DS]]></TYPE>\n      </TEMPLATE>\n    </DATASTORE>\n    <DATASTORE>\n    ...\n    </DATASTORE>\n  </DATASTORE_POOL>\n  <VNET_POOL/>\n  <VM_GROUP_POOL/>\n  <CLUSTER_POOL>\n    <CLUSTER>\n      <ID>100</ID>\n      <NAME>test_cluster</NAME>\n      <HOSTS>\n        <ID>0</ID>\n        <ID>1</ID>\n        <ID>2</ID>\n        <ID>3</ID>\n      </HOSTS>\n      <DATASTORES>\n        <ID>100</ID>\n      </DATASTORES>\n      <VNETS/>\n      <TEMPLATE>\n        <ONE_DRS>\n          <AUTOMATION><![CDATA[full]]></AUTOMATION>\n          <CPU_USAGE_WEIGHT><![CDATA[0.2]]></CPU_USAGE_WEIGHT>\n          <CPU_WEIGHT><![CDATA[0.2]]></CPU_WEIGHT>\n          <DISK_WEIGHT><![CDATA[0.1]]></DISK_WEIGHT>\n          <MEMORY_WEIGHT><![CDATA[0.4]]></MEMORY_WEIGHT>\n          <MIGRATION_THRESHOLD><![CDATA[10]]></MIGRATION_THRESHOLD>\n          <NET_WEIGHT><![CDATA[0.1]]></NET_WEIGHT>\n          <POLICY><![CDATA[balance]]></POLICY>\n          <PREDICTIVE><![CDATA[0.2]]></PREDICTIVE>\n        </ONE_DRS>\n        <RESERVED_CPU><![CDATA[]]></RESERVED_CPU>\n        <RESERVED_MEM><![CDATA[]]></RESERVED_MEM>\n      </TEMPLATE>\n    </CLUSTER>\n  </CLUSTER_POOL>\n  <REQUIREMENTS>\n    <VM>\n      <ID>0</ID>\n      <HOSTS>\n        <ID>0</ID>\n        <ID>1</ID>\n        <ID>2</ID>\n        <ID>3</ID>\n      </HOSTS>\n      <DATASTORES>\n        <ID>100</ID>\n      </DATASTORES>\n    </VM>\n    <VM>\n    ...\n    </VM>\n  </REQUIREMENTS>\n</SCHEDULER_DRIVER_ACTION>\n\n```\n\n----------------------------------------\n\nTITLE: Instantiating an OpenNebula Template\nDESCRIPTION: This command instantiates a VM template in OpenNebula. It specifies the network interface card (NIC) to use (`admin_net`) and the template name (`alpine`). It requires the OpenNebula CLI tool `onetemplate`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nonetemplate instantiate --nic admin_net alpine\n```\n\n----------------------------------------\n\nTITLE: Accessing Marketplace name from returned object\nDESCRIPTION: This snippet demonstrates how to access data from a returned object. Specifically, it retrieves the name of the first marketplace in the marketpool. It depends on a prior API call to get marketpool information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmarketpool = one.marketpool.info()\nm0 = marketpool.MARKETPLACE[0]\nprint \"Marketplace name is \" + m0.NAME\n```\n\n----------------------------------------\n\nTITLE: Kernel Parameter for I/O MMU Enablement\nDESCRIPTION: This kernel parameter enables I/O MMU (Intel VT-d or AMD-Vi) which is required for PCI passthrough. This needs to be set in the bootloader configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nintel_iommu=on\n```\n\n----------------------------------------\n\nTITLE: Securely Copy Database Backup via SCP\nDESCRIPTION: This command securely copies the OpenNebula database backup file from the leader node to a follower node using the `scp` command. The `<follower_ip>` placeholder should be replaced with the IP address of the follower node.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_ha.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ scp /var/lib/one/mysql_localhost_opennebula_2019-9-27_11:52:47.sql <follower_ip>:/tmp\n```\n\n----------------------------------------\n\nTITLE: Ping Result Output (Bash)\nDESCRIPTION: This is the expected output of the ping command, showing successful responses from the VM at 172.20.0.100. The output includes round-trip time (rtt) statistics, indicating the latency of the network connection.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\noneadmin@front-end:~$ ping -c 3 172.20.0.100\nPING 172.20.0.100 (172.20.0.100) 56(84) bytes of data.\n64 bytes from 172.20.0.100: icmp_seq=1 ttl=64 time=0.203 ms\n64 bytes from 172.20.0.100: icmp_seq=2 ttl=64 time=0.404 ms\n64 bytes from 172.20.0.100: icmp_seq=3 ttl=64 time=0.304 ms\n\n--- 172.20.0.100 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 2024ms\nrtt min/avg/max/mdev = 0.203/0.303/0.404/0.082 m\n```\n\n----------------------------------------\n\nTITLE: Listing VMs After Deployment - OpenNebula CLI\nDESCRIPTION: This command is a placeholder showing the output of the `onevm list` command, which is expected to show the result of deploying a VM to a host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\n$ onevm list\n```\n\n----------------------------------------\n\nTITLE: Configuring Network Settings with Keys in monitord.conf\nDESCRIPTION: This code snippet demonstrates how to configure the network settings in the `/etc/one/monitord.conf` file for encrypting monitoring messages. It includes the paths to the public and private keys generated for the monitor system. Ensuring that the correct keys are used is crucial for secure communication between the monitoring probes and the OpenNebula front-end.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nNETWORK = [\n  ...\n  PUBKEY = \"/etc/one/onemonitor_pem.pub\",\n  PRIKEY = \"/etc/one/onemonitor\"\n]\n```\n\n----------------------------------------\n\nTITLE: Detaching a NIC from a Virtual Machine in OpenNebula\nDESCRIPTION: This command detaches a network interface card (NIC) from a virtual machine. It removes the NIC with ID '1' from the VM with ID '2'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm nic-detach 2 1\n```\n\n----------------------------------------\n\nTITLE: Show FireEdge Logs (journalctl)\nDESCRIPTION: This command is used to view logs for the FireEdge service using `journalctl`. The `-u` option specifies the service unit. It requires systemd and appropriate privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/fireedge.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ journalctl -u opennebula-fireedge.service\n```\n\n----------------------------------------\n\nTITLE: User Inputs for Sunstone - No Convention (JSON)\nDESCRIPTION: This JSON snippet shows user inputs without specific naming conventions. These inputs will be rendered in Sunstone under the 'Others' tab or group.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"user_inputs\": {\n    \"APACHE_USER\": \"O|text|Apache user||\",\n    \"APACHE_ENDPOINT\": \"O|text|Apache endpoint||\"\n  },\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying VM Scheduled Actions\nDESCRIPTION: This example shows the output of the `onevm show` command, displaying the scheduled actions for a VM. The output includes the ID, action, arguments, scheduled time, repeat interval, end time, and status of each scheduled action.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_31\n\nLANGUAGE: text\nCODE:\n```\n$ onevm show 0\nVIRTUAL MACHINE 0 INFORMATION\nID                  : 0\nNAME                : one-0\n\n[...]\n\nSCHEDULED ACTIONS\nID           ACTION     ARGS    SCHEDULED        REPEAT            END  STATUS\n 0          suspend        -  09/20 00:00    Weekly 1,5  After 5 times  Next in 1.08 days\n 1           resume        -  09/23 14:15    Weekly 2,6  After 5 times  Next in 4.67 days\n 2  snapshot-create  snap-01  09/19 21:16  Each 5 hours    On 12/25/18  Next in 4.78 hours\n```\n\n----------------------------------------\n\nTITLE: Configuring Scheduled Actions in sunstone-server.conf\nDESCRIPTION: This code snippet configures scheduled actions within the `sunstone-server.conf` file, defining actions like `terminate` and `poweroff` with associated parameters such as `edit` and `execute_after_weeks`/`execute_after_minutes`.  These configurations determine the pre-defined actions that appear when creating a VM Charter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_36\n\nLANGUAGE: text\nCODE:\n```\nleases:\n  terminate:\n    edit: false\n    execute_after_weeks: 3\n  poweroff:\n    edit: true\n    execute_after_minutes: 5\n```\n\n----------------------------------------\n\nTITLE: Compiling OpenNebula with scons using multiple threads\nDESCRIPTION: This snippet shows how to compile OpenNebula using scons with a specified number of parallel processes. This can significantly speed up the compilation time.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/compile.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ scons -j 4 [OPTION=VALUE]\n```\n\n----------------------------------------\n\nTITLE: Listing Images in OpenNebula\nDESCRIPTION: This command lists all images available in the OpenNebula environment. It requires access to the OpenNebula CLI tools and provides information such as image ID, user, group, name, datastore, size, type, and status. The output helps verify if a previously exported image is ready for use.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\noneimage list\n```\n\n----------------------------------------\n\nTITLE: Custom CPU Topology Definition\nDESCRIPTION: This configuration defines a custom CPU topology with a specific number of sockets, cores, and threads. The total number of vCPUs is determined by the product of sockets, cores, and threads.  This example is for a VM with two sockets, two cores per socket, and two threads per core.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nVCPU   = 8\nMEMORY = 1024\n\nTOPOLOGY = [ SOCKETS = 2, CORES = 2, THREADS = 2 ]\n```\n\n----------------------------------------\n\nTITLE: Example SSH Connection to Edge Cluster as Ubuntu User - Bash\nDESCRIPTION: This command shows an example of connecting to an edge cluster using SSH as the `ubuntu` user. It uses the private key located at `/var/lib/one/.ssh-provision/id_rsa` and requires specifying the edge cluster's public IP address. After connecting as `ubuntu`, the user can use `sudo` for root access.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/operation_basics/provisioning_edge_cluster.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nssh -i /var/lib/one/.ssh-provision/id_rsa -l ubuntu <edge cluster public IP>\n```\n\n----------------------------------------\n\nTITLE: Navigating to OneDeploy Directory\nDESCRIPTION: This command changes the current directory to the one-deploy directory.  This is where the Ansible playbooks and other files are located.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncd one-deploy\n```\n\n----------------------------------------\n\nTITLE: Show OpenNebula Zone Information\nDESCRIPTION: Shows the configuration for the OpenNebula zone, including a list of front-end servers and their endpoints. This is relevant for HA configurations.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# onezone show 0\nZONE 0 INFORMATION\nID                : 0\nNAME              : OpenNebula\nSTATE             : ENABLED\n\nZONE SERVERS\nID NAME            ENDPOINT\n 0 Node-1          http://192.168.150.1:2633/RPC2\n 1 Node-2          http://192.168.150.2:2633/RPC2\n 2 Node-3          http://192.168.150.3:2633/RPC2\n\nHA & FEDERATION SYNC STATUS\n```\n\n----------------------------------------\n\nTITLE: Example Ansible Configuration File (ansible.cfg)\nDESCRIPTION: This configuration file sets various Ansible parameters, including the inventory file path, host key checking, privilege escalation settings, and the path to the Ansible collections. `inventory` specifies the inventory file, and `collections_paths` defines the location where Ansible collections are stored.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n[defaults]\ninventory=./example.yml\ngathering=explicit\nhost_key_checking=false\ndisplay_skipped_hosts=true\nretry_files_enabled=false\nany_errors_fatal=true\nstdout_callback=yaml\ntimeout=30\ncollections_paths=/home/user/one-deploy/ansible_collections\n\n[ssh_connection]\npipelining=true\nssh_args=-q -o ControlMaster=auto -o ControlPersist=60s\n\n[privilege_escalation]\nbecome      = true\nbecome_user = root\n```\n\n----------------------------------------\n\nTITLE: Configuring OneGate Endpoint\nDESCRIPTION: This snippet shows how to configure the OpenNebula Daemon with the OneGate endpoint URL in the /etc/one/oned.conf file. The ONEGATE_ENDPOINT variable should be set to the address that virtual machines can use to reach the OneGate server. Replace 'one.example.com' with the correct domain or IP address.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_7\n\nLANGUAGE: none\nCODE:\n```\nONEGATE_ENDPOINT=\"http://one.example.com:5030\"\n```\n\n----------------------------------------\n\nTITLE: OpenNebula IPAM Driver Configuration\nDESCRIPTION: This configuration snippet demonstrates how to activate the IPAM driver in OpenNebula's oned.conf file.  It shows the IPAM_MAD attribute and how to specify the driver to use.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-ipam.rst#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nIPAM_MAD = [\n        EXECUTABLE = \"one_ipam\",\n        ARGUMENTS  = \"-t 1 -i dummy, <ipam_mad>\"\n    ]\n```\n\n----------------------------------------\n\nTITLE: Changing oneadmin Authentication to X.509\nDESCRIPTION: This command shows how to change the oneadmin's authentication method to X.509.  The subject DN from the provided certificate will be set as the new password for the oneadmin user.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\noneuser chauth 0 x509 --x509 --cert /tmp/newcert.pem\n```\n\n----------------------------------------\n\nTITLE: Defining Datastore in Provision Template YAML\nDESCRIPTION: This code snippet demonstrates how to define a datastore within an OpenNebula provision template using YAML. It shows the datastore's name, datastore management driver (ds_mad), and transfer manager driver (tm_mad). This example provides an alternative to creating a datastore using a separate template file and the 'onedatastore create' command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/template.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ndatastores:\n  - name: \"myprovision-images\"\n    ds_mad: fs\n    tm_mad: local\n```\n\n----------------------------------------\n\nTITLE: Binding Network Cards to vfio-pci Driver\nDESCRIPTION: This snippet demonstrates how to identify network cards and bind them to the vfio-pci driver for use with DPDK.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# dpdk-devbind.py --status\n...\nNetwork devices using kernel driver\n===================================\n0000:01:00.1 'Ethernet Controller X710 for 10GbE SFP+ 1572' if=eno2 drv=i40e unused=vfio-pci\n0000:83:00.1 'Ethernet Controller X710 for 10GbE SFP+ 1572' if=enp131s0f1 drv=i40e unused=vfio-pci\n\n# dpdk-devbind.py --bind=vfio-pci enp131s0f1\n\n# dpdk-devbind.py --bind=vfio-pci eno2\n\n# dpdk-devbind.py --status\n...\nNetwork devices using DPDK-compatible driver\n============================================\n0000:01:00.1 'Ethernet Controller X710 for 10GbE SFP+ 1572' drv=vfio-pci unused=i40e\n0000:83:00.1 'Ethernet Controller X710 for 10GbE SFP+ 1572' drv=vfio-pci unused=i40e\n```\n\n----------------------------------------\n\nTITLE: Deploying nginx on Kubernetes\nDESCRIPTION: This command deploys an nginx pod on the Kubernetes cluster. It requires `kubectl` to be configured and connected to the cluster. This command pulls the nginx image from a container registry and creates a pod.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nroot@oneke-ip-172-20-0-2:~# kubectl run nginx --image=nginx --port 80\npod/nginx created\n```\n\n----------------------------------------\n\nTITLE: Install OpenNebula Front-end - AlmaLinux/RHEL\nDESCRIPTION: This command installs the core OpenNebula Front-end components using the yum package manager on AlmaLinux or RHEL. It installs the opennebula, opennebula-fireedge, opennebula-gate, opennebula-flow and opennebula-provision packages.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# yum -y install opennebula opennebula-fireedge opennebula-gate opennebula-flow opennebula-provision\n```\n\n----------------------------------------\n\nTITLE: Showing Virtual Network Details\nDESCRIPTION: This snippet shows how to view the details of a virtual network using the onevnet show command and an example output.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_8\n\nLANGUAGE: none\nCODE:\n```\n$ onevnet show 1\n```\n\n----------------------------------------\n\nTITLE: Upgrade onecfg (Bash)\nDESCRIPTION: Upgrades the OpenNebula configuration using the `onecfg` tool.  It automatically upgrades the configuration based on the internal version tracking.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$\\u00a0onecfg upgrade\n```\n\n----------------------------------------\n\nTITLE: Running Ansible Playbook for OpenNebula Deployment\nDESCRIPTION: This snippet demonstrates how to execute the Ansible playbook for deploying OpenNebula. It requires the user to be in the Hatch environment and have the ansible.cfg file configured in the working directory. The -v flag enables verbose output for monitoring the installation process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nansible-playbook -v opennebula.deploy.main\n```\n\n----------------------------------------\n\nTITLE: Set Default User Quota (CLI)\nDESCRIPTION: This command opens an editor to set the default quota for all users. This template is applied to new users unless they have an individual quota set.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/quotas.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser defaultquota\n```\n\n----------------------------------------\n\nTITLE: Export Marketplace Appliance using onemarketapp\nDESCRIPTION: This command exports a Marketplace Appliance, returning the ID of the new Image and the ID of the new associated template. If no template is defined, it will return -1.  The command includes parameters for the Marketplace Appliance ID, a name for the exported appliance, and the datastore ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/marketapps.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ onemarketapp export 40 from_t1app -d 1\nIMAGE\n    ID: 1\nVMTEMPLATE\n    ID: -1\n```\n\n----------------------------------------\n\nTITLE: Displaying Group Information\nDESCRIPTION: This command displays detailed information about a specific group using the `onegroup show` command. It requires the `onegroup` command-line tool and the group ID as input. It shows the group ID, name, and the users belonging to the group.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_groups.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onegroup show 100\nGROUP 100 INFORMATION\nID             : 100\nNAME           : new group\n\nUSERS\nID              NAME\n1               regularuser\n```\n\n----------------------------------------\n\nTITLE: Enable and Start Exporters\nDESCRIPTION: Enables and starts the `opennebula-exporter.service` and `opennebula-node-exporter.service` using `systemctl`. This ensures that the exporters start automatically on boot.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl enable --now opennebula-exporter.service opennebula-node-exporter.service\n```\n\n----------------------------------------\n\nTITLE: Listing Hosts with OpenNebula Provisioning Tool (oneprovision) - Bash\nDESCRIPTION: This command lists the hosts within the current OpenNebula provision using the `oneprovision` tool. It is executed from the Front-end node as the `oneadmin` user or as `root`. The command displays details such as ID, name, cluster, TVM, allocated CPU, allocated memory, and the status of each host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/operation_basics/provisioning_edge_cluster.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\noneprovision host list\n```\n\n----------------------------------------\n\nTITLE: Showing Cluster Details with onecluster\nDESCRIPTION: This snippet shows the details of the 'production' cluster using the `onecluster show` command. It presents the cluster's ID, name, and associated hosts, virtual networks, and datastores. The cluster name or ID is required as a parameter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster show production\nCLUSTER 100 INFORMATION\nID             : 100\nNAME           : production\n\nHOSTS\n\nVNETS\n\nDATASTORES\n```\n\n----------------------------------------\n\nTITLE: Terraform Provider Configuration Template\nDESCRIPTION: This Terraform template defines the provider configuration. It utilizes ERB syntax to inject connection details from the `conn` hash. This configuration is read from the YAML configuration file when the provider is created. Replace `aws` with the desired provider.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_1\n\nLANGUAGE: terraform\nCODE:\n```\nprovider \"aws\" {\n    access_key = \"<%= conn['ACCESS_KEY'] %>\"\n    secret_key = \"<%= conn['SECRET_KEY'] %>\"\n    region     = \"<%= conn['REGION'] %>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Poweroff VM with Go OpenNebula API\nDESCRIPTION: This code snippet demonstrates how to power off a running VM using the OpenNebula Cloud API for Go. It initializes a connection to OpenNebula, retrieves a VM by its ID, and then executes the poweroff operation. It requires the 'goca' package and the VM ID as a command line argument.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/go.rst#_snippet_0\n\nLANGUAGE: Go\nCODE:\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"strconv\"\n\n\t\"github.com/OpenNebula/one/src/oca/go/src/goca\"\n)\n\nfunc main() {\n\t// Initialize connection with OpenNebula\n\tcon := map[string]string{\n\t\t\"user\":     \"user\",\n\t\t\"password\": \"password\",\n\t\t\"endpoint\": \"XMLRPC address\",\n\t}\n\n\tclient := goca.NewDefaultClient(\n\t\tgoca.NewConfig(con[\"user\"], con[\"password\"], con[\"endpoint\"]),\n\t)\n\n\tcontroller := goca.NewController(client)\n\n\t// Read VM ID from arguments\n\tid, _ := strconv.Atoi(os.Args[1])\n\n\tvmctrl := controller.VM(id)\n\n\t// Fetch informations of the created VM\n\tvm, err := vmctrl.Info(false)\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Printf(\"Shutting down %+v\\n\", vm.Name)\n\n\t// Poweroff the VM\n\terr = vmctrl.Poweroff()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n}\n```\n\n----------------------------------------\n\nTITLE: Updating VM Status with OneGate CLI in Bash\nDESCRIPTION: This command updates the status of a specific VM to `READY` using the `onegate vm update` command. It requires the VM ID and the `--data` option with `READY=YES`. This forces the VM to report as ready, potentially resolving a stuck `DEPLOYING` state in the service. It also shows output of `onegate service show` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_19\n\nLANGUAGE: text\nCODE:\n```\nonegate vm update <ID> --data \"READY=YES\"\n\nonegate service show\nSERVICE 3\nNAME                : OneKE 1.29\nSTATE               : RUNNING\n\nROLE vnf\nVM 1\nNAME                : vnf_0_(service_3)\n\nROLE master\nVM 2\nNAME                : master_0_(service_3)\n\nROLE worker\nVM 3\nNAME                : worker_0_(service_3)\n\nROLE storage\n```\n\n----------------------------------------\n\nTITLE: Configuring Transparent OneGate Proxy (OpenNebula)\nDESCRIPTION: This snippet shows how to configure a transparent proxy for OneGate by adding a configuration to the `~oneadmin/remotes/etc/vnm/OpenNebulaNetwork.conf` file. This configuration specifies the service port, remote address, and remote port for the OneGate service. The `remote_addr` should be the OpenNebula Front-end VIP.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_3\n\nLANGUAGE: ruby\nCODE:\n```\n:tproxy:\n# OneGate service.\n- :service_port: 5030\n  :remote_addr: 10.11.12.13 # OpenNebula Front-end VIP\n  :remote_port: 5030\n```\n\n----------------------------------------\n\nTITLE: Guest Configuration for OneGate using Transparent Proxies\nDESCRIPTION: These commands show how to configure a Virtual Machine guest to connect to OneGate through a transparent proxy. The `ONEGATE_ENDPOINT` environment variable is set to use the proxy address, and the IP route confirms the address is accessible.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ grep ONEGATE_ENDPOINT /run/one-context/one_env\nexport ONEGATE_ENDPOINT=\"http://169.254.16.9:5030\"\n\n$ ip route show to 169.254.16.9\n169.254.16.9 dev eth0 scope link\n```\n\n----------------------------------------\n\nTITLE: Add Role to Running Service with curl\nDESCRIPTION: This snippet demonstrates how to add a new role to a running OpenNebula service using the curl command. It includes the role definition within the JSON payload.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service/5/role_action -u 'oneadmin:password' -v -X POST --data '{\n  \"action\": {\n    \"perform\":\"add_role\",\n    \"params\" : {\n      \"role\" : '{\n                \"name\": \"NEW_ROLE\",\n                \"cardinality\": 1,\n                \"template_id\": 0,\n                \"type\": \"vm\",\n                \"min_vms\": 1,\n                \"max_vms\": 2,\n                \"elasticity_policies\": [],\n                \"scheduled_policies\": []\n          }'\n    }\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Deleting a Virtual Network using OpenNebula CLI\nDESCRIPTION: This command deletes a Virtual Network named 'MyVNET'. The `onevnet delete` command is used to remove the Virtual Network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/self_provision.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onevnet delete MyVNET\n```\n\n----------------------------------------\n\nTITLE: Define Sample Public IPv4 VNet with OpenvSwitch\nDESCRIPTION: This snippet defines a sample public IPv4 Virtual Network (VNet) using the OpenvSwitch driver in OpenNebula. It configures the bridge, VLAN settings, DNS, gateway, and load balancer. Multiple address ranges (ARs) are defined, each specifying a single IP address and, in one case, a MAC address.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/vnet_template.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n# Configuration attributes (OpenvSwitch driver)\nNAME        = \"Public\"\nDESCRIPTION = \"Network with public IPs\"\n\nBRIDGE  = \"br1\"\nVLAN    = \"YES\"\nVLAN_ID = 12\n\nDNS           = \"8.8.8.8\"\nGATEWAY       = \"130.56.23.1\"\nLOAD_BALANCER = 130.56.23.2\n\nAR=[ TYPE = \"IP4\", IP = \"130.56.23.2\", SIZE = \"1\"]\nAR=[ TYPE = \"IP4\", IP = \"130.56.23.34\", SIZE = \"1\"]\nAR=[ TYPE = \"IP4\", IP = \"130.56.23.24\", SIZE = \"1\"]\nAR=[ TYPE = \"IP4\", IP = \"130.56.23.17\", MAC= \"50:20:20:20:20:21\", SIZE = \"1\"]\nAR=[ TYPE = \"IP4\", IP = \"130.56.23.12\", SIZE = \"1\"]\n```\n\n----------------------------------------\n\nTITLE: Listing ACL Rules\nDESCRIPTION: This command lists the existing ACL rules in OpenNebula using the `oneacl` command-line tool. The output shows the ID, USER, Resources, RID, Operations and ZONE for each rule.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n$ oneacl list\n   ID     USER RES_VHNIUTGDCOZSvRMAPtB   RID OPE_UMAC  ZONE\n    0       @1     V--I-T---O-S-------     *     ---c     *\n    1        *     ----------Z--------     *     u---     *\n    2        *     --------------MA---     *     u---     *\n    3       @1     -H-----------------     *     -m--    #0\n    4       @1     --N----D-----------     *     u---    #0\n    5     @106     ---I---------------   #31     u---    #0\n```\n\n----------------------------------------\n\nTITLE: Bash Show Virtual Network\nDESCRIPTION: This bash command demonstrates showing a virtual network and inspecting the resulting PROVISION template attributes. The values for 'B', 'L', 'P', and 'T' are populated based on the user inputs provided during the 'oneprovision create' command. This confirms that the user inputs are correctly resolved and used within the object template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n$ onevnet show 2\n```\n\n----------------------------------------\n\nTITLE: Action Schema Definition\nDESCRIPTION: This JSON schema defines the structure for performing actions on a service template, specifying 'perform' (the action to execute) and 'params' (parameters for the action). The 'perform' property is required and should be a string, while the 'params' property is an optional object containing parameters for the specified action.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_6\n\nLANGUAGE: JSON\nCODE:\n```\n{\n      :type => :object,\n      :properties => {\n        'action' => {\n          :type => :object,\n          :properties => {\n            'perform' => {\n              :type => :string,\n              :required => true\n            },\n            'params' => {\n              :type => :object,\n              :required => false,\n              :propierties => {\n                'merge_template' => {\n                    :type => object,\n                    :required => false\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Enterprise Repository on Debian 11\nDESCRIPTION: This bash script adds the OpenNebula Enterprise Edition repository to the Debian 11 system. It creates a `/etc/apt/sources.list.d/opennebula.list` file with the repository configuration, including the base URL (which requires a customer-specific token) and specifies the GPG key file. The script then updates the apt package list.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# echo \\\"deb [signed-by=/etc/apt/keyrings/opennebula.gpg] https://<token>@enterprise.opennebula.io/repo/|version|/Debian/11 stable opennebula\\\" > /etc/apt/sources.list.d/opennebula.list\n# apt-get update\n```\n\n----------------------------------------\n\nTITLE: onedb version with Verbose Output (Text)\nDESCRIPTION: Prints the current database schema version with verbose output, including timestamps and comments, using the `onedb version -v` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n$ onedb version -v\nShared tables version:   5.12.0\nRequired version:        5.12.0\nTimestamp: 09/08 11:52:46\nComment:   Database migrated from 5.6.0 to 5.12.0 (OpenNebula 5.12.0) by onedb command.\n\nLocal tables version:    5.12.0\nRequired version:        5.12.0\nTimestamp: 09/08 11:58:27\nComment:   Database migrated from 5.8.0 to 5.12.0 (OpenNebula 5.12.0) by onedb command.\n```\n\n----------------------------------------\n\nTITLE: SQLite Configuration in OpenNebula\nDESCRIPTION: This snippet shows the default OpenNebula configuration for the SQLite database backend. It defines the backend type as 'sqlite' and sets a timeout value.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/database.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nDB = [ BACKEND = \"sqlite\",\n           TIMEOUT = 2500 ]\n```\n\n----------------------------------------\n\nTITLE: Defining PCI Device by Class in OpenNebula\nDESCRIPTION: This snippet demonstrates how to define a PCI device by its class. It's useful when you need any device that matches a specific PCI class, such as any *PCI Express Root Ports*.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_16\n\nLANGUAGE: text\nCODE:\n```\nPCI = [\n  CLASS = \"0604\" ]\n```\n\n----------------------------------------\n\nTITLE: VM Monitoring Output Format\nDESCRIPTION: This snippet shows the expected format for monitoring information returned by VM drivers to OpenNebula. The format is a line of KEY=VALUE pairs separated by spaces. It also supports vector values using the format KEY = [ SK1=VAL1, SK2=VAL2 ]. These key-value pairs provide insights into the VM's resource usage and state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-vmm.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nSTATE=a USEDMEMORY=554632 DISK_SIZE=[ ID=0, SIZE=24 ] DISK_SIZE=[ ID=1, SIZE=242 ] SNAPSHOT_SIZE=[ ID=0, DISK_ID=0, SIZE=24 ]\n```\n\n----------------------------------------\n\nTITLE: Configuring NUMA Topology in OpenNebula Template\nDESCRIPTION: This snippet shows how to configure NUMA topology settings in an OpenNebula VM template. It defines the hugepage size, memory access mode, number of NUMA nodes and the vCPU pinning policy, controlling how virtual CPUs are mapped to physical cores for performance optimization.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_42\n\nLANGUAGE: text\nCODE:\n```\nTOPOLOGY = [\n     HUGEPAGE_SIZE = \"2\",\n     MEMORY_ACCESS = \"shared\",\n     NUMA_NODES    = \"2\",\n     PIN_POLICY    = \"THREAD\" ]\n```\n\n----------------------------------------\n\nTITLE: Datastore Export Return XML Format\nDESCRIPTION: This snippet shows the required XML format that the datastore export action (<ds_mad>/export) must return. It includes IMPORT_SOURCE, MD5, SIZE, FORMAT, and DISPOSE tags. The IMPORT_SOURCE specifies the location of the image data, MD5 is the MD5 checksum, SIZE is the size of the image, and FORMAT is the image format.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-market.rst#_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<IMPORT_INFO>\n    <IMPORT_SOURCE>$IMPORT_SOURCE</IMPORT_SOURCE>\n    <MD5>$MD5_SUM</MD5>\n    <SIZE>$SIZE</SIZE>\n    <FORMAT>$FORMAT</FORMAT>\n    <DISPOSE>NO</DISPOSE>\n</IMPORT_INFO>\"\n```\n\n----------------------------------------\n\nTITLE: Scaling a Service using Oneflow (Bash)\nDESCRIPTION: This bash command scales up the 'storage' role within a Oneflow service to 1. It's used to adjust the number of instances for a specific service component within the OpenNebula environment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/oneke_changelog.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ oneflow scale '<service_id>' storage 1\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Autostart Host Hook Definition\nDESCRIPTION: Defines the autostart-host hook for OpenNebula, which is triggered on the HOST resource when its state is MONITORED. It executes the autostart/host command and passes the host template via stdin. This hook is used for implementing VM autostart after host reboots.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_16\n\nLANGUAGE: text\nCODE:\n```\nNAME = autostart-host\nTYPE = state\nCOMMAND = autostart/host\nARGUMENTS = \\$TEMPLATE\nARGUMENTS_STDIN = yes\nRESOURCE = HOST\nSTATE = MONITORED\n```\n\n----------------------------------------\n\nTITLE: Apache Configuration for FireEdge (Non-TLS) - Bash\nDESCRIPTION: This snippet configures Apache as a reverse proxy for FireEdge in a non-TLS setup. It sets up `ProxyPass` and `ProxyPassReverse` directives to forward traffic to the FireEdge server running on `localhost:2616`. It also configures WebSocket proxying and access control.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/fireedge_for_large_deployments.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n<VirtualHost *:80>\n  ...\n\n  ProxyRequests     off\n  ProxyPreserveHost on\n\n  # no proxy for /error/ (Apache HTTPd errors messages)\n  ProxyPass /error/ !\n\n  ProxyPass /fireedge http://localhost:2616/fireedge\n  ProxyPassReverse /fireedge http://localhost:2616/fireedge\n\n  RewriteEngine on\n  RewriteCond %{HTTP:Upgrade} websocket [NC]\n  RewriteCond %{HTTP:Connection} upgrade [NC]\n  RewriteRule ^/fireedge/?(.*) \"ws://localhost:2616/fireedge/$1\" [P,L]\n\n  <Location /fireedge>\n      Order deny,allow\n      Allow from all\n  </Location>\n</VirtualHost>\n```\n\n----------------------------------------\n\nTITLE: Update User for X.509 Authentication (CLI)\nDESCRIPTION: This command updates an existing OpenNebula user to use X.509 certificate authentication. It sets the authentication driver to x509 and specifies the certificate's Distinguished Name (DN) as the password. Replace `johndoe` and the DN with the correct values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\noneuser chauth johndoe x509 \"/C=ES/O=ONE/OU=DEV/CN=clouduser\"\n```\n\n----------------------------------------\n\nTITLE: Instantiate Virtual Machine from Template\nDESCRIPTION: This command instantiates a virtual machine from a template. Requires the OpenNebula CLI tools to be installed and configured and the template to be present.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ onetemplate instantiate 3\nVM ID:11\n```\n\n----------------------------------------\n\nTITLE: Instantiating a Virtual Network from a Template\nDESCRIPTION: This snippet instantiates a virtual network from a virtual network template using the `onevntemplate instantiate` command.  It specifies the template ID (0), the IP address (192.168.0.100), and the size (64) for the network. This requires the OpenNebula CLI tool to be installed and configured, and the template with ID 0 must exist. The output is the ID of the created virtual network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onevntemplate instantiate 0 --ip 192.168.0.100 --size 64\nVN ID: 5\n```\n\n----------------------------------------\n\nTITLE: Becoming the oneadmin User\nDESCRIPTION: This command switches the current user to the `oneadmin` user, which is the OpenNebula administrator account. It is necessary to perform administrative tasks related to OpenNebula resource management. Requires sudo privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nsudo -i -u oneadmin\n```\n\n----------------------------------------\n\nTITLE: Creating Marketplace with Configuration File - bash\nDESCRIPTION: This code snippet demonstrates how to create a new marketplace in OpenNebula using the `onemarket create` command.  It takes a configuration file as input, which contains the necessary attributes for defining the marketplace.  The command returns the ID of the newly created marketplace.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/private_marketplaces/market_http.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nonemarket create market.conf\n```\n\n----------------------------------------\n\nTITLE: Example Service Body in OneFlow\nDESCRIPTION: This snippet shows an example of a complete Service body in OneFlow, including service name, description, state, deployment strategy, role definitions, and network configurations. It highlights the 'roles' array where each role contains the configuration for VMs and Virtual Routers(VR), as well as the 'networks_values' array which defines network assignments.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_18\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"Sample Service\",\n  \"description\": \"Test service with two roles\",\n  \"state\": 2,\n  \"deployment\": \"none\",\n  \"roles\": [\n    {\n      \"name\": \"Frontend\",\n      \"state\": 2,\n      \"type\": \"vm\",\n      \"cardinality\": 1,\n      \"template_id\": 0,\n      \"on_hold\": false,\n      \"min_vms\": 1,\n      \"max_vms\": 5,\n      \"elasticity_policies\": [],\n      \"scheduled_policies\": [],\n      \"template_contents\": {},\n      \"nodes\": [\n        {\n          \"deploy_id\": 8,\n          \"vm_info\": {\n            \"VM\": {\n              \"ID\": \"8\",\n              \"UID\": \"0\",\n              \"GID\": \"0\",\n              \"UNAME\": \"oneadmin\",\n              \"GNAME\": \"oneadmin\",\n              \"NAME\": \"MASTER_0_(service_5)\"\n            }\n          }\n        }\n      ],\n      \"last_vmname\": 1\n    },\n    {\n      \"name\": \"VNF\",\n      \"state\": 2,\n      \"type\": \"vr\",\n      \"cardinality\": 3,\n      \"template_id\": 1,\n      \"on_hold\": false,\n      \"vrouter_id\": 2,\n      \"template_contents\": {\n        \"NIC\": [\n          {\n            \"NETWORK_ID\": \"$Public\",\n            \"NAME\": \"NIC_0\"\n          },\n          {\n            \"NETWORK_ID\": \"$Private\",\n            \"NAME\": \"NIC_1\"\n          }\n        ]\n      },\n      \"nodes\": [\n        {\n          \"deploy_id\": 10,\n          \"vm_info\": {\n            \"VM\": {\n              \"ID\": \"10\",\n              \"UID\": \"0\",\n              \"GID\": \"0\",\n              \"UNAME\": \"oneadmin\",\n              \"GNAME\": \"oneadmin\",\n              \"NAME\": \"VR_ROLE_1_0_(service_5)\"\n            }\n          }\n        },\n        {\n          \"deploy_id\": 11,\n          \"vm_info\": {\n            \"VM\": {\n              \"ID\": \"11\",\n              \"UID\": \"0\",\n              \"GID\": \"0\",\n              \"UNAME\": \"oneadmin\",\n              \"GNAME\": \"oneadmin\",\n              \"NAME\": \"VR_ROLE_1_1_(service_5)\"\n            }\n          }\n        },\n        {\n          \"deploy_id\": 12,\n          \"vm_info\": {\n            \"VM\": {\n              \"ID\": \"12\",\n              \"UID\": \"0\",\n              \"GID\": \"0\",\n              \"UNAME\": \"oneadmin\",\n              \"GNAME\": \"oneadmin\",\n              \"NAME\": \"VR_ROLE_1_2_(service_5)\"\n            }\n          }\n        }\n      ],\n      \"last_vmname\": 0\n    }\n  ],\n  \"shutdown_action\": \"terminate-hard\",\n  \"on_hold\": false,\n  \"ready_status_gate\": false,\n  \"automatic_deletion\": false,\n  \"registration_time\": 1728498178,\n  \"start_time\": 1728498179,\n  \"networks_values\": [\n    { \"Public\": {\n        \"id\": \"0\"\n      },\n      \"Private\": {\n        \"reserve_from\": 2,\n        \"extra\": \"NAME=MY_RESERVATION\\nSIZE=5\"\n      }\n    }\n  ],\n  \"log\": [\n    {\n      \"timestamp\": 1728498179,\n      \"severity\": \"I\",\n      \"message\": \"New state: DEPLOYING_NETS\"\n    },\n    {\n      \"timestamp\": 1728498179,\n      \"severity\": \"I\",\n      \"message\": \"New state: DEPLOYING\"\n    },\n    {\n      \"timestamp\": 1728498185,\n      \"severity\": \"I\",\n      \"message\": \"New state: RUNNING\"\n    }\n  ]\n}\n}\n```\n\n----------------------------------------\n\nTITLE: Execute command with timeout and log - Shell\nDESCRIPTION: This snippet uses the `timeout_exec_and_log` function from `scripts_common.sh` to execute a command with a specified timeout, logging the execution.  It includes error handling for commands exceeding the timeout.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntimeout_exec_and_log 15 \"cp $SRC_PATH $DST_PATH\"\n```\n\n----------------------------------------\n\nTITLE: Metadata for User Inputs in Sunstone (JSON)\nDESCRIPTION: This JSON snippet shows how to add metadata to user inputs to enhance their display in Sunstone.  This metadata includes the type (APP/GROUP), name, title, and description. The logo attribute can also be used to add a logo to the service template using a base64 encoded image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"user_inputs_metadata\": [\n    {\n      \"type\": \"APP\",\n      \"name\": \"APACHE\",\n      \"title\": \"Apache\",\n      \"description\": \"Description of the Apache section.\"\n    },\n    {\n      \"type\": \"GROUP\",\n      \"name\": \"CONFIG\",\n      \"title\": \"Configuration\",\n      \"description\": \"Description of the Configuration section.\"\n    }\n  ],\n  \"logo\": \"data:image/png;base64,<BASE64_IMAGE>\"\n}\n```\n\n----------------------------------------\n\nTITLE: VM OS Definition using KERNEL_DS and INITRD_DS\nDESCRIPTION: This snippet defines the OS section of a VM template, specifying the kernel and RAM disk images. It utilizes `KERNEL_DS` and `INITRD_DS` attributes referencing file images by name and ID, respectively, along with kernel command-line arguments.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_29\n\nLANGUAGE: none\nCODE:\n```\nOS = [ KERNEL_DS  = \"$FILE[IMAGE=kernel5.10]\",\n           INITRD_DS  = \"$FILE[IMAGE_ID=23]\",\n           ROOT       = \"sda1\",\n           KERNEL_CMD = \"ro console=tty1\" ]\n```\n\n----------------------------------------\n\nTITLE: Making an Image Non-Persistent and Changing Permissions in OpenNebula\nDESCRIPTION: These commands modify the attributes of an existing image in OpenNebula. `oneimage nonpersistent centos7` changes the `PERSISTENT` attribute of the 'centos7' image to `NO`, ensuring that changes are not saved after the VM is terminated. `oneimage chmod centos7 744` changes the image permissions to 744, granting read, write, and execute permissions to the owner, and read-only permissions to the group and others.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/creating_images.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage nonpersistent centos7\n$ oneimage chmod centos7 744\n```\n\n----------------------------------------\n\nTITLE: Service Level User Inputs (JSON)\nDESCRIPTION: This JSON snippet shows how to define User Inputs at the Service level, meaning they apply to all roles in the service template. Attributes ATT_A, ATT_B, and ATT_C are defined as user inputs with specific constraints.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"Sample Service\",\n  \"description\": \"User Inputs at Service level example\",\n  \"deployment\": \"straight\",\n  \"roles\": [\n    {\n      \"name\": \"master\",\n      \"type\": \"vm\",\n      \"template_id\": 0,\n      \"cardinality\": 1\n    },\n    ...\n  ],\n  \"user_inputs\": {\n    \"ATT_A\": \"O|fixed|| |2\",\n    \"ATT_B\": \"M|list||0.5,1,2,4|1\",\n    \"ATT_C\": \"M|range||512..8192|2048\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Formatted Data Volume\nDESCRIPTION: This snippet demonstrates how to create a formatted data volume using the `oneimage create` command.  It specifies the size, name, format (qcow2), and datastore for the new volume. This creates a data disk for user storage.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage create --size 10240 --name db-disk --format qcow2 --datastore default\n```\n\n----------------------------------------\n\nTITLE: Adding a Group to a VDC with onevdc\nDESCRIPTION: This command adds an existing group to a specific VDC. `<vdc_id>` represents the ID of the VDC, and `<group_id>` represents the ID of the group to be added.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_vdcs.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onevdc addgroup <vdc_id> <group_id>\n```\n\n----------------------------------------\n\nTITLE: Listing Existing VDCs with onevdc\nDESCRIPTION: This command lists the existing VDCs in OpenNebula, displaying their IDs and names. It's useful for checking the current VDC configuration before creating or modifying VDCs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_vdcs.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onevdc list\n  ID NAME\n   0 default\n```\n\n----------------------------------------\n\nTITLE: Backing Up OpenNebula Federated Tables with onedb\nDESCRIPTION: This command backs up the federated tables in the master zone after it has been upgraded. It uses the `onedb backup` command with the `-v` (verbose) and `--federated` flags to export the federated data.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_federation.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nonedb backup -v --federated\n```\n\n----------------------------------------\n\nTITLE: Checking OpenNebula installation status\nDESCRIPTION: This snippet demonstrates the output of the `onecfg status` command, displaying the OpenNebula version, configuration file version, backup location, and available updates.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg status\n--- Versions -----------------\nOpenNebula: 5.10.1\nConfig:     5.6.0\n\n--- Backup to Process ---------------------\nSnapshot:    /var/lib/one/backups/config/backup\n(will be used as one-shot source for next update)\n\n--- Available updates --------\nNew config: 5.10.0\n- from 5.6.0 to 5.8.0 (YAML,Ruby)\n- from 5.8.0 to 5.10.0 (YAML,Ruby)\n```\n\n----------------------------------------\n\nTITLE: Live Migration Options (bash)\nDESCRIPTION: This code snippet shows how to enable unsafe migration by setting the `MIGRATE_OPTIONS` variable in the `/var/lib/one/remotes/etc/vmm/kvm/kvmrc` file. This is needed when disks have a cache setting different to `none`.  The `onehost sync --force` command must be run after modifying this file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nMIGRATE_OPTIONS=--unsafe\n```\n\n----------------------------------------\n\nTITLE: Adding a Role to a Running Service Using OneFlow CLI\nDESCRIPTION: These commands demonstrate how to add a role to a running service using the OneFlow command-line interface. First, the role description is defined in a JSON file (`role.tmpl`). Then, the `oneflow add-role` command is used to add the role to the specified service, identified by its ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n$ cat role.tmpl\n{\n    \"name\": \"MASTER\",\n    \"cardinality\": 1,\n    \"template_id\": 0,\n    \"type\": \"vm\",\n    \"min_vms\": 1,\n    \"max_vms\": 2,\n    \"elasticity_policies\": [],\n    \"scheduled_policies\": []\n}\n$ oneflow add-role 0 role.tmpl\n```\n\n----------------------------------------\n\nTITLE: Install OpenNebula Migration Package on Debian/Ubuntu (Bash)\nDESCRIPTION: Installs the OpenNebula migration community package on Debian/Ubuntu systems, required when upgrading OpenNebula CE. This assumes the deb package is already downloaded.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$\\u00a0dpkg -i opennebula-migration-community*.deb\n```\n\n----------------------------------------\n\nTITLE: Defining NIC requirements in VM template - Bash\nDESCRIPTION: This code snippet shows an example of how to define NIC requirements in a VM template using `NETWORK_MODE = \"auto\"` and `SCHED_REQUIREMENTS`. The first NIC attaches to a *public* network, while the second connects to a *private* network based on their `TRAFFIC_TYPE` labels.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/overview.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nNIC = [ NETWORK_MODE = \"auto\", SCHED_REQUIREMENTS = \"TRAFFIC_TYPE = \\\"public\\\"\" ]\nNIC = [ NETWORK_MODE = \"auto\", SCHED_REQUIREMENTS = \"TRAFFIC_TYPE = \\\"private\\\"\" ]\n```\n\n----------------------------------------\n\nTITLE: Copying the miniONE script to the AWS VM\nDESCRIPTION: This command copies the miniONE script to the ubuntu user's home directory on the AWS VM using the secure copy (scp) command. Replace <path to PEM file>, <path to minione script>, and <public IP of the VM> with the actual paths and IP address.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_6\n\nLANGUAGE: Bash\nCODE:\n```\nscp -i <path to PEM file> <path to minione script> ubuntu@<public IP of the VM>:~\n```\n\n----------------------------------------\n\nTITLE: Configuring VM Context\nDESCRIPTION: This snippet shows the configuration needed within a Virtual Machine to use the network contextualization attributes.  It indicates that the VM needs network configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_3\n\nLANGUAGE: none\nCODE:\n```\nCONTEXT = [\n  NETWORK=\"yes\"\n]\n```\n\n----------------------------------------\n\nTITLE: Define Sample IPv4 VNet in OpenNebula\nDESCRIPTION: This snippet defines a sample IPv4 Virtual Network (VNet) for internal VM communication within OpenNebula. It includes configuration attributes like the bridge interface and context attributes such as network address, mask, DNS, and gateway. It also defines two address ranges (AR) to be assigned to the VMs. The driver is set to dummy.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/vnet_template.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n# Configuration attributes (dummy driver)\nNAME        = \"Private Network\"\nDESCRIPTION = \"A private network for VM inter-communication\"\n\nBRIDGE = \"bond-br0\"\n\n# Context attributes\nNETWORK_ADDRESS = \"10.0.0.0\"\nNETWORK_MASK    = \"255.255.255.0\"\nDNS             = \"10.0.0.1\"\nGATEWAY         = \"10.0.0.1\"\n\n#Address Ranges, only these addresses will be assigned to the VMs\nAR=[TYPE = \"IP4\", IP = \"10.0.0.10\", SIZE = \"100\" ]\n\nAR=[TYPE = \"IP4\", IP = \"10.0.0.200\", SIZE = \"10\" ]\n```\n\n----------------------------------------\n\nTITLE: Configuring Asymmetric NUMA Topology in OpenNebula Template\nDESCRIPTION: This snippet demonstrates configuring an asymmetric NUMA topology in an OpenNebula VM template, where resources are not evenly distributed across NUMA nodes. It sets the memory allocation and total CPU units for each individual NUMA node, providing fine-grained control over resource allocation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_43\n\nLANGUAGE: text\nCODE:\n```\nTOPOLOGY = [ PIN_POLICY = CORE, SOCKETS = 2 ]\n\n   NUMA_NODE = [ MEMORY = 1024, TOTAL_CPUS = 2 ]\n   NUMA_NODE = [ MEMORY = 2048, TOTAL_CPUS = 4 ]\n```\n\n----------------------------------------\n\nTITLE: Checking OpenNebula Service Status\nDESCRIPTION: This snippet uses `systemctl` to check the status of the `opennebula.service`. The output should indicate that the service is `active (running)`. This verifies that the core OpenNebula services are properly started.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nsystemctl status opennebula.service\n```\n\n----------------------------------------\n\nTITLE: Viewing OneGate Logs (bash)\nDESCRIPTION: This command shows how to view logs related to the `opennebula-gate` service using `journalctl`. This is useful for troubleshooting and monitoring the service. It requires root privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# journalctl -u opennebula-gate.service\n```\n\n----------------------------------------\n\nTITLE: Assigning User to a Group\nDESCRIPTION: This command assigns a user to a specific group using the `oneuser chgrp` command. The `-v` flag enables verbose output.  It requires the `oneuser` command-line tool and the user and group names.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_groups.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser chgrp -v regularuser \"new group\"\nUSER 1: Group changed\n```\n\n----------------------------------------\n\nTITLE: Disabling Pagination (bash)\nDESCRIPTION: This snippet demonstrates how to disable pagination when listing VMs by setting ONE_POOL_PAGE_SIZE to a non-numeric value.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/scalability.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nONE_POOL_PAGE_SIZE=disabled onevm list\n```\n\n----------------------------------------\n\nTITLE: Listing Images in OpenNebula\nDESCRIPTION: This command lists all images in OpenNebula, showing their ID, user, group, name, datastore, size, type, persistence status, state, and the number of VMs using them. This provides a summary of the available images and their attributes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\noneimage list\n```\n\n----------------------------------------\n\nTITLE: Resetting OpenNebula Server with onezone server-reset command\nDESCRIPTION: The command `onezone server-reset` is used to reset a failing follower server in an OpenNebula HA setup. This is typically done after restoring the database on the follower. It takes the zone ID and server ID of the failed follower as input.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/frontend_ha.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onezone server-reset <zone_id> <server_id_of_failed_follower>\n```\n\n----------------------------------------\n\nTITLE: Show Virtual Network Template Information\nDESCRIPTION: This code shows how to display Virtual Network Template information using the 'onevntemplate show' command. It shows the ID, name, user, group, lock status, registration time, permissions, and template contents.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vn_templates.rst#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ onevntemplate show 0\n  TEMPLATE 0 INFORMATION\n  ID             : 0\n  NAME           : vntemplate\n  USER           : oneadmin\n  GROUP          : oneadmin\n  LOCK           : None\n  REGISTER TIME  : 11/28 14:44:21\n\n  PERMISSIONS\n  OWNER          : um-\n  GROUP          : ---\n  OTHER          : u--\n  TEMPLATE CONTENTS\n  BRIDGE=\"virbr0\"\n  VN_MAD=\"bridge\"\n```\n\n----------------------------------------\n\nTITLE: Creating the my-one Directory\nDESCRIPTION: These commands create a directory named 'my-one' and then navigate into it.  This directory will be used to store the configuration files for the OpenNebula deployment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nmkdir my-one\ncd my-one\n```\n\n----------------------------------------\n\nTITLE: QEMU Guest Agent Monitoring Example\nDESCRIPTION: This JSON output shows an example of the data returned in the MONITORING section of a VM instance after executing the guest agent command. It includes CPU, disk I/O, memory, network traffic, and the result of the VM_QEMU_PING command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"CPU\": \"0.0\",\n  \"DISKRDBYTES\": \"287175970\",\n  \"DISKRDIOPS\": \"14795\",\n  \"DISKWRBYTES\": \"2655895040\",\n  \"DISKWRIOPS\": \"36070\",\n  \"DISK_SIZE\": [\n    {\n      \"ID\": \"0\",\n      \"SIZE\": \"863\"\n    },\n    {\n      \"ID\": \"1\",\n      \"SIZE\": \"1\"\n    }\n  ],\n  \"ID\": \"159\",\n  \"MEMORY\": \"1838804\",\n  \"NETRX\": \"135117657\",\n  \"NETTX\": \"630067\",\n  \"TIMESTAMP\": \"1720712912\",\n  \"VM_QEMU_PING\": \"{}\"\n}\n```\n\n----------------------------------------\n\nTITLE: Terraform Resource Definition Template\nDESCRIPTION: This Terraform template defines a resource, in this case, related to AWS VPC, subnets, internet gateway, routes and security group.  It utilizes ERB syntax to inject information from the OpenNebula object (`obj`), provision settings (`provision`), and cluster information (`c`). This template defines resources to be created for the Edge Cluster.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_2\n\nLANGUAGE: terraform\nCODE:\n```\nresource \"aws_vpc\" \"device_<%= obj['ID'] %>\" {\n    cidr_block = \"<%= provision['CIDR'] ? provision['CIDR'] : '10.0.0.0/16'%>\"\n\n    tags = {\n        Name = \"<%= obj['NAME'] %>_vpc\"\n    }\n}\n\nresource \"aws_subnet\" \"device_<%= obj['ID'] %>\" {\n    vpc_id     = aws_vpc.device_<%= obj['ID'] %>.id\n    cidr_block = \"<%= provision['CIDR'] ? provision['CIDR'] : '10.0.0.0/16'%>\"\n\n    map_public_ip_on_launch = true\n\n    tags = {\n        Name = \"<%= obj['NAME'] %>_subnet\"\n    }\n}\n\nresource \"aws_internet_gateway\" \"device_<%= obj['ID'] %>\" {\n    vpc_id = aws_vpc.device_<%= obj['ID'] %>.id\n\n    tags = {\n        Name = \"<%= obj['NAME'] %>_gateway\"\n    }\n}\n\nresource \"aws_route\" \"device_<%= obj['ID'] %>\" {\n    route_table_id         = aws_vpc.device_<%= obj['ID'] %>.main_route_table_id\n    destination_cidr_block = \"0.0.0.0/0\"\n    gateway_id             = aws_internet_gateway.device_<%= obj['ID'] %>.id\n}\n\nresource \"aws_security_group\" \"device_<%= obj['ID'] %>_all\" {\n    name        = \"allow_all\"\n    description = \"Allow all traffic\"\n    vpc_id     = aws_vpc.device_<%= c['ID'] %>.id\n\n    ingress {\n        from_port   = 0\n        to_port     = 0\n        protocol    = \"-1\"\n        cidr_blocks = [\"0.0.0.0/0\"]\n    }\n\n    egress {\n        from_port   = 0\n        to_port     = 0\n        protocol    = \"-1\"\n        cidr_blocks = [\"0.0.0.0/0\"]\n    }\n\n    tags = {\n        Name = \"device_<%= obj['ID'] %>_all\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Service Template Schema Definition\nDESCRIPTION: This JSON schema defines the structure and requirements for creating a service template in OpenNebula. It specifies the types of data allowed for various attributes like 'name', 'deployment', 'roles', and 'shutdown_action'.  The schema details the data type, requirements, and properties for each field, including nested structures for roles, user inputs, and parents.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_5\n\nLANGUAGE: JSON\nCODE:\n```\n{\n        'name' => {\n            :type => :string,\n            :required => true\n        },\n        'deployment' => {\n            :type => :string,\n            :required => true\n        },\n        'roles' => {\n            :type => :array,\n            :items => {\n                :type => :object,\n                :properties => {\n                    'name' => {\n                        :type => :string,\n                        :required => true\n                    },\n                    'type' => {\n                        :type => :string,\n                        :required => false\n                    },\n                    'shutdown_action' => {\n                        :type => :string,\n                        :required => false\n                    },\n                    'min_vms' => {\n                        :type => :integer,\n                        :required => false\n                    },\n                    'max_vms' => {\n                        :type => :integer,\n                        :required => false\n                    },\n                    'cooldown' => {\n                        :type => :integer,\n                        :required => false\n                    },\n                    'elasticity_policies' => {\n                        :type => :array,\n                        :items => {\n                            :type => :object\n                        },\n                        :required => false\n                    },\n                    'scheduled_policies' => {\n                        :type => :array,\n                        :items => {\n                            :type => :object\n                        },\n                        :required => false\n                    },\n                    'template_id' => {\n                        :type => :integer,\n                        :required => true\n                    },\n                    'cardinality' => {\n                        :type => :integer,\n                        :default => 0,\n                        :minimum => 0\n                    },\n                    'template_contents' => {\n                        :type => :object,\n                        :properties => {},\n                        :required => false\n                    },\n                    'user_inputs' => {\n                        :type => :object,\n                        :properties => {},\n                        :required => false\n                    },\n                    'user_inputs_values' => {\n                        :type => :object,\n                        :properties => {},\n                        :required => false\n                    },\n                    'on_hold' => {\n                        :type => :boolean,\n                        :required => false\n                    },\n                    'parents' => {\n                        :type => :array,\n                        :items => {\n                            :type => :string\n                        }\n                    }\n                }\n            }\n        },\n        'shutdown_action' => {\n            :type => :string,\n            :required => true\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Verifying DPDK vhost Interface in Open vSwitch (Bash)\nDESCRIPTION: This snippet shows how to verify the DPDK vhost interface in the Open vSwitch bridge. It confirms the interface type as 'dpdkvhostuserclient' and shows the path to the vhost-server socket.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nBridge onebr.dpdk\n    datapath_type: netdev\n    Port \"one-10-0\"\n        tag: 1420\n        Interface \"one-10-0\"\n            type: dpdkvhostuserclient\n            options: {vhost-server-path=\"/var/lib/one//datastores/0/10/one-10-0\"}\n...\n```\n\n----------------------------------------\n\nTITLE: Restore OpenNebula Database via CLI\nDESCRIPTION: This command restores the OpenNebula database from a backup file using the `onedb restore` command-line tool. The `-f` option specifies the path to the backup file.  The file name in the example includes date and time of the backup.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_ha.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onedb restore -f /tmp/mysql_localhost_opennebula_2019-9-27_11:52:47.sql\nMySQL DB opennebula at localhost restored.\n```\n\n----------------------------------------\n\nTITLE: Checking OpenNebula status with no updates\nDESCRIPTION: This snippet shows the output of `onecfg status` when no configuration updates are available, indicating that the current configuration version is up to date with the installed OpenNebula version.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg status\n--- Versions ------------------------------\nOpenNebula:  5.10.2\nConfig:      5.10.0\n\n--- Available Configuration Updates -------\nNo updates available.\n```\n\n----------------------------------------\n\nTITLE: Accessing Template content as a Python Dictionary\nDESCRIPTION: Demonstrates accessing the content of a template as a plain Python dictionary. This is useful for TEMPLATE and USER_TEMPLATE elements which are often marked as anyType. Requires a valid host ID and a `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nhost = one.host.info(0)\narch = host.TEMPLATE['ARCH']\n```\n\n----------------------------------------\n\nTITLE: FRR Configuration for Hypervisors\nDESCRIPTION: This FRR configuration enables BGP EVPN on a hypervisor. It defines the router ID, remote AS, and address family for L2VPN EVPN. This configuration allows the hypervisor to send BGP updates with MAC addresses and IPs for VXLAN tunnel endpoints to a route reflector.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vxlan.rst#_snippet_5\n\nLANGUAGE: FRR\nCODE:\n```\nrouter bgp 7675\n bgp router-id 10.4.4.11\n no bgp default ipv4-unicast\n neighbor 10.4.4.13 remote-as 7675\n neighbor 10.4.4.13  capability extended-nexthop\n address-family l2vpn evpn\n  neighbor 10.4.4.13 activate\n  advertise-all-vni\n exit-address-family\nexit\n```\n\n----------------------------------------\n\nTITLE: Restarting Grafana Server\nDESCRIPTION: This command restarts the Grafana server service, applying any configuration changes made through provisioning or other methods. This is required for Grafana to recognize and load new datasources or dashboards.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/grafana.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl restart grafana-server.service\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Edge Cluster Provision Template (YAML)\nDESCRIPTION: This YAML file shows the structure and configuration options for an OpenNebula Edge Cluster provision template. It defines the cluster name, extends other YAML files for default settings and resource configurations, specifies the Ansible playbook to use for host configuration, and sets default values for provision objects, including provider name, AMI, instance type, and cloud-init settings. It also configures cluster-specific parameters like reserved CPU and memory, datastores, and CIDR block.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n---\n#-------------------------------------------------------------------------------\n# This is the canonical description file for a cluster build with 'AWS'\n# resources using the KVM hypervisor.\n# ------------------------------------------------------------------------------\n\nname: 'aws-cluster'\n\nextends:\n    - common.d/defaults.yml\n    - common.d/resources.yml\n    - common.d/hosts.yml\n    - aws.d/datastores.yml\n    - aws.d/fireedge.yml\n    - aws.d/inputs.yml\n    - aws.d/networks.yml\n\n#-------------------------------------------------------------------------------\n# playbook: Ansible playbook used for hosts configuration. Check ansible/aws.yml\n# for the specific roles applied.\n#-------------------------------------------------------------------------------\nplaybook:\n  - aws\n\n#-------------------------------------------------------------------------------\n# defaults: Common configuration attributes for provision objects\n#--------------------------------------------------------------------------------\ndefaults:\nprovision:\n    provider_name: 'aws'\n    ami: \"${input.aws_ami_image}\"\n    instancetype: \"${input.aws_instance_type}\"\n    cloud_init: true\nconnection:\n    remote_user: 'centos'\n\n#-------------------------------------------------------------------------------\n# cluster: Parameters for the OpenNebula cluster. Applies to all the Hosts\n#--------------------------------------------------------------------------------\n#  name: of the cluster\n#  description: Additional information\n#  reserved_cpu: In percentage. It will be subtracted from the TOTAL CPU\n#  reserved_memory: In percentage. It will be subtracted from the TOTAL MEM\n#--------------------------------------------------------------------------------\ncluster:\n  name: \"${provision}\"\n  description: 'AWS virtual edge cluster'\n  reserved_cpu: '0'\n  reserved_mem: '0'\n  datastores:\n    - 1\n    - 2\n  provision:\n    cidr: '10.0.0.0/16'\n\n#-------------------------------------------------------------------------------\n# AWS provision parameters.\n#-------------------------------------------------------------------------------\n# This section is used by provision drivers. DO NOT MODIFY IT\n#\n#   CIDR: Private IP block for the cluster. This value HAS TO MATCH that on\n```\n\n----------------------------------------\n\nTITLE: Command to Bypass Windows 11 Network Requirement\nDESCRIPTION: This command is used in the Windows 11 setup to bypass the network requirement during installation. It opens a Command Prompt in the Virtual Machine, executes the `oobe/BypassNRO` command, which reboots the machine, allowing to bypass the network requirements.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_9\n\nLANGUAGE: none\nCODE:\n```\noobe/BypassNRO\n```\n\n----------------------------------------\n\nTITLE: Listing and Exporting Images from OpenNebula Marketplace\nDESCRIPTION: These commands demonstrate how to list available images from the OpenNebula Marketplace and export a specific image to a datastore. The `onemarketapp list` command displays a list of available images with their details, while the `onemarketapp export` command exports the specified image (Devuan in this case) to the 'default' datastore, creating an IMAGE and VMTEMPLATE.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/creating_images.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onemarketapp list\n  ID NAME                         VERSION  SIZE STAT TYPE  REGTIME MARKET               ZONE\n[...]\n  43 alpine-vrouter                 1.0.3  256M  rdy  img 03/10/16 OpenNebula Public       0\n  44 CoreOS alpha                1000.0.0  245M  rdy  img 04/03/16 OpenNebula Public       0\n  45 Devuan                      1.0 Beta    8M  rdy  img 05/03/16 OpenNebula Public       0\n$ onemarketapp export Devuan Devuan --datastore default\nIMAGE\n\tID: 12\nVMTEMPLATE\n\tID: -1\n```\n\n----------------------------------------\n\nTITLE: Generating SSL Certificate with OpenSSL (Bash)\nDESCRIPTION: This snippet demonstrates how to generate a self-signed SSL certificate using OpenSSL. It creates a directory, navigates into it, and then uses openssl to generate the key and certificate files. The certificate is valid for 365 days.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/shared/cert.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ mkdir mycerts\n$ cd mycerts\n$ openssl req -x509 -nodes -newkey rsa:2048 -keyout key.pem -out certificate.pem -days 365 -batch\n```\n\n----------------------------------------\n\nTITLE: Running the upgrade subcommand in verbose mode\nDESCRIPTION: This example shows how to run the `onecfg upgrade` command in verbose mode using the `--verbose` flag. Verbose mode provides detailed output, including information about the versions being checked, files being updated, and any files being skipped. This is helpful for monitoring the upgrade process and identifying potential issues.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade --verbose\n```\n\n----------------------------------------\n\nTITLE: Running onecfg status with sudo in bash\nDESCRIPTION: This snippet shows how to execute the `onecfg status` command using `sudo`. This is required because `onecfg` must be run with privileged user `root` to work correctly.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo onecfg status\n```\n\n----------------------------------------\n\nTITLE: FireEdge Configuration\nDESCRIPTION: This code snippet shows the configuration for FireEdge, which defines the zone ID, name, and endpoint. The `default_zone` configuration in `/etc/one/fireedge-server.conf` needs to be adjusted on each FireEdge instance to map it to the correct OpenNebula zone.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/frontend_ha.rst#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\ndefault_zone:\n  id: 0\n  name: 'OpenNebula'\n  endpoint: 'http://localhost:2633/RPC2'\n```\n\n----------------------------------------\n\nTITLE: Restoring OpenNebula Federated Backup in Slave Zones with onedb\nDESCRIPTION: This command restores the federated backup in all slave zones. It involves copying the backup file to each slave zone and then using the `onedb restore` command with the `-v` (verbose) and `--federated` flags to import the federated data.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_federation.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nscp <backup_file> <slave_ip>:/tmp\n onedb restore <backup_file> -v --federated\n```\n\n----------------------------------------\n\nTITLE: Checking Edge Provider Information using oneprovider in OpenNebula\nDESCRIPTION: This snippet shows how to retrieve information about an existing Edge provider using the `oneprovider show` command in OpenNebula. It takes the provider's ID as input and displays its details, including connection information such as access keys and region. The output is unencrypted.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/provider_operations.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovider show 0\nPROVIDER 0 INFORMATION\nID   : 0\nNAME : aws-frankfurt\n\nCONNECTION INFORMATION\naccess_key : AWS access key\nsecret_key : AWS secret key\nregion     : eu-central-1\n```\n\n----------------------------------------\n\nTITLE: Validating OpenNebula Configuration Files\nDESCRIPTION: This snippet demonstrates the basic usage of the `onecfg validate` command to check the parsing of configuration files and displays an error message if a file cannot be processed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg validate\nERROR : Unable to process file '/etc/one/oned.conf' - Failed to parse file\n```\n\n----------------------------------------\n\nTITLE: Retrieving Virtual Router Information with OneGate (bash)\nDESCRIPTION: This command shows how to retrieve virtual router information using the `onegate vrouter show` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onegate vrouter show\nVROUTER 0\nNAME                : vr\nVMS                 : 1\n```\n\n----------------------------------------\n\nTITLE: Listing Proxy Process IDs\nDESCRIPTION: This command lists the PIDs of the running proxy processes. It shows the `one_tproxy` process running in the default network namespace and the `one_tproxy_*` processes in the dedicated network namespaces.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ /var/tmp/one/vnm/tproxy status\none_tproxy: 16803\none_tproxy_br0: 16809\n```\n\n----------------------------------------\n\nTITLE: Install Host Packages (RPM)\nDESCRIPTION: Installs the OpenNebula Prometheus-KVM package on host machines (RPM-based distributions). This package includes the OpenNebula Libvirt exporter and the Prometheus Node exporter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# yum -y install opennebula-prometheus-kvm\n```\n\n----------------------------------------\n\nTITLE: Listing Available Network Models for KVM\nDESCRIPTION: This command lists the available network models that can be emulated by KVM. It uses `kvm` with the `-net nic,model=?` option and redirects output to `/dev/null` to avoid running a VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nkvm -net nic,model=? -nographic /dev/null\n```\n\n----------------------------------------\n\nTITLE: oneacct output filtered by user\nDESCRIPTION: This example demonstrates how to filter the `oneacct` output for a specific user using the `-u` option and split the results for each VM using the `--split` option. It presents accounting records grouped by Virtual Machine ID (VID) for the specified user.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/accounting.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n$ oneacct -u 0 --split\n# User 0\n\n VID HOSTNAME        ACTION           REAS     START_TIME       END_TIME MEMORY CPU  NETRX  NETTX   DISK\n  12 host01          none             user 05/09 19:20:42 05/09 19:35:23  1024M   1  29.8M 638.8K     0K\n\n VID HOSTNAME        ACTION           REAS     START_TIME       END_TIME MEMORY CPU  NETRX  NETTX   DISK\n  13 host01          nic-attach       user 05/17 17:10:57 05/17 17:12:48   256M 0.1  19.2K  15.4K     8G\n  13 host01          nic-detach       user 05/17 17:12:48 05/17 17:13:48   256M 0.1  36.9K    25K     8G\n  13 host01          nic-attach       user 05/17 17:13:48 05/17 17:14:54   256M 0.1  51.2K  36.4K     8G\n  13 host01          nic-detach       user 05/17 17:14:54 05/17 17:17:19   256M 0.1  79.8K  61.7K     8G\n  13 host01          nic-attach       user 05/17 17:17:19 05/17 17:17:27   256M 0.1  79.8K  61.7K     8G\n  13 host01          terminate-hard   user 05/17 17:17:27 05/17 17:37:52   256M 0.1 124.6K  85.9K     8G\n\n VID HOSTNAME        ACTION           REAS     START_TIME       END_TIME MEMORY CPU  NETRX  NETTX   DISK\n  14 host02          nic-attach       user 05/17 17:38:16 05/17 17:40:00   256M 0.1  16.5K  13.2K     8G\n  14 host02          poweroff         user 05/17 17:40:00 05/17 17:53:40   256M 0.1  38.3K  18.8K     8G\n  14 host02          terminate-hard   user 05/17 17:55:55 05/18 14:54:19   256M 0.1     1M  27.3K     8G\n\n VID HOSTNAME        ACTION           REAS     START_TIME       END_TIME MEMORY CPU  NETRX  NETTX   DISK\n  29 host02          none             none 05/27 17:09:28              -   256M   1   2.4M   1.3K    10G\n```\n\n----------------------------------------\n\nTITLE: Verifying NFS Entry in fstab\nDESCRIPTION: This snippet displays the expected entry in the `/etc/fstab` file, ensuring the NFS share is configured to mount automatically. The entry specifies the NFS server, shared directory, mount point, filesystem type, and mount options.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n172.20.0.5:/storage/one_datastores /var/lib/one/datastores nfs rw,relatime,comment=one-deploy 0 0\n```\n\n----------------------------------------\n\nTITLE: Creating LUKS Image from Scratch\nDESCRIPTION: Creates an encrypted volume using the raw format with `qemu-img`. This includes generating a key, and saving it to a file, and setting permissions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n$ qemu-img create --object secret,id=sec0,file=passphrase.luks -o key-secret=sec0 -f luks /tmp/luks.vol 5G\n```\n\n----------------------------------------\n\nTITLE: Checking OpenNebula Configuration Status with onecfg\nDESCRIPTION: This snippet shows how to check the configuration status using the `onecfg status` command. This command is used to verify that the configuration is up-to-date and compatible with the installed OpenNebula version. It displays the OpenNebula and Config versions and indicates whether any configuration updates are available.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/start_here.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onecfg status\n--- Versions ------------------------------\nOpenNebula:  5.10.2\nConfig:      5.10.0\n\n--- Available Configuration Updates -------\nNo updates available.\n```\n\n----------------------------------------\n\nTITLE: Listing Transparent Proxy Log Files\nDESCRIPTION: This command lists the log files associated with the transparent proxy on the hypervisor host. The logs can be used for debugging purposes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ls -1 /var/log/one_tproxy*.log\n/var/log/one_tproxy.log\n/var/log/one_tproxy_br0.log\n```\n\n----------------------------------------\n\nTITLE: Defining Network Values for Service Template - Network Template Instantiation\nDESCRIPTION: This snippet shows how to define network values to instantiate a network template.  The \"template_id\" attribute refers to the ID of the Virtual Network Template. The \"extra\" attribute allows specifying additional parameters such as address ranges (AR) using a string formatted as AR=[ IP=192.168.122.10, SIZE=10, TYPE=IP4 ].\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_16\n\nLANGUAGE: json\nCODE:\n```\n{\n  ...\n  \"networks_values\": [\n    { \"Public\": {\n        template_id\": \"$<vnet_template_id>\",\n        \"extra\": \"AR=[ IP=192.168.122.10, SIZE=10, TYPE=IP4 ]\"\n      }\n    }\n  ]\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting XML Parameters with XPath (Ruby)\nDESCRIPTION: This snippet demonstrates how to extract parameters from an XML document using XPath expressions. It uses a Ruby script (`xpath.rb`) to retrieve values based on given XPath queries. The extracted values are then stored in an array for further processing.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-vmm.rst#_snippet_2\n\nLANGUAGE: ruby\nCODE:\n```\nXPATH=\"${DRIVER_PATH}/../../datastore/xpath.rb -b $DRV_ACTION\"\n\nunset i j XPATH_ELEMENTS\n\nDISK_XPATH=\"/VMM_DRIVER_ACTION_DATA/VM/TEMPLATE/DISK[ATTACH='YES']\"\n\nwhile IFS= read -r -d '' element; do\n    XPATH_ELEMENTS[i++]=\"$element\"\ndone < <($XPATH     $DISK_XPATH/DRIVER \\\n                    $DISK_XPATH/TYPE \\\n                    $DISK_XPATH/READONLY \\\n                    $DISK_XPATH/CACHE \\\n                    $DISK_XPATH/SOURCE)\n\nDRIVER=\"${XPATH_ELEMENTS[j++]:-$DEFAULT_TYPE}\"\nTYPE=\"${XPATH_ELEMENTS[j++]}\"\nREADONLY=\"${XPATH_ELEMENTS[j++]}\"\nCACHE=\"${XPATH_ELEMENTS[j++]}\"\nIMG_SRC=\"${XPATH_ELEMENTS[j++]}\"\n```\n\n----------------------------------------\n\nTITLE: Validating SSH connections\nDESCRIPTION: This set of commands validates SSH connections between the front-end and the nodes, ensuring that passwordless login is working correctly. It checks connections from the front-end to itself, from the front-end to the nodes, and from the nodes back to the front-end.  <frontend>, <node1>, <node2>, <node3>, etc. should be replaced with the actual hostnames or IP addresses.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/passwordless_ssh.txt#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# from Front-end to Front-end itself\n$ ssh <frontend>\n$ exit\n\n# from Front-end to node, back to Front-end and to other nodes\n$ ssh <node1>\n$ ssh <frontend>\n$ exit\n$ ssh <node2>\n$ exit\n$ ssh <node3>\n$ exit\n$ exit\n\n# from Front-end to node, back to Front-end and to other nodes\n$ ssh <node2>\n$ ssh <frontend>\n$ exit\n$ ssh <node1>\n$ exit\n$ ssh <node3>\n$ exit\n$ exit\n\n# from Front-end to nodes and back to Front-end and other nodes\n$ ssh <node3>\n$ ssh <frontend>\n$ exit\n$ ssh <node1>\n$ exit\n$ ssh <node2>\n$ exit\n$ exit\n```\n\n----------------------------------------\n\nTITLE: onecfg diff --format yaml Usage Example\nDESCRIPTION: This example demonstrates the output of `onecfg diff` in YAML format. It provides a detailed representation of changes, including the file path, change class, path elements, key, value, old value, state (ins, set), and extra information. The YAML format is suitable for accurately identifying and applying (patching) configuration changes. Requires `onecfg` and its dependencies.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/diff_formats.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n---\npatches:\n  \"/etc/one/cli/oneimage.yaml\":\n    class: Yaml::Strict\n    change:\n    - path:\n      - :ID\n      key: :adjust\n      value: false\n      state: ins\n      extra: {}\n    - path:\n      - :USER\n      key: :size\n      value: 15\n      old: 8\n      state: set\n      extra: {}\n    - path:\n      - :GROUP\n      key: :size\n      value: 15\n      old: 8\n      state: set\n      extra: {}\n    - path:\n      - :NAME\n      key: :expand\n      value: false\n      state: ins\n      extra: {}\n```\n\n----------------------------------------\n\nTITLE: Generating SSH Key Pair\nDESCRIPTION: This command generates a new RSA SSH key pair. It's essential for users to create these keys if they don't already exist, as OpenNebula utilizes them for authentication. The keys are typically stored in the standard ~/.ssh/ directory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ssh.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nssh-keygen -t rsa\n```\n\n----------------------------------------\n\nTITLE: Create Service Template with curl\nDESCRIPTION: This curl command creates a new service template named 'web-application' using the OpenNebula API. The command includes the authentication credentials (oneadmin:password), the API endpoint (/service_template), and the JSON payload that defines the service template's attributes, such as roles, deployment strategy, and policies.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_7\n\nLANGUAGE: Bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service_template -u 'oneadmin:password' -v --data '{\n      \"name\":\"web-application\",\n      \"deployment\":\"straight\",\n      \"roles\":[\n        {\n          \"name\":\"frontend\",\n          \"cardinality\":\"1\",\n          \"template_id\":\"0\",\n          \"type\": \"vm\",\n          \"shutdown_action\":\"shutdown\",\n          \"min_vms\":\"1\",\n          \"max_vms\":\"4\",\n          \"cooldown\":\"30\",\n          \"elasticity_policies\":[\n            {\n              \"type\":\"PERCENTAGE_CHANGE\",\n              \"adjust\":\"20\",\n              \"min_adjust_step\":\"1\",\n              \"expression\":\"CUSTOM_ATT>40\",\n              \"period\":\"3\",\n              \"period_number\":\"30\",\n              \"cooldown\":\"30\"\n            }\n          ],\n          \"scheduled_policies\":[\n            {\n              \"type\":\"CHANGE\",\n              \"adjust\":\"4\",\n              \"recurrence\":\"0 2 1-10 * * \"\n            }\n          ]\n        },\n        {\n          \"name\":\"worker\",\n          \"cardinality\":\"2\",\n          \"template_id\":\"0\",\n          \"type\": \"vm\",\n          \"shutdown_action\":\"shutdown\",\n          \"parents\":[\n            \"frontend\"\n          ],\n          \"min_vms\":\"2\",\n          \"max_vms\":\"10\",\n          \"cooldown\":\"240\",\n          \"elasticity_policies\":[\n            {\n              \"type\":\"CHANGE\",\n              \"adjust\":\"5\",\n              \"expression\":\"ATT=3\",\n              \"period\":\"5\",\n              \"period_number\":\"60\",\n              \"cooldown\":\"240\"\n            }\n          ],\n          \"scheduled_policies\":[\n          ]\n        }\n      ],\n      \"shutdown_action\":\"shutdown\"\n    }'\n```\n\n----------------------------------------\n\nTITLE: Example Monitor Output - OpenNebula\nDESCRIPTION: This is an example of the output from the monitor script, showing the format of the MONITOR parameter for a VM. The MONITOR parameter is encoded in base64 format and contains disk and snapshot sizes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nVM = [ ID = ${vm_id}, MONITOR = \"\\\n      DISK_SIZE=[ID=${disk_id},SIZE=${disk_size}]\n      ...\n      SNAPSHOT_SIZE=[ID=${snap},DISK_ID=${disk_id},SIZE=${snap_size}]\n      ...\n      \"\n  ]\n  ...\n```\n\n----------------------------------------\n\nTITLE: Show Virtual Machine Information (onevm show)\nDESCRIPTION: This command displays the information of a virtual machine, including its ID, name, disks, backup configuration, and associated backups. It helps verify the VM's configuration and backup settings.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 83\n```\n\n----------------------------------------\n\nTITLE: Accessing Attribute in Multiple Value Variable in OpenNebula VM Template\nDESCRIPTION: Shows how to access a specific attribute (IP) within a multiple-value variable (NIC) in an OpenNebula VM template to set the IP_PRIVATE variable.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_20\n\nLANGUAGE: text\nCODE:\n```\nIP_PRIVATE = $NIC[IP]\n```\n\n----------------------------------------\n\nTITLE: Example Requirement Expression for Excluding VM IDs\nDESCRIPTION: This example demonstrates how to define scheduling requirements to deploy in any Host, except the ones where VM 5 or VM 7 are running.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_30\n\nLANGUAGE: text\nCODE:\n```\n# Deploy in any Host, except the ones where VM 5 or VM 7 are running\nSCHED_REQUIREMENTS = \"(CURRENT_VMS != 5) & (CURRENT_VMS != 7)\"\n```\n\n----------------------------------------\n\nTITLE: User Inputs Example for Sunstone\nDESCRIPTION: This example shows a more complex example of User Inputs designed for use with Sunstone. It demonstrates a broader range of input types and how they can be used to configure various aspects of a VM deployment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_4\n\nLANGUAGE: none\nCODE:\n```\nUSER_INPUTS = [\n  BLOG_TITLE=\"M|text|Blog Title\",\n  BLOG_DESCRIPTION=\"O|text|Blog Description\",\n  MYSQL_ENDPOINT=\"M|text|MySQL Endpoint\",\n  MYSQL_USER=\"O|password|MySQL User\",\n  MYSQL_PASSWORD=\"O|password|MySQL Password\",\n  MYSQL_ADDITIONAL=\"O|boolean|Define additional parameters\",\n  MYSQL_SOCKET=\"O|text|MySQL Socket\",\n  MYSQL_CHARSET=\"O|text|MySQL Charset\",\n]\n```\n\n----------------------------------------\n\nTITLE: Building Python Bindings\nDESCRIPTION: These commands demonstrate how to build and install the OpenNebula Python bindings from source. It involves navigating to the python OCA directory, making the necessary files, creating a distribution package, and installing it.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/compile.rst#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nroot@frontend:~/ $> cd src/oca/python\nroot@frontend:~/ $> make\nroot@frontend:~/ $> make dist\nroot@frontend:~/ $> make install\n```\n\n----------------------------------------\n\nTITLE: Show Image Information (oneimage show)\nDESCRIPTION: This command displays detailed information about a specific image within OpenNebula, including its ID, name, user, group, datastore, type, registration time, persistence, source, format, size, state, running VMs, permissions, image template, and backup information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage show 1\n```\n\n----------------------------------------\n\nTITLE: List OpenNebula Virtual Network Templates\nDESCRIPTION: This command lists the OpenNebula virtual network templates. It displays the template ID, user, group, name, and registration time. Requires the OpenNebula CLI tools to be installed and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ onevntemplate list\n  ID USER     GROUP    NAME                                                  REGTIME\n   0 oneadmin oneadmin onprem-hci-cluster-private                         04/28 18:08:38\n```\n\n----------------------------------------\n\nTITLE: Showing Image Permissions in OpenNebula\nDESCRIPTION: This command shows the permissions of an image with ID 0. It displays the owner, group, and other permissions for the image. This allows users to understand the access control settings for the image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\noneimage show 0\n```\n\n----------------------------------------\n\nTITLE: Checking oneadmin user ID\nDESCRIPTION: This snippet displays the user ID (uid), group ID (gid), and groups of the 'oneadmin' user. It's used to verify the existence and configuration of the 'oneadmin' user on the backup server, a prerequisite for SSH access.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/restic.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nid oneadmin\n```\n\n----------------------------------------\n\nTITLE: Navigating to the OneDeploy Directory\nDESCRIPTION: This command changes the current directory to the one-deploy directory, which was created when the repository was cloned.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd one-deploy\n```\n\n----------------------------------------\n\nTITLE: Input Parameters Definition\nDESCRIPTION: Defines input parameters such as number of hosts, number of public IPs, DNS servers, AWS AMI image, AWS instance type and hypervisor, used for customization of the edge cluster.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_7\n\nLANGUAGE: YAML\nCODE:\n```\ninputs:\n  - name: 'number_hosts'\n    type: text\n    description: 'Number of AWS instances to create'\n    default: '1'\n\n  - name: 'number_public_ips'\n    type: text\n    description: 'Number of public IPs to get'\n    default: '1'\n\n  - name: 'dns'\n    type: text\n    description: 'Comma separated list of DNS servers for public network'\n    default: '1.1.1.1'\n\n  - name: 'aws_ami_image'\n    type: text\n    description: \"AWS ami image used for host deployments\"\n    default: ''\n\n  - name: 'aws_instance_type'\n    type: text\n    description: \"AWS instance type, use virtual instances\"\n    default: ''\n\n  - name: 'one_hypervisor'\n    type: list\n    description: \"Virtualization technology for the cluster hosts\"\n    default: 'lxc'\n    options:\n        - 'qemu'\n        - 'lxc'\n```\n\n----------------------------------------\n\nTITLE: Installing Context Package on RHEL 7.x with yum\nDESCRIPTION: These commands install the OpenNebula context package and its dependencies on RHEL 7.x (CentOS/Oracle Linux 7.x) using yum. It first installs the EPEL repository and then installs the one-context package.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# yum install -y epel-release\n# yum install -y one-context-[0-9]*el7*rpm\n```\n\n----------------------------------------\n\nTITLE: PCI Device Filter Configuration Example\nDESCRIPTION: This configuration defines filters for PCI device monitoring using vendor, device, and class IDs.  The :filter option specifies patterns to match against the PCI device information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\n# This option specifies the main filters for PCI card monitoring. The format\n# is the same as used by lspci to filter on PCI card by vendor:device(:class)\n# identification. Several filters can be added as a list, or separated\n# by commas. The NULL filter will retrieve all PCI cards.\n#\n# From lspci help:\n#     -d [<vendor>]:[<device>][:<class>]\n#            Show only devices with specified vendor, device and  class  ID.\n#            The  ID's  are given in hexadecimal and may be omitted or given\n#            as \"*\", both meaning \"any value\"#\n#\n# For example:\n#   :filter:\n#     - '10de:*'      # all NVIDIA VGA cards\n#     - '10de:11bf'   # only GK104GL [GRID K2]\n#     - '*:10d3'      # only 82574L Gigabit Network cards\n#     - '8086::0c03'  # only Intel USB controllers\n#\n# or\n#\n#   :filter: '*:*'    # all devices\n#\n# or\n#\n#   :filter: '0:0'    # no devices\n#\n:filter: '*:*'\n```\n\n----------------------------------------\n\nTITLE: Setting Permissions for secret.xml\nDESCRIPTION: This snippet sets the file permissions of the `secret.xml` file to 600, meaning only the owner can read and write to it.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n$ chmod 600 secret.xml\n```\n\n----------------------------------------\n\nTITLE: Setting execute permissions on miniONE\nDESCRIPTION: This command adds execute permissions to the miniONE script, making it executable. Without execute permissions, the script cannot be run.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_8\n\nLANGUAGE: Bash\nCODE:\n```\nchmod +x minione\n```\n\n----------------------------------------\n\nTITLE: Creating OpenNebula Hooks\nDESCRIPTION: Creates OpenNebula hooks using the `onehook create` command and the previously defined template files.  The first command creates the autostart-host hook and the second creates autostart-vm hook.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n$ onehook create autostart-host.tmpl\n$ onehook create autostart-vm.tmpl\n```\n\n----------------------------------------\n\nTITLE: Listing VMs in OpenNebula\nDESCRIPTION: This command lists all VMs running in the OpenNebula environment. It displays information such as VM ID, user, group, name, status, CPU usage, memory usage, host, and uptime.  It requires access to the OpenNebula CLI tools and is used to check the status of a deployed VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\nonevm list\n```\n\n----------------------------------------\n\nTITLE: Example Requirement Expression for VM ID\nDESCRIPTION: This example demonstrates how to define scheduling requirements to deploy only in the Host where VM 5 is running, using two different forms.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_29\n\nLANGUAGE: text\nCODE:\n```\n# Deploy only in the Host where VM 5 is running. Two different forms:\nSCHED_REQUIREMENTS = \"CURRENT_VMS = 5\"\nSCHED_REQUIREMENTS = \"\\\"HOST/VMS/ID\\\" @> 5\"\n```\n\n----------------------------------------\n\nTITLE: Export Virtual Router Marketplace App using onemarketapp Command\nDESCRIPTION: This command exports the 'Service Virtual Router' marketplace application, setting the datastore to 'default' and the VM name to 'vr'. It creates an image and a VM template in OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vrouter.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ onemarketapp export 'Service Virtual Router' vr --datastore default --vmname vr\nIMAGE\n    ID: 9\nVMTEMPLATE\n    ID: 8\n```\n\n----------------------------------------\n\nTITLE: Define Virtual Machine Template in OneProvision (YAML)\nDESCRIPTION: This snippet shows the basic YAML configuration for defining a virtual machine template within a OneProvision template. It sets the name, memory, and CPU for the VM template. These are the minimum required parameters for a template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntemplates:\n  - name: \"test_template\"\n    memory: 1\n    cpu: 1\n```\n\n----------------------------------------\n\nTITLE: Creating Image from Template\nDESCRIPTION: This snippet shows how to create an OpenNebula image using a template file. The `oneimage create` command is used with the template file name and the datastore to store the image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage create ubuntu_img.one --datastore default\n```\n\n----------------------------------------\n\nTITLE: Listing VMs with Pagination (bash)\nDESCRIPTION: This snippet demonstrates how to use the ONE_POOL_PAGE_SIZE environment variable to paginate VM listing, reducing memory consumption. Setting the value to a number greater than 2 enables pagination. To disable pagination, a non-numeric value like \"disabled\" can be used.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/scalability.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nONE_POOL_PAGE_SIZE=5000 onevm list\n```\n\n----------------------------------------\n\nTITLE: Example VM Context with ONEGATE_ENDPOINT (none)\nDESCRIPTION: This snippet shows the context variables that are automatically added when a VM template with the `CONTEXT/TOKEN` attribute is instantiated. It highlights the `ONEGATE_ENDPOINT` variable, which specifies the URL for the OneGate API.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_1\n\nLANGUAGE: none\nCODE:\n```\n...\n\nCONTEXT=[\n  DISK_ID=\"1\",\n  ONEGATE_ENDPOINT=\"http://192.168.0.1:5030\",\n  TARGET=\"hdb\",\n  TOKEN=\"YES\" ]\n```\n\n----------------------------------------\n\nTITLE: Creating a user in OpenNebula using oneuser command\nDESCRIPTION: This snippet shows how to create a new user with a specified username and password using the `oneuser create` command. The command takes the username and password as arguments and returns the user ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser create <user_name> <password>\nID: 3\n```\n\n----------------------------------------\n\nTITLE: Listing Virtual Networks using OpenNebula CLI\nDESCRIPTION: This command lists the existing Virtual Networks. The output shows the Virtual Networks along with their IDs, owners, groups, names, cluster, bridge, state, and number of leases.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/self_provision.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onevnet list\nID USER       GROUP        NAME        CLUSTER    BRIDGE  STATE  LEASES\n 0 admin      oneadmin     Private     -          vbr1    rdy        10\n 7 helen      users        MyVNET      -          vbr1    rdy         0\n```\n\n----------------------------------------\n\nTITLE: Define Sunstone View Names and Descriptions with YAML\nDESCRIPTION: This YAML snippet defines the names and descriptions of each Sunstone view, which will be displayed in the Sunstone UI. The 'views' attribute allows adding readable names and descriptions to the views, where localization keys can be assigned (groups.view.admin.name) or plain texts (Custom view).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/fireedge_sunstone_views.rst#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# Name and description of each view.\n#\n# More views could be added creating a new object under views attribute.\n# Example:\n#   customview:\n#     name: Name of the custom view\n#     description: Description of the custom view\n\nviews:\n  admin:\n    name: groups.view.admin.name\n    description: groups.view.admin.description\n  cloud:\n    name: groups.view.cloud.name\n    description: groups.view.cloud.description\n  groupadmin:\n    name: groups.view.groupadmin.name\n    description: groups.view.groupadmin.description\n  user:\n    name: groups.view.user.name\n    description: groups.view.user.description\n  customview:\n    name: Custom view\n    description: Description for custom view\n```\n\n----------------------------------------\n\nTITLE: Address XML for Allocate/Free Address\nDESCRIPTION: This is the XML format of the Address data included within IPAM_DRIVER_ACTION_DATA XML when calling allocate_address and free_address. The XML contains the AR (AddressRange) object and the ADDRESS object itself. It shows the structure for passing AddressRange and Address data to allocate_address and free_address actions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-ipam.rst#_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<IPAM_DRIVER_ACTION_DATA>\n  <AR>\n    As returned by previous action, see above for examples.\n  </AR>\n  <ADDRESS>\n    <IP> Requested IP address </IP>\n    <SIZE> Number of IPs to allocate, in a continous range from the firs IP</SIZE>\n    <MAC> Optional the MAC address </MAC>\n  </ADDRESS>\n</IPAM_DRIVER_ACTION_DATA>\n```\n\n----------------------------------------\n\nTITLE: Defining CLI Environment Variables\nDESCRIPTION: This code snippet shows how to define the ONE_XMLRPC and ONEFLOW_URL environment variables. These variables are required for the CLI tools to communicate with the OpenNebula Front-end.  Replace <your subdomain> with the actual subdomain name.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_hosted.rst#_snippet_2\n\nLANGUAGE: none\nCODE:\n```\nONE_XMLRPC=http://<your subdomain>.opennebula.cloud/xmlrpc\nONEFLOW_URL=http://<your subdomain>.opennebula.cloud:2474\n```\n\n----------------------------------------\n\nTITLE: Import VMDK with VMware Tools Removal\nDESCRIPTION: This example demonstrates importing a VMDK disk and removing VMware Tools using the oneswap command. It showcases the command execution and the listing of the created image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/ova_management/import_ova.rst#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n[onepoc@nebulito ~]$ oneswap import --vmdk /home/onepoc/ovas/vm-debian125/vm-debian125-1.vmdk --datastore 101 --remove_vmtools\nConverting the Image => Converting disk /home/onepoc/ovas/vm-debian125/vm-debian125-1.vmdk to qcow2...\n        (100.00/100%)\nDisk converted successfully in 58.15 seconds.\nConverted image: /tmp/vm-debian125-1/conversions/vm-debian125-1.qcow2\n\n(...)\n\nAllocating image 0 in OpenNebula\nWaiting for image to be ready. Timeout: 120 seconds.\nCreated image: 174\nDeleting password files.\nNo such file or directory @ apply2files - /tmp/vm-debian125-1/vpassfile\n\n[onepoc@nebulito ~]$ oneimage list\nID  USER     GROUP    NAME                DATASTORE     SIZE TYPE PER STAT RVMS\n174 onepoc   oneadmin vm-debian125-1_0    NFS image       5G OS    No rdy     0\n```\n\n----------------------------------------\n\nTITLE: Custom Host Definition YAML\nDESCRIPTION: This YAML snippet demonstrates how to define custom hosts for the HCI cluster, including their `im_mad` and `vm_mad` settings, hostname, Ceph group membership (`ceph_group`), devices, dedicated devices, and Ceph monitor interface. This allows for detailed control over the configuration of each host in the cluster. The `im_mad` and `vm_mad` parameters define the Image Manager and Virtual Machine Manager drivers to use, respectively.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\nhosts:\n\n  - im_mad: \"lxc\"\n    vm_mad: \"lxc\"\n    provision:\n      hostname: \"ceph01-host.localdomain\"\n      ceph_group: \"osd,mon\"\n      devices:\n        - \"/dev/sdb\"\n        - \"/dev/sdc\"\n      dedicated_devices:\n        - \"/dev/nvme1n1\"\n      ceph_monitor_interface: \"enp4s0\"\n\n  - im_mad: \"lxc\"\n    vm_mad: \"lxc\"\n    provision:\n      hostname: \"ceph02-host.localdomain\"\n      ceph_group: \"osd,mon\"\n      devices:\n        - \"/dev/sdc\"\n      dedicated_devices:\n        - \"/dev/nvme1n1\"\n      ceph_monitor_interface: \"enp4s0\"\n\n  - im_mad: \"lxc\"\n    vm_mad: \"lxc\"\n    provision:\n      hostname: \"ceph03-host.localdomain\"\n      ceph_group: \"osd,mon\"\n      dedicated_devices:\n        - \"/dev/nvme1n1\"\n      ceph_monitor_interface: \"enp4s0\"\n\n  - im_mad: \"lxc\"\n    vm_mad: \"lxc\"\n    provision:\n      hostname: \"host04.localdomain\"\n      ceph_group: \"clients\"\n```\n\n----------------------------------------\n\nTITLE: Setting ONE_XMLRPC environment variable (code)\nDESCRIPTION: This snippet shows how to set the ONE_XMLRPC environment variable to point to the load balancer's address, allowing the CLI to connect to the OpenNebula cluster through the load balancer.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/scalability.rst#_snippet_6\n\nLANGUAGE: code\nCODE:\n```\nexport ONE_XMLRPC=http://ENDPOINT_IP:2633/RPC2\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Zones with CLI\nDESCRIPTION: This command displays a list of accessible OpenNebula Zones and indicates the currently active Zone. It uses the `onezone list` command to retrieve the Zone information. The output shows the Zone ID, name, and endpoint URL.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/usage.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onezone list\nC    ID NAME                      ENDPOINT\n*     0 OpenNebula                http://localhost:2633/RPC2\n    104 ZoneB                     http://ultron.c12g.com:2634/RPC2\n```\n\n----------------------------------------\n\nTITLE: Enabling OpenNebula Services on Boot\nDESCRIPTION: This snippet demonstrates how to enable the OpenNebula services to start automatically on server boot using systemctl. This command enables opennebula, opennebula-fireedge, opennebula-gate and opennebula-flow. Only enable the services that are correctly configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl enable opennebula opennebula-fireedge opennebula-gate opennebula-flow\n```\n\n----------------------------------------\n\nTITLE: Creating a Hook Template\nDESCRIPTION: This example shows how to create a hook template for a VM transitioning to the ``PENDING`` state. The template defines the hook's name, type, command, arguments, resource, state, and LCM state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_3\n\nLANGUAGE: ONECONF\nCODE:\n```\nNAME      = hook-vm\nTYPE      = state\nCOMMAND   = vm-pending.rb\nARGUMENTS = \"\\$TEMPLATE pending\"\nON        = CUSTOM\nRESOURCE  = VM\nSTATE     = PENDING\nLCM_STATE = LCM_INIT\n```\n\n----------------------------------------\n\nTITLE: Installing OpenSSH Server on Windows with PowerShell\nDESCRIPTION: This PowerShell command installs the OpenSSH Server capability on Windows.  It uses the Add-WindowsCapability cmdlet to install the OpenSSH server.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_9\n\nLANGUAGE: powershell\nCODE:\n```\nAdd-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0\n```\n\n----------------------------------------\n\nTITLE: Fencing Script Example\nDESCRIPTION: This code snippet shows a loop within a fencing script (`fence_host.sh`) that attempts to fence an ILO5 device. It uses the `fence_ilo5` command to power cycle the host, retrying a certain number of times with a defined sleep interval. The script uses environment variables `FENCE_IP`, `PASSWORD`, `USERNAME`, and `ACTION` to configure the fencing operation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/vm_ha.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nwhile [ \"$RETRIES\" -gt 0 ]\ndo\n    fence_ilo5 -P --ip=$FENCE_IP --password=\"${PASSWORD}\" --username=\"${USERNAME}\" --action=\"${ACTION}\" && exit 0\n    RETRIES=$((RETRIES-1))\n    sleep $SLEEP_TIME\ndone\n```\n\n----------------------------------------\n\nTITLE: Generate Full Support Bundle with OneGather in Bash\nDESCRIPTION: This command generates a complete OpenNebula support bundle including OS details, logs, configuration files, database dumps, and host information.  Use it to collect comprehensive data for complex support scenarios.  Requires root or sudo privileges to execute.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/support.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo onegather --all\n```\n\n----------------------------------------\n\nTITLE: Disable OpenNebula Host via CLI\nDESCRIPTION: This command disables a specific host in the OpenNebula deployment using the `onehost` command-line tool. The `<host_id>` placeholder should be replaced with the actual ID of the host to be disabled.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_ha.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost disable <host_id>\n```\n\n----------------------------------------\n\nTITLE: Initializing PyONE with HTTPS endpoint and disabling verification\nDESCRIPTION: This snippet shows how to connect to an OpenNebula XML-RPC endpoint using HTTPS while disabling SSL certificate verification. This is useful for test platforms with self-signed certificates.  It also requires the `ssl` library.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pyone\nimport ssl\none = pyone.OneServer(\"https://one:8443/RPC2\", session=\"oneadmin:onepass\", https_verify=False)\n```\n\n----------------------------------------\n\nTITLE: Back up OpenNebula Configuration (Bash)\nDESCRIPTION: Creates backups of OpenNebula configuration files and the remotes directory before upgrading. It also uses the `onedb` command to back up the database. The date is appended to the backup directories.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ cp -ra /etc/one /etc/one.$(date +'%Y-%m-%d')\n$ cp -ra /var/lib/one/remotes/etc /var/lib/one/remotes/etc.$(date +'%Y-%m-%d')\n$ onedb backup\n```\n\n----------------------------------------\n\nTITLE: Showing VNF VM information using the command line\nDESCRIPTION: This command shows detailed information about a specific VM, particularly the external IP address.  It requires logging into the OpenNebula Front-end node. Replace `<VNF_VM_ID>` with the actual ID of the VNF VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nonevm show -j <VNF_VM_ID>|jq -r .VM.TEMPLATE.NIC[0].EXTERNAL_IP\n```\n\n----------------------------------------\n\nTITLE: Defining CDROM Image Template in OpenNebula\nDESCRIPTION: This example shows how to define a CDROM image template in OpenNebula. It includes the image name, type, and path to the ISO file. The TYPE parameter is set to CDROM to indicate that this is a CDROM image, PATH parameter points to the location of the ISO, and NAME provides a descriptive name.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/img_template.rst#_snippet_1\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nNAME          = \"MATLAB install CD\"\nTYPE          = CDROM\nPATH          = /home/one_user/images/matlab.iso\nDESCRIPTION   = \"Contains the MATLAB installation files. Mount it to install MATLAB on new OS images.\"\n```\n\n----------------------------------------\n\nTITLE: Copying SSH private key to nodes using scp (Not Recommended)\nDESCRIPTION: This command copies the `oneadmin` user's SSH private key to the specified node using `scp`. **This approach is not recommended due to security concerns.** It's preferable to use the SSH authentication agent service. The `-p` option preserves the modification times, access times, and modes from the original file. <node1>, <node2>, <node3>, etc. should be replaced with the actual hostnames or IP addresses.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/passwordless_ssh.txt#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ scp -p /var/lib/one/.ssh/id_rsa <node1>:/var/lib/one/.ssh/\n$ scp -p /var/lib/one/.ssh/id_rsa <node2>:/var/lib/one/.ssh/\n$ scp -p /var/lib/one/.ssh/id_rsa <node3>:/var/lib/one/.ssh/\n```\n\n----------------------------------------\n\nTITLE: Example Requirement Expression for Datastore Cluster\nDESCRIPTION: This example shows how to define scheduling requirements to use any datastore that is in cluster 101.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_31\n\nLANGUAGE: text\nCODE:\n```\n# Use any datastore that is in cluster 101 (it list of cluster IDs contains 101)\nSCHED_DS_REQUIREMENTS = \"\\\"CLUSTERS/ID\\\" @> 101\"\n```\n\n----------------------------------------\n\nTITLE: Powering Off VMs in OpenNebula with Ruby\nDESCRIPTION: This code snippet demonstrates how to power off all Virtual Machines in an OpenNebula pool using the Ruby API. It initializes a client with credentials and an endpoint, retrieves the Virtual Machine pool, and then iterates through each VM to perform the poweroff action.  The script depends on the `opennebula` gem and requires a valid OpenNebula endpoint and credentials.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/ruby.rst#_snippet_1\n\nLANGUAGE: ruby\nCODE:\n```\n#!/usr/bin/env ruby\n\n############################################################################\n# Environment Configuration\n############################################################################\nONE_LOCATION = ENV['ONE_LOCATION']\n\nif !ONE_LOCATION\n    RUBY_LIB_LOCATION = '/usr/lib/one/ruby'\n    GEMS_LOCATION     = '/usr/share/one/gems'\nelse\n    RUBY_LIB_LOCATION = ONE_LOCATION + '/lib/ruby'\n    GEMS_LOCATION     = ONE_LOCATION + '/share/gems'\nend\n\nif File.directory?(GEMS_LOCATION)\n    real_gems_path = File.realpath(GEMS_LOCATION)\n    if !defined?(Gem) || Gem.path != [real_gems_path]\n        $LOAD_PATH.reject! {|l| l =~ /vendor_ruby/ }\n        require 'rubygems'\n        Gem.use_paths(real_gems_path)\n    end\nend\n\n$LOAD_PATH << RUBY_LIB_LOCATION\n\n############################################################################\n# Required libraries\n############################################################################\nrequire 'opennebula'\ninclude OpenNebula\n\n# OpenNebula credentials\nCREDENTIALS = \"oneuser:onepass\"\n\n# XML_RPC endpoint where OpenNebula is listening\nENDPOINT = \"http://localhost:2633/RPC2\"\n\nclient  = Client.new(CREDENTIALS, ENDPOINT)\nvm_pool = VirtualMachinePool.new(client, -1)\n\nrc = vm_pool.info\n\nif OpenNebula.is_error?(rc)\n     puts rc.message\n     exit(-1)\nend\n\nvm_pool.each do |vm|\n     rc = vm.poweroff\n\n     if OpenNebula.is_error?(rc)\n          puts \"Virtual Machine #{vm.id}: #{rc.message}\"\n     else\n          puts \"Virtual Machine #{vm.id}: Powering Off\"\n     end\nend\n\nexit 0\n```\n\n----------------------------------------\n\nTITLE: Install EPEL Release - RHEL 9\nDESCRIPTION: This command installs the EPEL release package on RHEL 9. EPEL provides additional packages not available in the base RHEL repositories, which are required by OpenNebula. The command downloads and installs the RPM package directly from the Fedora Project.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm\n```\n\n----------------------------------------\n\nTITLE: Delete VM Template Attribute via OneGate API\nDESCRIPTION: This curl command deletes information from the template of the current VM using the OneGate API. It uses the X-ONEGATE-TOKEN and X-ONEGATE-VMID headers for authentication and specifies the /vm endpoint with type=2.  The -d option specifies the template attribute (APP_LOAD) to be deleted.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X \"PUT\" \"${ONEGATE_ENDPOINT}/vm?type=2\" \\\n    --header \"X-ONEGATE-TOKEN: `cat token.txt`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\" \\\n    -d \"APP_LOAD\"\n```\n\n----------------------------------------\n\nTITLE: Setting Patch Mode for Specific File in OpenNebula Upgrade\nDESCRIPTION: This command sets the patch mode to 'skip' specifically for the '/etc/one/oned.conf' file during the OpenNebula upgrade process. This allows the upgrade process to continue even if there are conflicts in the specified file, while other files remain with their default patching behavior.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/conflicts.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade --patch-modes skip:/etc/one/oned.conf\n```\n\n----------------------------------------\n\nTITLE: Defining User Inputs Metadata in OpenNebula Template\nDESCRIPTION: This example demonstrates the use of USER_INPUTS_METADATA to provide titles and descriptions for user inputs, enhancing the user experience in Sunstone. The example showcases how to define metadata for APP and GROUP types to structure and describe user input sections.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_40\n\nLANGUAGE: text\nCODE:\n```\nUSER_INPUTS_METADATA=[\n  DESCRIPTION=\"This tab includes all the information about the blog section in this template.\",\n  NAME=\"BLOG\",\n  TITLE=\"Blog\",\n  TYPE=\"APP\" ]\nUSER_INPUTS_METADATA=[\n  NAME=\"MYSQL\",\n  TITLE=\"MySQL\",\n  TYPE=\"APP\" ]\nUSER_INPUTS_METADATA=[\n  DESCRIPTION=\"MySQL configuration parameters\",\n  NAME=\"CONFIG\",\n  TITLE=\"Configuration\"\n```\n\n----------------------------------------\n\nTITLE: Change Ownership of Configuration Directories\nDESCRIPTION: These commands change the ownership of the `/etc/one` and `/var/lib/one/remotes/etc` directories to the `oneadmin` user and group. This ensures that the OpenNebula processes have the necessary permissions to access the configuration files.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_ha.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ chown -R oneadmin:oneadmin /etc/one\n$ chown -R oneadmin:oneadmin /var/lib/one/remotes/etc\n```\n\n----------------------------------------\n\nTITLE: Perform Action on Service with curl\nDESCRIPTION: This snippet demonstrates how to perform an action on a specific OpenNebula service using the curl command. It changes the group ownership of the service with the specified ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service/5/action -u 'oneadmin:password' -v -X POST --data '{\n  \"action\": {\n    \"perform\":\"chgrp\",\n    \"params\" : {\n      \"group_id\" : 2\n    }\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: downloader.sh Command Example\nDESCRIPTION: This snippet showcases an example of the downloader.sh command being used within the import script. It pipes the content from the IMPORT_SOURCE (specified by $IMPORT_SOURCE) to standard output, which is then directed to the target destination within the Marketplace.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-market.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n${UTILS_PATH}/downloader.sh $IMPORT_SOURCE -\n```\n\n----------------------------------------\n\nTITLE: Updating Service Template using CLI (file) in Bash\nDESCRIPTION: Updates an existing Service Template by applying changes from a file. The command `oneflow-template update <ID> <file>` merges the contents of the specified file with the template. <ID> represents the service template ID, and <file> specifies the path to the file containing the updates.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\noneflow-template update <ID> <file>\n```\n\n----------------------------------------\n\nTITLE: Checking OneGate Server Connectivity with OneGate CLI in Bash\nDESCRIPTION: This command checks the connectivity between a VNF node and the OneGate server on the Front-end node. It uses the `onegate vm show` command. A successful response displays VM information; a failure typically indicates a timeout and reveals a connectivity issue.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nonegate vm show\n```\n\n----------------------------------------\n\nTITLE: Showing Hook Information Using the CLI\nDESCRIPTION: This example shows how to retrieve detailed information about a specific hook using the ``onehook show`` command. It retrieves the hook's ID, name, type, template, and execution log.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm create --cpu 1 --memory 2 --name test\n  ID: 0\n$ onehook show 0\n  HOOK 0 INFORMATION\n  ID                : 0\n  NAME              : hook-vm\n  TYPE              : state\n  LOCK              : None\n\n  HOOK TEMPLATE\n  ARGUMENTS=\"$TEMPLATE pending\"\n  COMMAND=\"vm-pending.rb\"\n  LCM_STATE=\"LCM_INIT\"\n  REMOTE=\"NO\"\n  RESOURCE=\"VM\"\n  STATE=\"PENDING\"\n\n  EXECUTION LOG\n    ID    TIMESTAMP    EXECUTION\n    0     09/23 15:10  ERROR (255)\n```\n\n----------------------------------------\n\nTITLE: Removing a Role from a Running Service Using OneFlow CLI\nDESCRIPTION: This command demonstrates how to remove a role from a running service using the OneFlow command-line interface. The `oneflow remove-role` command takes the service ID and the role name as arguments.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n$ oneflow remove-role 0 MASTER\n```\n\n----------------------------------------\n\nTITLE: Creating a Temporary Directory and Metrics File (Bash)\nDESCRIPTION: This snippet creates a temporary directory using `mktemp -d` and an empty file named `metrics` inside it. The temporary directory will be used to store intermediate results and the final metrics before sending them to the monitoring endpoint.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nTMP_DIR=`mktemp -d`\necho \"\" > $TMP_DIR/metrics\n```\n\n----------------------------------------\n\nTITLE: Showing Edge Cluster Details\nDESCRIPTION: This snippet shows how to display detailed information about a specific provision using the `oneprovision show` command. It requires a valid provision ID as input and outputs various details, including the provision's ID, name, state, provider, and associated infrastructure resources (clusters, datastores, hosts, networks) and resource resources (VNTemplates).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/cluster_operations.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision show 0\nPROVISION 0 INFORMATION\nID        : 0\nNAME      : aws-cluster\nSTATE     : RUNNING\nPROVIDER  : aws\n\nProvision Infrastructure Resources\n\nCLUSTERS\n100: aws-cluster\n\nDATASTORES\n100: aws-cluster-image\n101: aws-cluster-system\n\nHOSTS\n0: 54.166.142.123\n1: 34.234.201.245\n\nNETWORKS\n0: aws-cluster-public\n\nProvision Resource Resources\n\nVNTEMPLATES\n0: aws-cluster-private\n```\n\n----------------------------------------\n\nTITLE: Display VM Information using onevm show - Bash\nDESCRIPTION: This snippet shows how to use the `onevm show` command to retrieve detailed information about a specific Virtual Machine in OpenNebula.  The output includes the VM's ID, name, state, monitoring data, template, error messages, and history. This is a key command for diagnosing VM failures.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm show 0\nVIRTUAL MACHINE 0 INFORMATION\nID                  : 0\nNAME                : one-0\nUSER                : oneadmin\nGROUP               : oneadmin\nSTATE               : ACTIVE\nLCM_STATE           : PROLOG_FAILED\nSTART TIME          : 07/19 17:44:20\nEND TIME            : 07/19 17:44:31\nDEPLOY ID           : -\n\nVIRTUAL MACHINE MONITORING\nNET_TX              : 0\nNET_RX              : 0\nUSED MEMORY         : 0\nUSED CPU            : 0\n\nVIRTUAL MACHINE TEMPLATE\nCONTEXT=[\n  FILES=/tmp/some_file,\n  TARGET=hdb ]\nCPU=0.1\nERROR=[\n  MESSAGE=\"Error executing image transfer script: Error copying /tmp/some_file to /var/lib/one/0/images/isofiles\",\n  TIMESTAMP=\"Tue Jul 19 17:44:31 2011\" ]\nMEMORY=64\nNAME=one-0\nVMID=0\n\nVIRTUAL MACHINE HISTORY\n SEQ        HOSTNAME ACTION           START        TIME       PTIME\n   0          host01   none  07/19 17:44:31 00 00:00:00 00 00:00:00\n```\n\n----------------------------------------\n\nTITLE: Defining OpenNebula VM Role Schema in JSON\nDESCRIPTION: This JSON schema defines the structure for an OpenNebula VM Role, specifying required and optional properties such as name, type, cardinality, template ID, template contents, user inputs, parents, shutdown action, and scaling policies. It utilizes JSON schema constructs to define data types, constraints, and validation rules for each property. The expected output is a validated VM Role configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_3\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  :type => :object,\n  :properties => {\n      'name' => {\n          :type => :string,\n          :required => true,\n          :regex => /^\\w+$/\n      },\n      'type' => {\n          :type => :string,\n          :required => true\n      },\n      'cardinality' => {\n          :type => :integer,\n          :default => 0,\n          :minimum => 0\n      },\n      'template_id' => {\n          :type => :integer,\n          :required => true\n      },\n      'template_contents' => {\n          :type => :object,\n          :properties => {},\n          :required => false\n      },\n      'user_inputs' => {\n          :type => :object,\n          :properties => {},\n          :required => false\n      },\n      'user_inputs_values' => {\n          :type => :object,\n          :properties => {},\n          :required => false\n      },\n      'parents' => {\n          :type => :array,\n          :items => {\n              :type => :string\n          }\n      },\n      'shutdown_action' => {\n          :type => :string,\n          :required => false\n      },\n      'min_vms' => {\n          :type => :integer,\n          :required => false,\n          :minimum => 0\n      },\n      'max_vms' => {\n          :type => :integer,\n          :required => false,\n          :minimum => 0\n      },\n      'cooldown' => {\n          :type => :integer,\n          :required => false,\n          :minimum => 0\n      },\n      'on_hold' => {\n          :type => :boolean,\n          :required => false\n      },\n      'elasticity_policies' => {\n          :type => :array,\n          :items => {\n              :type => :object,\n              :properties => {\n                  'type' => {\n                      :type => :string,\n                      :required => true\n                  },\n                  'adjust' => {\n                      :type => :integer,\n                      :required => true\n                  },\n                  'min_adjust_step' => {\n                      :type => :integer,\n                      :required => false,\n                      :minimum => 1\n                  },\n                  'period_number' => {\n                      :type => :integer,\n                      :required => false,\n                      :minimum => 0\n                  },\n                  'period' => {\n                      :type => :integer,\n                      :required => false,\n                      :minimum => 0\n                  },\n                  'expression' => {\n                      :type => :string,\n                      :required => true\n                  },\n                  'cooldown' => {\n                      :type => :integer,\n                      :required => false,\n                      :minimum => 0\n                  }\n              }\n          }\n      },\n      'scheduled_policies' => {\n          :type => :array,\n          :items => {\n              :type => :object,\n              :properties => {\n                  'type' => {\n                      :type => :string,\n                      :required => true\n                  },\n                  'adjust' => {\n                      :type => :integer,\n                      :required => true\n                  },\n                  'min_adjust_step' => {\n                      :type => :integer,\n                      :required => false,\n                      :minimum => 1\n                  },\n                  'start_time' => {\n                      :type => :string,\n                      :required => false\n                  },\n                  'recurrence' => {\n                      :type => :string,\n                      :required => false\n                  }\n              }\n          }\n      }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating User with Private SSH Key\nDESCRIPTION: This command creates a new OpenNebula user, using the user's private key directly. This requires the administrator to have access to the user's private key, specified using the `--key` option along with the `--ssh` flag for SSH authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ssh.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\noneuser create johndoe --ssh --key /home/newuser/.ssh/id_rsa\n```\n\n----------------------------------------\n\nTITLE: Defining NIC with NETWORK and NETWORK_UID in OpenNebula\nDESCRIPTION: This snippet shows how to define a NIC using the NETWORK name and NETWORK_UID attributes. NETWORK specifies the name of the virtual network and NETWORK_UID specifies the unique identifier of the network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_13\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nNIC = [ NETWORK     = \"Blue\",\n            NETWORK_UID = 0 ]\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Daemon Log Error Example\nDESCRIPTION: This code snippet demonstrates an error message found in the OpenNebula daemon log, indicating a failure to resolve the hostname of a host. This helps in identifying network configuration issues.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_9\n\nLANGUAGE: none\nCODE:\n```\nTue Jul 19 17:17:22 2011 [InM][I]: Monitoring host host01 (1)\nTue Jul 19 17:17:22 2011 [InM][I]: Command execution fail: scp -r /var/lib/one/remotes/. host01:/var/tmp/one\nTue Jul 19 17:17:22 2011 [InM][I]: ssh: Could not resolve hostname host01: nodename nor servname provided, or not known\nTue Jul 19 17:17:22 2011 [InM][I]: lost connection\nTue Jul 19 17:17:22 2011 [InM][I]: ExitCode: 1\nTue Jul 19 17:17:22 2011 [InM][E]: Error monitoring host 1 : MONITOR FAILURE 1 Could not update remotes\n```\n\n----------------------------------------\n\nTITLE: System Datastore Template Configuration for LVM\nDESCRIPTION: This configuration defines the parameters for creating a new SAN/LVM System Datastore. It sets the TM_MAD to fs_lvm_ssh, the TYPE to SYSTEM_DS, and specifies the BRIDGE_LIST.  It also sets the DISK_TYPE to BLOCK, which is used for volatile disks.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/lvm_drivers.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nNAME   = lvm_system\nTM_MAD = fs_lvm_ssh\nTYPE   = SYSTEM_DS\nBRIDGE_LIST = \"node1.kvm.lvm node2.kvm.lvm\"\nDISK_TYPE = BLOCK\n```\n\n----------------------------------------\n\nTITLE: Perform Action on Role VMs with curl\nDESCRIPTION: This snippet shows how to perform an action on all VMs within a specific role of an OpenNebula service. It uses the 'stop' action with parameters to control the frequency and number of VMs affected.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service/5/role/frontend/action -u 'oneadmin:password' -v -X POST --data '{\n  \"action\": {\n    \"perform\":\"stop\",\n    \"params\" : {\n      \"period\" : 60,\n      \"number\" : 2\n    }\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Example Placement Section in OpenNebula VM Template\nDESCRIPTION: Presents an example of a placement section within an OpenNebula VM template. This snippet shows how to define scheduling requirements and ranking using attributes such as CPUSPEED, FREE_CPU, NAME, and FREE_MB.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_26\n\nLANGUAGE: text\nCODE:\n```\nSCHED_REQUIREMENTS    = \"CPUSPEED > 1000\"\nSCHED_RANK            = \"FREE_CPU\"\nSCHED_DS_REQUIREMENTS = \"NAME=GoldenCephDS\"\nSCHED_DS_RANK         = FREE_MB\n```\n\n----------------------------------------\n\nTITLE: Nginx Configuration for TLS Proxy (nginx)\nDESCRIPTION: This snippet shows an example Nginx configuration file for setting up a TLS proxy for OneGate. It includes configurations for listening on port 80 and redirecting to HTTPS, listening on port 443 with SSL/TLS, and proxying requests to the OneGate service running on localhost:5030.  The `ONEGATE_ENDPOINT` variable should be replaced with your own domain.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_8\n\nLANGUAGE: nginx\nCODE:\n```\nserver {\n  listen 80;\n  return 301 https://$host$request_uri;\n}\n\nserver {\n  listen 443;\n  server_name ONEGATE_ENDPOINT;\n\n  ssl_certificate           /etc/one/cert.crt;\n  ssl_certificate_key       /etc/one/cert.key;\n\n  ssl on;\n  ssl_session_cache  builtin:1000  shared:SSL:10m;\n  ssl_protocols  TLSv1 TLSv1.1 TLSv1.2;\n  ssl_ciphers HIGH:!aNULL:!eNULL:!EXPORT:!CAMELLIA:!DES:!MD5:!PSK:!RC4;\n  ssl_prefer_server_ciphers on;\n\n  access_log            /var/log/nginx/onegate.access.log;\n\n  location / {\n\n    proxy_set_header        Host $host;\n    proxy_set_header        X-Real-IP $remote_addr;\n    proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header        X-Forwarded-Proto $scheme;\n\n    # Fix the â€œIt appears that your reverse proxy set up is broken\" error.\n    proxy_pass          http://localhost:5030;\n    proxy_read_timeout  90;\n\n    proxy_redirect      http://localhost:5030 https://ONEGATE_ENDPOINT;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sunstone View Directory Structure\nDESCRIPTION: This shows the directory structure for defining Sunstone views. Each view (admin, user, groupadmin) has its own directory under `/etc/one/fireedge/sunstone`, and each tab within that view is defined by a YAML file. The names of the YAML files determines which tabs are enabled in the view.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/fireedge_sunstone_views.rst#_snippet_2\n\nLANGUAGE: code\nCODE:\n```\n/etc/one/fireedge/sunstone\n|-- admin/\n|   |-- acl-tab.yaml                   <--- Enable ACL tab and define its actions\n|   |-- backupjobs-tab.yaml            <--- Enable Backup jobs tab and define its actions\n|   |-- backup-tab.yaml                <--- Enable Backup tab and define its actions\n|   |-- cluster-tab.yaml               <--- Enable Cluster tab and define its actions\n|   |-- datastore-tab.yaml             <--- Enable Datastore tab and define its actions\n|   |-- file-tab.yaml                  <--- Enable Files tab and define its actions\n|   |-- group-tab.yaml                 <--- Enable Groups tab and define its actions\n|   |-- host-tab.yaml                  <--- Enable Host tab and define its actions\n|   |-- image-tab.yaml                 <--- Enable Images tab and define its actions\n|   |-- marketplace-app-tab.yaml       <--- Enable Apps tab and define its actions\n|   |-- marketplace-tab.yaml           <--- Enable Marketplace tab and define its actions\n|   |-- sec-group-tab.yaml             <--- Enable Security groups tab and define its actions\n|   |-- service-tab.yaml               <--- Enable Service tab and define its actions\n|   |-- service-template-tab.yaml      <--- Enable Service template tab and define its actions\n|   |-- support-tab.yaml               <--- Enable Support tab and define its actions\n|   |-- user-tab.yaml                  <--- Enable User tab and define its actions\n|   |-- vdc-tab.yaml                   <--- Enable VDC tab and define its actions\n|   |-- vm-group-tab.yaml              <--- Enable Virtual Machine groups tab and define its actions\n|   |-- vm-tab-tab.yaml                <--- Enable Virtual Machine tab and define its actions\n|   |-- vm-template-tab.yaml           <--- Enable Virtual Machine templates tab and define its actions\n|   |-- vnet-tab.yaml                  <--- Enable Virtual Networks tab and define its actions\n|   |-- vnet-template-tab.yaml         <--- Enable Virtual Networks templates tab and define its actions\n|   |-- vrouter-tab.yaml               <--- Enable Virtual Router tab and define its actions\n|   |-- vrouter-template-tab.yaml      <--- Enable Virtual Router template tab and define its actions\n|   |-- zone-tab.yaml                  <--- Enable Zone tab and define its actions    \n|-- user/\n|   |-- backup-tab.yaml                <--- Enable Backup tab and define its actions\n|   |-- file-tab.yaml                  <--- Enable Files tab and define its actions\n|   |-- image-tab.yaml                 <--- Enable Images tab and define its actions\n|   |-- marketplace-app-tab.yaml       <--- Enable Apps tab and define its actions\n|   |-- sec-group-tab.yaml             <--- Enable Security groups tab and define its actions\n|   |-- vm-tab-tab.yaml                <--- Enable Virtual Machine tab and define its actions\n|   |-- vm-template-tab.yaml           <--- Enable Virtual Machine templates tab and define its actions\n|   |-- vnet-tab.yaml                  <--- Enable Virtual Networks tab and define its actions\n|-- groupadmin/\n|   |-- backup-tab.yaml                <--- Enable Backup tab and define its actions\n```\n\n----------------------------------------\n\nTITLE: OS Boot Configuration Example\nDESCRIPTION: This snippet shows an example of configuring the OS boot parameters in an OpenNebula VM template. It specifies the kernel, initrd, root device, and kernel command-line arguments to boot the VM from a local filesystem.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nOS = [ KERNEL     = /vmlinuz,\n           INITRD     = /initrd.img,\n           ROOT       = sda1,\n           KERNEL_CMD = \"ro console=tty1\"]\n```\n\n----------------------------------------\n\nTITLE: Export Marketplace App in OneProvision (YAML)\nDESCRIPTION: This snippet shows how to export a marketplace app into an image using OneProvision's YAML configuration. It defines the appid (Marketplace App ID), name, and dsid (Datastore ID).  Instead of `appid`, `appname` can be used.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nmarketplaceapps:\n  - appid: 238\n    name: \"test_image_2\"\n    dsid: 1\n```\n\n----------------------------------------\n\nTITLE: Using Image Template Variables in OpenNebula VM Template\nDESCRIPTION: Shows how to use an Image template variable (ROOT_PASS) from a specific image (IMAGE_ID=0) within an OpenNebula VM template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_23\n\nLANGUAGE: text\nCODE:\n```\nroot = \"$IMAGE[ROOT_PASS, IMAGE_ID=0]\"\n```\n\n----------------------------------------\n\nTITLE: Obtaining Certificate Hash with OpenSSL\nDESCRIPTION: This snippet demonstrates how to obtain the hash of a certificate using the `openssl` command.  This hash is used for naming the certificate file in the trusted certificates directory specified by `ONE_CERT_DIR` when OpenNebula's XML-RPC endpoint is behind an SSL proxy.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/cli.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ openssl x509 -in <certificate.pem> -hash\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Datastore Directory Structure Example\nDESCRIPTION: This example illustrates the typical directory structure for datastores in OpenNebula. It shows the organization of image files in the image datastore (ID 1) and VM disks/checkpoints in the system datastore (ID 0). It assumes VMs 0 and 2 are running, and VM 7 is stopped, therefore its directory exists but only contains stored data.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/internals_fs_common.txt#_snippet_0\n\nLANGUAGE: None\nCODE:\n```\n/var/lib/one/datastores\n|-- 0/\n|   |-- 0/\n|   |   |-- disk.0\n|   |   `-- disk.1\n|   |-- 2/\n|   |   `-- disk.0\n|   `-- 7/\n|       |-- checkpoint\n|       `-- disk.0\n`-- 1\n    |-- 05a38ae85311b9dbb4eb15a2010f11ce\n    |-- 2bbec245b382fd833be35b0b0683ed09\n    `-- d0e0df1fb8cfa88311ea54dfbcfc4b0c\n```\n\n----------------------------------------\n\nTITLE: Set Filesystem Permissions for FireEdge - Bash\nDESCRIPTION: This snippet sets the necessary filesystem permissions for FireEdge to function correctly, ensuring that the FireEdge configuration and credentials can be accessed by the user running the FireEdge server. It grants execute permissions to specific directories under `/var/lib/one`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/fireedge_for_large_deployments.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# chmod a+x /var\n# chmod a+x /var/lib\n# chmod a+x /var/lib/one\n# chmod a+x /var/lib/one/.one\n```\n\n----------------------------------------\n\nTITLE: Updating Resource Name in YAML Configuration (YAML)\nDESCRIPTION: This YAML configuration updates the resource name in the view configuration file. The `resource_name` property should match the path of the component, in uppercase.  This links the view to the appropriate UI component.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_27\n\nLANGUAGE: yaml\nCODE:\n```\nresource_name: \"USERSGROUPS\"\n```\n\n----------------------------------------\n\nTITLE: Verify cgroup controller delegation (bash)\nDESCRIPTION: This snippet demonstrates how to verify that the CPU and IO cgroup controllers have been successfully delegated to the `oneadmin` user. It checks the `cgroup.controllers` file within the user's slice to confirm the delegation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/io_limit.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncat /sys/fs/cgroup/user.slice/user-9869.slice/cgroup.controllers\ncpuset cpu io memory pids\n```\n\n----------------------------------------\n\nTITLE: Cloning OpenNebula Image\nDESCRIPTION: Clones an existing OpenNebula image to create a new one. This snippet shows how to use the `oneimage clone` command to create a copy of the 'Ubuntu' image named 'new_image'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage clone Ubuntu new_image\n```\n\n----------------------------------------\n\nTITLE: upgrade with no updates available\nDESCRIPTION: This example demonstrates the output when running `onecfg upgrade` and there are no updates available for the configuration.  The command executes and then reports that no updates were found, indicating that the system is already running the latest configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade\n```\n\n----------------------------------------\n\nTITLE: Enabling OpenNebula AlertManager Service - Bash\nDESCRIPTION: This command enables and starts the OpenNebula AlertManager service using systemctl. It ensures that the service is automatically started on boot and is running immediately.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/alerts.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl enable --now opennebula-alertmanager.service\n```\n\n----------------------------------------\n\nTITLE: Generating SSH Key Pair\nDESCRIPTION: This command generates an SSH key pair. The private key is stored in `~/.ssh/one`, and the public key is stored in `~/.ssh/one.pub`. The `-f` option specifies the filename for the key.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/shared/ssh.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nssh-keygen -f ~/.ssh/one\n```\n\n----------------------------------------\n\nTITLE: Set qcow2 cache mode to writethrough in KVM\nDESCRIPTION: This snippet shows how to set the cache mode to 'writethrough' for qcow2 storage drivers in KVM. This ensures data is written to disk during snapshots, providing better data safety but potentially slower write performance. It requires editing the vmm_exec_kvm.conf file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/release_notes/platform_notes.rst#_snippet_0\n\nLANGUAGE: conf\nCODE:\n```\nDISK = [ driver = \"qcow2\", cache = \"writethrough\" ]\n```\n\n----------------------------------------\n\nTITLE: Checking OpenNebula Federation Status with onezone\nDESCRIPTION: This command checks the federation status to ensure all zones are in sync and at the same index (FED_INDEX). It's executed on the command line using the `onezone list` command. Output shows zone ID, Name, Endpoint and FED_INDEX.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_federation.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nonezone list\n```\n\n----------------------------------------\n\nTITLE: KVM VMM Driver Configuration\nDESCRIPTION: This code snippet shows the KVM VMM driver configuration in /etc/one/oned.conf. It specifies the executable, arguments, default configuration file, and type for the KVM driver. The important part is the '-p' argument which allows multiple actions to be executed per host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_15\n\nLANGUAGE: code\nCODE:\n```\nVM_MAD = [\n    NAME       = \"kvm\",\n    EXECUTABLE = \"one_vmm_exec\",\n    ARGUMENTS  = \"-t 15 -r 0 kvm -p\",\n    DEFAULT    = \"vmm_exec/vmm_exec_kvm.conf\",\n    TYPE       = \"kvm\" ]\n```\n\n----------------------------------------\n\nTITLE: Checking OpenNebula Daemon Connectivity with oneuser\nDESCRIPTION: This command attempts to show the 'oneadmin' user to verify that the OpenNebula Daemon is running and accessible. If the daemon is not running, the command will fail and return an error message indicating a connection refusal to localhost on port 2633.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser show\n```\n\n----------------------------------------\n\nTITLE: Defining VR Role Schema in JSON\nDESCRIPTION: This JSON schema defines the structure for a VR (Virtual Router) Role, specifying properties such as name and type. This schema can be extended to include other properties relevant for VR configuration in OpenNebula. The code snippet provided is a basic representation of the VR Role schema.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_4\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  :type => :object,\n  :properties => {\n      'name' => {\n          :type => :string,\n          :required => true,\n          :regex => /^\\w+$/\n      },\n      'type' => {\n          :type => :string,\n\n```\n\n----------------------------------------\n\nTITLE: Dialog Configuration (YAML)\nDESCRIPTION: This YAML configuration snippet demonstrates how to define the structure for dialogs used in resource actions within the OpenNebula Sunstone interface.  It specifies which steps are required or enabled for various operations, such as creating or modifying VM templates.  The 'not_on' field allows disabling specific steps or sections based on the hypervisor.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_35\n\nLANGUAGE: yaml\nCODE:\n```\n# etc/sunstone/admin/vm-template-tab.yaml\n# ** Required means that it's necessary for the operation of the form\ndialogs:\n  information: true\n  ownership: true\n  capacity: true\n  vm_group: true\n  network: true\n  storage: true\n  placement: true\n  sched_action: true\n  booting: true\n  backup: true\ncreate_dialog:\n  ownership: true\n  capacity: true\n  showback: true\n  vm_group: true\n  network: true\n  storage: true\n  placement: true\n  pci: true\n  input_output: true\n  sched_action: true\n  context: true\n  booting: true\n  numa:\n    enabled: true\n    not_on:\n      - lxc\n  backup: true\n```\n\n----------------------------------------\n\nTITLE: Adding User Inputs to Service Template (JSON)\nDESCRIPTION: This JSON snippet demonstrates how to add User Inputs to a Service template.  User Inputs allow you to prompt the user for attributes and values during instantiation time. The snippet defines attributes ATT_A, ATT_B and ATT_C with various constraints like fixed values, list selection, and range selection, respectively.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"Sample Service\",\n  \"description\": \"Overwriting original template example\",\n  \"deployment\": \"straight\",\n  \"roles\": [\n    {\n      \"name\": \"master\",\n      \"type\": \"vm\",\n      \"template_id\": 0,\n      \"cardinality\": 1\n    },\n    {\n      \"name\": \"worker\",\n      \"type\": \"vm\",\n      \"template_id\": 1,\n      \"cardinality\": 2,\n      \"template_contents\": {\n        \"CPU\": 2,\n        \"MY_ATT\": \"Some fancy value\"\n      }\n    }\n  ],\n  \"user_inputs\": {\n    \"ATT_A\": \"O|fixed|| |2\",\n    \"ATT_B\": \"M|list||0.5,1,2,4|1\",\n    \"ATT_C\": \"M|range||512..8192|2048\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring VNC Graphics in VM Template\nDESCRIPTION: This code block shows how to configure VNC graphics settings within a VM template. It sets the LISTEN attribute to \"0.0.0.0\" to allow connections from any IP address and sets the TYPE to \"vnc\".\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_43\n\nLANGUAGE: none\nCODE:\n```\nGRAPHICS=[\n    LISTEN=\"0.0.0.0\",\n    TYPE=\"vnc\"\n]\n```\n\n----------------------------------------\n\nTITLE: Collecting Memory Metrics (Bash)\nDESCRIPTION: This snippet collects memory metrics (total, free, and used memory and swap) from `/proc/meminfo` using `grep` and `awk`. It calculates the percentage of used memory and swap and writes these percentages to the `$TMP_DIR/metrics` file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nMEM_TOTAL=`grep MemTotal: /proc/meminfo | awk '{print $2}'`\nMEM_FREE=`grep MemFree: /proc/meminfo | awk '{print $2}'`\nMEM_USED=$(($MEM_TOTAL-$MEM_FREE))\n\nMEM_USED_PERC=\"0\"\n\nif ! [ -z $MEM_TOTAL ] && [ $MEM_TOTAL -gt 0 ]; then\n    MEM_USED_PERC=`echo \"$MEM_USED $MEM_TOTAL\" | \\\n        awk '{ printf \"%.2f\", 100 * $1 / $2 }'`\nfi\n\nSWAP_TOTAL=`grep SwapTotal: /proc/meminfo | awk '{print $2}'`\nSWAP_FREE=`grep SwapFree: /proc/meminfo | awk '{print $2}'`\nSWAP_USED=$(($SWAP_TOTAL - $SWAP_FREE))\n\nSWAP_USED_PERC=\"0\"\n\nif ! [ -z $SWAP_TOTAL ] && [ $SWAP_TOTAL -gt 0 ]; then\n    SWAP_USED_PERC=`echo \"$SWAP_USED $SWAP_TOTAL\" | \\\n        awk '{ printf \"%.2f\", 100 * $1 / $2 }'`\nfi\n\necho \"MEM_USED_PERC = $MEM_USED_PERC\" >> $TMP_DIR/metrics\necho \"SWAP_USED_PERC = $SWAP_USED_PERC\" >> $TMP_DIR/metrics\n```\n\n----------------------------------------\n\nTITLE: Backup Datastore ls RETURNS JSON Example\nDESCRIPTION: This JSON snippet demonstrates the structure of the data returned by the `ls` action of a backup datastore driver. It provides downloader URLs for each disk in the backup.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"0\": \"rsync://102//0:0e6658/var/lib/one/datastores/102/21/0e6658/disk.0.0\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Hook Using the CLI\nDESCRIPTION: This example demonstrates how to create a hook using the ``onehook create`` command and a hook template file.  It assumes a template file named ``hook.tmpl`` exists with the hook definition.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onehook create hook.tmpl\n  ID: 0\n```\n\n----------------------------------------\n\nTITLE: Display Prometheus Configuration\nDESCRIPTION: Displays the contents of the generated Prometheus configuration file (`/etc/one/prometheus/prometheus.yml`).  This file defines scrape configurations for Prometheus to collect metrics from various exporters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# cat /etc/one/prometheus/prometheus.yml\n\n---\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets:\n      - 127.0.0.1:9093\n\nrule_files:\n- rules.yml\n\nscrape_configs:\n- job_name: prometheus\n  static_configs:\n  - targets:\n    - 127.0.0.1:9090\n- job_name: opennebula_exporter\n  static_configs:\n  - targets:\n    - 127.0.0.1:9925\n- job_name: node_exporter\n  static_configs:\n  - targets:\n    - 127.0.0.1:9100\n  - targets:\n    - kvm-local-uimw3-2.test:9100\n    labels:\n      one_host_id: '1'\n  - targets:\n    - kvm-local-uimw3-1.test:9100\n    labels:\n      one_host_id: '0'\n- job_name: libvirt_exporter\n  static_configs:\n  - targets:\n    - kvm-local-uimw3-2.test:9926\n    labels:\n      one_host_id: '1'\n  - targets:\n    - kvm-local-uimw3-1.test:9926\n    labels:\n      one_host_id: '0'\n```\n\n----------------------------------------\n\nTITLE: Setting Patch Mode for Specific File and Version in OpenNebula Upgrade\nDESCRIPTION: This command sets the patch mode to 'skip' for the '/etc/one/oned.conf' file only when upgrading to version 5.6.0. This allows the upgrade to proceed, ignoring problematic areas in the file for the specific version while other versions are patched differently.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/conflicts.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade --patch-modes skip:/etc/one/oned.conf:5.6.0\n```\n\n----------------------------------------\n\nTITLE: Release a Service\nDESCRIPTION: This command releases a service that has roles in a 'HOLD' state.  It takes the service ID as an argument and transitions the roles to their intended operational state. This command is part of the OneFlow CLI tool.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\n$ oneflow release <SERVICE_ID>\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Enterprise Repository on Debian 12\nDESCRIPTION: This bash script adds the OpenNebula Enterprise Edition repository to the Debian 12 system. It creates a `/etc/apt/sources.list.d/opennebula.list` file with the repository configuration, including the base URL (which requires a customer-specific token) and specifies the GPG key file. The script then updates the apt package list.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# echo \\\"deb [signed-by=/etc/apt/keyrings/opennebula.gpg] https://<token>@enterprise.opennebula.io/repo/|version|/Debian/12 stable opennebula\\\" > /etc/apt/sources.list.d/opennebula.list\n# apt-get update\n```\n\n----------------------------------------\n\nTITLE: Filtering accounting records by date range\nDESCRIPTION: This snippet demonstrates how to filter accounting records within a specific date range using the `-s` (start time) and `-e` (end time) options.  This is useful for analyzing resource consumption during a particular period.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/accounting.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n$ oneacct -s 05/01 -e 06/01\nShowing active history records from 2016-05-01 00:00:00 +0200 to 2016-06-02 00:00:00 +0200\n\n# User 0\n\n VID HOSTNAME        ACTION           REAS     START_TIME       END_TIME MEMORY CPU  NETRX  NETTX   DISK\n  28 host01          terminate        user 05/27 16:40:47 05/27 17:09:20  1024M 0.1     0K     0K  10.4G\n  29 host02          none             none 05/27 17:09:28              -   256M   1   2.4M   1.3K    10G\n```\n\n----------------------------------------\n\nTITLE: AddressRange XML Example for IPAM Driver Actions\nDESCRIPTION: This XML snippet represents the structure of the AddressRange data passed to IPAM driver actions via STDIN. It includes attributes such as IP type, first IP, MAC address, size, network details, gateway, DNS, MTU, and search domain.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-ipam.rst#_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<IPAM_DRIVER_ACTION_DATA>\n  <AR>\n    <TYPE>IP4</TYPE>\n    <IP> First IP in the network in '.' notation </IP>\n    <MAC> First MAC in the network in ':' notation </MAC\n    <SIZE>Number of IPs in the network </SIZE>\n    <NETWORK_ADDRESS> Base network address</NETWORK_ADDRESS>\n    <NETWORK_MASK> Network mask</NETWORK_MASK>\n    <GATEWAY> Default gateway for the network</GATEWAY>\n    <DNS> DNS servers, a space separated list of servers</DNS>\n    <GUEST_MTU> Sets the MTU for the NICs in this network</GUEST_MTU>\n    <SEARCH_DOMAIN> for DNS client</SEARCH_DOMAIN>\n  </AR>\n</IPAM_DRIVER_ACTION_DATA>\n```\n\n----------------------------------------\n\nTITLE: Updating Tab Manifest (JSON)\nDESCRIPTION: This JSON configuration updates the tab manifest for FireEdge, adding a new tab and associating it with a specific module and component. The `moduleId` property specifies which module to load the component from.  The `Component` property references the react component to be loaded.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_25\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"title\": \"System\",\n    \"icon\": \"Home\",\n    \"routes\": [\n        {\n            \"title\": \"Create User\",\n            \"path\": \"/user/create\",\n            \"Component\": \"CreateUser\"\n        },\n        {\n            \"title\": \"Users and Groups\",\n            \"path\": \"/usersgroups\",\n            \"sidebar\": true,\n            \"icon\": \"User\",\n            \"moduleId\": \"CustomContainersModule\", // We explicitly define which module to load the component from\n            \"Component\": \"UsersAndGroups\"\n        },\n        // Other tabs and definitions\n     ]\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Port Configuration for QinQ Network (Bash)\nDESCRIPTION: This bash command and its output demonstrate how to check the port configuration for a QinQ network in Open vSwitch using ovs-vsctl. It showcases the cvlans, qinq-ethtype, and other relevant parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n# ovs-vsctl list Port one-5-1\n\n_uuid               : 791b84a9-2705-4cf9-94b4-43b39b98fe62\nbond_active_slave   : []\nbond_downdelay      : 0\nbond_fake_iface     : false\nbond_mode           : []\nbond_updelay        : 0\ncvlans              : [101, 103, 110, 111, 112, 113]\nexternal_ids        : {}\nfake_bridge         : false\ninterfaces          : [6da7ff07-51ec-40e9-97cd-c74a36e2c267]\nlacp                : []\nmac                 : []\nname                : one-5-1\nother_config        : {qinq-ethtype=\"802.1q\"}\nprotected           : false\nqos                 : []\nrstp_statistics     : {}\nrstp_status         : {}\nstatistics          : {}\nstatus              : {}\ntag                 : 100\ntrunks              : []\nvlan_mode           : dot1q-tunnel\n```\n\n----------------------------------------\n\nTITLE: Printing SSH Public Key\nDESCRIPTION: This command prints the content of the SSH public key file, which is located at `~/.ssh/one.pub`. The `cat` command is used to display the file content to the console.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/shared/ssh.txt#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncat ~/.ssh/one.pub\n```\n\n----------------------------------------\n\nTITLE: Example Requirement Expression for Host Name\nDESCRIPTION: This example shows how to define scheduling requirements in the VM template to deploy only on hosts matching the pattern 'aquila*'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_27\n\nLANGUAGE: text\nCODE:\n```\n# Only aquila hosts (aquila0, aquila1...), note the quotes\nSCHED_REQUIREMENTS = \"NAME = \\\"aquila*\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Get Group Quota (CLI)\nDESCRIPTION: This command opens an editor session to edit the quota template for a specific group. The group name is passed as a parameter. The editor will contain tips about the syntax for defining quotas.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/quotas.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onegroup quota groupA\n```\n\n----------------------------------------\n\nTITLE: Configuring Flush Action in OpenNebula\nDESCRIPTION: This snippet configures the action to be taken when a host is flushed. It sets the `flush` action within the `default_actions` section of the OpenNebula host configuration file (`/etc/one/cli/onehost.yaml`) to `delete-recreate`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n:default_actions:\n  - :flush: delete-recreate\n```\n\n----------------------------------------\n\nTITLE: Hugepages Configuration Example\nDESCRIPTION: This configuration enables the use of hugepages for memory allocation of the VM. The `HUGEPAGE_SIZE` attribute in the `TOPOLOGY` section defines the size of the hugepages in megabytes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_13\n\nLANGUAGE: text\nCODE:\n```\nTOPOLOGY = [ PIN_POLICY = thread, SOCKETS = 2, HUGEPAGE_SIZE = 2 ]\n```\n\n----------------------------------------\n\nTITLE: SSH Login to EC2 VM\nDESCRIPTION: This command is used to log in to the EC2 VM using SSH. It specifies the user as ubuntu, the path to the PEM file, and the public IP address of the VM. Replace <public IP of the VM> with the actual IP address and <PEM file> with the correct path to the PEM file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\nssh <public IP of the VM> -l ubuntu -i <PEM file>\n```\n\nLANGUAGE: Bash\nCODE:\n```\nssh <IP> -l ubuntu -i ~/.ssh/aws_pemfile.pem\n```\n\n----------------------------------------\n\nTITLE: Displaying NUMA Node Details within the Guest OS using numactl\nDESCRIPTION: This snippet displays the output of the `numactl -H` command executed inside the guest VM, showing the NUMA topology as seen by the VM. It lists the NUMA nodes, their assigned CPUs, memory sizes, and distances between nodes. This verifies the correct exposure of the NUMA configuration to the guest OS.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_21\n\nLANGUAGE: Shell\nCODE:\n```\n# numactl -H\navailable: 2 nodes (0-1)\nnode 0 cpus: 0 1\nnode 0 size: 511 MB\nnode 0 free: 401 MB\nnode 1 cpus: 2 3\nnode 1 size: 511 MB\nnode 1 free: 185 MB\nnode distances:\nnode   0   1\n  0:  10  20\n  1:  20  10\n```\n\n----------------------------------------\n\nTITLE: OpenNebula State Hook Example (Image - Ruby)\nDESCRIPTION: This Ruby script demonstrates a state hook for OpenNebula images. It decodes the image template passed as a base64-encoded XML string in ARGV[0], extracts the image ID, and prints a message indicating that the image is ready to use. It depends on the 'base64' and 'nokogiri' libraries.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_15\n\nLANGUAGE: ruby\nCODE:\n```\n# Hook template\n#\n# NAME = image-ready\n# TYPE = state\n# COMMAND = image_ready.rb\n# STATE = READY\n# RESOURCE = IMAGE\n# ARGUMENTS = \"$TEMPLATE\"\n\n#!/usr/bin/ruby\n\nrequire 'base64'\nrequire 'nokogiri'\n\n#img_template = Nokogiri::XML(Base64::decode64(STDIN.gets.chomp)) for reading from STDIN\nimg_template = Nokogiri::XML(Base64::decode64(ARGV[0]))\n\nimg_id = img_template.xpath(\"//ID\").text.to_i\n\nputs \"Image #{img_id} ready to use!!\"\n```\n\n----------------------------------------\n\nTITLE: Listing LVM Volumes with Thin Snapshots\nDESCRIPTION: This snippet showcases the output of the `lvs` command when thin snapshots are created. It shows how snapshots (lv-one-11-0_s0, lv-one-11-0_s1) are linked to the original thin LV (lv-one-11-0) and the thin pool, sharing data and minimizing initial space consumption.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/lvm_drivers.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# lvs\n  LV              VG       Attr       LSize   Pool            Origin       Data%  Meta%  Move Log Cpy%Sync Convert\n  lv-one-11-0     vg-one-0 Vwi-aotz-- 256.00m lv-one-11-pool               48.44\n  lv-one-11-0_s0  vg-one-0 Vwi---tz-k 256.00m lv-one-11-pool  lv-one-11-0\n  lv-one-11-0_s1  vg-one-0 Vwi---tz-k 256.00m lv-one-11-pool  lv-one-11-0\n  lv-one-11-1     vg-one-0 Vwi-aotz-- 256.00m lv-one-11-pool               48.46\n  lv-one-11-pool  vg-one-0 twi---tz--   1.00g                              24.22  12.70\n```\n\n----------------------------------------\n\nTITLE: Virtual Network Definition with IPAM\nDESCRIPTION: This code snippet shows how to define a Virtual Network to use the IPAM driver.  It sets the IPAM_MAD in the AR definition.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-ipam.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\nNAME = \"IPAM Network\"\n\n  BRIDGE  = \"br0\"\n  VNM_MAD = \"dummy\"\n\n  AR = [\n    SIZE     = 21,\n    IPAM_MAD = <ipam_mad>\n   ]\n```\n\n----------------------------------------\n\nTITLE: Verifying Virtual Function Creation\nDESCRIPTION: This command lists the contents of the PCI device directory in `/sys/bus/pci/devices/` and filters the output for `virtfn`. The presence of `virtfn` entries confirms that virtual functions have been successfully created for the GPU.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nls -l /sys/bus/pci/devices/0000:41:00.0/ | grep virtfn\n```\n\n----------------------------------------\n\nTITLE: Configuring ip link options (OpenNebulaNetwork.conf)\nDESCRIPTION: This snippet shows how to configure the `ip_link_conf` options in `/var/lib/one/remotes/etc/vnm/OpenNebulaNetwork.conf`.  These options are passed to the `ip link add` command when creating VLAN interfaces. The example shows how to set UDP checksum and TOS values for the interface.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vlan.rst#_snippet_1\n\nLANGUAGE: Text\nCODE:\n```\n# Following options will be added when creating bridge. For example:\n#\n#     ip link add name <bridge name> type bridge stp_state 1\n#\n# :ip_bridge_conf:\n#     :stp_state: on\n\n\n# These options will be added to the ip link add command. For example:\n#\n#     sudo ip link add lxcbr0.260  type vxlan id 260 group 239.0.101.4 \\\n#       ttl 16 dev lxcbr0 udp6zerocsumrx  tos 3\n#\n:ip_link_conf:\n    :udp6zerocsumrx:\n    :tos: 3\n```\n\n----------------------------------------\n\nTITLE: Example Authentication Driver Script (Bash)\nDESCRIPTION: This is a Bash script that implements a simple authentication driver. It reads the XML input, extracts the username, password, and secret, and checks if the length of the secret matches the password.  It returns the driver name, username and secret on success or an error message with exit code 255 on failure.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-auth.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\nÂ \ndata=$(cat -)\n\nusername=$(echo \"${data}\" | xmllint --xpath '//AUTHN/USERNAME/text()' -)\npassword=$(echo \"${data}\" | xmllint --xpath '//AUTHN/PASSWORD/text()' -)\nsecret=$(echo \"${data}\" | xmllint --xpath '//AUTHN/SECRET/text()' -)\n\nlength=$(echo -n \"$secret\" | wc -c | tr -d ' ')\nÂ \nif [ $length = $password ]; then\n    echo \"length $username $secret\"\nelse\n    echo \"Invalid password\"\n    exit 255\nfi\n```\n\n----------------------------------------\n\nTITLE: Collecting Disk Metrics (Bash)\nDESCRIPTION: This snippet collects disk metrics for each mounted `/dev` partition using `/bin/df`. It parses the output of `df` using `awk` to extract total, used, and free space for each disk. It calculates the percentage of used disk space and appends the disk metrics to the `$TMP_DIR/metrics` file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n/bin/df -k -P | grep '^/dev' > $TMP_DIR/df\n\ncat $TMP_DIR/df | while read line; do\n    NAME=`echo $line | awk '{print $1}' | awk -F '/' '{print $NF}'`\n\n    DISK_TOTAL=`echo $line | awk '{print $2}'`\n    DISK_USED=`echo $line | awk '{print $3}'`\n    DISK_FREE=`echo $line | awk '{print $4}'`\n\n    DISK_USED_PERC=\"0\"\n\n    if ! [ -z $DISK_TOTAL ] && [ $DISK_TOTAL -gt 0 ]; then\n        DISK_USED_PERC=`echo \"$DISK_USED $DISK_TOTAL\" | \\\n            awk '{ printf \"%.2f\", 100 * $1 / $2 }'`\n    fi\n\n    echo \"DISK_USED_PERC_$NAME = $DISK_USED_PERC\" >> $TMP_DIR/metrics\ndone\n```\n\n----------------------------------------\n\nTITLE: Rescanning PCI bus in Linux guest\nDESCRIPTION: This command instructs the Linux guest OS to rescan the PCI bus, which is necessary after hotplugging disks or NICs. It writes '1' to the /sys/bus/pci/rescan file, triggering the rescan.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# echo 1 > /sys/bus/pci/rescan\n```\n\n----------------------------------------\n\nTITLE: Disabling Showback in Sunstone YAML Configuration\nDESCRIPTION: This YAML snippet demonstrates how to disable the showback reports tab in a Sunstone view by setting the `enabled` property to `false` within the `user-tab.yaml` configuration file. This configuration file controls the user interface elements displayed in Sunstone.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/showback.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n...\ninfo-tabs:\n  showback:\n    enabled: false\n```\n\n----------------------------------------\n\nTITLE: Adding OpenNebula Server to Zone using onezone command\nDESCRIPTION: This command is used to add an OpenNebula server to a specified zone. It requires the zone ID as a parameter. The command provides options for setting the server name and RPC endpoint.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/frontend_ha.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onezone server-add\nCommand server-add requires one parameter to run\n## USAGE\nserver-add <zoneid>\n        Add an OpenNebula server to this zone.\n        valid options: server_name, server_rpc\n\n## OPTIONS\n     -n, --name                Zone server name\n     -r, --rpc                 Zone server RPC endpoint\n     -v, --verbose             Verbose mode\n     -h, --help                Show this message\n     -V, --version             Show version and copyright information\n     --user name               User name used to connect to OpenNebula\n     --password password       Password to authenticate with OpenNebula\n     --endpoint endpoint       URL of OpenNebula xmlrpc frontend\n```\n\n----------------------------------------\n\nTITLE: Upgrading OpenNebula Configuration\nDESCRIPTION: This command upgrades the OpenNebula configuration to version 5.8.0 with verbose output. It creates a backup before applying changes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade --verbose --to 5.8.0\n```\n\n----------------------------------------\n\nTITLE: Handling unknown config version error\nDESCRIPTION: This snippet showcases the error message encountered when running `onecfg status` in an uninitialized environment or when the configuration version is unknown.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg status\n--- Versions ------------------------------\nOpenNebula:  5.8.0\nConfig:      unknown\nERROR: Unknown config version\n```\n\n----------------------------------------\n\nTITLE: Restore VM from Backup Increment\nDESCRIPTION: This command restores a VM from a specific increment of an image backup. It requires the increment ID, the VM ID, and the backup image ID. It deletes all snapshots of the VM during restoration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm restore --increment 1 83 176\n```\n\n----------------------------------------\n\nTITLE: Blacklisting NVIDIA Drivers in modprobe\nDESCRIPTION: This configuration blacklists the nouveau drivers (nouveau and lbm-nouveau) in modprobe. This prevents the system from loading these drivers for NVIDIA GPUs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nblacklist nouveau\nblacklist lbm-nouveau\noptions nouveau modeset=0\nalias nouveau off\nalias lbm-nouveau off\n```\n\n----------------------------------------\n\nTITLE: Setting Raw LXC Configuration\nDESCRIPTION: This snippet demonstrates how to use the RAW attribute to add a raw LXC configuration attribute to the container deployment file.  The TYPE parameter specifies the container type, and the DATA parameter contains the LXC configuration attribute and its value. If an attribute is already set by OpenNebula, the OpenNebula value takes precedence.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_driver.rst#_snippet_4\n\nLANGUAGE: YAML\nCODE:\n```\nRAW = [\n  TYPE = \"lxc\",\n  DATA = \"lxc.signal.reboot = 9\" ]\n```\n\n----------------------------------------\n\nTITLE: Implementing a Filter in Table Columns (JavaScript)\nDESCRIPTION: This JavaScript code snippet demonstrates how to implement a filter in table columns, specifically for the Marketplace Apps table within the OpenNebula Sunstone interface. It defines a filter based on the 'State' of the marketplace app, allowing users to filter apps based on their state using the CategoryFilter component. The 'includesValue' filter is applied to perform the filtering operation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_33\n\nLANGUAGE: javascript\nCODE:\n```\n// src/client/components/Tables/MarketplaceApps/columns.js\n{\n  Header: 'State',\n  id: 'STATE',\n  disableFilters: false,\n  Filter: ({ column }) =>\n    CategoryFilter({\n      column,\n      multiple: true,\n      title: 'State',\n    }),\n  filter: 'includesValue',\n}\n```\n\n----------------------------------------\n\nTITLE: FireEdge Port Conflict Error Message\nDESCRIPTION: This error message indicates that the port FireEdge is trying to use is already in use by another service. The error typically occurs during startup. The configuration file `/etc/one/fireedge-server.conf` needs to be adjusted to use an available port.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/fireedge.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nError: listen EADDRINUSE: address already in use 0.0.0.0:2616\n```\n\n----------------------------------------\n\nTITLE: Becoming Root User with Sudo\nDESCRIPTION: This command is used to switch to the root user account in a terminal. It's essential for performing administrative tasks such as installing software.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_onprem.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo -i\n```\n\n----------------------------------------\n\nTITLE: Creating a Virtual Network with Ruby in OpenNebula\nDESCRIPTION: This code snippet shows how to create a new Virtual Network in OpenNebula using the Ruby API. It defines a template for the network, initializes a client, builds the XML representation of the Virtual Network, and then allocates the Virtual Network using the defined template. The example showcases the basic steps for creating a new network and assumes a working OpenNebula environment with the necessary dependencies installed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/ruby.rst#_snippet_2\n\nLANGUAGE: ruby\nCODE:\n```\n#!/usr/bin/env ruby\n\n############################################################################\n# Environment Configuration\n############################################################################\nONE_LOCATION = ENV['ONE_LOCATION']\n\nif !ONE_LOCATION\n    RUBY_LIB_LOCATION = '/usr/lib/one/ruby'\n    GEMS_LOCATION     = '/usr/share/one/gems'\nelse\n    RUBY_LIB_LOCATION = ONE_LOCATION + '/lib/ruby'\n    GEMS_LOCATION     = ONE_LOCATION + '/share/gems'\nend\n\nif File.directory?(GEMS_LOCATION)\n    real_gems_path = File.realpath(GEMS_LOCATION)\n    if !defined?(Gem) || Gem.path != [real_gems_path]\n        $LOAD_PATH.reject! {|l| l =~ /vendor_ruby/ }\n        require 'rubygems'\n        Gem.use_paths(real_gems_path)\n    end\nend\n\n$LOAD_PATH << RUBY_LIB_LOCATION\n\n############################################################################\n# Required libraries\n############################################################################\nrequire 'opennebula'\ninclude OpenNebula\n\n# OpenNebula credentials\nCREDENTIALS = \"oneuser:onepass\"\n\n# XML_RPC endpoint where OpenNebula is listening\nENDPOINT = \"http://localhost:2633/RPC2\"\n\nclient = Client.new(CREDENTIALS, ENDPOINT)\n\ntemplate = <<-EOT\nNAME     = \"Red LAN\"\n\n# Now we'll use the host private network (physical)\nBRIDGE  = vbr0\n\n# Custom Attributes to be used in Context\nGATEWAY = 192.168.0.1\nDNS     = 192.168.0.1\n\nLOAD_BALANCER = 192.168.0.3\n\nAR = [\n    TYPE = IP4,\n    IP   = 192.168.0.1,\n    SIZE = 255\n]\nEOT\n\nxml = OpenNebula::VirtualNetwork.build_xml\nvn  = OpenNebula::VirtualNetwork.new(xml, client)\n\nrc = vn.allocate(template)\n\nif OpenNebula.is_error?(rc)\n    STDERR.puts rc.message\n    exit(-1)\nelse\n    puts \"ID: #{vn.id.to_s}\"\nend\n\nputs \"Before info:\"\nputs vn.to_xml\n\nputs\n\nvn.info\n\nputs \"After info:\"\nputs vn.to_xml\n```\n\n----------------------------------------\n\nTITLE: Sunstone View YAML Configuration\nDESCRIPTION: This YAML configuration file defines the Sunstone views accessible to different user groups.  The 'groups' section maps groups (e.g., 'oneadmin') to a list of view names. The 'default' section specifies the view available to all users. This configuration is used to orchestrate the user interface views based on group membership.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_32\n\nLANGUAGE: yaml\nCODE:\n```\n# etc/sunstone/sunstone-view.yaml\ngroups:\n  oneadmin:\n    - admin\n    - user\ndefault:\n  - user\n```\n\n----------------------------------------\n\nTITLE: Restic Repository Locked Error\nDESCRIPTION: This snippet shows an example error message indicating that the Restic repository is locked. This usually occurs when there are ongoing backup operations.  The message includes details about the process holding the lock, creation timestamp, and affected storage ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/restic.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nunable to create lock in backend: repository is already locked exclusively by PID 111971 on ubuntu2204-kvm-qcow2-6-5-yci34-0 by oneadmin (UID 9869, GID 9869)\nlock was created at 2022-11-28 17:33:51 (55.876852076s ago)\nstorage ID 1448874c\n```\n\n----------------------------------------\n\nTITLE: Updating Service Template using CLI (edit) in Bash\nDESCRIPTION: Updates an existing Service Template by opening an editor for manual changes using `oneflow-template update <ID>`.  The <ID> is replaced with the ID of the service template to be updated. Requires a text editor to be configured in the environment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\noneflow-template update <ID>\n```\n\n----------------------------------------\n\nTITLE: Retrieving Service Information using REST API with curl\nDESCRIPTION: This snippet shows how to retrieve detailed information about a specific SERVICE resource in OpenNebula using the REST API with a GET request. It authenticates with username 'oneadmin' and password 'password'. The command targets a specific service ID (in this case, 5).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service/5 -u 'oneadmin:password' -v\n```\n\n----------------------------------------\n\nTITLE: Virtual Machine Template Example\nDESCRIPTION: This is an example Virtual Machine template for OpenNebula, demonstrating basic settings for CPU, Disk, Graphics, Memory, NIC, OS, and Context.  The CONTEXT section is crucial for setting up the environment within the VM, but is not specific to transparent proxy.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nNAME = \"example0\"\nCONTEXT = [\n  NETWORK = \"YES\",\n  SSH_PUBLIC_KEY = \"$USER[SSH_PUBLIC_KEY]\",\n  TOKEN = \"YES\" ]\nCPU = \"1\"\nDISK = [\n  IMAGE = \"img0\" ]\nGRAPHICS = [\n  LISTEN = \"0.0.0.0\",\n  TYPE = \"VNC\" ]\nMEMORY = \"256\"\nNIC = [\n  NETWORK = \"vnet0\",\n  NETWORK_UNAME = \"oneadmin\",\n  SECURITY_GROUPS = \"100\" ]\nNIC_DEFAULT = [\n  MODEL = \"virtio\" ]\nOS = [\n  ARCH = \"x86_64\" ]\n```\n\n----------------------------------------\n\nTITLE: Remove Role from Running Service with curl\nDESCRIPTION: This snippet demonstrates how to remove a role from a running OpenNebula service using a curl command. It targets a specific role name for removal.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service/5/role_action -u 'oneadmin:password' -v -X POST --data '{\n  \"action\": {\n    \"perform\":\"remove_role\",\n    \"params\" : {\n      \"role\" : 'NEW_ROLE'\n    }\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: KVM Default Configuration (text)\nDESCRIPTION: This code snippet shows example default settings for the KVM driver in OpenNebula. It demonstrates how to configure attributes such as OS architecture, CPU features, disk driver, and Hyper-V/SPICE options.  These settings are typically found in `/etc/one/vmm_exec/vmm_exec_kvm.conf`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nOS       = [ ARCH = \"x86_64\" ]\nFEATURES = [ PAE = \"no\", ACPI = \"yes\", APIC = \"no\", HYPERV = \"no\", GUEST_AGENT = \"no\", VIRTIO_SCSI_QUEUES=\"auto\" ]\nDISK     = [ DRIVER = \"raw\" , CACHE = \"none\"]\nHYPERV_OPTIONS=\"<relaxed state='on'/><vapic state='on'/><spinlocks state='on' retries='4096'/>\"\nSPICE_OPTIONS=\"\n        <video>\n            <model type='vga' heads='1'/>\n        </video>\n             <sound model='ich6' />\n        <channel type='spicevmc'>\n            <target type='virtio' name='com.redhat.spice.0'/>\n        </channel>\n        <redirdev bus='usb' type='spicevmc'/>\n        <redirdev bus='usb' type='spicevmc'/>\n        <redirdev bus='usb' type='spicevmc'/>\"\n```\n\n----------------------------------------\n\nTITLE: Stopping All OpenNebula Services\nDESCRIPTION: This command uses `systemctl stop` to stop all the listed OpenNebula services at once. This is useful for maintenance or upgrades. The command requires root privileges to execute.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl stop opennebula opennebula-hem opennebula-fireedge \\\n        opennebula-gate opennebula-flow opennebula-guacd \\\n        opennebula-novnc opennebula-showback.timer \\\n        opennebula-ssh-agent opennebula-ssh-socks-cleaner.timer\n```\n\n----------------------------------------\n\nTITLE: Upgrade OpenNebula Packages on RHEL (Bash)\nDESCRIPTION: Upgrades OpenNebula and related packages on RHEL-based systems. Relies on the yum package manager.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ yum upgrade opennebula opennebula-gate opennebula-flow opennebula-provision opennebula-fireedge python3-pyone\n```\n\n----------------------------------------\n\nTITLE: Deleting an authentication token in OpenNebula\nDESCRIPTION: This snippet shows how to delete an authentication token using the `oneuser token-delete` command. This action removes the token from the user's configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser token-delete b6\nToken removed.\n```\n\n----------------------------------------\n\nTITLE: Defining ARM64 OS Template\nDESCRIPTION: This snippet defines the OS section for an ARM64 host template. It sets the architecture to \"aarch64\", specifies the firmware path and secure boot setting, and sets the machine type to \"virt\", typically an alias for the most recent QEMU ARM Virtual Machine.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_22\n\nLANGUAGE: none\nCODE:\n```\nOS=[\n  ARCH=\"aarch64\",\n  FIRMWARE=\"/usr/share/AAVMF/AAVMF_CODE.fd\",\n  FIRMWARE_SECURE=\"no\",\n  MACHINE=\"virt\"\n]\n```\n\n----------------------------------------\n\nTITLE: Finding I/O MMU Groups\nDESCRIPTION: This command finds the I/O MMU groups for the PCI cards. The groups are used to grant QEMU access to the VFIO devices. The command searches for symbolic links in the /sys/kernel/iommu_groups/ directory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n# find /sys/kernel/iommu_groups/ -type l\n```\n\n----------------------------------------\n\nTITLE: Example Ansible Inventory File (example.yml)\nDESCRIPTION: This YAML file defines the Ansible inventory, specifying the hosts and variables for the OpenNebula deployment.  It includes settings for the OpenNebula version, password, virtual network configuration, and IP addresses of the Front-end and Hypervisors.  The `ansible_host` parameter defines the IP address of each host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n---\nall:\n  vars:\n    ansible_user: root\n    one_version: '6.10'\n    one_pass: opennebulapass\n    vn:\n      admin_net:\n        managed: true\n        template:\n          VN_MAD: bridge\n          PHYDEV: eth0\n          BRIDGE: br0\n          AR:\n            TYPE: IP4\n            IP: 172.20.0.100\n            SIZE: 48\n          NETWORK_ADDRESS: 172.20.0.0\n          NETWORK_MASK: 255.255.255.0\n          GATEWAY: 172.20.0.1\n          DNS: 1.1.1.1\n\nfrontend:\n  hosts:\n    f1: { ansible_host: 172.20.0.2 }\n\nnode:\n  hosts:\n    n1: { ansible_host: 172.20.0.3 }\n    n2: { ansible_host: 172.20.0.4 }\n```\n\n----------------------------------------\n\nTITLE: LVM Driver Configuration in fs_lvm.conf\nDESCRIPTION: This configuration defines the behavior of the LVM driver. It sets the ZERO_LVM_ON_CREATE, ZERO_LVM_ON_DELETE, and DD_BLOCK_SIZE parameters. These parameters control whether LVM volumes are zeroed on creation or deletion, and the block size for dd operations.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/lvm_drivers.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n#  Zero LVM volumes on creation or resizing\nZERO_LVM_ON_CREATE=no\n\n#  Zero LVM volumes on delete, when the VM disks are disposed\nZERO_LVM_ON_DELETE=yes\n\n#  Block size for the dd commands\nDD_BLOCK_SIZE=32M\n```\n\n----------------------------------------\n\nTITLE: Listing Hosts after Adding to a Cluster with onehost\nDESCRIPTION: This snippet lists hosts after adding host01 to the production cluster, showing the updated cluster association in the `onehost list` output. This confirms that the host is now part of the 'production' cluster. The command does not take any parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost list\n  ID NAME         CLUSTER     RVM   TCPU   FCPU   ACPU   TMEM   FMEM   AMEM STAT\n   0 host01       producti      7    400    290    400   3.7G   2.2G   3.7G   on\n```\n\n----------------------------------------\n\nTITLE: Displaying Template Permissions using onetemplate show\nDESCRIPTION: This snippet shows the command to display template permissions using `onetemplate show 0`. The output is truncated to show only the PERMISSIONS section.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_21\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate show 0\n...\nPERMISSIONS\nOWNER          : um-\nGROUP          : ---\nOTHER          : ---\n```\n\n----------------------------------------\n\nTITLE: Enable/Disable FireEdge Service on Boot (systemctl)\nDESCRIPTION: These commands configure whether the FireEdge service starts automatically when the host boots. `enable` sets the service to start on boot, while `disable` prevents it. They require systemd and appropriate privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/fireedge.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ systemctl enable  opennebula-fireedge\n$ systemctl disable opennebula-fireedge\n```\n\n----------------------------------------\n\nTITLE: Bash command to display libvirtd.conf contents (RedHat)\nDESCRIPTION: This bash command displays the contents of the /etc/libvirt/libvirtd.conf file. It is often used to verify or inspect the Libvirt configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/release_notes/platform_notes.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncat /etc/libvirt/libvirtd.conf\n```\n\n----------------------------------------\n\nTITLE: Downloading OpenSUSE Context Package with wget\nDESCRIPTION: This command downloads the OpenNebula context package for OpenSUSE 15 and Tumbleweed using wget. The package is downloaded from the OpenNebula GitHub releases page.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# wget https://github.com/OpenNebula/one-apps/releases/download/v|context_release|/one-context-|context_release|-1.suse.noarch.rpm\n```\n\n----------------------------------------\n\nTITLE: Manual upgrade with version enforcing\nDESCRIPTION: This example demonstrates step-by-step manual upgrade with versions enforcing.  The `--from` and `--to` options are used to specify the source and target configuration versions, respectively.  This allows for fine-grained control over the upgrade process, especially when upgrading across multiple major versions. The `--verbose` parameter enables detailed logging.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade --verbose --from 5.4.0 --to 5.6.0\n```\n\n----------------------------------------\n\nTITLE: Verifying NVIDIA vGPU VFIO module\nDESCRIPTION: This command checks if the `nvidia_vgpu_vfio` module is loaded, indicating that the NVIDIA vGPU driver is active. The output should show the module name and the number of processes using it.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nlsmod | grep vfio\n```\n\n----------------------------------------\n\nTITLE: Initializing PyONE with HTTP endpoint\nDESCRIPTION: This snippet demonstrates how to instantiate the `OneServer` class to connect to an OpenNebula XML-RPC endpoint using HTTP. It requires the `pyone` library. It sets the server address and session credentials.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pyone\none = pyone.OneServer(\"http://one:2633/RPC2\", session=\"oneadmin:onepass\")\n```\n\n----------------------------------------\n\nTITLE: Showing the On-Premises Provider Details using oneprovider\nDESCRIPTION: This command displays the details of the onprem provider, including its ID and name. It requires the `oneprovider` tool to be available in the system's PATH.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/onprem_provider.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\noneprovider show onprem\n```\n\n----------------------------------------\n\nTITLE: Setting Max Actions Per Host\nDESCRIPTION: This configuration snippet from /etc/one/oned.conf increases the maximum number of actions allowed per host, which defaults to 1. By changing this value, OpenNebula can perform multiple operations concurrently on a single host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nMAX_ACTIONS_PER_HOST = 10\n```\n\n----------------------------------------\n\nTITLE: Installing pip and pipx on Ubuntu\nDESCRIPTION: This command installs the Python package installer pip and the tool pipx, which is used for installing and running Python applications in isolated environments.  It is a prerequisite for installing Hatch.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install python3-pip pipx\n```\n\n----------------------------------------\n\nTITLE: Displaying oneacct usage options\nDESCRIPTION: This snippet shows the available options for the `oneacct` command-line tool, used to print accounting information for virtual machines. The options allow filtering by time, user, group, host, and XPath expression. It also supports different output formats like XML, JSON, and CSV.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/accounting.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nUsage: oneacct [options]\n -s, --start TIME          First day of the data to retrieve\n -e, --end TIME            Last day of the data to retrieve\n -u, --userfilter user     User name or id to filter the results\n -g, --group group         Group name or id to filter the results\n -H, --host HOST           Host name or id to filter the results\n --xpath XPATH_EXPRESSION  Xpath expression to filter the results. For\n                               example: oneacct --xpath 'HISTORY[ETIME>0]'\n -x, --xml                 Show the resource in xml format\n -j, --json                Show the resource in json format\n --split                   Split the output in a table for each VM\n -v, --verbose             Verbose mode\n -h, --help                Show this message\n -V, --version             Show version and copyright information\n --describe                Describe list columns\n -l, --list x,y,z          Selects columns to display with list command\n --csv                     Write table in csv format\n --user name               User name used to connect to OpenNebula\n --password password       Password to authenticate with OpenNebula\n --endpoint endpoint       URL of OpenNebula XML-RPC front-end\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenNebula Networking Driver\nDESCRIPTION: This code block demonstrates how to configure the bridging technology used by the network driver in the /etc/one/oned.conf file. It shows examples for Open vSwitch (ovswitch_vxlan), Linux Bridge (bridge), and a custom driver with no bridging (none).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-nm.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nVN_MAD_CONF = [\n    NAME = \"ovswitch_vxlan\"\n    BRIDGE_TYPE = \"openvswitch\"\n]\n\nVN_MAD_CONF = [\n    NAME = \"bridge\"\n    BRIDGE_TYPE = \"linux\"\n]\n\nVN_MAD_CONF = [\n    NAME = \"custom\"\n    BRIDGE_TYPE = \"none\"\n]\n```\n\n----------------------------------------\n\nTITLE: OS Boot Configuration with Datastore Images\nDESCRIPTION: This snippet demonstrates how to configure the OS boot parameters using images stored in an OpenNebula File Datastore.  It uses the `$FILE` macro to reference kernel and initrd images by name. This is an alternative to specifying local file paths.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\nOS = [ KERNEL_DS  = \"$FILE[IMAGE=\\\"kernel 3.6\\\"]\",\n           INITRD_DS  = \"$FILE[IMAGE=\\\"initrd 3.6\\\"]\",\n           ROOT       = sda1,\n           KERNEL_CMD = \"ro console=tty1\"]\n```\n\n----------------------------------------\n\nTITLE: QEMU Guest Agent command example\nDESCRIPTION: This YAML configuration shows an example of a command to execute through the QEMU Guest Agent. It defines a command named 'vm_qemu_ping' that uses the 'one' command-line tool to send a 'guest-ping' command to the guest, with a timeout of 5 seconds.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n:commands:\n  :vm_qemu_ping: \"one-$vm_id '{\\\"execute\\\":\\\"guest-ping\\\"}' --timeout 5\"\n```\n\n----------------------------------------\n\nTITLE: SSH Connection to VM\nDESCRIPTION: This code snippet demonstrates how to connect to a virtual machine via SSH using the root user and the VM's IP address.  It shows the initial connection attempt, host key verification, and entering the shell. It assumes that the SSH server is running on the VM and accessible from the client machine.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\n$ ssh root@172.16.0.2\nThe authenticity of host '172.16.0.2 (172.16.0.2)' can't be established.\nED25519 key fingerprint is SHA256:Uz6WarB4k+1Sq2DI5Zz7b15p0ND7fr+kwxzIxSzr/Zg.\nThis key is not known by any other names\nAre you sure you want to continue connecting (yes/no/[fingerprint])? yes\nWarning: Permanently added '172.16.0.2' (ED25519) to the list of known hosts\nlocalhost:~#\n```\n\n----------------------------------------\n\nTITLE: Verifying Service Status with OneFlow CLI\nDESCRIPTION: This command lists all OneFlow services using the `oneflow list` command. It helps to verify if the service has transitioned to the `RUNNING` state after manually updating the VM statuses. It confirms the resolution of the deployment issue.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_20\n\nLANGUAGE: text\nCODE:\n```\n[oneadmin@FN]$ oneflow list\n ID USER     GROUP    NAME                                                                    STARTTIME STAT\n  3 oneadmin oneadmin OneKE 1.29                                                         08/30 12:35:21 RUNNING\n```\n\n----------------------------------------\n\nTITLE: Datastore Backup Data Structure in XML\nDESCRIPTION: This XML structure describes the input provided to the datastore driver when backing up data. It includes information about both the datastore being backed up and the virtual machine (VM) involved in the backup process.  Relevant datastore attributes, VM metadata, and templates defining specific configurations are present.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_13\n\nLANGUAGE: xml\nCODE:\n```\n<DS_DRIVER_ACTION_DATA>\n  <DATASTORE>\n    <ID>100</ID>\n    <UID>0</UID>\n    <GID>0</GID>\n    <UNAME>oneadmin</UNAME>\n    <GNAME>oneadmin</GNAME>\n    <NAME>rsync</NAME>\n    <PERMISSIONS>\n      <OWNER_U>1</OWNER_U>\n      <OWNER_M>1</OWNER_M>\n      <OWNER_A>0</OWNER_A>\n      <GROUP_U>1</GROUP_U>\n      <GROUP_M>0</GROUP_M>\n      <GROUP_A>0</GROUP_A>\n      <OTHER_U>0</OTHER_U>\n      <OTHER_M>0</OTHER_M>\n      <OTHER_A>0</OTHER_A>\n    </PERMISSIONS>\n    <DS_MAD>rsync</DS_MAD>\n    <TM_MAD>-</TM_MAD>\n    <BASE_PATH>/var/lib/one//datastores/100</BASE_PATH>\n    <TYPE>3</TYPE>\n    <DISK_TYPE>0</DISK_TYPE>\n    <STATE>0</STATE>\n    <CLUSTERS>\n      <ID>0</ID>\n    </CLUSTERS>\n    <TOTAL_MB>19663</TOTAL_MB>\n    <FREE_MB>6457</FREE_MB>\n    <USED_MB>13191</USED_MB>\n    <IMAGES/>\n    <TEMPLATE>\n      <DS_MAD>rsync</DS_MAD>\n      <RESTRICTED_DIRS>/</RESTRICTED_DIRS>\n      <RSYNC_HOST>192.168.150.1</RSYNC_HOST>\n      <RSYNC_USER>oneadmin</RSYNC_USER>\n      <SAFE_DIRS>/var/tmp</SAFE_DIRS>\n      <TM_MAD>-</TM_MAD>\n      <TYPE>BACKUP_DS</TYPE>\n    </TEMPLATE>\n  </DATASTORE>\n  <VM>\n    <ID>800</ID>\n    <UID>0</UID>\n    <GID>0</GID>\n    <UNAME>oneadmin</UNAME>\n    <GNAME>oneadmin</GNAME>\n    <NAME>alpine-800</NAME>\n    <PERMISSIONS>\n      <OWNER_U>1</OWNER_U>\n      <OWNER_M>1</OWNER_M>\n      <OWNER_A>0</OWNER_A>\n      <GROUP_U>0</GROUP_U>\n      <GROUP_M>0</GROUP_M>\n      <GROUP_A>0</GROUP_A>\n      <OTHER_U>0</OTHER_U>\n      <OTHER_M>0</OTHER_M>\n      <OTHER_A>0</OTHER_A>\n    </PERMISSIONS>\n    <LAST_POLL>0</LAST_POLL>\n    <STATE>3</STATE>\n    <LCM_STATE>69</LCM_STATE>\n    <PREV_STATE>3</PREV_STATE>\n    <PREV_LCM_STATE>69</PREV_LCM_STATE>\n    <RESCHED>0</RESCHED>\n    <STIME>1727952499</STIME>\n    <ETIME>0</ETIME>\n    <DEPLOY_ID>7c657ee7-166b-46d3-bf5f-53886f0b77dd</DEPLOY_ID>\n    <MONITORING/>\n    <SCHED_ACTIONS/>\n    <TEMPLATE>\n      <AUTOMATIC_DS_REQUIREMENTS>(\"CLUSTERS/ID\" @> 0)</AUTOMATIC_DS_REQUIREMENTS>\n      <AUTOMATIC_NIC_REQUIREMENTS>(\"CLUSTERS/ID\" @> 0)</AUTOMATIC_NIC_REQUIREMENTS>\n      <AUTOMATIC_REQUIREMENTS>(CLUSTER_ID = 0)</AUTOMATIC_REQUIREMENTS>\n      <CONTEXT>\n        <DISK_ID>1</DISK_ID>\n        <ETH0_DNS/>\n        <ETH0_EXTERNAL/>\n        <ETH0_GATEWAY>192.168.150.1</ETH0_GATEWAY>\n        <ETH0_IP>192.168.150.100</ETH0_IP>\n        <ETH0_IP6/>\n        <ETH0_IP6_GATEWAY/>\n        <ETH0_IP6_METHOD/>\n        <ETH0_IP6_METRIC/>\n        <ETH0_IP6_PREFIX_LENGTH/>\n        <ETH0_IP6_ULA/>\n        <ETH0_MAC>02:00:c0:a8:96:64</ETH0_MAC>\n        <ETH0_MASK/>\n        <ETH0_METHOD/>\n        <ETH0_METRIC/>\n        <ETH0_MTU/>\n        <ETH0_NETWORK/>\n        <ETH0_SEARCH_DOMAIN/>\n        <ETH0_VLAN_ID/>\n        <ETH0_VROUTER_IP/>\n        <ETH0_VROUTER_IP6/>\n        <ETH0_VROUTER_MANAGEMENT/>\n        <NETWORK>YES</NETWORK>\n        <SSH_PUBLIC_KEY>ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCYz+lkZoNyspRhrtXDKFN3cIEwN3w08mz0YGKpVDIiV0+/vgG8dAUQ70Irs3m83W9BHN+vNjKPgKcF+X+sSfxniOtavahxGCRjAhhs1IVm196C5ODbSgXVUWULdtmMHelXbLBJ8X340h/UO+eQ6eRLaRfslXUsgRqremVcvCCPz4LIuRiliGWiELAmqYcY+1zJLeg3QV2Pgn5vschM9e/A4AseKO+HnbGB/I5tnoeZT/Gc3FGfUZLNFVB2XsVGAEEzkqO8VI2msB7MCAZBHffIK6WfLIYgGP6Ha2JT1NWJU7Ncj9Xuql0ElF01VwWMDWzqc0DOiVSsTL89ugJKU6+h one</SSH_PUBLIC_KEY>\n        <TARGET>hda</TARGET>\n      </CONTEXT>\n      <CPU>0.1</CPU>\n      <DISK>\n        <ALLOW_ORPHANS>mixed</ALLOW_ORPHANS>\n        <CEPH_HOST>ubuntu2204-kvm-ceph-quincy-6-99-0c08-0.test</CEPH_HOST>\n        <CEPH_SECRET>7ebb2445-e96e-44c6-b7c7-07dc7a50f311</CEPH_SECRET>\n        <CEPH_USER>oneadmin</CEPH_USER>\n        <CLONE>YES</CLONE>\n        <CLONE_TARGET>SELF</CLONE_TARGET>\n        <CLUSTER_ID>0</CLUSTER_ID>\n        <DATASTORE>default</DATASTORE>\n        <DATASTORE_ID>1</DATASTORE_ID>\n        <DEV_PREFIX>vd</DEV_PREFIX>\n        <DISK_ID>0</DISK_ID>\n        <DISK_SNAPSHOT_TOTAL_SIZE>0</DISK_SNAPSHOT_TOTAL_SIZE>\n        <DISK_TYPE>RBD</DISK_TYPE>\n        <DRIVER>raw</DRIVER>\n        <FORMAT>raw</FORMAT>\n        <IMAGE>alpine</IMAGE>\n        <IMAGE_ID>0</IMAGE_ID>\n        <IMAGE_STATE>2</IMAGE_STATE>\n        <LN_TARGET>NONE</LN_TARGET>\n        <ORIGINAL_SIZE>256</ORIGINAL_SIZE>\n        <POOL_NAME>one</POOL_NAME>\n        <READONLY>NO</READONLY>\n        <SAVE>NO</SAVE>\n        <SIZE>256</SIZE>\n        <SOURCE>one/one-0</SOURCE>\n        <TARGET>vda</TARGET>\n        <TM_MAD>ceph</TM_MAD>\n        <TYPE>RBD</TYPE>\n      </DISK>\n      <GRAPHICS>\n        <LISTEN>0.0.0.0</LISTEN>\n        <PORT>6700</PORT>\n        <TYPE>vnc</TYPE>\n      </GRAPHICS>\n      <MEMORY>96</MEMORY>\n      <NIC>\n        <AR_ID>0</AR_ID>\n        <BRIDGE>br0</BRIDGE>\n        <BRIDGE_TYPE>linux</BRIDGE_TYPE>\n        <CLUSTER_ID>0</CLUSTER_ID>\n        <GATEWAY>192.168.150.1</GATEWAY>\n        <IP>192.168.150.100</IP>\n        <MAC>02:00:c0:a8:96:64</MAC>\n        <MODEL>virtio</MODEL>\n        <NAME>NIC0</NAME>\n        <NETWORK>public</NETWORK>\n        <NETWORK_ID>0</NETWORK_ID>\n        <NIC_ID>0</NIC_ID>\n\n```\n\n----------------------------------------\n\nTITLE: Installing Context Package on Debian/Ubuntu/Devuan with apt-get\nDESCRIPTION: These commands install the OpenNebula context package on Debian/Ubuntu/Devuan using apt-get and dpkg. It purges cloud-init, installs the context package, and fixes any dependency issues.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n# apt-get purge -y cloud-init\n# dpkg -i one-context_*deb || apt-get install -fy\n```\n\n----------------------------------------\n\nTITLE: Show Template Information via CLI - OpenNebula\nDESCRIPTION: This command shows the information of a template with the ID 0, including its permissions for the owner, group, and others. It uses the 'onetemplate show' command with the template ID as an argument.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate show 0\nTEMPLATE 0 INFORMATION\nID             : 0\nNAME           : vm-example\nUSER           : oneuser1\nGROUP          : users\nREGISTER TIME  : 01/13 05:40:28\n\nPERMISSIONS\nOWNER          : um-\nGROUP          : u--\nOTHER          : ---\n\n[...]\n```\n\n----------------------------------------\n\nTITLE: reStructuredText toctree Directive\nDESCRIPTION: This code snippet shows the usage of the 'toctree' directive in reStructuredText. It defines the table of contents structure for the document, setting the maximum depth to 2 and listing the included documents: Overview, Managing Providers, and Provision Cluster Operations.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/index.rst#_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. toctree::\n   :maxdepth: 2\n\n   Overview <overview>\n   Managing Providers <provider_operations>\n   Provision Cluster Operations <cluster_operations>\n```\n\n----------------------------------------\n\nTITLE: Show User Quota (CLI)\nDESCRIPTION: This command displays detailed information about a specific user, including their quota limits and current usage for various resources. The user name is passed as a parameter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/quotas.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser show uA\n```\n\n----------------------------------------\n\nTITLE: Remote Modules JSON Configuration\nDESCRIPTION: Example JSON configuration for loading remote modules locally from the FireEdge server.  It specifies the name and entry point for each module, allowing Sunstone to dynamically load them.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_5\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"UtilsModule\": {\n    \"name\": \"UtilsModule\",\n    \"entry\": \"__HOST__/fireedge/modules/UtilsModule/remoteEntry.js\"\n  },\n  \"ConstantsModule\": {\n    \"name\": \"ConstantsModule\",\n    \"entry\": \"__HOST__/fireedge/modules/ConstantsModule/remoteEntry.js\"\n  },\n  \"ContainersModule\": {\n    \"name\": \"ContainersModule\",\n    \"entry\": \"__HOST__/fireedge/modules/ContainersModule/remoteEntry.js\"\n  },\n  \"ComponentsModule\": {\n    \"name\": \"ComponentsModule\",\n    \"entry\": \"__HOST__/fireedge/modules/ComponentsModule/remoteEntry.js\"\n  },\n  \"FeaturesModule\": {\n    \"name\": \"FeaturesModule\",\n    \"entry\": \"__HOST__/fireedge/modules/FeaturesModule/remoteEntry.js\"\n  },\n  \"ProvidersModule\": {\n    \"name\": \"ProvidersModule\",\n    \"entry\": \"__HOST__/fireedge/modules/ProvidersModule/remoteEntry.js\"\n  },\n  \"ModelsModule\": {\n    \"name\": \"ModelsModule\",\n    \"entry\": \"__HOST__/fireedge/modules/ModelsModule/remoteEntry.js\"\n  },\n  \"HooksModule\": {\n    \"name\": \"HooksModule\",\n    \"entry\": \"__HOST__/fireedge/modules/HooksModule/remoteEntry.js\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Virtual Networks and Templates\nDESCRIPTION: This snippet lists the virtual networks and virtual network templates in OpenNebula using the `onevnet list` and `onevntemplate list` commands, respectively. It requires the OpenNebula CLI tool to be installed and configured.  The purpose is to check network and template configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onevnet list\n  ID USER     GROUP    NAME                      CLUSTERS   BRIDGE   STATE    LEASES\n   4 oneadmin oneadmin onprem-cluster-public     102        onebr4   rdy           0\n\n$ onevntemplate list\n  ID USER     GROUP    NAME                                                  REGTIME\n   0 oneadmin oneadmin onprem-cluster-private                         04/28 18:08:38\n```\n\n----------------------------------------\n\nTITLE: Role Level User Inputs (JSON)\nDESCRIPTION: This JSON snippet demonstrates defining User Inputs at the Role level. This allows specific customization for each role. The `master` role has `ATT_B` defined at the role level, while the service also defines user inputs. Role-level inputs take precedence.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"Sample Service\",\n  \"description\": \"User Inputs at Service level example\",\n  \"deployment\": \"straight\",\n  \"roles\": [\n    {\n      \"name\": \"master\",\n      \"type\": \"vm\",\n      \"template_id\": 0,\n      \"cardinality\": 1,\n      \"user_inputs\": {\n        \"ATT_B\": \"M|list||1,2,3,4|2\",\n      }\n    },\n    ...\n  ],\n  \"user_inputs\": {\n    \"ATT_A\": \"O|fixed|| |2\",\n    \"ATT_B\": \"M|list||0.5,1,2,4|1\",\n    \"ATT_C\": \"M|range||512..8192|2048\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Apache Configuration for X.509 Authentication\nDESCRIPTION: This snippet shows the Apache virtual host configuration needed to verify the client certificate and pass the DN in the X-Client-Dn header. This is needed for Sunstone to authenticate against OpenNebula using X.509 certificates.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n<VirtualHost *:443>\n    ...\n    SSLVerifyClient require\n    SSLVerifyDepth 1\n\n    RequestHeader set X-Client-Dn \"%{SSL_CLIENT_S_DN}s\" \n    <IfModule mod_ssl.c>\n        SSLProxyEngine On\n    </IfModule>\n</VirtualHost>\n```\n\n----------------------------------------\n\nTITLE: Export Users Component from index.js (JavaScript)\nDESCRIPTION: This JavaScript code snippet shows how to export the `Users` component from the `index.js` file within the `customContainers` module.  This makes the component available for use in other parts of the FireEdge application via module federation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_19\n\nLANGUAGE: javascript\nCODE:\n```\nexport * from '@modules/customContainers/Users'\n```\n\n----------------------------------------\n\nTITLE: oned.conf Configuration Snippet Example\nDESCRIPTION: This snippet from `/etc/one/oned.conf` shows the configuration structure using key-value pairs and nested lists. It demonstrates how to address nested parameters using paths, including those with special characters and quoted sections. It illustrates configurations containing nested structures which can appear several times.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/diff_formats.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nPORT = 2633                                  # path 1\n\nDB = [ BACKEND = \"sqlite\",                   # path 2\n       TIMEOUT = 2500 ]\n\nIM_MAD = [\n      NAME       = \"monitord\",\n      EXECUTABLE = \"onemonitord\",\n      ARGUMENTS  = \"-c monitord.conf\",\n      THREADS    = 8 ]                       # path 3\n```\n\n----------------------------------------\n\nTITLE: Import OVA with Multiple Datastores and VNETs\nDESCRIPTION: This example demonstrates importing an OVA file with two disks and two network interfaces, assigning each disk to a different Datastore and each NIC to a different VNET using the oneswap command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/ova_management/import_ova.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ oneswap import --ova /home/onepoc/ovas/ubuntu2404.ova --datastore 1,101 --network 1,0\nRunning: virt-v2v -v --machine-readable -i ova /home/onepoc/ovas/ubuntu2404.ova -o local -os /tmp/ubuntu2404/conversions/ -of qcow2 --root=first\n\nSetting up the source: -i ova /home/onepoc/ovas/ubuntu2404.ova\n\n(...)\n\n$ onetemplate list\nID  USER     GROUP    NAME                  REGTIME\n101 onepoc   oneadmin ubuntu2404    04/10 12:55:03\n```\n\n----------------------------------------\n\nTITLE: Creating an OS Image in OpenNebula using oneimage\nDESCRIPTION: This command creates an OS Image in OpenNebula using the `oneimage` command. It specifies the datastore, name, and path to the existing disk image. The description provides additional information about the Image.\n\nDependencies: OpenNebula CLI (`oneimage`)\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\noneimage create --datastore default --name Ubuntu --path /home/cloud/images/ubuntu-desktop/disk.0.qcow2 \\\n  --description \"Ubuntu desktop for developers.\"\n```\n\n----------------------------------------\n\nTITLE: Display Host Information with onehost show\nDESCRIPTION: This command displays detailed information about a specific host, including its state, monitoring information, and resource usage. It's used to diagnose host-related errors. It requires the host ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_8\n\nLANGUAGE: text\nCODE:\n```\n$ onehost show 1\n```\n\n----------------------------------------\n\nTITLE: Getting VM Template Information\nDESCRIPTION: This snippet retrieves and displays VM template information, including ID and NAME.  It depends on a valid OneServer instance to be initialized.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nvm_template = one.templatepool.info(-1, -1, -1).VMTEMPLATE[0]\nvm_template.get_ID()\nvm_template.get_NAME()\n```\n\n----------------------------------------\n\nTITLE: Configuring Persistent SSH Connections\nDESCRIPTION: This SSH configuration snippet enables persistent SSH connections, allowing multiple sessions to reuse a single connection. This improves performance by reducing the overhead of establishing new connections. Should only be enabled on the Front-end node.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/advanced_ssh_usage.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nHost *\n   ControlMaster auto\n   ControlPath /var/lib/one/ctrl-M-%C.sock\n   ControlPersist 0\n```\n\n----------------------------------------\n\nTITLE: Enabling Above 4G Encoding for GPU in QEMU\nDESCRIPTION: This QEMU commandline argument enables Above 4G Encoding, allowing the virtual machine to access the full memory of a GPU with more than 4GB of memory.  This configuration is added to the Libvirt XML to pass the argument to QEMU.  It sets the PCI MMIO region size to 64MB.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_8\n\nLANGUAGE: xml\nCODE:\n```\n<qemu:commandline>\n  <qemu:arg value='-fw_cfg'/>\n  <qemu:arg value='opt/ovmf/X-PciMmio64Mb,string=65536'/>\n</qemu:commandline>\n```\n\n----------------------------------------\n\nTITLE: Verifying configuration status after initialization\nDESCRIPTION: This snippet verifies the configuration status after initialization, showing that the configuration version is now known and matches the OpenNebula version.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg status\n--- Versions ------------------------------\nOpenNebula:  5.8.0\nConfig:      5.8.0\n\n--- Available Configuration Updates -------\nNo updates available.\n```\n\n----------------------------------------\n\nTITLE: Installing Build Dependencies (Debian)\nDESCRIPTION: This command installs the build dependencies for OpenNebula on Debian 11 and 12 using the apt package manager, followed by installing bower via npm. It simplifies the installation process by combining several package installations into one command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/build_deps.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\napt install bash-completion debhelper default-jdk default-libmysqlclient-dev freerdp2-dev grunt javahelper libaugeas-dev libcairo2-dev libcurl4-openssl-dev libnode-dev libossp-uuid-dev libpango1.0-dev libpulse-dev libsqlite3-dev libssh2-1-dev libssl-dev libsystemd-dev libtool libvncserver-dev libvorbis-dev libwebp-dev libws-commons-util-java libxml2-dev libxmlrpc-c++8-dev libxslt1-dev libzmq3-dev libzmq5 nodejs npm python3 python3-setuptools rake ruby-dev scons unzip && npm install -g bower\n```\n\n----------------------------------------\n\nTITLE: Pinging VM from Front-end (Bash)\nDESCRIPTION: This command pings the VM's IP address (172.20.0.100) from the OpenNebula front-end to verify network connectivity. The `-c 3` option sends three ICMP echo requests. This is a basic check to ensure the VM is reachable and responding on the network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nping -c 3 172.20.0.100\n```\n\n----------------------------------------\n\nTITLE: Encoding LDAP User DN and Password - Bash\nDESCRIPTION: This snippet shows how to use the oneuser encode command to escape special characters in the LDAP user DN and password. The resulting string is suitable for use in the $ONE_AUTH file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ldap.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser encode 'cn=First Name,dc=institution,dc=country' 'pass word'\ncn=First%20Name,dc=institution,dc=country:pass%20word\n```\n\n----------------------------------------\n\nTITLE: Get Service Template Response\nDESCRIPTION: This HTTP response (200 OK) shows the detailed information retrieved for a specific service template (ID 4) from the OpenNebula API.  It contains headers such as Content-Type, Content-Length, and X-Frame-Options, along with a JSON representation of the service template's attributes, including its roles, policies, and other configuration details.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_10\n\nLANGUAGE: HTTP\nCODE:\n```\n> GET /service_template/4 HTTP/1.1\n    > Authorization: Basic b25lYWRtaW46b3Blbm5lYnVsYQ==\n    > User-Agent: curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.14.0.0 zlib/1.2.3 libidn/1.18 libssh2/1.4.2\n    > Host: 127.0.0.1:2474\n    > Accept: */*\n    >\n    < HTTP/1.1 200 OK\n    < Content-Type: text/html;charset=utf-8\n    < X-XSS-Protection: 1; mode=block\n    < Content-Length: 1990\n    < X-Frame-Options: sameorigin\n    < Connection: keep-alive\n    < Server: thin 1.2.8 codename Black Keys\n    <\n    {\n      \"DOCUMENT\": {\n        \"TEMPLATE\": {\n          \"BODY\": {\n            \"deployment\": \"straight\",\n            \"name\": \"web-application\",\n            \"roles\": [\n              {\n                \"scheduled_policies\": [\n                  {\n                    \"adjust\": 4,\n                    \"type\": \"CHANGE\",\n                    \"recurrence\": \"0 2 1-10 * * \"\n                  }\n                ],\n                \"template_id\": 0,\n                \"type\": \"vm\",\n                ...\n\n```\n\n----------------------------------------\n\nTITLE: Listing Hatch Environments\nDESCRIPTION: This command displays the available Hatch environments. It verifies that the 'default' and 'ceph' environments have been successfully created.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nhatch env show\n```\n\n----------------------------------------\n\nTITLE: Adding All Clusters from a Zone to a VDC with onevdc\nDESCRIPTION: This command adds all clusters from a given zone to a VDC.  `<group_id>` represents the id of the group to which the clusters are added, `0` is the Zone ID, and `ALL` indicates that all clusters in the specified zone should be added to the VDC.  Note: The documentation contains a typo (`addcluser` instead of `addcluster`).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_vdcs.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onevdc addcluser <group_id> 0 ALL\n```\n\n----------------------------------------\n\nTITLE: SSH connection to the VM\nDESCRIPTION: This code shows the ssh connection to the vm with the ip address. This code shows a warning message when the host is not known.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh root@172.16.0.2\nThe authenticity of host '172.16.0.2 (172.16.0.2)' can't be established.\nED25519 key fingerprint is SHA256:Uz6WarB4k+1Sq2DI5Zz7b15p0ND7fr+kwxzIxSzr/Zg.\nThis key is not known by any other names\n```\n\n----------------------------------------\n\nTITLE: Get User Quota (CLI)\nDESCRIPTION: This command opens an editor session to edit the quota template for a specific user.  The user name is passed as a parameter. The editor will contain tips about the syntax for defining quotas.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/quotas.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser quota userA\n```\n\n----------------------------------------\n\nTITLE: Execute and log command - Shell\nDESCRIPTION: This snippet uses the `exec_and_log` function from `scripts_common.sh` to execute a command and log its execution. If the command fails, an error message is sent to OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nexec_and_log \"chmod g+w $DST_PATH\"\n```\n\n----------------------------------------\n\nTITLE: Restoring Federated Tables Bash\nDESCRIPTION: This command restores the federated tables from a backup file to the OpenNebula database on the slave node. This synchronizes the slave's database with the master's federated data.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ onedb restore --federated -s /var/lib/one/one.db /var/lib/one/one.db_federated_2017-6-14_16:0:36.bck\nSqlite database backup restored in one.db\n```\n\n----------------------------------------\n\nTITLE: PCI Device Name Filter Configuration Example\nDESCRIPTION: This configuration filters PCI devices based on their device name using regular expressions.  The :device_name option enables filtering based on human-readable device names.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\n# The PCI cards list restricted by the :filter option above can be even more\n# filtered by matching the device name against the list of regular expression\n# case-insensitive patterns.\n#\n# For example:\n#   :device_name:\n#     - 'Virtual Function'\n#     - 'Gigabit Network'\n#     - 'USB.*Host Controller'\n#     - '^MegaRAID'\n#\n:device_name:\n  - 'Ethernet'\n  - 'Audio Controller'\n```\n\n----------------------------------------\n\nTITLE: Directory structure of CLI views\nDESCRIPTION: This snippet shows the directory structure where the YAML files are located for each CLI command. These YAML files allow users to customize how specific commands are displayed by default.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/cli.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nroot@supermicro9:~# tree /etc/one/cli/\n/etc/one/cli/\nâ”œâ”€â”€ oneacct.yaml\nâ”œâ”€â”€ oneacl.yaml\nâ”œâ”€â”€ onecluster.yaml\nâ”œâ”€â”€ onedatastore.yaml\nâ””â”€â”€ oneflowtemplate.yaml\n```\n\n----------------------------------------\n\nTITLE: Asymmetric NUMA Topology Definition\nDESCRIPTION: This configuration demonstrates an asymmetric NUMA configuration where VM resources are not evenly distributed across the nodes. The `NUMA_NODE` attributes are manually set to define the memory and CPU allocation for each node.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_10\n\nLANGUAGE: text\nCODE:\n```\nMEMORY = 3072\nVCPU = 6\nCPU  = 6\nTOPOLOGY = [ PIN_POLICY = CORE, SOCKETS = 2 ]\n\nNUMA_NODE = [ MEMORY = 1024, TOTAL_CPUS = 2 ]\nNUMA_NODE = [ MEMORY = 2048, TOTAL_CPUS = 4 ]\n```\n\n----------------------------------------\n\nTITLE: List npm Scripts\nDESCRIPTION: This command lists all the available scripts defined in the `package.json` file.  These scripts provide shortcuts for common development tasks such as building, testing, and starting the application.  It's useful for understanding the available commands in the project.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ npm run       # List the available scripts\n```\n\n----------------------------------------\n\nTITLE: Changing Directory to MiniONE Script Location\nDESCRIPTION: This command navigates the terminal to the directory where the miniONE script has been downloaded. Replace ``<path/to/folder>`` with the actual path to the directory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_onprem.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd <path/to/folder>\n```\n\n----------------------------------------\n\nTITLE: Start FireEdge Server\nDESCRIPTION: This command starts the FireEdge server.  By default, it makes the application accessible at `http://localhost:2616/fireedge`.  This command is used to run the FireEdge application during development or in a production environment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ npm run start # Start the server, by default accessible on http://localhost:2616/fireedge\n```\n\n----------------------------------------\n\nTITLE: Install Host Packages (Deb)\nDESCRIPTION: Installs the OpenNebula Prometheus-KVM package on host machines (Debian-based distributions). This package includes the OpenNebula Libvirt exporter and the Prometheus Node exporter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# apt -y install opennebula-prometheus-kvm\n```\n\n----------------------------------------\n\nTITLE: Configure Image Wait Mode in OneProvision (YAML)\nDESCRIPTION: This snippet shows how to configure the wait mode for an image in OneProvision using YAML.  The `wait` attribute in the `meta` section determines whether OneProvision waits for the image to be ready after creation. The `mode` attribute sets the permissions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nimages:\n  - name: \"test_image\"\n    ds_id: 1\n    size: 2048\n    meta:\n      wait: false\n      mode: 644\n```\n\n----------------------------------------\n\nTITLE: Install NPM Dependencies\nDESCRIPTION: Installs the dependencies for the FireEdge Sunstone project using npm based on the package.json file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm i\n```\n\n----------------------------------------\n\nTITLE: Restarting Already Running OpenNebula Services\nDESCRIPTION: This command uses `systemctl try-restart` to restart a set of OpenNebula services only if they are already running. This prevents errors if a service isn't running and avoids unnecessary restarts. The command requires root privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl try-restart opennebula-hem opennebula-fireedge \\\n        opennebula-gate opennebula-flow opennebula-guacd \\\n        opennebula-novnc opennebula-ssh-agent\n```\n\n----------------------------------------\n\nTITLE: Monitoring Information in Plot Format using onehost\nDESCRIPTION: This command retrieves the USED_MEMORY for host 0, converts the unit to GB, and limits the number of data points to 10, and displays the data in a plot format in the console. The output is a text-based graph representing the memory usage over time.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost monitoring 0 USED_MEMORY --unit G --n 10\n```\n\n----------------------------------------\n\nTITLE: Creating a New User with SSH Authentication\nDESCRIPTION: This command creates a new OpenNebula user with SSH authentication enabled. It requires the username and the path to the user's public key file. The `--ssh` flag specifies that SSH authentication should be used. The public key is read from the provided file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/ssh.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\noneuser create johndoe --ssh --read-file /tmp/pub_key\n```\n\n----------------------------------------\n\nTITLE: Adding OpenNebula dependencies to Ruby Hook Scripts\nDESCRIPTION: Adds necessary OpenNebula dependencies to Ruby hook scripts by setting the RUBY_LIB_LOCATION and GEMS_LOCATION based on the ONE_LOCATION environment variable. This ensures that the scripts can access OpenNebula's Ruby libraries and gems. If ONE_LOCATION isn't set, it uses default paths.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_11\n\nLANGUAGE: ruby\nCODE:\n```\nONE_LOCATION = ENV['ONE_LOCATION']\n\nif !ONE_LOCATION\n    RUBY_LIB_LOCATION = '/usr/lib/one/ruby'\n    GEMS_LOCATION     = '/usr/share/one/gems'\nelse\n    RUBY_LIB_LOCATION = ONE_LOCATION + '/lib/ruby'\n    GEMS_LOCATION     = ONE_LOCATION + '/share/gems'\nend\n\nif File.directory?(GEMS_LOCATION)\n    Gem.use_paths(GEMS_LOCATION)\nend\n\n$LOAD_PATH << RUBY_LIB_LOCATION\n```\n\n----------------------------------------\n\nTITLE: Terminating a Virtual Machine\nDESCRIPTION: This snippet terminates a virtual machine with a given ID. It requires a valid VM ID and a `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\none.vm.action('terminate', 0)\n```\n\n----------------------------------------\n\nTITLE: OneGate VNet Template Attributes Configuration (OpenNebula)\nDESCRIPTION: This code snippet shows the required Virtual Network Template attributes configuration within the `/etc/one/onegate-server.conf` file for OneGate to properly support Virtual Network Functionality. It specifies a list of allowed VNet template attributes that OneGate is permitted to access. These attributes are essential for VNFs to obtain network configuration information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/shared/vnf_sdnat4_req.txt#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n:vnet_template_attributes:           # <--- NEW in 5.12.6+\n  - NETWORK_ADDRESS                  # <--- NEW in 5.12.6+\n  - NETWORK_MASK                     # <--- NEW in 5.12.6+\n  - GATEWAY                          # <--- NEW in 5.12.6+\n  - GATEWAY6                         # <--- NEW in 5.12.6+\n  - DNS                              # <--- NEW in 5.12.6+\n  - GUEST_MTU                        # <--- NEW in 5.12.6+\n  - CONTEXT_FORCE_IPV4               # <--- NEW in 5.12.6+\n  - SEARCH_DOMAIN                    # <--- NEW in 5.12.6+\n```\n\n----------------------------------------\n\nTITLE: Listing Ceph RBD Images in the Pool\nDESCRIPTION: This bash command lists the RBD images in a specified Ceph pool. It displays the image name, size, parent (if a snapshot), format, protection status, and lock status. It uses the `rbd ls` command with extended listing enabled, targeting the 'one' pool and authenticating with the 'libvirt' user.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n$ rbd ls -l -p one --id libvirt\nNAME         SIZE PARENT         FMT PROT LOCK\none-0      10240M                  2\none-0@snap 10240M                  2 yes\none-0-14-0 10240M one/one-0@snap   2\none-0-15-0 10240M one/one-0@snap   2\n```\n\n----------------------------------------\n\nTITLE: Configuring Remote Modules (JSON)\nDESCRIPTION: This JSON configuration defines remote modules for FireEdge, specifying their names and entry points.  The `entry` property points to the remoteEntry.js file served by the module.  This configuration enables runtime module loading.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_24\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"ContainersModule\": {\n    \"name\": \"ContainersModule\",\n    \"entry\": \"__HOST__/fireedge/modules/ContainersModule/remoteEntry.js\"\n  },\n  \"CustomContainersModule\": {\n    \"name\": \"CustomContainersModule\",\n    \"entry\": \"__HOST__/fireedge/modules/CustomContainersModule/remoteEntry.js\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Hold IP Address in All ARs - onevnet Command\nDESCRIPTION: This command puts a specific IP address on hold within all Address Ranges (ARs) of a virtual network. It uses the `onevnet hold` command, preventing the IP from being assigned to new virtual machines. Requires the virtual network name and the IP address to hold.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n#Hold IP 10.0.0.120 in all ARs\n$ onevnet hold \"Private Network\" 10.0.0.120\n```\n\n----------------------------------------\n\nTITLE: Updating a Template using onetemplate command\nDESCRIPTION: This snippet demonstrates how to update an existing VM template in OpenNebula using the `onetemplate update` command.  It will launch the editor defined in the `EDITOR` environment variable, allowing modifications to the template with ID 3.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_16\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate update 3\n```\n\n----------------------------------------\n\nTITLE: OpenNebula VM Capacity Example\nDESCRIPTION: This example shows the basic capacity attributes for a VM in the standard OpenNebula template format. It specifies the VM name, memory size (in MB), and CPU allocation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_5\n\nLANGUAGE: none\nCODE:\n```\nNAME   = test-vm\nMEMORY = 128\nCPU    = 1\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Datastores in Bash\nDESCRIPTION: This command lists the datastores configured in the OpenNebula cloud. It provides a summary of each datastore, including its ID, name, size, availability, associated clusters, number of images, type, data store manager (DS), transfer manager (TM), and status.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/datastores.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore list\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Daemon Log Format - Syslog\nDESCRIPTION: This snippet illustrates the standard format for OpenNebula Daemon log messages when using syslog.  It includes the date, hostname, process ID, zone ID, module, log level, and message. This format is useful for integrating OpenNebula logs with existing syslog infrastructure.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_1\n\nLANGUAGE: none\nCODE:\n```\ndate hostname process[pid]: [Z<zone_id>][module][log_level]: message\n```\n\n----------------------------------------\n\nTITLE: Check Ubuntu Version on Host\nDESCRIPTION: This command checks the Ubuntu version on a host using SSH. It requires SSH access to the host with root privileges and passwordless access.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh root@host01 cat /etc/lsb-release\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=20.04\nDISTRIB_CODENAME=focal\nDISTRIB_DESCRIPTION=\"Ubuntu 20.04.3 LTS\"\n```\n\n----------------------------------------\n\nTITLE: Example Authentication Driver Response with Groups\nDESCRIPTION: This is an example of an authentication driver response that includes group IDs. The driver name, username and then space separated list of groups the user should be assigned to.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-auth.rst#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nldap userx CN=userx,CN=Users,DC=opennebula,DC=org *100 101\n```\n\n----------------------------------------\n\nTITLE: Error Creating Domain with virsh\nDESCRIPTION: This code snippet displays an error encountered when attempting to create a domain using the `virsh create` command. The failure is due to a missing 'cpus' attribute in a NUMA cell definition within the XML deployment file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_26\n\nLANGUAGE: text\nCODE:\n```\nvirsh create deployment.0\nerror: Failed to create domain from deployment.0\nerror: XML error: Missing 'cpus' attribute in NUMA cell\n```\n\n----------------------------------------\n\nTITLE: Building Sunstone from Source\nDESCRIPTION: These commands detail how to build and install Sunstone from source. This includes installing npm dependencies, compiling with scons, and installing Sunstone with specific user and group permissions using the install script.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/compile.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\nroot@frontend:~/ $> cd ~/one/src/fireedge\nroot@frontend:~/ $> npm install\nroot@frontend:~/ $> cd ~/one\nroot@frontend:~/ $> scons fireedge=yes\nroot@frontend:~/ $> ./install.sh -F -u oneadmin -g oneadmin\n```\n\n----------------------------------------\n\nTITLE: OpenNebula VM Event Log Format - Syslog\nDESCRIPTION: This snippet describes the format for Virtual Machine events logged via syslog in OpenNebula. It includes the date, hostname, process ID, VM ID, zone ID, module, log level, and message. Understanding this format is crucial for monitoring and troubleshooting VM-related issues.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_2\n\nLANGUAGE: none\nCODE:\n```\ndate hostname process[pid]: [VM id][Z<zone_id>][module][log_level]: message\n```\n\n----------------------------------------\n\nTITLE: Exporting an OpenNebula Marketplace Application\nDESCRIPTION: This command exports an application (image) from the OpenNebula Marketplace to a datastore. It specifies the datastore (`default`) and the name of the application (`Alpine Linux 3.17`). It requires the `onemarketapp` tool.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nonemarketapp export -d default 'Alpine Linux 3.17' alpine\n```\n\n----------------------------------------\n\nTITLE: Installing OpenNebula from Source\nDESCRIPTION: These commands demonstrate how to download, extract, configure, build, and install OpenNebula from source. It involves using wget to download the tarball, tar to extract it, scons for building, and install.sh for installation with specific user and group permissions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/compile.rst#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\noneadmin@frontend:~/ $> wget <opennebula tar gz>\noneadmin@frontend:~/ $> tar xzf <opennebula tar gz>\noneadmin@frontend:~/ $> cd opennebula-x.y.z\noneadmin@frontend:~/opennebula-x.y.z/ $> scons -j2 mysql=yes syslog=yes fireedge=yes\n[ lots of compiling information ]\nscons: done building targets.\noneadmin@frontend:~/opennebula-x.y.z $> sudo ./install.sh -u oneadmin -g oneadmin\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Autostart VM Hook Definition\nDESCRIPTION: Defines the autostart-vm hook for OpenNebula, triggered on the VM resource when its STATE is POWEROFF and LCM_STATE is LCM_INIT. It runs the autostart/vm command, passing the VM template via stdin. This hook is crucial for the KVM autostart implementation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_17\n\nLANGUAGE: text\nCODE:\n```\nNAME = autostart-vm\nTYPE = state\nCOMMAND = autostart/vm\nARGUMENTS = \\$TEMPLATE\nARGUMENTS_STDIN = yes\nRESOURCE = VM\nSTATE = POWEROFF\nLCM_STATE = LCM_INIT\nON = CUSTOM\n```\n\n----------------------------------------\n\nTITLE: oneacct output in CSV format\nDESCRIPTION: This code snippet showcases how to obtain the `oneacct` output in CSV (Comma Separated Values) format using the `--csv` option. The output includes a header row with column names, followed by the data rows.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/accounting.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n$ oneacct --csv\nUID,VID,HOSTNAME,ACTION,REASON,START_TIME,END_TIME,MEMORY,CPU,NETRX,NETTX,DISK\n```\n\n----------------------------------------\n\nTITLE: Making an API call to get hostpool information\nDESCRIPTION: This snippet demonstrates how to make an API call using PyONE to retrieve hostpool information. It shows how to access the host's ID. It requires a valid `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport pyone\n\none = pyone.OneServer(\"http://one:2633/RPC2\", session=\"oneadmin:onepass\" )\nhostpool = one.hostpool.info()\nhost = hostpool.HOST[0]\nid = host.ID\n```\n\n----------------------------------------\n\nTITLE: Displaying user tokens in OpenNebula\nDESCRIPTION: This snippet shows the output of the `oneuser show` command when tokens are configured for a user. It displays information about the token ID, effective group ID, group name, and expiration date.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser show\n[...]\nTOKENS\n     ID EGID  EGROUP     EXPIRATION\n3ea673b 100   groupB     2016-09-03 03:58:51\nc33ff10 100   groupB     expired\nf836893 *1    users      forever\n```\n\n----------------------------------------\n\nTITLE: OneGate Permissions Configuration (OpenNebula)\nDESCRIPTION: This code snippet shows the required permissions configuration within the `/etc/one/onegate-server.conf` file for OneGate to properly support Virtual Network Functionality. It includes permissions for VMs, Services, Virtual Routers (added in 5.12.6+), and Virtual Networks (added in 5.12.6+). This configuration enables OneGate to perform actions on these resources.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/shared/vnf_sdnat4_req.txt#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n:permissions:\n  :vm:\n    :show: true\n    :show_by_id: true\n    :update: true\n    :update_by_id: true\n    :action_by_id: true\n  :service:\n    :show: true\n    :change_cardinality: true\n  :vrouter:                          # <--- NEW in 5.12.6+\n    :show: true                      # <--- NEW in 5.12.6+\n  :vnet:                             # <--- NEW in 5.12.6+\n    :show_by_id: true                # <--- NEW in 5.12.6+\n```\n\n----------------------------------------\n\nTITLE: Virtual Router Role Instantiation\nDESCRIPTION: This snippet shows the structure of a virtual router role when instantiated within a service. It includes the `vrouter_id` which is the ID of the created virtual router, and `vrouter_ips` which contains the allocated floating IPs and their associated network IDs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_29\n\nLANGUAGE: javascript\nCODE:\n```\n{\n    ...\n    \"roles\": [\n      ...\n      {\n        \"name\": \"VR_EXAMPLE\",\n        \"type\": \"vr\",\n        \"template_id\": 1,\n        \"state\": 2,\n        \"cardinality\": 3,\n        \"template_contents\": {\n          \"NIC\": [\n            {\n              \"NETWORK_ID\": \"0\",\n              \"FLOATING_IP\": \"yes\"\n            }\n          ],\n          \"NAME\": \"VR_EXAMPLE(service_5)\"\n        },\n        \"nodes\": [\n          ...\n        ],\n        \"on_hold\": false,\n        \"last_vmname\": 0,\n        \"vrouter_id\": 2,\n        \"vrouter_ips\": [\n          {\n            \"NETWORK_ID\": 0,\n            \"VROUTER_IP\": \"1.1.1.1\"\n          }\n        ]\n      }\n      ...\n    ]\n    ...\n  }\n```\n\n----------------------------------------\n\nTITLE: Displaying Virtual CPU Information with CPU Affinity using virsh\nDESCRIPTION: This snippet shows the output of `virsh vcpuinfo 1`, which displays virtual CPU (VCPU) information for a VM, including the CPU it's running on, its state, and CPU affinity. This allows verification of CPU pinning.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_20\n\nLANGUAGE: Shell\nCODE:\n```\nvirsh # vcpuinfo 1\nVCPU:           0\nCPU:            0\nState:          running\nCPU time:       13.0s\nCPU Affinity:   y-------\n\nVCPU:           1\nCPU:            4\nState:          running\nCPU time:       5.8s\nCPU Affinity:   ----y---\n\nVCPU:           2\nCPU:            1\nState:          running\nCPU time:       39.1s\nCPU Affinity:   -y------\n\nVCPU:           3\nCPU:            5\nState:          running\nCPU time:       25.4s\nCPU Affinity:   -----y--\n```\n\n----------------------------------------\n\nTITLE: Add Build Script for Custom Containers Module (JavaScript)\nDESCRIPTION: This JavaScript code snippet shows how to add a new build script to the `package.json` file for the `CustomContainersModule`. The script uses `rimraf` to clean the destination directory and then invokes `webpack` to build the module with the specified configuration file and build target. It defines an alias \"build:ccm\" to refer to this new script.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_21\n\nLANGUAGE: javascript\nCODE:\n```\n\"scripts\": {\n  \"build:ctm\": \"rimraf dist/modules/ContainersModule && BUILD_TARGET=remote webpack --config ./src/modules/containers/webpack.config.prod.containers.js\",\n\n  // Adding it under the alias \"build:ccm\"\n  \"build:ccm\": \"rimraf dist/modules/CustomContainersModule && BUILD_TARGET=remote webpack --config ./src/modules/customContainers/webpack.config.prod.customContainers.js\",\n  // More module build commands\n  }\n```\n\n----------------------------------------\n\nTITLE: Exporting a Marketplace Application\nDESCRIPTION: This snippet exports a marketplace application using the `onemarketapp export` command. It specifies the marketplace application ID (74), the desired name (`alpine_market`), and the datastore (`default`). The OpenNebula CLI tool must be installed and configured.  The output shows the IDs of the created image and virtual machine template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ onemarketapp export 74 alpine_market -d default\n    IMAGE\n        ID: 2\n    VMTEMPLATE\n        ID: 3\n```\n\n----------------------------------------\n\nTITLE: Module Barrel File Export\nDESCRIPTION: This code snippet demonstrates how to create a barrel file for a module. It exports all nested modules from the top-level index file using the `export * from` syntax, ensuring all exports are accessible from the module's root.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_30\n\nLANGUAGE: javascript\nCODE:\n```\nexport * from '@modules/containers/ACLs'\nexport * from '@modules/containers/BackupJobs'\nexport * from '@modules/containers/Backups'\nexport * from '@modules/containers/Clusters'\nexport * from '@modules/containers/Dashboard'\nexport * from '@modules/containers/Datastores'\nexport * from '@modules/containers/Files'\nexport * from '@modules/containers/Groups'\nexport * from '@modules/containers/Guacamole'\nexport * from '@modules/containers/Hosts'\nexport * from '@modules/containers/Images'\nexport * from '@modules/containers/Login'\nexport * from '@modules/containers/MarketplaceApps'\nexport * from '@modules/containers/Marketplaces'\nexport * from '@modules/containers/Providers'\nexport * from '@modules/containers/Provisions'\nexport * from '@modules/containers/SecurityGroups'\nexport * from '@modules/containers/ServiceTemplates'\nexport * from '@modules/containers/Services'\nexport * from '@modules/containers/Settings'\nexport * from '@modules/containers/Support'\nexport * from '@modules/containers/TestApi'\nexport * from '@modules/containers/TestForm'\nexport * from '@modules/containers/Users'\nexport * from '@modules/containers/VDCs'\nexport * from '@modules/containers/VnTemplates'\nexport * from '@modules/containers/VirtualMachines'\nexport * from '@modules/containers/VirtualNetworks'\nexport * from '@modules/containers/VirtualRouterTemplates'\nexport * from '@modules/containers/VirtualRouters'\nexport * from '@modules/containers/VmGroups'\nexport * from '@modules/containers/VmTemplates'\nexport * from '@modules/containers/WebMKS'\nexport * from '@modules/containers/Zones'\n```\n\n----------------------------------------\n\nTITLE: Setting Hardcoded Values in OpenNebula VM Template\nDESCRIPTION: Demonstrates setting a hardcoded value for the SET_HOSTNAME variable within an OpenNebula VM template.  This directly assigns the string \"MAINHOST\" to the variable.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_18\n\nLANGUAGE: text\nCODE:\n```\nSET_HOSTNAME   = \"MAINHOST\"\n```\n\n----------------------------------------\n\nTITLE: Show Image Information (oneimage show) After Restore\nDESCRIPTION: This command displays information about the newly restored image, including its ID, name (derived from the VM and snapshot ID), user, group, datastore, type, registration time, persistence, source, and path. This verifies the image was created successfully.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage show\n```\n\n----------------------------------------\n\nTITLE: Copy Container Module Files\nDESCRIPTION: These commands copy the `Users` directory and the webpack configuration file from the original `ContainersModule` to the newly created `customContainers` directory. This provides a starting point for the new module, allowing it to inherit the basic structure and configuration of the original.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# Copying the Users directory\ncp -r src/modules/containers/Users src/modoules/customContainers \n\n# Copying containers webpack config for reference\ncp src/modules/containers/webpack.config.prod.containers.js src/modules/customContainers/webpack.config.prod.customcontainers.js\n\n# We'll also create a index.js file which will expose our new component\ntouch src/modules/customContainers/index.js \n```\n\n----------------------------------------\n\nTITLE: Cloning the OneDeploy Repository\nDESCRIPTION: This command clones the OneDeploy repository from GitHub.  This repository contains the Ansible playbooks and other necessary files for deploying OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/OpenNebula/one-deploy.git\n```\n\n----------------------------------------\n\nTITLE: Change Directory to FireEdge\nDESCRIPTION: Navigates to the FireEdge directory within the cloned OpenNebula repository. This directory contains the source code for the Sunstone web interface.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncd ./one/src/fireedge\n```\n\n----------------------------------------\n\nTITLE: Changing Object Body Content\nDESCRIPTION: The 'onedb change-body' command updates the body content of OpenNebula objects. It supports filtering by ID, XPath, or simple expressions. Values can be changed, appended, or deleted.  Supported object types are vm, host, vnet, image, cluster, document, group, marketplace, marketplaceapp, secgroup, template, vrouter or zone.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_16\n\nLANGUAGE: text\nCODE:\n```\n$ onedb change-body vm --expr UNAME=johndoe '/VM/TEMPLATE/NIC[NETWORK=\"service\"]/NETWORK' new_network\n```\n\nLANGUAGE: text\nCODE:\n```\n$ onedb change-body vm '/VM/TEMPLATE/DISK/CACHE' --delete --dry\n```\n\nLANGUAGE: text\nCODE:\n```\n$ onedb change-body vm --expr LCM_STATE=8 '/VM/TEMPLATE/DISK/CACHE' --delete\n```\n\nLANGUAGE: text\nCODE:\n```\n$ onedb change-body vm --expr LCM_STATE=8 '/VM/TEMPLATE/DISK/CACHE' default --append\n```\n\n----------------------------------------\n\nTITLE: OpenNebula VM Template Example in XML\nDESCRIPTION: This example shows a simple OpenNebula VM template defined in XML. It includes the VM name, CPU count, memory size, and disk configurations using both IMAGE_ID and IMAGE/IMAGE_UNAME combinations.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<TEMPLATE>\n  <NAME>test_vm</NAME>\n  <CPU>2</CPU>\n  <MEMORY>1024</MEMORY>\n  <DISK>\n    <IMAGE_ID>2</IMAGE_ID>\n  </DISK>\n  <DISK>\n    <IMAGE>Data</IMAGE>\n    <IMAGE_UNAME>oneadmin</IMAGE_UNAME>\n  </DISK>\n</TEMPLATE>\n```\n\n----------------------------------------\n\nTITLE: Error Creating Domain from Deployment\nDESCRIPTION: This code snippet showcases an error encountered when creating a domain from a deployment file with an invalid NUMA configuration. Specifically, it highlights the failure due to a memory-backend-ram having size '0', which is unsupported. The error message also includes an internal error from QEMU.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_25\n\nLANGUAGE: text\nCODE:\n```\nerror: Failed to create domain from deployment.0\nerror: internal error: process exited while connecting to monitor:  qemu-system-x86_64: -object memory-backend-ram,id=ram-node1,size=0,host-nodes=0,policy=bind: property 'size' of memory-backend-ram doesn't take value '0'\n```\n\n----------------------------------------\n\nTITLE: User Login with X.509 Authentication\nDESCRIPTION: This command shows how a user can log in to OpenNebula using X.509 authentication. It requires the username, the --x509 flag, the certificate file, and the key file.  It generates a login token stored in $ONE_AUTH, which defaults to $HOME/.one/one_auth. The token has a default expiration time of 10 hours, which can be changed with the --time option.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\noneuser login johndoe --x509 --cert newcert.pem --key newkey.pem\n```\n\n----------------------------------------\n\nTITLE: Recovering a OneKE Service with OneFlow in Bash\nDESCRIPTION: This command is used to terminate a OneKE service that is stuck in the DEPLOYING state and cannot be deleted through the standard `delete` operation.  It utilizes the `oneflow recover` command with the `--delete` option, requiring the service ID as input. This forces the termination, allowing for re-instantiation of the service.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\noneflow recover --delete <service_ID>\n```\n\n----------------------------------------\n\nTITLE: Define Shared Dependencies (JavaScript)\nDESCRIPTION: This JavaScript code defines the shared dependencies for the module, allowing it to access and utilize common libraries like `react` without bundling them directly. The `sharedDeps` function imports the `package.json` file to determine dependency versions and configures the shared dependencies with options like `singleton`, `eager`, and `requiredVersion`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_16\n\nLANGUAGE: javascript\nCODE:\n```\nconst deps = require('../../package.json').dependencies\n\nconst sharedDeps = ({ eager = false } = {}) => ({\n  react: {\n    singleton: true,\n    eager,\n    requiredVersion: deps.react,\n  },\n  // Add other dependencies here as needed\n})\n\nmodule.exports = sharedDeps\n```\n\n----------------------------------------\n\nTITLE: History Record Error Message (None)\nDESCRIPTION: Example error message displayed by `onedb fsck` when a history record for a VM is not closed (etime = 0). This indicates a problem with accounting or showback.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_10\n\nLANGUAGE: none\nCODE:\n```\n[UNREPAIRED] History record for VM <<vid>> seq # <<seq>> is not closed (etime = 0)\n```\n\n----------------------------------------\n\nTITLE: Create User for X.509 Authentication (CLI)\nDESCRIPTION: This command creates a new OpenNebula user configured for X.509 certificate authentication.  Replace `johndoe` and the DN with the correct values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\noneuser create johndoe \"/C=ES/O=ONE/OU=DEV/CN=clouduser\" --driver x509\n```\n\n----------------------------------------\n\nTITLE: Example lscpu Output - NUMA Topology\nDESCRIPTION: This is the `lscpu` output for the VM with the NUMA topology configured. It shows 2 NUMA nodes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_8\n\nLANGUAGE: text\nCODE:\n```\n# lscpu\n...\nCPU(s):                8\nOn-line CPU(s) list:   0-7\nThread(s) per core:    2\nCore(s) per socket:    2\nSocket(s):             2\nNUMA node(s):          2\n...\n```\n\n----------------------------------------\n\nTITLE: Listing hosts to check attributes - Bash\nDESCRIPTION: This snippet shows the usage of `onehost list` to display a list of hosts along with their cluster and resource allocation information. This is helpful to verify the attributes of hosts, such as CPU, memory, and the cluster they belong to, before setting scheduling requirements.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/overview.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nonehost list\n  ID NAME            CLUSTER   RVM      ALLOCATED_CPU      ALLOCATED_MEM STAT\n   1 host01          cluster_a   0       0 / 200 (0%)     0K / 3.6G (0%) on\n   2 host02          cluster_a   0       0 / 200 (0%)     0K / 3.6G (0%) on\n   3 host03          cluster_b   0       0 / 200 (0%)     0K / 3.6G (0%) on\n```\n\n----------------------------------------\n\nTITLE: Showing Host Information in OpenNebula\nDESCRIPTION: This snippet shows how to display detailed information about a specific host using the `onehost show` command.  It displays the host ID, name, cluster, state, and monitoring information, including the probe version.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost show 0\nHOST 0 INFORMATION\nID                    : 0\n[...]\nMONITORING INFORMATION\nVERSION=\"|release|\"\n[...]\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Datastore Information Structure\nDESCRIPTION: This code snippet demonstrates the structure of datastore information collected by OpenNebula monitoring probes.  It shows the used, total, and free space for both the datastore location and individual datastores, along with their respective IDs.  The DATASTORE LOCATION is the path where the datastores are mounted, typically /var/lib/one/datastores.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-im.rst#_snippet_4\n\nLANGUAGE: None\nCODE:\n```\nDS_LOCATION_USED_MB=1\nDS_LOCATION_TOTAL_MB=12639\nDS_LOCATION_FREE_MB=10459\nDS = [\n  ID = 0,\n  USED_MB = 1,\n  TOTAL_MB = 12639,\n  FREE_MB = 10459\n]\nDS = [\n  ID = 1,\n  USED_MB = 1,\n  TOTAL_MB = 12639,\n  FREE_MB = 10459\n]\nDS = [\n  ID = 2,\n  USED_MB = 1,\n  TOTAL_MB = 12639,\n  FREE_MB = 10459\n]\n```\n\n----------------------------------------\n\nTITLE: Setting RAW attribute for LXC in OpenNebula\nDESCRIPTION: This snippet shows how to use the RAW attribute to pass hypervisor-specific configurations to LXC containers. It sets boot.autostart to true, ensuring the container starts automatically, and limits the number of processes to 10000.  This allows customization of LXC container settings beyond the standard OpenNebula template attributes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_37\n\nLANGUAGE: text\nCODE:\n```\nRAW = [\n    type = \"lxc\",\n    data = \"boot.autostart\": \"true\", \"limits.processes\": \"10000\"\n]\n```\n\n----------------------------------------\n\nTITLE: Monitoring Message Structure\nDESCRIPTION: Defines the general structure of monitoring messages in OpenNebula. It consists of the message type, ID, result, timestamp, and payload.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-im.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nMESSAGE_TYPE ID RESULT TIMESTAMP PAYLOAD\n```\n\n----------------------------------------\n\nTITLE: Downloading RHEL 9.x Context Package with wget\nDESCRIPTION: This command downloads the OpenNebula context package for RHEL 9.x (AlmaLinux/RockyLinux/Oracle Linux 9.x) and Fedora using wget, obtaining it from the OpenNebula GitHub releases page.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# wget https://github.com/OpenNebula/one-apps/releases/download/v|context_release|/one-context-|context_release|-1.el9.noarch.rpm\n```\n\n----------------------------------------\n\nTITLE: Start FireEdge Server\nDESCRIPTION: Starts the FireEdge server, making the Sunstone interface accessible in a web browser. By default it is accessible on http://localhost:2616/fireedge.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm run start\n```\n\n----------------------------------------\n\nTITLE: Create Custom Containers Directory\nDESCRIPTION: This command creates a new directory named `customContainers` inside the `src/modules` directory. The `-p` option ensures that parent directories are also created if they don't exist. This directory will house the source code for the new custom module.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p  src/modules/customContainers\n```\n\n----------------------------------------\n\nTITLE: List OpenNebula Hosts\nDESCRIPTION: This command lists the OpenNebula hosts in the system. It shows the host ID, name, cluster, and resource allocation information. Requires the OpenNebula CLI tools to be installed and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost list\n  ID NAME                  CLUSTER    TVM      ALLOCATED_CPU      ALLOCATED_MEM STAT\n   5 host03                onprem-clu   0       0 / 200 (0%)     0K / 3.8G (0%) on\n   4 host02                onprem-clu   0       0 / 200 (0%)     0K / 3.8G (0%) on\n   3 host01                onprem-clu   0       0 / 200 (0%)     0K / 3.8G (0%) on\n```\n\n----------------------------------------\n\nTITLE: Defining a Vector Attribute in XML Template\nDESCRIPTION: Illustrates the XML syntax for defining a vector attribute within an OpenNebula VM template. Each sub-attribute within the vector is represented as a nested XML element.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<NAME>\n  <NAME1>VALUE1</NAME1>\n  <NAME2>VALUE2</NAME2>\n</NAME>\n```\n\n----------------------------------------\n\nTITLE: Showing Hook Execution Record Using the CLI\nDESCRIPTION: This example shows how to retrieve detailed information about a specific hook execution using the ``onehook show`` command with the ``-e`` option. It retrieves the execution ID, timestamp, command, and arguments.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ onehook show 0 -e 0\n  HOOK 0 INFORMATION\n  ID                : 0\n  NAME              : hook-vm\n  TYPE              : state\n  LOCK              : None\n\n  HOOK EXECUTION RECORD\n  EXECUTION ID      : 0\n  TIMESTAMP         : 09/23 15:10:38\n  COMMAND           : /var/lib/one/remotes/hooks/vm-pending.rb PFZNPgogIDxJR...8+CjwvVk0+ pending\n  ARGUMENTS         :\n  <VM>\n  <ID>0</ID>\n  <UID>0</UID>\n  <GID>0</GID>\n  <UNAME>oneadmin</UNAME>\n  <GNAME>oneadmin</GNAME>\n  <NAME>test</NAME>\n```\n\n----------------------------------------\n\nTITLE: LXC Profile Configuration for Privileged Containers\nDESCRIPTION: This snippet defines the LXC profile configuration parameters for privileged containers. It includes settings for mounting, capabilities, cgroup devices, and more, enhancing the security of the container. This configuration is located in **/var/lib/one/remotes/etc/vmm/lxc/profiles/profile_privileged** on the frontend.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_driver.rst#_snippet_0\n\nLANGUAGE: lxc\nCODE:\n```\nlxc.mount.entry = 'mqueue dev/mqueue mqueue rw,relatime,create=dir,optional 0 0'\nlxc.cap.drop = 'sys_time sys_module sys_rawio'\nlxc.mount.auto = 'proc:mixed'\nlxc.mount.auto = 'sys:mixed'\nlxc.cgroup.devices.deny = 'a'\nlxc.cgroup.devices.allow = 'b *:* m'\nlxc.cgroup.devices.allow = 'c *:* m'\nlxc.cgroup.devices.allow = 'c 136:* rwm'\nlxc.cgroup.devices.allow = 'c 1:3 rwm'\nlxc.cgroup.devices.allow = 'c 1:5 rwm'\nlxc.cgroup.devices.allow = 'c 1:7 rwm'\nlxc.cgroup.devices.allow = 'c 1:8 rwm'\nlxc.cgroup.devices.allow = 'c 1:9 rwm'\nlxc.cgroup.devices.allow = 'c 5:0 rwm'\nlxc.cgroup.devices.allow = 'c 5:1 rwm'\nlxc.cgroup.devices.allow = 'c 5:2 rwm'\nlxc.cgroup.devices.allow = 'c 10:229 rwm'\nlxc.cgroup.devices.allow = 'c 10:200 rwm'\n```\n\n----------------------------------------\n\nTITLE: Creating Image Datastore via CLI\nDESCRIPTION: This snippet demonstrates how to create an image datastore using the OpenNebula command-line interface (CLI). It takes the 'ds.conf' file (containing the template) as input and creates the datastore.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/local_ds.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n$ onedatastore create ds.conf\nID: 100\n```\n\n----------------------------------------\n\nTITLE: Remove Frontend from HA (Shell)\nDESCRIPTION: This command removes the failing frontend from the OpenNebula High Availability (HA) configuration.  This must be executed on the leader node. Replace <zone_id> and <server_id> with appropriate values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/replace_failing_fe.rst#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nonezone server-del <zone_id> <server_id>\n```\n\n----------------------------------------\n\nTITLE: Downloading Windows Context Package with PowerShell\nDESCRIPTION: This PowerShell command downloads the OpenNebula context package for Windows and saves it to C:\\. It uses the Net.WebClient object to download the file from the OpenNebula GitHub releases page.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_8\n\nLANGUAGE: powershell\nCODE:\n```\n(New-Object Net.WebClient).DownloadFile(\"https://github.com/OpenNebula/one-apps/releases/download/v|context_release|/one-context-|context_release|.msi\", \"C:\\one-context-|context_release|.msi\")\n```\n\n----------------------------------------\n\nTITLE: Get hostname from parameter - Shell\nDESCRIPTION: This snippet uses the `arg_host` function from `scripts_common.sh` to extract the hostname part from a given parameter, storing it in the `SRC_HOST` variable.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nSRC_HOST=`arg_host $SRC`\n```\n\n----------------------------------------\n\nTITLE: Reference Image ID in Template Definition (YAML)\nDESCRIPTION: This snippet demonstrates how to reference an image ID within a virtual machine template definition in a OneProvision YAML file.  The `disk.image_id` uses the `${image.test_image.id}` syntax to dynamically reference the created image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nimages:\n  - name: \"test_image\"\n    ds_id: 1\n    size: 2048\n\ntemplates:\n  - name: \"test_template\"\n    memory: 1\n    cpu: 1\n    disk:\n      - image_id: ${image.test_image.id}\n```\n\n----------------------------------------\n\nTITLE: Seeing Host Template as Dictionary\nDESCRIPTION: This snippet demonstrates how to get host template information and convert it to a dictionary for easier access. Requires a valid `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nhost = one.hostpool.info().HOST[0]\ndict(host.TEMPLATE)\n```\n\n----------------------------------------\n\nTITLE: Displaying Scheduled Actions with Charters\nDESCRIPTION: This example shows the output of the `onevm show` command, demonstrating scheduled actions created through charters. The `*` in front of the ID indicates that the warning time has passed for that action.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_38\n\nLANGUAGE: bash\nCODE:\n```\nSCHEDULED ACTIONS\nID     ACTION     ARGS    SCHEDULED        REPEAT            END  STATUS\n*0  suspend          -  01/01 03:00                               Next in 1.25 hours\n 1  terminate        -  15/01 03:00                               Next in 14 days\n```\n\n----------------------------------------\n\nTITLE: Verify Prometheus and Exporters are Running\nDESCRIPTION: Uses `ss` and `grep` to check if Prometheus and the exporters are listening on the expected ports (9925, 9100, 9090).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# ss -tapn | grep 'LISTEN.*\\(9925\\|9100\\|9090\\)'\nLISTEN    0      100          0.0.0.0:9925       0.0.0.0:*     users:((\"ruby\",pid=32402,fd=7))\nLISTEN    0      4096               *:9090             *:*     users:((\"prometheus\",pid=35494,fd=7))\nLISTEN    0      4096               *:9100             *:*     users:((\"node_exporter\",pid=32507,fd=3))\n```\n\n----------------------------------------\n\nTITLE: Basic AddressRange Definition Template\nDESCRIPTION: This code snippet shows a basic AddressRange definition returned by the register_address_range action. It includes IPAM_MAD, TYPE, IP, and SIZE attributes in template format.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-ipam.rst#_snippet_1\n\nLANGUAGE: template\nCODE:\n```\nAR = [\n      IPAM_MAD = \"dummy\",\n      TYPE = \"IP4\",\n      IP   = \"10.0.0.1\",\n      SIZE = \"255\"\n    ]\n```\n\n----------------------------------------\n\nTITLE: Export XML Import Info\nDESCRIPTION: This XML snippet shows the structure of an `IMPORT_INFO` element used when exporting data for import into OpenNebula. It includes tags for source, MD5 checksum, size, format, dispose action, and the command used for disposal. The CDATA sections allow for inclusion of special characters or markup.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_14\n\nLANGUAGE: xml\nCODE:\n```\n<IMPORT_INFO>\n  <IMPORT_SOURCE><![CDATA[<src>]]></IMPORT_SOURCE>\n  <MD5><![CDATA[<md5sum>]]></MD5>\n  <SIZE><![CDATA[<size>]]></SIZE>\n  <FORMAT><![CDATA[<format>]]></FORMAT>\n  <DISPOSE><dispose></DISPOSE>\n  <DISPOSE_CMD><<![CDATA[<dispose command>]]>/DISPOSE_CMD>\n</IMPORT_INFO>\n```\n\n----------------------------------------\n\nTITLE: Example HTTP POST request and response\nDESCRIPTION: This snippet shows an example HTTP POST request sent to the `/service_template` endpoint and the corresponding 400 Bad Request response. The request fails because the 'cardinality' value for the 'worker' role is not greater than or equal to 'min_vms'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_1\n\nLANGUAGE: HTTP\nCODE:\n```\n> POST /service_template HTTP/1.1\n> User-Agent: curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.14.0.0 zlib/1.2.3 libidn/1.18 libssh2/1.4.2\n> Host: onflow.server:2474\n>\n< HTTP/1.1 400 Bad Request\n< Content-Type: text/html;charset=utf-8\n< Content-Type:application/json;charset=utf-8\n< Content-Length: 40\n<\n{\n  \"error\": {\n    \"message\": \"Role 'worker' 'cardinality' must be greater than or equal to 'min_vms'\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying VM information with automatic requirements - Bash\nDESCRIPTION: This code snippet demonstrates how to display a VM's information using the `onevm show` command, which includes the automatic requirements added by OpenNebula. These requirements ensure that the VM uses compatible resources from the correct Cluster. In this case, the VM requires resources from cluster ID 100.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/overview.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nonevm show 0\n[...]\nAUTOMATIC_REQUIREMENTS=\"CLUSTER_ID = 100\"\n```\n\n----------------------------------------\n\nTITLE: Backing Up Federated Tables Bash\nDESCRIPTION: This command creates a backup of the federated tables in the OpenNebula database.  It is used before adding a new slave zone to ensure data consistency.  The -s option specifies the storage type and related parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onedb backup --federated -s /var/lib/one/one.db\nSqlite database backup of federated tables stored in /var/lib/one/one.db_federated_2017-6-15_8:52:51.bck\nUse 'onedb restore' to restore the DB.\n```\n\n----------------------------------------\n\nTITLE: XML Plan Example\nDESCRIPTION: This XML snippet demonstrates an example plan with multiple actions. Each action defines an operation to be performed on a specific VM, including deployment, migration, and poweroff. The deploy action includes NIC configurations with Network IDs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-sched.rst#_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<PLAN>\n    <ID>-1</ID>\n    <ACTION>\n        <VM_ID>23</VM_ID>\n        <OPERATION>deploy</OPERATION>\n        <HOST_ID>12</HOST_ID>\n        <DS_ID>100</DS_ID>\n        <NIC>\n        <NIC_ID>0</NIC_ID>\n        <NETWORK_ID>101</NETWORK_ID>\n        </NIC>\n        <NIC>\n        <NIC_ID>1</NIC_ID>\n        <NETWORK_ID>100</NETWORK_ID>\n        </NIC>\n    </ACTION>\n    <ACTION>\n        <VM_ID>24</VM_ID>\n        <OPERATION>migrate</OPERATION>\n        <HOST_ID>15</HOST_ID>\n        <DS_ID>200</DS_ID>\n    </ACTION>\n    <ACTION>\n        <VM_ID>25</VM_ID>\n        <OPERATION>poweroff</OPERATION>\n    </ACTION>\n</PLAN>\n```\n\n----------------------------------------\n\nTITLE: Testing OneGate Connectivity (bash)\nDESCRIPTION: This command shows how to test OneGate connectivity from within a deployed guest Virtual Machine by executing the `onegate vm show` command. This verifies that the VM can communicate with the OneGate service.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onegate vm show\n```\n\n----------------------------------------\n\nTITLE: Showing System Datastore Information in Bash\nDESCRIPTION: This command displays detailed information about the system datastore. The example shows the details for datastore named 'system'. The output includes general information, capacity, generic attributes (from DATASTORE TEMPLATE), and a list of images stored in the datastore. Note that System datastores typically do not have images registered in them.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/datastores.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore show system\n```\n\n----------------------------------------\n\nTITLE: Sync OpenNebula Hosts\nDESCRIPTION: This command synchronizes the virtualization, storage, and networking drivers on the OpenNebula hosts. It is executed as the `oneadmin` user.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_11\n\nLANGUAGE: Bash\nCODE:\n```\nonehost sync\n```\n\n----------------------------------------\n\nTITLE: Get Virtual Router Information via OneGate API\nDESCRIPTION: This curl command retrieves information about the Virtual Router using the OneGate API. It includes X-ONEGATE-TOKEN and X-ONEGATE-VMID in the header for authorization. The endpoint is /vrouter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X \"GET\" \"${ONEGATE_ENDPOINT}/vrouter\" \\\n    --header \"X-ONEGATE-TOKEN: `cat token.txt`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\"\n\n{\n  \"VROUTER\": {\n      \"NAME\": \"vr\",\n      \"ID\": \"0\",\n      \"VMS\": {\n      \"ID\": [\n          \"1\"\n      ]\n      },\n      \"TEMPLATE\": {\n      \"NIC\": [\n          {\n          \"NETWORK\": \"vnet\",\n          \"NETWORK_ID\": \"0\",\n          \"NIC_ID\": \"0\"\n          }\n      ],\n      \"TEMPLATE_ID\": \"0\"\n      }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monitoring Daemon Configuration in oned.conf (Bash)\nDESCRIPTION: This snippet configures the monitoring daemon settings in the OpenNebula oned.conf file. It defines the daemon's name, executable path, arguments (usually a configuration file), and number of threads. These settings control how OpenNebula gathers information from the cluster nodes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nIM_MAD = [\n      NAME          = \"monitord\",\n      EXECUTABLE    = \"onemonitord\",\n      ARGUMENTS     = \"-c monitord.conf\",\n      THREADS       = 8\n]\n```\n\n----------------------------------------\n\nTITLE: Setting Market Proxy Settings with Systemd\nDESCRIPTION: This snippet demonstrates how to set proxy settings for OpenNebula using systemd.  It involves editing the opennebula systemd service file to include environment variables for http_proxy, https_proxy, and no_proxy.  This ensures that the OpenNebula processes correctly use the specified proxy server for market operations.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/release_notes/known_issues.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n[Service]\nEnvironment=\"http_proxy=http://proxy_server\"\nEnvironment=\"https_proxy=http://proxy_server\"\nEnvironment=\"no_proxy=domain1,domain2\"\n```\n\n----------------------------------------\n\nTITLE: Complete AddressRange Definition Template\nDESCRIPTION: This code snippet shows a complete AddressRange definition returned by the register_address_range action. It includes IPAM_MAD, TYPE, IP, SIZE, and custom network attributes in template format.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-ipam.rst#_snippet_2\n\nLANGUAGE: template\nCODE:\n```\nAR = [\n      IPAM_MAD = \"dummy\",\n      TYPE = \"IP4\",\n      IP   = \"10.0.0.2\",\n      SIZE = \"200\",\n      NETWORK_ADDRESS   = \"10.0.0.0\",\n      NETWORK_MASK      = \"255.255.255.0\",\n      GATEWAY           = \"10.0.0.1\",\n      DNS               = \"10.0.0.1\",\n      IPAM_ATTR         = \"10.0.0.240\",\n      OTHER_IPAM_ATTR   = \".mydoamin.com\"\n    ]\n```\n\n----------------------------------------\n\nTITLE: OpenNebula API Hook Example (Ruby)\nDESCRIPTION: This Ruby script serves as an example API hook for OpenNebula. It decodes the API information passed as a base64-encoded XML string in ARGV[0], checks if the API call was successful, and prints a message indicating whether the user was created successfully or failed, along with the username. It requires the 'base64' and 'nokogiri' libraries.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_12\n\nLANGUAGE: ruby\nCODE:\n```\n# Hook template\n#\n# NAME = user-create\n# TYPE = api\n# COMMAND = \"user_create.rb\"\n# ARGUMENTS = \"$API\"\n# CALL = \"one.user.allocate\"\n\n#!/usr/bin/ruby\n\nrequire 'base64'\nrequire 'nokogiri'\n\n#api_info= Nokogiri::XML(Base64::decode64(STDIN.gets.chomp)) for reading from STDIN\napi_info = Nokogiri::XML(Base64::decode64(ARGV[0]))\n\nsuccess = api_info.xpath(\"/CALL_INFO/RESULT\").text.to_i == 1\nuname   = api_info.xpath('//PARAMETER[TYPE=\"IN\" and POSITION=2]/VALUE').text\n\nif !success\n    puts \"Failing to create user\"\n    exit -1\nend\n\nputs \"User #{uname} successfully created\"\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Daemon Log Format - File Based\nDESCRIPTION: This snippet shows the structure of OpenNebula Daemon log messages for a file-based logging system. It includes the date, zone ID, module, log level, and message body. This helps in understanding and parsing log files for debugging purposes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\ndate [Z<zone_id>][module][log_level]: message body\n```\n\n----------------------------------------\n\nTITLE: Build the Custom Containers Module\nDESCRIPTION: This command executes the `build:ccm` script defined in the `package.json` file.  It builds the customContainersModule, ensuring it's ready for deployment and use within the FireEdge ecosystem.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build:ccm # Building our customContainersModule\n> FireEdge@1.0.0 build:ccm\n> rimraf dist/modules/CustomContainersModule && BUILD_TARGET=remote webpack --config ./src/modules/customContainers/webpack.config.prod.customContainers.js\n```\n\n----------------------------------------\n\nTITLE: Copying User Tab Configuration (Bash)\nDESCRIPTION: This command copies an existing user tab configuration file to create a new one for the users and groups tab. This step is necessary to define a new view in Sunstone. The `usersgroups-tab.yaml` will then be modified.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\ncp /etc/one/fireedge/sunstone/admin/user-tab.yaml /etc/one/fireedge/sunstone/admin/usersgroups-tab.yaml\n```\n\n----------------------------------------\n\nTITLE: Defining VM Selection for Backup Job in OpenNebula\nDESCRIPTION: This snippet demonstrates how to define the VMs to be included in a Backup Job using the BACKUP_VMS attribute. The order of the VMs in the comma-separated list determines the sequence of backup operations.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nBACKUP_VMS = \"13,15,3\"\n```\n\n----------------------------------------\n\nTITLE: Set Image Wait Timeout in OneProvision (YAML)\nDESCRIPTION: This snippet demonstrates setting the wait timeout for an image creation in OneProvision.  It configures both `wait` and `wait_timeout` attributes within the `meta` section of the image definition.  This specifies waiting for the image to be ready and setting a timeout value in seconds.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nimages:\n  - name: \"test_image\"\n    ds_id: 1\n    size: 2048\n    meta:\n      wait: true\n      wait_timeout: 30\n```\n\n----------------------------------------\n\nTITLE: ACL Rule Example for Sunstone\nDESCRIPTION: This ACL rule example grants user #3 and members of group @100 the USE and MANAGE permissions for IMAGE and TEMPLATE resources in zone #0.  This rule is used to demonstrate ACL creation within Sunstone.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_10\n\nLANGUAGE: text\nCODE:\n```\n#3 IMAGE+TEMPLATE/@100 USE+MANAGE #0\n```\n\n----------------------------------------\n\nTITLE: Marketplace Monitor Action App Discovery Format\nDESCRIPTION: This snippet illustrates the format for monitoring with discovery, returning information for each Marketplace App. The information of each Appliance must be encoded in Base64 and assigned to the APP variable.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-market.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nAPP=\"TkFNRT0idHR5b...\"\nAPP=\"TkFNRT0idHR5b...\"\nAPP=\"TkFNRT0iQ2Fya...\"\nAPP=\"TkFNRT0iVGVzd...\"\nAPP=\"TkFNRT0iZ1VzZ...\"\nAPP=\"TkFNRT0iVnlhd...\"\nAPP=\"TkFNRT0iZ1VTR...\"\nAPP=\"TkFNRT0iZGVia...\"\n...\n```\n\n----------------------------------------\n\nTITLE: Listing One Files Bash\nDESCRIPTION: Lists the content of the /var/lib/one/.one directory which holds authorization files. These files will be copied to the slave nodes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/data_center_federation/config.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ ls -1 /var/lib/one/.one\none_auth\noneflow_auth\nonegate_auth\nsunstone_auth\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Datastores\nDESCRIPTION: This code snippet demonstrates how to list all datastores in OpenNebula using the 'onedatastore list' command. The output displays the ID, name, cluster, images count, type, datastore MAD, and transfer MAD for each datastore. Requires the 'onedatastore' command-line tool to be available and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/file_ds.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n> onedatastore list\n  ID NAME                      CLUSTER         IMAGES TYPE DS       TM\n   0 system                    -                    0 sys  -        dummy\n   1 default                   -                    0 img  dummy    dummy\n   2 files                     -                    0 fil  fs       local\n 100 kernels                   -                    0 fil  fs       local\n```\n\n----------------------------------------\n\nTITLE: Connecting to Edge Cluster via SSH - Bash\nDESCRIPTION: This command provides a template for connecting to an edge cluster via SSH. It requires specifying the location of the private key file, the user, and the edge cluster's public IP address. The user's identity file is typically stored in `/var/lib/one/.ssh/id_rsa` for `oneadmin` and `/var/lib/one/.ssh-provision/id_rsa` for `ubuntu`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/operation_basics/provisioning_edge_cluster.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nssh -i <location of private key file> -l <user> <edge cluster public IP>\n```\n\n----------------------------------------\n\nTITLE: Import Statements for UsersAndGroups Component (JavaScript)\nDESCRIPTION: This JavaScript code snippet shows the necessary import statements for the `UsersAndGroups` component. It imports components from Material-UI (`@mui/material`) and the `@ComponentsModule`.  The imports from `@ComponentsModule` use module federation to dynamically resolve dependencies at runtime. It adds Grid component from material UI and GroupsTable component from @ComponentsModule.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_17\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Chip, Stack, Typography, Grid } from '@mui/material' // Adding the Grid import\n\nimport {\n  Tr,\n  MultipleTags,\n  ResourcesBackButton,\n  GroupsTable, // Adding the GroupsTable import\n  UsersTable,\n  UserTabs,\n  SubmitButton,\n  TranslateProvider,\n} from '@ComponentsModule'\n```\n\n----------------------------------------\n\nTITLE: Monitoring Information in Table Format using onehost\nDESCRIPTION: This command retrieves the USED_MEMORY for host 0, converts the unit to GB, limits the number of data points to 10, and displays the data in a table format. The output shows the time and corresponding USED_MEMORY value.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost monitoring 0 USED_MEMORY --unit G --n 10 --table\n```\n\n----------------------------------------\n\nTITLE: Listing Available Services using REST API with curl\nDESCRIPTION: This snippet demonstrates how to list all available SERVICE resources in OpenNebula using the REST API with a GET request to the /service endpoint. It authenticates with username 'oneadmin' and password 'password'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2474/service -u 'oneadmin:password' -v\n```\n\n----------------------------------------\n\nTITLE: Installing Context Package on Alpine Linux with apk\nDESCRIPTION: This command installs the OpenNebula context package on Alpine Linux using apk. The `--allow-untrusted` option allows installation of packages from untrusted sources.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n# apk add --allow-untrusted one-context-[0-9]*apk\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration Snippet Example\nDESCRIPTION: This YAML snippet from `/etc/one/cli/oneimage.yaml` demonstrates the structure of configuration files used with OpenNebula.  It shows symbolized keys (`:ID`, `:desc`, `:size`, `:adjust`) and their relationships, as well as an example of nested hash structures. It's used to illustrate how to construct paths to address specific parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/diff_formats.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n:ID:\n  :desc: ONE identifier for the Image       # path 5\n  :size: 4\n  :adjust: true\n```\n\n----------------------------------------\n\nTITLE: List Existing OpenNebula Providers\nDESCRIPTION: This command lists the existing OpenNebula providers. It requires the OpenNebula CLI tool `oneprovider` to be installed and configured with appropriate credentials.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovider list\n  ID NAME                                                                    REGTIME\n   0 onprem                                                           04/28 11:31:34\n```\n\n----------------------------------------\n\nTITLE: Updating Translations\nDESCRIPTION: This command updates the translation files for a specific language using `sphinx-intl`. It reads the configuration from `source/conf.py`, the extracted message catalog from `build/locale`, and updates the .po files for the specified language `<lang>`.\nSOURCE: https://github.com/opennebula/docs/blob/master/README.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ sphinx-intl update -c source/conf.py -p build/locale -l <lang>\n```\n\n----------------------------------------\n\nTITLE: Creating a Kernels & Files Datastore\nDESCRIPTION: This example shows how to create a Kernels & Files Datastore using the 'onedatastore create' command with a configuration file.  The output shows the ID of the newly created datastore. Requires the 'onedatastore' command-line tool to be available and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/file_ds.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n> onedatastore create kernels_ds.conf\nID: 100\n```\n\n----------------------------------------\n\nTITLE: Configuring VM Template Tab in YAML\nDESCRIPTION: This YAML configuration file defines the settings and actions available in the VM Template tab of the Sunstone interface. It configures features, actions, filters, info tabs, and dialogs related to VM templates. This file is a crucial part of customizing the user interface to match specific needs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/fireedge_sunstone_views.rst#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# This file describes the information and actions available in the VM Template tab\n\n# Resource\n\nresource_name: \"VM-TEMPLATE\"\n\n# Features - Enable features on vm templates\n\nfeatures:\n\n  # True to hide the CPU setting in the dialogs\n  hide_cpu: false\n\n  # False to not scale the CPU.\n  # An integer value would be used as a multiplier as follows:\n  #     CPU = cpu_factor * VCPU\n  # Set it to 1 to tie CPU and vCPU.\n  cpu_factor: false\n\n# Actions - Which buttons are visible to operate over the resources\n\nactions:\n  create_dialog: true\n  import_dialog: true\n  update_dialog: true\n  instantiate_dialog: true\n  create_app_dialog: true\n  clone: true\n  delete: true\n  chown: true\n  chgrp: true\n  lock: true\n  unlock: true\n  share: true\n  unshare: true\n  edit_labels: true\n\n# Filters - List of criteria to filter the resources\n\nfilters:\n  label: true\n  owner: true\n  group: true\n  locked: true\n  vrouter: true\n\n\n# Info Tabs - Which info tabs are used to show extended information\n\ninfo-tabs:\n  info:\n    enabled: true\n    information_panel:\n      enabled: true\n      actions:\n        rename: true\n    permissions_panel:\n      enabled: true\n      actions:\n        chmod: true\n    ownership_panel:\n      enabled: true\n      actions:\n        chown: true\n        chgrp: true\n\n  template:\n    enabled: true\n\n# Dialogs - Enable or disable different actions on a dialog that it is enabled on the actions section\n\ndialogs:\n  instantiate_dialog:\n    information: true\n    ownership: true\n    capacity: true\n    vm_group: true\n    vcenter:\n      enabled: true\n      not_on:\n        - kvm\n        - lxc\n    network: true\n    storage: true\n    placement: true\n    sched_action: true\n    booting: true\n    backup: true\n  create_dialog:\n    ownership: true\n    capacity: true\n    showback: true\n    vm_group: true\n    vcenter:\n      enabled: true\n      not_on:\n        - kvm\n        - lxc\n    network: true\n    storage: true\n    placement: true\n    input_output: true\n    sched_action: true\n    context: true\n    booting: true\n    numa:\n      enabled: true\n      not_on:\n        - lxc\n    backup: true\n```\n\n----------------------------------------\n\nTITLE: Listing Clusters after Adding Resources with onecluster\nDESCRIPTION: This snippet lists the OpenNebula clusters after adding a virtual network and a datastore. It shows the updated output of the `onecluster list` command, including the updated NETS and DATASTORES counts for the 'production' cluster. The command takes no parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster list\n  ID NAME            HOSTS NETS  DATASTORES\n 100 production      1     1     1\n```\n\n----------------------------------------\n\nTITLE: Listing LVM Volumes in a Standard Datastore\nDESCRIPTION: This snippet shows the output of the `lvs` command, displaying the logical volumes (LVs) created for virtual machine disks in a standard (non-thin) LVM datastore. It illustrates the naming convention used for LVs based on VM ID and disk ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/lvm_drivers.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# lvs\n  LV          VG       Attr       LSize Pool Origin Data%  Meta%  Move\n  lv-one-10-0 vg-one-0 -wi------- 2.20g\n  lv-one-9-0  vg-one-0 -wi------- 2.20g\n```\n\n----------------------------------------\n\nTITLE: Installing Context Package on ALT Linux with apt-get\nDESCRIPTION: This command installs the OpenNebula context package on ALT Linux using apt-get. The `-fy` options force the installation and fix any dependency issues.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# apt-get install -fy one-context-[0-9]*alt*rpm\n```\n\n----------------------------------------\n\nTITLE: OpenNebula VLAN ID Configuration in oned.conf\nDESCRIPTION: This snippet shows how to configure the VLAN ID pool in OpenNebula's oned.conf file. The VLAN_IDS section defines the starting VLAN ID and any reserved VLAN IDs or ranges, ensuring proper VLAN allocation for Open vSwitch and 802.1Q networks.  Modifying this section allows reservation of VLANs and definition of the starting VLAN ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/openvswitch.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n#  VLAN_IDS: VLAN ID pool for the automatic VLAN_ID assigment. This pool\n#  is for 802.1Q networks (Open vSwitch and 802.1Q drivers). The driver\n#  will try first to allocate VLAN_IDS[START] + VNET_ID\n#     start: First VLAN_ID to use\n#     reserved: Comma separated list of VLAN_IDs or ranges. Two numbers\n#     separated by a colon indicate a range.\n\nVLAN_IDS = [\n    START    = \"2\",\n    RESERVED = \"0, 1, 4095\"\n]\n```\n\n----------------------------------------\n\nTITLE: Listing .one Directory Contents (Bash)\nDESCRIPTION: This command lists the contents of the `/var/lib/one/.one` directory, which typically contains authentication-related files, such as `sunstone_auth`. The `-1` option ensures each file is listed on a new line.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/cloud_auth.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nls -1 /var/lib/one/.one\n```\n\n----------------------------------------\n\nTITLE: Configuring Live and Cold Migrations in OpenNebula\nDESCRIPTION: This configuration controls the migration type and cold migration mode. `LIVE_RESCHEDS` determines if rescheduling uses live (1) or cold (0) migrations. `COLD_MIGRATE_MODE` specifies the type of cold migration: Save (0), Power off (1), or Hard power off (2).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/configuration.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nLIVE_RESCHEDS     = 0\nCOLD_MIGRATE_MODE = 0\n```\n\n----------------------------------------\n\nTITLE: Ceph S3 Marketplace Configuration\nDESCRIPTION: This snippet illustrates the configuration of a Ceph S3 Marketplace within OpenNebula.  It defines the necessary attributes such as ACCESS_KEY_ID, SECRET_ACCESS_KEY, BUCKET, ENDPOINT, FORCE_PATH_STYLE, MARKET_MAD, REGION, SIGNATURE_VERSION, and AWS. This configuration is used when creating a new Marketplace in OpenNebula that utilizes a Ceph S3 backend.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/private_marketplaces/market_s3.rst#_snippet_0\n\nLANGUAGE: conf\nCODE:\n```\nNAME              = S3CephMarket\nACCESS_KEY_ID     = \"*********************\"\nSECRET_ACCESS_KEY = \"*********************\"\nBUCKET            = \"opennebula-market\"\nENDPOINT          = \"http://ceph-gw.opennebula.org\"\nFORCE_PATH_STYLE  = \"YES\"\nMARKET_MAD        = s3\nREGION            = \"default\"\nSIGNATURE_VERSION = s3\nAWS               = no\n```\n\n----------------------------------------\n\nTITLE: Defining NIC Alias in OpenNebula\nDESCRIPTION: This snippet demonstrates how to define a NIC alias in OpenNebula. It shows how to specify the network and the parent NIC for the alias. The `NETWORK` attribute specifies the virtual network to use, and the `PARENT` attribute specifies the parent NIC to which the alias will be attached.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_20\n\nLANGUAGE: text\nCODE:\n```\nNIC_ALIAS = [ NETWORK = \"private\", PARENT = \"test\" ]\n```\n\n----------------------------------------\n\nTITLE: Copying a CA Certificate to the Trusted Directory\nDESCRIPTION: This command shows how to copy a CA certificate to the OpenNebula trusted certificates directory. It assumes that the CA certificate has been hashed and the hash is known. The certificate is renamed to <CA_hash>.0 before being copied, which is required for OpenNebula to recognize and trust the certificate during X.509 authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo cp cacert.pem /etc/one/auth/certificates/78d0bbd8.0\n```\n\n----------------------------------------\n\nTITLE: Listing Datastores with OpenNebula Provisioning Tool (oneprovision) - Bash\nDESCRIPTION: This command lists the datastores within the OpenNebula provision using the `oneprovision` tool. It must be executed on the Front-end node as either the `oneadmin` user or as `root`. The command displays information about each datastore including ID, name, size, availability, associated clusters, number of images, type, DS, TM, and status.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/operation_basics/provisioning_edge_cluster.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\noneprovision datastore list\n```\n\n----------------------------------------\n\nTITLE: Disable System Datastore OpenNebula\nDESCRIPTION: This command disables the system datastore, preventing new VMs from being deployed to it. Existing VMs in the datastore will continue to run. The `onedatastore show system` command displays the datastore's details, including its state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/datastores.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onedatastore disable system\n\n$ onedatastore show system\nDATASTORE 0 INFORMATION\nID             : 0\nNAME           : system\n...\nSTATE          : DISABLED\n...\n```\n\n----------------------------------------\n\nTITLE: Generate Limited Support Bundle with OneGather in Bash\nDESCRIPTION: This command generates a limited OpenNebula support bundle, focusing on frontend-specific information and excluding database dumps. It's suitable for addressing most support issues and needs to be run with elevated privileges (root or sudo).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/support.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo onegather\n```\n\n----------------------------------------\n\nTITLE: Checking Ubuntu Version via SSH\nDESCRIPTION: This snippet checks the Ubuntu version installed on two hosts (host01 and host02) by connecting via SSH and reading the `/etc/lsb-release` file.  It requires SSH access to the hosts with the `root` user.  The expected output is the Ubuntu distribution information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/edge_clusters/onprem_cluster.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh root@host01 cat /etc/lsb-release\nWarning: Permanently added 'host01,10.4.4.100' (ECDSA) to the list of known hosts.\n$ cat /etc/lsb-release\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=20.04\nDISTRIB_CODENAME=focal\nDISTRIB_DESCRIPTION=\"Ubuntu 20.04.3 LTS\"\n\n$  ssh root@host02 cat /etc/lsb-release\nWarning: Permanently added 'host02,10.4.4.101' (ECDSA) to the list of known hosts.\n$ cat /etc/lsb-release\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=20.04\nDISTRIB_CODENAME=focal\nDISTRIB_DESCRIPTION=\"Ubuntu 20.04.3 LTS\"\n```\n\n----------------------------------------\n\nTITLE: Creating the .ssh directory on the VNF node\nDESCRIPTION: This command creates the `.ssh` directory in the `root` user's home directory on the VNF node. This is a prerequisite for copying the SSH key in the next command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh root@1.2.3.4 install -m u=rwx,go= -d /root/.ssh/ # make sure ~/.ssh/ exists\n```\n\n----------------------------------------\n\nTITLE: Copy WHMCS Tenants Module Files (Bash)\nDESCRIPTION: This command copies the WHMCS Tenants Module files from the OpenNebula installation directory to the WHMCS modules directory. It recursively copies all files and directories, overwriting existing files during an update.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/whmcs_tenants/configure.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncp -rf /usr/share/one/whmcs/modules /path/to/web/root/whmcs/.\n```\n\n----------------------------------------\n\nTITLE: Installing Enchant Package\nDESCRIPTION: This command installs the `python3-enchant` package using the apt package manager. This package provides Python bindings for the Enchant library, which is used for spell checking. This is a prerequisite for running the spell checker.\nSOURCE: https://github.com/opennebula/docs/blob/master/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install python3-enchant\n```\n\n----------------------------------------\n\nTITLE: NUMA Topology Definition\nDESCRIPTION: This example demonstrates how to define a NUMA topology for a VM, exposing each socket as a separate NUMA node with its own local memory.  The `PIN_POLICY` attribute is used to enable NUMA topology.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nVCPU   = 8\nMEMORY = 1024\n\nTOPOLOGY = [ PIN_POLICY = thread, SOCKETS = 2, CORES = 2, THREADS = 2 ]\n```\n\n----------------------------------------\n\nTITLE: AlertManager Configuration - YAML\nDESCRIPTION: This YAML configuration defines the routing, receivers, and inhibit rules for the AlertManager.  It sets up a webhook receiver listening on a local port and defines rules for grouping alerts and inhibiting specific alerts based on severity.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/alerts.rst#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nroute:\n  group_by: ['alertname']\n  group_wait: 30s\n  group_interval: 5m\n  repeat_interval: 1h\n  receiver: 'web.hook'\nreceivers:\n  - name: 'web.hook'\n    webhook_configs:\n      - url: 'http://127.0.0.1:5001/'\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'dev', 'instance']\n```\n\n----------------------------------------\n\nTITLE: Granting Execute Permissions to MiniONE Script\nDESCRIPTION: This command makes the miniONE script executable. This is necessary before the script can be run.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_onprem.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nchmod +x minione\n```\n\n----------------------------------------\n\nTITLE: Instantiating a Template\nDESCRIPTION: This snippet instantiates a template with a given ID and name.  It creates a new VM based on the specified template. Requires a valid template ID and a `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\none.template.instantiate(0, \"my_VM\")\n```\n\n----------------------------------------\n\nTITLE: Checking IP Address inside Network Namespace\nDESCRIPTION: This command checks if the 'internal' end of the VETH device pair has been put inside the dedicated namespace. It displays the IP address configuration within the namespace.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ ip netns exec one_tproxy_br0 ip address\n1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n7: br0a@if8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000\n    link/ether 12:00:83:53:f4:3d brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 169.254.16.9/32 scope global br0a\n       valid_lft forever preferred_lft forever\n    inet6 fe80::1000:83ff:fe53:f43d/64 scope link\n       valid_lft forever preferred_lft forever\n```\n\n----------------------------------------\n\nTITLE: Changing directory to user's home\nDESCRIPTION: This command changes the current directory to the home directory of the user 'ubuntu'.  It's necessary to navigate to the directory where miniONE was copied.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_7\n\nLANGUAGE: Bash\nCODE:\n```\ncd ~ubuntu\n```\n\n----------------------------------------\n\nTITLE: Entering the Hatch Shell\nDESCRIPTION: This command activates the default Hatch virtual environment.  This ensures that the subsequent commands are executed within the context of the virtual environment, using the installed dependencies.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nhatch shell\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies with pip\nDESCRIPTION: This command installs the necessary Python packages for building the documentation using pip. It installs specific versions of Sphinx, sphinx_rtd_theme, sphinx-prompt, sphinxcontrib-spelling, pyyaml, and sphinx-substitution-extensions.  It's important to have Python and pip installed before running this command.\nSOURCE: https://github.com/opennebula/docs/blob/master/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install 'sphinx<7.3' sphinx_rtd_theme sphinx-prompt sphinxcontrib-spelling pyyaml sphinx-substitution-extensions\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Hosts\nDESCRIPTION: This command, executed as the `oneadmin` user, lists the OpenNebula hosts (hypervisors) in the cloud. It shows the status, CPU allocation, and memory allocation of each host. It depends on the OpenNebula CLI tool `onehost`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nonehost list\n```\n\n----------------------------------------\n\nTITLE: Change Template Permissions via CLI - OpenNebula\nDESCRIPTION: This command changes the permissions of template 0 using the 'onetemplate chmod' command. It demonstrates changing permissions to 664, 644, and 607 and verifying the changes using 'onetemplate show'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate show 0\n...\nPERMISSIONS\nOWNER          : um-\nGROUP          : u--\nOTHER          : ---\n\n$ onetemplate chmod 0 664 -v\nVMTEMPLATE 0: Permissions changed\n\n$ onetemplate show 0\n...\nPERMISSIONS\nOWNER          : um-\nGROUP          : um-\nOTHER          : u--\n\n$ onetemplate chmod 0 644 -v\nVMTEMPLATE 0: Permissions changed\n\n$ onetemplate show 0\n...\nPERMISSIONS\nOWNER          : um-\nGROUP          : u--\nOTHER          : u--\n\n$ onetemplate chmod 0 607 -v\nVMTEMPLATE 0: Permissions changed\n\n$ onetemplate show 0\n...\nPERMISSIONS\nOWNER          : um-\nGROUP          : ---\nOTHER          : uma\n```\n\n----------------------------------------\n\nTITLE: Example VXLAN Bridge and Link Configuration\nDESCRIPTION: This snippet provides an example configuration for VXLAN bridge and link parameters within the `/var/lib/one/remotes/etc/vnm/OpenNebulaNetwork.conf` file.  It demonstrates how to set options for creating the bridge (using `ip link add`) and the VXLAN interface, including parameters such as `udp6zerocsumrx` and `tos`. These settings will be applied when OpenNebula creates VXLAN networks.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vxlan.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Following options will be added when creating bridge. For example:\n#\n#     ip link add name <bridge name> type bridge stp_state 1\n#\n# :ip_bridge_conf:\n#     :stp_state: on\n\n\n# These options will be added to the ip link add command. For example:\n#\n#     sudo ip link add lxcbr0.260  type vxlan id 260 group 239.0.101.4 \\\n#       ttl 16 dev lxcbr0 udp6zerocsumrx  tos 3\n#\n:ip_link_conf:\n    :udp6zerocsumrx:\n    :tos: 3\n```\n\n----------------------------------------\n\nTITLE: onedb patch (Text)\nDESCRIPTION: Executes a patch to edit the timestamps of VM history records, used to calculate accounting and showback.  This is used to repair VM history end-time errors.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_11\n\nLANGUAGE: text\nCODE:\n```\n$ onedb patch -v /usr/lib/one/ruby/onedb/patches/history_times.rb\nVersion read:\nShared tables 4.11.80 : OpenNebula 5.0.1 daemon bootstrap\nLocal tables  4.13.85 : OpenNebula 5.0.1 daemon bootstrap\n\nSqlite database backup stored in /var/lib/one/one.db_2015-10-13_12:40:2.bck\nUse 'onedb restore' or copy the file back to restore the DB.\n\n  > Running patch /usr/lib/one/ruby/onedb/patches/history_times.rb\nThis tool will allow you to edit the timestamps of VM history records, used to calculate accounting and showback.\nVM ID: 1\nHistory sequence number: 0\n\nSTIME   Start time          : 2015-10-08 15:24:06 UTC\nPSTIME  Prolog start time   : 2015-10-08 15:24:06 UTC\n```\n\n----------------------------------------\n\nTITLE: Restarting Services (bash)\nDESCRIPTION: These commands show how to restart the `nginx`, `opennebula`, and `opennebula-gate` services using `systemctl`.  This ensures that the changes to the configuration files are applied and the services are running correctly. These commands require root privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl restart nginx\n# systemctl restart opennebula\n# systemctl restart opennebula-gate\n```\n\n----------------------------------------\n\nTITLE: Example of Multiple Patch Modes for OpenNebula Upgrade\nDESCRIPTION: This example demonstrates setting multiple patch modes for different files and versions during the OpenNebula upgrade process. It shows how to use the '--patch-modes' parameter multiple times to specify different patching strategies for different configuration files and versions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/conflicts.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade \\\n    --patch-modes skip:/etc/one/oned.conf \\\n    --patch-modes skip,replace:/etc/one/oned.conf:5.10.0 \\\n    --patch-modes force:/etc/one/fireedge/sunstone-views.yaml:5.6.0 \\\n    --patch-modes replace:/etc/one/fireedge-server.conf \\\n    --patch-modes skip:/etc/one/fireedge/sunstone/admin/acl-tab.yaml:5.4.1 \\\n    --patch-modes skip:/etc/one/fireedge/sunstone/admin/vm-tab.yaml:5.4.2 \\\n    --patch-modes skip:/etc/one/fireedge/sunstone/admin/vm-template-tab.yaml\n```\n\n----------------------------------------\n\nTITLE: Downloading RHEL 7.x Context Package with wget\nDESCRIPTION: This command downloads the OpenNebula context package for RHEL 7.x (CentOS/Oracle Linux 7.x) using wget. It retrieves the package from the OpenNebula GitHub releases page.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# wget https://github.com/OpenNebula/one-apps/releases/download/v|context_release|/one-context-|context_release|-1.el7.noarch.rpm\n```\n\n----------------------------------------\n\nTITLE: Obtaining JWT Token via cURL (Bash)\nDESCRIPTION: This bash code snippet demonstrates how to obtain a JWT (JSON Web Token) by making a POST request to the FireEdge API's authentication endpoint. It sends the user's username and password in a JSON payload to the API and retrieves the 'token' value from the response data, which can then be used for single sign-on.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_36\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X POST -H \"Content-Type: application/json\" \\\n$ -d '{ \"user\": \"username\", \"token\": \"password\" }' \\\n$ http://{fireedge}/fireedge/api/auth\n```\n\nLANGUAGE: text\nCODE:\n```\n{\"id\":200,\"message\":\"OK\",\"data\":{\"token\":\"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiIwIiwiYXVkIjoic2VydmVyYWRtaW46b25lYWRtaW4iLCJqdGkiOiJ2SU85ME91VUU5b1RNaXRRVytLYmNqRXZlS252Qnc5c2Ura1pPNlVRdmRjPSIsImlhdCI6MTY1MDI3NTQzMC45MzcsImV4cCI6MTY1MDI4NjIzMH0.AqJGLbCNG470PbjoI4yLqvKNOl1FR4Ui6YlK6pSZddQ\",\"id\":\"0\"}}\n```\n\n----------------------------------------\n\nTITLE: Striping Policy RANK Expression\nDESCRIPTION: This RANK expression implements the striping policy, which aims to maximize the resources available to VMs in a node. It prioritizes nodes with fewer running VMs to spread VMs across the cluster. It doesn't have any dependencies and is used directly in the OpenNebula scheduler configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/rank_scheduler.rst#_snippet_1\n\nLANGUAGE: OpenNebula\nCODE:\n```\nRANK = \"- RUNNING_VMS\"\n```\n\n----------------------------------------\n\nTITLE: Displaying sunstone_auth File Contents (Bash)\nDESCRIPTION: This command displays the contents of the `sunstone_auth` file located in the `/var/lib/one/.one` directory. This file typically contains the serveradmin's username and an encrypted password or secret key used for authentication between Sunstone and the OpenNebula daemon.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/cloud_auth.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncat /var/lib/one/.one/sunstone_auth\n```\n\n----------------------------------------\n\nTITLE: Equinix Metal Insufficient Capacity Error\nDESCRIPTION: This error message indicates that there is not enough hardware available at the specified Equinix Metal facility for the requested machine type. The solution is to select a different node type or Equinix Metal provider.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/equinix_provider.rst#_snippet_2\n\nLANGUAGE: none\nCODE:\n```\nThe facility ams1 has no provisionable c3.small.x86 servers matching your criteria\n```\n\n----------------------------------------\n\nTITLE: Defining OS Image Template in OpenNebula\nDESCRIPTION: This example shows how to define an OS image template in OpenNebula. It includes the image name, path, and a description of the image content and purpose. The NAME and PATH parameters are required, while DESCRIPTION provides additional information about the image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/img_template.rst#_snippet_0\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nNAME          = \"Ubuntu Web Development\"\nPATH          = /home/one_user/images/ubuntu_desktop.img\nDESCRIPTION   = \"Ubuntu 10.04 desktop for Web Development students.\nContains the pdf lessons and exercises as well as all the necessary\nprogramming tools and testing frameworks.\"\n```\n\n----------------------------------------\n\nTITLE: Get VM Information via OneGate API\nDESCRIPTION: This curl command retrieves information about the current virtual machine using the OneGate API.  It uses the X-ONEGATE-TOKEN and X-ONEGATE-VMID headers for authentication and specifies the /vm endpoint. The response is a JSON object containing details about the VM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X \"GET\" \"${ONEGATE_ENDPOINT}/vm\" \\\n    --header \"X-ONEGATE-TOKEN: `cat token.txt`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\"\n{  \n    \"VM\": {  \n        \"ID\": ...,  \n        \"NAME\": ...,  \n        \"TEMPLATE\": {  \n            \"NIC\": [  \n                {  \n                    \"IP\": ...,  \n                    \"IP6_LINK\": ...,  \n                    \"MAC\": ...,  \n                    \"NETWORK\": ...,  \n                },  \n                // more nics ...  \n            ]  \n        },  \n        \"USER_TEMPLATE\": {  \n            \"ROLE_NAME\": ...,  \n            \"SERVICE_ID\": ...,  \n            // more user template attributes  \n        }  \n    }  \n}\n```\n\n----------------------------------------\n\nTITLE: Chain-Loading OS Profiles in YAML\nDESCRIPTION: This YAML snippet shows how to chain-load profiles using the `OS_PROFILE` attribute. The `basic_profile.yaml` is modified to include the `windows_optimized` profile, allowing you to combine settings from both profiles. The value of `OS_PROFILE` should match the filename (excluding the .yaml extension) of the profile to be loaded.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/os_profile.rst#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# basic_profile.yaml\n\"General\":\n  NAME: \"Example profile\"\n  OS_PROFILE: \"windows_optimized\"\n  CPU: 4\n  VCPU: 4\n  MEMORY: 8\n  MEMORYUNIT: \"GB\"\n\n\"Advanced options\":\n  Backup:\n    BACKUP_CONFIG:\n     MODE: \"INCREMENT\"\n     INCREMENT_MODE: \"CBT\"\n     BACKUP_VOLATILE: \"Yes\"\n     FS_FREEZE: \"AGENT\"\n     KEEP_LAST: 7\n```\n\n----------------------------------------\n\nTITLE: Installing Context Package on RHEL 8.x with yum\nDESCRIPTION: These commands install the OpenNebula context package and its dependencies on RHEL 8.x (CentOS/AlmaLinux/Oracle Linux 8.x) using yum. It installs the EPEL repository, the one-context package, and enables the network service.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# yum install -y epel-release\n# yum install -y one-context-[0-9]*el8*rpm\n# systemctl enable network.service\n```\n\n----------------------------------------\n\nTITLE: Defining restricted attributes in oned.conf\nDESCRIPTION: This code snippet configures restricted VM attributes in `oned.conf`. This prevents users from modifying certain parameters like CPU, VPU and NIC when instantiating the template, enforcing resource control. Attributes are restricted at the VM level. \nDependencies: OpenNebula oned.conf\nInputs: None\nOutputs: The restricted attributes will prevent users from changing these parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_7\n\nLANGUAGE: none\nCODE:\n```\nVM_RESTRICTED_ATTR = \"CPU\"\nVM_RESTRICTED_ATTR = \"VPU\"\nVM_RESTRICTED_ATTR = \"NIC\"\n```\n\n----------------------------------------\n\nTITLE: Applying a Configuration Patch with the --all Flag\nDESCRIPTION: This example demonstrates using the `--all` flag with the `onecfg patch` command.  When `--all` is specified, the patch application process will only succeed if all changes within the patch can be applied successfully.  If any changes fail, the entire patch operation is rolled back, and an error message is displayed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg patch --verbose --format line --all /tmp/diff-oned2\n```\n\n----------------------------------------\n\nTITLE: Filtering Actions by Hypervisor (YAML)\nDESCRIPTION: This YAML configuration snippet demonstrates how to filter actions based on the hypervisor type for virtual machines within the OpenNebula Sunstone interface. Specifically, it shows how to enable the 'attach_disk' action for storage, but disable it when the hypervisor is 'lxc'.  This allows for hypervisor-specific configurations and feature availability.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_34\n\nLANGUAGE: yaml\nCODE:\n```\n# etc/sunstone/admin/vm-tab.yaml\nstorage:\n  enabled: true\n  actions:\n    attach_disk:\n      enabled: true\n      not_on:\n        - lxc\n```\n\n----------------------------------------\n\nTITLE: SSH Tunneling for Prometheus Access\nDESCRIPTION: This code snippet demonstrates how to set up an SSH tunnel to access a Prometheus instance running on a remote OpenNebula server.  The tunnel forwards the local port 9090 to the remote server's 9090 port, allowing Grafana to access Prometheus if they are on different machines.  Replace user@opennebula-server-running-prometheus with the correct username and server address.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/grafana.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh -L 9090:localhost:9090 user@opennebula-server-running-prometheus\n```\n\n----------------------------------------\n\nTITLE: Kubernetes Service and IngressRoute for nginx\nDESCRIPTION: This YAML defines a Kubernetes Service and IngressRoute to expose the nginx application. It creates a Service named `nginx` and an IngressRoute to route traffic to the nginx service on port 80. This relies on the Traefik ingress controller.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\nspec:\n  selector:\n    run: nginx\n  ports:\n    - name: http\n      protocol: TCP\n      port: 80\n      targetPort: 80\n---\n# In Traefik < 3.0.0 it used to be \"apiVersion: traefik.containo.us/v1alpha1\".\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: nginx\nspec:\n  entryPoints: [web]\n  routes:\n    - kind: Rule\n      match: Path(`/`)\n      services:\n        - kind: Service\n          name: nginx\n          port: 80\n          scheme: http\n```\n\n----------------------------------------\n\nTITLE: Validating Provision Template with oneprovision\nDESCRIPTION: This command validates the provided provision template. If the template is valid, the command returns an exit code of 0, indicating success. This check is essential before provisioning resources to ensure the template's correctness.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/cluster_operations.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nvalidate\n```\n\n----------------------------------------\n\nTITLE: Setting up VM Template with TOKEN attribute in OpenNebula (none)\nDESCRIPTION: This snippet shows how to configure a VM template in OpenNebula by setting the `CONTEXT/TOKEN` attribute to `YES`. This allows the VM to interact with the OneGate API and retrieve VM information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/onegate_usage.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nCPU     = \"0.5\"\nMEMORY  = \"1024\"\n\nDISK = [\n  IMAGE_ID = \"0\" ]\nNIC = [\n  NETWORK_ID = \"0\" ]\n\nCONTEXT = [\n  TOKEN = \"YES\" ]\n```\n\n----------------------------------------\n\nTITLE: Setting SSH Terminal Color Schema - bash\nDESCRIPTION: This code snippet demonstrates how to set the color scheme for an SSH terminal session in OpenNebula. It uses RGB values to define foreground, background, and specific color indices in the Xterm 256-color palette. It allows customization of the terminal's appearance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/end-user_web_interfaces/fireedge_sunstone.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nforeground: rgb:00/00/ff;\nbackground: rgb:ff/ff/ff;\ncolor9: rgb:80/00/80\n```\n\n----------------------------------------\n\nTITLE: Emulated TPM XML Configuration (Alternative)\nDESCRIPTION: This is another example of emulated TPM XML Configuration. Note: This snippet only includes the starting tag. It appears to be incomplete in the original documentation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_6\n\nLANGUAGE: xml\nCODE:\n```\n<devices>\n```\n\n----------------------------------------\n\nTITLE: Saving a VM Instance - OpenNebula\nDESCRIPTION: This command saves an existing VM instance by cloning the source Template and replacing the disks with copies of the current disks. It uses the onevm save command, requiring the VM ID, a name for the new VM copy, and the `--persistent` option to make the cloned images persistent. NIC interfaces are overwritten.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_instances.rst#_snippet_25\n\nLANGUAGE: shell\nCODE:\n```\n$ onevm save web_vm copy_of_web_vm --persistent\nTemplate ID: 26\n```\n\n----------------------------------------\n\nTITLE: Retrieving Showback Data using CLI with CSV Output\nDESCRIPTION: This command demonstrates how to retrieve showback information for a specific user (`cloud_user`) and output the data in CSV format, listing the year, month, VM ID, and cost. The `oneshowback list` command is used with the `--csv` and `--list` options to achieve this.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/showback.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n$ oneshowback list -u cloud_user --list YEAR,MONTH,VM_ID,COST --csv\nYEAR,MONTH,VM_ID,COST\n2015,10,4258,1824279.62\n2015,10,4265,433749.03\n2015,11,4258,34248600\n```\n\n----------------------------------------\n\nTITLE: Configuring VM_MAD in oned.conf (Text)\nDESCRIPTION: This snippet demonstrates how to configure the Virtual Machine Manager (VM_MAD) settings in the `oned.conf` file. It shows how to specify the driver name, executable, arguments, and other related parameters such as `keep_snapshots`, `live_resize`, and `support_shareable`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-vmm.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nVM_MAD = [\n        sunstone_name = \"KVM\",\n        name           = \"kvm\",\n        executable     = \"one_vmm_exec\",\n        arguments      = \"-t 15 -r 0 -i kvm\",\n        default        = \"vmm_exec/vmm_exec_kvm.conf\",\n        type           = \"kvm\",\n        keep_snapshots = \"no\",\n        live_resize    = \"yes\",\n        support_shareable  = \"yes\",\n    ]\n```\n\n----------------------------------------\n\nTITLE: Dumping System Datastore Information in XML\nDESCRIPTION: This XML snippet provides an example of a DS_DRIVER_ACTION_DATA structure containing information about a system datastore. It includes datastore metadata like IDs, permissions, paths, types, the associated clusters, storage capacity, and template configurations. It also contains datastore location and monitor vm disk information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_12\n\nLANGUAGE: xml\nCODE:\n```\n<DS_DRIVER_ACTION_DATA>\n    <DATASTORE>\n        <ID>0</ID>\n        <UID>0</UID>\n        <GID>0</GID>\n        <UNAME>oneadmin</UNAME>\n        <GNAME>oneadmin</GNAME>\n        <NAME>system</NAME>\n        <PERMISSIONS>\n            <OWNER_U>1</OWNER_U>\n            <OWNER_M>1</OWNER_M>\n            <OWNER_A>0</OWNER_A>\n            <GROUP_U>1</GROUP_U>\n            <GROUP_M>0</GROUP_M>\n            <GROUP_A>0</GROUP_A>\n            <OTHER_U>0</OTHER_U>\n            <OTHER_M>0</OTHER_M>\n            <OTHER_A>0</OTHER_A>\n        </PERMISSIONS>\n        <DS_MAD><![CDATA[-]]></DS_MAD>\n        <TM_MAD><![CDATA[qcow2]]></TM_MAD>\n        <BASE_PATH><![CDATA[/var/lib/one//datastores/0]]></BASE_PATH>\n        <TYPE>1</TYPE>\n        <DISK_TYPE>0</DISK_TYPE>\n        <STATE>0</STATE>\n        <CLUSTERS>\n            <ID>0</ID>\n        </CLUSTERS>\n        <TOTAL_MB>31998</TOTAL_MB>\n        <FREE_MB>12650</FREE_MB>\n        <USED_MB>17694</USED_MB>\n        <IMAGES></IMAGES>\n        <TEMPLATE>\n            <ALLOW_ORPHANS><![CDATA[NO]]></ALLOW_ORPHANS>\n            <DS_MIGRATE><![CDATA[YES]]></DS_MIGRATE>\n            <SHARED><![CDATA[YES]]></SHARED>\n            <TM_MAD><![CDATA[qcow2]]></TM_MAD>\n            <TYPE><![CDATA[SYSTEM_DS]]></TYPE>\n        </TEMPLATE>\n    </DATASTORE>\n    <DATASTORE_LOCATION>/var/lib/one//datastores</DATASTORE_LOCATION>\n    <MONITOR_VM_DISKS>1</MONITOR_VM_DISKS>\n</DS_DRIVER_ACTION_DATA>\n```\n\n----------------------------------------\n\nTITLE: Default Webpack Configuration (JavaScript)\nDESCRIPTION: This JavaScript code defines the default Webpack configuration file for a FireEdge module.  It configures module federation, shared dependencies, and other essential settings for compatibility with the Sunstone client.  The configuration includes settings for module name, entry point, output path, plugins, and loaders.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_28\n\nLANGUAGE: javascript\nCODE:\n```\nconst moduleName = '<ModuleName>' // This is how the module will be referenced\nconst path = require('path')\nconst { ModuleFederationPlugin } = require('webpack').container\nconst sharedDeps = require('../sharedDeps') // Dependencies shared between modules\nconst TerserPlugin = require('terser-webpack-plugin')\nconst ExternalRemotesPlugin = require('external-remotes-plugin')\nconst ONE_LOCATION = process.env.ONE_LOCATION\nconst ETC_LOCATION = ONE_LOCATION ? `${ONE_LOCATION}/etc` : '/etc'\n\n// The path to the remotes-config.json file, necessary in order to resolve cross-module dependencies when building.\nconst remotesConfigPath =\n  process.env.NODE_ENV === 'production'\n    ? `${ETC_LOCATION}/one/fireedge/sunstone/remotes-config.json`\n    : path.resolve(\n        __dirname,\n        '..',\n        '..',\n        '..',\n        'etc',\n        'sunstone',\n        'remotes-config.json'\n      )\n\nconst remotesConfig = require(remotesConfigPath)\n\nconst configuredRemotes = Object.entries(remotesConfig)\n  .filter(([_, { name }]) => name !== moduleName)\n  .reduce((acc, [module, { name }]) => {\n    acc[\n      `@${module}`\n    ] = `${name}@[window.__REMOTES_MODULE_CONFIG__.${module}.entry]`\n\n    return acc\n  }, {})\n\nmodule.exports = {\n  mode: 'production',\n  entry: path.resolve(__dirname, 'index.js'),\n  output: {\n    path: path.resolve(__dirname, '../../../', 'dist', 'modules', moduleName),\n    filename: '[name].bundle.js',\n    chunkFilename: '[contenthash].[id].js',\n    uniqueName: moduleName,\n    publicPath: 'auto',\n  },\n  plugins: [\n    new ModuleFederationPlugin({\n      name: moduleName,\n      filename: 'remoteEntry.js',\n      exposes: {\n        '.': path.resolve(__dirname, 'index.js'),\n      },\n      remotes: configuredRemotes,\n      shared: sharedDeps({ eager: false }),\n    }),\n    new ExternalRemotesPlugin(),\n  ],\n\n  optimization: {\n    minimizer: [new TerserPlugin({ extractComments: false })],\n    moduleIds: 'deterministic',\n    chunkIds: 'deterministic',\n  },\n  resolve: {\n    alias: {\n      '@modules': path.resolve(__dirname, '../'),\n    },\n  },\n  devtool: 'source-map',\n  stats: {\n    errorDetails: true,\n    warnings: true,\n  },\n  experiments: {\n    topLevelAwait: true,\n  },\n  module: {\n    rules: [\n      {\n        test: /\\.js$/,\n        use: 'babel-loader',\n        include: path.resolve(__dirname, '../../'),\n      },\n      {\n        test: /\\.(png|jpe?g|gif)$/i,\n        use: [\n          {\n            loader: 'file-loader',\n            options: {\n              name: '[path][name].[ext]',\n              outputPath: 'assets/images/',\n            },\n          },\n        ],\n      },\n    ],\n  },\n}\n```\n\n----------------------------------------\n\nTITLE: Example lscpu Output - Custom CPU Topology\nDESCRIPTION: This is the `lscpu` output for the VM with the custom CPU topology defined above. It shows 8 CPUs, 2 threads per core, 2 cores per socket, and 2 sockets.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n# lscpu\n...\nCPU(s):                8\nOn-line CPU(s) list:   0-7\nThread(s) per core:    2\nCore(s) per socket:    2\nSocket(s):             2\nNUMA node(s):          1\n...\n```\n\n----------------------------------------\n\nTITLE: Setting Action Limits for Hosts and Clusters\nDESCRIPTION: This configuration limits the number of deploy and migration actions. `MAX_ACTIONS_PER_HOST` defines the maximum scheduled actions per host. `MAX_ACTIONS_PER_CLUSTER` defines the maximum scheduled actions per cluster. These limits prevent resource overload.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/configuration.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nMAX_ACTIONS_PER_HOST    = 1\nMAX_ACTIONS_PER_CLUSTER = 30\n```\n\n----------------------------------------\n\nTITLE: Creating Service Template using CLI in Bash\nDESCRIPTION: Registers a JSON template file as a Service Template using the `oneflow-template create` command. The command takes the path to the JSON file as an argument. The ID of the created template is then displayed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ oneflow-template create /tmp/my_service.json\nID: 0\n```\n\n----------------------------------------\n\nTITLE: Datastore Driver Configuration - Bash\nDESCRIPTION: This configuration sets up the Datastore Driver, which manages the storage back-end. It specifies the path to the driver executable and arguments, including the number of threads and the datastore MADs and system datastore TM drivers to be used. The EXECUTABLE and ARGUMENTS parameters are essential for defining how OpenNebula interacts with the storage.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nDATASTORE_MAD = [\n        EXECUTABLE = \"one_datastore\",\n        ARGUMENTS  = \"-t 15 -d dummy,fs,lvm,ceph,dev,iscsi_libvirt,vcenter -s shared,local,ceph,fs_lvm\"\n    ]\n```\n\n----------------------------------------\n\nTITLE: Backing up OVMF firmware files in Linux\nDESCRIPTION: These commands back up the original OVMF firmware files before replacing them. The `mkdir` command creates a new directory called `backup_OVMF` inside `/usr/share`. The `mv` command then moves the `edk2`, `qemu`, and `OVMF` directories into the backup directory to preserve the original files.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncd /usr/share\nmkdir backup_OVMF\nmv edk2 qemu OVMF backup_OVMF/\n```\n\n----------------------------------------\n\nTITLE: Setting VM scheduling requirements for KVM and excluding Gold QoS - Bash\nDESCRIPTION: This code snippet sets the `SCHED_REQUIREMENTS` attribute to exclude Gold QoS Hosts and target KVM hypervisors.  The boolean expression `QOS != GOLD & HYPERVISOR = kvm` ensures that only hosts that are not associated with clusters with Gold QoS and are running the KVM hypervisor are considered for deployment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/overview.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nSCHED_REQUIREMENTS = \"QOS != GOLD & HYPERVISOR = kvm\"\n```\n\n----------------------------------------\n\nTITLE: Example User Environment Configuration (Bash)\nDESCRIPTION: This snippet showcases an example configuration for a user's environment within OpenNebula. It sets the ONE_XMLRPC variable and includes the contents of the .one/one_auth file, which contains the user's credentials. Proper filesystem permissions should be applied to the .one/one_auth file to protect the password.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/cli.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ tail ~/.bashrc\n\nONE_XMLRPC=http://localhost:2633/RPC2\n\nexport ONE_XMLRPC\n\n$ cat ~/.one/one_auth\nregularuser:password\n```\n\n----------------------------------------\n\nTITLE: Instantiating a template with incompatible cluster IDs - Bash\nDESCRIPTION: This code snippet shows an example of instantiating a VM template that contains resources from different clusters, leading to an error. The error message indicates that the VM requires resources from incompatible clusters, preventing the VM creation. Specifically, the disk requires CLUSTER 101 and the NIC requires CLUSTER 100.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/overview.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nonetemplate instantiate 0\n[TemplateInstantiate] Error allocating a new virtual machine. Incompatible cluster IDs.\nDISK [0]: IMAGE [0] from DATASTORE [1] requires CLUSTER [101]\nNIC [0]: NETWORK [1] requires CLUSTER [100]\n```\n\n----------------------------------------\n\nTITLE: OpenNebula Scheduler Configuration in oned.conf\nDESCRIPTION: This is a complete example of configuration settings from OpenNebula's `oned.conf` file for the scheduler. It includes settings for the scheduler driver, window, retry time, action limits, timeout, migration options, and DRS interval. These parameters control VM placement, resource allocation, and system optimization within OpenNebula.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/configuration.rst#_snippet_7\n\nLANGUAGE: ini\nCODE:\n```\nSCHED_MAD = [\n      EXECUTABLE = \"one_sched\",\n      ARGUMENTS  = \"-t 15 -p rank -o one_drs\"\n]\n\nSCHED_MAX_WND_TIME   = 10\nSCHED_MAX_WND_LENGTH = 7\n\nSCHED_RETRY_TIME = 60\n\nMAX_ACTIONS_PER_HOST    = 1\nMAX_ACTIONS_PER_CLUSTER = 30\n\nACTION_TIMEOUT = 300\n\nLIVE_RESCHEDS     = 0\nCOLD_MIGRATE_MODE = 0\n\nDRS_INTERVAL = -1\n```\n\n----------------------------------------\n\nTITLE: Fallback Context Installation using virt-customize\nDESCRIPTION: This snippet shows a fallback method for installing context packages on the first boot of the VM. It installs the epel-release package, copies the one-context RPM to the /tmp directory, installs the RPM on the first boot, and enables the network service with error handling.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/ova_management/import_ova.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nvirt-customize -q -a /tmp/vm-alma9/conversions/vm-alma9-sda --firstboot-install epel-release --copy-in /var/lib/one/context//one-context-6.10.0-3.el9.noarch.rpm:/tmp --firstboot-install /tmp/one-context-6.10.0-3.el9.noarch.rpm --run-command 'systemctl enable network.service || exit 0'\n```\n\n----------------------------------------\n\nTITLE: IM Probe Output Format\nDESCRIPTION: Illustrates the required output format for IM probes in OpenNebula. Each line should define a key-value pair.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-im.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nKEY1=\"value\"\nKEY2=\"another value with spaces\"\n```\n\n----------------------------------------\n\nTITLE: Batch Set Quota (CLI)\nDESCRIPTION: The `batchquota` command sets the same quotas for multiple users or groups. It takes a comma-separated list of user/group names or IDs as input.  The third parameter, 35 in the user example, is unexpected and likely represents an error. A template is still expected for the quota.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/quotas.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser batchquota userA,userB,35\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ onegroup batchquota 100..104\n```\n\n----------------------------------------\n\nTITLE: Configuring XML-RPC Server (none)\nDESCRIPTION: This snippet shows how to configure the XML-RPC server for large deployments in OpenNebula by adjusting the maximum number of connections and the connection backlog. These values are set in oned.conf.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/scalability.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nMAX_CONN = 240\nMAX_CONN_BACKLOG = 480\n```\n\n----------------------------------------\n\nTITLE: Define Virtual Network Template in OneProvision (YAML)\nDESCRIPTION: This snippet demonstrates how to create a virtual network template using OneProvision.  It defines the name, vn_mad (Virtual Network Manager Driver), and an address range (AR) with IP, size, and type. These are the minimum required parameters for a virtual network template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nvntemplates:\n  - name: \"test_vntemplate\"\n    vn_mad: \"bridge\"\n    ar:\n      - ip: \"10.0.0.1\"\n        size: 10\n        type: \"IP4\"\n```\n\n----------------------------------------\n\nTITLE: Adding Custom SSH Keys to the Authentication Agent\nDESCRIPTION: This command adds a custom SSH key to the OpenNebula SSH Authentication Agent. It requires setting the SSH_AUTH_SOCK environment variable to the agent's socket path.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/advanced_ssh_usage.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ SSH_AUTH_SOCK=/var/run/one/ssh-agent.sock ssh-add .ssh/id_rsa-encrypted\n```\n\n----------------------------------------\n\nTITLE: YAML Template with Array and Count Inputs\nDESCRIPTION: This YAML snippet defines a host configuration with array and count inputs. The 'hostname' is configured using the value of the 'array_i' user input, and the number of hosts created is determined by the 'count_i' user input. This demonstrates how to use these inputs to dynamically configure the number and names of hosts during provisioning.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\nhosts:\n  - im_mad: 'kvm'\n    vm_mad: 'kvm'\n    provision:\n      hostname: ${input.array_i}\n    count: ${input.count_i}\n```\n\n----------------------------------------\n\nTITLE: Example Accessing Sunstone Provision GUI\nDESCRIPTION: This is an example of accessing Sunstone OneProvision GUI using a specific subdomain \"poc\".  This demonstrates how to replace the <your subdomain> placeholder with an actual value.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_hosted.rst#_snippet_4\n\nLANGUAGE: none\nCODE:\n```\nhttps://poc.opennebula.cloud/fireedge/provision\n```\n\n----------------------------------------\n\nTITLE: Upgrade OpenNebula Packages on Ubuntu/Debian (Bash)\nDESCRIPTION: Updates the package list and upgrades OpenNebula and related packages on Ubuntu/Debian systems.  Dependencies: apt-get.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ apt-get update\n$ apt-get install --only-upgrade opennebula opennebula-gate opennebula-flow opennebula-provision opennebula-fireedge python3-pyone\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Community Repository on RHEL\nDESCRIPTION: This bash script adds the OpenNebula Community Edition repository to the RHEL system. It creates a `/etc/yum.repos.d/opennebula.repo` file with the repository configuration, including the base URL, GPG key URL, and enabling the repository. The script then refreshes the yum cache.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# cat << \\\"EOT\\\" > /etc/yum.repos.d/opennebula.repo\n[opennebula]\nname=OpenNebula Community Edition\nbaseurl=https://downloads.opennebula.io/repo/|version|/RedHat/$releasever/$basearch\nenabled=1\ngpgkey=https://downloads.opennebula.io/repo/repo2.key\ngpgcheck=1\nrepo_gpgcheck=1\nEOT\n# yum makecache\n```\n\n----------------------------------------\n\nTITLE: FireEdge API Authentication\nDESCRIPTION: This code demonstrates how to authenticate a user against the FireEdge API. It uses a POST request with a JSON payload containing the username and password. Upon successful authentication, a JWT token is returned, which must be included in subsequent API requests in the authorization header.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_31\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST -H \"Content-Type: application/json\" \\\n-d '{\"user\": \"username\", \"token\": \"password\"}' \\\nhttp://fireedge.server/fireedge/api/auth\n```\n\n----------------------------------------\n\nTITLE: Showing OpenNebula Datastore Information in Bash\nDESCRIPTION: This command displays detailed information about a specific datastore. The example shows the details for datastore with ID 1. The output includes general information, capacity, generic attributes (from DATASTORE TEMPLATE), and a list of images stored in the datastore.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/datastores.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore show 1\n```\n\n----------------------------------------\n\nTITLE: Setting Deployment Mode with TM_MAD_SYSTEM attribute\nDESCRIPTION: This code snippet shows how to set the deployment mode for a Virtual Machine by adding the TM_MAD_SYSTEM attribute to the Virtual Machine template.  The value \"ssh\" selects the SSH deployment mode.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/nas_ds.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nTM_MAD_SYSTEM=\"ssh\"\n```\n\n----------------------------------------\n\nTITLE: Example BGP EVPN Route Output\nDESCRIPTION: This example shows the output of the 'show bgp evpn route' command on a hypervisor. It displays the network, next hop, and other routing information for VXLAN tunnels.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vxlan.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n10.4.4.11# show bgp evpn route\n   Network          Next Hop            Metric LocPrf Weight Path\nRoute Distinguisher: 10.4.4.11:2\n*> [2]:[0]:[0]:[48]:[02:00:0a:03:03:c9]\n                    10.4.4.11                          32768 i\n*> [3]:[0]:[32]:[10.4.4.11]\n                   10.4.4.11                           32768 i\nRoute Distinguisher: 10.4.4.12:2\n*>i[2]:[0]:[0]:[48]:[02:00:0a:03:03:c8]\n                   10.4.4.12                0    100      0 i\n*>i[3]:[0]:[32]:[10.4.4.12]\n                   10.4.4.12                0    100      0 i\n```\n\n----------------------------------------\n\nTITLE: Listing Hatch Environments\nDESCRIPTION: This command lists the available Hatch environments.  Hatch creates virtual environments to isolate the dependencies for different parts of the OneDeploy installation, such as Ansible and Ceph.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nhatch env show\n```\n\n----------------------------------------\n\nTITLE: Defining a File System Disk in OpenNebula\nDESCRIPTION: This snippet defines a virtual disk with a file system (fs) type, a size of 4096 MB, and an ext3 format. This disk will be available as a block device within the virtual machine.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_10\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nDISK = [ TYPE   = fs,\n             SIZE   = 4096,\n             FORMAT = ext3 ]\n```\n\n----------------------------------------\n\nTITLE: Activating Hatch Shell\nDESCRIPTION: This command activates the default Hatch virtual environment. After running this command, the terminal prompt will be prefixed with (one-deploy), indicating that the virtual environment is active.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nhatch shell\n```\n\n----------------------------------------\n\nTITLE: Ansible Directory Structure\nDESCRIPTION: This snippet represents the directory structure where Ansible roles and playbooks are stored in the OpenNebula environment. It includes roles for various functionalities like Ceph, DDC, FRR, OpenNebula node setup, and playbooks for AWS, DigitalOcean, Equinix, Google, and on-premise deployments.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/playbooks.rst#_snippet_0\n\nLANGUAGE: None\nCODE:\n```\n/usr/share/one/oneprovision/ansible\nâ”œâ”€â”€ roles\nâ”‚   â”œâ”€â”€ ceph-opennebula-facts\nâ”‚   â”œâ”€â”€ ceph-opennebula-mon\nâ”‚   â”œâ”€â”€ ceph-opennebula-osd\nâ”‚   â”œâ”€â”€ ceph-slice\nâ”‚   â”œâ”€â”€ ddc\nâ”‚   â”œâ”€â”€ frr\nâ”‚   â”œâ”€â”€ iptables\nâ”‚   â”œâ”€â”€ opennebula-node-kvm\nâ”‚   â”œâ”€â”€ opennebula-node-lxc\nâ”‚   â”œâ”€â”€ opennebula-repository\nâ”‚   â””â”€â”€ opennebula-ssh\nâ”œâ”€â”€ ceph-6.0\nâ”‚   â””â”€â”€ plugins\nâ”œâ”€â”€ ceph_hci\nâ”‚   â”œâ”€â”€ group_vars.yml.erb\nâ”‚   â””â”€â”€ site.yml\nâ”œâ”€â”€ ansible.cfg.erb\nâ”œâ”€â”€ aws.yml\nâ”œâ”€â”€ digitalocean.yml\nâ”œâ”€â”€ equinix.yml\nâ”œâ”€â”€ google.yml\nâ”œâ”€â”€ hci-requirements.yml\nâ”œâ”€â”€ onprem.yml\nâ”œâ”€â”€ vultr_metal.yml\nâ””â”€â”€ vultr.yml\n```\n\n----------------------------------------\n\nTITLE: XML-RPC Server Configuration in oned.conf (Bash)\nDESCRIPTION: This snippet configures the XML-RPC server settings within the OpenNebula oned.conf file. It defines parameters such as maximum connections, connection backlog, keep-alive timeout, and message size. This configuration adjusts the behavior of the XML-RPC server for handling API requests.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n#*******************************************************************************\n# XML-RPC server configuration\n#*******************************************************************************\n\n#MAX_CONN           = 15\n#MAX_CONN_BACKLOG   = 15\n#KEEPALIVE_TIMEOUT  = 15\n#KEEPALIVE_MAX_CONN = 30\n#TIMEOUT            = 15\n#RPC_LOG            = NO\n#MESSAGE_SIZE       = 1073741824\n#LOG_CALL_FORMAT    = \"Req:%i UID:%u %m invoked %l\"\n```\n\n----------------------------------------\n\nTITLE: Adding Address Range to Virtual Network - onevnet Command\nDESCRIPTION: This command adds a new address range (AR) to a virtual network. It uses the `onevnet addar` command with the virtual network name, IP address, and size of the range as arguments. This expands the IP address pool available to the virtual network.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/manage_vnets.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nonevnet addar Private --ip 10.0.0.200 --size 20\n```\n\n----------------------------------------\n\nTITLE: Configuring the Scheduler Driver in OpenNebula\nDESCRIPTION: This configuration defines the scheduler driver and its arguments. `EXECUTABLE` specifies the path to the driver, and `ARGUMENTS` sets the number of threads, placement scheduler, and optimization scheduler. The number of threads determines concurrent scheduling operations. The placement scheduler sets the initial placement algorithm, and the optimization scheduler sets how VMs are optimized cluster-wide.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/configuration.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSCHED_MAD = [\n      EXECUTABLE = \"one_sched\",\n      ARGUMENTS  = \"-t 15 -p rank -o one_drs\"\n]\n```\n\n----------------------------------------\n\nTITLE: Example numactl Output - NUMA Topology\nDESCRIPTION: This is the `numactl -H` output for the VM with NUMA topology enabled. It shows two NUMA nodes (0 and 1) with their CPU assignments, memory sizes, and node distances.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_9\n\nLANGUAGE: text\nCODE:\n```\n# numactl -H\navailable: 2 nodes (0-1)\nnode 0 cpus: 0 1 2 3\nnode 0 size: 511 MB\nnode 0 free: 235 MB\nnode 1 cpus: 4 5 6 7\nnode 1 size: 511 MB\nnode 1 free: 359 MB\nnode distances:\nnode   0   1\n  0:  10  20\n  1:  20  10\n```\n\n----------------------------------------\n\nTITLE: Pinging a VM to Verify Network Connectivity\nDESCRIPTION: This command pings a specified IP address to verify network connectivity.  The `-c 3` flag limits the ping count to 3. The IP address `172.20.0.100` is the target VM's IP.  This command requires network access from the machine where it's executed to the target IP address.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\nping -c 3 172.20.0.100\n```\n\n----------------------------------------\n\nTITLE: Overriding EMULATOR for KVM in OpenNebula\nDESCRIPTION: This snippet demonstrates how to override the default emulator path for KVM VMs using the EMULATOR attribute. By setting EMULATOR to \"/usr/bin/qemu-system-aarch64\", the VM will use the AArch64 (ARM64) version of QEMU. This can be used to run VMs built for different architectures than the host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_38\n\nLANGUAGE: text\nCODE:\n```\nEMULATOR=\"/usr/bin/qemu-system-aarch64\"\n```\n\n----------------------------------------\n\nTITLE: Securing the SSH key on VNF node\nDESCRIPTION: This command modifies the permissions of the SSH private key on the VNF node to ensure it is only readable and writable by the owner. This is necessary for SSH to function securely.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh root@1.2.3.4 chmod u=rw,go= /root/.ssh/id_rsa    # make sure the key is secured\n```\n\n----------------------------------------\n\nTITLE: Defining a Single Attribute in OpenNebula Template\nDESCRIPTION: Demonstrates the syntax for defining a single attribute in an OpenNebula VM template file.  The attribute consists of a name and a value separated by an equals sign. Attribute names are case-insensitive.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nNAME=VALUE\n```\n\n----------------------------------------\n\nTITLE: Extracting files from edk2-ovmf RPM in Linux\nDESCRIPTION: These commands extract files from the edk2-ovmf RPM for updating firmware files. The `rpm2cpio` command extracts the contents of the RPM archive to standard output, which is then piped to `cpio` to extract the files into the specified directory. The `find` command lists all files in the extracted directory to verify the operation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncd /path/to/downloaded/RPM/\nmkdir extracted\ncd extracted\nrpm2cpio ../edk2-ovmf.el8.noarch.rpm | cpio -idmv\nfind .\n```\n\n----------------------------------------\n\nTITLE: X.509 Authentication Configuration in Sunstone\nDESCRIPTION: This snippet configures Sunstone to use X.509 certificate authentication. The certificate's DN is extracted and matched to the password in the user database.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nauth: x509\n```\n\n----------------------------------------\n\nTITLE: Configuring Hook Log Retention in oned.conf\nDESCRIPTION: This snippet demonstrates how to configure the number of hook execution log records stored in the OpenNebula database within the `oned.conf` file.  Setting `LOG_RETENTION` determines how many of the most recent execution records are kept for each hook. This is useful for debugging and retrying hook executions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nHOOK_LOG_CONF = [\n    LOG_RETENTION = 10 ]\n```\n\n----------------------------------------\n\nTITLE: Listing OneFlow Resources via CLI\nDESCRIPTION: This example shows how to list OneFlow resources using the command-line interface (CLI). It sets the ONEFLOW_URL environment variable to the OneFlow server's address and then executes the 'oneflow list' command. This assumes that the OneFlow server is running and accessible at the specified URL.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oneflow.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ONEFLOW_URL=http://one.example.com:2474 oneflow list\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula Community Repository on Ubuntu 22.04\nDESCRIPTION: This bash script adds the OpenNebula Community Edition repository to the Ubuntu 22.04 system. It creates a `/etc/apt/sources.list.d/opennebula.list` file with the repository configuration, including the base URL and specifies the GPG key file. The script then updates the apt package list.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n# echo \\\"deb [signed-by=/etc/apt/keyrings/opennebula.gpg] https://downloads.opennebula.io/repo/|version|/Ubuntu/22.04 stable opennebula\\\" > /etc/apt/sources.list.d/opennebula.list\n# apt-get update\n```\n\n----------------------------------------\n\nTITLE: HAProxy Configuration for Load Balancing (text)\nDESCRIPTION: This snippet presents a HAProxy configuration for load balancing client requests across multiple OpenNebula API servers. It configures a frontend listening on port 2633 and a backend with three OpenNebula servers.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/scalability.rst#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nfrontend OpenNebula\nbind 0.0.0.0:2633\nstats enable\nmode tcp\ndefault_backend one_nodes\n\nbackend one_nodes\nmode tcp\nstats enable\nbalance roundrobin\nserver opennebula1 10.134.236.10:2633 check\nserver opennebula2 10.134.236.11:2633 check\nserver opennebula3 10.134.236.12:2633 check\n```\n\n----------------------------------------\n\nTITLE: XFS Image Mount Error Message\nDESCRIPTION: This code snippet represents an error message encountered when mounting XFS images with an incompatible block size in the OpenNebula LXC environment. It indicates a failure due to a function not implemented, suggesting the use of images with a 4K block size for compatibility.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_driver.rst#_snippet_1\n\nLANGUAGE: none\nCODE:\n```\nMon Apr  4 22:20:25 2022 [Z0][VMM][I]: mount: /var/lib/one/datastores/0/30/mapper/disk.1: mount(2) system call failed: Function not implemented.\n```\n\n----------------------------------------\n\nTITLE: Datastore Configuration for AWS Cluster\nDESCRIPTION: Defines image and system datastores for an AWS cluster, using the SSH replication driver.  It configures the type, ds_mad, tm_mad, and safe_dirs for each datastore and specifies the replica_host for the system datastore.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_5\n\nLANGUAGE: YAML\nCODE:\n```\ndatastores:\n\n  - name: \"${provision}-image\"\n    type: 'image_ds'\n    ds_mad: 'fs'\n    tm_mad: 'local'\n    safe_dirs: \"/var/tmp /tmp\"\n\n  - name: \"${provision}-system\"\n    type: 'system_ds'\n    tm_mad: 'local'\n    safe_dirs: \"/var/tmp\n    replica_host: \"use-first-host\"\n```\n\n----------------------------------------\n\nTITLE: Context Variables for OneKE Deployment\nDESCRIPTION: This section defines the context variables necessary to replicate deployments from prior OneKE releases. This specifies settings such as disabling Multus, setting the CNI plugin to Canal, and enabling Longhorn, MetalLB, and Traefik.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/oneke_changelog.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n``ONEAPP_K8S_MULTUS_ENABLED``   ``NO``\n``ONEAPP_K8S_CNI_PLUGIN``       ``canal``\n``ONEAPP_K8S_LONGHORN_ENABLED`` ``YES``\n``ONEAPP_K8S_METALLB_ENABLED``  ``YES``\n``ONEAPP_K8S_TRAEFIK_ENABLED``  ``YES``\n```\n\n----------------------------------------\n\nTITLE: Example lscpu Output - Basic VM Configuration\nDESCRIPTION: This is the output of the `lscpu` command within a VM configured with the basic template above. It shows the number of CPUs, threads per core, cores per socket, sockets, and NUMA node information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n# lscpu\n...\nCPU(s):                4\nOn-line CPU(s) list:   0-3\nThread(s) per core:    1\nCore(s) per socket:    1\nSocket(s):             4\nNUMA node(s):          1\n```\n\n----------------------------------------\n\nTITLE: Retrieve Libvirt Exporter Metrics (Host)\nDESCRIPTION: Uses `curl` to retrieve metrics from the `opennebula-libvirt-exporter` running on localhost port 9926.  The output shows the metrics being exposed by the exporter.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ curl localhost:9926/metrics\n# TYPE opennebula_libvirt_requests_total counter\n# HELP opennebula_libvirt_requests_total The total number of HTTP requests handled by the Rack application.\nopennebula_libvirt_requests_total{code=\"200\",method=\"get\",path=\"/metrics\"} 18.0\n...\n# TYPE opennebula_libvirt_daemon_up gauge\n# HELP opennebula_libvirt_daemon_up State of the libvirt daemon 0:down 1:up\nopennebula_libvirt_daemon_up 1.0\n```\n\n----------------------------------------\n\nTITLE: Publishing Translations\nDESCRIPTION: This command publishes the translated documentation by building the HTML files with the specified language. It sets the `language` option for Sphinx to `<lang>` and then calls `make html` to build the documentation. The `-e` option is used to pass the `SPHINXOPTS` environment variable to make.\nSOURCE: https://github.com/opennebula/docs/blob/master/README.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ make -e SPHINXOPTS=\"-D language='<lang>'\" html\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenNebula Group Template\nDESCRIPTION: This example shows how to set the DEFAULT_IMAGE_PERSISTENT and DEFAULT_IMAGE_PERSISTENT_NEW attributes in the OPENNEBULA section of a group template. DEFAULT_IMAGE_PERSISTENT controls the default value for the PERSISTENT attribute on image creation (clone and disk save-as). DEFAULT_IMAGE_PERSISTENT_NEW controls the default value for the PERSISTENT attribute on image creation (only new images).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_groups.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\nOPENNEBULA = [\n  DEFAULT_IMAGE_PERSISTENT     = \"YES\",\n  DEFAULT_IMAGE_PERSISTENT_NEW = \"NO\"\n]\n```\n\n----------------------------------------\n\nTITLE: Forcing OpenNebula configuration reinitialization\nDESCRIPTION: This snippet demonstrates how to force reinitialization of the configuration using the `--force` parameter. This is useful when needing to reset the configuration state.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg init --force\nINFO  : Initialized on version 5.10.0\n```\n\n----------------------------------------\n\nTITLE: Displaying VM NUMA Node and Topology Information using OpenNebula CLI\nDESCRIPTION: This shows the output of the `onevm show 0` command, which displays the NUMA node and topology information for a specific VM as reported by OpenNebula. This includes CPU assignments to NUMA nodes, memory allocated to each node, and the overall topology configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_23\n\nLANGUAGE: Shell\nCODE:\n```\n$ onevm show 0\n...\nNUMA NODES\n\n  ID   CPUS     MEMORY TOTAL_CPUS\n   0    0,4       512M          2\n   0    1,5       512M          2\n\nTOPOLOGY\n\nNUMA_NODES  CORES  SOCKETS  THREADS\n```\n\n----------------------------------------\n\nTITLE: Passing Custom Libvirt/KVM Attributes\nDESCRIPTION: This example shows how to use the `RAW` attribute to pass custom libvirt/KVM attributes to the VM. The `TYPE` is set to `kvm`. `VALIDATE` controls whether the data is validated against the libvirt schema (defaults to `yes`). The `DATA` field contains the XML configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_9\n\nLANGUAGE: xml\nCODE:\n```\nRAW = [\n  TYPE = \"kvm\",\n  VALIDATE = \"yes\",\n  DATA = \"<devices><serial type=\\\"pty\\\"><source path=\\\"/dev/pts/5\\\"/><target port=\\\"0\\\"/></serial><console type=\\\"pty\\\" tty=\\\"/dev/pts/5\\\"><source path=\\\"/dev/pts/5\\\"/><target port=\\\"0\\\"/></console></devices>\" ]\n```\n\n----------------------------------------\n\nTITLE: Creating vm-pending.rb Ruby Script\nDESCRIPTION: Creates a simple Ruby script, vm-pending.rb, which prints \"Executed!\" to standard output. It then sets the execute permission on the script using chmod and retries hook id 0 and execution 0. This script is designed to test the basic execution of a hook.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_7\n\nLANGUAGE: ruby\nCODE:\n```\n#!/usr/bin/ruby\nputs \"Executed!\"\n```\n\n----------------------------------------\n\nTITLE: Setting the ONE_AUTH Environment Variable\nDESCRIPTION: This command sets the ONE_AUTH environment variable to the file containing the X.509 login token. This environment variable is used by the OpenNebula CLI to locate the authentication token, enabling the user to interact with the OpenNebula cloud.  Setting this variable is crucial for using the CLI after logging in with X.509.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nexport ONE_AUTH=/home/oneadmin/.one/one_x509\n```\n\n----------------------------------------\n\nTITLE: Configuring Ruby Environment for OpenNebula\nDESCRIPTION: This code snippet configures the Ruby environment to use the OpenNebula Ruby library. It sets the `RUBY_LIB_LOCATION` and `GEMS_LOCATION` based on the `ONE_LOCATION` environment variable, and ensures the correct gems are used. It is crucial to correctly set up the environment before using the OpenNebula Ruby bindings.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/ruby.rst#_snippet_0\n\nLANGUAGE: ruby\nCODE:\n```\n############################################################################\n# Environment Configuration\n############################################################################\nONE_LOCATION = ENV['ONE_LOCATION']\n\nif !ONE_LOCATION\n    RUBY_LIB_LOCATION = '/usr/lib/one/ruby'\n    GEMS_LOCATION     = '/usr/share/one/gems'\nelse\n    RUBY_LIB_LOCATION = ONE_LOCATION + '/lib/ruby'\n    GEMS_LOCATION     = ONE_LOCATION + '/share/gems'\nend\n\nif File.directory?(GEMS_LOCATION)\n    real_gems_path = File.realpath(GEMS_LOCATION)\n    if !defined?(Gem) || Gem.path != [real_gems_path]\n        $LOAD_PATH.reject! {|l| l =~ /vendor_ruby/ }\n        require 'rubygems'\n        Gem.use_paths(real_gems_path)\n    end\nend\n\n$LOAD_PATH << RUBY_LIB_LOCATION\n```\n\n----------------------------------------\n\nTITLE: Removing OpenNebula Server from Zone using onezone command\nDESCRIPTION: This command is used to remove an OpenNebula server from a specific zone. It requires the zone ID and server ID as parameters. The command offers verbose mode and help options.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/frontend_ha.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onezone server-del\nCommand server-del requires 2 parameters to run.\n## USAGE\nserver-del <zoneid> <serverid>\n        Delete an OpenNebula server from this zone.\n\n## OPTIONS\n     -v, --verbose             Verbose mode\n     -h, --help                Show this message\n     -V, --version             Show version and copyright information\n     --user name               User name used to connect to OpenNebula\n     --password password       Password to authenticate with OpenNebula\n     --endpoint endpoint       URL of OpenNebula xmlrpc frontend\n```\n\n----------------------------------------\n\nTITLE: Handling xmlrpc compilation errors\nDESCRIPTION: This snippet shows an example of an error that might occur when compiling OpenNebula with xmlrpc and provides instructions on how to resolve it, either by removing the `new_xmlrpc=yes` option or installing a compatible version of xmlrpc-c.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/compile.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nerror: 'class xmlrpc_c::serverAbyss::constrOpt' has no member named 'maxConn'\n```\n\n----------------------------------------\n\nTITLE: Defining restricted DISK attributes in oned.conf\nDESCRIPTION: This code snippet shows another configuration of restricted VM attributes in `oned.conf`. This example restricts the ability to delete a DISK that has the `TOTAL_BYTES_SEC` attribute. \nDependencies: OpenNebula oned.conf\nInputs: None\nOutputs: Prevents users from deleting disks with the restricted `TOTAL_BYTES_SEC` attribute.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_8\n\nLANGUAGE: none\nCODE:\n```\nVM_RESTRICTED_ATTR = \"DISK/TOTAL_BYTES_SEC\"\n```\n\n----------------------------------------\n\nTITLE: List OpenNebula Virtual Networks\nDESCRIPTION: This command lists the OpenNebula virtual networks. It displays the network ID, user, group, name, clusters, bridge, state and leases. Requires the OpenNebula CLI tools to be installed and configured.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ onevnet list\n  ID USER     GROUP    NAME                      CLUSTERS   BRIDGE   STATE    LEASES\n   4 oneadmin oneadmin onprem-hci-cluster-public     102        onebr4   rdy           0\n```\n\n----------------------------------------\n\nTITLE: Sunstone View Directory Structure\nDESCRIPTION: This code snippet illustrates the directory structure for Sunstone views within the OpenNebula configuration directory.  Each subdirectory represents a specific view (e.g., admin, user) and contains YAML files that define the tab configurations for that view. The `sunstone-views.yaml` file is the main configuration file for Sunstone views.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/end-user_web_interfaces/fireedge_sunstone.rst#_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n/etc/one/fireedge/sunstone/\n...\n|-- admin/\n|   |-- backup-tab.yaml           <--- the Backup tab configuration file\n|   |-- cluster-tab.yaml          <--- the Cluster tab configuration file (not installed by default)   \n|   |-- datastore-tab.yaml        <--- the Datastore tab configuration file\n|   |-- file-tab.yaml             <--- the File tab configuration file\n|   |-- group-tab.yaml            <--- the Group tab configuration file\n|   |-- host-tab.yaml             <--- the Host tab configuration file\n|   |-- image-tab.yaml            <--- the Image tab configuration file\n|   |-- marketplace-app-tab.yaml  <--- the Marketplace App tab configuration file\n|   |-- sec-group-tab.yaml        <--- the Security Group tab configuration file\n|   |-- user-tab.yaml             <--- the User tab configuration file\n|   |-- vdc-tab.yaml              <--- the VDC tab configuration file \n|   |-- vm-tab.yaml               <--- the VM tab configuration file\n|   |-- vm-template-tab.yaml      <--- the VM Template tab configuration file\n|   |-- vm-group-tab.yaml         <--- the VM Group tab configuration file\n|   |-- vnet-tab.yaml             <--- the Virtual Network tab configuration file\n|-- sunstone-server.conf\n|-- sunstone-views.yaml           <--- the FireEdge Sunstone views main configuration\n`-- user/\n    ...\n    |-- vm-tab.yaml               <--- the VM tab configuration file\n    `-- vm-template-tab.yaml      <--- the VM Template tab configuration file\n...\n```\n\n----------------------------------------\n\nTITLE: Registering a New Edge Cluster Provider in Ruby\nDESCRIPTION: This Ruby code snippet shows the structure for creating a new Edge Cluster Provider within OpenNebula. It inherits from the `Terraform` class and defines constants for resource types and provider connection keys. It also includes methods for initializing the provider and handling user data. This file should be placed in `/usr/lib/one/oneprovision/lib/terraform/providers`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_0\n\nLANGUAGE: ruby\nCODE:\n```\nrequire 'terraform/terraform'\n\n# Module OneProvision\nmodule OneProvision\n\n    # <<PROVIDER NAME>> Terraform Provider\n    class <<PROVIDER CLASS>> < Terraform\n\n        NAME = Terraform.append_provider(__FILE__, name)\n\n        # OpenNebula - Terraform equivalence\n        TYPES = {\n            :cluster   => '<<TERRAFORM RESOURCE>>',\n            :datastore => '<<TERRAFORM RESOURCE>>',\n            :host      => '<<TERRAFORM RESOURCE>>',\n            :network   => '<<TERRAFORM RESOURCE>>'\n        }\n\n        # These are the keys needed by the terraform provider configuration\n        KEYS = %w[<<PROPVIDER CONNECTION INFO>>]\n\n        # Class constructor\n        #\n        # @param provider [Provider]\n        # @param state    [String] Terraform state in base64\n        # @param conf     [String] Terraform config state in base64\n        def initialize(provider, state, conf)\n            # If credentials are stored into a file, set this variable to true\n            # If not, leave it as it is\n            @file_credentials = false\n\n            super\n        end\n\n        # Get user data to add into the VM\n        #\n        # @param ssh_key [String] SSH keys to add\n        def user_data(ssh_key)\n            <<IMPLEMENT THIS METHOD IF NEEDED, IF NOT YOU CAN DELETE IT>>\n        end\n\n    end\n\nend\n```\n\n----------------------------------------\n\nTITLE: Regenerating initrd with dracut\nDESCRIPTION: This command regenerates the initrd image after modifying the dracut configuration. The `--force` option ensures that the existing initrd is overwritten.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/pci_passthrough.rst#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n# dracut --force\n```\n\n----------------------------------------\n\nTITLE: Displaying NUMA Memory Statistics using numastat\nDESCRIPTION: This code block shows the output from the `numastat -m` command, providing detailed memory statistics for each NUMA node, including total, free, and used memory, as well as hugepage allocation details. This helps in monitoring the memory usage and hugepage availability on the host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_18\n\nLANGUAGE: Shell\nCODE:\n```\n# numastat -m\n                             Node 0           Total\n                    --------------- ---------------\nMemTotal                 7805.56         7805.56\nMemFree                   862.80          862.80\nMemUsed                  6942.76         6942.76\n...\nHugePages_Total          2048.00         2048.00\nHugePages_Free           1536.00         1536.00\nHugePages_Surp              0.00            0.00\n```\n\n----------------------------------------\n\nTITLE: Copying new OVMF firmware files in Linux\nDESCRIPTION: These commands copy the extracted OVMF firmware files to the system directories. The `cp -r` command recursively copies the `edk2`, `qemu`, and `OVMF` directories from the extracted location to the `/usr/share/` directory, overwriting the existing files. The `-r` option ensures that directories are copied recursively.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncd /path/to/download/RPM/extracted/usr/share/\ncp -r edk2 qemu OVMF /usr/share/.\n```\n\n----------------------------------------\n\nTITLE: Environment Variable Validation and Error Handling (Bash)\nDESCRIPTION: This snippet checks if the ONEGATE_TOKEN and ONEGATE_ENDPOINT environment variables are set. If either is missing, an error message is printed to the console, and the script exits with an error code.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nif [ -z $ONEGATE_TOKEN ]; then\n    echo \"ONEGATE_TOKEN env variable must point to the token.txt file\"\n    ERROR=1\nfi\n\nif [ -z $ONEGATE_ENDPOINT ]; then\n    echo \"ONEGATE_ENDPOINT env variable must be set\"\n    ERROR=1\nfi\n\nif [ $ERROR = 1 ]; then\n    exit -1\nfi\n```\n\n----------------------------------------\n\nTITLE: List Images and Show Template NIC configuration\nDESCRIPTION: This example shows how to list the created images after importing the OVA and then how to show the template and filter to see the network configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/ova_management/import_ova.rst#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ oneimage list\nID  USER     GROUP    NAME            DATASTORE     SIZE TYPE PER STAT RVMS\n151 onepoc   oneadmin ubuntu2404_1    NFS image       2G DB    No rdy     0\n150 onepoc   oneadmin ubuntu2404_0    default         8G OS    No rdy     0\n\n$ onetemplate show 101 | grep NIC -A 1\nNIC=[\n        NETWORK_ID=\"1\" ]\nNIC=[\n        NETWORK_ID=\"0\" ]\n```\n\n----------------------------------------\n\nTITLE: Enable and Start Guacamole Service - Bash\nDESCRIPTION: This snippet enables and starts the Guacamole service, required if you want to use Guacamole with FireEdge. It uses `systemctl` to manage the `opennebula-guacd` service. Guacamole enables access to virtual machines via a web browser.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/fireedge_for_large_deployments.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl enable opennebula-guacd\n# systemctl start  opennebula-guacd\n```\n\n----------------------------------------\n\nTITLE: Command Line Parameters Example (Bash)\nDESCRIPTION: This snippet shows an example of using command-line parameters to authenticate and specify the endpoint when executing an OpenNebula command.  It demonstrates how to use the `--user`, `--endpoint` parameters. The password will be prompted if not provided.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/cli.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm list --user my_user --endpoint http://one.frontend.com:2633/RPC2\nPassword:\n[...]\n```\n\n----------------------------------------\n\nTITLE: Verify Node and Libvirt Exporters are Running (Host)\nDESCRIPTION: Uses `ss` and `grep` to check if the node and libvirt exporters are listening on the expected ports (9926, 9100) on the host machines.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# ss -tapn | grep 'LISTEN.*\\(9926\\|9100\\)'\nLISTEN    0      100          0.0.0.0:9926       0.0.0.0:*     users:((\"ruby\",pid=38851,fd=7))\nLISTEN    0      4096               *:9100             *:*     users:((\"node_exporter\",pid=38884,fd=3))\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Virtual Networks\nDESCRIPTION: This command, executed as the `oneadmin` user, lists the OpenNebula virtual networks. It shows the network ID, user, group, name, clusters, bridge, state, leases, and error count. Requires the OpenNebula CLI tool `onevnet`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nonevnet list\n```\n\n----------------------------------------\n\nTITLE: Connecting to Kubernetes master node via SSH\nDESCRIPTION: This command establishes an SSH connection to the Kubernetes master node through the VNF node. It requires the public IP address of the VNF node. Replace `1.2.3.4` with the VNF node's public IP and ensure the `root` user has SSH access configured correctly.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh -A -J root@1.2.3.4 root@172.20.0.2\n```\n\n----------------------------------------\n\nTITLE: Marketplace Import Return Template Format\nDESCRIPTION: This snippet shows the OpenNebula syntax template that the marketplace import action (<market_mad>/import) must return. It includes the SOURCE, MD5, SIZE_IN_MB, and FORMAT fields, which specify the location, checksum, size, and format of the imported image respectively.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-market.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nSOURCE=\"<SOURCE>\"\nMD5=\"<MD5>\"\nSIZE=\"<SIZE_IN_MB>\"\nFORMAT=\"<FORMAT>\"\n```\n\n----------------------------------------\n\nTITLE: User Inputs for Sunstone - With Convention (JSON)\nDESCRIPTION: This JSON snippet shows user inputs with specific naming conventions (ONEAPP_*).  This allows Sunstone to group the user inputs into tabs and groups for a better user experience, specifically under an 'APACHE' tab and 'CONFIG' group.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"user_inputs\": {\n    \"ONEAPP_APACHE_CONFIG_USER\": \"O|text|Apache user||\",\n    \"ONEAPP_APACHE_CONFIG_ENDPOINT\": \"O|text|Apache endpoint||\"\n  },\n}\n```\n\n----------------------------------------\n\nTITLE: HCI Cluster Provisioning YAML\nDESCRIPTION: This YAML snippet shows the basic structure of the HCI cluster provisioning template. It defines the name and description of the cluster and extends other YAML files containing default values, resources, host configurations, datastore configurations, FireEdge settings, input parameters, and network settings. The `extends` section specifies the files to inherit configurations from.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/hci_clusters/onprem_cluster_ceph.rst#_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\nname: 'onprem-hci-cluster'\n\ndescription: 'On-premises hyper-convergent Ceph cluster'\n\nextends:\n    - onprem.d/defaults.yml\n    - onprem.d/resources.yml\n    - onprem.d/hosts-hci.yml\n    - onprem.d/datastores-hci.yml\n    - onprem.d/fireedge.yml\n    - onprem.d/inputs-hci.yml\n    - onprem.d/networks.yml\n```\n\n----------------------------------------\n\nTITLE: Creating secret.xml File\nDESCRIPTION: This snippet creates a secret.xml file containing the UUID.  The UUID is inserted into the XML structure, which defines a secret used for LUKS encryption.  A here document (<<EOF) is used to write the XML content to the file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ cat > secret.xml <<EOF\n<secret ephemeral='no' private='yes'>\n   <uuid>$UUID</uuid>\n      <description>luks key</description>\n</secret>\nEOF\n```\n\n----------------------------------------\n\nTITLE: Displaying MiniONE Script Options\nDESCRIPTION: This command executes the miniONE script with the ``-h`` flag, displaying a list of available options and their descriptions. This is helpful for customizing the installation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_onprem.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nbash minione -h\n```\n\n----------------------------------------\n\nTITLE: Installing Context Package on FreeBSD with pkg\nDESCRIPTION: These commands install the OpenNebula context package and its dependencies on FreeBSD using pkg. It installs required packages like curl, bash, sudo, base64, ruby, and open-vm-tools-nox11, and then installs the one-context package.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n# pkg install -y curl bash sudo base64 ruby open-vm-tools-nox11\n# pkg install -y one-context-[0-9]*.txz\n```\n\n----------------------------------------\n\nTITLE: Downloading RHEL 8.x Context Package with wget\nDESCRIPTION: This command downloads the OpenNebula context package for RHEL 8.x (CentOS/AlmaLinux/RockyLinux/Oracle Linux 8.x) using wget. It fetches the package from the OpenNebula GitHub releases page.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# wget https://github.com/OpenNebula/one-apps/releases/download/v|context_release|/one-context-|context_release|-1.el8.noarch.rpm\n```\n\n----------------------------------------\n\nTITLE: Bash Provisioning Command with User Input\nDESCRIPTION: This bash command shows how to create a provision using a template and the '--skip-provision' option.  It demonstrates the interactive prompting for user inputs defined in the template. The tool will then ask for the value of each of the inputs, using default values where available.  The example showcases text, boolean, password, and list input types.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision create test.yaml -D --skip-provision\n\nText `text_i` (default=This is a text): test\n\nBool `bool_i` (default=NO): YES\n\nPass `password_i` (default=1234):\n\n    0  OPT 1\n    1  OPT 2\n    2  OPT 3\n    3  OPT 4\n\nPlease type the selection number (default=1): 0\n```\n\n----------------------------------------\n\nTITLE: Scan vCenter Permissions with OneSupport in Bash\nDESCRIPTION: This command uses the onesupport_vcenter_privs tool to gather permissions configuration directly from the vCenter instance. It requires connection parameters like host, user, password, and the user for OpenNebula to check. The output is printed to standard output.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/support.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ onesupport_vcenter_privs\n```\n\nLANGUAGE: bash\nCODE:\n```\nUsage: onesupport_vcenter_privs [arguments]\n\nMandatory arguments:\n  --host=name       .... vCenter hostname\n  --user=name       .... vCenter login user name\n  --password=text   .... vCenter password\n  --check-user=name .... vCenter user for OpenNebula to check\n```\n\n----------------------------------------\n\nTITLE: Disable PolicyKit for Libvirt (RedHat)\nDESCRIPTION: This snippet shows how to disable PolicyKit for Libvirt on RedHat systems.  It involves modifying the libvirtd.conf file and setting auth_unix_ro and auth_unix_rw to \"none\", along with setting appropriate permissions for the unix socket.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/release_notes/platform_notes.rst#_snippet_1\n\nLANGUAGE: conf\nCODE:\n```\nauth_unix_ro = \"none\"\nauth_unix_rw = \"none\"\nunix_sock_group = \"oneadmin\"\nunix_sock_ro_perms = \"0770\"\nunix_sock_rw_perms = \"0770\"\n```\n\n----------------------------------------\n\nTITLE: Configuring OneGate Host\nDESCRIPTION: This snippet demonstrates configuring the OneGate server to listen on all network interfaces by setting the ':host' parameter to '0.0.0.0' in the /etc/one/onegate-server.conf file. This allows the OneGate server to accept connections from any IP address.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_6\n\nLANGUAGE: none\nCODE:\n```\n:host: 0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Running the MiniONE Script to Install OpenNebula Front-end\nDESCRIPTION: This command executes the miniONE script, installing the OpenNebula front-end. The ``--frontend`` flag specifies that only the front-end should be installed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_onprem.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nbash minione --frontend\n```\n\n----------------------------------------\n\nTITLE: Rsync Datastore Configuration File\nDESCRIPTION: This configuration file defines the parameters for the Rsync backup datastore in OpenNebula.  It specifies the datastore name, type, Rsync user, and Rsync host. The TM_MAD is set to '-' indicating no specific Transfer Manager is used.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/rsync.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nNAME   = \"rsync Backups\"\nTYPE   = \"BACKUP_DS\"\n\nDS_MAD = \"rsync\"\nTM_MAD = \"-\"\n\nRSYNC_USER = \"oneadmin\"\nRSYNC_HOST = \"192.168.100.1\"\n```\n\n----------------------------------------\n\nTITLE: Converting Image to LUKS\nDESCRIPTION: This snippet converts an existing image to a LUKS-encrypted image using `qemu-img convert`. It specifies the input image, the output LUKS image, and the secret file containing the encryption key.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ qemu-img convert --target-image-opts --object secret,id=sec0,file=passphrase.luks -f qcow2 /var/lib/one//datastores/1/2f7afcdd0f5c7644a8f82ec57f3ede54 -n driver=luks,file.filename=/tmp/alpine-3.17.luks,key-secret=sec0\n```\n\n----------------------------------------\n\nTITLE: ACL Rule Example with No Effect\nDESCRIPTION: This example illustrates how ACL rules add permissions and cannot restrict existing ones. If a user is already granted permissions through a group, a rule specifically for that user will not override the group's permissions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_13\n\nLANGUAGE: text\nCODE:\n```\n@108 IMAGE/#45 USE+MANAGE\n```\n\nLANGUAGE: text\nCODE:\n```\n#7 IMAGE/#45 USE\n```\n\n----------------------------------------\n\nTITLE: Service Template with on_hold Parameter in JavaScript\nDESCRIPTION: This code snippet shows a Service Template in JSON format with the `on_hold` parameter set to true or false. The `on_hold` parameter determines whether the VMs of the Service should be instances on hold when the Service is instantiated.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/multivm_service_management/appflow_use_cli.rst#_snippet_19\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"name\": \"my_service\",\n  \"deployment\": \"straight\",\n  \"type\": \"vm\",\n  \"template_id\": 0,\n  \"on_hold\": true|false,\n  \"roles\": [\n    {\n      ...\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configure Default Sunstone Views with YAML\nDESCRIPTION: This YAML snippet configures the default Sunstone views based on the user's primary group. Users belonging to the 'oneadmin' group will have access to both 'admin' and 'user' views. All other users will default to the 'user' view, but only if the group that the user belongs does not have the FIREEDGE attribute on his template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/fireedge_sunstone_views.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# This file describes which Sunstone views are available according to the\n# primary group a user belongs to\ngroups:\n    oneadmin:\n        - admin\n        - user\ndefault:\n    - user\n```\n\n----------------------------------------\n\nTITLE: Downloading Debian/Ubuntu/Devuan Context Package with wget\nDESCRIPTION: This command downloads the OpenNebula context package for Debian/Ubuntu/Devuan using wget. The package is retrieved from the OpenNebula GitHub releases page.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# wget https://github.com/OpenNebula/one-apps/releases/download/v|context_release|/one-context_|context_release|-1.deb\n```\n\n----------------------------------------\n\nTITLE: Datastore Transfer Manager Configuration (Shared) - Bash\nDESCRIPTION: This configuration defines another Datastore Transfer Manager configuration, focusing on shared storage. Specifically, it showcases enabling system datastore migrations using the DS_MIGRATE parameter. It demonstrates configuring shared storage with system datastore migrations.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nTM_MAD_CONF = [\n        NAME        = \"shared\",\n        LN_TARGET   = \"NONE\",\n        CLONE_TARGET= \"SYSTEM\",\n        SHARED      = \"yes\",\n        DS_MIGRATE  = \"yes\"\n    ]\n```\n\n----------------------------------------\n\nTITLE: Override Alertmanager Systemd Service (Bash)\nDESCRIPTION: This bash script overrides the default Alertmanager systemd service to configure it as a cluster peer for high availability. It modifies the ExecStart parameter to include cluster peer addresses.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n[Service]\nExecStart=\nExecStart=/usr/bin/alertmanager \\\n             --config.file=/etc/one/alertmanager/alertmanager.yml \\\n             --storage.path=/var/lib/alertmanager/data/ \\\n             --cluster.peer=192.168.150.1:9094 \\\n             --cluster.peer=192.168.150.3:9094\n```\n\n----------------------------------------\n\nTITLE: Configuring TPM Device in Libvirt XML\nDESCRIPTION: This XML snippet configures a Trusted Platform Module (TPM) device within the Libvirt virtual machine configuration. It specifies a TPM model of 'tpm-tis' and utilizes an emulator backend.  This allows the VM to use TPM functionality.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_7\n\nLANGUAGE: xml\nCODE:\n```\n<tpm model='tpm-tis'>\n  <backend type='emulator'/>\n</tpm>\n```\n\n----------------------------------------\n\nTITLE: Setting Default Patch Mode for OpenNebula Upgrade\nDESCRIPTION: This command sets the default patch mode to 'skip' for all files during the OpenNebula upgrade process. It instructs the 'onecfg upgrade' tool to skip problematic places in configuration files, preventing the upgrade from failing due to customizations.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/conflicts.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg upgrade --patch-modes skip\n```\n\n----------------------------------------\n\nTITLE: Enabling NVIDIA Virtual Functions\nDESCRIPTION: This command uses the `sriov-manage` utility to enable virtual functions on the NVIDIA GPU.  The slot, bus, domain, and function are passed as arguments. This step is crucial for enabling vGPU functionality.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# /usr/lib/nvidia/sriov-manage -e slot:bus:domain.function\n/usr/lib/nvidia/sriov-manage -e 00:41:0000.0\n```\n\n----------------------------------------\n\nTITLE: Setting OpenNebula User Credentials for CLI\nDESCRIPTION: These commands create the .one directory in the user's home directory and create the one_auth file with the OpenNebula user's password. The CLI tools use this file to authenticate with the OpenNebula Front-end. Replace \"password\" with the actual user password received by email.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_hosted.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p \"$HOME/.one\"\necho 'one:password' > \"$HOME/.one/one_auth\"\n```\n\n----------------------------------------\n\nTITLE: Log message in VM log file - Shell\nDESCRIPTION: This snippet shows how to use the 'log' function from `scripts_common.sh` to write a message to the VM log file. It takes one parameter: the message to be logged.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nlog \"Creating directory $DST_DIR\"\n```\n\n----------------------------------------\n\nTITLE: Importing a Service Template in Batch Mode\nDESCRIPTION: This command imports a Service Template into a specified marketplace in batch mode, automatically importing all related VM templates as well. It uses the `--market` and `--yes` parameters to avoid interactive prompts.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/marketapps.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nonemarketapp service-template import 0 --market 100 --yes\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Datastores\nDESCRIPTION: This command, executed as the `oneadmin` user, lists the OpenNebula datastores.  It displays information about the datastore size, available space, cluster association, image count, type, and status. Requires the OpenNebula CLI tool `onedatastore`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore list\n```\n\n----------------------------------------\n\nTITLE: Create Service Template Response\nDESCRIPTION: This is an example HTTP response (201 Created) from the OpenNebula API when a service template is successfully created. It includes headers such as Content-Type and Content-Length, as well as a JSON representation of the newly created service template. The JSON document details the template's configuration, including roles, policies, and other attributes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_8\n\nLANGUAGE: HTTP\nCODE:\n```\n> POST /service_template HTTP/1.1\n    > Authorization: Basic b25lYWRtaW46b23lbm5lYnVsYQ==\n    > User-Agent: curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.14.0.0 zlib/1.2.3 libidn/1.18 libssh2/1.4.2\n    > Host: oneflow.server:2474\n    > Accept: */*\n    > Content-Length: 771\n    > Content-Type: application/x-www-form-urlencoded\n    >\n    < HTTP/1.1 201 Created\n    < Content-Type: text/html;charset=utf-8\n    < X-XSS-Protection: 1; mode=block\n    < Content-Length: 1990\n    < X-Frame-Options: sameorigin\n    < Connection: keep-alive\n    < Server: thin 1.2.8 codename Black Keys\n    <\n    {\n      \"DOCUMENT\": {\n        \"TEMPLATE\": {\n          \"BODY\": {\n            \"deployment\": \"straight\",\n            \"name\": \"web-application\",\n            \"roles\": [\n              {\n                \"scheduled_policies\": [\n                  {\n                    \"adjust\": 4,\n                    \"type\": \"CHANGE\",\n                    \"recurrence\": \"0 2 1-10 * * \"\n                  }\n                ],\n                \"template_id\": 0,\n                \"type\": \"vm\",\n                \"name\": \"frontend\",\n                \"min_vms\": 1,\n                \"max_vms\": 4,\n                \"cardinality\": 1,\n                \"cooldown\": 30,\n                \"shutdown_action\": \"shutdown\",\n                \"elasticity_policies\": [\n                  {\n                    \"expression\": \"CUSTOM_ATT>40\",\n                    \"adjust\": 20,\n                    \"min_adjust_step\": 1,\n                    \"cooldown\": 30,\n                    \"period\": 3,\n                    \"period_number\": 30,\n                    \"type\": \"PERCENTAGE_CHANGE\"\n                  }\n                ]\n              },\n              {\n                \"scheduled_policies\": [\n\n                ],\n                \"template_id\": 0,\n                \"type\": \"vm\",\n                \"name\": \"worker\",\n                \"min_vms\": 2,\n                \"max_vms\": 10,\n                \"cardinality\": 2,\n                \"parents\": [\n                  \"frontend\"\n                ],\n                \"cooldown\": 240,\n                \"shutdown_action\": \"shutdown\",\n                \"elasticity_policies\": [\n                  {\n                    \"expression\": \"ATT=3\",\n                    \"adjust\": 5,\n                    \"cooldown\": 240,\n                    \"period\": 5,\n                    \"period_number\": 60,\n                    \"type\": \"CHANGE\"\n                  }\n                ]\n              }\n            ],\n            \"shutdown_action\": \"shutdown\"\n          }\n        },\n        \"TYPE\": \"101\",\n        \"GNAME\": \"oneadmin\",\n        \"NAME\": \"web-application\",\n        \"GID\": \"0\",\n        \"ID\": \"4\",\n        \"UNAME\": \"oneadmin\",\n        \"PERMISSIONS\": {\n          \"OWNER_A\": \"0\",\n          \"OWNER_M\": \"1\",\n          \"OWNER_U\": \"1\",\n          \"OTHER_A\": \"0\",\n          \"OTHER_M\": \"0\",\n          \"OTHER_U\": \"0\",\n          \"GROUP_A\": \"0\",\n          \"GROUP_M\": \"0\",\n          \"GROUP_U\": \"0\"\n        },\n        \"UID\": \"0\"\n      }\n    }\n```\n\n----------------------------------------\n\nTITLE: Setting PEM file permissions (Linux/macOS)\nDESCRIPTION: This command sets the permissions of the PEM file to read-only for the user, ensuring that only the user can read the file. This is a security requirement for SSH to connect properly.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\nchmod 400 <PEM file>\n```\n\nLANGUAGE: Bash\nCODE:\n```\nchmod 400 ~/.ssh/aws_pemfile.pem\n```\n\n----------------------------------------\n\nTITLE: Network Configuration (Public)\nDESCRIPTION: Configures a public network using the 'elastic' VN_MAD, specifying the bridge, netrole, DNS, and IP address range (AR) using AWS IPAM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_8\n\nLANGUAGE: YAML\nCODE:\n```\nnetworks:\n  - name: \"${provision}-public\"\n    vn_mad: 'elastic'\n    bridge: 'br0'\n    netrole: 'public'\n    dns: \"${input.dns}\"\n    provision:\n    count: \"${input.number_public_ips}\"\n    ar:\n      - provison_id: \"${provision_id}\"\n        size: '1'\n        ipam_mad: 'aws'\n```\n\n----------------------------------------\n\nTITLE: Reloading sysctl Configuration (Bash)\nDESCRIPTION: This snippet shows how to reload the sysctl configuration from the `/etc/sysctl.conf` file, applying the changes made to the kernel runtime parameters. This is necessary after modifying the `net.ipv4.igmp_max_memberships` setting to increase the multicast group limit.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/vxlan.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# sysctl -p\n```\n\n----------------------------------------\n\nTITLE: Install npm Dependencies\nDESCRIPTION: This command installs all the dependencies listed in the `package.json` file for the FireEdge project. This is a crucial first step to ensure all necessary libraries and tools are available for the project to function correctly.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ npm i         # Install dependencies from package.json\n```\n\n----------------------------------------\n\nTITLE: Checking ONEGATE_ENDPOINT Value in Bash\nDESCRIPTION: This command searches for the `ONEGATE_ENDPOINT` variable within the files located in the `/run/one-context` directory. It helps verify the IP address of the Front-end node that the VNF node is configured to connect to. The output displays the file and the value of the variable if found.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ngrep -r ONEGATE /run/one-context*\n```\n\n----------------------------------------\n\nTITLE: Syncing OpenNebula Host Configuration (bash)\nDESCRIPTION: This command shows how to propagate the configuration changes to the hypervisor hosts by executing the `onehost sync -f` command as the `oneadmin` user on the leader Front-end machine. This ensures that all hosts have the latest network configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost sync -f\n```\n\n----------------------------------------\n\nTITLE: Generating UUID\nDESCRIPTION: This snippet generates a UUID (Universally Unique Identifier) using the `uuidgen` command and stores it in the `UUID` environment variable.  This UUID is later used to identify the secret in the virtualization system.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ UUID=$(uuidgen); echo $UUID\n```\n\n----------------------------------------\n\nTITLE: Example numactl Output - Custom CPU Topology\nDESCRIPTION: This `numactl -H` output corresponds to the custom CPU topology configuration. It shows a single NUMA node utilizing all 8 CPUs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n# numactl -H\navailable: 1 nodes (0)\nnode 0 cpus: 0 1 2 3 4 5 6 7\nnode 0 size: 1023 MB\nnode 0 free: 600 MB\nnode distances:\nnode   0\n  0:  10\n```\n\n----------------------------------------\n\nTITLE: Address Template Output for get_address\nDESCRIPTION: This is an example of the template output expected from the `get_address` action.  It defines the assigned IP address and the allocated size.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-ipam.rst#_snippet_5\n\nLANGUAGE: template\nCODE:\n```\nADDRESS = [ IP = \"10.0.0.2\", SIZE=34 ]\n```\n\n----------------------------------------\n\nTITLE: Deleting Edge Cluster\nDESCRIPTION: This snippet demonstrates how to delete a provisioned edge cluster using the `oneprovision delete` command. It requires a provision ID. It can optionally use the `--cleanup` parameter to terminate VMs and delete images within the datastores before deletion, and `--delete-all` to delete contained VMs and Images.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/cluster_operations.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision delete 0 -d\n2018-11-27 12:45:21 INFO  : Deleting provision 0\n2018-11-27 12:45:21 INFO  : Undeploying hosts\n2018-11-27 12:45:23 INFO  : Deleting provision objects\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision delete 0 -d\n2018-11-27 13:44:40 INFO  : Deleting provision 0\nERROR: Provision with running VMs can't be deleted\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovision delete 0 -d --cleanup\n2018-11-27 13:56:39 INFO  : Deleting provision 0\n2018-11-27 13:56:44 INFO  : Undeploying hosts\n2018-11-27 13:56:51 INFO  : Deleting provision objects\n```\n\n----------------------------------------\n\nTITLE: NUMA Node Affinity Configuration\nDESCRIPTION: This example shows how to set NUMA node affinity, pinning the VM's virtual CPUs and memory to a specific NUMA node. This prevents VM CPU processes from migrating across NUMA nodes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_11\n\nLANGUAGE: text\nCODE:\n```\nMEMORY = 1024\nVCPU = 4\nCPU  = 1\n\nTOPOLOGY = [ NODE_AFFINITY = 1 ]\n```\n\n----------------------------------------\n\nTITLE: VM Creation Failure due to Image Permissions\nDESCRIPTION: This code snippet demonstrates an error message that appears when a user tries to create a VM without proper permissions to access the image.  It indicates that the user is not authorized to use the specified image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_groups.rst#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n[TemplateInstantiate] User [6] : Not authorized to perform USE IMAGE [0].\n```\n\n----------------------------------------\n\nTITLE: Downloading ALT Linux Context Package with wget\nDESCRIPTION: This command downloads the OpenNebula context package for ALT Linux p9, p10, and Sisyphus using wget. The package is retrieved from the OpenNebula GitHub releases page.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# wget https://github.com/OpenNebula/one-apps/releases/download/v|context_release|/one-context-|context_release|-alt1.noarch.rpm\n```\n\n----------------------------------------\n\nTITLE: Address XML for Get Address Action\nDESCRIPTION: This XML structure is sent to the get_address action.  It includes the AR (AddressRange) as previously returned, along with the requested SIZE (number of IPs).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-ipam.rst#_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<IPAM_DRIVER_ACTION_DATA>\n  <AR>\n    As returned by previous action, see above for examples.\n  </AR>\n  <ADDRESS>\n    <SIZE> Number of IPs to allocate, in a continous range from the firs IP</SIZE>\n  </ADDRESS>\n</IPAM_DRIVER_ACTION_DATA>\n```\n\n----------------------------------------\n\nTITLE: Alertmanager Configuration YAML (HA)\nDESCRIPTION: This YAML configuration snippet configures Alertmanager for high availability (HA). It defines the alertmanagers and their target addresses for deduplication of alert notifications.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_16\n\nLANGUAGE: yaml\nCODE:\n```\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets:\n      - 192.168.150.2:9093\n      - 192.168.150.3:9093\n      - 192.168.150.1:9093\n```\n\n----------------------------------------\n\nTITLE: Enable Extra Repositories for OpenNebula on RHEL/AlmaLinux\nDESCRIPTION: This bash script enables extra repositories (powertools, crb) on RHEL9 and AlmaLinux9 to resolve dependencies required for OpenNebula installation. It uses `yum` to identify and enable the necessary repositories.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nrepo=$(yum repolist --disabled | grep -i -e powertools -e crb | awk '{print $1}' | head -1)\nyum config-manager --set-enabled $repo && yum makecache\n```\n\n----------------------------------------\n\nTITLE: Masking OpenNebula SSH Authentication Agent Service\nDESCRIPTION: This command masks the OpenNebula SSH Authentication Agent service, preventing it from starting automatically. This is useful if you want to avoid using the agent and rely on other methods for cross-host connections.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/advanced_ssh_usage.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl mask opennebula-ssh-agent.service\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenNebula XML-RPC with HTTPS (YAML)\nDESCRIPTION: This YAML configuration snippet shows how to configure Sunstone to use HTTPS for the OpenNebula XML-RPC connection. This is essential when Sunstone runs on a different machine than the OpenNebula daemon to secure the communication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/cloud_auth.rst#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n:one_xmlrpc: https://frontend:2634/RPC2\n```\n\n----------------------------------------\n\nTITLE: Restricted VM Attributes Configuration\nDESCRIPTION: This snippet defines restricted VM attributes in `oned.conf`, which users cannot modify when creating or updating templates. The example restricts modification to CPU, VPU, and NIC attributes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_17\n\nLANGUAGE: none\nCODE:\n```\nVM_RESTRICTED_ATTR = \"CPU\"\nVM_RESTRICTED_ATTR = \"VPU\"\nVM_RESTRICTED_ATTR = \"NIC\"\n```\n\n----------------------------------------\n\nTITLE: Cloning a Template using onetemplate command\nDESCRIPTION: This snippet shows how to clone an existing VM template in OpenNebula using the `onetemplate clone` command.  It clones the template with ID 6 and names the new template `new_template`. The command returns the ID of the cloned template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_15\n\nLANGUAGE: text\nCODE:\n```\n$ onetemplate clone 6 new_template\nID: 7\n```\n\n----------------------------------------\n\nTITLE: Copying a Module to FireEdge Directory (Bash)\nDESCRIPTION: This command copies a module directory to the FireEdge modules directory, making it accessible to the FireEdge server.  This step is required to deploy the module for client-side use. Replace 'customContainers' with the actual module name.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\ncp -r dist/modules/customContainers /usr/lib/one/fireedge/dist/modules\n```\n\n----------------------------------------\n\nTITLE: Creating Scaleway Provider Command Output\nDESCRIPTION: This is the expected output when creating a new Scaleway provider using the command `oneprovider create provider.yaml`. It represents the ID of the created provider.  The ID is an integer value assigned by OpenNebula to uniquely identify the new provider.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/scaleway_provider.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nID: 0\n```\n\n----------------------------------------\n\nTITLE: Setting Execute Permissions on vm-pending.rb\nDESCRIPTION: Sets the execute permission (760) on the Ruby script vm-pending.rb using chmod. This allows the script to be executed by the owner and group.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ chmod 760 /var/lib/one/remotes/hooks/vm-pending.rb\n```\n\n----------------------------------------\n\nTITLE: Provider and Type Configuration\nDESCRIPTION: Specifies the image, provider (AWS), and provision type (virtual) for the cluster.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_6\n\nLANGUAGE: YAML\nCODE:\n```\nimage: 'OPENNEBULA-AWS'\nprovider: 'aws'\nprovision_type: 'virtual'\n```\n\n----------------------------------------\n\nTITLE: Creating a New User with X.509 Authentication Using DN\nDESCRIPTION: This command shows how to create a new OpenNebula user with X.509 authentication using the user's certificate subject DN. This method allows the administrator to create the user if they already know the user's DN. The specified DN is used as the password for authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/x509.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\noneuser create johndoe --x509 \"user_subject_DN\"\n```\n\n----------------------------------------\n\nTITLE: Install Required Packages for Debian/Ubuntu\nDESCRIPTION: This bash script updates the package list and installs the `gnupg`, `wget`, and `apt-transport-https` packages, which are required for adding and using HTTPS repositories in Debian and Ubuntu.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# apt-get update\n# apt-get -y install gnupg wget apt-transport-https\n```\n\n----------------------------------------\n\nTITLE: Create Virtual Network Template from File\nDESCRIPTION: This snippet demonstrates how to create a Virtual Network Template using the 'onevntemplate create' command. It reads the template definition from the 'vn_template.txt' file and creates a new template with ID 0.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vn_templates.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ cat vn_template.txt\n  NAME=vntemplate\n  VN_MAD=\"bridge\"\n  BRIDGE=\"virbr0\"\n$ onevntemplate create vn_template.txt\n  ID: 0\n```\n\n----------------------------------------\n\nTITLE: Updating the VM operating system\nDESCRIPTION: This command updates the system's package list and upgrades any outdated packages to their latest versions. This ensures the system has the latest security patches and software updates.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\napt update && apt upgrade\n```\n\n----------------------------------------\n\nTITLE: Add OpenNebula GPG Key on Debian/Ubuntu\nDESCRIPTION: This bash script downloads the OpenNebula repository signing GPG key and adds it to the system's trusted keys. This allows the system to verify the authenticity of packages from the OpenNebula repository.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# wget -q -O- https://downloads.opennebula.io/repo/repo2.key | gpg --dearmor --yes --output /etc/apt/keyrings/opennebula.gpg\n```\n\n----------------------------------------\n\nTITLE: Configuring Graphics settings in OpenNebula\nDESCRIPTION: This snippet shows how to configure graphics settings for a VM. The example sets the graphics TYPE to \"vnc\", the LISTEN IP to \"0.0.0.0\", and the PORT to \"5905\".\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_17\n\nLANGUAGE: OpenNebula Template\nCODE:\n```\nGRAPHICS = [\n      TYPE    = \"vnc\",\n      LISTEN  = \"0.0.0.0\",\n      PORT    = \"5905\"]\n```\n\n----------------------------------------\n\nTITLE: Creating Image Datastore using CLI\nDESCRIPTION: This snippet shows the command used to create an Image Datastore in OpenNebula using the onedatastore command-line tool and the ds.conf configuration file. It assumes the ds.conf file exists and holds valid configuration parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/storage_setup/ceph_ds.rst#_snippet_15\n\nLANGUAGE: text\nCODE:\n```\n> onedatastore create ds.conf\nID: 101\n```\n\n----------------------------------------\n\nTITLE: Listing LXC Profile Files\nDESCRIPTION: This bash command lists the LXC profile files located in the `/var/lib/one/remotes/etc/vmm/lxc/profiles` directory. It's crucial that the `oneadmin` user has read permissions on these files, and the `onehost sync` command is used to ensure changes are synced across the host.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/lxc_node/lxc_driver.rst#_snippet_5\n\nLANGUAGE: Bash\nCODE:\n```\nls -l /var/lib/one/remotes/etc/vmm/lxc/profiles\n...\n```\n\n----------------------------------------\n\nTITLE: Showing Open vSwitch configuration\nDESCRIPTION: This snippet shows the configuration of an Open vSwitch bridge using the `ovs-vsctl show` command. It displays the bridge name, ports, interfaces, and VLAN tags associated with the bridge. The output provides insights into the network configuration and connectivity of the Open vSwitch bridge.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/networking_setup/node.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n# ovs-vsctl show\n61a35859-c8a3-4fd0-a30e-185aa568956f\n    Bridge \"ovsbr0\"\n        Port \"enp0s8\"\n            Interface \"enp0s8\"\n        Port \"one-19-0\"\n            tag: 4\n            Interface \"one-19-0\"\n        Port \"ovsbr0\"\n            Interface \"ovsbr0\"\n                type: internal\n```\n\n----------------------------------------\n\nTITLE: Update User for X.509 Authentication with Certificate File (CLI)\nDESCRIPTION: This command updates an existing OpenNebula user to use X.509 certificate authentication using a certificate file.  Replace `johndoe` and `/tmp/my_cert.pem` with the correct values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/authentication/sunstone_auth.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\noneuser chauth johndoe --x509 --cert /tmp/my_cert.pem\n```\n\n----------------------------------------\n\nTITLE: Gettext for Translations\nDESCRIPTION: This command extracts translatable strings from the documentation source files. The extracted strings are stored in .po files which can be translated. It uses the `make` utility to call the `gettext` target.\nSOURCE: https://github.com/opennebula/docs/blob/master/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ make gettext\n```\n\n----------------------------------------\n\nTITLE: Managing OpenNebula SSH Authentication Agent Service\nDESCRIPTION: These commands are used to manage the OpenNebula SSH Authentication Agent service on the Front-end. They allow you to stop, start, or restart the service using systemctl.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/advanced_ssh_usage.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl stop    opennebula-ssh-agent.service\n# systemctl start   opennebula-ssh-agent.service\n# systemctl restart opennebula-ssh-agent.service\n```\n\n----------------------------------------\n\nTITLE: Synchronize Configuration Files via Rsync\nDESCRIPTION: This command synchronizes the `/etc/one` and `/var/lib/one/remotes/etc` directories from the leader node to a follower node using the `rsync` command.  The `<follower_ip>` placeholder should be replaced with the IP address of the follower node.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_ha.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ rsync -r /etc/one root@<follower_ip>:/etc\n$ rsync -r /var/lib/one/remotes/etc root@<follower_ip>:/var/lib/one/remotes\n```\n\n----------------------------------------\n\nTITLE: Upgrade OpenNebula Node Packages on RHEL\nDESCRIPTION: This command upgrades the OpenNebula node packages on RHEL-based systems using `yum`. The `<hypervisor>` tag should be replaced with the specific hypervisor (e.g., kvm or lxc).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_13\n\nLANGUAGE: Bash\nCODE:\n```\nyum upgrade opennebula-node-<hypervisor>\n```\n\n----------------------------------------\n\nTITLE: Becoming the oneadmin User\nDESCRIPTION: This snippet demonstrates how to switch to the `oneadmin` user using `sudo`. This is required to execute OpenNebula commands and manage cloud resources as the appropriate user.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nsudo -i -u oneadmin\n```\n\n----------------------------------------\n\nTITLE: Restricted Disk Attributes Configuration\nDESCRIPTION: This snippet defines a restricted DISK attribute in `oned.conf`, specifically `DISK/TOTAL_BYTES_SEC`, which users cannot modify. A user cannot delete any element of a list that has a restricted attributes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/vm_management/vm_templates.rst#_snippet_19\n\nLANGUAGE: none\nCODE:\n```\nVM_RESTRICTED_ATTR = \"DISK/TOTAL_BYTES_SEC\"\n```\n\n----------------------------------------\n\nTITLE: Listing SSH Keys in the Authentication Agent\nDESCRIPTION: This command lists the SSH keys that have been added to the OpenNebula SSH Authentication Agent. It requires setting the SSH_AUTH_SOCK environment variable to the agent's socket path.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/advanced_ssh_usage.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ SSH_AUTH_SOCK=/var/run/one/ssh-agent.sock ssh-add -l\n```\n\n----------------------------------------\n\nTITLE: Creating LUKS-Encrypted Image\nDESCRIPTION: This snippet creates an empty LUKS-encrypted image using `qemu-img create`. It uses a secret file containing the encryption key and specifies the size of the image.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ qemu-img create --object secret,id=sec0,file=passphrase.luks -o key-secret=sec0 -f luks /tmp/alpine-3.17.luks 256M\n```\n\n----------------------------------------\n\nTITLE: XML Authentication Request Structure\nDESCRIPTION: This XML snippet defines the structure of the authentication request passed to the authentication driver via standard input. It includes the username, password (value from OpenNebula database), and secret (value provided in the authentication string).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-auth.rst#_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<AUTHN>\n    <USERNAME>VALUE</USERNAME>\n    <PASSWORD>VALUE</PASSWORD>\n    <SECRET>VALUE</SECRET>\n</AUTHN>\n```\n\n----------------------------------------\n\nTITLE: Restarting/Reloading Proxy Daemons\nDESCRIPTION: These commands restart or reload the configuration of the proxy daemons. While they can be used for debugging, the proxy daemons are typically managed by networking drivers.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ /var/tmp/one/vnm/tproxy restart\n$ /var/tmp/one/vnm/tproxy reload\n```\n\n----------------------------------------\n\nTITLE: Configuring Retry Time for Failed VM Placements\nDESCRIPTION: This configuration sets the retry time for failed VM placements. `SCHED_RETRY_TIME` specifies the time in seconds the scheduler waits before retrying the allocation. This is used when a VM cannot be placed due to insufficient resources.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/configuration.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nSCHED_RETRY_TIME = 60\n```\n\n----------------------------------------\n\nTITLE: Updating a host using a flat dictionary\nDESCRIPTION: This snippet shows how to update a host using a flat dictionary.  The dictionary keys will become attribute-value vectors. It requires a valid host ID and a `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\none.host.update(0,  {\"LABELS\": \"HD\"}, 1)\n```\n\n----------------------------------------\n\nTITLE: Installing Hatch\nDESCRIPTION: These commands install hatch, a Python project manager. The first command installs hatch using pipx. The second command ensures that the hatch executable is in the user's PATH. The third command sources the .bashrc file to update the current shell's environment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\npipx install hatch\npipx ensurepath\nsource ~/.bashrc\n```\n\n----------------------------------------\n\nTITLE: Mount Context CD-ROM\nDESCRIPTION: These commands mount the contextualization CD-ROM, allowing access to the context.sh and token.txt files containing necessary variables for OneGate API authentication and endpoint information. This sets up the environment to interact with OneGate.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# mkdir /mnt/context\n# mount /dev/hdb /mnt/context\n# cd /mnt/context\n# ls\ncontext.sh  token.txt\n# cat context.sh\n# Context variables generated by OpenNebula\nDISK_ID='1'\nONEGATE_ENDPOINT='http://192.168.0.1:5030'\nVMID='0'\nTARGET='hdb'\nTOKEN='yes'\n\n# cat token.txt\nyCxieDUS7kra7Vn9ILA0+g==\n```\n\n----------------------------------------\n\nTITLE: Playbook List in Provision Template (YAML)\nDESCRIPTION: This snippet demonstrates how to specify a list of playbooks to be applied to a host in the provision template. In this example, the 'onprem' and 'mycustom' playbooks are defined.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/playbooks.rst#_snippet_1\n\nLANGUAGE: YAML\nCODE:\n```\n---\nplaybook:\n  - onprem\n  - mycustom\n```\n\n----------------------------------------\n\nTITLE: Importing a VM Template in Batch Mode\nDESCRIPTION: This command imports a VM Template into a specific marketplace in batch mode, automatically importing all associated images as well. The `--market` and `--yes` parameters enable non-interactive execution.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/appliances/marketapps.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nonemarketapp vm-template import 0 --market 100 --yes\n```\n\n----------------------------------------\n\nTITLE: OpenNebula apt Auth Configuration\nDESCRIPTION: This code snippet defines the structure of the `/etc/apt/auth.conf.d/opennebula.conf` file used to store OpenNebula repository credentials separately in Debian and Ubuntu. It includes the machine address, username, and password.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/opennebula_repository_configuration.rst#_snippet_10\n\nLANGUAGE: text\nCODE:\n```\nmachine enterprise.opennebula.io\nlogin <user>\npassword <password>\n```\n\n----------------------------------------\n\nTITLE: Downloading Alpine Linux Context Package with wget\nDESCRIPTION: This command downloads the OpenNebula context package for Alpine Linux using wget. The package is fetched from the OpenNebula GitHub releases page.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# wget https://github.com/OpenNebula/one-apps/releases/download/v|context_release|/one-context-|context_release|-r1.apk\n```\n\n----------------------------------------\n\nTITLE: Installing OpenNebula CLI Tools on Debian/Ubuntu\nDESCRIPTION: This command installs the opennebula-tools, opennebula-flow, and opennebula-provision packages on Debian/Ubuntu systems using apt. These packages are required for using the OpenNebula command-line interface (CLI) to manage the OpenNebula Front-end.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_hosted.rst#_snippet_0\n\nLANGUAGE: none\nCODE:\n```\napt install opennebula-tools opennebula-flow opennebula-provision\n```\n\n----------------------------------------\n\nTITLE: Building Translations\nDESCRIPTION: This command builds the translated documentation files using `sphinx-intl`. It reads the configuration from `source/conf.py` and generates the translated files.  This assumes that the .po files have been translated.\nSOURCE: https://github.com/opennebula/docs/blob/master/README.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ sphinx-intl build -c source/conf.py\n```\n\n----------------------------------------\n\nTITLE: Restarting OpenNebula\nDESCRIPTION: This snippet demonstrates how to restart the OpenNebula service using `systemctl`. Restarting the service is necessary after modifying the configuration files to apply the changes and ensure the monitoring daemon picks up the new settings.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl restart opennebula\n```\n\n----------------------------------------\n\nTITLE: Becoming root user\nDESCRIPTION: This command elevates the current user (ubuntu) to the root user. This is required for performing system-level operations such as updating the system and installing software.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\nsudo -i\n```\n\n----------------------------------------\n\nTITLE: Downloading FreeBSD Context Package with wget\nDESCRIPTION: This command downloads the OpenNebula context package for FreeBSD 12 and 13 using wget. The package is downloaded from the OpenNebula GitHub releases page.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# wget https://github.com/OpenNebula/one-apps/releases/download/v|context_release|/one-context-|context_release|_1.txz\n```\n\n----------------------------------------\n\nTITLE: Accessing Sunstone Provision GUI\nDESCRIPTION: This snippet provides the URL to access the Sunstone OneProvision GUI. Replace <your subdomain> with the actual subdomain provided for your OpenNebula hosted environment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_hosted.rst#_snippet_3\n\nLANGUAGE: none\nCODE:\n```\nhttps://<your subdomain>/fireedge/provision\n```\n\n----------------------------------------\n\nTITLE: Basic VM Template Configuration - Memory and VCPU\nDESCRIPTION: This configuration defines the basic memory and VCPU settings for a VM. The guest OS will see VCPU sockets with one core and one thread each.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nMEMORY = 1024\nVCPU   = 4\n```\n\n----------------------------------------\n\nTITLE: Example Authentication Driver Calls\nDESCRIPTION: These are example calls to an authentication driver using echo and authenticate. The example shows passing XML data via standard input, demonstrating different password values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-auth.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\necho '<AUTHN><USERNAME>test</USERNAME><PASSWORD>5</PASSWORD><SECRET>testpassword</SECRET></AUTHN>' | \\\n    authenticate\n```\n\nLANGUAGE: bash\nCODE:\n```\necho '<AUTHN><USERNAME>test</USERNAME><PASSWORD>5</PASSWORD><SECRET>another_try</SECRET></AUTHN>' | \\\n    authenticate\n```\n\nLANGUAGE: bash\nCODE:\n```\necho '<AUTHN><USERNAME>test</USERNAME><PASSWORD>5</PASSWORD><SECRET>12345</SECRET></AUTHN>' | \\\n    authenticate\n```\n\n----------------------------------------\n\nTITLE: Retrying OpenNebula Hook Execution\nDESCRIPTION: Retries a specific hook execution in OpenNebula. The command `onehook retry 0 0` retries hook ID 0 and execution ID 0. This is often used after correcting an error that caused the initial hook execution to fail.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/hook_driver.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ onehook retry 0 0\n```\n\n----------------------------------------\n\nTITLE: Connecting to VNF node via SSH\nDESCRIPTION: This command establishes an SSH connection to the VNF node as the root user. Replace `<VNF IP>` with the actual IP address of the VNF node. This allows executing commands directly on the VNF node for troubleshooting.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_18\n\nLANGUAGE: text\nCODE:\n```\nssh root@<VNF IP>\n```\n\n----------------------------------------\n\nTITLE: Updating vmm_exec_kvm.conf for custom OVMF files\nDESCRIPTION: This code snippet shows how to update the `/etc/one/vmm_exec/vmm_exec_kvm.conf` file to include custom OVMF firmware files. This is necessary when using older firmware versions for instantiated VMs. The `OVMF_UEFIS` variable needs to be modified to include the paths to the backed-up firmware files.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/guest_os/windows_best_practice.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nOVMF_UEFIS = \"/usr/share/OVMF/OVMF_CODE.fd /usr/share/OVMF/OVMF_CODE.secboot.fd /usr/share/AAVMF/AAVMF_CODE.fd /usr/share/backup_OVMF/OVMF/OVMF_CODE.fd /usr/share/backup_OVMF/OVMF/OVMF_CODE.secboot.fd\"\n```\n\n----------------------------------------\n\nTITLE: Diff Configuration Files\nDESCRIPTION: This snippet demonstrates the `onecfg diff` command, which identifies changes made by the user compared to the base configuration files.  It outputs the differences found.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg diff\n/etc/one/oned.conf\n- set DEFAULT_DEVICE_PREFIX \"\\\"sd\\\"\"\n- set VM_MAD/\"vcenter\"/ARGUMENTS \"\\\"-p -t 15 -r 0 -s sh vcenter\\\"\"\n- rm  VM_MAD/\"vcenter\"/DEFAULT\n- ins HM_MAD/ARGUMENTS \"\\\"-p 2101 -l 2102 -b 127.0.0.1\\\"\"\n- ins VM_RESTRICTED_ATTR \"\\\"NIC/FILTER\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Updating Package Lists (bash)\nDESCRIPTION: This command shows how to update package lists using `apt-get`.  This is the first step to ensure that you are installing the latest version of software, like nginx.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/onegate.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# apt-get update\n# apt-get -y install nginx\n```\n\n----------------------------------------\n\nTITLE: server_cipher Authentication Token Format (Generic)\nDESCRIPTION: This code shows the authentication token format for users with the server_cipher driver. It includes the target username to specify the user on whose behalf the operation is being performed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/cloud_auth.rst#_snippet_4\n\nLANGUAGE: generic\nCODE:\n```\nusername:target_username:secret\n```\n\n----------------------------------------\n\nTITLE: Displaying NUMA Node Details using numactl\nDESCRIPTION: This snippet shows the output of `numactl -H` on the hypervisor, displaying the NUMA node configuration, including CPU IDs, memory size, and node distances. This is essential for understanding the physical topology of the host machine.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_17\n\nLANGUAGE: Shell\nCODE:\n```\n# numactl -H\navailable: 1 nodes (0)\nnode 0 cpus: 0 1 2 3 4 5 6 7\nnode 0 size: 7805 MB\nnode 0 free: 2975 MB\nnode distances:\nnode   0\n  0:  10\n```\n\n----------------------------------------\n\nTITLE: Installing Context Package on OpenSUSE with zypper\nDESCRIPTION: This command installs the OpenNebula context package on OpenSUSE using zypper. The `--no-gpg-check` option disables GPG signature verification.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/install_steps.txt#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n# zypper --no-gpg-check install -y one-context-[0-9]*suse*rpm\n```\n\n----------------------------------------\n\nTITLE: Install Prometheus Packages (RPM)\nDESCRIPTION: Installs the OpenNebula Prometheus and Prometheus-KVM packages on RPM-based distributions (Alma, RHEL). These packages provide the Prometheus monitoring system, Alertmanager, and metric exporters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# yum -y install opennebula-prometheus opennebula-prometheus-kvm\n```\n\n----------------------------------------\n\nTITLE: Install Prometheus Packages (Deb)\nDESCRIPTION: Installs the OpenNebula Prometheus and Prometheus-KVM packages on Debian-based distributions (Ubuntu, Debian). These packages provide the Prometheus monitoring system, Alertmanager, and metric exporters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# apt -y install opennebula-prometheus opennebula-prometheus-kvm\n```\n\n----------------------------------------\n\nTITLE: Listing Network Namespaces\nDESCRIPTION: This command lists all custom network namespaces. Each active Virtual Network requires a dedicated namespace to run the proxy inside.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/tproxy.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ ip netns list\none_tproxy_br0 (id: 0)\n```\n\n----------------------------------------\n\nTITLE: Initialize onecfg (Bash)\nDESCRIPTION: Reinitializes the OpenNebula configuration state using the `onecfg` tool, forcing initialization if necessary. This is used to resolve outdated metadata errors.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ onecfg init --force\n$ onecfg status\n```\n\n----------------------------------------\n\nTITLE: Install OpenNebula Migration Package on RHEL (Bash)\nDESCRIPTION: Installs the OpenNebula migration community package on RHEL systems, which is required when upgrading OpenNebula CE.  This assumes the rpm package is already downloaded.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$\\u00a0rpm -i opennebula-migration-community*.rpm\n```\n\n----------------------------------------\n\nTITLE: PCI Device XML Output Example\nDESCRIPTION: This XML output displays details about the PCI device. It includes the device name, path, parent device, driver information, PCI class, domain, bus, slot, function, vendor ID, product ID, virtual function capabilities (maxCount), IOMMU group, and PCI-Express link capabilities.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/vgpu.rst#_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<device>\n    <name>pci_0000_41_00_0</name>\n    <path>/sys/devices/pci0000:40/0000:40:03.1/0000:41:00.0</path>\n    <parent>pci_0000_40_03_1</parent>\n    <driver>\n        <name>nvidia</name>\n    </driver>\n    <capability type='pci'>\n        <class>0x030200</class>\n        <domain>0</domain>\n        <bus>65</bus>\n        <slot>0</slot>\n        <function>0</function>\n        <product id='0x2236'/>\n        <vendor id='0x10de'>NVIDIA Corporation</vendor>\n        <capability type='virt_functions' maxCount='32'/>\n        <iommuGroup number='44'>\n        <address domain='0x0000' bus='0x40' slot='0x03' function='0x1'/>\n        <address domain='0x0000' bus='0x41' slot='0x00' function='0x0'/>\n        <address domain='0x0000' bus='0x40' slot='0x03' function='0x0'/>\n        </iommuGroup>\n        <pci-express>\n        <link validity='cap' port='0' speed='16' width='16'/>\n        <link validity='sta' speed='2.5' width='16'/>\n        </pci-express>\n    </capability>\n</device>\n```\n\n----------------------------------------\n\nTITLE: Installing OneDeploy Requirements\nDESCRIPTION: This command installs the necessary components for the OneDeploy installation, including Ansible collections and Python dependencies. It uses a Makefile to orchestrate the installation process within Hatch virtual environments.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nmake requirements\n```\n\n----------------------------------------\n\nTITLE: Disabling SSH Host Keys Checking (NOT RECOMMENDED)\nDESCRIPTION: This SSH configuration snippet completely disables SSH host key checking. This is strongly discouraged as it introduces a major security vulnerability.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/advanced_ssh_usage.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nHost *\n    StrictHostKeyChecking no\n    UserKnownHostsFile /dev/null\n```\n\n----------------------------------------\n\nTITLE: Network Template Configuration (Private)\nDESCRIPTION: Configures a private network template using the 'vxlan' VN_MAD, specifying phydev, automatic_vlan_id, netrole, vxlan_mode, vxlan_tep, ip_link_conf, and cluster_ids.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_9\n\nLANGUAGE: YAML\nCODE:\n```\nvntemplates:\n  - name: \"${provision}-private\"\n    vn_mad: 'vxlan'\n    phydev: 'eth0'\n    automatic_vlan_id: 'yes'\n    netrole: 'private'\n    vxlan_mode: 'evpn'\n    vxlan_tep: 'dev'\n    ip_link_conf: 'nolearning='\n    cluster_ids: \"${cluster.0.id}\"\n```\n\n----------------------------------------\n\nTITLE: Exporting an Image from OpenNebula Marketplace\nDESCRIPTION: This command downloads a specified image from the OpenNebula Marketplace and assigns it to a local image repository. The `-d default` flag specifies the datastore to use and the image name within quotes refers to the marketplace application. The command requires access to the OpenNebula CLI tools and network connectivity to the marketplace.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nonemarketapp export -d default 'Alpine Linux 3.17' alpine\n```\n\n----------------------------------------\n\nTITLE: List Available NPM Scripts\nDESCRIPTION: Lists the available scripts defined in the package.json file. This helps developers understand available commands for building, testing, and running the application.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm run\n```\n\n----------------------------------------\n\nTITLE: Host Provisioning Configuration\nDESCRIPTION: Configures host provisioning settings, including the IM/VM MAD, count of servers to create, and hostname pattern, with options for reserved CPU and memory.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_11\n\nLANGUAGE: YAML\nCODE:\n```\nhosts:\n\n  - im_mad: \"${input.one_hypervisor}\"\n    vm_mad: \"${input.one_hypervisor}\"\n    provision:\n    count: \"${input.number_hosts}\"\n    hostname: \"edge-vhost${index}\"\n```\n\n----------------------------------------\n\nTITLE: Fixed Policy RANK Expression\nDESCRIPTION: This RANK expression implements the fixed policy, which allows manual sorting of hosts based on the PRIORITY attribute. It prioritizes nodes with higher PRIORITY values. The PRIORITY attribute needs to be configured for the hosts. It is used directly in the OpenNebula scheduler configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/rank_scheduler.rst#_snippet_3\n\nLANGUAGE: OpenNebula\nCODE:\n```\nRANK = PRIORITY\n```\n\n----------------------------------------\n\nTITLE: Cloning OneDeploy Repository\nDESCRIPTION: This command clones the one-deploy repository from GitHub.  This repository contains the Ansible playbooks and other files necessary to deploy OpenNebula. Requires git to be installed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/OpenNebula/one-deploy.git\n```\n\n----------------------------------------\n\nTITLE: Creating Scaleway Provider in OpenNebula\nDESCRIPTION: This command creates a new Scaleway provider in OpenNebula using the provided YAML configuration file.  The command `oneprovider create provider.yaml` parses the `provider.yaml` file and registers a new provider instance within OpenNebula. The output displays the ID of the newly created provider.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/scaleway_provider.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\noneprovider create provider.yaml\n```\n\n----------------------------------------\n\nTITLE: Modifying /etc/hosts file for Custom Domain\nDESCRIPTION: Shows how to add a custom domain entry to the /etc/hosts file for local resolution when using a custom SAN for Kubernetes.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/usage_basics/running_kubernetes_clusters.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n127.0.0.1 localhost\n1.2.3.4 k8s.yourdomain.it\n```\n\n----------------------------------------\n\nTITLE: Defining a Single Attribute in XML Template\nDESCRIPTION: Illustrates the XML syntax for defining a single attribute within an OpenNebula VM template. The attribute name is represented as an XML element, and the value is its content.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<NAME>VALUE</NAME>\n```\n\n----------------------------------------\n\nTITLE: Activate Metal Provider and Provision in OpenNebula (Bash)\nDESCRIPTION: This snippet activates the Metal provider and its associated provisions in OpenNebula by creating symbolic links. It links the provision configuration from the 'edge-clusters-extra' directory to the 'edge-clusters' directory.  The |PROVISION_METAL| and |PROVIDER_METAL| variables need to be replaced with the actual values.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/activate_metal.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nln -s /usr/share/one/oneprovision/edge-clusters-extra/metal/provisions/\\ |PROVISION_METAL|\\  /usr/share/one/oneprovision/edge-clusters/metal/provisions/\nln -s /usr/share/one/oneprovision/edge-clusters-extra/metal/providers/\\ |PROVIDER_METAL|\\ /usr/share/one/oneprovision/edge-clusters/metal/providers/\\ |PROVIDER_METAL|\n```\n\n----------------------------------------\n\nTITLE: Example of Unhealthy Monitoring System Logs\nDESCRIPTION: This log example shows debug messages indicating the Host is being actively monitored periodically. This often indicates that the Monitor Daemon isn't receiving data from probes, typically caused by incorrect UDP settings. You want to see a restart of the `onemonitord` process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nSun Mar 15 22:31:55 2020 [Z0][HMM][D]: Monitoring host localhost(0)\nSun Mar 15 22:31:59 2020 [Z0][HMM][D]: Start monitor success, host: 0\nSun Mar 15 22:35:10 2020 [Z0][HMM][D]: Monitoring host localhost(0)\nSun Mar 15 22:35:19 2020 [Z0][HMM][D]: Start monitor success, host: 0\n```\n\n----------------------------------------\n\nTITLE: Build FireEdge Modules with NPM\nDESCRIPTION: Builds all the modules for the FireEdge Sunstone project using npm. This command compiles the code and prepares it for deployment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\n```\n\n----------------------------------------\n\nTITLE: Example Requirement Expression for Hypervisor\nDESCRIPTION: This example shows how to define scheduling requirements in the VM template to ensure its placement in a specific hypervisor (vcenter).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_32\n\nLANGUAGE: text\nCODE:\n```\nSCHED_REQUIREMENTS = \"HYPERVISOR=\\\"vcenter\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Create Virtual Router using onevrouter create command\nDESCRIPTION: Creates a new virtual router in OpenNebula based on the provided template file. The template defines the router's name and network interfaces.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/network_management/vrouter.rst#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ onevrouter create myvr.txt\nID: 1\n```\n\n----------------------------------------\n\nTITLE: Listing Existing Groups\nDESCRIPTION: This command lists the existing groups in OpenNebula. It requires the `onegroup` command-line tool and displays the ID and name of each group.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_groups.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onegroup list\n  ID NAME\n   0 oneadmin\n   1 users\n```\n\n----------------------------------------\n\nTITLE: Enable OpenNebula Host\nDESCRIPTION: This command enables a disabled OpenNebula host, identified by its `<host_id>`. This step is part of the OpenNebula upgrade process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_14\n\nLANGUAGE: Bash\nCODE:\n```\nonehost enable <host_id>\n```\n\n----------------------------------------\n\nTITLE: Clone OpenNebula Repository\nDESCRIPTION: Clones the OpenNebula repository from GitHub. This is the first step in setting up the development environment for customizing Sunstone.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:OpenNebula/one.git\n```\n\n----------------------------------------\n\nTITLE: Complete VM Recovery after TM Debug\nDESCRIPTION: After successfully completing the Transfer Manager actions, this command completes the VM recovery process, transitioning it to the RUNNING state. It requires the VM ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm recover 2 --success\n```\n\n----------------------------------------\n\nTITLE: VM Features Configuration\nDESCRIPTION: This snippet shows how to configure the features section of an OpenNebula VM template, including PAE, ACPI, APIC, Guest Agent and virtio queues. These options control various aspects of the VM's behavior and capabilities.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_8\n\nLANGUAGE: text\nCODE:\n```\nFEATURES = [\n        PAE = \"yes\",\n        ACPI = \"yes\",\n        APIC = \"no\",\n        GUEST_AGENT = \"yes\",\n        VIRTIO_SCSI_QUEUES = \"auto\"\n        VIRTIO_BLK_QUEUES = \"auto\"\n    ]\n```\n\n----------------------------------------\n\nTITLE: Defining the Action Timeout in OpenNebula\nDESCRIPTION: This configuration defines the action timeout. `ACTION_TIMEOUT` sets the maximum time in seconds a scheduled action can remain pending. After this time, the action is marked as a failure.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/configuration.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nACTION_TIMEOUT = 300\n```\n\n----------------------------------------\n\nTITLE: Check onecfg Status (Bash)\nDESCRIPTION: Checks the status of the OpenNebula configuration using the `onecfg` tool. Used to verify the configuration state before upgrading.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ onecfg status\n```\n\n----------------------------------------\n\nTITLE: Example of KVM Hypervisor Usage Probe Output\nDESCRIPTION: This snippet provides an example output from the KVM hypervisor usage probe. The probe collects key metrics such as memory usage, CPU usage, and network traffic, which OpenNebula uses for monitoring and resource management. The output is formatted as OpenNebula Template syntax, allowing easy integration with the OpenNebula system.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nHYPERVISOR=kvm\nUSEDMEMORY=2147156\nFREEMEMORY=5831016\nFREECPU=792\nUSEDCPU=8\nNETRX=0\nNETTX=0\n```\n\n----------------------------------------\n\nTITLE: Using Virtual Network Template Variables in OpenNebula VM Template\nDESCRIPTION: Illustrates how to use a Virtual Network template variable (DNS) from a specific network (NETWORK_ID=3) within an OpenNebula VM template.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_22\n\nLANGUAGE: text\nCODE:\n```\nDNS = \"$NETWORK[DNS, NETWORK_ID=3]\"\n```\n\n----------------------------------------\n\nTITLE: SSH Connection with Fingerprint Check\nDESCRIPTION: This command attempts to establish an SSH connection to a new node, displaying the SSH fingerprint for verification.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/advanced_ssh_usage.rst#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh -o FingerprintHash=sha256 <node4>\n```\n\n----------------------------------------\n\nTITLE: Initializing PyONE for Further Examples\nDESCRIPTION: This snippet initializes PyONE. It is a prerequisite for the following examples.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport pyone\none = pyone.OneServer(\"http://one:2633/RPC2\", session=\"oneadmin:onepass\" )\n```\n\n----------------------------------------\n\nTITLE: UsersAndGroups Component Definition (JSX)\nDESCRIPTION: This JSX code defines the `UsersAndGroups` component, which displays both a `UsersTable` and a `GroupsTable` in a two-column grid layout using Material-UI's `Grid` component. It uses React's `useState` hook to manage selected rows and integrates with the `UserAPI` for data updates. It uses shared components such as ResourcesBackButton and TranslateProvider. Actions are based on the UsersTable component.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_18\n\nLANGUAGE: jsx\nCODE:\n```\nexport function UsersAndGroups() {\n  const [selectedRows, setSelectedRows] = useState(() => [])\n  const actions = UsersTable.Actions()\n  const { zone } = useGeneral()\n\n  return (\n    <TranslateProvider>\n      <ResourcesBackButton\n        selectedRows={selectedRows}\n        setSelectedRows={setSelectedRows}\n        useUpdateMutation={UserAPI.useUpdateUserMutation}\n        zone={zone}\n        actions={actions}\n        table={(props) => (\n          <Grid container spacing={2}>\n            <Grid item sm={6}>\n              <UsersTable.Table\n                onSelectedRowsChange={props.setSelectedRows}\n                globalActions={props.actions}\n                onRowClick={props.resourcesBackButtonClick}\n                useUpdateMutation={props.useUpdateMutation}\n                zoneId={props.zone}\n                initialState={{\n                  selectedRowIds: props.selectedRowsTable,\n                }}\n              />\n            </Grid>\n\n            <Grid item sm={6}>\n              <GroupsTable.Table\n                onSelectedRowsChange={props.setSelectedRows}\n                globalActions={props.actions}\n                onRowClick={props.resourcesBackButtonClick}\n                useUpdateMutation={props.useUpdateMutation}\n                zoneId={props.zone}\n                initialState={{\n                  selectedRowIds: props.selectedRowsTable,\n                }}\n              />\n            </Grid>\n          </Grid>\n        )}\n        simpleGroupsTags={(props) => (\n          <GroupedTags\n            tags={props.selectedRows}\n            handleElement={props.handleElement}\n            onDelete={props.handleUnselectRow}\n          />\n        )}\n        info={(props) => {\n          const propsInfo = {\n            user: props?.selectedRows?.[0]?.original,\n            selectedRows: props?.selectedRows,\n          }\n          props?.gotoPage && (propsInfo.gotoPage = props.gotoPage)\n          props?.unselect && (propsInfo.unselect = props.unselect)\n\n          return <InfoTabs {...propsInfo} />\n        }}\n      />\n    </TranslateProvider>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Virtio Keyboard in vmm_exec_kvm.conf (ARM64)\nDESCRIPTION: This snippet adds a virtio keyboard to the VM configuration by modifying the `/etc/one/vmm_exec/vmm_exec_kvm.conf` file.  This ensures keyboard functionality when accessing the VM via VNC on ARM64.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/kvm_node/kvm_driver.rst#_snippet_21\n\nLANGUAGE: none\nCODE:\n```\nRAW = \"<devices><input type='keyboard' bus='virtio'/></devices>\"\n```\n\n----------------------------------------\n\nTITLE: Accessing FireEdge Sunstone URL\nDESCRIPTION: This URL provides access to the new iteration of Sunstone written in React/Redux. It's the web interface for managing the OpenNebula cloud.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/fireedge.rst#_snippet_1\n\nLANGUAGE: none\nCODE:\n```\nhttp://<OPENNEBULA-FRONTEND>:2616\n```\n\n----------------------------------------\n\nTITLE: Installing OpenNebula with sudo\nDESCRIPTION: This snippet demonstrates installing OpenNebula with system-wide mode which requires super user privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/compile.rst#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ sudo ./install.sh <install_options>\n```\n\n----------------------------------------\n\nTITLE: Recover VM with Interactive TM Debug\nDESCRIPTION: This command initiates the VM recovery process in interactive Transfer Manager (TM) debug mode. It allows manual intervention to fix issues during data transfer.  It requires the VM ID.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/troubleshooting.rst#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ onevm recover 2 --retry --interactive\n```\n\n----------------------------------------\n\nTITLE: onedb version (Text)\nDESCRIPTION: Prints the current database schema version using the `onedb version` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n$ onedb version\nShared: 5.12.0\nLocal:  5.12.0\nRequired shared version: 5.12.0\nRequired local version:  5.12.0\n```\n\n----------------------------------------\n\nTITLE: Marketplace Monitor Action Report Format\nDESCRIPTION: This snippet shows the format for the monitor action report when simple monitoring is used, reporting the available and used space in the Marketplace. The output must be in OpenNebula-syntax template format, defining USED_MB, FREE_MB, and TOTAL_MB.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-market.rst#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nUSED_MD=<USED_MB>\nFREE_MB=<FREE_MB>\nTOTAL_MB=<TOTAL_MB>\n```\n\n----------------------------------------\n\nTITLE: Example numactl Output - Basic VM Configuration\nDESCRIPTION: This is the output of the `numactl -H` command within a VM configured with the basic template. It displays the NUMA node configuration, including CPU assignments, memory size, and node distances.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n# numactl -H\navailable: 1 nodes (0)\nnode 0 cpus: 0 1 2 3\nnode 0 size: 1023 MB\nnode 0 free: 607 MB\nnode distances:\nnode   0\n  0:  10\n```\n\n----------------------------------------\n\nTITLE: Authentication Token Format (Generic)\nDESCRIPTION: This code shows the format of a regular authentication token, composed of 'username' and 'secret'.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/cloud_auth.rst#_snippet_3\n\nLANGUAGE: generic\nCODE:\n```\nusername:secret\n```\n\n----------------------------------------\n\nTITLE: Show Image Backup Information (oneimage show)\nDESCRIPTION: This command displays the information about a specific image backup, including its ID, VM ID, type, and backup increments. It's used to identify the available backup increments and their corresponding IDs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/operations.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ oneimage show 176\n```\n\n----------------------------------------\n\nTITLE: Synchronizing Host Files in OpenNebula\nDESCRIPTION: This snippet demonstrates how to synchronize driver files to hosts using the `onehost sync` command. It updates the hosts with a version lower than the one in `/var/lib/one/remotes/VERSION`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/hosts.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost sync\n```\n\n----------------------------------------\n\nTITLE: ACL Rule Examples\nDESCRIPTION: These are examples of ACL rules showing how to grant different permissions to users or groups for various resources.  The syntax defines the user/group, the resources, the allowed operations, and the scope (zone/resource ID).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/chmod.rst#_snippet_8\n\nLANGUAGE: text\nCODE:\n```\n@1      VM+IMAGE+TEMPLATE+DOCUMENT+SECGROUP/*   CREATE  *\n*       ZONE/*                                  USE     *\n*       MARKETPLACE+MARKETPLACEAPP/*            USE     *\n@1      HOST/*                                  MANAGE  #0\n@1      NET+DATASTORE/*                         USE     #0\n@106    IMAGE/#31                               USE     #0\n```\n\n----------------------------------------\n\nTITLE: Listing Datastores\nDESCRIPTION: This command lists the existing datastores in OpenNebula, including the newly created Restic datastore. It allows you to verify that the datastore has been created successfully and check its status.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/restic.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nonedatastore list\n```\n\n----------------------------------------\n\nTITLE: AWS Configuration Example (CIDR)\nDESCRIPTION: Defines the CIDR block for the AWS configuration.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_4\n\nLANGUAGE: YAML\nCODE:\n```\naws_configuration:\n    cidr: '10.0.0.0/16'\n```\n\n----------------------------------------\n\nTITLE: MONITOR_VM Message Format\nDESCRIPTION: Shows the structure of the MONITOR_VM message, including VM ID, UUID, and base64 encoded monitoring information. The monitoring information contains data about CPU, memory, disk I/O, and network traffic.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-im.rst#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nVM = [ ID=\"0\",\n           UUID=\"6c1e1565-50f4-43b6-ba71-0fe46477d2ec\",\n           MONITOR=\"Q1BVPSIxLjAxIgpNRU1PUlk9IjE0MDgxNiIKTkVUUlg9IjAiCk5FVFRYPSIwIgpESVNLUkRCWVRFUz0iNDQxNjU0NDQiCkRJU0tXUkJZVEVTPSIxMjY2Njg4IgpESVNLUkRJT1BTPSIxMjg5IgpESVNLV1JJT1BTPSI4ODEiCg==\"]\n    VM = [ ID=\"1\",\n           ... ]\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenNebula authentication with user/password\nDESCRIPTION: This snippet shows the content of the `$HOME/.one/one_auth` file, which stores the username and password for OpenNebula authentication. The format is `username:password` on a single line.  This is the default authentication mechanism.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ cat $HOME/.one/one_auth\noneadmin:opennebula\n```\n\n----------------------------------------\n\nTITLE: Default Configuration Attributes\nDESCRIPTION: Defines default configuration attributes for provision objects, including the hypervisor package, SSH private key deployment, and nested virtualization options for QEMU/KVM.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/edge_provider_drivers_development/provision_driver.rst#_snippet_10\n\nLANGUAGE: YAML\nCODE:\n```\ndefaults:\n  configuration:\n    # Select the hypervisor package to install\n    oneprovision_hypervisor: \"${input.one_hypervisor}\"\n\n    # required for copying recovery VM snaphosts to the replica host\n    opennebula_ssh_deploy_private_key: true\n\n    # Options to enable nested virtualization used for QEMU/KVM\n    opennebula_node_kvm_use_ev: true\n\n    opennebula_node_kvm_param_nested: True\n\n    opennebula_node_kvm_manage_kvm: False\n```\n\n----------------------------------------\n\nTITLE: OneDRS Configuration in oned.conf (INI)\nDESCRIPTION: Configures OneDRS initial placement in the ``/etc/one/oned.conf`` file. This involves modifying the ``SCHED_MAD`` section to use the ``one_drs`` scheduler with specific arguments, including a timeout, placement policy, and optimization policy.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/drs.rst#_snippet_0\n\nLANGUAGE: ini\nCODE:\n```\nSCHED_MAD = [\n  EXECUTABLE = \"one_sched\",\n  ARGUMENTS  = \"-t 15 -p one_drs -o one_drs\"\n]\n```\n\n----------------------------------------\n\nTITLE: Backup Datastore ls STDIN XML Example\nDESCRIPTION: This XML snippet shows the format of the data passed to the `ls` action of a backup datastore driver via standard input. It contains the VM, Datastore, and Image object information.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<DS_DRIVER_ACTION_DATA>\n  <VM>...</VM>\n  <DATASTORE>...</DATASTORE>\n  <IMAGE>...</IMAGE>\n</DS_DRIVER_ACTION_DATA>\n```\n\n----------------------------------------\n\nTITLE: Getting Virtual Machine Information\nDESCRIPTION: This snippet retrieves and displays virtual machine information, including ID, NAME, and TEMPLATE. Requires a valid `OneServer` instance.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/python.rst#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmy_vm = one.vmpool.info(-1,-1,-1,-1).VM[0]\nmy_vm.get_ID()\nmy_vm.get_NAME()\nmy_vm.get_TEMPLATE()\n```\n\n----------------------------------------\n\nTITLE: Virtual Machine Hook Configuration - Bash\nDESCRIPTION: This configuration defines a Virtual Machine Hook, specifying when the hook should be executed (ON), the command to execute, and any arguments for the command. It details the name of the hook, execution trigger based on VM state, command to run, arguments passed, and remote execution setting.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/oned.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nVM_HOOK = [\n      name      = \"advanced_hook\",\n      on        = \"CUSTOM\",\n      state     = \"ACTIVE\",\n      lcm_state = \"BOOT_UNKNOWN\",\n      command   = \"log.rb\",\n      arguments = \"$ID $PREV_STATE $PREV_LCM_STATE\" ]\n```\n\n----------------------------------------\n\nTITLE: Listing Clusters After Creation with onecluster\nDESCRIPTION: This snippet lists the OpenNebula clusters after creating a new cluster named 'production'. It shows the updated output of the `onecluster list` command, including the newly created cluster and its initial resource counts. The command takes no parameters.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/cluster_guide.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ onecluster list\n  ID NAME            HOSTS NETS  DATASTORES\n 100 production      0     0     0\n```\n\n----------------------------------------\n\nTITLE: onedb history (Text)\nDESCRIPTION: Shows the upgrade history of the OpenNebula database using the `onedb history` command. Includes connection parameters for MySQL/MariaDB.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\n$ onedb history -S localhost -u oneadmin -p oneadmin -d opennebula\nVersion:   3.0.0\nTimestamp: 10/07 12:40:49\nComment:   OpenNebula 3.0.0 daemon bootstrap\n\n...\n\nVersion:   3.7.80\nTimestamp: 10/08 17:36:15\nComment:   Database migrated from 3.6.0 to 3.7.80 (OpenNebula 3.7.80) by onedb command.\n\nVersion:   3.8.0\nTimestamp: 10/19 16:04:17\nComment:   Database migrated from 3.7.80 to 3.8.0 (OpenNebula 3.8.0) by onedb command.\n```\n\n----------------------------------------\n\nTITLE: List OpenNebula Hosts\nDESCRIPTION: Lists the registered hosts in OpenNebula using the `onehost list` command. This is a prerequisite for configuring Prometheus to scrape metrics from the hosts.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/prometheus/install.rst#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost list\nID NAME                          CLUSTER    TVM      ALLOCATED_CPU      ALLOCATED_MEM STAT\n 1 kvm-local-uimw3-2.test        default      0       0 / 100 (0%)     0K / 1.2G (0%) on\n 0 kvm-local-uimw3-1.test        default      0       0 / 100 (0%)     0K / 1.2G (0%) on\n```\n\n----------------------------------------\n\nTITLE: Get path from parameter - Shell\nDESCRIPTION: This snippet uses the `arg_path` function from `scripts_common.sh` to extract the path part from a given parameter, storing it in the `SRC_PATH` variable.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nSRC_PATH=`arg_path $SRC`\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenNebula configuration\nDESCRIPTION: This snippet illustrates the basic usage of the `onecfg init` command to initialize the configuration management state based on the currently installed OpenNebula version.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg init\nINFO  : Initialized on version 5.10.0\n```\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg init\nANY   : Already initialized\n```\n\n----------------------------------------\n\nTITLE: Inspecting Disk for Context Injection\nDESCRIPTION: Example output of inspecting the disk for context injection by oneswap.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/ova_management/import_ova.rst#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nInspecting disk...Done (3.92s)\n```\n\n----------------------------------------\n\nTITLE: Stopping, Starting, and Restarting OpenNebula Services\nDESCRIPTION: These commands use systemctl to manage the OpenNebula service.  `systemctl stop opennebula` halts the service, `systemctl start opennebula` initiates it, `systemctl restart opennebula` restarts it and `systemctl try-restart opennebula` restarts the service only if it is already running. These commands require root privileges.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/frontend_installation/install.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n# systemctl stop        opennebula\n# systemctl start       opennebula\n# systemctl restart     opennebula\n# systemctl try-restart opennebula\n```\n\n----------------------------------------\n\nTITLE: Creating a Host Error Hook\nDESCRIPTION: This command creates a host hook in OpenNebula using the definition file `/usr/share/one/examples/host_hooks/error_hook`. The hook is triggered when a host transitions to the ERROR state and executes the script specified in the definition file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/ha/vm_ha.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nonehook create /usr/share/one/examples/host_hooks/error_hook\n```\n\n----------------------------------------\n\nTITLE: Show Linux Bridge Configuration (Bash)\nDESCRIPTION: This snippet demonstrates how to display existing Linux bridge interfaces using the `ip link show type bridge` command. This is useful for verifying bridge setup on OpenNebula hosts.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/networking.txt#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# ip link show type bridge\n4: br0: ...\n5: br1: ...\n```\n\n----------------------------------------\n\nTITLE: Disable OpenNebula Host (Bash)\nDESCRIPTION: Disables a specific host within OpenNebula to prevent monitoring processes during the upgrade. Requires the host's ID as input.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_single.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ onehost disable <host_id>\n```\n\n----------------------------------------\n\nTITLE: Creating Cloud Configuration Directory\nDESCRIPTION: These commands create a directory called my-one and change the current directory to it. This directory will contain the configuration files for the OpenNebula installation.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_shared_ds.rst#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nmkdir my-one\ncd my-one\n```\n\n----------------------------------------\n\nTITLE: Example of Healthy Monitoring System Logs\nDESCRIPTION: This example shows log entries indicating successful monitoring of VMs and hosts. The logs confirm that OpenNebula is receiving monitoring data periodically from the VMs and hosts, which ensures the monitoring system is functioning correctly. The data from this process are used in the Sunstone UI and accessed via the CLI.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nSun Mar 15 22:12:15 2020 [Z0][HMM][I]: Successfully monitored VM: 0\nSun Mar 15 22:13:10 2020 [Z0][HMM][I]: Successfully monitored host: 0\nSun Mar 15 22:13:45 2020 [Z0][HMM][I]: Successfully monitored VM: 2\nSun Mar 15 22:15:10 2020 [Z0][HMM][I]: Successfully monitored host: 1\n```\n\n----------------------------------------\n\nTITLE: Equinix Provider YAML Template\nDESCRIPTION: This YAML template defines an Equinix provider for OpenNebula. It includes the provider name, description, connection details (token, project, facility), and input options for the operating system and plan.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/providers/equinix_provider.rst#_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\nname: 'equinix-amsterdam'\n\ndescription: 'Edge cluster in Equinix Amsterdam'\nprovider: 'equinix'\n\nplain:\n   provision_type: 'metal'\n\nconnection:\n  token: 'Equinix token'\n  project: 'Equinix project'\n  facility: 'ams1'\n\ninputs:\n  - name: 'equinix_os'\n    type: 'list'\n    default: 'ubuntu_20_04'\n    options:\n      - 'ubuntu_20_04'\n  - name: 'equinix_plan'\n    type: 'list'\n    default: 't1.small'\n    options:\n      - 't1.small'\n      - 'c1.small'\n      - 'm1.xlarge'\n```\n\n----------------------------------------\n\nTITLE: Configure Authentication Driver in oned.conf\nDESCRIPTION: This snippet shows how to configure the authentication driver in the oned.conf file. Specifically, adding the \"length\" driver to the `authn` list.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-auth.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nAUTH_MAD = [\n    executable = \"one_auth_mad\",\n    authn = \"ssh,x509,ldap,server_cipher,server_x509,length\"\n]\n```\n\n----------------------------------------\n\nTITLE: Installing Spell Checking Dependencies with pip\nDESCRIPTION: This command installs the Python packages required for spell checking the documentation using pip.  It installs sphinxcontrib-spelling and pyenchant, which are used to identify spelling errors in the documentation source files.\nSOURCE: https://github.com/opennebula/docs/blob/master/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install sphinxcontrib-spelling pyenchant\n```\n\n----------------------------------------\n\nTITLE: Applying a Configuration Patch from a File (line format)\nDESCRIPTION: This example shows how to apply a configuration patch by reading the patch data from a file named `/tmp/diff-oned1`.  The `onecfg patch` command is used with the `--format line` option to specify that the patch data is in the `line` format.  The `--verbose` flag provides detailed output during the patch application process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg patch --verbose --format line /tmp/diff-oned1\n```\n\n----------------------------------------\n\nTITLE: Forcing reinitialization with specific version\nDESCRIPTION: This snippet shows how to force reinitialization and specify a target configuration version using the `--force` and `--to` parameters. This allows overriding the automatically detected version.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/configuration_management/usage.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# onecfg init --force --to 5.8.0\nINFO  : Initialized on version 5.8.0\n```\n\n----------------------------------------\n\nTITLE: JSON Configuration Example\nDESCRIPTION: Shows the structure for configuring remote modules in Sunstone using a JSON file. Each module entry specifies the module's name and the URL to its remoteEntry.js file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_4\n\nLANGUAGE: JSON\nCODE:\n```\n{\n    \"<ModuleKey>\": {\n        \"name\": \"<ModuleName>\",\n        \"entry\": \"<ModuleEntryURL>\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Sunstone via Command Line\nDESCRIPTION: This code snippet shows how to access the Sunstone web UI using a web browser. It uses HTTPS on port 2616, which is the default port for Sunstone. The FRONT-END IP should be replaced with the actual IP address of the OpenNebula front-end server.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/operation_basics/provisioning_edge_cluster.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhttps://<FRONT-END IP>:2616/fireedge/provision\n```\n\n----------------------------------------\n\nTITLE: Checking the kernel version\nDESCRIPTION: This command displays information about the running kernel, including its version. It can be used to verify that the VM is running the expected kernel version after an update and restart.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_5\n\nLANGUAGE: Bash\nCODE:\n```\nuname -a\n```\n\n----------------------------------------\n\nTITLE: Copying known_hosts file to nodes using scp\nDESCRIPTION: This command copies the `known_hosts` file from the front-end to the specified node using `scp`. The `-p` option preserves the modification times, access times, and modes from the original file. This is done to ensure that the SSH client can verify the identity of the remote host. <node1>, <node2>, <node3>, etc. should be replaced with the actual hostnames or IP addresses.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/passwordless_ssh.txt#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ scp -p /var/lib/one/.ssh/known_hosts <node1>:/var/lib/one/.ssh/\n$ scp -p /var/lib/one/.ssh/known_hosts <node2>:/var/lib/one/.ssh/\n$ scp -p /var/lib/one/.ssh/known_hosts <node3>:/var/lib/one/.ssh/\n```\n\n----------------------------------------\n\nTITLE: Storage Fixed Policy RANK Expression\nDESCRIPTION: This RANK expression implements the storage fixed policy, which allows manual sorting of datastores based on the PRIORITY attribute. It prioritizes datastores with higher PRIORITY values. The PRIORITY attribute must be set on the datastores. It is used in OpenNebula scheduler for selecting datastores.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/capacity_planning/scheduler/rank_scheduler.rst#_snippet_6\n\nLANGUAGE: OpenNebula\nCODE:\n```\nRANK = PRIORITY\n```\n\n----------------------------------------\n\nTITLE: Example of NUMA Configuration Probe Output\nDESCRIPTION: This snippet presents sample output from the NUMA configuration probe. It gives detailed information about the NUMA node configuration, including huge page sizes, CPU cores assigned to each node, and memory node details. This data is vital for optimizing VM placement and resource allocation in NUMA-aware environments.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/configuration.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\nHUGEPAGE = [ NODE_ID = \"0\", SIZE = \"2048\", PAGES = \"0\" ]\nHUGEPAGE = [ NODE_ID = \"0\", SIZE = \"1048576\", PAGES = \"0\" ]\nCORE = [ NODE_ID = \"0\", ID = \"3\", CPUS = \"3,7\" ]\nCORE = [ NODE_ID = \"0\", ID = \"1\", CPUS = \"1,5\" ]\nCORE = [ NODE_ID = \"0\", ID = \"2\", CPUS = \"2,6\" ]\nCORE = [ NODE_ID = \"0\", ID = \"0\", CPUS = \"0,4\" ]\nMEMORY_NODE = [ NODE_ID = \"0\", TOTAL = \"7978172\", DISTANCE = \"0\" ]\n```\n\n----------------------------------------\n\nTITLE: Controlling Backup Process in OpenNebula\nDESCRIPTION: These commands allow to cancel any ongoing or pending VM backup operations and retry the backup process for VMs in the ERROR set.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/backups/backup_jobs.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncancel\n```\n\nLANGUAGE: bash\nCODE:\n```\nretry\n```\n\n----------------------------------------\n\nTITLE: Get OneGate Endpoints Information\nDESCRIPTION: This curl command retrieves information about the available endpoints in OneGate using the /service endpoint. It requires the X-ONEGATE-TOKEN and X-ONEGATE-VMID headers for authentication.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/onegate_api.rst#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X \"GET\" \"${ONEGATE_ENDPOINT}/service\" \\\n    --header \"X-ONEGATE-TOKEN: `cat token.txt`\" \\\n    --header \"X-ONEGATE-VMID: $VMID\"\n\n{\n    \"vm_info\": \"http://<onegate_endpoint>/vm\",\n    \"service_info\": \"http://<onegate_endpoint>/service\"\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying Marketplace Size\nDESCRIPTION: This snippet shows how to modify the default size of the S3 Marketplace. By changing the value of `TOTAL_MB_DEFAULT` in the `/var/lib/one/remotes/market/s3/monitor` file, the maximum size of the Marketplace can be adjusted. Modifying OpenNebula internals is generally discouraged due to potential upgrade issues.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/marketplace/private_marketplaces/market_s3.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nTOTAL_MB_DEFAULT = 1048576 # Default maximum 1TB\n```\n\n----------------------------------------\n\nTITLE: STATE_VM Message Format\nDESCRIPTION: Defines the structure of the STATE_VM message in OpenNebula, which includes the VM ID, deploy ID, UUID, and the VM's current state (e.g., RUNNING, POWEROFF).\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-im.rst#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nVM=[\n      ID=115,\n      DEPLOY_ID=one-115,\n      UUID=\"6c1e1565-50f4-43b6-ba71-0fe46477d2ec\",\n      STATE=\"RUNNING\" ]\n    VM=[\n      ID=116,\n      DEPLOY_ID=one-116,\n      UUID=\"1a3f2513-50f4-43b6-ba71-0fe46477d2ec\",\n      STATE=\"POWEROFF\" ]\n```\n\n----------------------------------------\n\nTITLE: Installing OpenNebula using install.sh\nDESCRIPTION: This snippet demonstrates how to install OpenNebula using the `install.sh` script with various options. These options allow for specifying the installation user, group, and target directory, along with choices for client utilities and components.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/compile.rst#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n./install.sh <install_options>\n```\n\n----------------------------------------\n\nTITLE: Resolving Remote Modules Path (JavaScript)\nDESCRIPTION: This JavaScript code snippet defines the path to the remotes-config.json file.  It then loads the configuration.  This path is dynamically determined based on the environment (production vs. development).  The loaded configuration is then used to configure remote module resolution within Webpack.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_29\n\nLANGUAGE: javascript\nCODE:\n```\n// The path to the remotes-config.json file, necessary in order to resolve cross-module dependencies when building.\nconst remotesConfigPath =\n  process.env.NODE_ENV === 'production'\n    ? `${ETC_LOCATION}/one/fireedge/sunstone/remotes-config.json`\n    : path.resolve(\n        __dirname,\n        '..',\n        '..',\n        '..',\n        'etc',\n        'sunstone',\n        'remotes-config.json'\n      )\n\nconst remotesConfig = require(remotesConfigPath)\n\nconst configuredRemotes = Object.entries(remotesConfig)\n  .filter(([_, { name }]) => name !== moduleName)\n  .reduce((acc, [module, { name }]) => {\n    acc[\n      `@${module}`\n    ] = `${name}@[window.__REMOTES_MODULE_CONFIG__.${module}.entry]`\n\n    return acc\n  }, {})\n```\n\n----------------------------------------\n\nTITLE: VM Configuration Example\nDESCRIPTION: This example shows the configuration of a Virtual Machine with two disks, one non-persistent and one persistent.  The IMAGE_ID attribute specifies the image used for each disk.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_3\n\nLANGUAGE: config\nCODE:\n```\nNAME   = vm01\nCPU    = 0.1\nMEMORY = 64\n\nDISK   = [ IMAGE_ID = 0 ] # non-persistent disk\nDISK   = [ IMAGE_ID = 1 ] # persistent disk\n```\n\n----------------------------------------\n\nTITLE: Example PUT Request and Response Headers\nDESCRIPTION: This snippet provides an example of the HTTP headers exchanged during a PUT request to update a service, including the request headers sent by the client and the response headers returned by the server, followed by a partial JSON response from the server.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/system_interfaces/appflow_api.rst#_snippet_24\n\nLANGUAGE: text\nCODE:\n```\n> PUT /service/4 HTTP/1.1\n> Authorization: Basic b25lYWRtaW46b3Blbm5lYnVsYQ==\n> User-Agent: curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.14.0.0 zlib/1.2.3 libidn/1.18 libssh2/1.4.2\n> Host: 127.0.0.1:2474\n> Accept: */*\n> Content-Length: 1219\n> Content-Type: application/x-www-form-urlencoded\n> Expect: 100-continue\n>\n* Done waiting for 100-continue\n< HTTP/1.1 200 OK\n< Content-Type: text/html;charset=utf-8\n< X-XSS-Protection: 1; mode=block\n< Content-Length: 1995\n< X-Frame-Options: sameorigin\n< Connection: keep-alive\n< Server: thin 1.2.8 codename Black Keys\n<\n{\n  \"DOCUMENT\": {\n    \"TEMPLATE\": {\n      \"BODY\": {\n        \"deployment\": \"straight\",\n        \"name\": \"web-application\",\n        \"roles\": [\n          {\n            \"scheduled_policies\": [\n              {\n                \"adjust\": 4,\n                \"type\": \"CHANGE\",\n                \"recurrence\": \"0 2 1-10 * * \"\n              }\n            ],\n            \"template_id\": 0,\n            \"type\": \"vm\",\n            \"name\": \"frontend\",\n            \"min_vms\": 1,\n            \"max_vms\": 4,\n            \"cardinality\": 1,\n            \"cooldown\": 30,\n            \"shutdown_action\": \"shutdown-hard\",\n            ...\n\n```\n\n----------------------------------------\n\nTITLE: Displaying user information (regular user)\nDESCRIPTION: This snippet demonstrates a regular user attempting to list all users, which fails due to lack of authorization. Then, it shows the regular user displaying their own information successfully.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/users_groups_management/manage_users.rst#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ oneuser list\n[UserPoolInfo] User [2] not authorized to perform action on user.\n\n$ oneuser show\nUSER 2 INFORMATION\nID             : 2\nNAME           : regularuser\nGROUP          : 1\nPASSWORD       : 5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8\n```\n\n----------------------------------------\n\nTITLE: Set Image Ownership Using User and Group Names (YAML)\nDESCRIPTION: This snippet demonstrates how to set image ownership using user and group names within OneProvision's YAML configuration. It uses `uname` and `gname` within the `meta` section, in addition to the `mode` attribute, to define the owner, group, and permissions.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/references/virtual.rst#_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nimages:\n    - name: \"test_image\"\n      ds_id: 1\n      size: 2048\n      meta:\n        uname: user1\n        gname: users\n        mode: 644\n```\n\n----------------------------------------\n\nTITLE: Copy Database Backup (Shell)\nDESCRIPTION: This command copies the database backup file to the backup directory. Replace <onedb_backup> with the actual path to the backup file.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/replace_failing_fe.rst#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncp -rp <onedb_backup> $BAK_DIR\n```\n\n----------------------------------------\n\nTITLE: Listing OpenNebula Virtual Machines\nDESCRIPTION: This command lists the OpenNebula virtual machines in the system. It displays information such as ID, user, group, name, state, CPU usage, memory usage, host, and running time. It requires the OpenNebula CLI tool `onevm`.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/automatic_deployment/one_deploy_tutorial_local_ds.rst#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nonevm list\n```\n\n----------------------------------------\n\nTITLE: Build FireEdge Modules\nDESCRIPTION: This command executes the `build` script defined in the `package.json` file.  It's responsible for compiling and bundling all the modules within the FireEdge project into a distributable format. This ensures that all code is optimized and ready for deployment.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ npm run build # Build all the modules. \n```\n\n----------------------------------------\n\nTITLE: Restarting the VM\nDESCRIPTION: This command restarts the VM immediately. This is often required after kernel upgrades to ensure the new kernel is loaded.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/quick_start/deployment_basics/try_opennebula_on_kvm.rst#_snippet_4\n\nLANGUAGE: Bash\nCODE:\n```\nshutdown -r now\n```\n\n----------------------------------------\n\nTITLE: Automatically Accepting New SSH Host Keys\nDESCRIPTION: This SSH configuration snippet automatically accepts new SSH host keys during the first connection. While it reduces security, it improves usability by avoiding manual key verification. Only use with OpenSSH 7.6 and newer.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/large-scale_deployment/advanced_ssh_usage.rst#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nHost *\n    StrictHostKeyChecking accept-new\n```\n\n----------------------------------------\n\nTITLE: Tab Manifest JSON Configuration\nDESCRIPTION: Defines the structure for the tab-manifest.json file, which controls the loading of components and dynamic tab management in Sunstone. This configuration specifies the tab's title, path, sidebar visibility, icon, module ID, and component name.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_6\n\nLANGUAGE: JSON\nCODE:\n```\n{\n    \"title\": \"<TabTitle>\",\n    \"path\": \"<TabPath>\",\n    \"sidebar\": \"<ShowInSidebar>\",\n    \"icon\": \"<IconName>\",\n    \"moduleId\": \"<ModuleIdentifier>\",\n    \"Component\": \"<ComponentName>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting an Edge Provider using oneprovider in OpenNebula\nDESCRIPTION: This snippet demonstrates how to delete an Edge provider using the `oneprovider delete` command in OpenNebula. It takes the provider's ID as input and removes the provider from the system. An error will occur if the provider is in use.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/provision_clusters/operations/provider_operations.rst#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ oneprovider delete 2\n```\n\n----------------------------------------\n\nTITLE: Error message to oned - Shell\nDESCRIPTION: This snippet demonstrates using the `error_message` function from `scripts_common.sh` to send an error message to the OpenNebula daemon. It surrounds the message with separators and exits the script.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/sd.rst#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nerror_message \"File '$FILE' not found\"\n```\n\n----------------------------------------\n\nTITLE: Export Users Component from Users/index.js (JavaScript)\nDESCRIPTION: This JavaScript code snippet updates the exports inside the `src/modules/customContainers/Users/index.js` file to point to the correct directory, `Users/Users`. This ensures that the component is correctly exported and can be imported by other modules.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_20\n\nLANGUAGE: javascript\nCODE:\n```\nexport * from '@modules/customContainers/Users/Users'\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Resource Forecasting\nDESCRIPTION: This YAML snippet shows the default configuration options for resource forecasting in OpenNebula, located at `/var/lib/one/remotes/kvm-probes.d/forecast.conf`. It defines the `db_retention`, `forecast_period`, and `forecast_far_period` settings for both hosts and virtual machines, allowing administrators to adjust storage usage and prediction accuracy.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/monitor_alert/forecast.rst#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nhost:\n    db_retention: 4  # Weeks\n    forecast_period: 5  # Minutes\n    forecast_far_period: 720  # Hours (30 days)\n\nvirtualmachine:\n    db_retention: 2  # Weeks\n    forecast_period: 5  # Minutes\n    forecast_far_period: 48  # Hours (2 days)\n```\n\n----------------------------------------\n\nTITLE: Modify Module Name in Webpack Config (JavaScript)\nDESCRIPTION: This JavaScript code snippet shows the modification required in the webpack configuration file (`webpack.config.prod.customcontainers.js`).  It updates the module name from `ContainersModule` to `CustomContainers`. This ensures that the module is correctly identified during the build process.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/sunstone_dev.rst#_snippet_15\n\nLANGUAGE: javascript\nCODE:\n```\n// We will update the module name at the top to `CustomContainers`\nconst moduleName = 'ContainersModule'\n```\n\n----------------------------------------\n\nTITLE: Directory structure for custom network driver hooks\nDESCRIPTION: This code block illustrates the directory structure of the bridge network driver, showing the location of custom scripts for pre, post, and clean actions within the action.d directories. These scripts are executed in alphabetical order after the main driver action is successfully executed.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/infrastructure_drivers_development/devel-nm.rst#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nroot@ubuntu1804-local-6ee11-2:/var/tmp/one/vnm/bridge# tree ./\n./\nâ”œâ”€â”€ clean\nâ”œâ”€â”€ clean.d\nâ”‚Â Â  â”œâ”€â”€ 01_del_fdb\nâ”‚Â Â  â”œâ”€â”€ 02_del_routes\nâ”œâ”€â”€ post\nâ”œâ”€â”€ post.d\nâ”‚Â Â  â”œâ”€â”€ 01_add_fdb\nâ”‚Â Â  â”œâ”€â”€ 02_add_routes\nâ”œâ”€â”€ pre\nâ”œâ”€â”€ pre.d\nâ”‚Â Â  â”œâ”€â”€ 01_update_router\nâ””â”€â”€ update_sg\n```\n\n----------------------------------------\n\nTITLE: Compiling OpenNebula with scons\nDESCRIPTION: This snippet shows how to compile OpenNebula using the scons command. It can be parallelized using the `-j` parameter to specify the number of threads.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/compile.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ scons [OPTION=VALUE]\n```\n\n----------------------------------------\n\nTITLE: Generated NUMA Node Entries\nDESCRIPTION: These are the `NUMA_NODE` entries that OpenNebula generates based on the NUMA topology definition. Each entry represents a NUMA node with its associated memory and total CPUs.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/host_cluster_management/numa.rst#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\nNUMA_NODE = [ MEMORY = 512, TOTAL_CPUS = 4 ]\nNUMA_NODE = [ MEMORY = 512, TOTAL_CPUS = 4 ]\n```\n\n----------------------------------------\n\nTITLE: Building Documentation with Make\nDESCRIPTION: This command builds the documentation using the make utility. It assumes that Sphinx is installed and configured. The output will be HTML files in the build directory.\nSOURCE: https://github.com/opennebula/docs/blob/master/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmake html\n```\n\n----------------------------------------\n\nTITLE: Disable OpenNebula Zone via CLI\nDESCRIPTION: This command disables an OpenNebula zone using the `onezone` command-line tool. It is applicable for upgrades from version 6.2+. The `<zone_id>` placeholder must be replaced with the actual ID of the zone to be disabled.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/intro_release_notes/upgrades/upgrading_ha.rst#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ onezone disable <zone_id>\n```\n\n----------------------------------------\n\nTITLE: Defining SCHED_REQUIREMENTS for MAC Address in OpenNebula\nDESCRIPTION: This snippet shows how to define SCHED_REQUIREMENTS to ensure a VM runs on a host with a specific MAC address, effectively creating a MAC pinning configuration. It utilizes the NIC[MAC] attribute to match the VM's MAC address with the host's network interface MAC address.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/references/template.rst#_snippet_33\n\nLANGUAGE: text\nCODE:\n```\nSCHED_REQUIREMENTS = \"MAC=\\\"$NIC[MAC]$\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining and Setting Secret in Virsh\nDESCRIPTION: This snippet defines a secret in Virsh using the `secret.xml` file and then sets its value using the content of the `passphrase.luks` file.  The UUID is extracted from the XML file using `sed` before being used in the `secret-set-value` command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/management_and_operations/storage_management/images.rst#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\n$ virsh -c qemu:///system secret-define secret.xml\n\n$ virsh -c qemu:///system secret-set-value $(sed -n 's:.*<uuid>\\(.*\\)</uuid>.*:\\1:p' secret.xml) --file passphrase.luks --plain\n```\n\n----------------------------------------\n\nTITLE: Install EPEL Release on RHEL 8 using rpm\nDESCRIPTION: This command installs the epel-release package on RHEL 8 using rpm. It downloads the package directly from the Fedora project's website and installs it using the rpm -ivh command.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/open_cluster_deployment/common_node/epel.txt#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\n```\n\n----------------------------------------\n\nTITLE: Installing Build Dependencies (Ubuntu)\nDESCRIPTION: This command installs the required build dependencies for OpenNebula on Ubuntu 22.04 and 24.04 using the apt package manager, followed by installing bower via npm. It combines multiple package installations into a single command for convenience.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/integration_and_development/references/build_deps.rst#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\napt install bash-completion debhelper default-jdk freerdp2-dev grunt javahelper libaugeas-dev libcairo2-dev libcurl4-openssl-dev libmysql++-dev libmysqlclient-dev libnode-dev libossp-uuid-dev libpango1.0-dev libpulse-dev libsqlite3-dev libssh2-1-dev libssl-dev libsystemd-dev libtool libvncserver-dev libvorbis-dev libwebp-dev libws-commons-util-java libxml2-dev libxmlrpc-c++8-dev libxslt1-dev libzmq3-dev libzmq5 nodejs npm python3 python3-pip python3-setuptools rake ruby-dev scons unzip && npm install -g bower\n```\n\n----------------------------------------\n\nTITLE: onedb update-history (Text)\nDESCRIPTION: Updates the scheduling record of a previous VM sequence interactively using the `onedb update-history` command. This opens an editor to modify the XML of the specified sequence.\nSOURCE: https://github.com/opennebula/docs/blob/master/source/installation_and_configuration/opennebula_services/database.rst#_snippet_8\n\nLANGUAGE: text\nCODE:\n```\n$ onedb update-history --id 224 --seq 0\n```"
  }
]