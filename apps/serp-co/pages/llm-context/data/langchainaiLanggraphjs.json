[
  {
    "owner": "langchain-ai",
    "repo": "langgraphjs",
    "content": "TITLE: Creating a ReAct Agent with LangGraphJS\nDESCRIPTION: This JavaScript code defines a ReAct agent using LangGraphJS's prebuilt `createReactAgent` function. It initializes a ChatOpenAI model, defines a `getWeather` tool using `@langchain/core/tools` and a Zod schema, and then creates the agent by passing the LLM and the tool to `createReactAgent`.  The `getWeather` tool returns hardcoded weather data based on the input location.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/create-react-agent.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n\"import { ChatOpenAI } from \\\"@langchain/openai\\\";\\nimport { tool } from '@langchain/core/tools';\\nimport { z } from 'zod';\\nimport { createReactAgent } from \\\"@langchain/langgraph/prebuilt\\\";\\n\\nconst model = new ChatOpenAI({\\n  model: \\\"gpt-4o\\\",\\n});\\n\\nconst getWeather = tool((input) => {\\n  if (['sf', 'san francisco', 'san francisco, ca'].includes(input.location.toLowerCase())) {\\n    return 'It\\\\\\'s 60 degrees and foggy.';\\n  } else {\\n    return 'It\\\\\\'s 90 degrees and sunny.';\\n  }\\n}, {\\n  name: 'get_weather',\\n  description: 'Call to get the current weather.',\\n  schema: z.object({\\n    location: z.string().describe(\\\"Location to get the weather for.\\\"),\\n  })\\n})\\n\\nconst agent = createReactAgent({ llm: model, tools: [getWeather] });\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Human-in-the-Loop Essay Review Workflow with LangGraphJS Functional API\nDESCRIPTION: This code demonstrates a simple workflow that writes an essay on a given topic and then interrupts to request human review. It uses the task and entrypoint functions from LangGraphJS along with the interrupt mechanism for human-in-the-loop interaction. The workflow is checkpointed using MemorySaver for persistence.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { task, entrypoint, interrupt, MemorySaver } from \"@langchain/langgraph\";\n\nconst writeEssay = task(\"write_essay\", (topic: string): string => {\n  // A placeholder for a long-running task.\n  return `An essay about topic: ${topic}`;\n});\n\nconst workflow = entrypoint(\n  { checkpointer: new MemorySaver(), name: \"workflow\" },\n  async (topic: string) => {\n    const essay = await writeEssay(topic);\n    const isApproved = interrupt({\n      // Any json-serializable payload provided to interrupt as argument.\n      // It will be surfaced on the client side as an Interrupt when streaming data\n      // from the workflow.\n      essay, // The essay we want reviewed.\n      // We can add any additional information that we need.\n      // For example, introduce a key called \"action\" with some instructions.\n      action: \"Please approve/reject the essay\",\n    });\n\n    return {\n      essay, // The essay that was generated\n      isApproved, // Response from HIL\n    };\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Graph State for Self-RAG Process\nDESCRIPTION: Creates a state management structure using LangGraph annotations that will track documents, questions, generated text, and quality assessments throughout the RAG process.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { type DocumentInterface } from \"@langchain/core/documents\";\n\n// Represents the state of our graph.\nconst GraphState = Annotation.Root({\n  documents: Annotation<DocumentInterface[]>({\n    reducer: (x, y) => y ?? x ?? [],\n  }),\n  question: Annotation<string>({\n    reducer: (x, y) => y ?? x ?? \"\",\n  }),\n  generation: Annotation<string>({\n    reducer: (x, y) => y ?? x,\n    default: () => \"\",\n  }),\n  generationVQuestionGrade: Annotation<string>({\n    reducer: (x, y) => y ?? x,\n  }),\n  generationVDocumentsGrade: Annotation<string>({\n    reducer: (x, y) => y ?? x,\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Agent State with Message History\nDESCRIPTION: Creates a graph state definition using LangGraph annotations. The state consists of a messages array that can be appended to by each node in the graph, with a reducer to concatenate new messages with existing ones.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst GraphState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n    default: () => [],\n  })\n})\n```\n\n----------------------------------------\n\nTITLE: Creating Full-stack LangGraph Application with CLI\nDESCRIPTION: Command to set up a complete agent chat application using the create-agent-chat-app CLI tool, which provides options for agent type, frontend framework, and package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-agent-chat-app@latest\n```\n\n----------------------------------------\n\nTITLE: Constructing RAG Workflow Graph in Python\nDESCRIPTION: This snippet demonstrates the construction of the RAG workflow graph using the StateGraph class from LangGraph. It defines the nodes and their connections in the workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph } from \"@langchain/langgraph\";\n\n# Define the graph\nconst workflow = new StateGraph(GraphState)\n  # Define the nodes which we'll cycle between.\n  .addNode(\"agent\", agent)\n  .addNode(\"retrieve\", toolNode)\n  .addNode(\"gradeDocuments\", gradeDocuments)\n  .addNode(\"rewrite\", rewrite)\n  .addNode(\"generate\", generate);\n```\n\n----------------------------------------\n\nTITLE: Adding conditional edges to a StateGraph - TypeScript\nDESCRIPTION: This code demonstrates how to use conditional edges in the graph, along with a routing function to determine the next nodes based on the current state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\ngraph.addConditionalEdges(\"nodeA\", routingFunction, {\n  true: \"nodeB\",\n  false: \"nodeC\",\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG Pipeline Nodes in LangGraph.js\nDESCRIPTION: This snippet defines the core functions (nodes) for a RAG workflow including document retrieval, relevance assessment, answer generation, query transformation, and web search integration. Each function processes the graph state and returns updated state components.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_crag.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\nimport { Document } from \"@langchain/core/documents\";\nimport { z } from \"zod\";\nimport { ChatPromptTemplate } from \"@langchain/core/prompts\";\nimport { pull } from \"langchain/hub\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { StringOutputParser } from \"@langchain/core/output_parsers\";\nimport { formatDocumentsAsString } from \"langchain/util/document\";\n\n// Define the LLM once. We'll reuse it throughout the graph.\nconst model = new ChatOpenAI({\n  model: \"gpt-4o\",\n  temperature: 0,\n});\n\n/**\n * Retrieve documents\n *\n * @param {typeof GraphState.State} state The current state of the graph.\n * @param {RunnableConfig | undefined} config The configuration object for tracing.\n * @returns {Promise<Partial<typeof GraphState.State>>} The new state object.\n */\nasync function retrieve(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---RETRIEVE---\");\n\n  const documents = await retriever\n    .withConfig({ runName: \"FetchRelevantDocuments\" })\n    .invoke(state.question);\n\n  return {\n    documents,\n  };\n}\n\n/**\n * Generate answer\n *\n * @param {typeof GraphState.State} state The current state of the graph.\n * @param {RunnableConfig | undefined} config The configuration object for tracing.\n * @returns {Promise<Partial<typeof GraphState.State>>} The new state object.\n */\nasync function generate(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---GENERATE---\");\n\n  const prompt = await pull<ChatPromptTemplate>(\"rlm/rag-prompt\");\n  // Construct the RAG chain by piping the prompt, model, and output parser\n  const ragChain = prompt.pipe(model).pipe(new StringOutputParser());\n\n  const generation = await ragChain.invoke({\n    context: formatDocumentsAsString(state.documents),\n    question: state.question,\n  });\n\n  return {\n    generation,\n  };\n}\n\n/**\n * Determines whether the retrieved documents are relevant to the question.\n *\n * @param {typeof GraphState.State} state The current state of the graph.\n * @param {RunnableConfig | undefined} config The configuration object for tracing.\n * @returns {Promise<Partial<typeof GraphState.State>>} The new state object.\n */\nasync function gradeDocuments(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---CHECK RELEVANCE---\");\n\n  // pass the name & schema to `withStructuredOutput` which will force the model to call this tool.\n  const llmWithTool = model.withStructuredOutput(\n    z\n      .object({\n        binaryScore: z\n          .enum([\"yes\", \"no\"])\n          .describe(\"Relevance score 'yes' or 'no'\"),\n      })\n      .describe(\n        \"Grade the relevance of the retrieved documents to the question. Either 'yes' or 'no'.\"\n      ),\n    {\n      name: \"grade\",\n    }\n  );\n\n  const prompt = ChatPromptTemplate.fromTemplate(\n    `You are a grader assessing relevance of a retrieved document to a user question.\n  Here is the retrieved document:\n  \n  {context}\n  \n  Here is the user question: {question}\n\n  If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\n  Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.`\n  );\n\n  // Chain\n  const chain = prompt.pipe(llmWithTool);\n\n  const filteredDocs: Array<DocumentInterface> = [];\n  for await (const doc of state.documents) {\n    const grade = await chain.invoke({\n      context: doc.pageContent,\n      question: state.question,\n    });\n    if (grade.binaryScore === \"yes\") {\n      console.log(\"---GRADE: DOCUMENT RELEVANT---\");\n      filteredDocs.push(doc);\n    } else {\n      console.log(\"---GRADE: DOCUMENT NOT RELEVANT---\");\n    }\n  }\n\n  return {\n    documents: filteredDocs,\n  };\n}\n\n/**\n * Transform the query to produce a better question.\n *\n * @param {typeof GraphState.State} state The current state of the graph.\n * @param {RunnableConfig | undefined} config The configuration object for tracing.\n * @returns {Promise<Partial<typeof GraphState.State>>} The new state object.\n */\nasync function transformQuery(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---TRANSFORM QUERY---\");\n\n  // Pull in the prompt\n  const prompt = ChatPromptTemplate.fromTemplate(\n    `You are generating a question that is well optimized for semantic search retrieval.\n  Look at the input and try to reason about the underlying sematic intent / meaning.\n  Here is the initial question:\n  \\n ------- \\n\n  {question} \n  \\n ------- \\n\n  Formulate an improved question: `\n  );\n\n  // Prompt\n  const chain = prompt.pipe(model).pipe(new StringOutputParser());\n  const betterQuestion = await chain.invoke({ question: state.question });\n\n  return {\n    question: betterQuestion,\n  };\n}\n\n/**\n * Web search based on the re-phrased question using Tavily API.\n *\n * @param {typeof GraphState.State} state The current state of the graph.\n * @param {RunnableConfig | undefined} config The configuration object for tracing.\n * @returns {Promise<Partial<typeof GraphState.State>>} The new state object.\n */\nasync function webSearch(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---WEB SEARCH---\");\n\n  const tool = new TavilySearchResults();\n  const docs = await tool.invoke({ input: state.question });\n  const webResults = new Document({ pageContent: docs });\n  const newDocuments = state.documents.concat(webResults);\n\n  return {\n    documents: newDocuments,\n  };\n}\n\n/**\n * Determines whether to generate an answer, or re-generate a question.\n *\n * @param {typeof GraphState.State} state The current state of the graph.\n * @returns {\"transformQuery\" | \"generate\"} Next node to call\n */\nfunction decideToGenerate(state: typeof GraphState.State) {\n  console.log(\"---DECIDE TO GENERATE---\");\n\n  const filteredDocs = state.documents;\n  if (filteredDocs.length === 0) {\n    // All documents have been filtered checkRelevance\n    // We will re-generate a new query\n    console.log(\"---DECISION: TRANSFORM QUERY---\");\n    return \"transformQuery\";\n  }\n\n  // We have relevant documents, so generate answer\n  console.log(\"---DECISION: GENERATE---\");\n  return \"generate\";\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Top-Level Orchestration Graph in LangGraph.js\nDESCRIPTION: This code defines the top-level orchestration graph (`superGraph`) using `StateGraph`. It adds nodes for 'ResearchTeam', 'PaperWritingTeam', and 'supervisor'. The 'ResearchTeam' node invokes `researchChain`, while 'PaperWritingTeam' invokes `authoringChain`. Edges are created to connect these nodes to the 'supervisor' node, which determines the next step.  Conditional edges are used to route the graph based on the supervisor's output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: javascript\nCODE:\n```\nconst superGraph = new StateGraph(State)\n  .addNode(\"ResearchTeam\", async (input) => {{\n    const getMessagesResult = await getMessages.invoke(input);\n    const researchChainResult = await researchChain.invoke({{\n      messages: getMessagesResult.messages,\n    }});\n    const joinGraphResult = await joinGraph.invoke({{\n      messages: researchChainResult.messages,\n    }});\n  }})\n  .addNode(\"PaperWritingTeam\", getMessages.pipe(authoringChain).pipe(joinGraph))\n  .addNode(\"supervisor\", supervisorNode)\n  .addEdge(\"ResearchTeam\", \"supervisor\")\n  .addEdge(\"PaperWritingTeam\", \"supervisor\")\n  .addConditionalEdges(\"supervisor\", (x) => x.next, {{\n    PaperWritingTeam: \"PaperWritingTeam\",\n    ResearchTeam: \"ResearchTeam\",\n    FINISH: END,\n  }})\n  .addEdge(START, \"supervisor\");\n\nconst compiledSuperGraph = superGraph.compile();\n\n```\n\n----------------------------------------\n\nTITLE: Implementing LLM Streaming with StateGraph in TypeScript\nDESCRIPTION: This code demonstrates how to create a simple LangGraph workflow that calls an OpenAI model and streams back events during execution. It initializes a StateGraph with MessagesAnnotation, adds a model call node, and uses streamEvents to capture and log different types of events during execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/streaming.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { StateGraph, MessagesAnnotation } from \"langgraph\";\n\nconst model = new ChatOpenAI({ model: \"gpt-4-turbo-preview\" });\n\nfunction callModel(state: typeof MessagesAnnotation.State) {\n  const response = model.invoke(state.messages);\n  return { messages: response };\n}\n\nconst workflow = new StateGraph(MessagesAnnotation)\n  .addNode(\"callModel\", callModel)\n  .addEdge(\"start\", \"callModel\")\n  .addEdge(\"callModel\", \"end\");\nconst app = workflow.compile();\n\nconst inputs = [{ role: \"user\", content: \"hi!\" }];\n\nfor await (const event of app.streamEvents(\n  { messages: inputs },\n  { version: \"v2\" }\n)) {\n  const kind = event.event;\n  console.log(`${kind}: ${event.name}`);\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing the LangGraph Graph\nDESCRIPTION: This JavaScript code visualizes the LangGraph graph using `tslab`. It gets the graph from the agent, draws it as a Mermaid PNG, converts it to an ArrayBuffer, and displays it using `tslab.display.png`. This assumes `tslab` is available in the environment.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/create-react-agent.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n\"import * as tslab from \\\"tslab\\\";\\n\\nconst graph = agent.getGraph();\\nconst image = await graph.drawMermaidPng();\\nconst arrayBuffer = await image.arrayBuffer();\\n\\nawait tslab.display.png(new Uint8Array(arrayBuffer));\"\n```\n\n----------------------------------------\n\nTITLE: Creating a StateGraph for Multi-Agent Workflow in JavaScript\nDESCRIPTION: This snippet demonstrates the creation of a StateGraph for a multi-agent workflow. It adds nodes for Researcher and ChartGenerator agents, defines conditional edges, and compiles the graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\n\n// 1. Create the graph\nconst workflow = new StateGraph(AgentState)\n   // 2. Add the nodes; these will do the work\n  .addNode(\"Researcher\", researchNode)\n  .addNode(\"ChartGenerator\", chartNode)\n  .addNode(\"call_tool\", toolNode);\n\n// 3. Define the edges. We will define both regular and conditional ones\n// After a worker completes, report to supervisor\nworkflow.addConditionalEdges(\"Researcher\", router, {\n  // We will transition to the other agent\n  continue: \"ChartGenerator\",\n  call_tool: \"call_tool\",\n  end: END,\n});\n\nworkflow.addConditionalEdges(\"ChartGenerator\", router, {\n  // We will transition to the other agent\n  continue: \"Researcher\",\n  call_tool: \"call_tool\",\n  end: END,\n});\n\nworkflow.addConditionalEdges(\n  \"call_tool\",\n  // Each agent node updates the 'sender' field\n  // the tool calling node does not, meaning\n  // this edge will route back to the original agent\n  // who invoked the tool\n  (x) => x.sender,\n  {\n    Researcher: \"Researcher\",\n    ChartGenerator: \"ChartGenerator\",\n  },\n);\n\nworkflow.addEdge(START, \"Researcher\");\nconst graph = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Approval Process with Human-in-the-loop - LangGraph - TypeScript\nDESCRIPTION: This code demonstrates the creation of an approval workflow node using the interrupt function in LangGraph. It pauses a graph for human approval at a critical juncture. The snippet requires LangGraph and its Command object, and inputs include the graph's state and the output that the human will review for approval or rejection, which determines the graph's subsequent path.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt, Command } from \"@langchain/langgraph\";\n\nfunction humanApproval(state: typeof GraphAnnotation.State): Command {\n  const isApproved = interrupt({\n    question: \"Is this correct?\",\n    llm_output: state.llm_output,\n  });\n\n  if (isApproved) {\n    return new Command({ goto: \"some_node\" });\n  } else {\n    return new Command({ goto: \"another_node\" });\n  }\n}\n\nconst graph = graphBuilder\n  .addNode(\"human_approval\", humanApproval)\n  .compile({ checkpointer });\n\nconst threadConfig = { configurable: { thread_id: \"some_id\" } };\nawait graph.invoke(new Command({ resume: true }), threadConfig);\n```\n\n----------------------------------------\n\nTITLE: Implementing Node Functions for RAG Workflow in TypeScript\nDESCRIPTION: This snippet defines the main processing nodes in the RAG workflow, including the agent function for generating responses, a rewrite function for query transformation, and a generate function for final answer production.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nasync function agent(state: typeof GraphState.State): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---CALL AGENT---\");\n  \n  const { messages } = state;\n  // Find the AIMessage which contains the `give_relevance_score` tool call,\n  // and remove it if it exists. This is because the agent does not need to know\n  // the relevance score.\n  const filteredMessages = messages.filter((message) => {\n    if (\"tool_calls\" in message && Array.isArray(message.tool_calls) && message.tool_calls.length > 0) {\n      return message.tool_calls[0].name !== \"give_relevance_score\";\n    }\n    return true;\n  });\n\n  const model = new ChatOpenAI({\n    model: \"gpt-4o\",\n    temperature: 0,\n    streaming: true,\n  }).bindTools(tools);\n\n  const response = await model.invoke(filteredMessages);\n  return {\n    messages: [response],\n  };\n}\n\nasync function rewrite(state: typeof GraphState.State): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---TRANSFORM QUERY---\");\n\n  const { messages } = state;\n  const question = messages[0].content as string;\n  const prompt = ChatPromptTemplate.fromTemplate(\n    `Look at the input and try to reason about the underlying semantic intent / meaning. \\n \nHere is the initial question:\n\\n ------- \\n\n{question} \n\\n ------- \\n\nFormulate an improved question:`,\n  );\n\n  // Grader\n  const model = new ChatOpenAI({\n    model: \"gpt-4o\",\n    temperature: 0,\n    streaming: true,\n  });\n  const response = await prompt.pipe(model).invoke({ question });\n  return {\n    messages: [response],\n  };\n}\n\nasync function generate(state: typeof GraphState.State): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---GENERATE---\");\n  \n  const { messages } = state;\n  const question = messages[0].content as string;\n  // Extract the most recent ToolMessage\n  const lastToolMessage = messages.slice().reverse().find((msg) => msg._getType() === \"tool\");\n  if (!lastToolMessage) {\n    throw new Error(\"No tool message found in the conversation history\");\n  }\n\n  const docs = lastToolMessage.content as string;\n\n  const prompt = await pull<ChatPromptTemplate>(\"rlm/rag-prompt\");\n\n  const llm = new ChatOpenAI({\n    model: \"gpt-4o\",\n    temperature: 0,\n    streaming: true,\n  });\n\n  const ragChain = prompt.pipe(llm);\n\n  const response = await ragChain.invoke({\n    context: docs,\n    question,\n  });\n\n  return {\n    messages: [response],\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Building and Compiling the Agent Graph in TypeScript\nDESCRIPTION: This code snippet creates and compiles the agent graph for the travel assistant system. It connects the various agent nodes while specifying the endings for each node, facilitating a flexible routing system among agents based on user inputs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst graph = new StateGraph(MessagesAnnotation)\n  .addNode(\"travel_advisor\", travelAdvisor, {\n    ends: [\"sightseeing_advisor\", \"hotel_advisor\", \"__end__\"],\n  })\n  .addNode(\"sightseeing_advisor\", sightseeingAdvisor, {\n    ends: [\"travel_advisor\", \"hotel_advisor\", \"__end__\"],\n  })\n  .addNode(\"hotel_advisor\", hotelAdvisor, {\n    ends: [\"travel_advisor\", \"sightseeing_advisor\", \"__end__\"],\n  })\n  // we'll always start with a general travel advisor\n  .addEdge(\"__start__\", \"travel_advisor\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Defining State Structure for Plan-Execute Agent\nDESCRIPTION: Creates an annotation structure to track the agent's state, including input, plan steps, execution history, and final response. Uses LangGraph's Annotation system for state management.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\n\nconst PlanExecuteState = Annotation.Root({\n  input: Annotation<string>({\n    reducer: (x, y) => y ?? x ?? \"\",\n  }),\n  plan: Annotation<string[]>({\n    reducer: (x, y) => y ?? x ?? [],\n  }),\n  pastSteps: Annotation<[string, string][]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n  response: Annotation<string>({\n    reducer: (x, y) => y ?? x,\n  }),\n})\n```\n\n----------------------------------------\n\nTITLE: Defining LangGraph Entrypoint for ReAct Agent\nDESCRIPTION: This code defines the entrypoint for the ReAct agent, which orchestrates the `callModel` and `callTool` tasks. It handles the logic for calling the model, executing tool calls, appending messages to the message list, and repeating the process until the model generates no more tool calls. The `entrypoint` function sets up this workflow using LangGraph's functional API.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n\"import { entrypoint, addMessages } from \\\"@langchain/langgraph\\\";\\n\\nconst agent = entrypoint(\\n  \\\"agent\\\",\\n  async (messages: BaseMessageLike[]) => {\\n    let currentMessages = messages;\\n    let llmResponse = await callModel(currentMessages);\\n    while (true) {\\n      if (!llmResponse.tool_calls?.length) {\\n        break;\\n      }\\n\\n      // Execute tools\\n      const toolResults = await Promise.all(\\n        llmResponse.tool_calls.map((toolCall) => {\\n          return callTool(toolCall);\\n        })\\n      );\\n      \\n      // Append to message list\\n      currentMessages = addMessages(currentMessages, [llmResponse, ...toolResults]);\\n\\n      // Call model again\\n      llmResponse = await callModel(currentMessages);\\n    }\\n\\n    return llmResponse;\\n  }\\n);\"\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph Dependencies with npm\nDESCRIPTION: This command installs the required dependencies for the ReAct agent example, including @langchain/langgraph, @langchain/openai, and zod. These packages are necessary for building and running the agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @langchain/langgraph @langchain/openai @langchain/core zod\"\n```\n\n----------------------------------------\n\nTITLE: Agent Supervisor Implementation\nDESCRIPTION: Implements the supervisor agent that routes work between worker agents using Claude LLM.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/agent_supervisor.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { z } from \"zod\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n\nconst members = [\"researcher\", \"chart_generator\"] as const;\n\nconst systemPrompt = \"You are a supervisor tasked with managing a conversation between the\" +\n  \" following workers: {members}. Given the following user request,\" +\n  \" respond with the worker to act next. Each worker will perform a\" +\n  \" task and respond with their results and status. When finished,\" +\n  \" respond with FINISH.\";\n\n// ... supervisor implementation code ...\n```\n\n----------------------------------------\n\nTITLE: Implementing MongoDB Checkpoint Saver in LangGraph.js\nDESCRIPTION: This code demonstrates how to use the MongoDBSaver class to store, retrieve, and list checkpoints in a MongoDB database. It shows the complete workflow including configuration setup, checkpoint creation, storage, retrieval, and listing operations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint-mongodb/README.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MongoClient } from \"mongodb\";\nimport { MongoDBSaver } from \"@langchain/langgraph-checkpoint-mongodb\";\n\nconst writeConfig = {\n  configurable: {\n    thread_id: \"1\",\n    checkpoint_ns: \"\"\n  }\n};\nconst readConfig = {\n  configurable: {\n    thread_id: \"1\"\n  }\n};\n\n\nconst client = new MongoClient(process.env.MONGODB_URL);\n\nconst checkpointer = new MongoDBSaver({ client });\nconst checkpoint = {\n  v: 1,\n  ts: \"2024-07-31T20:14:19.804150+00:00\",\n  id: \"1ef4f797-8335-6428-8001-8a1503f9b875\",\n  channel_values: {\n    my_key: \"meow\",\n    node: \"node\"\n  },\n  channel_versions: {\n    __start__: 2,\n    my_key: 3,\n    \"start:node\": 3,\n    node: 3\n  },\n  versions_seen: {\n    __input__: {},\n    __start__: {\n      __start__: 1\n    },\n    node: {\n      \"start:node\": 2\n    }\n  },\n  pending_sends: [],\n}\n\n// store checkpoint\nawait checkpointer.put(writeConfig, checkpoint, {}, {});\n\n// load checkpoint\nawait checkpointer.get(readConfig);\n\n// list checkpoints\nfor await (const checkpoint of checkpointer.list(readConfig)) {\n  console.log(checkpoint);\n}\n\nawait client.close();\n```\n\n----------------------------------------\n\nTITLE: Grading Generation Against Documents in Self-RAG Graph\nDESCRIPTION: This function assesses whether the generated answer is grounded in and supported by the retrieved documents. It uses a structured output from the language model to produce a binary score.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nasync function generateGenerationVDocumentsGrade(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---GENERATE GENERATION vs DOCUMENTS GRADE---\");\n\n  const llmWithTool = model.withStructuredOutput(\n    z\n      .object({\n        binaryScore: z\n          .enum([\"yes\", \"no\"])\n          .describe(\"Relevance score 'yes' or 'no'\"),\n      })\n      .describe(\n        \"Grade the relevance of the retrieved documents to the question. Either 'yes' or 'no'.\"\n      ),\n    {\n      name: \"grade\",\n    }\n  );\n\n  const prompt = ChatPromptTemplate.fromTemplate(\n    `You are a grader assessing whether an answer is grounded in / supported by a set of facts.\n  Here are the facts:\n  \\n ------- \\n\n  {documents} \n  \\n ------- \\n\n  Here is the answer: {generation}\n  Give a binary score 'yes' or 'no' to indicate whether the answer is grounded in / supported by a set of facts.`\n  );\n\n  const chain = prompt.pipe(llmWithTool);\n\n  const score = await chain.invoke({\n    documents: formatDocumentsAsString(state.documents),\n    generation: state.generation,\n  });\n\n  return {\n    generationVDocumentsGrade: score.binaryScore,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Input and Output Annotations in StateGraph using Javascript\nDESCRIPTION: This code snippet showcases how to define input and output schemas for your graph using the Annotation.Root function. The input schema captures a question, while the output schema defines the corresponding answer. It creates a StateGraph instance with the defined input and output schemas, adds a node for generating the answer, and compiles the graph for invocation. The snippet demonstrates the intended use and flow of data through the graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/input_output_schema.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Annotation, StateGraph } from \"@langchain/langgraph\";\n\nconst InputAnnotation = Annotation.Root({\n  question: Annotation<string>,\n});\n\nconst OutputAnnotation = Annotation.Root({\n  answer: Annotation<string>,\n});\n\nconst answerNode = (_state: typeof InputAnnotation.State) => {\n  return { answer: \"bye\" };\n};\n\nconst graph = new StateGraph({\n  input: InputAnnotation,\n  output: OutputAnnotation,\n})\n  .addNode(\"answerNode\", answerNode)\n  .addEdge(\"__start__\", \"answerNode\")\n  .compile();\n\nawait graph.invoke({\n  question: \"hi\",\n});\n```\n\n----------------------------------------\n\nTITLE: Adding a Node Function that Invokes a Subgraph in LangGraphJS\nDESCRIPTION: Example showing how to implement a node function that invokes a subgraph with a different state schema. This pattern allows for state transformation between the parent graph and subgraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\nconst SubgraphAnnotation = Annotation.Root({\n  bar: Annotation<string>, // note that this key is shared with the parent graph state\n  baz: Annotation<string>,\n});\n\nconst subgraphNodeOne = async (state: typeof SubgraphAnnotation.State) => {\n  return { baz: \"baz\" };\n};\n\nconst subgraphNodeTwo = async (state: typeof SubgraphAnnotation.State) => {\n  return { bar: state.bar + state.baz }\n};\n\nconst subgraphCalledInFunction = new StateGraph(SubgraphAnnotation)\n  .addNode(\"subgraphNode1\", subgraphNodeOne)\n  .addNode(\"subgraphNode2\", subgraphNodeTwo)\n  .addEdge(\"__start__\", \"subgraphNode1\")\n  .addEdge(\"subgraphNode1\", \"subgraphNode2\")\n  .compile();\n\n// Define parent graph\nconst ParentAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n});\n\nconst nodeOne = async (state: typeof ParentAnnotation.State) => {\n  return {\n    foo: \"hi! \" + state.foo,\n  };\n}\n\nconst nodeTwo = async (state: typeof ParentAnnotation.State) => {\n  const response = await subgraphCalledInFunction.invoke({\n    bar: state.foo,\n  });\n  return { foo: response.bar }\n}\n\nconst graphWithFunction = new StateGraph(ParentStateAnnotation)\n  .addNode(\"node1\", nodeOne)\n  // note that we're adding the compiled subgraph as a node to the parent graph\n  .addNode(\"node2\", nodeTwo)\n  .addEdge(\"__start__\", \"node1\")\n  .addEdge(\"node1\", \"node2\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Human-in-the-loop with Interrupt - LangGraph - TypeScript\nDESCRIPTION: This snippet demonstrates the usage of the interrupt function from LangGraph to pause a workflow and solicit human input for revising a piece of text. Dependencies include the LangGraph library and a checkpointer for saving state. The input is the graph's state, and the output is the updated state based on the human's input. It operates within a workflow compiled with LangGraph's StateGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt } from \"@langchain/langgraph\";\n\nfunction humanNode(state: typeof GraphAnnotation.State) {\n  const value = interrupt(\n    {\n      text_to_revise: state.some_text,\n    }\n  );\n  return {\n    some_text: value,\n  };\n}\n\nconst graph = workflow.compile({\n  checkpointer,\n});\n\nconst threadConfig = { configurable: { thread_id: \"some_id\" } };\nawait graph.invoke(someInput, threadConfig);\n\nconst valueFromHuman = \"...\";\n\nawait graph.invoke(new Command({ resume: valueFromHuman }), threadConfig);\n```\n\n----------------------------------------\n\nTITLE: Streaming Messages with Memory in Python\nDESCRIPTION: This snippet demonstrates how to initiate a conversation with the agent while preserving the context by streaming messages to it. The agent responds based on the user's query while maintaining the conversational flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nconst streamWithMemory = await agentWithMemory.stream([{\\n  role: \"user\",\\n  content: \"What's the weather in san francisco?\",\\n}], config);\\n\\nfor await (const step of streamWithMemory) {\\n  for (const [taskName, update] of Object.entries(step)) {\\n    const message = update as BaseMessage;\\n    // Only print task updates\\n    if (taskName === \"agentWithMemory\") continue;\\n    console.log(`\\n${taskName}:`);\\n    prettyPrintMessage(message);\\n  }\\n}\n```\n\n----------------------------------------\n\nTITLE: Travel Agent Graph Definition in LangGraphJS\nDESCRIPTION: This TypeScript code defines a graph with three travel assistant agents: travelAdvisor, sightseeingAdvisor, and hotelAdvisor. Each agent uses an LLM with structured output to determine its response and the next agent to route to. The code also sets up a 'human' node for collecting user input and defines edges between agents.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-multi-turn-convo.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { z } from \"zod\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport {\n  MessagesAnnotation,\n  StateGraph,\n  START,\n  Command,\n  interrupt,\n  MemorySaver\n} from \"@langchain/langgraph\";\n\nconst model = new ChatOpenAI({ model: \"gpt-4o\" });\n\n\n/**\n * Call LLM with structured output to get a natural language response as well as a target agent (node) to go to next.\n * @param messages list of messages to pass to the LLM\n * @param targetAgentNodes list of the node names of the target agents to navigate to\n */\nfunction callLlm(messages: BaseMessage[], targetAgentNodes: string[]) {\n  // define the schema for the structured output:\n  // - model's text response (`response`)\n  // - name of the node to go to next (or 'finish')\n  const outputSchema = z.object({\n    response: z.string().describe(\"A human readable response to the original question. Does not need to be a final response. Will be streamed back to the user.\"),\n    goto: z.enum([\"finish\", ...targetAgentNodes]).describe(\"The next agent to call, or 'finish' if the user's query has been resolved. Must be one of the specified values.\"),\n  })\n  return model.withStructuredOutput(outputSchema, { name: \"Response\" }).invoke(messages)\n}\n\nasync function travelAdvisor(\n  state: typeof MessagesAnnotation.State\n): Promise<Command> {\n  const systemPrompt = \n      \"You are a general travel expert that can recommend travel destinations (e.g. countries, cities, etc). \" +\n      \"If you need specific sightseeing recommendations, ask 'sightseeingAdvisor' for help. \" +\n      \"If you need hotel recommendations, ask 'hotelAdvisor' for help. \" +\n      \"If you have enough information to respond to the user, return 'finish'. \" +\n      \"Never mention other agents by name.\";\n\n  const messages = [{\\\"role\\\": \\\"system\\\", \\\"content\\\": systemPrompt}, ...state.messages] as BaseMessage[];\n  const targetAgentNodes = [\"sightseeingAdvisor\", \"hotelAdvisor\"];\n  const response = await callLlm(messages, targetAgentNodes);\n  const aiMsg = {\\\"role\\\": \\\"ai\\\", \\\"content\\\": response.response, \\\"name\\\": \\\"travelAdvisor\\\"};\n  \n  let goto = response.goto;\n  if (goto === \"finish\") {\n      goto = \"human\";\n  }\n\n  return new Command({goto, update: { \\\"messages\\\": [aiMsg] } });\n}\n\nasync function sightseeingAdvisor(\n  state: typeof MessagesAnnotation.State\n): Promise<Command> {\n  const systemPrompt = \n      \"You are a travel expert that can provide specific sightseeing recommendations for a given destination. \" +\n      \"If you need general travel help, go to 'travelAdvisor' for help. \" +\n      \"If you need hotel recommendations, go to 'hotelAdvisor' for help. \" +\n      \"If you have enough information to respond to the user, return 'finish'. \" +\n      \"Never mention other agents by name.\";\n\n  const messages = [{\\\"role\\\": \\\"system\\\", \\\"content\\\": systemPrompt}, ...state.messages] as BaseMessage[];\n  const targetAgentNodes = [\"travelAdvisor\", \"hotelAdvisor\"];\n  const response = await callLlm(messages, targetAgentNodes);\n  const aiMsg = {\\\"role\\\": \\\"ai\\\", \\\"content\\\": response.response, \\\"name\\\": \\\"sightseeingAdvisor\\\"};\n  \n  let goto = response.goto;\n  if (goto === \"finish\") {\n      goto = \"human\";\n  }\n\n  return new Command({ goto, update: {\\\"messages\\\": [aiMsg] } });\n}\n\nasync function hotelAdvisor(\n  state: typeof MessagesAnnotation.State\n): Promise<Command> {\n  const systemPrompt = \n      \"You are a travel expert that can provide hotel recommendations for a given destination. \" +\n      \"If you need general travel help, ask 'travelAdvisor' for help. \" +\n      \"If you need specific sightseeing recommendations, ask 'sightseeingAdvisor' for help. \" +\n      \"If you have enough information to respond to the user, return 'finish'. \" +\n      \"Never mention other agents by name.\";\n\n  const messages = [{\\\"role\\\": \\\"system\\\", \\\"content\\\": systemPrompt}, ...state.messages] as BaseMessage[];\n  const targetAgentNodes = [\"travelAdvisor\", \"sightseeingAdvisor\"];\n  const response = await callLlm(messages, targetAgentNodes);\n  const aiMsg = {\\\"role\\\": \\\"ai\\\", \\\"content\\\": response.response, \\\"name\\\": \\\"hotelAdvisor\\\"};\n  \n  let goto = response.goto;\n  if (goto === \"finish\") {\n      goto = \"human\";\n  }\n\n  return new Command({ goto, update: {\\\"messages\\\": [aiMsg] } });\n}\n\nfunction humanNode(\n  state: typeof MessagesAnnotation.State\n): Command {\n  const userInput: string = interrupt(\"Ready for user input.\");\n\n  let activeAgent: string | undefined = undefined;\n\n  // Look up the active agent\n  for (let i = state.messages.length - 1; i >= 0; i--) {\n      if (state.messages[i].name) {\n          activeAgent = state.messages[i].name;\n          break;\n      }\n  }\n\n  if (!activeAgent) {\n      throw new Error(\"Could not determine the active agent.\");\n  }\n\n  return new Command({\n      goto: activeAgent,\n      update: {\n        \\\"messages\\\": [\n            {\n                \\\"role\\\": \\\"human\\\",\n                \\\"content\\\": userInput,\n            }\n        ]\n      }\n  });\n}\n\nconst builder = new StateGraph(MessagesAnnotation)\n  .addNode(\"travelAdvisor\", travelAdvisor, {\n    ends: [\"sightseeingAdvisor\", \"hotelAdvisor\"]\n  })\n  .addNode(\"sightseeingAdvisor\", sightseeingAdvisor, {\n    ends: [\"human\", \"travelAdvisor\", \"hotelAdvisor\"]\n  })\n  .addNode(\"hotelAdvisor\", hotelAdvisor, {\n    ends: [\"human\", \"travelAdvisor\", \"sightseeingAdvisor\"]\n  })\n  // This adds a node to collect human input, which will route\n  // back to the active agent.\n  .addNode(\"human\", humanNode, {\n    ends: [\"hotelAdvisor\", \"sightseeingAdvisor\", \"travelAdvisor\", \"human\"]\n  })\n  // We'll always start with a general travel advisor.\n  .addEdge(START, \"travelAdvisor\")\n\nconst checkpointer = new MemorySaver()\nconst graph = builder.compile({ checkpointer })\n```\n\n----------------------------------------\n\nTITLE: Defining Graph State Structure\nDESCRIPTION: Defines the graph state structure with annotations for question, generation, and documents with custom reducer functionality.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { Document } from \"@langchain/core/documents\";\nimport { Annotation } from \"@langchain/langgraph\";\n\nconst GraphState = Annotation.Root({\n  question: Annotation<string>,\n  generation: Annotation<string>,\n  documents: Annotation<Document[]>({\n    reducer: (_, y) => y,\n    default: () => [],\n  })\n})\n```\n\n----------------------------------------\n\nTITLE: Defining Agent State Structure\nDESCRIPTION: This snippet defines the structure of the agent's state, which tracks messages and their updates throughout the execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Doc Writing Agent Node in LangGraph.js\nDESCRIPTION: This code snippet defines a node for the document writing agent in a LangGraph.js graph.  It uses `agentStateModifier` to create a state modifier for the agent's prompt, incorporating the current files in the directory.  It uses `createReactAgent` to create the agent, providing it with an LLM (`docWritingLlm`), file-writing tools (`writeDocumentTool`, `editDocumentTool`, `readDocumentTool`), and the state modifier. `prelude` adds file information into the agent's prompt. Finally, `runAgentNode` executes the agent and returns the results.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: javascript\nCODE:\n```\nconst docWritingLlm = new ChatOpenAI({ modelName: \"gpt-4o\" });\n\nconst docWritingNode = (state: typeof DocWritingState.State) => {{\n  const stateModifier = agentStateModifier(\n    `You are an expert writing a research document.\\nBelow are files currently in your directory:\\n${state.current_files}`,\n    [writeDocumentTool, editDocumentTool, readDocumentTool],\n    state.team_members ?? [],\n  )\n  const docWriterAgent = createReactAgent({{\n    llm: docWritingLlm,\n    tools: [writeDocumentTool, editDocumentTool, readDocumentTool],\n    stateModifier,\n  }})\n  const contextAwareDocWriterAgent = prelude.pipe(docWriterAgent);\n  return runAgentNode({ state, agent: contextAwareDocWriterAgent, name: \"DocWriter\" });\n}}\n\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI Chat Model for LangGraph\nDESCRIPTION: Initialization of a ChatOpenAI model instance to be used in the graph. The model is configured to use GPT-4o and tools are bound to it for tool calling capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({ model: \"gpt-4o\" });\n\nconst boundModel = model.bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: Creating an InMemoryStore with Embedding - TypeScript\nDESCRIPTION: This snippet illustrates how to configure an InMemoryStore with OpenAI embeddings enabled, which is crucial for achieving advanced functionality in a memory management system within LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence-functional.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { InMemoryStore } from \"@langchain/langgraph\";\nimport { OpenAIEmbeddings } from \"@langchain/openai\";\n\nconst inMemoryStore = new InMemoryStore({\n  index: {\n    embeddings: new OpenAIEmbeddings({\n      model: \"text-embedding-3-small\",\n    }),\n    dims: 1536,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Specialized Tools for Multi-agent System\nDESCRIPTION: Creates two specialized tools for the agents: a chart generation tool using d3.js and canvas for visualization, and a web search tool using Tavily. These tools will be used by different agent specialists in the graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nrequire(\"esm-hook\"); // Only for running this in TSLab. See: https://github.com/yunabe/tslab/issues/72\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\nimport { tool } from \"@langchain/core/tools\";\nimport * as d3 from \"d3\";\n// ----------ATTENTION----------\n// If attempting to run this notebook locally, you must follow these instructions\n// to install the necessary system dependencies for the `canvas` package.\n// https://www.npmjs.com/package/canvas#compiling\n// -----------------------------\nimport { createCanvas } from \"canvas\";\nimport { z } from \"zod\";\nimport * as tslab from \"tslab\";\n\nconst chartTool = tool(\n  ({ data }) => {\n    const width = 500;\n    const height = 500;\n    const margin = { top: 20, right: 30, bottom: 30, left: 40 };\n\n    const canvas = createCanvas(width, height);\n    const ctx = canvas.getContext(\"2d\");\n\n    const x = d3\n      .scaleBand()\n      .domain(data.map((d) => d.label))\n      .range([margin.left, width - margin.right])\n      .padding(0.1);\n\n    const y = d3\n      .scaleLinear()\n      .domain([0, d3.max(data, (d) => d.value) ?? 0])\n      .nice()\n      .range([height - margin.bottom, margin.top]);\n\n    const colorPalette = [\n      \"#e6194B\",\n      \"#3cb44b\",\n      \"#ffe119\",\n      \"#4363d8\",\n      \"#f58231\",\n      \"#911eb4\",\n      \"#42d4f4\",\n      \"#f032e6\",\n      \"#bfef45\",\n      \"#fabebe\",\n    ];\n\n    data.forEach((d, idx) => {\n      ctx.fillStyle = colorPalette[idx % colorPalette.length];\n      ctx.fillRect(\n        x(d.label) ?? 0,\n        y(d.value),\n        x.bandwidth(),\n        height - margin.bottom - y(d.value),\n      );\n    });\n\n    ctx.beginPath();\n    ctx.strokeStyle = \"black\";\n    ctx.moveTo(margin.left, height - margin.bottom);\n    ctx.lineTo(width - margin.right, height - margin.bottom);\n    ctx.stroke();\n\n    ctx.textAlign = \"center\";\n    ctx.textBaseline = \"top\";\n    x.domain().forEach((d) => {\n      const xCoord = (x(d) ?? 0) + x.bandwidth() / 2;\n      ctx.fillText(d, xCoord, height - margin.bottom + 6);\n    });\n\n    ctx.beginPath();\n    ctx.moveTo(margin.left, height - margin.top);\n    ctx.lineTo(margin.left, height - margin.bottom);\n    ctx.stroke();\n\n    ctx.textAlign = \"right\";\n    ctx.textBaseline = \"middle\";\n    const ticks = y.ticks();\n    ticks.forEach((d) => {\n      const yCoord = y(d); // height - margin.bottom - y(d);\n      ctx.moveTo(margin.left, yCoord);\n      ctx.lineTo(margin.left - 6, yCoord);\n      ctx.stroke();\n      ctx.fillText(d.toString(), margin.left - 8, yCoord);\n    });\n    tslab.display.png(canvas.toBuffer());\n    return \"Chart has been generated and displayed to the user!\";\n  },\n  {\n    name: \"generate_bar_chart\",\n    description:\n      \"Generates a bar chart from an array of data points using D3.js and displays it for the user.\",\n    schema: z.object({\n      data: z\n        .object({\n          label: z.string(),\n          value: z.number(),\n        })\n        .array(),\n    }),\n  }\n)\n\nconst tavilyTool = new TavilySearchResults();\n```\n\n----------------------------------------\n\nTITLE: Building the State Graph\nDESCRIPTION: This snippet demonstrates how to build the LangGraph by adding the defined nodes and specifying the starting node. It uses `StateGraph` from `@langchain/langgraph` to construct the graph, connecting nodes for initial support, billing support, technical support, and refund handling.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { StateGraph } from \\\"@langchain/langgraph\\\";\\n\\nlet builder = new StateGraph(StateAnnotation)\\n  .addNode(\\\"initial_support\\\", initialSupport)\\n  .addNode(\\\"billing_support\\\", billingSupport)\\n  .addNode(\\\"technical_support\\\", technicalSupport)\\n  .addNode(\\\"handle_refund\\\", handleRefund)\\n  .addEdge(\\\"__start__\\\", \\\"initial_support\\\");\"\n```\n\n----------------------------------------\n\nTITLE: Creating Note Taking Agent Node in LangGraph.js\nDESCRIPTION: This code defines a node for a note-taking agent in a LangGraph.js graph. It sets up a state modifier with instructions for the agent, including the current files. It initializes the agent with `createReactAgent`, providing tools like `createOutlineTool` and `readDocumentTool`. It then uses `prelude.pipe` to add file information to the prompt. Finally, it wraps agent execution within `runAgentNode`.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: javascript\nCODE:\n```\nconst noteTakingNode = (state: typeof DocWritingState.State) => {{\n  const stateModifier = agentStateModifier(\n    \"You are an expert senior researcher tasked with writing a paper outline and\" +\n    ` taking notes to craft a perfect paper. ${state.current_files}`,\n    [createOutlineTool, readDocumentTool],\n    state.team_members ?? [],\n  )\n  const noteTakingAgent = createReactAgent({{\n    llm: docWritingLlm,\n    tools: [createOutlineTool, readDocumentTool],\n    stateModifier,\n  }})\n  const contextAwareNoteTakingAgent = prelude.pipe(noteTakingAgent);\n  return runAgentNode({ state, agent: contextAwareNoteTakingAgent, name: \"NoteTaker\" });\n}}\n\n```\n\n----------------------------------------\n\nTITLE: Defining a Subgraph with a Weather Tool in LangGraph\nDESCRIPTION: Creates a LangGraph subgraph that processes requests for weather information with a breakpoint before the weather node. It includes tool definition, model setup, state annotation, and node functions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\nimport { tool } from \"@langchain/core/tools\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { StateGraph, MessagesAnnotation, Annotation } from \"@langchain/langgraph\";\n\nconst getWeather = tool(async ({ city }) => {\n  return `It's sunny in ${city}`;\n}, {\n  name: \"get_weather\",\n  description: \"Get the weather for a specific city\",\n  schema: z.object({\n    city: z.string().describe(\"A city name\")\n  })\n});\n\nconst rawModel = new ChatOpenAI({ model: \"gpt-4o-mini\" });\nconst model = rawModel.withStructuredOutput(getWeather);\n\n// Extend the base MessagesAnnotation state with another field\nconst SubGraphAnnotation = Annotation.Root({\n  ...MessagesAnnotation.spec,\n  city: Annotation<string>,\n});\n\nconst modelNode = async (state: typeof SubGraphAnnotation.State) => {\n  const result = await model.invoke(state.messages);\n  return { city: result.city };\n};\n\nconst weatherNode = async (state: typeof SubGraphAnnotation.State) => {\n  const result = await getWeather.invoke({ city: state.city });\n  return {\n    messages: [\n      {\n        role: \"assistant\",\n        content: result,\n      }\n    ]\n  };\n};\n\nconst subgraph = new StateGraph(SubGraphAnnotation)\n  .addNode(\"modelNode\", modelNode)\n  .addNode(\"weatherNode\", weatherNode)\n  .addEdge(\"__start__\", \"modelNode\")\n  .addEdge(\"modelNode\", \"weatherNode\")\n  .addEdge(\"weatherNode\", \"__end__\")\n  .compile({ interruptBefore: [\"weatherNode\"] });\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Handoffs with Command in LangGraphJS\nDESCRIPTION: Shows how to use the Command object to implement handoffs between agents, allowing one agent to specify which agent to call next and what data to pass along. This pattern enables dynamic routing in multi-agent systems.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/multi_agent.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = (state: typeof StateAnnotation.State) => {\n  const goto = getNextAgent(...)  // 'agent' / 'another_agent'\n  return new Command({\n    // Specify which agent to call next\n    goto: goto,\n    // Update the graph state\n    update: {\n      foo: \"bar\",\n    }\n  });\n};\n```\n\n----------------------------------------\n\nTITLE: Implementing Human-in-the-Loop with LangGraph in TypeScript\nDESCRIPTION: The function `humanReviewNode` provides an interactive checkpoint in a LangGraph flow, allowing human intervention to review tool calls. This snippet assumes the presence of LangGraph-specific dependencies such as GraphAnnotation.State and Command. The interrupt mechanism supports multiple actions (continue, update, feedback), modifying the graph’s execution path accordingly.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nfunction humanReviewNode(state: typeof GraphAnnotation.State) {\n  // this is the value we\\'ll be providing via new Command({ resume: <human_review> })\n  const humanReview = interrupt({\n    question: \"Is this correct?\",\n    // Surface tool calls for review\n    tool_call,\n  });\n\n  const [reviewAction, reviewData] = humanReview;\n\n  // Approve the tool call and continue\n  if (reviewAction === \"continue\") {\n    return new Command({ goto: \"run_tool\" });\n  }\n  \n  // Modify the tool call manually and then continue\n  if (reviewAction === \"update\") {\n    const updatedMsg = getUpdatedMsg(reviewData);\n    return new Command({ goto: \"run_tool\", update: { messages: [updatedMsg] } });\n  }\n  \n  // Give natural language feedback, and then pass that back to the agent\n  if (reviewAction === \"feedback\") {\n    const feedbackMsg = getFeedbackMsg(reviewData);\n    return new Command({ goto: \"call_llm\", update: { messages: [feedbackMsg] } });\n  }\n  \n  throw new Error(\"Unreachable\");\n}\n```\n\n----------------------------------------\n\nTITLE: Executing and Demonstrating the LangGraphJS Workflow\nDESCRIPTION: This final snippet demonstrates how to use the compiled LangGraphJS workflow, including error handling and output formatting.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage, isAIMessage } from \"@langchain/core/messages\";\nimport { GraphRecursionError } from \"@langchain/langgraph\";\n\nconst prettyPrint = (message: BaseMessage) => {\n  let txt = `[${message._getType()}]: ${message.content}`;\n  if (\n    (isAIMessage(message) && (message as AIMessage)?.tool_calls?.length) ||\n    0 > 0\n  ) {\n    const tool_calls = (message as AIMessage)?.tool_calls\n      ?.map((tc) => `- ${tc.name}(${JSON.stringify(tc.args)})`)\n      .join(\"\\n\");\n    txt += ` \\nTools: \\n${tool_calls}`;\n  }\n  console.log(txt);\n};\n\nconst inputs = {\n  messages: [\n    new HumanMessage(\n      \"what is the weather in sf? Don't give up! Keep using your tools.\",\n    ),\n  ],\n};\n\ntry {\n  for await (\n    const output of await app.stream(inputs, {\n      streamMode: \"values\",\n      recursionLimit: 10,\n    })\n  ) {\n    const lastMessage = output.messages[output.messages.length - 1];\n    prettyPrint(lastMessage);\n    console.log(\"-----\\n\");\n  }\n} catch (e) {\n  if ((e as GraphRecursionError).name === \"GraphRecursionError\") {\n    console.log(\"As expected, maximum steps reached. Exiting.\");\n  } else {\n    console.error(e);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Graph State with Command in a Tool - TypeScript\nDESCRIPTION: This snippet demonstrates how to create a tool that returns a Command object to update the graph state with user information and add a message to the conversation history.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/update-state-from-tools.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\n\nconst lookupUserInfo = tool(async (input, config) => {\n  const userInfo = getUserInfo(config);\n  return new Command({\n    // update state keys\n    update: {\n      user_info: userInfo,\n      messages: [\n        new ToolMessage({\n          content: \"Successfully looked up user information\",\n          tool_call_id: config.toolCall.id,\n        }),\n      ],\n    },\n  });\n}, {\n  name: \"lookup_user_info\",\n  description: \"Use this to look up user information to better assist them with their questions.\",\n  schema: z.object(...)\n});\n```\n\n----------------------------------------\n\nTITLE: Command Usage in LangGraph Node (State Update and Control Flow)\nDESCRIPTION: This code snippet demonstrates how to use the `Command` object to update the state and direct the control flow to the next node. It defines a node `myNode` that updates the `foo` property of the state to \"bar\" and then directs the graph to the `myOtherNode` node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/command.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst myNode = (state: typeof StateAnnotation.State) => {\n  return new Command({\n    // state update\n    update: {\n      foo: \"bar\",\n    },\n    // control flow\n    goto: \"myOtherNode\",\n  });\n};\n```\n\n----------------------------------------\n\nTITLE: Executing the LangGraph.js RAG Pipeline\nDESCRIPTION: This snippet shows how to execute the RAG pipeline by streaming through the workflow and logging the output at each node. It initializes with a question about agent memory and includes configuration for recursion limits.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_crag.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst inputs = {\n  question: \"Explain how the different types of agent memory work.\",\n};\nconst config = { recursionLimit: 50 };\nlet finalGeneration;\nfor await (const output of await app.stream(inputs, config)) {\n  for (const [key, value] of Object.entries(output)) {\n    console.log(`Node: '${key}'`);\n    // Optional: log full state at each node\n    // console.log(JSON.stringify(value, null, 2));\n    finalGeneration = value;\n  }\n  console.log(\"\\n---\\n\");\n}\n\n// Log the final generation.\nconsole.log(JSON.stringify(finalGeneration, null, 2));\n```\n\n----------------------------------------\n\nTITLE: Implementing PregelRunner for Parallel Task Execution in TypeScript\nDESCRIPTION: The PregelRunner class that executes tasks from the PregelLoop in parallel, with retry logic, timeout handling, and result processing capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-execution-model.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nclass PregelRunner {\n  loop: PregelLoop;\n  \n  // Execute all tasks for the current superstep\n  async tick(options?: {\n    timeout?: number,\n    retryPolicy?: RetryPolicy,\n    onStepWrite?: OnStepWriteCallback,\n    signal?: AbortSignal\n  }): Promise<void> {\n    const tasks = this.loop.tasks;\n    \n    // Execute tasks concurrently with retries\n    const results = await this._executeTasksWithRetry(\n      tasks,\n      options\n    );\n    \n    // Process results\n    for (const [taskId, result] of Object.entries(results)) {\n      await this._commit(taskId, result);\n    }\n    \n    // Process all writes from tasks\n    await this.loop._processWritesFromTasks();\n  }\n  \n  // Execute a single task with retry logic\n  async _executeTask(\n    task: PregelTask,\n    options?: { timeout?: number, signal?: AbortSignal }\n  ): Promise<any> {\n    // Setup context for task execution\n    // Execute the task function with proper context\n    // Handle errors and timeouts\n    // Return result or throw error\n  }\n  \n  // Process the result of a task\n  async _commit(taskId: string, result: any): Promise<void> {\n    // Convert result to channel writes\n    const writes = _resultToWrites(result, task);\n    \n    // Save writes to be processed later\n    this.loop.putWrites(taskId, writes);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Constructing the LangGraphJS Workflow\nDESCRIPTION: This code constructs the LangGraphJS workflow, defining nodes, edges, and conditional paths for the agent's decision-making process.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\n\nconst workflow = new StateGraph(AgentState)\n  .addNode(\"first_agent\", firstModel)\n  .addNode(\"agent\", callModel)\n  .addNode(\"action\", toolNode)\n  .addEdge(START, \"first_agent\")\n  .addConditionalEdges(\n    \"agent\",\n    shouldContinue,\n    {\n      continue: \"action\",\n      end: END,\n    },\n  )\n  .addEdge(\"action\", \"agent\")\n  .addEdge(\"first_agent\", \"action\");\n\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Using interrupt Function for Human-in-the-loop in TypeScript\nDESCRIPTION: Demonstrates how to use the interrupt function to pause graph execution at specific points to collect user input. The function surfaces interrupt information to the client, allowing user input collection, state validation, or decision-making before resuming execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt } from \"@langchain/langgraph\";\n\nconst humanApprovalNode = (state: typeof StateAnnotation.State) => {\n  ...\n  const answer = interrupt(\n      // This value will be sent to the client.\n      // It can be any JSON serializable value.\n      { question: \"is it ok to continue?\"},\n  );\n  ...\n```\n\n----------------------------------------\n\nTITLE: Detailed Example of Workflow Execution and Resumption in LangGraphJS\nDESCRIPTION: This expanded example shows the complete workflow execution process, including running the workflow, handling interrupts, and resuming after human input. It demonstrates streaming workflow execution data and using Command objects to resume interrupted workflows with human feedback.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { task, entrypoint, interrupt, MemorySaver, Command } from \"@langchain/langgraph\";\n\nconst writeEssay = task(\"write_essay\", (topic: string): string => {\n  return `An essay about topic: ${topic}`;\n});\n\nconst workflow = entrypoint(\n  { checkpointer: new MemorySaver(), name: \"workflow\" },\n  async (topic: string) => {\n    const essay = await writeEssay(topic);\n    const isApproved = interrupt({\n      essay, // The essay we want reviewed.\n      action: \"Please approve/reject the essay\",\n    });\n\n    return {\n      essay,\n      isApproved,\n    };\n  }\n);\n\nconst threadId = crypto.randomUUID();\n\nconst config = {\n  configurable: {\n    thread_id: threadId,\n  },\n};\n\nfor await (const item of await workflow.stream(\"cat\", config)) {\n  console.log(item);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Minimal Integration Test for Complete Execution in TypeScript\nDESCRIPTION: Defines a test function for a complete execution of a simple three-node graph. This test initializes a PregelLoop and PregelRunner, runs the execution loop, and verifies the final output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-testing-plan.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst testCompleteExecution = async () => {\n  const { channels, nodes } = setupTestGraph();\n\n  const loop = new PregelLoop(\n    channels,\n    {\n      superstep: 0,\n      channelVersions: {},\n      nodeLastSeenVersions: {},\n      pendingPushes: [],\n    },\n    new TestCheckpointer()\n  );\n\n  const runner = new PregelRunner(loop);\n\n  // Initialize with input\n  await loop._first({ input: \"test data\" });\n\n  // Run execution loop\n  while (await loop.tick({})) {\n    await runner.tick();\n  }\n\n  // Verify final output\n  expect(channels.output.get()).toEqual(\"finalized processed test data\");\n};\n```\n\n----------------------------------------\n\nTITLE: Adding Compiled Subgraph to Parent Graph in TypeScript\nDESCRIPTION: Shows how to add a compiled subgraph as a node in a parent graph. This is useful when the parent graph and subgraph share state keys and no transformation is needed between them.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\n.addNode(\"subgraph\", subgraphBuilder.compile());\n```\n\n----------------------------------------\n\nTITLE: Defining Edge Functions for RAG Workflow in TypeScript\nDESCRIPTION: This snippet defines key functions used in the edges of the RAG workflow graph. It includes functions for deciding whether to retrieve more information, grading document relevance, and checking the relevance of retrieved documents.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END } from \"@langchain/langgraph\";\nimport { pull } from \"langchain/hub\";\nimport { z } from \"zod\";\nimport { ChatPromptTemplate } from \"@langchain/core/prompts\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { AIMessage, BaseMessage } from \"@langchain/core/messages\";\n\nfunction shouldRetrieve(state: typeof GraphState.State): string {\n  const { messages } = state;\n  console.log(\"---DECIDE TO RETRIEVE---\");\n  const lastMessage = messages[messages.length - 1];\n\n  if (\"tool_calls\" in lastMessage && Array.isArray(lastMessage.tool_calls) && lastMessage.tool_calls.length) {\n    console.log(\"---DECISION: RETRIEVE---\");\n    return \"retrieve\";\n  }\n  // If there are no tool calls then we finish.\n  return END;\n}\n\nasync function gradeDocuments(state: typeof GraphState.State): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---GET RELEVANCE---\");\n\n  const { messages } = state;\n  const tool = {\n    name: \"give_relevance_score\",\n    description: \"Give a relevance score to the retrieved documents.\",\n    schema: z.object({\n      binaryScore: z.string().describe(\"Relevance score 'yes' or 'no'\")\n    })\n  }\n\n  const prompt = ChatPromptTemplate.fromTemplate(\n    `You are a grader assessing relevance of retrieved docs to a user question.\n  Here are the retrieved docs:\n  \\n ------- \\n\n  {context} \n  \\n ------- \\n\n  Here is the user question: {question}\n  If the content of the docs are relevant to the users question, score them as relevant.\n  Give a binary score 'yes' or 'no' score to indicate whether the docs are relevant to the question.\n  Yes: The docs are relevant to the question.\n  No: The docs are not relevant to the question.`,\n  );\n\n  const model = new ChatOpenAI({\n    model: \"gpt-4o\",\n    temperature: 0,\n  }).bindTools([tool], {\n    tool_choice: tool.name,\n  });\n\n  const chain = prompt.pipe(model);\n\n  const lastMessage = messages[messages.length - 1];\n\n  const score = await chain.invoke({\n    question: messages[0].content as string,\n    context: lastMessage.content as string,\n  });\n\n  return {\n    messages: [score]\n  };\n}\n\nfunction checkRelevance(state: typeof GraphState.State): string {\n  console.log(\"---CHECK RELEVANCE---\");\n\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1];\n  if (!(\"tool_calls\" in lastMessage)) {\n    throw new Error(\"The 'checkRelevance' node requires the most recent message to contain tool calls.\")\n  }\n  const toolCalls = (lastMessage as AIMessage).tool_calls;\n  if (!toolCalls || !toolCalls.length) {\n    throw new Error(\"Last message was not a function message\");\n  }\n\n  if (toolCalls[0].args.binaryScore === \"yes\") {\n    console.log(\"---DECISION: DOCS RELEVANT---\");\n    return \"yes\";\n  }\n  console.log(\"---DECISION: DOCS NOT RELEVANT---\");\n  return \"no\";\n}\n```\n\n----------------------------------------\n\nTITLE: Defining LangGraph Agent State Schema\nDESCRIPTION: Creates the agent state schema using LangGraph annotations, defining a messages array that maintains conversation history with a reducer for concatenation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/agent_executor/base.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Retriever Tool Node for LangGraph\nDESCRIPTION: Sets up a retriever tool and a ToolNode for the LangGraph. The tool allows the agent to search information from Lilian Weng's blog posts on various LLM topics, and the ToolNode integrates this capability into the graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport { createRetrieverTool } from \"langchain/tools/retriever\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst tool = createRetrieverTool(\n  retriever,\n  {\n    name: \"retrieve_blog_posts\",\n    description:\n      \"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\",\n  },\n);\nconst tools = [tool];\n\nconst toolNode = new ToolNode<typeof GraphState.State>(tools);\n```\n\n----------------------------------------\n\nTITLE: Creating Grandparent Graph in LangGraph.js\nDESCRIPTION: This code defines a grandparent graph in LangGraph.js, which utilizes the parent graph as a subgraph. It includes a router node, conditional edges for routing based on state, and compiles the graph with a memory saver checkpointer.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nconst checkpointer = new MemorySaver();\n\nconst GrandfatherStateAnnotation = Annotation.Root({\n  ...MessagesAnnotation.spec,\n  toContinue: Annotation<boolean>,\n});\n\nconst grandparentRouterNode = async (_state: typeof GrandfatherStateAnnotation.State) => {\n  // Dummy logic that will always continue\n  return { toContinue: true };\n};\n\nconst grandparentConditionalEdge = async (state: typeof GrandfatherStateAnnotation.State) => {\n  if (state.toContinue) {\n    return \"parentGraph\";\n  } else {\n    return \"__end__\";\n  }\n};\n\nconst grandparentGraph = new StateGraph(GrandfatherStateAnnotation)\n  .addNode(\"routerNode\", grandparentRouterNode)\n  .addNode(\"parentGraph\", parentGraph)\n  .addEdge(\"__start__\", \"routerNode\")\n  .addConditionalEdges(\"routerNode\", grandparentConditionalEdge)\n  .addEdge(\"parentGraph\", \"__end__\")\n  .compile({ checkpointer });\n```\n\n----------------------------------------\n\nTITLE: Creating Agent Nodes with Role-Specific Functionality\nDESCRIPTION: Defines agent nodes for the graph, including a helper function for running agents and two specialized agents: a research agent with search capabilities and a chart generator agent. Each agent has specific tools and system instructions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\nimport type { RunnableConfig } from \"@langchain/core/runnables\";\n\n// Helper function to run a node for a given agent\nasync function runAgentNode(props: {\n  state: typeof AgentState.State;\n  agent: Runnable;\n  name: string;\n  config?: RunnableConfig;\n}) {\n  const { state, agent, name, config } = props;\n  let result = await agent.invoke(state, config);\n  // We convert the agent output into a format that is suitable\n  // to append to the global state\n  if (!result?.tool_calls || result.tool_calls.length === 0) {\n    // If the agent is NOT calling a tool, we want it to\n    // look like a human message.\n    result = new HumanMessage({ ...result, name: name });\n  }\n  return {\n    messages: [result],\n    // Since we have a strict workflow, we can\n    // track the sender so we know who to pass to next.\n    sender: name,\n  };\n}\n\nconst llm = new ChatOpenAI({ modelName: \"gpt-4o\" });\n\n// Research agent and node\nconst researchAgent = await createAgent({\n  llm,\n  tools: [tavilyTool],\n  systemMessage:\n    \"You should provide accurate data for the chart generator to use.\",\n});\n\nasync function researchNode(\n  state: typeof AgentState.State,\n  config?: RunnableConfig,\n) {\n  return runAgentNode({\n    state: state,\n    agent: researchAgent,\n    name: \"Researcher\",\n    config,\n  });\n}\n\n// Chart Generator\nconst chartAgent = await createAgent({\n  llm,\n  tools: [chartTool],\n  systemMessage: \"Any charts you display will be visible by the user.\",\n});\n\nasync function chartNode(state: typeof AgentState.State) {\n  return runAgentNode({\n    state: state,\n    agent: chartAgent,\n    name: \"ChartGenerator\",\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Creating the LangGraph Agent Workflow\nDESCRIPTION: Assembles the complete agent workflow by defining the StateGraph, adding nodes for the LLM and tool execution, and configuring the edges between them to create a cyclic decision-making process.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/agent_executor/base.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { START, StateGraph } from \"@langchain/langgraph\";\n\n// Define a new graph\nconst workflow = new StateGraph(AgentState)\n  // Define the two nodes we will cycle between\n  .addNode(\"callModel\", callModel)\n  .addNode(\"executeTools\", toolNode)\n  // Set the entrypoint as `callModel`\n  // This means that this node is the first one called\n  .addEdge(START, \"callModel\")\n  // We now add a conditional edge\n  .addConditionalEdges(\n    // First, we define the start node. We use `callModel`.\n    // This means these are the edges taken after the `agent` node is called.\n    \"callModel\",\n    // Next, we pass in the function that will determine which node is called next.\n    shouldContinue,\n  )\n  // We now add a normal edge from `tools` to `agent`.\n  // This means that after `tools` is called, `agent` node is called next.\n  .addEdge(\"executeTools\", \"callModel\");\n\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Using Injectable Parameters in LangGraphJS Entrypoint\nDESCRIPTION: This example shows how to access injectable parameters within an entrypoint function, including previous state and store for long-term memory. It demonstrates using getPreviousState to access state from previous checkpoints and configuring a workflow with a store for persistent data storage.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  entrypoint,\n  getPreviousState,\n  BaseStore,\n  InMemoryStore,\n} from \"@langchain/langgraph\";\nimport { RunnableConfig } from \"@langchain/core/runnables\";\n\nconst inMemoryStore = new InMemoryStore(...);  // An instance of InMemoryStore for long-term memory\n\nconst myWorkflow = entrypoint(\n  {\n    checkpointer,  // Specify the checkpointer\n    store: inMemoryStore,  // Specify the store\n    name: \"myWorkflow\",\n  },\n  async (someInput: Record<string, any>) => {\n    const previous = getPreviousState<any>(); // For short-term memory\n    // Rest of workflow logic...\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Running the ReAct Agent with Tool Call\nDESCRIPTION: This JavaScript code runs the ReAct agent with an input that requires a tool call. It sends a message asking about the weather in SF to the agent, streams the response, and logs the content, tool calls, or the raw message.  The output is formatted for readability.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/create-react-agent.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n\"let inputs = { messages: [{ role: \\\"user\\\", content: \\\"what is the weather in SF?\\\" }] };\\n\\nlet stream = await agent.stream(inputs, {\\n  streamMode: \\\"values\\\",\\n});\\n\\nfor await (const { messages } of stream) {\\n  let msg = messages[messages?.length - 1];\\n  if (msg?.content) {\\n    console.log(msg.content);\\n  } else if (msg?.tool_calls?.length > 0) {\\n    console.log(msg.tool_calls);\\n  } else {\\n    console.log(msg);\\n  }\\n  console.log(\\\"-----\\n\\\");\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Creating Web Research Tools for LangGraphJS Agents\nDESCRIPTION: Implementation of research tools including Tavily search and a web scraper that agents can use to find information on the web. These tools enable the research team to search for information and extract content from webpages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\nimport { CheerioWebBaseLoader } from \"@langchain/community/document_loaders/web/cheerio\";\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst tavilyTool = new TavilySearchResults();\n\nconst scrapeWebpage = tool(async (input) => {\n    const loader = new CheerioWebBaseLoader(input.url);\n    const docs = await loader.load();\n    const formattedDocs = docs.map(\n      (doc) =>\n        `<Document name=\"${doc.metadata?.title}\">\\n${doc.pageContent}\\n</Document>`,\n    );\n    return formattedDocs.join(\"\\n\\n\");\n  },\n  {\n    name: \"scrape_webpage\",\n    description: \"Scrape the contents of a webpage.\",\n    schema: z.object({\n      url: z.string(),\n    }),\n  }\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent with Graph API in LangGraph\nDESCRIPTION: This code snippet demonstrates how to implement an agent using LangGraph's Graph API. It defines nodes for LLM calls and tool execution, along with conditional edges to route between them based on the LLM's decision to use tools or not.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_15\n\nLANGUAGE: ts\nCODE:\n```\nimport { MessagesAnnotation, StateGraph } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport {\n  SystemMessage,\n  ToolMessage\n} from \"@langchain/core/messages\";\n\n// Nodes\nasync function llmCall(state: typeof MessagesAnnotation.State) {\n  // LLM decides whether to call a tool or not\n  const result = await llmWithTools.invoke([\n    {\n      role: \"system\",\n      content: \"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n    },\n    ...state.messages\n  ]);\n\n  return {\n    messages: [result]\n  };\n}\n\nconst toolNode = new ToolNode(tools);\n\n// Conditional edge function to route to the tool node or end\nfunction shouldContinue(state: typeof MessagesAnnotation.State) {\n  const messages = state.messages;\n  const lastMessage = messages.at(-1);\n\n  // If the LLM makes a tool call, then perform an action\n  if (lastMessage?.tool_calls?.length) {\n    return \"Action\";\n  }\n  // Otherwise, we stop (reply to the user)\n  return \"__end__\";\n}\n\n// Build workflow\nconst agentBuilder = new StateGraph(MessagesAnnotation)\n  .addNode(\"llmCall\", llmCall)\n  .addNode(\"tools\", toolNode)\n  // Add edges to connect nodes\n  .addEdge(\"__start__\", \"llmCall\")\n  .addConditionalEdges(\n    \"llmCall\",\n    shouldContinue,\n    {\n      // Name returned by shouldContinue : Name of next node to visit\n      \"Action\": \"tools\",\n      \"__end__\": \"__end__\",\n    }\n  )\n  .addEdge(\"tools\", \"llmCall\")\n  .compile();\n\n// Invoke\nconst messages = [{\n  role: \"user\",\n  content: \"Add 3 and 4.\"\n}];\nconst result = await agentBuilder.invoke({ messages });\nconsole.log(result.messages);\n```\n\n----------------------------------------\n\nTITLE: Creating a ReAct Agent with LangGraph.js and Anthropic\nDESCRIPTION: Example of how to create a ReAct agent using LangGraph.js, including setting up a search tool, initializing the Anthropic model, and invoking the agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/README.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// npm install @langchain-anthropic\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { tool } from \"@langchain/core/tools\";\n\nimport { z } from \"zod\";\n\nconst search = tool(async ({ query }) => {\n  if (query.toLowerCase().includes(\"sf\") || query.toLowerCase().includes(\"san francisco\")) {\n    return \"It's 60 degrees and foggy.\"\n  }\n  return \"It's 90 degrees and sunny.\"\n}, {\n  name: \"search\",\n  description: \"Call to surf the web.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n});\n\nconst model =  new ChatAnthropic({\n  model: \"claude-3-7-sonnet-latest\"\n});\n\nconst agent = createReactAgent({\n  llm: model,\n  tools: [search],\n});\n\nconst result = await agent.invoke(\n  {\n    messages: [{\n      role: \"user\",\n      content: \"what is the weather in sf\"\n    }]\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Implementing Stable Sorting for Parallel Outputs\nDESCRIPTION: Advanced pattern that ensures consistent ordering of outputs from parallel branches by assigning scores and sorting them in a sink node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\ntype ScoredValue = {\n  value: string;\n  score: number;\n};\n\nconst reduceFanouts = (left?: ScoredValue[], right?: ScoredValue[]) => {\n  if (!left) {\n    left = [];\n  }\n  if (!right || right?.length === 0) {\n    // Overwrite. Similar to redux.\n    return [];\n  }\n  return left.concat(right);\n};\n\nconst StableSortingAnnotation = Annotation.Root({\n  aggregate: Annotation<string[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n  which: Annotation<string>({\n    reducer: (x: string, y: string) => (y ?? x),\n  }),\n  fanoutValues: Annotation<ScoredValue[]>({\n    reducer: reduceFanouts,\n  }),\n})\n\n\nclass ParallelReturnNodeValue {\n  private _value: string;\n  private _score: number;\n\n  constructor(nodeSecret: string, score: number) {\n    this._value = nodeSecret;\n    this._score = score;\n  }\n\n  public call(state: typeof StableSortingAnnotation.State) {\n    console.log(`Adding ${this._value} to ${state.aggregate}`);\n    return { fanoutValues: [{ value: this._value, score: this._score }] };\n  }\n}\n\n// Create the graph\n\nconst nodeA3 = (state: typeof StableSortingAnnotation.State) => {\n  console.log(`Adding I'm A to ${state.aggregate}`);\n  return { aggregate: [\"I'm A\"] };\n};\n\nconst nodeB3 = new ParallelReturnNodeValue(\"I'm B\", 0.1);\nconst nodeC3 = new ParallelReturnNodeValue(\"I'm C\", 0.9);\nconst nodeD3 = new ParallelReturnNodeValue(\"I'm D\", 0.3);\n\nconst aggregateFanouts = (state: typeof StableSortingAnnotation.State) => {\n  // Sort by score (reversed)\n  state.fanoutValues.sort((a, b) => b.score - a.score);\n  return {\n    aggregate: state.fanoutValues.map((v) => v.value).concat([\"I'm E\"]),\n    fanoutValues: [],\n  };\n};\n\n// Define the route function\nfunction routeBCOrCD(state: typeof StableSortingAnnotation.State): string[] {\n  if (state.which === \"cd\") {\n    return [\"c\", \"d\"];\n  }\n  return [\"b\", \"c\"];\n}\n\nconst builder3 = new StateGraph(StableSortingAnnotation)\n  .addNode(\"a\", nodeA3)\n  .addEdge(START, \"a\")\n  .addNode(\"b\", nodeB3.call.bind(nodeB3))\n  .addNode(\"c\", nodeC3.call.bind(nodeC3))\n  .addNode(\"d\", nodeD3.call.bind(nodeD3))\n  .addNode(\"e\", aggregateFanouts)\n  .addConditionalEdges(\"a\", routeBCOrCD, [\"b\", \"c\", \"d\"])\n  .addEdge(\"b\", \"e\")\n  .addEdge(\"c\", \"e\")\n  .addEdge(\"d\", \"e\")\n  .addEdge(\"e\", END);\n\nconst graph3 = builder3.compile();\n\n// Invoke the graph\nlet g3result = await graph3.invoke({ aggregate: [], which: \"bc\" });\nconsole.log(\"Result 1: \", g3result);\n```\n\n----------------------------------------\n\nTITLE: Complete Example of Parent and Subgraph Execution Flow\nDESCRIPTION: This comprehensive example demonstrates the execution flow between parent graphs and subgraphs with interrupts. It shows how node execution counts are tracked and how state is maintained across interruptions, providing insight into the LangGraph execution model.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  StateGraph,\n  START,\n  interrupt,\n  Command,\n  MemorySaver,\n  Annotation\n} from \"@langchain/langgraph\";\n\nconst GraphAnnotation = Annotation.Root({\n  stateCounter: Annotation<number>({\n    reducer: (a, b) => a + b,\n    default: () => 0\n  })\n})\n\nlet counterNodeInSubgraph = 0;\n\nfunction nodeInSubgraph(state: typeof GraphAnnotation.State) {\n  counterNodeInSubgraph += 1;  // This code will **NOT** run again!\n  console.log(`Entered 'nodeInSubgraph' a total of ${counterNodeInSubgraph} times`);\n  return {};\n}\n\nlet counterHumanNode = 0;\n\nasync function humanNode(state: typeof GraphAnnotation.State) {\n  counterHumanNode += 1; // This code will run again!\n  console.log(`Entered humanNode in sub-graph a total of ${counterHumanNode} times`);\n  const answer = await interrupt(\"what is your name?\");\n  console.log(`Got an answer of ${answer}`);\n  return {};\n}\n\nconst checkpointer = new MemorySaver();\n\nconst subgraphBuilder = new StateGraph(GraphAnnotation)\n  .addNode(\"some_node\", nodeInSubgraph)\n  .addNode(\"human_node\", humanNode)\n  .addEdge(START, \"some_node\")\n  .addEdge(\"some_node\", \"human_node\")\nconst subgraph = subgraphBuilder.compile({ checkpointer });\n\nlet counterParentNode = 0;\n\nasync function parentNode(state: typeof GraphAnnotation.State) {\n  counterParentNode += 1; // This code will run again on resuming!\n  console.log(`Entered 'parentNode' a total of ${counterParentNode} times`);\n\n  // Please note that we're intentionally incrementing the state counter\n  // in the graph state as well to demonstrate that the subgraph update\n  // of the same key will not conflict with the parent graph (until\n  const subgraphState = await subgraph.invoke(state);\n  return subgraphState;\n}\n\nconst builder = new StateGraph(GraphAnnotation)\n  .addNode(\"parent_node\", parentNode)\n  .addEdge(START, \"parent_node\")\n\n// A checkpointer must be enabled for interrupts to work!\nconst graph = builder.compile({ checkpointer });\n\nconst config = {\n  configurable: {\n    thread_id: crypto.randomUUID(),\n  }\n};\n\nfor await (const chunk of await graph.stream({ stateCounter: 1 }, config)) {\n  console.log(chunk);\n}\n\nconsole.log('--- Resuming ---');\n\nfor await (const chunk of await graph.stream(new Command({ resume: \"35\" }), config)) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Establishing Multi-Agent Communication Workflow\nDESCRIPTION: Sets up networkGraph for agent communications. Implements a loop to keep interactions between agents active until task completion. Centralizes agent task navigation using LangChain's infrastructure.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nconst networkGraph = entrypoint(\n  \"networkGraph\",\n  async (messages: BaseMessageLike[]) => {\n    // Converts inputs to LangChain messages as a side-effect\n    let currentMessages = addMessages([], messages);\n\n    let callActiveAgent = callTravelAdvisor;\n    while (true) {\n      const agentMessages = await callActiveAgent(currentMessages);\n      currentMessages = addMessages(currentMessages, agentMessages);\n      \n      // Find the last AI message\n      // If one of the handoff tools is called, the last message returned\n      // by the agent will be a ToolMessage because we set them to have\n      // \"returnDirect: true\". This means that the last AIMessage will\n      // have tool calls.\n      // Otherwise, the last returned message will be an AIMessage with\n      // no tool calls, which means we are ready for new input.\n      const aiMsg = [...agentMessages].reverse()\n        .find((m): m is AIMessage => m.getType() === \"ai\");\n        \n      // If no tool calls, we're done\n      if (!aiMsg?.tool_calls?.length) {\n        break;\n      }\n\n      // Get the last tool call and determine next agent\n      const toolCall = aiMsg.tool_calls.at(-1)!;\n      if (toolCall.name === \"transferToTravelAdvisor\") {\n        callActiveAgent = callTravelAdvisor;\n      } else if (toolCall.name === \"transferToHotelAdvisor\") {\n        callActiveAgent = callHotelAdvisor;\n      } else {\n        throw new Error(`Expected transfer tool, got '${toolCall.name}'`);\n      }\n    }\n\n    return messages;\n  });\n```\n\n----------------------------------------\n\nTITLE: Dynamic Tool Generation with Closures in LangGraph.js\nDESCRIPTION: Implements tool generation using closures to maintain access to dynamic content. Includes state management and schema definition for LLM interaction.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/pass-run-time-values-to-tools.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nfunction generateTools(state: typeof MessagesAnnotation.State) {\n  const updateFavoritePets = tool(\n    async (input, config: LangGraphRunnableConfig) => {\n      // Some arguments are populated by the LLM; these are included in the schema below\n      const { pets } = input;\n      // Others (such as a UserID) are best provided via the config\n      // This is set when when invoking or streaming the graph\n      const userId = config.configurable?.userId;\n      // LangGraph's managed key-value store is also accessible via the config\n      const store = config.store;\n      await store.put([userId, \"pets\"], \"names\", pets )\n      await store.put([userId, \"pets\"], \"context\", {content: state.messages[0].content})\n\n      return \"update_favorite_pets called.\";\n    },\n    {\n      // The LLM \"sees\" the following schema:\n      name: \"update_favorite_pets\",\n      description: \"add to the list of favorite pets.\",\n      schema: z.object({\n        pets: z.array(z.string()),\n      }),\n    }\n  );\n  return [updateFavoritePets];\n};\n```\n\n----------------------------------------\n\nTITLE: Creating Agent Nodes with TypeScript\nDESCRIPTION: This code snippet defines a function to create agent nodes for a travel assistant network. Each node handles requests and determines which agent to call next based on a structured response. It includes validation for the response schema using zod. Dependencies include ChatOpenAI and LangGraph components.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport {\n  Command,\n  MessagesAnnotation,\n  StateGraph\n} from \"@langchain/langgraph\";\n\nimport { z } from \"zod\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o\",\n  temperature: 0.1,\n});\n\nconst makeAgentNode = (params: {\n  name: string,\n  destinations: string[],\n  systemPrompt: string\n}) => {\n  return async (state: typeof MessagesAnnotation.State) => {\n    const possibleDestinations = [\"__end__\", ...params.destinations] as const;\n    // define schema for the structured output:\n    // - model's text response (`response`)\n    // - name of the node to go to next (or '__end__')\n    const responseSchema = z.object({\n      response: z.string().describe(\n        \"A human readable response to the original question. Does not need to be a final response. Will be streamed back to the user.\"\n      ),\n      goto: z.enum(possibleDestinations).describe(\"The next agent to call, or __end__ if the user's query has been resolved. Must be one of the specified values.\"),\n    });\n    const messages = [\n      {\n        role: \"system\",\n        content: params.systemPrompt\n      },\n      ...state.messages,\n    ];\n    const response = await model.withStructuredOutput(responseSchema, {\n      name: \"router\",\n    }).invoke(messages);\n\n    // handoff to another agent or halt\n    const aiMessage = {\n      role: \"assistant\",\n      content: response.response,\n      name: params.name,\n    };\n    return new Command({\n      goto: response.goto,\n      update: { messages: aiMessage }\n    });\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Implementing Helper Utilities for Agent Creation in TypeScript\nDESCRIPTION: Defines utility functions for creating worker agents and supervisors, including state modifiers and agent node runners. It uses Zod for schema validation and includes various imports from LangChain and OpenAI libraries.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\nimport { HumanMessage, BaseMessage, SystemMessage } from \"@langchain/core/messages\";\nimport {\n  ChatPromptTemplate,\n  MessagesPlaceholder,\n} from \"@langchain/core/prompts\";\nimport { JsonOutputToolsParser } from \"langchain/output_parsers\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { Runnable } from \"@langchain/core/runnables\";\nimport { StructuredToolInterface } from \"@langchain/core/tools\";\nimport { MessagesAnnotation } from \"@langchain/langgraph\";\n\nconst agentStateModifier = (\n  systemPrompt: string,\n  tools: StructuredToolInterface[],\n  teamMembers: string[],\n): ((state: typeof MessagesAnnotation.State) => BaseMessage[]) => {\n  const toolNames = tools.map((t) => t.name).join(\", \");\n  const systemMsgStart = new SystemMessage(systemPrompt +\n    \"\\nWork autonomously according to your specialty, using the tools available to you.\" +\n    \" Do not ask for clarification.\" +\n    \" Your other team members (and other teams) will collaborate with you with their own specialties.\" +\n    ` You are chosen for a reason! You are one of the following team members: ${teamMembers.join(\", \")}.`)\n  const systemMsgEnd = new SystemMessage(`Supervisor instructions: ${systemPrompt}\\n` +\n      `Remember, you individually can only use these tools: ${toolNames}` +\n      \"\\n\\nEnd if you have already completed the requested task. Communicate the work completed.\");\n\n  return (state: typeof MessagesAnnotation.State): any[] => \n    [systemMsgStart, ...state.messages, systemMsgEnd];\n}\n\nasync function runAgentNode(params: {\n  state: any;\n  agent: Runnable;\n  name: string;\n}) {\n  const { state, agent, name } = params;\n  const result = await agent.invoke({\n    messages: state.messages,\n  });\n  const lastMessage = result.messages[result.messages.length - 1];\n  return {\n    messages: [new HumanMessage({ content: lastMessage.content, name })],\n  };\n}\n\nasync function createTeamSupervisor(\n  llm: ChatOpenAI,\n  systemPrompt: string,\n  members: string[],\n): Promise<Runnable> {\n  const options = [\"FINISH\", ...members];\n  const routeTool = {\n    name: \"route\",\n    description: \"Select the next role.\",\n    schema: z.object({\n      reasoning: z.string(),\n      next: z.enum([\"FINISH\", ...members]),\n      instructions: z.string().describe(\"The specific instructions of the sub-task the next role should accomplish.\"),\n    })\n  }\n  let prompt = ChatPromptTemplate.fromMessages([\n    [\"system\", systemPrompt],\n    new MessagesPlaceholder(\"messages\"),\n    [\n      \"system\",\n      \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\",\n    ],\n  ]);\n  prompt = await prompt.partial({\n    options: options.join(\", \"),\n    team_members: members.join(\", \"),\n  });\n\n  const supervisor = prompt\n    .pipe(\n      llm.bindTools([routeTool], {\n        tool_choice: \"route\",\n      }),\n    )\n    .pipe(new JsonOutputToolsParser())\n    // select the first one\n    .pipe((x) => ({\n      next: x[0].args.next,\n      instructions: x[0].args.instructions,\n    }));\n\n  return supervisor;\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing State Graph for Evaluator-Optimizer Workflow in TypeScript\nDESCRIPTION: This snippet illustrates setting up a StateGraph for an evaluator-optimizer workflow using Langchain's Graph API. It defines annotations, structured schemas for feedback, and nodes for generating and evaluating jokes. The workflow routes based on the evaluated feedback and iteratively refines the output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_12\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { z } from \"zod\";\nimport { Annotation, StateGraph } from \"@langchain/langgraph\";\n\n// Graph state\nconst StateAnnotation = Annotation.Root({\n  joke: Annotation<string>,\n  topic: Annotation<string>,\n  feedback: Annotation<string>,\n  funnyOrNot: Annotation<string>,\n});\n\n// Schema for structured output to use in evaluation\nconst feedbackSchema = z.object({\n  grade: z.enum([\"funny\", \"not funny\"]).describe(\n    \"Decide if the joke is funny or not.\"\n  ),\n  feedback: z.string().describe(\n    \"If the joke is not funny, provide feedback on how to improve it.\"\n  ),\n});\n\n// Augment the LLM with schema for structured output\nconst evaluator = llm.withStructuredOutput(feedbackSchema);\n\n// Nodes\nasync function llmCallGenerator(state: typeof StateAnnotation.State) {\n  // LLM generates a joke\n  let msg;\n  if (state.feedback) {\n    msg = await llm.invoke(\n      `Write a joke about ${state.topic} but take into account the feedback: ${state.feedback}`\n    );\n  } else {\n    msg = await llm.invoke(`Write a joke about ${state.topic}`);\n  }\n  return { joke: msg.content };\n}\n\nasync function llmCallEvaluator(state: typeof StateAnnotation.State) {\n  // LLM evaluates the joke\n  const grade = await evaluator.invoke(`Grade the joke ${state.joke}`);\n  return { funnyOrNot: grade.grade, feedback: grade.feedback };\n}\n\n// Conditional edge function to route back to joke generator or end based upon feedback from the evaluator\nfunction routeJoke(state: typeof StateAnnotation.State) {\n  // Route back to joke generator or end based upon feedback from the evaluator\n  if (state.funnyOrNot === \"funny\") {\n    return \"Accepted\";\n  } else if (state.funnyOrNot === \"not funny\") {\n    return \"Rejected + Feedback\";\n  }\n}\n\n// Build workflow\nconst optimizerWorkflow = new StateGraph(StateAnnotation)\n  .addNode(\"llmCallGenerator\", llmCallGenerator)\n  .addNode(\"llmCallEvaluator\", llmCallEvaluator)\n  .addEdge(\"__start__\", \"llmCallGenerator\")\n  .addEdge(\"llmCallGenerator\", \"llmCallEvaluator\")\n  .addConditionalEdges(\n    \"llmCallEvaluator\",\n    routeJoke,\n    {\n      // Name returned by routeJoke : Name of next node to visit\n      \"Accepted\": \"__end__\",\n      \"Rejected + Feedback\": \"llmCallGenerator\",\n    }\n  )\n  .compile();\n\n// Invoke\nconst state = await optimizerWorkflow.invoke({ topic: \"Cats\" });\nconsole.log(state.joke);\n```\n\n----------------------------------------\n\nTITLE: Defining Graph Nodes and Conditional Logic\nDESCRIPTION: This snippet defines the main nodes of the graph, including the agent and tool invocation logic, as well as the conditional edge function.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END } from \"@langchain/langgraph\";\nimport { AIMessage, ToolMessage } from \"@langchain/core/messages\";\nimport { RunnableConfig } from \"@langchain/core/runnables\";\n\nconst shouldContinue = (state: typeof AgentState.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  if (!lastMessage.tool_calls || lastMessage.tool_calls.length === 0) {\n    return END;\n  }\n  return \"tools\";\n};\n\nconst callModel = async (\n  state: typeof AgentState.State,\n  config?: RunnableConfig,\n) => {\n  let modelMessages = [];\n  for (let i = state.messages.length - 1; i >= 0; i--) {\n    modelMessages.push(state.messages[i]);\n    if (modelMessages.length >= 5) {\n      if (!ToolMessage.isInstance(modelMessages[modelMessages.length - 1])) {\n        break;\n      }\n    }\n  }\n  modelMessages.reverse();\n\n  const response = await boundModel.invoke(modelMessages, config);\n  return { messages: [response] };\n};\n```\n\n----------------------------------------\n\nTITLE: Implementing Graph Nodes and Edges\nDESCRIPTION: Implements the core graph components including document retrieval, generation, grading, and routing logic with async functions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Document } from \"@langchain/core/documents\";\n\n/* ---Nodes--- */\n\nconst retrieve = async (state: typeof GraphState.State): Promise<Partial<typeof GraphState.State>> => {\n  console.log(\"---RETRIEVE---\");\n  const documents = await retriever.invoke(state.question);\n  return { documents };\n};\n\nconst generate = async (state: typeof GraphState.State): Promise<Partial<typeof GraphState.State>> => {\n  console.log(\"---GENERATE---\");\n  const generation = await ragChain.invoke({\n    context: formatDocs(state.documents),\n    question: state.question,\n  });\n  return { generation };\n};\n\nconst gradeDocuments = async (state: typeof GraphState.State): Promise<Partial<typeof GraphState.State>> => {\n  console.log(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\");\n  const relevantDocs: Document[] = [];\n  for (const doc of state.documents) {\n    const grade: { score: string } = await retrievalGrader.invoke({\n      question: state.question,\n      content: doc.pageContent,\n    });\n    if (grade.score === \"yes\") {\n      console.log(\"---GRADE: DOCUMENT RELEVANT---\");\n      relevantDocs.push(doc);\n    } else {\n      console.log(\"---GRADE: DOCUMENT NOT RELEVANT---\");\n    }\n  }\n  return { documents: relevantDocs };\n};\n\nconst transformQuery = async (state: typeof GraphState.State): Promise<Partial<typeof GraphState.State>> => {\n  console.log(\"---TRANSFORM QUERY---\");\n  const betterQuestion = await rewriter.invoke({ question: state.question });\n  return { question: betterQuestion };\n};\n\nconst webSearch = async (state: typeof GraphState.State): Promise<Partial<typeof GraphState.State>> => {\n  console.log(\"---WEB SEARCH---\");\n  const stringifiedSearchResults = await webSearchTool.invoke(state.question);\n  return {\n    documents: [new Document({ pageContent: stringifiedSearchResults })],\n  };\n};\n\n/* ---Edges--- */\n\nconst routeQuestion = async (state: typeof GraphState.State) => {\n  const source: { datasource: string } = await questionRouter.invoke({\n    question: state.question,\n  });\n  if (source.datasource === \"web_search\") {\n    console.log(`---ROUTING QUESTION \"${state.question} TO WEB SEARCH---`);\n    return \"web_search\";\n  } else {\n    console.log(`---ROUTING QUESTION \"${state.question} TO RAG---`);\n    return \"retrieve\";\n  }\n};\n\nconst decideToGenerate = async (state: typeof GraphState.State) => {\n  const filteredDocuments = state.documents;\n  if (filteredDocuments.length === 0) {\n    console.log(\n      \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\",\n    );\n    return \"transform_query\";\n  } else {\n    console.log(\"---DECISION: GENERATE---\");\n    return \"generate\";\n  }\n};\n\nconst gradeGenerationDocumentsAndQuestion = async (\n  state: typeof GraphState.State,\n) => {\n  const hallucinationGrade: { score: string } = await hallucinationGrader\n    .invoke({\n      generation: state.generation,\n      context: formatDocs(state.documents),\n    });\n  if (hallucinationGrade.score === \"yes\") {\n    console.log(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\");\n    console.log(\"---GRADING GENERATION vs. QUESTION---\");\n    const onTopicGrade: { score: string } = await answerGrader.invoke({\n      question: state.question,\n      generation: state.generation,\n    });\n    if (onTopicGrade.score === \"yes\") {\n      console.log(\"---DECISION: GENERATION ADDRESSES QUESTION---\");\n      return \"useful\";\n    } else {\n      console.log(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\");\n      return \"not_useful\";\n    }\n  } else {\n    console.log(\n      \"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RETRY---\",\n    );\n    return \"not_supported\";\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Human Input Command in LangGraphJS\nDESCRIPTION: This TypeScript function defines a 'human' node in a LangGraphJS graph. It uses the `interrupt` function to prompt the user for input, then constructs a command to update the message history with the user's input and route back to the currently active agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-multi-turn-convo.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nfunction human(state: typeof MessagesAnnotation.State): Command {\n  const userInput: string = interrupt(\"Ready for user input.\");\n\n  // Determine the active agent\n  const activeAgent = ...; \n\n  return new Command({\n    update: {\n      messages: [{\n        role: \"human\",\n        content: userInput,\n      }]\n    },\n    goto: activeAgent,\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Complete Usage of Interrupt in a Graph - LangGraph - TypeScript\nDESCRIPTION: This detailed example showcases how to define and integrate a human-in-the-loop node in a LangGraph graph with the use of the interrupt function and StateGraph. The snippet requires LangGraph and its components like MemorySaver and Annotation. It illustrates the building, streaming, and resuming of a graph's execution with human input processing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MemorySaver, Annotation, interrupt, Command, StateGraph } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  some_text: Annotation<string>()\n});\n\nfunction humanNode(state: typeof StateAnnotation.State) {\n   const value = interrupt(\n      {\n         text_to_revise: state.some_text\n      }\n   );\n   return {\n      some_text: value\n   };\n}\n\nconst workflow = new StateGraph(StateAnnotation)\n  .addNode(\"human_node\", humanNode)\n  .addEdge(\"__start__\", \"human_node\")\n\nconst checkpointer = new MemorySaver();\nconst graph = workflow.compile({\n   checkpointer\n});\n\nfor await (const chunk of await graph.stream(\n   { some_text: \"Original text\" },\n   threadConfig\n)) {\n   console.log(chunk);\n}\n\nfor await (const chunk of await graph.stream(\n   new Command({ resume: \"Edited text\" }),\n   threadConfig\n)) {\n   console.log(chunk);\n}\n```\n\nLANGUAGE: typescript\nCODE:\n```\n{\n   __interrupt__: [\n      {\n         value: { question: 'Please revise the text', some_text: 'Original text' },\n         resumable: true,\n         ns: ['human_node:10fe492f-3688-c8c6-0d0a-ec61a43fecd6'],\n         when: 'during'\n      }\n   ]\n}\n{ human_node: { some_text: 'Edited text' } }\n```\n\n----------------------------------------\n\nTITLE: Defining LangGraph Tasks for Model and Tool Calls\nDESCRIPTION: This code defines two LangGraph tasks: `callModel` and `callTool`. The `callModel` task invokes the chat model with a list of messages and binds available tools, while the `callTool` task executes a specific tool call and returns a ToolMessage with the tool's output. These tasks are essential for the ReAct agent's tool-calling functionality.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n\"import {\\n  type BaseMessageLike,\\n  AIMessage,\\n  ToolMessage,\\n} from \\\"@langchain/core/messages\\\";\\nimport { type ToolCall } from \\\"@langchain/core/messages/tool\\\";\\nimport { task } from \\\"@langchain/langgraph\\\";\\n\\nconst toolsByName = Object.fromEntries(tools.map((tool) => [tool.name, tool]));\\n\\nconst callModel = task(\\\"callModel\\\", async (messages: BaseMessageLike[]) => {\\n  const response = await model.bindTools(tools).invoke(messages);\\n  return response;\\n});\\n\\nconst callTool = task(\\n  \\\"callTool\\\",\\n  async (toolCall: ToolCall): Promise<AIMessage> => {\\n    const tool = toolsByName[toolCall.name];\\n    const observation = await tool.invoke(toolCall.args);\\n    return new ToolMessage({ content: observation, tool_call_id: toolCall.id });\\n    // Can also pass toolCall directly into the tool to return a ToolMessage\\n    // return tool.invoke(toolCall);\\n  });\"\n```\n\n----------------------------------------\n\nTITLE: Adding Conditional Edges in LangGraphJS\nDESCRIPTION: This code snippet demonstrates how to add conditional edges to a LangGraphJS graph builder. It defines the routing logic based on the `nextRepresentative` property of the graph's state. The edges route execution to either the `billing_support`, `technical_support`, or `__end__` nodes depending on the value of `state.nextRepresentative`.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nbuilder = builder.addConditionalEdges(\"initial_support\", async (state: typeof StateAnnotation.State) => {\n  if (state.nextRepresentative.includes(\"BILLING\")) {\n    return \"billing\";\n  } else if (state.nextRepresentative.includes(\"TECHNICAL\")) {\n    return \"technical\";\n  } else {\n    return \"conversational\";\n  }\n}, {\n  billing: \"billing_support\",\n  technical: \"technical_support\",\n  conversational: \"__end__\",\n});\n\nconsole.log(\"Added edges!\");\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Multi-agent Workflow in LangGraphJS\nDESCRIPTION: Shows how to create a custom multi-agent workflow with explicit control flow. Agents are defined as graph nodes with a predetermined sequence of execution defined through normal edges.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/multi_agent.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  StateGraph,\n  MessagesAnnotation,\n} from \"@langchain/langgraph\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o-mini\",\n});\n\nconst agent1 = async (state: typeof MessagesAnnotation.State) => {\n  const response = await model.invoke(...);\n  return { messages: [response] };\n};\n\nconst agent2 = async (state: typeof MessagesAnnotation.State) => {\n  const response = await model.invoke(...);\n  return { messages: [response] };\n};\n\nconst graph = new StateGraph(MessagesAnnotation)\n  .addNode(\"agent1\", agent1)\n  .addNode(\"agent2\", agent2)\n  // define the flow explicitly\n  .addEdge(\"__start__\", \"agent1\")\n  .addEdge(\"agent1\", \"agent2\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent with Functional API in LangGraph\nDESCRIPTION: This code shows how to implement an agent using LangGraph's Functional API (beta). It defines tasks for LLM calls and tool execution, then composes them in an entrypoint function that implements the agent's reasoning loop.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_16\n\nLANGUAGE: ts\nCODE:\n```\nimport { task, entrypoint, addMessages } from \"@langchain/langgraph\";\nimport { BaseMessageLike, ToolCall } from \"@langchain/core/messages\";\n\nconst callLlm = task(\"llmCall\", async (messages: BaseMessageLike[]) => {\n  // LLM decides whether to call a tool or not\n  return llmWithTools.invoke([\n    {\n      role: \"system\",\n      content: \"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n    },\n    ...messages\n  ]);\n});\n\nconst callTool = task(\"toolCall\", async (toolCall: ToolCall) => {\n  // Performs the tool call\n  const tool = toolsByName[toolCall.name];\n  return tool.invoke(toolCall.args);\n});\n\nconst agent = entrypoint(\n  \"agent\",\n  async (messages: BaseMessageLike[]) => {\n    let llmResponse = await callLlm(messages);\n\n    while (true) {\n      if (!llmResponse.tool_calls?.length) {\n        break;\n      }\n\n      // Execute tools\n      const toolResults = await Promise.all(\n        llmResponse.tool_calls.map((toolCall) => callTool(toolCall))\n      );\n\n      messages = addMessages(messages, [llmResponse, ...toolResults]);\n      llmResponse = await callLlm(messages);\n    }\n\n    messages = addMessages(messages, [llmResponse]);\n    return messages;\n  }\n);\n\n// Invoke\nconst messages = [{\n  role: \"user\",\n  content: \"Add 3 and 4.\"\n}];\n\nconst stream = await agent.stream([messages], {\n  streamMode: \"updates\",\n});\n\nfor await (const step of stream) {\n  console.log(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Branched Graph State\nDESCRIPTION: Shows how to execute a graph from a branched state using the updated configuration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfor await (\n  const { messages } of await graphWithInterrupt.stream(null, {\n    ...branchConfig,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing a ReAct Agent with StateGraph and ToolNode\nDESCRIPTION: Building a complete ReAct agent using LangGraph's StateGraph. The agent cycles between calling the model and executing tools until it resolves the query without needing more tools.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  StateGraph,\n  MessagesAnnotation,\n  END,\n  START\n} from \"@langchain/langgraph\";\n\nconst toolNodeForGraph = new ToolNode(tools)\n\nconst shouldContinue = (state: typeof MessagesAnnotation.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1];\n  if (\"tool_calls\" in lastMessage && Array.isArray(lastMessage.tool_calls) && lastMessage.tool_calls?.length) {\n      return \"tools\";\n  }\n  return END;\n}\n\nconst callModel = async (state: typeof MessagesAnnotation.State) => {\n  const { messages } = state;\n  const response = await modelWithTools.invoke(messages);\n  return { messages: response };\n}\n\n\nconst workflow = new StateGraph(MessagesAnnotation)\n  // Define the two nodes we will cycle between\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNodeForGraph)\n  .addEdge(START, \"agent\")\n  .addConditionalEdges(\"agent\", shouldContinue, [\"tools\", END])\n  .addEdge(\"tools\", \"agent\");\n\nconst app = workflow.compile()\n```\n\n----------------------------------------\n\nTITLE: Implementing Checkpointer-Graph Interface in TypeScript\nDESCRIPTION: Defines the integration between the Graph layer and Checkpointer, providing persistence and time-travel capabilities for state graphs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/langgraph-architecture-spec.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nclass StateGraph<SD, S, U, N> {\n  compile({\n    checkpointer,\n    store,\n    // ...other options\n  }: {\n    checkpointer?: BaseCheckpointSaver | false;\n    store?: BaseStore;\n    // ...other options\n  }): CompiledStateGraph<S, U, N>;\n}\n\nclass CompiledStateGraph<S, U, N> extends CompiledGraph {\n  async getState(options?: GetStateOptions): Promise<StateSnapshot>;\n  async getCheckpoint(id: string): Promise<CheckpointTuple>;\n  async listCheckpoints(options?: CheckpointListOptions): Promise<CheckpointTuple[]>;\n}\n```\n\n----------------------------------------\n\nTITLE: Proper config handling for nested Runnables\nDESCRIPTION: This example demonstrates the correct way to pass the config object to nested Runnable functions in web environments. By accepting and forwarding the config parameter, the graph can properly trace and stream events from nested functions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/use-in-web-environments.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Import from \"@langchain/langgraph/web\"\nimport {\n  END,\n  START,\n  StateGraph,\n  Annotation,\n} from \"@langchain/langgraph/web\";\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { type RunnableConfig, RunnableLambda } from \"@langchain/core/runnables\";\nimport { type StreamEvent } from \"@langchain/core/tracers/log_stream\";\n\nconst GraphState3 = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n\n// Note the second argument here.\nconst nodeFn3 = async (_state: typeof GraphState3.State, config?: RunnableConfig) => {\n  // If you need to nest deeper, remember to pass `_config` when invoking\n  const nestedFn = RunnableLambda.from(\n    async (input: string, _config?: RunnableConfig) => {\n      return new HumanMessage(`Hello from ${input}!`);\n    },\n  ).withConfig({ runName: \"nested\" });\n  const responseMessage = await nestedFn.invoke(\"a nested function\", config);\n  return { messages: [responseMessage] };\n};\n\n// Define a new graph\nconst workflow3 = new StateGraph(GraphState3)\n  .addNode(\"node\", nodeFn3)\n  .addEdge(START, \"node\")\n  .addEdge(\"node\", END);\n\nconst app3 = workflow3.compile({});\n\n// Stream intermediate steps from the graph\nconst eventStream3 = app3.streamEvents(\n  { messages: [] },\n  { version: \"v2\" },\n  { includeNames: [\"nested\"] },\n);\n\nconst events3: StreamEvent[] = [];\nfor await (const event of eventStream3) {\n  console.log(event);\n  events3.push(event);\n}\n\nconsole.log(`Received ${events3.length} events from the nested function`);\n```\n\n----------------------------------------\n\nTITLE: Implementing the Planner Node Function for ReWOO Agent\nDESCRIPTION: Creates a getPlan function that processes the LLM's planning output, extracts the individual steps and tools using regex, and updates the graph state with the parsed plan and steps.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RunnableConfig } from \"@langchain/core/runnables\";\n\nconst regexPattern = new RegExp(\n  \"Plan\\\\s*\\\\d*:\\\\s*([^#]+)\\\\s*(#E\\\\d+)\\\\s*=\\\\s*(\\\\w+)\\\\s*\\\\[([^\\\\]]+)\\\\]\",\n  \"g\",\n);\n\nasync function getPlan(state: typeof GraphState.State, config?: RunnableConfig) {\n  console.log(\"---GET PLAN---\");\n  const task = state.task;\n  const result = await planner.invoke({ task }, config);\n  // Find all matches in the sample text.\n  const matches = result.content.toString().matchAll(regexPattern);\n  let steps: string[][] = [];\n  for (const match of matches) {\n    const item = [match[1], match[2], match[3], match[4], match[0]];\n    if (item.some((i) => i === undefined)) {\n      throw new Error(\"Invalid match\");\n    }\n    steps.push(item as string[]);\n  }\n  return {\n    steps,\n    planString: result.content.toString(),\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Fan-out and Fan-in Pattern with State Aggregation\nDESCRIPTION: Creates a graph that branches out from node A to nodes B and C, then merges at node D before ending. Uses a reducer to concatenate state values from parallel branches.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph, Annotation } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  aggregate: Annotation<string[]>({\n    reducer: (x, y) => x.concat(y),\n  })\n});\n\n// Create the graph\nconst nodeA = (state: typeof StateAnnotation.State) => {\n  console.log(`Adding I'm A to ${state.aggregate}`);\n  return { aggregate: [`I'm A`] };\n};\nconst nodeB = (state: typeof StateAnnotation.State) => {\n  console.log(`Adding I'm B to ${state.aggregate}`);\n  return { aggregate: [`I'm B`] };\n};\nconst nodeC = (state: typeof StateAnnotation.State) => {\n  console.log(`Adding I'm C to ${state.aggregate}`);\n  return { aggregate: [`I'm C`] };\n};\nconst nodeD = (state: typeof StateAnnotation.State) => {\n  console.log(`Adding I'm D to ${state.aggregate}`);\n  return { aggregate: [`I'm D`] };\n};\n\nconst builder = new StateGraph(StateAnnotation)\n  .addNode(\"a\", nodeA)\n  .addEdge(START, \"a\")\n  .addNode(\"b\", nodeB)\n  .addNode(\"c\", nodeC)\n  .addNode(\"d\", nodeD)\n  .addEdge(\"a\", \"b\")\n  .addEdge(\"a\", \"c\")\n  .addEdge(\"b\", \"d\")\n  .addEdge(\"c\", \"d\")\n  .addEdge(\"d\", END);\n\nconst graph = builder.compile();\n```\n\n----------------------------------------\n\nTITLE: Grading Document Relevance in Self-RAG Graph\nDESCRIPTION: This function assesses the relevance of retrieved documents to the input question. It uses a structured output from the language model to grade each document as relevant or not relevant, filtering the documents accordingly.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nasync function gradeDocuments(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---CHECK RELEVANCE---\");\n\n  // pass the name & schema to `withStructuredOutput` which will force the model to call this tool.\n  const llmWithTool = model.withStructuredOutput(\n    z\n      .object({\n        binaryScore: z\n          .enum([\"yes\", \"no\"])\n          .describe(\"Relevance score 'yes' or 'no'\"),\n      })\n      .describe(\n        \"Grade the relevance of the retrieved documents to the question. Either 'yes' or 'no'.\"\n      ),\n    {\n      name: \"grade\",\n    }\n  );\n\n  const prompt = ChatPromptTemplate.fromTemplate(\n    `You are a grader assessing relevance of a retrieved document to a user question.\n  Here is the retrieved document:\n  \n  {context}\n  \n  Here is the user question: {question}\n\n  If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\n  Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.`\n  );\n\n  // Chain\n  const chain = prompt.pipe(llmWithTool);\n\n  const filteredDocs: Array<DocumentInterface> = [];\n  for await (const doc of state.documents) {\n    const grade = await chain.invoke({\n      context: doc.pageContent,\n      question: state.question,\n    });\n    if (grade.binaryScore === \"yes\") {\n      console.log(\"---GRADE: DOCUMENT RELEVANT---\");\n      filteredDocs.push(doc);\n    } else {\n      console.log(\"---GRADE: DOCUMENT NOT RELEVANT---\");\n    }\n  }\n\n  return {\n    documents: filteredDocs,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Defining the StateGraph for Token Management - TypeScript\nDESCRIPTION: This code snippet illustrates how to define a state graph that manages the flow of messages through different nodes, determining when to call tools or finish the process.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, END } from \"@langchain/langgraph\";\nimport { AIMessage } from \"@langchain/core/messages\";\n\nconst routeMessage = (state: typeof StateAnnotation.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  // If no tools are called, we can finish (respond to the user)\n  if (!lastMessage?.tool_calls?.length) {\n    return END;\n  }\n  // Otherwise if there is, we continue and call the tools\n  return \"tools\";\n};\n\nconst callModel = async (\n  state: typeof StateAnnotation.State,\n) => {\n  // For versions of @langchain/core < 0.2.3, you must call `.stream()`\n  // and aggregate the message from chunks instead of calling `.invoke() `.\n  const { messages } = state;\n  const responseMessage = await boundModel.invoke(messages);\n  return { messages: [responseMessage] };\n};\n\nconst workflow = new StateGraph(StateAnnotation)\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  .addEdge(\"__start__\", \"agent\")\n  .addConditionalEdges(\"agent\", routeMessage)\n  .addEdge(\"tools\", \"agent\");\n\nconst agent = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Streaming Results from Super Graph in LangGraph.js\nDESCRIPTION: This code snippet demonstrates how to stream results from the compiled `superGraph`. It invokes the graph with a user message asking to look up a current event, write a poem about it, and then plot a bar chart of the distribution of words.  The results are streamed, and each step of the stream (excluding the end step) is logged to the console, separated by '---'. A recursion limit is set to 150.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: javascript\nCODE:\n```\nresultStream = compiledSuperGraph.stream(\n  {{\n    messages: [\n      new HumanMessage(\n        \"Look up a current event, write a poem about it, then plot a bar chart of the distribution of words therein.\",\n      ),\n    ],\n  }},\n  {{ recursionLimit: 150 }},\n);\n\nfor await (const step of await resultStream) {{\n  if (!step.__end__) {{\n    console.log(step);\n    console.log(\"---\");\n  }}\n}}\n\n```\n\n----------------------------------------\n\nTITLE: Defining a State Graph with Conditional Edges - TypeScript\nDESCRIPTION: The TypeScript snippet details the definition of a state graph with a conditional edge and nodes to implement a simple loop. It discusses the use of a reducer for state handling, node implementation, and edge definition, with a condition to terminate the loop.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/recursion-limit.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\n// Define the state with a reducer\nconst StateAnnotation = Annotation.Root({\n  aggregate: Annotation<string[]>({\n    reducer: (a, b) => a.concat(b),\n    default: () => [],\n  }),\n});\n\n// Define nodes\nconst a = async function (state: typeof StateAnnotation.State) {\n  console.log(`Node A sees ${state.aggregate}`);\n  return { aggregate: [\"A\"] };\n}\n\nconst b = async function (state: typeof StateAnnotation.State) {\n  console.log(`Node B sees ${state.aggregate}`);\n  return { aggregate: [\"B\"] };\n}\n\n// Define edges\nconst route = async function (state: typeof StateAnnotation.State) {\n  if (state.aggregate.length < 7) {\n    return \"b\";\n  } else {\n    return \"__end__\";\n  }\n}\n\n\n// Define the graph\nconst graph = new StateGraph(StateAnnotation)\n  .addNode(\"a\", a)\n  .addNode(\"b\", b)\n  .addEdge(\"__start__\", \"a\")\n  .addConditionalEdges(\"a\", route)\n  .addEdge(\"b\", \"a\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Constructing StateGraph for LangGraphJS ReAct Agent\nDESCRIPTION: This code constructs the StateGraph for the LangGraphJS ReAct agent, defining nodes, edges, and conditional logic for the workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamically-returning-directly.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { START, StateGraph } from \"@langchain/langgraph\";\n\n// Define a new graph\nconst workflow = new StateGraph(AgentState)\n  // Define the two nodes we will cycle between\n  .addNode(\"agent\", callModel)\n  // Note the \"action\" and \"final\" nodes are identical!\n  .addNode(\"tools\", toolNode)\n  .addNode(\"final\", toolNode)\n  // Set the entrypoint as `agent`\n  .addEdge(START, \"agent\")\n  // We now add a conditional edge\n  .addConditionalEdges(\n    // First, we define the start node. We use `agent`.\n    \"agent\",\n    // Next, we pass in the function that will determine which node is called next.\n    shouldContinue,\n  )\n  // We now add a normal edge from `tools` to `agent`.\n  .addEdge(\"tools\", \"agent\")\n  .addEdge(\"final\", END);\n\n// Finally, we compile it!\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Map-Reduce Graph for Joke Generation in TypeScript\nDESCRIPTION: This extensive TypeScript snippet defines the entire map-reduce graph for generating jokes. It includes imports, model setup, state definitions, graph components, and graph construction using LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/map-reduce.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { StateGraph, END, START, Annotation, Send } from \"@langchain/langgraph\";\n\n/* Model and prompts */\n\n// Define model and prompts we will use\nconst subjectsPrompt = \"Generate a comma separated list of between 2 and 5 examples related to: {topic}.\"\nconst jokePrompt = \"Generate a joke about {subject}\"\nconst bestJokePrompt = `Below are a bunch of jokes about {topic}. Select the best one! Return the ID (index) of the best one.\n\n{jokes}`\n\n// Zod schemas for getting structured output from the LLM\nconst Subjects = z.object({\n  subjects: z.array(z.string()),\n});\nconst Joke = z.object({\n  joke: z.string(),\n});\nconst BestJoke = z.object({\n  id: z.number(),\n});\n\nconst model = new ChatAnthropic({\n  model: \"claude-3-5-sonnet-20240620\",\n});\n\n/* Graph components: define the components that will make up the graph */\n\n// This will be the overall state of the main graph.\n// It will contain a topic (which we expect the user to provide)\n// and then will generate a list of subjects, and then a joke for\n// each subject\nconst OverallState = Annotation.Root({\n  topic: Annotation<string>,\n  subjects: Annotation<string[]>,\n  // Notice here we pass a reducer function.\n  // This is because we want combine all the jokes we generate\n  // from individual nodes back into one list.\n  jokes: Annotation<string[]>({\n    reducer: (state, update) => state.concat(update),\n  }),\n  bestSelectedJoke: Annotation<string>,\n});\n\n// This will be the state of the node that we will \"map\" all\n// subjects to in order to generate a joke\ninterface JokeState {\n  subject: string;\n}\n\n// This is the function we will use to generate the subjects of the jokes\nconst generateTopics = async (\n  state: typeof OverallState.State\n): Promise<Partial<typeof OverallState.State>> => {\n  const prompt = subjectsPrompt.replace(\"topic\", state.topic);\n  const response = await model\n    .withStructuredOutput(Subjects, { name: \"subjects\" })\n    .invoke(prompt);\n  return { subjects: response.subjects };\n};\n\n// Function to generate a joke\nconst generateJoke = async (state: JokeState): Promise<{ jokes: string[] }> => {\n  const prompt = jokePrompt.replace(\"subject\", state.subject);\n  const response = await model\n    .withStructuredOutput(Joke, { name: \"joke\" })\n    .invoke(prompt);\n  return { jokes: [response.joke] };\n};\n\n// Here we define the logic to map out over the generated subjects\n// We will use this an edge in the graph\nconst continueToJokes = (state: typeof OverallState.State) => {\n  // We will return a list of `Send` objects\n  // Each `Send` object consists of the name of a node in the graph\n  // as well as the state to send to that node\n  return state.subjects.map((subject) => new Send(\"generateJoke\", { subject }));\n};\n\n// Here we will judge the best joke\nconst bestJoke = async (\n  state: typeof OverallState.State\n): Promise<Partial<typeof OverallState.State>> => {\n  const jokes = state.jokes.join(\"\\n\\n\");\n  const prompt = bestJokePrompt\n    .replace(\"jokes\", jokes)\n    .replace(\"topic\", state.topic);\n  const response = await model\n    .withStructuredOutput(BestJoke, { name: \"best_joke\" })\n    .invoke(prompt);\n  return { bestSelectedJoke: state.jokes[response.id] };\n};\n\n// Construct the graph: here we put everything together to construct our graph\nconst graph = new StateGraph(OverallState)\n  .addNode(\"generateTopics\", generateTopics)\n  .addNode(\"generateJoke\", generateJoke)\n  .addNode(\"bestJoke\", bestJoke)\n  .addEdge(START, \"generateTopics\")\n  .addConditionalEdges(\"generateTopics\", continueToJokes)\n  .addEdge(\"generateJoke\", \"bestJoke\")\n  .addEdge(\"bestJoke\", END);\n\nconst app = graph.compile();\n```\n\n----------------------------------------\n\nTITLE: Continuing Execution from Forked Checkpoint\nDESCRIPTION: This code snippet shows how to continue the LangGraph execution from a forked checkpoint. The `checkpoint_id` is set to the forked checkpoint's ID (`xyz-fork`). The graph is then streamed from the forked checkpoint, allowing you to explore alternative paths.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/time-travel.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst threadConfig = { configurable: { thread_id: '1', checkpoint_id: 'xyz-fork' }, streamMode: \"values\" };\n\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Routing Logic with Graph API in TypeScript\nDESCRIPTION: This snippet implements a routing mechanism using the Graph API from the Langchain framework. It classifies input and directs it to specific tasks that generate stories, jokes, or poems. It utilizes Zod for validating the routing schema and defines a workflow for executing based on user input.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Import necessary libraries\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\nimport { z } from \"zod\";\n\n// Schema for structured output to use as routing logic\nconst routeSchema = z.object({\n  step: z.enum([\"poem\", \"story\", \"joke\"]).describe(\n    \"The next step in the routing process\"\n  ),\n});\n\n// Augment the LLM with schema for structured output\nconst router = llm.withStructuredOutput(routeSchema);\n\n// Graph state\nconst StateAnnotation = Annotation.Root({\n  input: Annotation<string>,\n  decision: Annotation<string>,\n  output: Annotation<string>,\n});\n\n// Nodes\n// Write a story\nasync function llmCall1(state: typeof StateAnnotation.State) {\n  const result = await llm.invoke([{\n    role: \"system\",\n    content: \"You are an expert storyteller.\",\n  }, {\n    role: \"user\",\n    content: state.input\n  }]);\n  return { output: result.content };\n}\n\n// Write a joke\nasync function llmCall2(state: typeof StateAnnotation.State) {\n  const result = await llm.invoke([{\n    role: \"system\",\n    content: \"You are an expert comedian.\",\n  }, {\n    role: \"user\",\n    content: state.input\n  }]);\n  return { output: result.content };\n}\n\n// Write a poem\nasync function llmCall3(state: typeof StateAnnotation.State) {\n  const result = await llm.invoke([{\n    role: \"system\",\n    content: \"You are an expert poet.\",\n  }, {\n    role: \"user\",\n    content: state.input\n  }]);\n  return { output: result.content };\n}\n\nasync function llmCallRouter(state: typeof StateAnnotation.State) {\n  // Route the input to the appropriate node\n  const decision = await router.invoke([\n    {\n      role: \"system\",\n      content: \"Route the input to story, joke, or poem based on the user's request.\"\n    },\n    {\n      role: \"user\",\n      content: state.input\n    },\n  ]);\n\n  return { decision: decision.step };\n}\n\n// Conditional edge function to route to the appropriate node\nfunction routeDecision(state: typeof StateAnnotation.State) {\n  // Return the node name you want to visit next\n  if (state.decision === \"story\") {\n    return \"llmCall1\";\n  } else if (state.decision === \"joke\") {\n    return \"llmCall2\";\n  } else if (state.decision === \"poem\") {\n    return \"llmCall3\";\n  }\n}\n\n// Build workflow\nconst routerWorkflow = new StateGraph(StateAnnotation)\n  .addNode(\"llmCall1\", llmCall1)\n  .addNode(\"llmCall2\", llmCall2)\n  .addNode(\"llmCall3\", llmCall3)\n  .addNode(\"llmCallRouter\", llmCallRouter)\n  .addEdge(\"__start__\", \"llmCallRouter\")\n  .addConditionalEdges(\n    \"llmCallRouter\",\n    routeDecision,\n    [\"llmCall1\", \"llmCall2\", \"llmCall3\"],\n  )\n  .addEdge(\"llmCall1\", \"__end__\")\n  .addEdge(\"llmCall2\", \"__end__\")\n  .addEdge(\"llmCall3\", \"__end__\")\n  .compile();\n\n// Invoke\nconst state = await routerWorkflow.invoke({\n  input: \"Write me a joke about cats\"\n});\nconsole.log(state.output);\n```\n\n----------------------------------------\n\nTITLE: Defining Agent Handoff Tools in LangChain\nDESCRIPTION: Implements tools to manage agent handoffs between travelAdvisor and hotelAdvisor. They are created to handle task delegation without looping back to the main model, helping in quick transfers. 'returnDirect' is set to true to facilitate early exit.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n// Define a tool to signal intent to hand off to a different agent\n// Note: this is not using Command(goto) syntax for navigating to different agents:\n// `workflow()` below handles the handoffs explicitly\nconst transferToHotelAdvisor = tool(async () => {\n  return \"Successfully transferred to hotel advisor\";\n}, {\n  name: \"transferToHotelAdvisor\",\n  description: \"Ask hotel advisor agent for help.\",\n  schema: z.object({}),\n  // Hint to our agent implementation that it should stop\n  // immediately after invoking this tool \n  returnDirect: true,\n}); \n\nconst transferToTravelAdvisor = tool(async () => {\n  return \"Successfully transferred to travel advisor\";\n}, {\n  name: \"transferToTravelAdvisor\", \n  description: \"Ask travel advisor agent for help.\",\n  schema: z.object({}),\n  // Hint to our agent implementation that it should stop\n  // immediately after invoking this tool\n  returnDirect: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Conversation Flow with the ReAct Agent\nDESCRIPTION: This TypeScript code demonstrates how to use the created ReAct agent in a conversation. It shows how to stream responses for two separate user inputs and handle the conversation flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-conversation-history.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n\nconst config = { configurable: { thread_id: \"2\"}, streamMode: \"values\" as const }\n\nconst inputMessage = new HumanMessage(\"hi! I'm bob\");\nfor await (const event of await app.stream({\n    messages: [inputMessage]\n}, config)) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n\nconsole.log(\"\\n\\n================================= END =================================\\n\\n\")\n\nconst inputMessage2 = new HumanMessage(\"what's my name?\");\nfor await (const event of await app.stream({\n    messages: [inputMessage2]\n}, config)) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (2) =================================`)\n    console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Continuing LangGraph Execution After State Update\nDESCRIPTION: This code snippet demonstrates how to resume graph execution after manually updating the state, completing the human-in-the-loop interaction.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Continue the graph execution\nfor await (const event of await graph.stream(null, graphStateConfig)) {\n    console.log(`--- ${event.input} ---`);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Document Retrieval in Self-RAG Graph\nDESCRIPTION: This function retrieves relevant documents based on the current state of the graph. It uses a retriever to fetch documents related to the input question and updates the state with the retrieved documents.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nasync function retrieve(\n  state: typeof GraphState.State,\n  config?: RunnableConfig\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---RETRIEVE---\");\n\n  const documents = await retriever\n    .withConfig({ runName: \"FetchRelevantDocuments\" })\n    .invoke(state.question, config);\n\n  return {\n    documents,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a React Agent with Structured Output - LangGraphJS - Python\nDESCRIPTION: This snippet creates a React agent that utilizes a structured output schema defined using Zod. The agent is set up with tools and a response format specified, allowing it to return outputs in a desired structured format based on user input.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-return-structured-output.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport { z } from \"zod\";\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\nconst responseFormat = z.object({\n    // Respond to the user in this format\n    mySpecialOutput: z.string(),\n})\n\nconst graph = createReactAgent({\n    llm: llm,\n    tools: tools,\n    // specify the schema for the structured output using `responseFormat` parameter\n    responseFormat: responseFormat\n})\n```\n\n----------------------------------------\n\nTITLE: Transforming Queries in Self-RAG Graph\nDESCRIPTION: This function improves the input question to optimize it for semantic search retrieval. It uses a language model to reformulate the question based on its underlying semantic intent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nasync function transformQuery(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---TRANSFORM QUERY---\");\n\n  // Pull in the prompt\n  const prompt = ChatPromptTemplate.fromTemplate(\n    `You are generating a question that is well optimized for semantic search retrieval.\n  Look at the input and try to reason about the underlying sematic intent / meaning.\n  Here is the initial question:\n  \\n ------- \\n\n  {question} \n  \\n ------- \\n\n  Formulate an improved question: `\n  );\n\n  // Construct the chain\n  const chain = prompt.pipe(model).pipe(new StringOutputParser());\n  const betterQuestion = await chain.invoke({ question: state.question });\n\n  return {\n    question: betterQuestion,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Tool Node Implementation with Closure in LangGraph.js\nDESCRIPTION: Shows how to implement a tool node that uses closures to access the latest message state when processing requests.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/pass-run-time-values-to-tools.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst toolNodeWithClosure = async (state: typeof MessagesAnnotation.State) => {\n  // We fetch the tools any time this node is reached to\n  // form a closure and let it access the latest messages\n  const tools = generateTools(state);\n  const toolNodeWithConfig = new ToolNode(tools);\n  return toolNodeWithConfig.invoke(state);\n};\n```\n\n----------------------------------------\n\nTITLE: Accessing Memories in Model Call\nDESCRIPTION: Demonstrates how to search and retrieve user memories within a node of the LangGraph execution. Retrieved memories are processed to create a structured input for a model's function call, showcasing the use of persistent user data in conversational models.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_14\n\nLANGUAGE: TypeScript\nCODE:\n```\nconst callModel = async (\n  state: typeof StateAnnotation.State,\n  config: LangGraphRunnableConfig\n) => {\n  const store = config.store;\n  const userId = config.configurable.user_id;\n  const memories = await store.search([userId, \"memories\"]);\n  const info = memories.map((memory) => {\n    return JSON.stringify(memory.value);\n  }).join(\"\\n\");\n\n  // ... Use memories in the model call\n}\n```\n\n----------------------------------------\n\nTITLE: Using Command with ends parameter in LangGraph\nDESCRIPTION: This code snippet demonstrates how to use the `Command` class in LangGraph to dynamically route between nodes without explicit edges. It shows how to define potential destination nodes using the `ends` parameter when adding a node to the graph, which is crucial for resolving UNREACHABLE_NODE errors when using `Command` instances.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/UNREACHABLE_NODE.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport { Annotation, Command } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n});\n\nconst nodeA = async (_state: typeof StateAnnotation.State) => {\n  const goto = Math.random() > .5 ? \"nodeB\" : \"nodeC\";\n  return new Command({\n    update: { foo: \"a\" },\n    goto,\n  });\n};\n\nconst nodeB = async (state: typeof StateAnnotation.State) => {\n  return {\n    foo: state.foo + \"|b\",\n  };\n}\n\nconst nodeC = async (state: typeof StateAnnotation.State) => {\n  return {\n    foo: state.foo + \"|c\",\n  };\n}\n\nimport { StateGraph } from \"@langchain/langgraph\";\n\n// NOTE: there are no edges between nodes A, B and C!\nconst graph = new StateGraph(StateAnnotation)\n  .addNode(\"nodeA\", nodeA, {\n    // Explicitly specify \"nodeB\" and \"nodeC\" as potential destinations for nodeA\n    ends: [\"nodeB\", \"nodeC\"],\n  })\n  .addNode(\"nodeB\", nodeB)\n  .addNode(\"nodeC\", nodeC)\n  .addEdge(\"__start__\", \"nodeA\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Authorization Handler for Resource Access Control in TypeScript\nDESCRIPTION: This code snippet shows how to implement an authorization handler using the LangGraph SDK. It adds metadata to resources during creation, filters resources during search/list operations, and ensures users can only access their own resources across all operations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/auth.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Auth, HTTPException } from \"@langchain/langgraph-sdk/auth\";\n\nexport const auth = new Auth()\n  .authenticate(async (request: Request) => ({\n    identity: \"user-123\",\n    permissions: [],\n  }))\n  .on(\"*\", ({ value, user }) => {\n    // Create filter to restrict access to just this user's resources\n    const filters = { owner: user.identity };\n\n    // If the operation supports metadata, add the user identity\n    // as metadata to the resource.\n    if (\"metadata\" in value) {\n      value.metadata ??= {};\n      value.metadata.owner = user.identity;\n    }\n\n    // Return filters to restrict access\n    // These filters are applied to ALL operations (create, read, update, search, etc.)\n    // to ensure users can only access their own resources\n    return filters;\n  });\n```\n\n----------------------------------------\n\nTITLE: Setting Up ReAct-style Agent with Tool Calling\nDESCRIPTION: This extensive code snippet sets up a more complex LangGraph example, implementing a ReAct-style agent with tool calling capabilities using Anthropic's model and a fake search tool.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Set up the tool\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { tool } from \"@langchain/core/tools\";\nimport { StateGraph, START, END, MessagesAnnotation } from \"@langchain/langgraph\";\nimport { MemorySaver } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport { AIMessage } from \"@langchain/core/messages\";\nimport { z } from \"zod\";\n\nconst search = tool((_) => {\n  return \"It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\";\n}, {\n  name: \"search\",\n  description: \"Call to surf the web.\",\n  schema: z.string(),\n})\n\nconst tools = [search]\nconst toolNode = new ToolNode(tools)\n\n// Set up the model\nconst model = new ChatAnthropic({ model: \"claude-3-5-sonnet-20240620\" })\nconst modelWithTools = model.bindTools(tools)\n\n\n// Define nodes and conditional edges\n\n// Define the function that determines whether to continue or not\nfunction shouldContinue(state: typeof MessagesAnnotation.State): \"action\" | typeof END {\n  const lastMessage = state.messages[state.messages.length - 1];\n  // If there is no function call, then we finish\n  if (lastMessage && !(lastMessage as AIMessage).tool_calls?.length) {\n      return END;\n  }\n  // Otherwise if there is, we continue\n  return \"action\";\n}\n\n// Define the function that calls the model\nasync function callModel(state: typeof MessagesAnnotation.State): Promise<Partial<typeof MessagesAnnotation.State>> {\n  const messages = state.messages;\n  const response = await modelWithTools.invoke(messages);\n  // We return an object with a messages property, because this will get added to the existing list\n  return { messages: [response] };\n}\n\n// Define a new graph\nconst workflow = new StateGraph(MessagesAnnotation)\n  // Define the two nodes we will cycle between\n  .addNode(\"agent\", callModel)\n  .addNode(\"action\", toolNode)\n  // We now add a conditional edge\n  .addConditionalEdges(\n      // First, we define the start node. We use `agent`.\n      // This means these are the edges taken after the `agent` node is called.\n      \"agent\",\n      // Next, we pass in the function that will determine which node is called next.\n      shouldContinue\n  )\n  // We now add a normal edge from `action` to `agent`.\n  // This means that after `action` is called, `agent` node is called next.\n  .addEdge(\"action\", \"agent\")\n  // Set the entrypoint as `agent`\n  // This means that this node is the first one called\n  .addEdge(START, \"agent\");\n\n// Setup memory\nconst memory = new MemorySaver();\n\n// Finally, we compile it!\n// This compiles it into a LangChain Runnable,\n// meaning you can use it as you would any other runnable\nconst app = workflow.compile({\n  checkpointer: memory,\n  interruptBefore: [\"action\"]\n});\n```\n\n----------------------------------------\n\nTITLE: Building a ReAct Style Agent with LangGraph\nDESCRIPTION: This TypeScript code builds a ReAct style agent using LangGraph. It sets up a StateGraph with nodes for model calls and tool actions, and defines the workflow for conversation management.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-conversation-history.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { tool } from \"@langchain/core/tools\";\nimport { BaseMessage, AIMessage } from \"@langchain/core/messages\";\nimport { StateGraph, Annotation, START, END } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport { MemorySaver } from \"@langchain/langgraph\";\nimport { z } from \"zod\";\n\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n\nconst memory = new MemorySaver();\n\nconst searchTool = tool((_): string => {\n    // This is a placeholder for the actual implementation\n    // Don't let the LLM know this though 😊\n    return \"It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\"\n}, {\n    name: \"search\",\n    description: \"Call to surf the web.\",\n    schema: z.object({\n        query: z.string()\n    })\n})\n\n\nconst tools = [searchTool]\nconst toolNode = new ToolNode<typeof AgentState.State>(tools)\nconst model = new ChatAnthropic({ model: \"claude-3-haiku-20240307\" })\nconst boundModel = model.bindTools(tools)\n\nfunction shouldContinue(state: typeof AgentState.State): \"action\" | typeof END {\n  const lastMessage = state.messages[state.messages.length - 1];\n  // If there is no function call, then we finish\n  if (lastMessage && !(lastMessage as AIMessage).tool_calls?.length) {\n      return END;\n  }\n  // Otherwise if there is, we continue\n  return \"action\";\n}\n\n// Define the function that calls the model\nasync function callModel(state: typeof AgentState.State) {\n  const response = await model.invoke(state.messages);\n  // We return an object, because this will get merged with the existing state\n  return { messages: [response] };\n}\n\n// Define a new graph\nconst workflow = new StateGraph(AgentState)\n    // Define the two nodes we will cycle between\n    .addNode(\"agent\", callModel)\n    .addNode(\"action\", toolNode)\n    // We now add a conditional edge\n    .addConditionalEdges(\n        // First, we define the start node. We use `agent`.\n        // This means these are the edges taken after the `agent` node is called.\n        \"agent\",\n        // Next, we pass in the function that will determine which node is called next.\n        shouldContinue\n    )\n    // We now add a normal edge from `action` to `agent`.\n    // This means that after `action` is called, `agent` node is called next.\n    .addEdge(\"action\", \"agent\")\n    // Set the entrypoint as `agent`\n    // This means that this node is the first one called\n    .addEdge(START, \"agent\");\n\n// Finally, we compile it!\n// This compiles it into a LangChain Runnable,\n// meaning you can use it as you would any other runnable\nconst app = workflow.compile({\n    checkpointer: memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Agent with Tool Integration in LangGraphJS\nDESCRIPTION: Utility function to create an agent that can use a set of tools. It constructs a prompt with system instructions for collaboration and tool usage, then binds OpenAI tools to the LLM.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  ChatPromptTemplate,\n  MessagesPlaceholder,\n} from \"@langchain/core/prompts\";\nimport { StructuredTool } from \"@langchain/core/tools\";\nimport { convertToOpenAITool } from \"@langchain/core/utils/function_calling\";\nimport { Runnable } from \"@langchain/core/runnables\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\n/**\n * Create an agent that can run a set of tools.\n */\nasync function createAgent({\n  llm,\n  tools,\n  systemMessage,\n}: {\n  llm: ChatOpenAI;\n  tools: StructuredTool[];\n  systemMessage: string;\n}): Promise<Runnable> {\n  const toolNames = tools.map((tool) => tool.name).join(\", \");\n  const formattedTools = tools.map((t) => convertToOpenAITool(t));\n\n  let prompt = ChatPromptTemplate.fromMessages([\n    [\n      \"system\",\n      \"You are a helpful AI assistant, collaborating with other assistants.\" +\n      \" Use the provided tools to progress towards answering the question.\" +\n      \" If you are unable to fully answer, that's OK, another assistant with different tools \" +\n      \" will help where you left off. Execute what you can to make progress.\" +\n      \" If you or any of the other assistants have the final answer or deliverable,\" +\n      \" prefix your response with FINAL ANSWER so the team knows to stop.\" +\n      \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n    ],\n    new MessagesPlaceholder(\"messages\"),\n  ]);\n  prompt = await prompt.partial({\n    system_message: systemMessage,\n    tool_names: toolNames,\n  });\n\n  return prompt.pipe(llm.bind({ tools: formattedTools }));\n}\n```\n\n----------------------------------------\n\nTITLE: Forking Actions in Langchain JavaScript\nDESCRIPTION: This snippet provides a method for forking past actions in a Langchain graph, allowing exploration of alternative paths. By updating the graph state with a specific 'checkpoint_id', a new forked checkpoint is created. This supports further execution paths from both current and past graph states. Dependencies include 'graph.updateState' and 'graph.stream'. Input configurations define 'thread_id' and 'checkpoint_id', while the output logs the events of the forked execution path.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = { configurable: { thread_id: \"1\", checkpoint_id: \"xxx\" } };\nawait graph.updateState(config, { state: \"updated state\" });\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = { configurable: { thread_id: '1', checkpoint_id: 'xxx-fork' }, streamMode: \"values\" as const };\nfor await (const event of await graph.stream(null, config)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Executing LangGraph Workflow with Streaming Output\nDESCRIPTION: Runs the compiled workflow graph by providing input parameters and configuration. Uses a streaming approach to process and display output from each node, with a custom prettifyOutput function to enhance log readability.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\nconst inputs = {\n  question: \"Explain how the different types of agent memory work.\"\n};\nconst config = { recursionLimit: 50 };\n\nconst prettifyOutput = (output: Record<string, any>) => {\n  const key = Object.keys(output)[0];\n  const value = output[key];\n  console.log(`Node: '${key}'`);\n  if (key === \"retrieve\" && \"documents\" in value) {\n    console.log(`Retrieved ${value.documents.length} documents.`);\n  } else if (key === \"gradeDocuments\" && \"documents\" in value) {\n    console.log(`Graded documents. Found ${value.documents.length} relevant document(s).`);\n  } else {\n    console.dir(value, { depth: null });\n  }\n}\n\nfor await (const output of await app.stream(inputs, config)) {\n  prettifyOutput(output);\n  console.log(\"\\n---ITERATION END---\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing the Graph with Mermaid\nDESCRIPTION: Code to render the graph visualization using Mermaid and display it as a PNG image in a Jupyter notebook environment with tslab.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst representation = graph.getGraph();\nconst image = await representation.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Creating a ReAct Agent with LangGraph.js and Anthropic\nDESCRIPTION: Example of creating a reactive agent using LangGraph.js prebuilt components with Claude model from Anthropic. The agent uses a search tool to respond to weather queries based on location.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/README.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// npm install @langchain-anthropic\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { tool } from \"@langchain/core/tools\";\n\nimport { z } from \"zod\";\n\nconst search = tool(async ({ query }) => {\n  if (query.toLowerCase().includes(\"sf\") || query.toLowerCase().includes(\"san francisco\")) {\n    return \"It's 60 degrees and foggy.\"\n  }\n  return \"It's 90 degrees and sunny.\"\n}, {\n  name: \"search\",\n  description: \"Call to surf the web.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n});\n\nconst model =  new ChatAnthropic({\n  model: \"claude-3-7-sonnet-latest\"\n});\n\nconst agent = createReactAgent({\n  llm: model,\n  tools: [search],\n});\n\nconst result = await agent.invoke(\n  {\n    messages: [{\n      role: \"user\",\n      content: \"what is the weather in sf\"\n    }]\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Command Usage for Subgraph Navigation in LangGraph\nDESCRIPTION: This snippet demonstrates how to use the `Command` object to navigate from a node within a subgraph to a different node in the parent graph. It defines a node `myNode` which updates the state and then directs the graph to a node (`other_subgraph`) in the parent graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/command.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst myNode = (state: typeof StateAnnotation.State) => {\n  return new Command({\n    update: { foo: \"bar\" },\n    goto: \"other_subgraph\", // where `other_subgraph` is a node in the parent graph\n    graph: Command.PARENT,\n  });\n};\n```\n\n----------------------------------------\n\nTITLE: Setting up API Keys for LangGraphJS Environment\nDESCRIPTION: Configuration code to set up necessary API keys for OpenAI, Tavily search, and optional LangSmith tracing for the hierarchical agent system.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n// process.env.TAVILY_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"sk_...\";\n// process.env.LANGCHAIN_TRACING_V2 = \"true\";\n// process.env.LANGCHAIN_PROJECT = \"Multi-agent Collaboration: LangGraphJS\";\n\n// Or use a dotenv file:\n// import \"dotenv/config\";\n```\n\n----------------------------------------\n\nTITLE: Implementing a Multi-Agent Swarm with LangGraph\nDESCRIPTION: TypeScript code demonstrating how to create a multi-agent swarm using LangGraph. It includes setting up agents, tools, and the swarm workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-swarm/README.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { tool } from \"@langchain/core/tools\";\nimport { MemorySaver } from \"@langchain/langgraph\";\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\nimport { createSwarm, createHandoffTool } from \"@langchain/langgraph-swarm\";\n\nconst model = new ChatOpenAI({ modelName: \"gpt-4o\" });\n\n// Create specialized tools\nconst add = tool(\n  async (args) => args.a + args.b,\n  {\n    name: \"add\",\n    description: \"Add two numbers.\",\n    schema: z.object({\n      a: z.number(),\n      b: z.number()\n    })\n  }\n);\n\n// Create agents with handoff tools\nconst alice = createReactAgent({\n  llm: model,\n  tools: [add, createHandoffTool({ agentName: \"Bob\" })],\n  name: \"Alice\",\n  prompt: \"You are Alice, an addition expert.\"\n});\n\nconst bob = createReactAgent({\n  llm: model,\n  tools: [createHandoffTool({ \n    agentName: \"Alice\", \n    description: \"Transfer to Alice, she can help with math\" \n  })],\n  name: \"Bob\",\n  prompt: \"You are Bob, you speak like a pirate.\"\n});\n\n// Create swarm workflow\nconst checkpointer = new MemorySaver();\nconst workflow = createSwarm({\n  agents: [alice, bob],\n  defaultActiveAgent: \"Alice\"\n});\n\nexport const app = workflow.compile({ \n  checkpointer \n});\n\nconst config = { configurable: { thread_id: \"1\" } };\nconst turn1 = await app.invoke(\n  { messages: [{ role: \"user\", content: \"i'd like to speak to Bob\" }] },\n  config\n);\nconsole.log(turn1);\n\nconst turn2 = await app.invoke(\n  { messages: [{ role: \"user\", content: \"what's 5 + 7?\" }] },\n  config\n);\nconsole.log(turn2);\n```\n\n----------------------------------------\n\nTITLE: JavaScript LangGraph Configuration File Example\nDESCRIPTION: Example of a langgraph.json configuration file for a JavaScript LangGraph application. Specifies dependencies from the local directory, a single graph from a specific file, and an inline environment variable.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/application_structure.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"dependencies\": [\n      \".\"\n    ],\n    \"graphs\": {\n      \"my_agent\": \"./your_package/your_file.js:agent\"\n    },\n    \"env\": {\n      \"OPENAI_API_KEY\": \"secret-key\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using messages in graph state with a reducer function - TypeScript\nDESCRIPTION: This snippet illustrates how to define a state annotation for managing messages in a graph state using the `messagesStateReducer` function. It specifically shows how to maintain a list of messages and properly update it based on state changes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { BaseMessage } from \"@langchain/core/messages\";\nimport { Annotation, type Messages } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  messages: Annotation<BaseMessage[], Messages>({\n    reducer: messagesStateReducer,\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Decision Logic with Anthropic Claude\nDESCRIPTION: Defines the agent's decision-making logic using Anthropic Claude LLM, including a routing function to determine whether to execute tools or end the agent workflow based on the LLM's response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/agent_executor/base.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { RunnableConfig } from \"@langchain/core/runnables\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { END } from \"@langchain/langgraph\";\n\n// Define the LLM to be used in the agent\nconst llm = new ChatAnthropic({\n  model: \"claude-3-5-sonnet-20240620\",\n  temperature: 0,\n}).bindTools(tools); // Ensure you bind the same tools passed to the ToolExecutor to the LLM, so these tools can be used in the agent\n\n// Define logic that will be used to determine which conditional edge to go down\nconst shouldContinue = (data: typeof AgentState.State): \"executeTools\" | typeof END => {\n  const { messages } = data;\n  const lastMsg = messages[messages.length - 1];\n  // If the agent called a tool, we should continue. If not, we can end.\n  if (!(\"tool_calls\" in lastMsg) || !Array.isArray(lastMsg.tool_calls) || !lastMsg?.tool_calls?.length) {\n    return END;\n  }\n  // By returning the name of the next node we want to go to\n  // LangGraph will automatically route to that node\n  return \"executeTools\";\n};\n\nconst callModel = async (data: typeof AgentState.State, config?: RunnableConfig): Promise<Partial<typeof AgentState.State>> => {\n  const { messages } = data;\n  const result = await llm.invoke(messages, config);\n  return {\n    messages: [result],\n  };\n};\n```\n\n----------------------------------------\n\nTITLE: Implementing the Solver Function for ReWOO Agent\nDESCRIPTION: Creates the solve function that represents the solver component of ReWOO. It formats the plan and results, creates a prompt to generate the final answer, and updates the state with the result.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst solvePrompt = ChatPromptTemplate.fromTemplate(\n  `Solve the following task or problem. To solve the problem, we have made step-by-step Plan and\nretrieved corresponding Evidence to each Plan. Use them with caution since long evidence might\ncontain irrelevant information.\n\n{plan}\n\nNow solve the question or task according to provided Evidence above. Respond with the answer\ndirectly with no extra words.\n\nTask: {task}\nResponse:`,\n);\n\nasync function solve(state: typeof GraphState.State, config?: RunnableConfig) {\n  console.log(\"---SOLVE---\");\n  let plan = \"\";\n  const _results = state.results || {};\n  for (let [_plan, stepName, tool, toolInput] of state.steps) {\n    for (const [k, v] of Object.entries(_results)) {\n      toolInput = toolInput.replace(k, v);\n    }\n    plan += `Plan: ${_plan}\\n${stepName} = ${tool}[${toolInput}]\\n`;\n  }\n  const model = new ChatOpenAI({\n    temperature: 0,\n    model: \"gpt-4o\",\n  });\n  const result = await solvePrompt\n    .pipe(model)\n    .invoke({ plan, task: state.task }, config);\n  return {\n    result: result.content.toString(),\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Decision Logic and Model Calling in LangGraphJS\nDESCRIPTION: This snippet defines functions for determining whether to continue processing or return results directly, and for calling the language model within the LangGraphJS workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamically-returning-directly.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RunnableConfig } from \"@langchain/core/runnables\";\nimport { END } from \"@langchain/langgraph\";\nimport { AIMessage } from \"@langchain/core/messages\";\n\n// Define the function that determines whether to continue or not\nconst shouldContinue = (state: typeof AgentState.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  // If there is no function call, then we finish\n  if (!lastMessage?.tool_calls?.length) {\n    return END;\n  } // Otherwise if there is, we check if it's suppose to return direct\n  else {\n    const args = lastMessage.tool_calls[0].args;\n    if (args?.return_direct) {\n      return \"final\";\n    } else {\n      return \"tools\";\n    }\n  }\n};\n\n// Define the function that calls the model\nconst callModel = async (state: typeof AgentState.State, config?: RunnableConfig) => {\n  const messages = state.messages;\n  const response = await boundModel.invoke(messages, config);\n  // We return an object, because this will get added to the existing list\n  return { messages: [response] };\n};\n```\n\n----------------------------------------\n\nTITLE: Defining State Management with Annotations in LangGraphJS\nDESCRIPTION: Configures the state object that passes between nodes in the graph. Uses Annotation to define message history with a concatenation reducer and sender tracking with a replacement reducer.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { Annotation } from \"@langchain/langgraph\";\n\n// This defines the object that is passed between each node\n// in the graph. We will create different nodes for each agent and tool\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n  sender: Annotation<string>({\n    reducer: (x, y) => y ?? x ?? \"user\",\n    default: () => \"user\",\n  }),\n})\n```\n\n----------------------------------------\n\nTITLE: Creating a Human Assistance Tool with Interrupt in LangGraph\nDESCRIPTION: Implementation of a tool that uses interrupt to request assistance from a human user during agent execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt } from \"@langchain/langgraph\";\nimport { z } from \"zod\";\n\nconst humanAssistance = tool(async ({ query }) => {\n  const humanResponse = interrupt({ query });\n  return humanResponse.data;\n}, {\n  name: \"humanAssistance\",\n  description: \"Request assistance from a human.\",\n  schema: z.object({\n    query: z.string().describe(\"Human readable question for the human\")\n  })\n});\n\nconst tools = [getWeather, humanAssistance];\n```\n\n----------------------------------------\n\nTITLE: Graph Construction and Workflow\nDESCRIPTION: Constructs the final workflow graph with nodes and edges for agent interaction.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/agent_supervisor.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport { START, StateGraph } from \"@langchain/langgraph\";\n\nconst workflow = new StateGraph(AgentState)\n  .addNode(\"researcher\", researcherNode)\n  .addNode(\"chart_generator\", chartGenNode)\n  .addNode(\"supervisor\", supervisorChain);\n\nmembers.forEach((member) => {\n  workflow.addEdge(member, \"supervisor\");\n});\n\nworkflow.addConditionalEdges(\n  \"supervisor\",\n  (x: typeof AgentState.State) => x.next,\n);\n\nworkflow.addEdge(START, \"supervisor\");\n\nconst graph = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing a ReAct Agent with ToolNode for Error Handling\nDESCRIPTION: Construction of a state graph using the LangGraphJS framework to implement a ReAct agent with tool calling capability. The implementation uses Anthropic's Claude model and the prebuilt ToolNode for handling tool execution errors.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling-errors.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph, MessagesAnnotation } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { BaseMessage, isAIMessage } from \"@langchain/core/messages\";\n\nconst toolNode = new ToolNode([getWeather]);\n\nconst modelWithTools = new ChatAnthropic({\n  model: \"claude-3-haiku-20240307\",\n  temperature: 0,\n}).bindTools([getWeather]);\n\nconst shouldContinue = async (state: typeof MessagesAnnotation.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1];\n  if (isAIMessage(lastMessage) && lastMessage.tool_calls?.length) {\n    return \"tools\";\n  }\n  return \"__end__\";\n}\n\nconst callModel = async (state: typeof MessagesAnnotation.State) => {\n  const { messages } = state;\n  const response = await modelWithTools.invoke(messages);\n  return { messages: [response] };\n}\n\nconst app = new StateGraph(MessagesAnnotation)\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  .addEdge(\"__start__\", \"agent\")\n  .addEdge(\"tools\", \"agent\")\n  .addConditionalEdges(\"agent\", shouldContinue, {\n    // Explicitly list possible destinations so that\n    // we can automatically draw the graph below.\n    tools: \"tools\",\n    __end__: \"__end__\",\n  })\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Compiling Persistent Workflow in LangGraphJS\nDESCRIPTION: This snippet illustrates the compilation of a workflow with a memory-saving checkpointer to persist conversation states across sessions. It involves using the MemorySaver from '@langchain/langgraph' for maintaining in-memory checkpoints in LangGraphJS.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport { MemorySaver } from \"@langchain/langgraph\";\n\n// Here we only save in-memory\nconst memory = new MemorySaver();\nconst persistentGraph = workflow.compile({ checkpointer: memory });\n```\n\n----------------------------------------\n\nTITLE: Using the Agent with Taylor Swift's User ID - Python\nDESCRIPTION: Another example of invoking the agent, this time with Taylor Swift's user ID to demonstrate how the agent provides different recommendations based on the user's location.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/update-state-from-tools.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nconst taylorStream = await agent.stream({\n  messages: [{\n    role: \"user\",\n    content: \"hi, what should i do this weekend?\",\n  }],\n  \n}, {\n  // provide user ID in the config\n  configurable: { user_id: \"zyx987\" }\n});\n\nfor await (const chunk of taylorStream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Execution Function for ReWOO Worker\nDESCRIPTION: Creates the toolExecution function that handles the worker component of ReWOO. It determines the current step, performs variable substitution, executes the appropriate tool (Google search or LLM), and updates the state with the results.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst _getCurrentTask = (state: typeof GraphState.State) => {\n  console.log(\"_getCurrentTask\", state);\n  if (!state.results) {\n    return 1;\n  }\n  if (Object.entries(state.results).length === state.steps.length) {\n    return null;\n  }\n  return Object.entries(state.results).length + 1;\n};\n\nconst _parseResult = (input: unknown) => {\n  if (typeof input === \"string\") {\n    const parsedInput = JSON.parse(input);\n    if (Array.isArray(parsedInput) && \"content\" in parsedInput[0]) {\n      // This means it is a tool result.\n      return parsedInput.map(({ content }) => content).join(\"\\n\");\n    }\n  }\n\n  if (input && typeof input === \"object\" && \"content\" in input) {\n    // If it's not a tool, we know it's an LLM result.\n    const { content } = input;\n    return content;\n  }\n  throw new Error(\"Invalid input received\");\n};\n\nasync function toolExecution(state: typeof GraphState.State, config?: RunnableConfig) {\n  console.log(\"---EXECUTE TOOL---\");\n  const _step = _getCurrentTask(state);\n  if (_step === null) {\n    throw new Error(\"No current task found\");\n  }\n  const [_, stepName, tool, toolInputTemplate] = state.steps[_step - 1];\n  let toolInput = toolInputTemplate;\n  const _results = state.results || {};\n  for (const [k, v] of Object.entries(_results)) {\n    toolInput = toolInput.replace(k, v);\n  }\n  let result;\n  if (tool === \"Google\") {\n    result = await search.invoke(toolInput, config);\n  } else if (tool === \"LLM\") {\n    result = await model.invoke(toolInput, config);\n  } else {\n    throw new Error(\"Invalid tool specified\");\n  }\n  _results[stepName] = JSON.stringify(_parseResult(result), null, 2);\n  return { results: _results };\n}\n```\n\n----------------------------------------\n\nTITLE: Reducer Functions in LangGraph State Management with TypeScript\nDESCRIPTION: Explains the mechanism of reducers in LangGraph for updating state keys. The snippet displays how reducer functions concatenate updates to existing state values, allowing nodes to provide partial updates.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\nconst State = Annotation.Root({\n  foo: Annotation<number>,\n  bar: Annotation<string[]>({\n    reducer: (state: string[], update: string[]) => state.concat(update),\n    default: () => [],\n  }),\n});\n\nconst graphBuilder = new StateGraph(State);\n```\n\n----------------------------------------\n\nTITLE: Setting Static Breakpoints at Compile Time in TypeScript\nDESCRIPTION: Demonstrates how to set static breakpoints before and after node execution at compile time, run the graph until a breakpoint, update the graph state, and resume execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/breakpoints.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst graph = graphBuilder.compile({\n    interruptBefore: [\"nodeA\"],\n    interruptAfter: [\"nodeB\", \"nodeC\"],\n    checkpointer: ..., // Specify a checkpointer\n});\n\nconst threadConfig = {\n    configurable: {\n        thread_id: \"someThread\"\n    }\n};\n\n// Run the graph until the breakpoint\nawait graph.invoke(inputs, threadConfig);\n\n// Optionally update the graph state based on user input\nawait graph.updateState(update, threadConfig);\n\n// Resume the graph\nawait graph.invoke(null, threadConfig);\n```\n\n----------------------------------------\n\nTITLE: Running Workflow without Checkpointer in LangChain\nDESCRIPTION: This snippet demonstrates executing a graph workflow in LangChain without persistence, emulating a user conversation and handling input streams of messages. It prints out content or tool calls from the processed messages. Requires the compiled graph from StateGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nlet inputs = { messages: [{ role: \"user\", content: \"Hi I'm Yu, nice to meet you.\" }] };\nfor await (\n  const { messages } of await graph.stream(inputs, {\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n\ninputs = { messages: [{ role: \"user\", content: \"Remember my name?\" }] };\nfor await (\n  const { messages } of await graph.stream(inputs, {\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Document Retriever with Vector Store\nDESCRIPTION: Sets up a document retriever by loading web content, splitting into chunks, and creating a vector store with OpenAI embeddings\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_crag.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { CheerioWebBaseLoader } from \"@langchain/community/document_loaders/web/cheerio\";\nimport { RecursiveCharacterTextSplitter } from \"@langchain/textsplitters\";\nimport { MemoryVectorStore } from \"langchain/vectorstores/memory\";\nimport { OpenAIEmbeddings } from \"@langchain/openai\";\n\nconst urls = [\n  \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n  \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n  \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n];\n\nconst docs = await Promise.all(\n  urls.map((url) => new CheerioWebBaseLoader(url).load()),\n);\nconst docsList = docs.flat();\n\nconst textSplitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 250,\n  chunkOverlap: 0,\n});\nconst docSplits = await textSplitter.splitDocuments(docsList);\n\n// Add to vectorDB\nconst vectorStore = await MemoryVectorStore.fromDocuments(\n  docSplits,\n  new OpenAIEmbeddings(),\n);\nconst retriever = vectorStore.asRetriever();\n```\n\n----------------------------------------\n\nTITLE: Building the Authoring Graph in LangGraph.js\nDESCRIPTION: This code creates a state graph named `authoringGraph` using `StateGraph` and adds nodes for 'DocWriter', 'NoteTaker', 'ChartGenerator', and 'supervisor'. It defines edges to control the flow of the program. Conditional edges are added to route the graph based on the supervisor's decision.  The graph starts at the START node and proceeds to the supervisor.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: javascript\nCODE:\n```\n// Create the graph here:\nconst authoringGraph = new StateGraph(DocWritingState)\n  .addNode(\"DocWriter\", docWritingNode)\n  .addNode(\"NoteTaker\", noteTakingNode)\n  .addNode(\"ChartGenerator\", chartGeneratingNode)\n  .addNode(\"supervisor\", docWritingSupervisor)\n  // Add the edges that always occur\n  .addEdge(\"DocWriter\", \"supervisor\")\n  .addEdge(\"NoteTaker\", \"supervisor\")\n  .addEdge(\"ChartGenerator\", \"supervisor\")\n  // Add the edges where routing applies\n  .addConditionalEdges(\"supervisor\", (x) => x.next, {{\n    DocWriter: \"DocWriter\",\n    NoteTaker: \"NoteTaker\",\n    ChartGenerator: \"ChartGenerator\",\n    FINISH: END,\n  }})\n  .addEdge(START, \"supervisor\");\n\nconst enterAuthoringChain = RunnableLambda.from(\n  (({ messages }: {{ messages: BaseMessage[] }}) => {{\n    return {{\n      messages: messages,\n      team_members: [\"Doc Writer\", \"Note Taker\", \"Chart Generator\"],\n    }};\n  }},\n);\nconst authoringChain = enterAuthoringChain.pipe(authoringGraph.compile());\n```\n\n----------------------------------------\n\nTITLE: Implementing Dynamic Breakpoints with NodeInterrupt in TypeScript\nDESCRIPTION: Illustrates how to create a dynamic breakpoint using the NodeInterrupt error, which triggers when a specific condition is met during node execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/breakpoints.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nfunction myNode(state: typeof GraphAnnotation.State) {\n    if (state.input.length > 5) {\n        throw new NodeInterrupt(`Received input that is longer than 5 characters: ${state.input}`);\n    }\n    return state;\n}\n```\n\n----------------------------------------\n\nTITLE: Running LangGraph for a different user to verify memory isolation\nDESCRIPTION: Executes the LangGraph for User 2 to demonstrate that memories are isolated between users in the cross-thread persistence setup.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nconfig = { configurable: { thread_id: \"3\", userId: \"2\" } };\ninputMessage = { type: \"user\", content: \"what is my name?\" };\n\nfor await (const chunk of await graph.stream(\n  { messages: [inputMessage] },\n  { ...config, streamMode: \"values\" }\n)) {\n  console.log(chunk.messages[chunk.messages.length - 1]);\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Langchain and Dependencies\nDESCRIPTION: This command installs the required Langchain libraries to set up and interact with chat models in a directed graph structure. It requires npm to be installed on the system.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-from-final-node.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Storing and Retrieving Memories using InMemoryStore in LangGraph\nDESCRIPTION: This code snippet demonstrates how to store and retrieve memories using LangGraph's InMemoryStore. It initializes an InMemoryStore, saves data under a specific namespace and key, retrieves the data by key, and searches for memories within the namespace using content filters. InMemoryStore is used here but in production a database-backed store should be used.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/memory.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\n// InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.\nconst store = new InMemoryStore();\nconst userId = \"my-user\";\nconst applicationContext = \"chitchat\";\nconst namespace = [userId, applicationContext];\nawait store.put(namespace, \"a-memory\", {\n  rules: [\n    \"User likes short, direct language\",\n    \"User only speaks English & TypeScript\",\n  ],\n  \"my-key\": \"my-value\",\n});\n// get the \"memory\" by ID\nconst item = await store.get(namespace, \"a-memory\");\n// list \"memories\" within this namespace, filtering on content equivalence\nconst items = await store.search(namespace, {\n  filter: { \"my-key\": \"my-value\" },\n});\n```\n\n----------------------------------------\n\nTITLE: Answer Grader Implementation\nDESCRIPTION: Implementation of a grading system to evaluate the relevancy and usefulness of final answers.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nconst ANSWER_GRADER_PROMPT_TEMPLATE =\n  `You are a grader assessing whether an answer is useful to resolve a question.\nHere is the answer:\n\n<answer>\n{generation} \n</answer>\n\nHere is the question:\n\n<question>\n{question}\n</question>\n\nGive a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question.\nProvide the binary score as a JSON with a single key 'score' and no preamble or explanation.`;\n\nconst answerGraderPrompt = ChatPromptTemplate.fromTemplate(\n  ANSWER_GRADER_PROMPT_TEMPLATE,\n);\n\nconst answerGrader = answerGraderPrompt.pipe(jsonModeLlm).pipe(\n  new JsonOutputParser(),\n);\n\nconst generation3 = await ragChain.invoke({\n  context: formatDocs(docs3),\n  question: testQuestion2,\n});\n\nawait answerGrader.invoke({ question: testQuestion2, generation: generation3 });\n```\n\n----------------------------------------\n\nTITLE: Acting as Entire Subgraph in Graph Execution in JavaScript\nDESCRIPTION: This snippet demonstrates how to act as the entire subgraph during graph execution. It runs the graph, interrupts it, updates the state as the entire weather subgraph, and then resumes execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_20\n\nLANGUAGE: javascript\nCODE:\n```\nconst entireSubgraphExampleStream = await graph.stream({\n  messages: [\n    {\n      role: \"user\",\n      content: \"what's the weather in sf\"\n    }\n  ],\n}, {\n  configurable: {\n    thread_id: \"8\",\n  },\n  streamMode: \"updates\",\n  subgraphs: true,\n});\n\nfor await (const update of entireSubgraphExampleStream) {\n  console.log(update);\n}\n\nconsole.log(\"interrupted!\");\n\nawait graph.updateState({\n  configurable: {\n    thread_id: \"8\",\n  }\n}, {\n  messages: [{ role: \"assistant\", content: \"rainy\" }]\n}, \"weatherGraph\");\n\nconst resumedEntireSubgraphExampleStream = await graph.stream(null, {\n  configurable: {\n    thread_id: \"8\",\n  },\n  streamMode: \"updates\",\n});\n\nfor await (const update of resumedEntireSubgraphExampleStream) {\n  console.log(update);\n}\n\nconst currentStateAfterUpdate = await graph.getState({\n  configurable: {\n    thread_id: \"8\",\n  }\n});\n\nconsole.log(currentStateAfterUpdate.values.messages);\n```\n\n----------------------------------------\n\nTITLE: Implementing Prompt Chaining with Graph API\nDESCRIPTION: Implementation of a prompt chaining workflow using LangGraph's Graph API. Creates a joke generator that processes a joke through multiple enhancement steps with a quality gate to ensure jokes have punchlines.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\n// Graph state\nconst StateAnnotation = Annotation.Root({\n  topic: Annotation<string>,\n  joke: Annotation<string>,\n  improvedJoke: Annotation<string>,\n  finalJoke: Annotation<string>,\n});\n\n// Define node functions\n\n// First LLM call to generate initial joke\nasync function generateJoke(state: typeof StateAnnotation.State) {\n  const msg = await llm.invoke(`Write a short joke about ${state.topic}`);\n  return { joke: msg.content };\n}\n\n// Gate function to check if the joke has a punchline\nfunction checkPunchline(state: typeof StateAnnotation.State) {\n  // Simple check - does the joke contain \"?\" or \"!\"\n  if (state.joke?.includes(\"?\") || state.joke?.includes(\"!\")) {\n    return \"Pass\";\n  }\n  return \"Fail\";\n}\n\n  // Second LLM call to improve the joke\nasync function improveJoke(state: typeof StateAnnotation.State) {\n  const msg = await llm.invoke(\n    `Make this joke funnier by adding wordplay: ${state.joke}`\n  );\n  return { improvedJoke: msg.content };\n}\n\n// Third LLM call for final polish\nasync function polishJoke(state: typeof StateAnnotation.State) {\n  const msg = await llm.invoke(\n    `Add a surprising twist to this joke: ${state.improvedJoke}`\n  );\n  return { finalJoke: msg.content };\n}\n\n// Build workflow\nconst chain = new StateGraph(StateAnnotation)\n  .addNode(\"generateJoke\", generateJoke)\n  .addNode(\"improveJoke\", improveJoke)\n  .addNode(\"polishJoke\", polishJoke)\n  .addEdge(\"__start__\", \"generateJoke\")\n  .addConditionalEdges(\"generateJoke\", checkPunchline, {\n    Pass: \"improveJoke\",\n    Fail: \"__end__\"\n  })\n  .addEdge(\"improveJoke\", \"polishJoke\")\n  .addEdge(\"polishJoke\", \"__end__\")\n  .compile();\n\n// Invoke\nconst state = await chain.invoke({ topic: \"cats\" });\nconsole.log(\"Initial joke:\");\nconsole.log(state.joke);\nconsole.log(\"\\n--- --- ---\\n\");\nif (state.improvedJoke !== undefined) {\n  console.log(\"Improved joke:\");\n  console.log(state.improvedJoke);\n  console.log(\"\\n--- --- ---\\n\");\n\n  console.log(\"Final joke:\");\n  console.log(state.finalJoke);\n} else {\n  console.log(\"Joke failed quality gate - no punchline detected!\");\n}\n```\n\n----------------------------------------\n\nTITLE: Instantiating Travel Advisors in TypeScript\nDESCRIPTION: This snippet shows the instantiation of three agents for a travel advisory system, each with distinct prompts and routing capabilities. It creates interconnected agents - travel advisor, sightseeing advisor, and hotel advisor, capable of resolving user queries through mutual communication.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst travelAdvisor = makeAgentNode({\n  name: \"travel_advisor\",\n  destinations: [\"sightseeing_advisor\", \"hotel_advisor\"],\n  systemPrompt: [\n    \"You are a general travel expert that can recommend travel destinations (e.g. countries, cities, etc). \",\n    \"If you need specific sightseeing recommendations, ask 'sightseeing_advisor' for help. \",\n    \"If you need hotel recommendations, ask 'hotel_advisor' for help. \",\n    \"If you have enough information to respond to the user, return '__end__'. \",\n    \"Never mention other agents by name.\"\n  ].join(\"\"),\n});\n\nconst sightseeingAdvisor = makeAgentNode({\n  name: \"sightseeing_advisor\",\n  destinations: [\"travel_advisor\", \"hotel_advisor\"],\n  systemPrompt: [\n    \"You are a travel expert that can provide specific sightseeing recommendations for a given destination. \",\n    \"If you need general travel help, go to 'travel_advisor' for help. \",\n    \"If you need hotel recommendations, go to 'hotel_advisor' for help. \",\n    \"If you have enough information to respond to the user, return 'finish'. \",\n    \"Never mention other agents by name.\"\n  ].join(\"\"),\n});\n\nconst hotelAdvisor = makeAgentNode({\n  name: \"hotel_advisor\",\n  destinations: [\"travel_advisor\", \"sightseeing_advisor\"],\n  systemPrompt: [\n    \"You are a booking expert that provides hotel recommendations for a given destination. \",\n    \"If you need general travel help, ask 'travel_advisor' for help. \",\n    \"If you need specific sightseeing recommendations, ask 'sightseeing_advisor' for help. \",\n    \"If you have enough information to respond to the user, return 'finish'. \",\n    \"Never mention other agents by name.\",\n  ].join(\"\"),\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Functional API Workflow with Langchain in TypeScript\nDESCRIPTION: This code snippet demonstrates the creation of an evaluator-optimizer workflow using Langchain's Functional API. It sets up schema-based tasks for generating and evaluating jokes, implements a loop to refine outputs based on feedback, and streams updates until a satisfactory joke is generated.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_13\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { z } from \"zod\";\nimport { task, entrypoint } from \"@langchain/langgraph\";\n\n// Schema for structured output to use in evaluation\nconst feedbackSchema = z.object({\n  grade: z.enum([\"funny\", \"not funny\"]).describe(\n    \"Decide if the joke is funny or not.\"\n  ),\n  feedback: z.string().describe(\n    \"If the joke is not funny, provide feedback on how to improve it.\"\n  ),\n});\n\n// Augment the LLM with schema for structured output\nevaluator = llm.withStructuredOutput(feedbackSchema);\n\n// Tasks\nconst llmCallGenerator = task(\"jokeGenerator\", async (params: {\n  topic: string;\n  feedback?: z.infer<typeof feedbackSchema>;\n}) => {\n  // LLM generates a joke\n  const msg = params.feedback\n    ? await llm.invoke(\n        `Write a joke about ${params.topic} but take into account the feedback: ${params.feedback.feedback}`\n      )\n    : await llm.invoke(`Write a joke about ${params.topic}`);\n  return msg.content;\n});\n\nconst llmCallEvaluator = task(\"jokeEvaluator\", async (joke: string) => {\n  // LLM evaluates the joke\n  return evaluator.invoke(`Grade the joke ${joke}`);\n});\n\n// Build workflow\nconst workflow = entrypoint(\n  \"optimizerWorkflow\",\n  async (topic: string) => {\n    let feedback: z.infer<typeof feedbackSchema> | undefined;\n    let joke: string;\n\n    while (true) {\n      joke = await llmCallGenerator({ topic, feedback });\n      feedback = await llmCallEvaluator(joke);\n\n      if (feedback.grade === \"funny\") {\n        break;\n      }\n    }\n\n    return joke;\n  }\n);\n\n// Invoke\nconst stream = await workflow.stream(\"Cats\", {\n  streamMode: \"updates\",\n});\n\nfor await (const step of stream) {\n  console.log(step);\n  console.log(\"\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a StateGraph with LangGraph in JavaScript\nDESCRIPTION: Builds a StateGraph using LangGraph, mapping out nodes and conditional edges for processing messages. It includes logic for processing agent messages and tool invocations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-values.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\nimport { AIMessage } from \"@langchain/core/messages\";\n\nconst routeMessage = (state: typeof StateAnnotation.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  // If no tools are called, we can finish (respond to the user)\n  if (!lastMessage?.tool_calls?.length) {\n    return END;\n  }\n  // Otherwise if there is, we continue and call the tools\n  return \"tools\";\n};\n\nconst callModel = async (\n  state: typeof StateAnnotation.State,\n) => {\n  // For versions of @langchain/core < 0.2.3, you must call `.stream()`\n  // and aggregate the message from chunks instead of calling `.invoke()`.\n  const { messages } = state;\n  const responseMessage = await boundModel.invoke(messages);\n  return { messages: [responseMessage] };\n};\n\nconst workflow = new StateGraph(StateAnnotation)\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  .addEdge(START, \"agent\")\n  .addConditionalEdges(\"agent\", routeMessage)\n  .addEdge(\"tools\", \"agent\");\n\nconst graph = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Updating Graph State in LangGraphJS\nDESCRIPTION: This code snippet updates the state of the LangGraphJS graph by setting `refundAuthorized` to `true` for a given `thread_id`.  After updating the state, it resumes the graph's execution by calling `graph.stream()` with `null` input and the same `thread_id`. The output from the resumed execution is then logged to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nawait graph.updateState({ configurable: { thread_id: \"refund_testing_id\" } }, {\n  refundAuthorized: true,\n});\n\nconst resumedStream = await graph.stream(null, { configurable: { thread_id: \"refund_testing_id\" }});\n\nfor await (const value of resumedStream) {\n  console.log(value);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating the Prompt Template for the ReWOO Planner in TypeScript\nDESCRIPTION: Defines a chat prompt template that instructs the LLM to create a step-by-step plan using tools like Google search and LLM reasoning, with variable substitution to pass information between steps.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatPromptTemplate } from \"@langchain/core/prompts\";\n\nconst template =\n  `For the following task, make plans that can solve the problem step by step. For each plan, indicate\nwhich external tool together with tool input to retrieve evidence. You can store the evidence into a \nvariable #E that can be called by later tools. (Plan, #E1, Plan, #E2, Plan, ...)\n\nTools can be one of the following:\n(1) Google[input]: Worker that searches results from Google. Useful when you need to find short\nand succinct answers about a specific topic. The input should be a search query.\n(2) LLM[input]: A pre-trained LLM like yourself. Useful when you need to act with general \nworld knowledge and common sense. Prioritize it when you are confident in solving the problem\nyourself. Input can be any instruction.\n\nFor example,\nTask: Thomas, Toby, and Rebecca worked a total of 157 hours in one week. Thomas worked x \nhours. Toby worked 10 hours less than twice what Thomas worked, and Rebecca worked 8 hours \nless than Toby. How many hours did Rebecca work? \nPlan: Given Thomas worked x hours, translate the problem into algebraic expressions and solve with Wolfram Alpha.\n#E1 = WolframAlpha[Solve x + (2x - 10) + ((2x - 10) - 8) = 157]\nPlan: Find out the number of hours Thomas worked.\n#E2 = LLM[What is x, given #E1]\nPlan: Calculate the number of hours Rebecca worked.\n#E3 = Calculator[(2 * #E2 - 10) - 8]\n\nImportant!\nVariables/results MUST be referenced using the # symbol!\nThe plan will be executed as a program, so no coreference resolution apart from naive variable replacement is allowed.\nThe ONLY way for steps to share context is by including #E<step> within the arguments of the tool.\n\nBegin! \nDescribe your plans with rich details. Each Plan should be followed by only one #E.\n\nTask: {task}`;\n\nconst promptTemplate = ChatPromptTemplate.fromMessages([[\"human\", template]]);\n\nconst planner = promptTemplate.pipe(model);\n\nconst task = \"what is the hometown of the winner of the 2023 australian open?\";\nawait planner.invoke({ task });\n```\n\n----------------------------------------\n\nTITLE: Building a Chatbot with Conversation Summarization\nDESCRIPTION: Implementing a chatbot using LangGraph that automatically summarizes conversation history when it exceeds a certain length. The code defines the state structure, model interaction logic, and decision-making for when to summarize conversations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { SystemMessage, HumanMessage, AIMessage, RemoveMessage } from \"@langchain/core/messages\";\nimport { MemorySaver } from \"@langchain/langgraph-checkpoint\";\nimport { MessagesAnnotation, StateGraph, START, END, Annotation } from \"@langchain/langgraph\";\nimport { v4 as uuidv4 } from \"uuid\";\n\nconst memory = new MemorySaver();\n\n// We will add a `summary` attribute (in addition to `messages` key,\n// which MessagesAnnotation already has)\nconst GraphAnnotation = Annotation.Root({\n  ...MessagesAnnotation.spec,\n  summary: Annotation<string>({\n    reducer: (_, action) => action,\n    default: () => \"\",\n  })\n})\n\n// We will use this model for both the conversation and the summarization\nconst model = new ChatAnthropic({ model: \"claude-3-haiku-20240307\" });\n\n// Define the logic to call the model\nasync function callModel(state: typeof GraphAnnotation.State): Promise<Partial<typeof GraphAnnotation.State>> {\n  // If a summary exists, we add this in as a system message\n  const { summary } = state;\n  let { messages } = state;\n  if (summary) {\n    const systemMessage = new SystemMessage({\n      id: uuidv4(),\n      content: `Summary of conversation earlier: ${summary}`\n    });\n    messages = [systemMessage, ...messages];\n  }\n  const response = await model.invoke(messages);\n  // We return an object, because this will get added to the existing state\n  return { messages: [response] };\n}\n\n// We now define the logic for determining whether to end or summarize the conversation\nfunction shouldContinue(state: typeof GraphAnnotation.State): \"summarize_conversation\" | typeof END {\n  const messages = state.messages;\n  // If there are more than six messages, then we summarize the conversation\n  if (messages.length > 6) {\n    return \"summarize_conversation\";\n  }\n  // Otherwise we can just end\n  return END;\n}\n\nasync function summarizeConversation(state: typeof GraphAnnotation.State): Promise<Partial<typeof GraphAnnotation.State>> {\n  // First, we summarize the conversation\n  const { summary, messages } = state;\n  let summaryMessage: string;\n  if (summary) {\n    // If a summary already exists, we use a different system prompt\n    // to summarize it than if one didn't\n    summaryMessage = `This is summary of the conversation to date: ${summary}\\n\\n` +\n      \"Extend the summary by taking into account the new messages above:\";\n  } else {\n    summaryMessage = \"Create a summary of the conversation above:\";\n  }\n\n  const allMessages = [...messages, new HumanMessage({\n    id: uuidv4(),\n    content: summaryMessage,\n  })];\n  const response = await model.invoke(allMessages);\n  // We now need to delete messages that we no longer want to show up\n  // I will delete all but the last two messages, but you can change this\n  const deleteMessages = messages.slice(0, -2).map((m) => new RemoveMessage({ id: m.id }));\n  if (typeof response.content !== \"string\") {\n    throw new Error(\"Expected a string response from the model\");\n  }\n  return { summary: response.content, messages: deleteMessages };\n}\n\n// Define a new graph\nconst workflow = new StateGraph(GraphAnnotation)\n  // Define the conversation node and the summarize node\n  .addNode(\"conversation\", callModel)\n  .addNode(\"summarize_conversation\", summarizeConversation)\n  // Set the entrypoint as conversation\n  .addEdge(START, \"conversation\")\n  // We now add a conditional edge\n  .addConditionalEdges(\n    // First, we define the start node. We use `conversation`.\n    // This means these are the edges taken after the `conversation` node is called.\n    \"conversation\",\n    // Next, we pass in the function that will determine which node is called next.\n    shouldContinue\n  )\n  // We now add a normal edge from `summarize_conversation` to END.\n  // This means that after `summarize_conversation` is called, we end.\n  .addEdge(\"summarize_conversation\", END);\n\n// Finally, we compile it!\nconst app = workflow.compile({ checkpointer: memory });\n```\n\n----------------------------------------\n\nTITLE: Defining Tools for LangGraph Agent in TypeScript\nDESCRIPTION: This code demonstrates how to define arithmetic tools (multiply, add, divide) using the tool function from LangChain Core. It shows the creation and binding of tools to an LLM for use in an agent workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_14\n\nLANGUAGE: ts\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\n// Define tools\nconst multiply = tool(\n  async ({ a, b }: { a: number; b: number }) => {\n    return a * b;\n  },\n  {\n    name: \"multiply\",\n    description: \"Multiply two numbers together\",\n    schema: z.object({\n      a: z.number().describe(\"first number\"),\n      b: z.number().describe(\"second number\"),\n    }),\n  }\n);\n\nconst add = tool(\n  async ({ a, b }: { a: number; b: number }) => {\n    return a + b;\n  },\n  {\n    name: \"add\",\n    description: \"Add two numbers together\",\n    schema: z.object({\n      a: z.number().describe(\"first number\"),\n      b: z.number().describe(\"second number\"),\n    }),\n  }\n);\n\nconst divide = tool(\n  async ({ a, b }: { a: number; b: number }) => {\n    return a / b;\n  },\n  {\n    name: \"divide\",\n    description: \"Divide two numbers\",\n    schema: z.object({\n      a: z.number().describe(\"first number\"),\n      b: z.number().describe(\"second number\"),\n    }),\n  }\n);\n\n// Augment the LLM with tools\nconst tools = [add, multiply, divide];\nconst toolsByName = Object.fromEntries(tools.map((tool) => [tool.name, tool]));\nconst llmWithTools = llm.bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: Registering General Auth and Resource Handlers - TypeScript\nDESCRIPTION: This snippet illustrates the setup of a general authentication handler along with resource-specific handlers for threads and assistants. It checks user permissions before allowing actions and logs requests.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/auth.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Auth, HTTPException } from \"@langchain/langgraph-sdk/auth\";\n\nexport const auth = new Auth()\n  .authenticate(async (request: Request) => ({\n    identity: \"user-123\",\n    permissions: [\"threads:write\", \"threads:read\"],\n  }))\n  .on(\"*\", ({ event, user }) => {\n    console.log(`Request for ${event} by ${user.identity}`);\n    throw new HTTPException(403, { message: \"Forbidden\" });\n  })\n  .on(\"threads\", ({ permissions, value, user }) => {\n    if (!permissions.includes(\"write\")) {\n      throw new HTTPException(403, {\n        message: \"User lacks the required permissions.\",\n      });\n    }\n    if (\"metadata\" in value) {\n      value.metadata ??= {};\n      value.metadata.owner = user.identity;\n    }\n    return { owner: user.identity };\n  })\n  .on(\"threads:create\", ({ value, user, permissions }) => {\n    if (!permissions.includes(\"write\")) {\n      throw new HTTPException(403, {\n        message: \"User lacks the required permissions.\",\n      });\n    }\n    value.metadata ??= {};\n    value.metadata.owner = user.identity;\n    return { owner: user.identity };\n  })\n  .on(\"threads:read\", ({ user }) => {\n    return { owner: user.identity };\n  })\n  .on(\"threads:create_run\", ({ value, user }) => {\n    value.metadata ??= {};\n    value.metadata.owner = user.identity;\n    return { owner: user.identity };\n  })\n  .on(\"assistants:create\", ({ value, user, permissions }) => {\n    if (!permissions.includes(\"assistants:create\")) {\n      throw new HTTPException(403, {\n        message: \"User lacks the required permissions.\",\n      });\n    }\n    value.metadata ??= {};\n    value.metadata.owner = user.identity;\n    return { owner: user.identity };\n  });\n```\n\n----------------------------------------\n\nTITLE: Entrypoint for Multi-Agent Network - TypeScript\nDESCRIPTION: This snippet sets up the main entry point for the multi-agent network, which continuously calls active agents and processes messages to facilitate agent communication and transitions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst networkGraph = entrypoint(\n  { name: \"networkGraph\" },\n  async (messages: BaseMessageLike[]) => {\n    let callActiveAgent = callTravelAdvisor;\n    let agentMessages;\n    while (true) {\n      agentMessages = await callActiveAgent(messages);\n      messages = addMessages(messages, agentMessages);\n      callActiveAgent = getNextAgent(messages);\n    }\n    return messages;\n  });\n```\n\n----------------------------------------\n\nTITLE: Composing Research Team Graph in TypeScript\nDESCRIPTION: Creates a state graph for the research team, defining nodes for search, web scraping, and supervisor agents. It sets up the control flow and compiles the graph into a runnable chain.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\n\nconst researchGraph = new StateGraph(ResearchTeamState)\n  .addNode(\"Search\", searchNode)\n  .addNode(\"supervisor\", supervisorAgent)\n  .addNode(\"WebScraper\", researchNode)\n  // Define the control flow\n  .addEdge(\"Search\", \"supervisor\")\n  .addEdge(\"WebScraper\", \"supervisor\")\n  .addConditionalEdges(\"supervisor\", (x) => x.next, {\n    Search: \"Search\",\n    WebScraper: \"WebScraper\",\n    FINISH: END,\n  })\n  .addEdge(START, \"supervisor\");\n\nconst researchChain = researchGraph.compile();\n```\n\n----------------------------------------\n\nTITLE: Using Entrypoint Wrapper in TypeScript\nDESCRIPTION: This code snippet demonstrates how to use the entrypoint wrapper in a LangGraph workflow to incorporate the MemorySaver checkpointer for persisting states. Inputs are processed asynchronously, allowing seamless state maintenance.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { entrypoint } from \"@langchain/langgraph\";\nconst workflow = entrypoint({\n  name: \"workflow\",\n  checkpointer,\n}, async (inputs) => {\n  ...\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring ReAct Agents with LangChain\nDESCRIPTION: Defines 'travelAdvisor' and 'hotelAdvisor' agents using LangChain's createReactAgent function. Equipped with tailored tools, they include stateModifier to guide agent behavior. Requires dependencies like '@langchain/messages' and model instance from 'ChatAnthropic'.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nimport {\n  AIMessage,\n  type BaseMessageLike\n} from \"@langchain/core/messages\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\nimport {\n  addMessages,\n  entrypoint,\n  task,\n} from \"@langchain/langgraph\";\n\nconst model = new ChatAnthropic({\n  model: \"claude-3-5-sonnet-latest\",\n});\n\nconst travelAdvisorTools = [\n  getTravelRecommendations,\n  transferToHotelAdvisor,\n];\n\n// Define travel advisor ReAct agent\nconst travelAdvisor = createReactAgent({\n  llm: model,\n  tools: travelAdvisorTools,\n  stateModifier: [\n    \"You are a general travel expert that can recommend travel destinations (e.g. countries, cities, etc).\",\n    \"If you need hotel recommendations, ask 'hotel_advisor' for help.\",\n    \"You MUST include human-readable response before transferring to another agent.\",\n  ].join(\" \"),\n});\n\n// You can also add additional logic like changing the input to the agent / output from the agent, etc.\n// NOTE: we're invoking the ReAct agent with the full history of messages in the state\nconst callTravelAdvisor = task(\"callTravelAdvisor\", async (messages: BaseMessageLike[]) => {\n  const response = await travelAdvisor.invoke({ messages });\n  return response.messages;\n});\n\nconst hotelAdvisorTools = [\n  getHotelRecommendations,\n  transferToTravelAdvisor,\n];\n\n// Define hotel advisor ReAct agent\nconst hotelAdvisor = createReactAgent({\n  llm: model,\n  tools: hotelAdvisorTools,\n  stateModifier: [\n    \"You are a hotel expert that can provide hotel recommendations for a given destination.\",\n    \"If you need help picking travel destinations, ask 'travel_advisor' for help.\",\n    \"You MUST include a human-readable response before transferring to another agent.\"\n  ].join(\" \"),\n});\n\n// Add task for hotel advisor\nconst callHotelAdvisor = task(\"callHotelAdvisor\", async (messages: BaseMessageLike[]) => {\n  const response = await hotelAdvisor.invoke({ messages });\n  return response.messages;\n});\n```\n\n----------------------------------------\n\nTITLE: Defining a Message Graph with Model Callbacks in TypeScript\nDESCRIPTION: This code defines a message processing graph using LangGraphJS. It includes user information retrieval and model selection based on provided configuration. Two language models, Anthropic's Claude 3 Haiku and OpenAI's GPT-4o, are interchangeably used depending on the configuration. Key dependencies include '@langchain/core' and related modules.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/configuration.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { ChatPromptTemplate } from \"@langchain/core/prompts\";\nimport { RunnableConfig } from \"@langchain/core/runnables\";\nimport {\n  END,\n  START,\n  StateGraph,\n  Annotation,\n} from \"@langchain/langgraph\";\n\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n  userInfo: Annotation<string | undefined>({\n    reducer: (x, y) => {\n      return y ? y : x ? x : \"N/A\";\n    },\n    default: () => \"N/A\",\n  })\n});\n\nconst promptTemplate = ChatPromptTemplate.fromMessages([\n  [\"system\", \"You are a helpful assistant.\\n\\n## User Info:\\n{userInfo}\"],\n  [\"placeholder\", \"{messages}\"],\n]);\n\nconst callModel = async (\n  state: typeof AgentState.State,\n  config?: RunnableConfig,\n) => {\n  const { messages, userInfo } = state;\n  const modelName = config?.configurable?.model;\n  const model = modelName === \"claude\"\n    ? new ChatAnthropic({ model: \"claude-3-haiku-20240307\" })\n    : new ChatOpenAI({ model: \"gpt-4o\" });\n  const chain = promptTemplate.pipe(model);\n  const response = await chain.invoke(\n    {\n      messages,\n      userInfo,\n    },\n    config,\n  );\n  return { messages: [response] };\n};\n\nconst fetchUserInformation = async (\n  _: typeof AgentState.State,\n  config?: RunnableConfig,\n) => {\n  const userDB = {\n    user1: {\n      name: \"John Doe\",\n      email: \"jod@langchain.ai\",\n      phone: \"+1234567890\",\n    },\n    user2: {\n      name: \"Jane Doe\",\n      email: \"jad@langchain.ai\",\n      phone: \"+0987654321\",\n    },\n  };\n  const userId = config?.configurable?.user;\n  if (userId) {\n    const user = userDB[userId as keyof typeof userDB];\n    if (user) {\n      return {\n        userInfo:\n          `Name: ${user.name}\\nEmail: ${user.email}\\nPhone: ${user.phone}`,\n      };\n    }\n  }\n  return { userInfo: \"N/A\" };\n};\n\nconst workflow = new StateGraph(AgentState)\n  .addNode(\"fetchUserInfo\", fetchUserInformation)\n  .addNode(\"agent\", callModel)\n  .addEdge(START, \"fetchUserInfo\")\n  .addEdge(\"fetchUserInfo\", \"agent\")\n  .addEdge(\"agent\", END);\n\nconst graph = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Importing and Configuring Postgres Checkpointer in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to import required modules and configure a Postgres checkpointer within a StateGraph. It requires the `@langchain/langgraph` and `@langchain/langgraph-checkpoint-postgres` packages. The `PostgresSaver.fromConnString` method is used to instantiate the checkpointer. No specific input or output constraints are mentioned.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-postgres.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: ts\nCODE:\n```\nimport { StateGraph } from \"@langchain/langgraph\";\nimport { PostgresSaver } from \"@langchain/langgraph-checkpoint-postgres\";\n\nconst builder = new StateGraph(...);\n\n// ... define the graph\n\nconst checkpointer = PostgresSaver.fromConnString(...); // postgres checkpointer (see examples below)\n\nconst graph = builder.compile({ checkpointer });\n...\n```\n\n----------------------------------------\n\nTITLE: Storing New Memories in LangGraph.js Agent\nDESCRIPTION: This snippet demonstrates how to invoke a LangGraph.js agent to store a new memory about trash day. It sends a user message to the agent, which processes and stores this information for future recall.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nresult = await agent.invoke({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Please remember that every Thursday is trash day.\",\n    },\n  ],\n});\n\nprintMessages(result.messages);\n```\n\n----------------------------------------\n\nTITLE: Initializing MemorySaver in TypeScript\nDESCRIPTION: This code snippet showcases how to create an instance of MemorySaver, which acts as a checkpointer to store intermediate states across workflow executions. It requires the @langchain/langgraph package.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst checkpointer = new MemorySaver();\n```\n\n----------------------------------------\n\nTITLE: Forking LangGraph by Updating State\nDESCRIPTION: This code snippet demonstrates how to fork a LangGraph execution by updating the state at a specific checkpoint. The `checkpoint_id` is included in the `threadConfig` to specify the checkpoint to update. The `graph.updateState` method is used to update the state at the specified checkpoint, creating a new forked checkpoint.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/time-travel.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst threadConfig = { configurable: { thread_id: \"1\", checkpoint_id: \"xyz\" } };\n\ngraph.updateState(threadConfig, { state: \"updated state\" });\n```\n\n----------------------------------------\n\nTITLE: Defining Top-Level State Interface in LangGraph.js\nDESCRIPTION: This code defines the top-level state interface for the graph using `Annotation.Root`. The state consists of `messages` (an array of messages), `next` (the next team to be called), and `instructions` (instructions for the graph). Reducers and default values are set for each field.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: javascript\nCODE:\n```\n// Define the top-level State interface\nconst State = Annotation.Root({{\n  messages: Annotation<BaseMessage[]>({{\n    reducer: (x, y) => x.concat(y),\n  }}),\n  next: Annotation<string>({{\n    reducer: (x, y) => y ?? x,\n    default: () => \"ResearchTeam\",\n  }}),\n  instructions: Annotation<string>({{\n    reducer: (x, y) => y ?? x,\n    default: () => \"Resolve the user's request.\",\n  }}),\n}});\n\nconst supervisorNode = await createTeamSupervisor(\n  llm,\n  \"You are a supervisor tasked with managing a conversation between the\" +\n    \" following teams: {team_members}. Given the following user request,\" +\n    \" respond with the worker to act next. Each worker will perform a\" +\n    \" task and respond with their results and status. When finished,\" +\n    \" respond with FINISH.\\n\\n\" +\n    \" Select strategically to minimize the number of steps taken.\",\n  [\"ResearchTeam\", \"PaperWritingTeam\"],\n);\n\nconst getMessages = RunnableLambda.from((state: typeof State.State) => {{\n  return {{ messages: state.messages }};\n}});\n\nconst joinGraph = RunnableLambda.from((response: any) => {{\n  return {{\n    messages: [response.messages[response.messages.length - 1]],\n  }};\n}});\n\n```\n\n----------------------------------------\n\nTITLE: Creating Routing Logic with Functional API in TypeScript\nDESCRIPTION: This snippet demonstrates a functional approach to routing input using Langchain's Functional API. It defines tasks to generate stories, jokes, and poems based on user input and routes the execution flow accordingly. The implementation emphasizes the seamless integration of tasks and input handling.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Import necessary libraries\nimport { z } from \"zod\";\nimport { task, entrypoint } from \"@langchain/langgraph\";\n\n// Schema for structured output to use as routing logic\nconst routeSchema = z.object({\n  step: z.enum([\"poem\", \"story\", \"joke\"]).describe(\n    \"The next step in the routing process\"\n  ),\n});\n\n// Augment the LLM with schema for structured output\nconst router = llm.withStructuredOutput(routeSchema);\n\n// Tasks\n// Write a story\nconst llmCall1 = task(\"generateStory\", async (input: string) => {\n  const result = await llm.invoke([{\n    role: \"system\",\n    content: \"You are an expert storyteller.\",\n  }, {\n    role: \"user\",\n    content: input\n  }]);\n  return result.content;\n});\n\n// Write a joke\nconst llmCall2 = task(\"generateJoke\", async (input: string) => {\n  const result = await llm.invoke([{\n    role: \"system\",\n    content: \"You are an expert comedian.\",\n  }, {\n    role: \"user\",\n    content: input\n  }]);\n  return result.content;\n});\n\n// Write a poem\nconst llmCall3 = task(\"generatePoem\", async (input: string) => {\n  const result = await llm.invoke([{\n    role: \"system\",\n    content: \"You are an expert poet.\",\n  }, {\n    role: \"user\",\n    content: input\n  }]);\n  return result.content;\n});\n\n// Route the input to the appropriate node\nconst llmCallRouter = task(\"router\", async (input: string) => {\n  const decision = await router.invoke([\n    {\n      role: \"system\",\n      content: \"Route the input to story, joke, or poem based on the user's request.\"\n    },\n    {\n      role: \"user\",\n      content: input\n    },\n  ]);\n  return decision.step;\n});\n\n// Build workflow\nconst workflow = entrypoint(\n  \"routerWorkflow\",\n  async (input: string) => {\n    const nextStep = await llmCallRouter(input);\n\n    let llmCall;\n    if (nextStep === \"story\") {\n      llmCall = llmCall1;\n    } else if (nextStep === \"joke\") {\n      llmCall = llmCall2;\n    } else if (nextStep === \"poem\") {\n      llmCall = llmCall3;\n    }\n\n    const finalResult = await llmCall(input);\n    return finalResult;\n  }\n);\n\n// Invoke\nconst stream = await workflow.stream(\"Write me a joke about cats\", {\n  streamMode: \"updates\",\n});\n\nfor await (const step of stream) {\n  console.log(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Conditional Branching with Dynamic Path Selection\nDESCRIPTION: Creates a graph with conditional branching where the path taken depends on the 'which' parameter in the state, demonstrating dynamic control flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst ConditionalBranchingAnnotation = Annotation.Root({\n  aggregate: Annotation<string[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n  which: Annotation<string>({\n    reducer: (x: string, y: string) => (y ?? x),\n  })\n})\n\n// Create the graph\nconst nodeA2 = (state: typeof ConditionalBranchingAnnotation.State) => {\n  console.log(`Adding I'm A to ${state.aggregate}`);\n  return { aggregate: [`I'm A`] };\n};\nconst nodeB2 = (state: typeof ConditionalBranchingAnnotation.State) => {\n  console.log(`Adding I'm B to ${state.aggregate}`);\n  return { aggregate: [`I'm B`] };\n};\nconst nodeC2 = (state: typeof ConditionalBranchingAnnotation.State) => {\n  console.log(`Adding I'm C to ${state.aggregate}`);\n  return { aggregate: [`I'm C`] };\n};\nconst nodeD2 = (state: typeof ConditionalBranchingAnnotation.State) => {\n  console.log(`Adding I'm D to ${state.aggregate}`);\n  return { aggregate: [`I'm D`] };\n};\nconst nodeE2 = (state: typeof ConditionalBranchingAnnotation.State) => {\n  console.log(`Adding I'm E to ${state.aggregate}`);\n  return { aggregate: [`I'm E`] };\n};\n\n// Define the route function\nfunction routeCDorBC(state: typeof ConditionalBranchingAnnotation.State): string[] {\n  if (state.which === \"cd\") {\n    return [\"c\", \"d\"];\n  }\n  return [\"b\", \"c\"];\n}\n\nconst builder2 = new StateGraph(ConditionalBranchingAnnotation)\n  .addNode(\"a\", nodeA2)\n  .addEdge(START, \"a\")\n  .addNode(\"b\", nodeB2)\n  .addNode(\"c\", nodeC2)\n  .addNode(\"d\", nodeD2)\n  .addNode(\"e\", nodeE2)\n  // Add conditional edges\n  // Third parameter is to support visualizing the graph\n  .addConditionalEdges(\"a\", routeCDorBC, [\"b\", \"c\", \"d\"])\n  .addEdge(\"b\", \"e\")\n  .addEdge(\"c\", \"e\")\n  .addEdge(\"d\", \"e\")\n  .addEdge(\"e\", END);\n\nconst graph2 = builder2.compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Approval Pattern for Human-in-the-loop in LangGraphJS\nDESCRIPTION: Shows how to implement an approval pattern where a human can review and approve an agent's action before it proceeds. This pattern uses breakpoints before sensitive actions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Compile our graph with a checkpointer and a breakpoint before the step to approve\nconst graph = builder.compile({ checkpointer, interruptBefore: [\"node_2\"] });\n\n// Run the graph up to the breakpoint\nfor await (const event of await graph.stream(inputs, threadConfig)) {\n    console.log(event);\n}\n    \n// ... Get human approval ...\n\n// If approved, continue the graph execution from the last saved checkpoint\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining the Graph State\nDESCRIPTION: This snippet defines the state for the LangGraph, including messages, next representative, and refund authorization status. It utilizes `Annotation` and `MessagesAnnotation` from `@langchain/langgraph` to structure the state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { Annotation, MessagesAnnotation } from \\\"@langchain/langgraph\\\";\\n\\nconst StateAnnotation = Annotation.Root({\\n  ...MessagesAnnotation.spec,\\n  nextRepresentative: Annotation<string>,\\n  refundAuthorized: Annotation<boolean>\\n});\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Initial Support Node\nDESCRIPTION: This snippet defines the `initialSupport` node, which simulates a secretary handling incoming questions. It uses a system template to guide the response and categorizes the user's issue to route them to the appropriate team (billing, technical, or respond conversationally) using an LLM. It returns the response message and the next representative's ID.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { z } from \\\"zod\\\";\\nimport { zodToJsonSchema } from \\\"zod-to-json-schema\\\";\\n\\nconst initialSupport = async (state: typeof StateAnnotation.State) => {\\n  const SYSTEM_TEMPLATE =\\n    `You are frontline support staff for LangCorp, a company that sells computers.\\nBe concise in your responses.\\nYou can chat with customers and help them with basic questions, but if the customer is having a billing or technical problem,\\ndo not try to answer the question directly or gather information.\\nInstead, immediately transfer them to the billing or technical team by asking the user to hold for a moment.\\nOtherwise, just respond conversationally.`;\\n  const supportResponse = await model.invoke([\\n    { role: \\\"system\\\", content: SYSTEM_TEMPLATE },\\n    ...state.messages,\\n  ]);\\n\\n  const CATEGORIZATION_SYSTEM_TEMPLATE = `You are an expert customer support routing system.\\nYour job is to detect whether a customer support representative is routing a user to a billing team or a technical team, or if they are just responding conversationally.`;\\n  const CATEGORIZATION_HUMAN_TEMPLATE =\\n    `The previous conversation is an interaction between a customer support representative and a user.\\nExtract whether the representative is routing the user to a billing or technical team, or whether they are just responding conversationally.\\nRespond with a JSON object containing a single key called \\\"nextRepresentative\\\" with one of the following values:\\n\\nIf they want to route the user to the billing team, respond only with the word \\\"BILLING\\\".\\nIf they want to route the user to the technical team, respond only with the word \\\"TECHNICAL\\\".\\nOtherwise, respond only with the word \\\"RESPOND\\\".`;\\n  const categorizationResponse = await model.invoke([{ role: \\\"system\\\", content: CATEGORIZATION_SYSTEM_TEMPLATE },\\n  ...state.messages,\\n  { role: \\\"user\\\", content: CATEGORIZATION_HUMAN_TEMPLATE }],\\n  {\\n    response_format: {\\n      type: \\\"json_object\\\",\\n      schema: zodToJsonSchema(\\n        z.object({\\n          nextRepresentative: z.enum([\\\"BILLING\\\", \\\"TECHNICAL\\\", \\\"RESPOND\\\"]),\\n        })\\n      )\\n    }\\n  });\\n  // Some chat models can return complex content, but Together will not\\n  const categorizationOutput = JSON.parse(categorizationResponse.content as string);\\n  // Will append the response message to the current interaction state\\n  return { messages: [supportResponse], nextRepresentative: categorizationOutput.nextRepresentative };\\n};\"\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Graph with Checkpoints in LangGraph using TypeScript\nDESCRIPTION: This code snippet illustrates the creation of a simple graph in LangGraph with nodes and edges defined, along with the implementation of a checkpointer. It demonstrates how nodes can return state values and how the graph is compiled with a `MemorySaver` checkpointer to enable persistence.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, START, END, MemorySaver, Annotation } from \"@langchain/langgraph\";\n\nconst GraphAnnotation = Annotation.Root({\n  foo: Annotation<string>\n  bar: Annotation<string[]>({\n    reducer: (a, b) => [...a, ...b],\n    default: () => [],\n  })\n});\n\nfunction nodeA(state: typeof GraphAnnotation.State) {\n  return { foo: \"a\", bar: [\"a\"] };\n}\n\nfunction nodeB(state: typeof GraphAnnotation.State) {\n  return { foo: \"b\", bar: [\"b\"] };\n}\n\nconst workflow = new StateGraph(GraphAnnotation)\n  .addNode(\"nodeA\", nodeA)\n  .addNode(\"nodeB\", nodeB)\n  .addEdge(START, \"nodeA\")\n  .addEdge(\"nodeA\", \"nodeB\")\n  .addEdge(\"nodeB\", END);\n\nconst checkpointer = new MemorySaver();\nconst graph = workflow.compile({ checkpointer });\n\nconst config = { configurable: { thread_id: \"1\" } };\nawait graph.invoke({ foo: \"\" }, config);\n```\n\n----------------------------------------\n\nTITLE: Creating a Planning Agent\nDESCRIPTION: Sets up the planning component that generates a step-by-step plan for achieving the objective. Uses a prompt template and GPT-4 with structured output to create plans with clear, executable steps.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatPromptTemplate } from \"@langchain/core/prompts\";\n\nconst plannerPrompt = ChatPromptTemplate.fromTemplate(\n  `For the given objective, come up with a simple step by step plan. \\\nThis plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\nThe result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n\n{objective}`,\n);\n\nconst model = new ChatOpenAI({\n  modelName: \"gpt-4-0125-preview\",\n}).withStructuredOutput(planFunction);\n\nconst planner = plannerPrompt.pipe(model);\n```\n\n----------------------------------------\n\nTITLE: Defining AgentState for LangGraphJS\nDESCRIPTION: This code defines the AgentState using Annotation from LangGraphJS, setting up a messages array with a custom reducer for concatenation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Invoking Subgraphs with Interrupts\nDESCRIPTION: This example demonstrates how parent graphs interact with subgraphs containing interrupts. When a subgraph with an interrupt is invoked, the parent graph will resume execution from the beginning of the node where the subgraph was called.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nasync function nodeInParentGraph(state: typeof GraphAnnotation.State) {\n    someCode();  // <-- This will re-execute when the subgraph is resumed.\n    // Invoke a subgraph as a function.\n    // The subgraph contains an `interrupt` call.\n    const subgraphResult = await subgraph.invoke(someInput);\n    ...\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Retriever with Vector Search\nDESCRIPTION: Sets up a retriever by loading web content from multiple URLs, splitting it into chunks, and storing it in a vector database. The code creates a retriever from a MemoryVectorStore with OpenAI embeddings.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { CheerioWebBaseLoader } from \"@langchain/community/document_loaders/web/cheerio\";\nimport { RecursiveCharacterTextSplitter } from \"@langchain/textsplitters\";\nimport { MemoryVectorStore } from \"langchain/vectorstores/memory\";\nimport { OpenAIEmbeddings } from \"@langchain/openai\";\n\nconst urls = [\n  \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n  \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n  \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n];\n\nconst docs = await Promise.all(\n  urls.map((url) => new CheerioWebBaseLoader(url).load()),\n);\nconst docsList = docs.flat();\n\nconst textSplitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 500,\n  chunkOverlap: 50,\n});\nconst docSplits = await textSplitter.splitDocuments(docsList);\n\n// Add to vectorDB\nconst vectorStore = await MemoryVectorStore.fromDocuments(\n  docSplits,\n  new OpenAIEmbeddings(),\n);\n\nconst retriever = vectorStore.asRetriever();\n```\n\n----------------------------------------\n\nTITLE: Setting Up Reflection Chain\nDESCRIPTION: Configures a reflection prompt template for essay evaluation and feedback generation\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/reflection/reflection.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst reflectionPrompt = ChatPromptTemplate.fromMessages([\n  [\n    \"system\",\n    `You are a teacher grading an essay submission.\nGenerate critique and recommendations for the user's submission.\nProvide detailed recommendations, including requests for length, depth, style, etc.`,\n  ],\n  new MessagesPlaceholder(\"messages\"),\n]);\nconst reflect = reflectionPrompt.pipe(llm);\n```\n\n----------------------------------------\n\nTITLE: Implementing Refund Handling Node\nDESCRIPTION: This snippet defines the `handleRefund` node, which processes refund requests. It checks if the refund is authorized. If not, it throws a `NodeInterrupt`, allowing for resumption of the graph after human authorization. If authorized, it processes the refund and returns a confirmation message.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n\"import { NodeInterrupt } from \\\"@langchain/langgraph\\\";\\n\\nconst handleRefund = async (state: typeof StateAnnotation.State) => {\\n  if (!state.refundAuthorized) {\\n    console.log(\\\"--- HUMAN AUTHORIZATION REQUIRED FOR REFUND ---\\\");\\n    throw new NodeInterrupt(\\\"Human authorization required.\\\")\\n  }\\n  return {\\n    messages: {\\n      role: \\\"assistant\\\",\\n      content: \\\"Refund processed!\\\",\\n    },\\n  };\\n};\"\n```\n\n----------------------------------------\n\nTITLE: Streaming Graph Updates\nDESCRIPTION: This code demonstrates how to stream updates from the compiled LangGraph. It initializes the input with a user message and then iterates through the stream of chunks received from the graph. It logs the updates from each node as they are received, using the \"updates\" stream mode.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-updates.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nlet inputs = { messages: [{ role: \"user\",  content: \"what's the weather in sf\" }] };\n\nfor await (\n  const chunk of await graph.stream(inputs, {\n    streamMode: \"updates\",\n  })\n) {\n  for (const [node, values] of Object.entries(chunk)) {\n    console.log(`Receiving update from node: ${node}`);\n    console.log(values);\n    console.log(\"\\n====\\n\");\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Question Router Implementation\nDESCRIPTION: Creation of a question routing system using Ollama's JSON mode to direct queries to appropriate data sources.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatPromptTemplate } from \"@langchain/core/prompts\";\nimport { JsonOutputParser } from \"@langchain/core/output_parsers\";\nimport { ChatOllama } from \"@langchain/ollama\";\n\nconst jsonModeLlm = new ChatOllama({\n  model: \"llama3\",\n  format: \"json\",\n  temperature: 0,\n});\n\nconst QUESTION_ROUTER_SYSTEM_TEMPLATE =\n  `You are an expert at routing a user question to a vectorstore or web search.\nUse the vectorstore for questions on LLM agents, prompt engineering, and adversarial attacks.\nYou do not need to be stringent with the keywords in the question related to these topics.\nOtherwise, use web-search. Give a binary choice 'web_search' or 'vectorstore' based on the question.\nReturn the a JSON with a single key 'datasource' and no preamble or explanation.`;\n\nconst questionRouterPrompt = ChatPromptTemplate.fromMessages([\n  [\"system\", QUESTION_ROUTER_SYSTEM_TEMPLATE],\n  [\"human\", \"{question}\"],\n]);\n\nconst questionRouter = questionRouterPrompt.pipe(jsonModeLlm).pipe(\n  new JsonOutputParser(),\n);\n\nawait questionRouter.invoke({ question: \"llm agent memory\" });\n```\n\n----------------------------------------\n\nTITLE: Implementing Pregel Computation Model in TypeScript\nDESCRIPTION: This code snippet defines the PregelLoop and PregelRunner classes, which are responsible for executing the Pregel computation model. It also includes a StateSnapshot interface for managing the execution state. The PregelLoop handles individual computation steps, error handling, and write operations, while the PregelRunner manages task execution with optional retry policies and timeouts.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/langgraph-architecture-spec.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nclass PregelLoop {\n  // Execute one step of the Pregel computation model, returns whether more steps are needed\n  tick(params): Promise<boolean>;\n  // Handle errors and prepare final output\n  finishAndHandleError(error): Promise<void>;\n  // Save write operations from a node task\n  putWrites(taskId, writes): void;\n}\n\nclass PregelRunner {\n  // Execute tasks with optional retry policies and timeouts\n  tick({timeout, retryPolicy, onStepWrite, signal}): Promise<void>;\n}\n\n// Pseudo-code showing the execution flow:\nconst loop = new PregelLoop(channels, checkpointer);\nconst runner = new PregelRunner(loop);\n\n// Main execution loop\nwhile (await loop.tick(params)) {\n  await runner.tick({timeout, retryPolicy});\n}\n\ninterface StateSnapshot {\n  values: Record<string, any>;\n  next: Array<string>;\n  config: RunnableConfig;\n  tasks: PregelTaskDescription[];\n  metadata?: CheckpointMetadata;\n  createdAt?: string;\n  parentConfig?: RunnableConfig;\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Message and Step Pretty-Printing Functions in TypeScript\nDESCRIPTION: These functions are used to format and display messages and steps from the agent's execution. They handle different types of messages, including AI messages with tool calls, and avoid printing cached steps.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { BaseMessage, isAIMessage } from \"@langchain/core/messages\";\n\nconst prettyPrintMessage = (message: BaseMessage) => {\n  console.log(\"=\".repeat(30), `${message.getType()} message`, \"=\".repeat(30));\n  console.log(message.content);\n  if (isAIMessage(message) && message.tool_calls?.length) {\n    console.log(JSON.stringify(message.tool_calls, null, 2));\n  }\n}\n\nconst prettyPrintStep = (step: Record<string, any>) => {\n  if (step.__metadata__?.cached) {\n    return;\n  }\n  for (const [taskName, update] of Object.entries(step)) {\n    const message = update as BaseMessage;\n    // Only print task updates\n    if (taskName === \"agent\") continue;\n    console.log(`\\n${taskName}:`);\n    if (taskName === \"__interrupt__\") {\n      console.log(update);\n    } else {\n      prettyPrintMessage(message);\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Graph Execution with Weather Query and Breakpoint\nDESCRIPTION: Demonstrates how to execute the graph with a weather-related query that triggers the subgraph with a breakpoint, showing the interruption flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst config2 = { configurable: { thread_id: \"2\" } };\n\nconst streamWithBreakpoint = await graph.stream({\n  messages: [{\n    role: \"user\",\n    content: \"what's the weather in sf\"\n  }]\n}, { ...config2, streamMode: \"updates\" });\n\nfor await (const update of streamWithBreakpoint) {\n  console.log(update);\n}\n```\n\n----------------------------------------\n\nTITLE: Running the ReAct Agent with a Single Tool Call\nDESCRIPTION: Executing the ReAct agent with a simple query that requires a single tool call. The code streams and displays each step of the agent's thought process.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n\n// example with a single tool call\nconst stream = await app.stream(\n  {\n    messages: [{ role: \"user\", content: \"what's the weather in sf?\" }],\n  },\n  {\n    streamMode: \"values\"\n  }\n)\nfor await (const chunk of stream) {\n  const lastMessage = chunk.messages[chunk.messages.length - 1];\n  const type = lastMessage._getType();\n  const content = lastMessage.content;\n  const toolCalls = lastMessage.tool_calls;\n  console.dir({\n    type,\n    content,\n    toolCalls\n  }, { depth: null });\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Parent Graph with Routing Logic in LangGraph\nDESCRIPTION: Creates a parent graph that routes user queries either to the weather subgraph or a normal LLM based on query content. Includes memory persistence, router model, and conditional logic.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst memory = new MemorySaver();\n\nconst RouterStateAnnotation = Annotation.Root({\n  ...MessagesAnnotation.spec,\n  route: Annotation<\"weather\" | \"other\">,\n});\n\nconst routerModel = rawModel.withStructuredOutput(\n  z.object({\n    route: z.enum([\"weather\", \"other\"]).describe(\"A step that should execute next to based on the currnet input\")\n  }),\n  {\n    name: \"router\"\n  }\n);\n\nconst routerNode = async (state: typeof RouterStateAnnotation.State) => {\n  const systemMessage = {\n    role: \"system\",\n    content: \"Classify the incoming query as either about weather or not.\",\n  };\n  const messages = [systemMessage, ...state.messages]\n  const { route } = await routerModel.invoke(messages);\n  return { route };\n}\n\nconst normalLLMNode = async (state: typeof RouterStateAnnotation.State) => {\n  const responseMessage = await rawModel.invoke(state.messages);\n  return { messages: [responseMessage] };\n};\n\nconst routeAfterPrediction = async (state: typeof RouterStateAnnotation.State) => {\n  if (state.route === \"weather\") {\n    return \"weatherGraph\";\n  } else {\n    return \"normalLLMNode\";\n  }\n};\n\nconst graph = new StateGraph(RouterStateAnnotation)\n  .addNode(\"routerNode\", routerNode)\n  .addNode(\"normalLLMNode\", normalLLMNode)\n  .addNode(\"weatherGraph\", subgraph)\n  .addEdge(\"__start__\", \"routerNode\")\n  .addConditionalEdges(\"routerNode\", routeAfterPrediction)\n  .addEdge(\"normalLLMNode\", \"__end__\")\n  .addEdge(\"weatherGraph\", \"__end__\")\n  .compile({ checkpointer: memory });\n```\n\n----------------------------------------\n\nTITLE: Final State Management in TypeScript\nDESCRIPTION: This snippet deals with workflow output through the entrypoint.final function. The function segregates values to be returned from the ones saved as previous state, enabling dynamic state preservation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { entrypoint, getPreviousState } from \"@langchain/langgraph\";\n\nconst workflow = entrypoint({\n  name: \"workflow\",\n  checkpointer,\n}, async (inputs) => {\n  const previous = getPreviousState();\n  const result = doSomething(previous, inputs);\n  ...\n  return entrypoint.final({\n    value: result,\n    save: combineState(inputs, result),\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Invoking ToolNode with Multiple Parallel Tool Calls\nDESCRIPTION: Example of creating an AIMessage with multiple tool calls and passing it to ToolNode. This demonstrates parallel tool execution capability.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst messageWithMultipleToolCalls = new AIMessage({\n  content: \"\",\n  tool_calls: [\n    {\n      name: \"get_coolest_cities\",\n      args: {},\n      id: \"tool_call_id\",\n      type: \"tool_call\",\n    },\n    {\n      name: \"get_weather\",\n      args: { location: \"sf\" },\n      id: \"tool_call_id_2\",\n      type: \"tool_call\",\n    }\n  ]\n})\n\nawait toolNode.invoke({ messages: [messageWithMultipleToolCalls] })\n```\n\n----------------------------------------\n\nTITLE: Create a StateGraph with dynamic control flow using Command\nDESCRIPTION: This snippet demonstrates how to create a `StateGraph` using nodes defined in the previous example. Critically, no conditional edges are defined because nodeA defines the control flow. The `ends` attribute is added to the nodeA configuration to signal the possible destination nodes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/command.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph } from \"@langchain/langgraph\";\n\n// NOTE: there are no edges between nodes A, B and C!\nconst graph = new StateGraph(StateAnnotation)\n  .addNode(\"nodeA\", nodeA, {\n    ends: [\"nodeB\", \"nodeC\"],\n  })\n  .addNode(\"nodeB\", nodeB)\n  .addNode(\"nodeC\", nodeC)\n  .addEdge(\"__start__\", \"nodeA\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing SQLite Checkpoint Management in LangGraph.js\nDESCRIPTION: Demonstrates how to initialize, store, and retrieve checkpoints using SQLite database integration. Shows configuration setup, checkpoint data structure, and methods for storing, loading, and listing checkpoints.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint-sqlite/README.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { SqliteSaver } from \"@langchain/langgraph-checkpoint-sqlite\";\n\nconst writeConfig = {\n  configurable: {\n    thread_id: \"1\",\n    checkpoint_ns: \"\"\n  }\n};\nconst readConfig = {\n  configurable: {\n    thread_id: \"1\"\n  }\n};\n\nconst checkpointer = SqliteSaver.fromConnString(\":memory:\");\nconst checkpoint = {\n  v: 1,\n  ts: \"2024-07-31T20:14:19.804150+00:00\",\n  id: \"1ef4f797-8335-6428-8001-8a1503f9b875\",\n  channel_values: {\n    my_key: \"meow\",\n    node: \"node\"\n  },\n  channel_versions: {\n    __start__: 2,\n    my_key: 3,\n    \"start:node\": 3,\n    node: 3\n  },\n  versions_seen: {\n    __input__: {},\n    __start__: {\n      __start__: 1\n    },\n    node: {\n      \"start:node\": 2\n    }\n  },\n  pending_sends: [],\n}\n\n// store checkpoint\nawait checkpointer.put(writeConfig, checkpoint, {}, {})\n\n// load checkpoint\nawait checkpointer.get(readConfig)\n\n// list checkpoints\nfor await (const checkpoint of checkpointer.list(readConfig)) {\n  console.log(checkpoint);\n}\n```\n\n----------------------------------------\n\nTITLE: Constructing LangGraph Workflow with Conditional Edges\nDESCRIPTION: Creates a state graph with multiple nodes representing different stages of a document retrieval and generation process. Defines node connections and conditional transitions using addEdge and addConditionalEdges methods.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\n\nconst workflow = new StateGraph(GraphState)\n  .addNode(\"retrieve\", retrieve)\n  .addNode(\"gradeDocuments\", gradeDocuments)\n  .addNode(\"generate\", generate)\n  .addNode(\n    \"generateGenerationVDocumentsGrade\",\n    generateGenerationVDocumentsGrade\n  )\n  .addNode(\"transformQuery\", transformQuery)\n  .addNode(\n    \"generateGenerationVQuestionGrade\",\n    generateGenerationVQuestionGrade\n  );\n\n// Build graph\nworkflow.addEdge(START, \"retrieve\");\nworkflow.addEdge(\"retrieve\", \"gradeDocuments\");\nworkflow.addConditionalEdges(\"gradeDocuments\", decideToGenerate, {\n  transformQuery: \"transformQuery\",\n  generate: \"generate\",\n});\nworkflow.addEdge(\"transformQuery\", \"retrieve\");\nworkflow.addEdge(\"generate\", \"generateGenerationVDocumentsGrade\");\nworkflow.addConditionalEdges(\n  \"generateGenerationVDocumentsGrade\",\n  gradeGenerationVDocuments,\n  {\n    supported: \"generateGenerationVQuestionGrade\",\n    \"not supported\": \"generate\",\n  }\n);\n\nworkflow.addConditionalEdges(\n  \"generateGenerationVQuestionGrade\",\n  gradeGenerationVQuestion,\n  {\n    useful: END,\n    \"not useful\": \"transformQuery\",\n  }\n);\n\n// Compile\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Breakpoints for Human-in-the-loop in LangGraphJS\nDESCRIPTION: Sets up a graph with a checkpointer and breakpoint before a specific node, allowing the graph to pause execution for human interaction and then resume from the saved checkpoint.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// Compile our graph with a checkpointer and a breakpoint before \"step_for_human_in_the_loop\"\nconst graph = builder.compile({ checkpointer, interruptBefore: [\"step_for_human_in_the_loop\"] });\n\n// Run the graph up to the breakpoint\nconst threadConfig = { configurable: { thread_id: \"1\" }, streamMode: \"values\" as const };\nfor await (const event of await graph.stream(inputs, threadConfig)) {\n    console.log(event);\n}\n    \n// Perform some action that requires human in the loop\n\n// Continue the graph execution from the current checkpoint \nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Conditional Edges in TypeScript for LangGraph\nDESCRIPTION: Illustrates the process of adding conditional edges to a graph in TypeScript using the addConditionalEdges method. This example demonstrates how to define path maps for routing function outputs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/langgraph_studio.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ngraph.addConditionalEdges(\"node_a\", routingFunction, { foo: \"node_b\", bar: \"node_c\" });\n```\n\n----------------------------------------\n\nTITLE: Streaming Workflow Response - TypeScript\nDESCRIPTION: This code snippet demonstrates how to use a specified user ID to initiate the workflow and stream messages, allowing for an interactive chat experience where user preferences are contextually retrieved and utilized.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence-functional.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = {\n  configurable: {\n    thread_id: \"1\",\n  },\n  streamMode: \"values\" as const,\n};\n\nconst inputMessage = {\n  role: \"user\",\n  content: \"Hi! Remember: my name is Bob\",\n};\n\nconst stream = await workflow.stream({ messages: [inputMessage], userId: \"1\" }, config);\n\nfor await (const chunk of stream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Manual initialization of state with messages - TypeScript\nDESCRIPTION: This snippet provides a manual equivalent of initializing a graph with message management. It illustrates the explicit definition of state annotations, including a default value for messages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { Annotation, StateGraph, messagesStateReducer } from \"@langchain/langgraph\";\n\nexport const StateAnnotation = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: messagesStateReducer,\n    default: () => [],\n  }),\n});\n\nconst graph = new StateGraph(StateAnnotation)\n  .addNode(...)\n  ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Core Pregel Logic Functions in TypeScript\nDESCRIPTION: Core algorithm functions that implement the complete Pregel lifecycle, including initialization, task preparation, write application, and result finalization.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-execution-model.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Initialize and prepare first superstep\nfunction _first(\n  input: any,\n  channels: Record<string, BaseChannel>,\n  checkpointer?: BaseCheckpointSaver\n): RunnableConfig {\n  // Initialize channels with input values\n  _initializeChannels(channels, input);\n  \n  // Create initial checkpoint\n  const config = _createConfig();\n  if (checkpointer) {\n    const checkpoint = _createInitialCheckpoint(channels);\n    checkpointer.put(config, checkpoint, { superstep: 0 });\n  }\n  \n  return config;\n}\n\n// Prepare tasks based on channel updates\nfunction _prepareNextTasks(\n  channels: Record<string, BaseChannel>,\n  readEdges: ReadEdges,\n  versions: Versions\n): PregelTask[] {\n  const tasks: PregelTask[] = [];\n  \n  // Add PUSH tasks (explicit function calls)\n  for (const pushTask of versions.pendingPushes) {\n    tasks.push(_prepareSingleTask(\n      pushTask.node,\n      pushTask.type,\n      channels,\n      readEdges,\n      versions\n    ));\n  }\n  \n  // Add PULL tasks (triggered by channel updates)\n  for (const node of readEdges.keys()) {\n    if (_shouldExecuteNode(node, channels, readEdges, versions)) {\n      tasks.push(_prepareSingleTask(\n        node,\n        \"pull\",\n        channels,\n        readEdges,\n        versions\n      ));\n    }\n  }\n  \n  return tasks;\n}\n\n// Apply writes to channels\nfunction _applyWrites(\n  channels: Record<string, BaseChannel>,\n  writes: ChannelWrite[],\n  versions: Versions\n): void {\n  for (const write of writes) {\n    const channel = channels[write.channel];\n    const updated = channel.update(write.values);\n    \n    if (updated) {\n      versions.channelVersions[write.channel] += 1;\n    }\n  }\n}\n\n// Finalize execution and prepare result\nfunction _finalize(\n  channels: Record<string, BaseChannel>,\n  outputChannels: string[]\n): any {\n  // Extract final values from output channels\n  if (outputChannels.length === 1) {\n    // Single output channel case\n    return channels[outputChannels[0]].get();\n  } else {\n    // Multiple output channels case\n    return Object.fromEntries(\n      outputChannels.map(name => [name, channels[name].get()])\n    );\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Keys for Multi-agent Collaboration\nDESCRIPTION: Environment configuration for the multi-agent collaboration system, setting up necessary API keys for OpenAI, Tavily, and LangChain services, along with tracing configuration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n// process.env.TAVILY_API_KEY = \"sk_...\";\n// process.env.LANGCHAIN_API_KEY = \"sk_...\";\n// process.env.LANGCHAIN_TRACING_V2 = \"true\";\n// process.env.LANGCHAIN_PROJECT = \"Multi-agent Collaboration: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Running the ReAct Agent with Multiple Sequential Tool Calls\nDESCRIPTION: Executing the ReAct agent with a more complex query that requires multiple tool calls in sequence. This demonstrates the agent's ability to chain tools to solve more complex problems.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\n// example with a multiple tool calls in succession\nconst streamWithMultiToolCalls = await app.stream(\n  {\n      messages: [{ role: \"user\", content: \"what's the weather in the coolest cities?\" }],\n  },\n  {\n    streamMode: \"values\"\n  }\n)\nfor await (const chunk of streamWithMultiToolCalls) {\n  const lastMessage = chunk.messages[chunk.messages.length - 1];\n  const type = lastMessage._getType();\n  const content = lastMessage.content;\n  const toolCalls = lastMessage.tool_calls;\n  console.dir({\n    type,\n    content,\n    toolCalls\n  }, { depth: null });\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Graph and Validating Persistence in TypeScript\nDESCRIPTION: This snippet illustrates how to run the compiled graph and inspect the persisted state for both parent and subgraph. It includes configurations for streaming and obtaining graph state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-persistence.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = { configurable: { thread_id: \"1\" } };\n\nconst stream = await graph.stream({\n  foo: \"foo\"\n}, {\n  ...config,\n  subgraphs: true,\n});\n\nfor await (const [_source, chunk] of stream) {\n  console.log(chunk);\n}\n\n// View the parent graph state\n(await graph.getState(config)).values;\n\n// To view the subgraph state, find the recent config value\nlet stateWithSubgraph;\n\nconst graphHistories = await graph.getStateHistory(config);\n\nfor await (const state of graphHistories) {\n  if (state.next[0] === \"node2\") {\n    stateWithSubgraph = state;\n    break;\n  }\n}\n\nconst subgraphConfig = stateWithSubgraph.tasks[0].state;\n\nconsole.log(subgraphConfig);\n\n(await graph.getState(subgraphConfig)).values;\n```\n\n----------------------------------------\n\nTITLE: Examining Tool Calls Generated by Anthropic Model\nDESCRIPTION: Invoking the Anthropic model with a query and examining the tool_calls property of the response, demonstrating how the model generates appropriate tool calls.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst responseMessage = await modelWithTools.invoke(\"what's the weather in sf?\");\n\nresponseMessage.tool_calls;\n```\n\n----------------------------------------\n\nTITLE: Defining Parent Graph with State Transformation\nDESCRIPTION: Defines a parent graph in LangGraph that orchestrates state transitions through child and grandchild graphs. The code highlights the transformation of state keys to maintain independence between layers, leveraging langgraph's StateGraph functionalities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-transform-state.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph, START, END, Annotation } from \"@langchain/langgraph\";\n\nconst ParentAnnotation = Annotation.Root({\n    myKey: Annotation<string>,\n});\n\nconst parent1 = (state: typeof ParentAnnotation.State) => {\n    // NOTE: child or grandchild keys won't be accessible here\n    return { myKey: \"hi \" + state.myKey };\n};\n\nconst parent2 = (state: typeof ParentAnnotation.State) => {\n    return { myKey: state.myKey + \" bye!\" };\n};\n\nconst callChildGraph = async (state: typeof ParentAnnotation.State) => {\n    // we're transforming the state from the parent state channels (`myKey`)\n    // to the child state channels (`myChildKey`)\n    const childGraphInput = { myChildKey: state.myKey };\n    // we're transforming the state from the child state channels (`myChildKey`)\n    // back to the parent state channels (`myKey`)\n    const childGraphOutput = await childGraph.invoke(childGraphInput);\n    return { myKey: childGraphOutput.myChildKey };\n};\n\nconst parent = new StateGraph(ParentAnnotation)\n    .addNode(\"parent1\", parent1)\n    // NOTE: we're passing a function here instead of just a compiled graph (`childGraph`)\n    .addNode(\"child\", callChildGraph)\n    .addNode(\"parent2\", parent2)\n    .addEdge(START, \"parent1\")\n    .addEdge(\"parent1\", \"child\")\n    .addEdge(\"child\", \"parent2\")\n    .addEdge(\"parent2\", END);\n\nconst parentGraph = parent.compile();\n```\n\n----------------------------------------\n\nTITLE: Creating a React Agent\nDESCRIPTION: Creates a ReAct agent using the defined LLM and tool. The agent is configured with the ChatAnthropic model and the 'get_items' tool.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-events-from-within-tools.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\nconst agent = createReactAgent({\n  llm: model,\n  tools: [getItems],\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Decision Logic and Model Calling\nDESCRIPTION: This code defines the logic for deciding which path to take in the graph and the function to call the model with the current state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AIMessage, AIMessageChunk } from \"@langchain/core/messages\";\nimport { RunnableConfig } from \"@langchain/core/runnables\";\nimport { concat } from \"@langchain/core/utils/stream\";\n\nconst shouldContinue = (state: typeof AgentState.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  if (!lastMessage.tool_calls || lastMessage.tool_calls.length === 0) {\n    return \"end\";\n  }\n  return \"continue\";\n};\n\nconst callModel = async (\n  state: typeof AgentState.State,\n  config?: RunnableConfig,\n) => {\n  const { messages } = state;\n  let response: AIMessageChunk | undefined;\n  for await (const message of await boundModel.stream(messages, config)) {\n    if (!response) {\n      response = message;\n    } else {\n      response = concat(response, message);\n    }\n  }\n  return {\n    messages: response ? [response as AIMessage] : [],\n  };\n};\n```\n\n----------------------------------------\n\nTITLE: Building a StateGraph with LangGraph.js\nDESCRIPTION: This snippet demonstrates how to build and compile a StateGraph for the RAG workflow. It defines nodes, edges, and conditional paths between components based on document relevance.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_crag.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\n\nconst workflow = new StateGraph(GraphState)\n  // Define the nodes\n  .addNode(\"retrieve\", retrieve)\n  .addNode(\"gradeDocuments\", gradeDocuments)\n  .addNode(\"generate\", generate)\n  .addNode(\"transformQuery\", transformQuery)\n  .addNode(\"webSearch\", webSearch);\n\n// Build graph\nworkflow.addEdge(START, \"retrieve\");\nworkflow.addEdge(\"retrieve\", \"gradeDocuments\");\nworkflow.addConditionalEdges(\n  \"gradeDocuments\",\n  decideToGenerate,\n);\nworkflow.addEdge(\"transformQuery\", \"webSearch\");\nworkflow.addEdge(\"webSearch\", \"generate\");\nworkflow.addEdge(\"generate\", END);\n\n// Compile\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Defining Edge Logic for Multi-Agent Workflow in JavaScript\nDESCRIPTION: This snippet defines the router function that determines the next action based on the agent's output. It checks for tool calls or final answers to decide whether to continue, call a tool, or end the workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nimport { AIMessage } from \"@langchain/core/messages\";\n// Either agent can decide to end\nfunction router(state: typeof AgentState.State) {\n  const messages = state.messages;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  if (lastMessage?.tool_calls && lastMessage.tool_calls.length > 0) {\n    // The previous agent is invoking a tool\n    return \"call_tool\";\n  }\n  if (\n    typeof lastMessage.content === \"string\" &&\n    lastMessage.content.includes(\"FINAL ANSWER\")\n  ) {\n    // Any agent decided the work is done\n    return \"end\";\n  }\n  return \"continue\";\n}\n```\n\n----------------------------------------\n\nTITLE: Fetching State Snapshot for a Specific Checkpoint ID in TypeScript\nDESCRIPTION: This snippet shows how to get a state snapshot from a specific checkpoint ID by including both the `thread_id` and `checkpoint_id` in the configuration. This allows users to access the state of the graph at a precise moment during execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Get a state snapshot for a specific checkpoint_id\nconst configWithCheckpoint = { configurable: { thread_id: \"1\", checkpoint_id: \"1ef663ba-28fe-6528-8002-5a559208592c\" } };\nconst stateWithCheckpoint = await graph.getState(configWithCheckpoint);\n```\n\n----------------------------------------\n\nTITLE: Manually Deleting Messages in LangGraph.js\nDESCRIPTION: Shows how to manually delete messages from the state using the RemoveMessage modifier.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/delete-messages.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst messages = (await app.getState(config)).values.messages;\nconsole.dir(\n  messages.map((msg) => ({\n    id: msg.id,\n    type: msg._getType(),\n    content: msg.content,\n    tool_calls:\n    msg.tool_calls,\n  })),\n  { depth: null }\n);\n\nimport { RemoveMessage } from \"@langchain/core/messages\";\n\nawait app.updateState(config, { messages: new RemoveMessage({ id: messages[0].id }) })\n\nconst updatedMessages = (await app.getState(config)).values.messages;\nconsole.dir(\n  updatedMessages.map((msg) => ({\n    id: msg.id,\n    type: msg._getType(),\n    content: msg.content,\n    tool_calls:\n    msg.tool_calls,\n  })),\n  { depth: null }\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Graph Nodes and Functions\nDESCRIPTION: Create functions for decision-making, tool execution, and model calling to be used as graph nodes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { FunctionMessage } from \"@langchain/core/messages\";\nimport { AgentAction } from \"@langchain/core/agents\";\n\nconst shouldContinue = (state: typeof AgentState.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1];\n  if (\n    !(\"function_call\" in lastMessage.additional_kwargs) ||\n    !lastMessage.additional_kwargs.function_call\n  ) {\n    return \"end\";\n  }\n  return \"continue\";\n};\n\nconst _getAction = (state: typeof AgentState.State): AgentAction => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1];\n  if (!lastMessage) {\n    throw new Error(\"No messages found.\");\n  }\n  if (!lastMessage.additional_kwargs.function_call) {\n    throw new Error(\"No function call found in message.\");\n  }\n  return {\n    tool: lastMessage.additional_kwargs.function_call.name,\n    toolInput: JSON.stringify(\n      lastMessage.additional_kwargs.function_call.arguments,\n    ),\n    log: \"\",\n  };\n};\n\nconst callModel = async (state: typeof AgentState.State) => {\n  const { messages } = state;\n  const response = await newModel.invoke(messages);\n  return {\n    messages: [response],\n  };\n};\n\nconst callTool = async (state: typeof AgentState.State) => {\n  const action = _getAction(state);\n  const response = await toolExecutor.invoke(action);\n  const functionMessage = new FunctionMessage({\n    content: response,\n    name: action.tool,\n  });\n  return { messages: [functionMessage] };\n};\n```\n\n----------------------------------------\n\nTITLE: Streaming Values from StateGraph in JavaScript\nDESCRIPTION: Streams the state of the graph using 'values' mode, allowing users to interact and update the state as required. This involves consuming graph stream chunks asynchronously and logging results to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-values.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nlet inputs = { messages: [{ role: \"user\", content: \"what's the weather in sf\" }] };\n\nfor await (\n  const chunk of await graph.stream(inputs, {\n    streamMode: \"values\",\n  })\n) {\n  console.log(chunk[\"messages\"]);\n  console.log(\"\\n====\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Building and Compiling the Graph\nDESCRIPTION: Constructs the state graph by adding nodes and conditional edges, then compiles it with checkpointing and interrupt capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, MemorySaver, START, StateGraph } from \"@langchain/langgraph\";\n\nconst graph = new StateGraph(GraphState)\n  .addNode(\"web_search\", webSearch)\n  .addNode(\"retrieve\", retrieve)\n  .addNode(\"grade_documents\", gradeDocuments)\n  .addNode(\"generate\", generate)\n  .addNode(\"transform_query\", transformQuery)\n  .addConditionalEdges(START, routeQuestion)\n  .addEdge(\"web_search\", \"generate\")\n  .addEdge(\"retrieve\", \"grade_documents\")\n  .addConditionalEdges(\"grade_documents\", decideToGenerate)\n  .addEdge(\"transform_query\", \"retrieve\")\n  .addConditionalEdges(\"generate\", gradeGenerationDocumentsAndQuestion, {\n    not_supported: \"generate\",\n    useful: END,\n    not_useful: \"transform_query\",\n  });\n\nconst app = graph.compile({\n  checkpointer: new MemorySaver(),\n  interruptBefore: [\"web_search\"],\n});\n```\n\n----------------------------------------\n\nTITLE: Advanced Agent Implementation with Tools\nDESCRIPTION: Implementation of a ReAct-style agent with tool calling and human interaction capabilities using Anthropic's models.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { tool } from \"@langchain/core/tools\";\nimport { StateGraph, MessagesAnnotation, START, END, MemorySaver } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport { AIMessage, ToolMessage } from \"@langchain/core/messages\";\nimport { z } from \"zod\";\n\nconst search = tool((_) => {\n  return \"It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\";\n}, {\n  name: \"search\",\n  description: \"Call to surf the web.\",\n  schema: z.string(),\n})\n\nconst tools = [search]\nconst toolNode = new ToolNode<typeof MessagesAnnotation.State>(tools)\n\nconst model = new ChatAnthropic({ model: \"claude-3-5-sonnet-20240620\" })\n\nconst askHumanTool = tool((_) => {\n  return \"The human said XYZ\";\n}, {\n  name: \"askHuman\",\n  description: \"Ask the human for input.\",\n  schema: z.string(),\n});\n\n\nconst modelWithTools = model.bindTools([...tools, askHumanTool])\n```\n\n----------------------------------------\n\nTITLE: Field-Specific Embedding in LangGraph.js Memory Store\nDESCRIPTION: This snippet demonstrates how to override which fields to embed when storing specific memories. It configures a default indexing strategy but selectively changes which fields are embedded for different memories, allowing more flexible and targeted memory retrieval.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\nconst overrideStore = new InMemoryStore({\n  index: {\n    embeddings: embeddings,\n    dims: 1536,\n    // Default to embed memory field\n    fields: [\"memory\"],\n  }\n});\n\n// Store one memory with default indexing\nawait overrideStore.put([\"user_123\", \"memories\"], \"mem1\", {\n  memory: \"I love spicy food\",\n  context: \"At a Thai restaurant\",\n});\n\n// Store another memory, overriding which fields to embed\nawait overrideStore.put([\"user_123\", \"memories\"], \"mem2\", {\n  memory: \"I love spicy food\",\n  context: \"At a Thai restaurant\",\n  // Override: only embed the context\n  index: [\"context\"]\n});\n\n// Search about food - matches mem1 (using default field)\nconsole.log(\"Expect mem1\");\nconst results2 = await overrideStore.search([\"user_123\", \"memories\"], {\n  query: \"what food do they like\",\n  limit: 1,\n});\n\nfor (const r of results2) {\n  console.log(`Item: ${r.key}; Score(${r.score})`);\n  console.log(`Memory: ${r.value.memory}`);\n}\n\n// Search about restaurant atmosphere - matches mem2 (using overridden field)\nconsole.log(\"Expect mem2\");\nconst results3 = await overrideStore.search([\"user_123\", \"memories\"], {\n  query: \"restaurant environment\",\n  limit: 1,\n});\n\nfor (const r of results3) {\n  console.log(`Item: ${r.key}; Score(${r.score})`);\n  console.log(`Memory: ${r.value.memory}`);\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Checkpoints in Pregel Graphs with TypeScript\nDESCRIPTION: This code snippet demonstrates a more complex Pregel graph with node state persistence through checkpoints. It uses memory storage to save node states across multiple invocations. Key dependencies include 'Channel' for graph communication, 'Pregel' for graph setup, and 'MemorySaver' for checkpoint management. Checkpoint functionality ensures state consistency across different thread IDs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nit(\"should handle checkpoints correctly\", async () => {\n  const inputPlusTotal = jest.fn(\n    (x: { total: number; input: number }): number => x.total + x.input,\n  );\n\n  const one = Channel.subscribeTo([\"input\"])\n    .join([\"total\"])\n    .pipe(inputPlusTotal)\n    .pipe(Channel.writeTo(\"output\", \"total\"));\n\n  const memory = new MemorySaver();\n\n  const app = new Pregel({\n    nodes: { one },\n    channels: { total: new BinaryOperatorAggregate<number>((a, b) => a + b) },\n    checkpointer: memory,\n  });\n\n  // Invocation 1\n  await expect(\n    app.invoke(2, { configurable: { thread_id: \"1\" } }),\n  ).resolves.toBe(2);\n  let checkpoint = memory.get({ configurable: { thread_id: \"1\" } });\n  expect(checkpoint).not.toBeNull();\n  expect(checkpoint?.channelValues.total).toBe(2);\n\n  // Invocation 2\n  await expect(\n    app.invoke(3, { configurable: { thread_id: \"1\" } }),\n  ).resolves.toBe(5);\n  checkpoint = memory.get({ configurable: { thread_id: \"1\" } });\n  expect(checkpoint?.channelValues.total).toBe(7);\n\n  // Invocation 3\n  await expect(\n    app.invoke(5, { configurable: { thread_id: \"2\" } }),\n  ).resolves.toBe(5);\n  checkpoint = memory.get({ configurable: { thread_id: \"2\" } });\n  expect(checkpoint?.channelValues.total).toBe(5);\n  checkpoint = memory.get({ configurable: { thread_id: \"1\" } });\n  expect(checkpoint?.channelValues.total).toBe(7);\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Control Flow for Message Filtering Agent in LangGraphJS\nDESCRIPTION: This snippet defines the logic for the message filtering agent, determining whether to continue processing messages or end the conversation based on the presence of tool calls in the last message. It also defines the message filtering function and the call model function.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-conversation-history.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nasync function shouldContinueMessageFiltering(state: typeof MessageFilteringAgentState.State): Promise<\"action\" | typeof END> {\n    const lastMessage = state.messages[state.messages.length - 1];\n    // If there is no function call, then we finish\n    if (lastMessage && !(lastMessage as AIMessage).tool_calls?.length) {\n        return END;\n    }\n    // Otherwise if there is, we continue\n    return \"action\";\n}\n\nconst filterMessages = (messages: BaseMessage[]): BaseMessage[] => {\n  // This is very simple helper function which only ever uses the last message\n  return messages.slice(-1);\n}\n\n// Define the function that calls the model\nasync function callModelMessageFiltering(state: typeof MessageFilteringAgentState.State) {\n  const response = await boundMessageFilteringModel.invoke(filterMessages(state.messages));\n  // We return an object, because this will get merged with the existing state\n  return { messages: [response] };\n}\n```\n\n----------------------------------------\n\nTITLE: Editing Tool Call Parameters Using Command in LangGraph.js\nDESCRIPTION: Demonstrates how to edit a tool call by sending a Command with an \"update\" action. This combines the existing tool call with new parameters, updates the AI message, and continues execution with the modified tool call.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nfor await (const event of await graph.stream(\n  new Command({\n    resume: {\n      action: \"update\",\n      data: { city: \"San Francisco\" }\n    }\n  }),\n  config\n)) {\n  const recentMsg = event.messages[event.messages.length - 1];\n  console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n  console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Invoking Multi-Agent Workflow Graph in JavaScript\nDESCRIPTION: This snippet shows how to invoke the compiled graph with a human message input. It includes streaming results, prettifying output, and logging the results of each step in the workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nconst streamResults = await graph.stream(\n  {\n    messages: [\n      new HumanMessage({\n        content: \"Generate a bar chart of the US gdp over the past 3 years.\",\n      }),\n    ],\n  },\n  { recursionLimit: 150 },\n);\n\nconst prettifyOutput = (output: Record<string, any>) => {\n  const keys = Object.keys(output);\n  const firstItem = output[keys[0]];\n\n  if (\"messages\" in firstItem && Array.isArray(firstItem.messages)) {\n    const lastMessage = firstItem.messages[firstItem.messages.length - 1];\n    console.dir({\n      type: lastMessage._getType(),\n      content: lastMessage.content,\n      tool_calls: lastMessage.tool_calls,\n    }, { depth: null });\n  }\n\n  if (\"sender\" in firstItem) {\n    console.log({\n      sender: firstItem.sender,\n    })\n  }\n}\n\nfor await (const output of await streamResults) {\n  if (!output?.__end__) {\n    prettifyOutput(output);\n    console.log(\"----\");\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing State Annotation for Graph in JavaScript\nDESCRIPTION: This snippet sets up a state annotation using LangGraph's Annotation utility. It creates a root annotation that contains a message reducer, intended to handle state updates throughout the graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-values.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst StateAnnotation = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Using Pre-built REACT Agent in LangGraph\nDESCRIPTION: This code demonstrates how to create an agent using LangGraph's pre-built createReactAgent function. It provides a simplified approach for implementing a REACT-style agent by passing in an LLM and tools.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_17\n\nLANGUAGE: ts\nCODE:\n```\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\n// Pass in:\n// (1) an LLM instance\n// (2) the tools list (which is used to create the tool node)\nconst prebuiltAgent = createReactAgent({\n  llm: llmWithTools,\n  tools,\n});\n\n// invoke\nconst result = await prebuiltAgent.invoke({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Add 3 and 4.\",\n    },\n  ],\n});\nconsole.log(result.messages);\n```\n\n----------------------------------------\n\nTITLE: Retrieving Outer Graph State in JavaScript\nDESCRIPTION: This snippet retrieves the state of the outer graph, including subgraph states. It uses the graph's getState method with the subgraphs option set to true.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_16\n\nLANGUAGE: javascript\nCODE:\n```\nconst outerGraphState = await graph.getState({\n  configurable: {\n    thread_id: \"4\",\n  }\n}, { subgraphs: true })\n\nconsole.log(outerGraphState.tasks[0].state);\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Anthropic API\nDESCRIPTION: Setting the Anthropic API key as an environment variable for authentication with Anthropic's services.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nprocess.env.ANTHROPIC_API_KEY = 'your-anthropic-api-key';\n```\n\n----------------------------------------\n\nTITLE: Generating Answers in Self-RAG Graph\nDESCRIPTION: This function generates an answer based on the retrieved documents and the input question. It uses a RAG chain that combines a prompt, the language model, and an output parser to produce the generation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nasync function generate(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---GENERATE---\");\n\n  // Pull in the prompt\n  const prompt = await pull<ChatPromptTemplate>(\"rlm/rag-prompt\");\n  // Construct the RAG chain by piping the prompt, model, and output parser\n  const ragChain = prompt.pipe(model).pipe(new StringOutputParser());\n\n  const generation = await ragChain.invoke({\n    context: formatDocumentsAsString(state.documents),\n    question: state.question,\n  });\n\n  return {\n    generation,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Accepting a Reformatted Tool Call\nDESCRIPTION: Creates a Command to continue with the execution after the tool call has been reformatted based on feedback. This completes the custom tool message workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\n// highlight-next-line\nconst continueCommand = new Command({\n  // highlight-next-line\n  resume: {\n    // highlight-next-line\n    action: \"continue\",\n    // highlight-next-line\n  },\n  // highlight-next-line\n});\n\nconst continueStream = await agent.stream(continueCommand, config3)\n\nfor await (const step of continueStream) {\n  printStep(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Using the ReAct Agent with a User Message\nDESCRIPTION: This code demonstrates how to use the defined ReAct agent with a user message. It includes a helper function to print messages, defines a user message for querying the weather in San Francisco, invokes the agent with the message, and iterates through the stream to print updates from different tasks.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n\"import { BaseMessage, isAIMessage } from \\\"@langchain/core/messages\\\";\\n\\nconst prettyPrintMessage = (message: BaseMessage) => {\\n  console.log(\\\"=\".repeat(30), `${message.getType()} message`, \\\"=\".repeat(30));\\n  console.log(message.content);\\n  if (isAIMessage(message) && message.tool_calls?.length) {\\n    console.log(JSON.stringify(message.tool_calls, null, 2));\\n  }\\n}\\n\\n// Usage example\\nconst userMessage = { role: \\\"user\\\", content: \\\"What's the weather in san francisco?\\\" };\\nconsole.log(userMessage);\\n\\nconst stream = await agent.stream([userMessage]);\\n\\nfor await (const step of stream) {\\n  for (const [taskName, update] of Object.entries(step)) {\\n    const message = update as BaseMessage;\\n    // Only print task updates\\n    if (taskName === \\\"agent\\\") continue;\\n    console.log(`\\n${taskName}:`);\\n    prettyPrintMessage(message);\\n  }\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Defining Annotations for Overall and Node Outputs in JavaScript\nDESCRIPTION: This snippet defines the overall state annotations and the specific output annotations for the nodes that handle query generation and document retrieval. It sets up the structure required for managing private states among nodes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/pass_private_state.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Annotation, StateGraph } from \"@langchain/langgraph\";\n\n// The overall state of the graph\nconst OverallStateAnnotation = Annotation.Root({\n  question: Annotation<string>,\n  answer: Annotation<string>,\n});\n\n// This is what the node that generates the query will return\nconst QueryOutputAnnotation = Annotation.Root({\n  query: Annotation<string>,\n});\n\n// This is what the node that retrieves the documents will return\nconst DocumentOutputAnnotation = Annotation.Root({\n  docs: Annotation<string[]>,\n});\n\n// This is what the node that retrieves the documents will return\nconst GenerateOutputAnnotation = Annotation.Root({\n  ...OverallStateAnnotation.spec,\n  ...DocumentOutputAnnotation.spec\n});\n```\n\n----------------------------------------\n\nTITLE: Advanced Tool Implementation with Fallback Strategy\nDESCRIPTION: Implements an enhanced haiku generator with fallback to a more capable model (Claude-3-Sonnet) and message cleanup functionality when initial attempts fail.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling-errors.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AIMessage, ToolMessage, RemoveMessage } from \"@langchain/core/messages\";\n\nconst haikuRequestSchema2 = z.object({\n  topic: z.array(z.string()).length(3),\n});\n\nconst masterHaikuGenerator2 = tool(async ({ topic }) => {\n  const model = new ChatAnthropic({\n    model: \"claude-3-haiku-20240307\",\n    temperature: 0,\n  });\n  const chain = model.pipe(new StringOutputParser());\n  const topics = topic.join(\", \");\n  const haiku = await chain.invoke(`Write a haiku about ${topics}`);\n  return haiku;\n}, {\n  name: \"master_haiku_generator\",\n  description: \"Generates a haiku based on the provided topics.\",\n  schema: haikuRequestSchema2,\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using PostgreSQL Checkpoint Saver in TypeScript\nDESCRIPTION: Demonstrates how to initialize and use the PostgresSaver class for checkpoint management. Shows configuration setup, storing checkpoints, loading checkpoints, and listing all checkpoints from the database.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint-postgres/README.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { PostgresSaver } from \"@langchain/langgraph-checkpoint-postgres\";\n\nconst writeConfig = {\n  configurable: {\n    thread_id: \"1\",\n    checkpoint_ns: \"\"\n  }\n};\nconst readConfig = {\n  configurable: {\n    thread_id: \"1\"\n  }\n};\n\n// you can optionally pass a configuration object as the second parameter\nconst checkpointer = PostgresSaver.fromConnString(\"postgresql://...\", {\n  schema: \"schema_name\" // defaults to \"public\"\n});\n\n// You must call .setup() the first time you use the checkpointer:\nawait checkpointer.setup();\n\nconst checkpoint = {\n  v: 1,\n  ts: \"2024-07-31T20:14:19.804150+00:00\",\n  id: \"1ef4f797-8335-6428-8001-8a1503f9b875\",\n  channel_values: {\n    my_key: \"meow\",\n    node: \"node\"\n  },\n  channel_versions: {\n    __start__: 2,\n    my_key: 3,\n    \"start:node\": 3,\n    node: 3\n  },\n  versions_seen: {\n    __input__: {},\n    __start__: {\n      __start__: 1\n    },\n    node: {\n      \"start:node\": 2\n    }\n  },\n  pending_sends: [],\n}\n\n// store checkpoint\nawait checkpointer.put(writeConfig, checkpoint, {}, {});\n\n// load checkpoint\nawait checkpointer.get(readConfig);\n\n// list checkpoints\nfor await (const checkpoint of checkpointer.list(readConfig)) {\n  console.log(checkpoint);\n}\n```\n\n----------------------------------------\n\nTITLE: Testing API with JavaScript SDK\nDESCRIPTION: JavaScript code to test the LangGraph API using the JavaScript SDK. It sends a message to the assistant and streams the response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/langgraph-platform/local-server.md#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nconst { Client } = await import(\"@langchain/langgraph-sdk\");\n\n// only set the apiUrl if you changed the default port when calling langgraph dev\nconst client = new Client({ apiUrl: \"http://localhost:2024\"});\n\nconst streamResponse = client.runs.stream(\n    null, // Threadless run\n    \"agent\", // Assistant ID\n    {\n        input: {\n            \"messages\": [\n                { \"role\": \"user\", \"content\": \"What is LangGraph?\"}\n            ]\n        },\n        streamMode: \"messages\",\n    }\n);\n\nfor await (const chunk of streamResponse) {\n    console.log(`Receiving new event of type: ${chunk.event}...`);\n    console.log(JSON.stringify(chunk.data));\n    console.log(\"\\n\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Creating ToolNode for LangGraphJS ReAct Agent\nDESCRIPTION: This code creates a ToolNode, which is a prebuilt node that takes a LangChain chat model's generated tool call and executes that tool, returning the output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamically-returning-directly.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst toolNode = new ToolNode(tools);\n```\n\n----------------------------------------\n\nTITLE: Creating and Running a Basic LangGraph CUA Agent\nDESCRIPTION: Complete example showing how to initialize and run a LangGraph CUA agent with system and user messages, including streaming output processing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport \"dotenv/config\";\nimport { createCua } from \"@langchain/langgraph-cua\";\n\nconst cuaGraph = createCua();\n\n// Define the input messages\nconst messages = [\n  {\n    role: \"system\",\n    content:\n      \"You're an advanced AI computer use assistant. The browser you are using \" +\n      \"is already initialized, and visiting google.com.\",\n  },\n  {\n    role: \"user\",\n    content:\n      \"I want to contribute to the LangGraph.js project. Please find the GitHub repository, and inspect the read me, \" +\n      \"along with some of the issues and open pull requests. Then, report back with a plan of action to contribute.\",\n  },\n];\n\nasync function main() {\n  // Stream the graph execution\n  const stream = await cuaGraph.stream(\n    { messages },\n    {\n      streamMode: \"updates\",\n      subgraphs: true,\n    }\n  );\n\n  // Process the stream updates\n  for await (const update of stream) {\n    console.log(update);\n  }\n\n  console.log(\"Done\");\n}\n\nmain().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Initializing Parent Graph in LangGraph.js\nDESCRIPTION: This snippet initializes a parent graph using LangGraph.js, incorporating nodes for routing, LLM interaction, and a subgraph. It defines edges to connect these nodes and compiles the graph without a checkpointer for use as a subgraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nconst parentGraph = new StateGraph(RouterStateAnnotation)\n  .addNode(\"routerNode\", routerNode)\n  .addNode(\"normalLLMNode\", normalLLMNode)\n  .addNode(\"weatherGraph\", subgraph)\n  .addEdge(\"__start__\", \"routerNode\")\n  .addConditionalEdges(\"routerNode\", routeAfterPrediction)\n  .addEdge(\"normalLLMNode\", \"__end__\")\n  .addEdge(\"weatherGraph\", \"__end__\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Technical Support Node\nDESCRIPTION: This snippet defines the `technicalSupport` node, simulating a technical support specialist. It uses a system template to guide the response, addressing technical computer issues. It returns the technical support representative's response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n\"const technicalSupport = async (state: typeof StateAnnotation.State) => {\\n  const SYSTEM_TEMPLATE =\\n    `You are an expert at diagnosing technical computer issues. You work for a company called LangCorp that sells computers.\\nHelp the user to the best of your ability, but be concise in your responses.`;\\n\\n  let trimmedHistory = state.messages;\\n  // Make the user's question the most recent message in the history.\\n  // This helps small models stay focused.\\n  if (trimmedHistory.at(-1)._getType() === \\\"ai\\\") {\\n    trimmedHistory = trimmedHistory.slice(0, -1);\\n  }\\n\\n  const response = await model.invoke([\\n    {\\n      role: \\\"system\\\",\\n      content: SYSTEM_TEMPLATE,\\n    },\\n    ...trimmedHistory,\\n  ]);\\n\\n  return {\\n    messages: response,\\n  };\\n};\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Handoff Tool for LangGraph Multi-Agent Swarm\nDESCRIPTION: TypeScript code demonstrating how to create a custom handoff tool for a multi-agent swarm, including customization of tool name, description, and data passed during handoffs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-swarm/README.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\nimport { BaseMessage, ToolMessage } from \"@langchain/core/messages\";\nimport { tool } from \"@langchain/core/tools\";\nimport { Command, getCurrentTaskInput } from \"@langchain/langgraph\";\n\nconst createCustomHandoffTool = ({\n  agentName,\n  toolName,\n  toolDescription,\n}: {\n  agentName: string;\n  toolName: string;\n  toolDescription: string;\n}) => {\n\n  const handoffTool = tool(\n    async (args, config) => {\n      const toolMessage = new ToolMessage({\n        content: `Successfully transferred to ${agentName}`,\n        name: toolName,\n        tool_call_id: config.toolCall.id,\n      });\n\n      // you can use a different messages state key here, if your agent uses a different schema\n      // e.g., \"alice_messages\" instead of \"messages\"\n      // see this how-to guide for more details: \n      // https://langchain-ai.github.io/langgraphjs/how-tos/pass-run-time-values-to-tools/\n      const { messages } = (getCurrentTaskInput() as { messages: BaseMessage[] });\n      const lastAgentMessage = messages[messages.length - 1];\n      return new Command({\n        goto: agentName,\n        graph: Command.PARENT,\n        // NOTE: this is a state update that will be applied to the swarm multi-agent graph (i.e., the PARENT graph)\n        update: {\n          messages: [lastAgentMessage, toolMessage],\n          activeAgent: agentName,\n          // optionally pass the task description to the next agent\n          taskDescription: args.taskDescription,\n        },\n      });\n    },\n    {\n      name: toolName,\n      schema: z.object({\n        // you can add additional tool call arguments for the LLM to populate\n        // for example, you can ask the LLM to populate a task description for the next agent\n        taskDescription: z.string().describe(\"Detailed description of what the next agent should do, including all of the relevant context\")\n      }),\n      description: toolDescription,\n    }\n  );\n\n  return handoffTool;\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Memory with LangGraph Runnable Config\nDESCRIPTION: Illustrates the process of updating user memory in a particular graph node using the configuration passed during graph execution. Shows how to namespace and store memory data with unique identifiers extracted from the configuration objects.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_13\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport {\n  type LangGraphRunnableConfig,\n  MessagesAnnotation,\n} from \"@langchain/langgraph\";\n\nconst updateMemory = async (\n  state: typeof MessagesAnnotation.State,\n  config: LangGraphRunnableConfig\n) => {\n  const store = config.store;\n  const userId = config.configurable.user_id;\n  const namespace = [userId, \"memories\"];\n  \n  // ... Analyze conversation and create a new memory\n  \n  const memoryId = uuid4();\n  \n  await store.put(namespace, memoryId, { memory });\n};\n```\n\n----------------------------------------\n\nTITLE: Creating a Connection Pool with Node-Postgres in Python-like Syntax\nDESCRIPTION: This snippet demonstrates the use of the `pg` package in Node.js to create a connection pool for a Postgres instance and configure the `PostgresSaver`. It includes setting up a checkpointer and invoking a graph with a pre-defined configuration, catering to persistent state management within LangGraph.js applications.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-postgres.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { PostgresSaver } from \"@langchain/langgraph-checkpoint-postgres\";\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\nimport pg from \"pg\";\n\nconst { Pool } = pg;\n\nconst pool = new Pool({\n  connectionString: \"postgresql://user:password@localhost:5434/testdb\"\n});\n\nconst checkpointer = new PostgresSaver(pool);\n\n// NOTE: you need to call .setup() the first time you're using your checkpointer\n\nawait checkpointer.setup();\n\nconst graph = createReactAgent({\n  tools: [getWeather],\n  llm: new ChatOpenAI({\n    model: \"gpt-4o-mini\",\n  }),\n  checkpointSaver: checkpointer,\n});\nconst config = { configurable: { thread_id: \"1\" } };\n\nawait graph.invoke({\n  messages: [{\n    role: \"user\",\n    content: \"what's the weather in sf\"\n  }],\n}, config);\n```\n\nLANGUAGE: python\nCODE:\n```\nawait checkpointer.get(config);\n```\n\n----------------------------------------\n\nTITLE: Defining a Workflow with Chat Model - TypeScript\nDESCRIPTION: This snippet defines a LangGraph workflow that utilizes a chat model to process messages while managing user memories stored in the InMemoryStore, demonstrating advanced memory querying and updating functionalities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence-functional.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { v4 } from \"uuid\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport {\n  entrypoint,\n  task,\n  MemorySaver,\n  addMessages,\n  type BaseStore,\n  getStore,\n} from \"@langchain/langgraph\";\nimport type { BaseMessage, BaseMessageLike } from \"@langchain/core/messages\";\n\nconst model = new ChatAnthropic({\n  model: \"claude-3-5-sonnet-latest\",\n});\n\nconst callModel = task(\"callModel\", async (\n  messages: BaseMessage[],\n  memoryStore: BaseStore,\n  userId: string\n) => {\n  const namespace = [\"memories\", userId];\n  const lastMessage = messages.at(-1);\n  if (typeof lastMessage?.content !== \"string\") {\n    throw new Error(\"Received non-string message content.\");\n  }\n  const memories = await memoryStore.search(namespace, {\n    query: lastMessage.content,\n  });\n  const info = memories.map((memory) => memory.value.data).join(\"\\n\");\n  const systemMessage = `You are a helpful assistant talking to the user. User info: ${info}`;\n  \n  // Store new memories if the user asks the model to remember\n  if (lastMessage.content.toLowerCase().includes(\"remember\")) {\n    // Hard-coded for demo\n    const memory = `Username is Bob`;\n    await memoryStore.put(namespace, v4(), { data: memory });\n  }\n  const response = await model.invoke([\n    {\n      role: \"system\",\n      content: systemMessage \n    },\n    ...messages\n  ]);\n  return response;\n});\n\n// NOTE: we're passing the store object here when creating a workflow via entrypoint()\nconst workflow = entrypoint({\n  checkpointer: new MemorySaver(),\n  store: inMemoryStore,\n  name: \"workflow\",\n}, async (params: {\n  messages: BaseMessageLike[];\n  userId: string;\n}, config) => {\n  const messages = addMessages([], params.messages)\n  const response = await callModel(messages, config.store, params.userId);\n  return entrypoint.final({\n    value: response,\n    save: addMessages(messages, response),\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Results for US GDP Growth Chart using LangGraph in JavaScript\nDESCRIPTION: This snippet shows how to use a LangGraph to process a query for generating a bar chart of US GDP growth from 2021-2023. It streams the results and logs each output, with a recursion limit of 150.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/agent_supervisor.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nstreamResults = graph.stream(\n  {\n    messages: [\n      new HumanMessage({\n        content: \"Generate a bar chart of the US GDP growth from 2021-2023.\",\n      }),\n    ],\n  },\n  { recursionLimit: 150 },\n);\n\nfor await (const output of await streamResults) {\n  if (!output?.__end__) {\n    console.log(output);\n    console.log(\"----\");\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Graph as Mermaid Diagram in TypeScript\nDESCRIPTION: Demonstrates how to visualize a LangGraph as a Mermaid diagram. This feature is useful for visualizing complex graphs and enhancing debugging capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_19\n\nLANGUAGE: typescript\nCODE:\n```\nconst representation = graph.getGraph();\nconst image = await representation.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\nconst buffer = new Uint8Array(arrayBuffer);\n```\n\n----------------------------------------\n\nTITLE: Initializing StateGraph with Routing Logic in LangGraph.js\nDESCRIPTION: Sets up a workflow graph with planning, tool execution, and solving nodes. Includes routing logic to handle task execution flow and state management using MemorySaver for checkpointing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst _route = (state: typeof GraphState.State) => {\n  console.log(\"---ROUTE TASK---\");\n  const _step = _getCurrentTask(state);\n  if (_step === null) {\n    // We have executed all tasks\n    return \"solve\";\n  }\n  // We are still executing tasks, loop back to the \"tool\" node\n  return \"tool\";\n};\n\nconst workflow = new StateGraph(GraphState)\n  .addNode(\"plan\", getPlan)\n  .addNode(\"tool\", toolExecution)\n  .addNode(\"solve\", solve)\n  .addEdge(\"plan\", \"tool\")\n  .addEdge(\"solve\", END)\n  .addConditionalEdges(\"tool\", _route)\n  .addEdge(START, \"plan\");\n\n// Compile\nconst app = workflow.compile({ checkpointer: new MemorySaver() });\n```\n\n----------------------------------------\n\nTITLE: Implementing Auth States in LangGraph CUA\nDESCRIPTION: Demonstrates how to set up authentication state persistence in LangGraph CUA using an auth state ID.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createCua } from \"@langgraph/cua\";\n\nconst cuaGraph = createCua({ authStateId: \"<your_auth_state_id>\" });\n```\n\n----------------------------------------\n\nTITLE: Building a Simple LangGraph Workflow with Human Review Node in Python\nDESCRIPTION: This Python snippet forms a simple graph that integrates human decision nodes in a LangGraph workflow. It includes tool invocation, LLM calls, and graph visualization. Dependencies include LangGraph-related modules such as MessagesAnnotation, StateGraph, and others for handling AI messages and tool calls.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport {\n  MessagesAnnotation,\n  StateGraph,\n  START,\n  END,\n  MemorySaver,\n  Command,\n  interrupt\n} from \"@langchain/langgraph\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { tool } from '@langchain/core/tools';\nimport { z } from 'zod';\nimport { AIMessage, ToolMessage } from '@langchain/core/messages';\nimport { ToolCall } from '@langchain/core/messages/tool';\n\nconst weatherSearch = tool((input: { city: string }) => {\n    console.log(\"----\");\n    console.log(`Searching for: ${input.city}`);\n    console.log(\"----\");\n    return \"Sunny!\";\n}, {\n    name: 'weather_search',\n    description: 'Search for the weather',\n    schema: z.object({\n        city: z.string()\n    })\n});\n\nconst model = new ChatAnthropic({ \n    model: \"claude-3-5-sonnet-latest\"\n}).bindTools([weatherSearch]);\n\nconst callLLM = async (state: typeof MessagesAnnotation.State) => {\n    const response = await model.invoke(state.messages);\n    return { messages: [response] };\n};\n\nconst humanReviewNode = async (state: typeof MessagesAnnotation.State): Promise<Command> => {\n    const lastMessage = state.messages[state.messages.length - 1] as AIMessage;\n    const toolCall = lastMessage.tool_calls![lastMessage.tool_calls!.length - 1];\n\n    const humanReview = interrupt<\n      {\n        question: string;\n        toolCall: ToolCall;\n      },\n      {\n        action: string;\n        data: any;\n      }>({\n        question: \"Is this correct?\",\n        toolCall: toolCall\n      });\n\n    const reviewAction = humanReview.action;\n    const reviewData = humanReview.data;\n\n    if (reviewAction === \"continue\") {\n        return new Command({ goto: \"run_tool\" });\n    }\n    else if (reviewAction === \"update\") {\n        const updatedMessage = {\n            role: \"ai\",\n            content: lastMessage.content,\n            tool_calls: [{\n                id: toolCall.id,\n                name: toolCall.name,\n                args: reviewData\n            }],\n            id: lastMessage.id\n        };\n        return new Command({ goto: \"run_tool\", update: { messages: [updatedMessage] } });\n    }\n    else if (reviewAction === \"feedback\") {\n        const toolMessage = new ToolMessage({\n          name: toolCall.name,\n          content: reviewData,\n          tool_call_id: toolCall.id\n        })\n        return new Command({ goto: \"call_llm\", update: { messages: [toolMessage] }});\n    }\n    throw new Error(\"Invalid review action\");\n};\n\nconst runTool = async (state: typeof MessagesAnnotation.State) => {\n    const newMessages: ToolMessage[] = [];\n    const tools = { weather_search: weatherSearch };\n    const lastMessage = state.messages[state.messages.length - 1] as AIMessage;\n    const toolCalls = lastMessage.tool_calls!;\n\n    for (const toolCall of toolCalls) {\n        const tool = tools[toolCall.name as keyof typeof tools];\n        const result = await tool.invoke(toolCall.args);\n        newMessages.push(new ToolMessage({\n            name: toolCall.name,\n            content: result,\n            tool_call_id: toolCall.id\n        }));\n    }\n    return { messages: newMessages };\n};\n\nconst routeAfterLLM = (state: typeof MessagesAnnotation.State): typeof END | \"human_review_node\" => {\n    const lastMessage = state.messages[state.messages.length - 1] as AIMessage;\n    if (!lastMessage.tool_calls?.length) {\n        return END;\n    }\n    return \"human_review_node\";\n};\n\nconst workflow = new StateGraph(MessagesAnnotation)\n    .addNode(\"call_llm\", callLLM)\n    .addNode(\"run_tool\", runTool)\n    .addNode(\"human_review_node\", humanReviewNode, {\n      ends: [\"run_tool\", \"call_llm\"]\n    })\n    .addEdge(START, \"call_llm\")\n    .addConditionalEdges(\n        \"call_llm\",\n        routeAfterLLM,\n        [\"human_review_node\", END]\n    )\n    .addEdge(\"run_tool\", \"call_llm\");\n\nconst memory = new MemorySaver();\n\nconst graph = workflow.compile({ checkpointer: memory });\n```\n\n----------------------------------------\n\nTITLE: Defining Schema for Planning Step\nDESCRIPTION: Creates a JSON schema for plan creation using Zod and converts it to a function calling format. This defines the structure for the planning step output, which will be an array of steps.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\nimport { zodToJsonSchema } from \"zod-to-json-schema\";\n\nconst plan = zodToJsonSchema(\n  z.object({\n    steps: z\n      .array(z.string())\n      .describe(\"different steps to follow, should be in sorted order\"),\n  }),\n);\nconst planFunction = {\n  name: \"plan\",\n  description: \"This tool is used to plan the steps to follow\",\n  parameters: plan,\n};\n\nconst planTool = {\n  type: \"function\",\n  function: planFunction,\n};\n```\n\n----------------------------------------\n\nTITLE: Creating and Compiling the StateGraph\nDESCRIPTION: Define and compile the StateGraph, connecting nodes and adding conditional edges for the workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\n\nconst workflow = new StateGraph(AgentState)\n  .addNode(\"agent\", callModel)\n  .addNode(\"action\", callTool)\n  .addEdge(START, \"agent\")\n  .addConditionalEdges(\n    \"agent\",\n    shouldContinue,\n    {\n      continue: \"action\",\n      end: END,\n    },\n  )\n  .addEdge(\"action\", \"agent\");\n\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Creating Team Supervisor in LangGraph.js\nDESCRIPTION: This code defines a team supervisor using `createTeamSupervisor`. The supervisor's LLM is set to `docWritingLlm`. The prompt is designed to manage conversations between workers (`docTeamMembers`). The supervisor's role is to determine which worker should act next based on the user's request. It returns FINISH when the task is complete.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: javascript\nCODE:\n```\nconst docTeamMembers = [\"DocWriter\", \"NoteTaker\", \"ChartGenerator\"];\nconst docWritingSupervisor = await createTeamSupervisor(\n  docWritingLlm,\n  \"You are a supervisor tasked with managing a conversation between the\" +\n    \" following workers:  {team_members}. Given the following user request,\" +\n    \" respond with the worker to act next. Each worker will perform a\" +\n    \" task and respond with their results and status. When finished,\" +\n    \" respond with FINISH.\\n\\n\" +\n    \" Select strategically to minimize the number of steps taken.\",\n  docTeamMembers,\n);\n\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-Agent Workflow with Active Agent Router in TypeScript\nDESCRIPTION: Demonstrates how to set up a multi-agent workflow using StateGraph and configure an active agent router. Shows the connection between different agents and workflow compilation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-swarm/README.md#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { addActiveAgentRouter } from \"@langchain/langgraph-swarm\";\n\nlet workflow = (\n    new StateGraph(SwarmState)\n    .addNode(\"Alice\", callAlice, { ends: [\"Bob\"] })\n    .addNode(\"Bob\", callBob, { ends: [\"Alice\"] })\n)\n// this is the router that enables us to keep track of the last active agent\nworkflow = addActiveAgentRouter(workflow, {\n    routeTo: [\"Alice\", \"Bob\"],\n    defaultActiveAgent: \"Alice\",\n})\n\n// compile the workflow\nconst app = workflow.compile()\n```\n\n----------------------------------------\n\nTITLE: Defining State Annotations in LangGraph with TypeScript\nDESCRIPTION: Illustrates how to define comprehensive input, output, and overall state annotations within a LangGraph graph. Nodes can update or read from these annotations, demonstrating how multiple states are managed internally and externally.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport {\n  Annotation,\n  START,\n  StateGraph,\n  StateType,\n  UpdateType,\n} from \"@langchain/langgraph\";\n\nconst InputStateAnnotation = Annotation.Root({\n  user_input: Annotation<string>,\n});\n\nconst OutputStateAnnotation = Annotation.Root({\n  graph_output: Annotation<string>,\n});\n\nconst OverallStateAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n  bar: Annotation<string>,\n  user_input: Annotation<string>,\n  graph_output: Annotation<string>,\n});\n\nconst node1 = async (state: typeof InputStateAnnotation.State) => {\n  // Write to OverallStateAnnotation\n  return { foo: state.user_input + \" name\" };\n};\n\nconst node2 = async (state: typeof OverallStateAnnotation.State) => {\n  // Read from OverallStateAnnotation, write to OverallStateAnnotation\n  return { bar: state.foo + \" is\" };\n};\n\nconst node3 = async (state: typeof OverallStateAnnotation.State) => {\n  // Read from OverallStateAnnotation, write to OutputStateAnnotation\n  return { graph_output: state.bar + \" Lance\" };\n};\n\n// Most of the time the StateGraph type parameters are inferred by TypeScript,\n// but this is a special case where they must be specified explicitly in order\n// to avoid a type error.\nconst graph = new StateGraph<\n  typeof OverallStateAnnotation[\"spec\"],\n  StateType<typeof OverallStateAnnotation[\"spec\"]>,\n  UpdateType<typeof OutputStateAnnotation[\"spec\"]>,\n  typeof START,\n  typeof InputStateAnnotation[\"spec\"],\n  typeof OutputStateAnnotation[\"spec\"]\n>({\n  input: InputStateAnnotation,\n  output: OutputStateAnnotation,\n  stateSchema: OverallStateAnnotation,\n})\n  .addNode(\"node1\", node1)\n  .addNode(\"node2\", node2)\n  .addNode(\"node3\", node3)\n  .addEdge(\"__start__\", \"node1\")\n  .addEdge(\"node1\", \"node2\")\n  .addEdge(\"node2\", \"node3\")\n  .compile();\n\nawait graph.invoke({ user_input: \"My\" });\n```\n\n----------------------------------------\n\nTITLE: Providing Feedback to Tool Call Using Command in LangGraph.js\nDESCRIPTION: Shows how to provide natural language feedback to a tool call using a Command with a \"feedback\" action. This creates a new tool message combining the existing call with user feedback and routes execution back to the LLM for a revised tool call.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nfor await (const event of await graph.stream(\n  new Command({\n    resume: {\n      action: \"feedback\",\n      data: \"User requested changes: use <city, country> format for location\"\n    }\n  }),\n  config\n)) {\n  const recentMsg = event.messages[event.messages.length - 1];\n  console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n  console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Replaying a Prior Graph Execution with Checkpoint ID in TypeScript\nDESCRIPTION: This snippet illustrates how to replay a graph from a specified checkpoint by providing both the `thread_id` and `checkpoint_id` in the configuration. This enables users to reproduce past executions of the graph based on saved states.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = { configurable: { thread_id: \"1\" } };\nawait graph.invoke(inputs, config);\n// Additionally, the checkpoint_id can be included to replay from a specific checkpoint.\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Tools for LangGraph Tool Calling\nDESCRIPTION: Creating two custom tools with Zod schemas: one for fetching weather information based on location and another for retrieving a list of cool cities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tool } from '@langchain/core/tools';\nimport { z } from 'zod';\n\nconst getWeather = tool((input) => {\n  if (['sf', 'san francisco'].includes(input.location.toLowerCase())) {\n    return 'It\\'s 60 degrees and foggy.';\n  } else {\n    return 'It\\'s 90 degrees and sunny.';\n  }\n}, {\n  name: 'get_weather',\n  description: 'Call to get the current weather.',\n  schema: z.object({\n    location: z.string().describe(\"Location to get the weather for.\"),\n  })\n})\n\nconst getCoolestCities = tool(() => {\n  return 'nyc, sf';\n}, {\n  name: 'get_coolest_cities',\n  description: 'Get a list of coolest cities',\n  schema: z.object({\n    noOp: z.string().optional().describe(\"No-op parameter.\"),\n  })\n})\n```\n\n----------------------------------------\n\nTITLE: Setting up Document Retrieval System with LangChain\nDESCRIPTION: Creates a document retrieval system by loading web content from specified URLs, splitting the text into chunks, and initializing a vector store with OpenAI embeddings for later retrieval.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { CheerioWebBaseLoader } from \"@langchain/community/document_loaders/web/cheerio\";\nimport { RecursiveCharacterTextSplitter } from \"@langchain/textsplitters\";\nimport { MemoryVectorStore } from \"langchain/vectorstores/memory\";\nimport { OpenAIEmbeddings } from \"@langchain/openai\";\n\nconst urls = [\n  \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n  \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n  \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n];\n\nconst docs = await Promise.all(\n  urls.map((url) => new CheerioWebBaseLoader(url).load()),\n);\nconst docsList = docs.flat();\n\nconst textSplitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 500,\n  chunkOverlap: 250,\n});\nconst docSplits = await textSplitter.splitDocuments(docsList);\n\n// Add to vectorDB\nconst vectorStore = await MemoryVectorStore.fromDocuments(\n  docSplits,\n  new OpenAIEmbeddings({ model: \"text-embedding-3-large\" }),\n);\nconst retriever = vectorStore.asRetriever();\n```\n\n----------------------------------------\n\nTITLE: Creating an InMemoryStore - TypeScript\nDESCRIPTION: This snippet demonstrates how to create an instance of InMemoryStore for persisting data across threads in LangGraph applications. It utilizes the functional API to set up the store that allows for storing and retrieving memories.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence-functional.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\nconst store = new InMemoryStore();\n```\n\n----------------------------------------\n\nTITLE: Resuming Interrupted Graph Execution with Command in LangGraph\nDESCRIPTION: Code showing how to resume a paused graph execution by providing user input through a Command.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Command } from \"@langchain/langgraph\";\n\nconst resumeStream = await graph.stream(new Command({\n  resume: \"baz\"\n}), config);\n\n// Continue execution\nfor await (const event of resumeStream) {\n  if (event.__metadata__?.cached) {\n    continue;\n  }\n  console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Graph State Structure\nDESCRIPTION: Creates a state management structure for the graph using annotations to handle documents, questions, and generation outputs\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_crag.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { DocumentInterface } from \"@langchain/core/documents\";\n\n// Represents the state of our graph.\nconst GraphState = Annotation.Root({\n  documents: Annotation<DocumentInterface[]>({\n    reducer: (x, y) => y ?? x ?? [],\n  }),\n  question: Annotation<string>({\n    reducer: (x, y) => y ?? x ?? \"\",\n  }),\n  generation: Annotation<string>({\n    reducer: (x, y) => y ?? x,\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Termination Conditions in State Graphs - TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to implement a termination condition in a state graph using a conditional edge. The function returns '__END__' to terminate the loop based on a specified condition. Dependencies include a state graph and a condition implementation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/recursion-limit.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst route = async function (state: typeof StateAnnotation.State) {\n  if (terminationCondition(state)) {\n    return \"__END__\";\n  } else {\n    return \"a\";\n  }\n}\n\nconst graph = StateGraph(State)\n  .addNode(a)\n  .addNode(b)\n  .addConditionalEdges(\"a\", route)\n  .addEdge(\"b\", \"a\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Creating a Search Tool for LangGraph Agent\nDESCRIPTION: Definition of a search tool using LangChain's tool function with Zod schema validation. The tool provides a placeholder implementation for searching information like weather data.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst searchTool = tool(async (_) => {\n  // This is a placeholder for the actual implementation\n  return \"Cold, with a low of 13 ℃\";\n}, {\n  name: \"search\",\n  description:\n    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n});\n\nawait searchTool.invoke({ query: \"What's the weather like?\" });\n\nconst tools = [searchTool];\n```\n\n----------------------------------------\n\nTITLE: Implementing Instruction Updates with LangGraph Store\nDESCRIPTION: Demonstrates how to implement dynamic instruction updates using LangGraph's memory store. Shows two key nodes: one for using stored instructions and another for updating them based on conversation context using OpenAI's chat model.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/memory.md#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { BaseStore } from \"@langchain/langgraph/store\";\nimport { State } from \"@langchain/langgraph\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\n// Node that *uses* the instructions\nconst callModel = async (state: State, store: BaseStore) => {\n  const namespace = [\"agent_instructions\"];\n  const instructions = await store.get(namespace, \"agent_a\");\n  // Application logic\n  const prompt = promptTemplate.format({\n    instructions: instructions[0].value.instructions,\n  });\n  // ... rest of the logic\n};\n\n// Node that updates instructions\nconst updateInstructions = async (state: State, store: BaseStore) => {\n  const namespace = [\"instructions\"];\n  const currentInstructions = await store.search(namespace);\n  // Memory logic\n  const prompt = promptTemplate.format({\n    instructions: currentInstructions[0].value.instructions,\n    conversation: state.messages,\n  });\n  const llm = new ChatOpenAI();\n  const output = await llm.invoke(prompt);\n  const newInstructions = output.content; // Assuming the LLM returns the new instructions\n  await store.put([\"agent_instructions\"], \"agent_a\", {\n    instructions: newInstructions,\n  });\n  // ... rest of the logic\n};\n```\n\n----------------------------------------\n\nTITLE: Visualizing the Runnable Graph - JavaScript\nDESCRIPTION: This snippet illustrates how to visualize the compiled agent graph using tslab for drawing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst runnableGraph = agent.getGraph();\nconst image = await runnableGraph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Defining the Chat Bot Node for LangGraph\nDESCRIPTION: Creates a node for the LangGraph workflow that processes messages from the state and invokes the chat bot to generate a response, returning the new message to be added to the state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { MessagesAnnotation } from \"@langchain/langgraph\";\n\nasync function chatBotNode (state: typeof MessagesAnnotation.State) {\n  const messages = state.messages\n  const chatBotResponse = await myChatBot(messages);\n  return { messages: [chatBotResponse] }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Agent State and Wrapper in TypeScript\nDESCRIPTION: Shows how to create a custom state annotation for an agent named Alice with isolated message handling, and implement a wrapper function to transform between parent and child agent states. Includes state schema definition and agent initialization.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-swarm/README.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { Annotation, StateGraph, messagesStateReducer } from \"@langchain/langgraph\";\n\nexport const AliceStateAnnotation = Annotation.Root({\n  alice_messages: Annotation<BaseMessage[]>({\n    reducer: messagesStateReducer,\n    default: () => [],\n  }),\n});\nimport { SwarmState } from \"@langchain/langgraph-swarm\";\n\n// see this guide to learn how you can implement a custom tool-calling agent\n// https://langchain-ai.github.io/langgraphjs/how-tos/react-agent-from-scratch/\nconst alice = (\n    new StateGraph(AliceStateAnnotation)\n    .addNode(\"model\", ...)\n    .addNode(\"tools\", ...)\n    .addEdge(...)\n    ...\n    .compile()\n)\n\n// wrapper calling the agent\nconst callAlice = async (state: typeof SwarmState.State) => {\n    // you can put any input transformation from parent state -> agent state\n    // for example, you can invoke \"alice\" with \"task_description\" populated by the LLM\n    const response = await alice.invoke({\"alice_messages\": state[\"messages\"]})\n    // you can put any output transformation from agent state -> parent state\n    return { \"messages\": response.alice_messages }\n}\n\nconst callBob = async (state: typeof SwarmState.State) => {\n    ...\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Supervisor Architecture in Multi-agent LangGraphJS\nDESCRIPTION: Demonstrates a supervisor architecture where a central supervisor agent decides which specialized agent to call next based on the current state. Each agent reports back to the supervisor after completing its task.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/multi_agent.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  StateGraph,\n  MessagesAnnotation,\n  Command,\n} from \"@langchain/langgraph\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o-mini\",\n});\n\nconst supervisor = async (state: typeof MessagesAnnotation.State) => {\n  // you can pass relevant parts of the state to the LLM (e.g., state.messages)\n  // to determine which agent to call next. a common pattern is to call the model\n  // with a structured output (e.g. force it to return an output with a \"next_agent\" field)\n  const response = await model.withStructuredOutput(...).invoke(...);\n  // route to one of the agents or exit based on the supervisor's decision\n  // if the supervisor returns \"__end__\", the graph will finish execution\n  return new Command({\n    goto: response.next_agent,\n  });\n};\n\nconst agent1 = async (state: typeof MessagesAnnotation.State) => {\n  // you can pass relevant parts of the state to the LLM (e.g., state.messages)\n  // and add any additional logic (different models, custom prompts, structured output, etc.)\n  const response = await model.invoke(...);\n  return new Command({\n    goto: \"supervisor\",\n    update: {\n      messages: [response],\n    },\n  });\n};\n\nconst agent2 = async (state: typeof MessagesAnnotation.State) => {\n  const response = await model.invoke(...);\n  return new Command({\n    goto: \"supervisor\",\n    update: {\n      messages: [response],\n    },\n  });\n};\n\nconst graph = new StateGraph(MessagesAnnotation)\n  .addNode(\"supervisor\", supervisor, {\n    ends: [\"agent1\", \"agent2\", \"__end__\"],\n  })\n  .addNode(\"agent1\", agent1, {\n    ends: [\"supervisor\"],\n  })\n  .addNode(\"agent2\", agent2, {\n    ends: [\"supervisor\"],\n  })\n  .addEdge(\"__start__\", \"supervisor\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Retrieving Previous State in TypeScript\nDESCRIPTION: This code snippet shows how to retrieve the previous state using the getPreviousState function in a LangGraph workflow. It is essential for maintaining the context across execution in the workflow logic.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { entrypoint, getPreviousState } from \"@langchain/langgraph\";\n\nconst workflow = entrypoint({\n  name: \"workflow\",\n  checkpointer,\n}, async (inputs) => {\n  const previous = getPreviousState();\n  const result = doSomething(previous, inputs);\n  ...\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Multiple Types of Chunks with LangGraph\nDESCRIPTION: This code demonstrates how to stream multiple types of chunks, such as 'updates' and 'debug' information, from a LangGraph agent. It passes an array of values under the `streamMode` key to the `.stream()` method and then iterates through the stream, logging the received events.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-multiple.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nlet inputs = { messages: [{ role: \"user\", content: \"what's the weather in sf?\" }] };\n\nlet stream = await graph.stream(inputs, {\n  streamMode: [\"updates\", \"debug\"],\n});\n\nfor await (const chunk of stream) {\n  console.log(`Receiving new event of type: ${chunk[0]}`);\n  console.log(chunk[1]);\n  console.log(\"\\n====\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Invoking the Graph with User Input in TypeScript\nDESCRIPTION: This code snippet demonstrates how to initiate the graph with user input to obtain travel recommendations. It shows how to stream responses back from the first agent. The input format expects user messages encapsulated in an array.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst simpleStream = await graph.stream({\n  messages: [{\n    role: \"user\",\n    content: \"i wanna go somewhere warm in the caribbean\",\n  }],\n});\n\nfor await (const chunk of simpleStream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Compiled Subgraph with Shared State Keys in TypeScript\nDESCRIPTION: Illustrates creating and using a subgraph with a state schema that shares at least one key with the parent graph for communication. The shared key allows the graphs to exchange information.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n});\n\nconst SubgraphStateAnnotation = Annotation.Root({\n  foo: Annotation<string>, // note that this key is shared with the parent graph state\n  bar: Annotation<string>,\n});\n\n// Define subgraph\nconst subgraphNode = async (state: typeof SubgraphStateAnnotation.State) => {\n  // note that this subgraph node can communicate with\n  // the parent graph via the shared \"foo\" key\n  return { foo: state.foo + \"bar\" };\n};\n\nconst subgraph = new StateGraph(SubgraphStateAnnotation)\n  .addNode(\"subgraph\", subgraphNode);\n  ...\n  .compile();\n\n// Define parent graph\nconst parentGraph = new StateGraph(StateAnnotation)\n  .addNode(\"subgraph\", subgraph)\n  ...\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Streaming Node Output\nDESCRIPTION: Example of how to stream output from the workflow as it's produced by each node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nfor await (const output of await app.stream(inputs)) {\n  console.log(\"output\", output);\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Invoking the Stable Sorting Graph with Alternative Path\nDESCRIPTION: Second example of invoking the stable sorting graph with a different path selection to demonstrate consistent ordering of results regardless of execution path.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nlet g3result2 = await graph3.invoke({ aggregate: [], which: \"cd\" });\nconsole.log(\"Result 2: \", g3result2);\n\n```\n\n----------------------------------------\n\nTITLE: Adding Node with RetryPolicy in LangGraphJS\nDESCRIPTION: This code snippet demonstrates how to add nodes to a LangGraph `StateGraph` with specific retry policies. One node uses a `maxAttempts` retry configuration, while the other node defines a custom `retryOn` function to retry only on `SQLITE_BUSY` errors. The retry policies are passed to the `addNode` function.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/node-retry-policies.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport Database from \"better-sqlite3\"\nimport { ChatAnthropic } from \"@langchain/anthropic\"\nimport { MessagesAnnotation, StateGraph, START, END } from \"@langchain/langgraph\"\nimport { AIMessage } from \"@langchain/core/messages\"\n\n// Create an in-memory database\nconst db: typeof Database.prototype = new Database(':memory:');\n\nconst model = new ChatAnthropic({ model: \"claude-3-5-sonnet-20240620\" });\n\nconst callModel = async (state: typeof MessagesAnnotation.State) => {\n    const response = await model.invoke(state.messages);\n    return { messages: [response] };\n}\n\nconst queryDatabase = async (state: typeof MessagesAnnotation.State) => {\n    const queryResult: string = JSON.stringify(db.prepare(\"SELECT * FROM Artist LIMIT 10;\").all());\n\n    return { messages: [new AIMessage({content: \"queryResult\"})]};\n};\n\nconst workflow = new StateGraph(MessagesAnnotation)\n    // Define the two nodes we will cycle between\n    .addNode(\"call_model\", callModel, { retryPolicy: {maxAttempts: 5}})\n    .addNode(\"query_database\", queryDatabase, { retryPolicy: { retryOn: (e: any): boolean => {\n        if (e instanceof Database.SqliteError) {\n          // Retry on \"SQLITE_BUSY\" error\n          return e.code === 'SQLITE_BUSY';\n        }\n        return false; // Don't retry on other errors\n      }}})\n    .addEdge(START, \"call_model\")\n    .addEdge(\"call_model\", \"query_database\")\n    .addEdge(\"query_database\", END);\n\nconst graph = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Define graph with conditional control flow using Command\nDESCRIPTION: This snippet shows how to define a `StateGraph` where control flow is determined within a node (`nodeA`) using the `Command` object. The `nodeA` randomly selects the next node (`nodeB` or `nodeC`) and updates the graph state. No conditional edges are defined because the `Command` object controls the routing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/command.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation, Command } from \"@langchain/langgraph\";\n\n// Define graph state\nconst StateAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n});\n\n// Define the nodes\nconst nodeA = async (_state: typeof StateAnnotation.State) => {\n  console.log(\"Called A\");\n  // this is a replacement for a real conditional edge function\n  const goto = Math.random() > .5 ? \"nodeB\" : \"nodeC\";\n  // note how Command allows you to BOTH update the graph state AND route to the next node\n  return new Command({\n    // this is the state update\n    update: {\n      foo: \"a\",\n    },\n    // this is a replacement for an edge\n    goto,\n  });\n};\n\n// Nodes B and C are unchanged\nconst nodeB = async (state: typeof StateAnnotation.State) => {\n  console.log(\"Called B\");\n  return {\n    foo: state.foo + \"|b\",\n  };\n}\n\nconst nodeC = async (state: typeof StateAnnotation.State) => {\n  console.log(\"Called C\");\n  return {\n    foo: state.foo + \"|c\",\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Tools and ToolNode for LangGraph Agent\nDESCRIPTION: Sets up the Tavily search tool and initializes a ToolNode that will be responsible for executing tools in the agent workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/agent_executor/base.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst tools = [new TavilySearchResults({ maxResults: 1 })];\n\nconst toolNode = new ToolNode<typeof AgentState.State>(tools);\n```\n\n----------------------------------------\n\nTITLE: Streaming Workflow in LangGraphJS\nDESCRIPTION: This code snippet illustrates how to stream data from a workflow using the 'stream' method. It processes incoming chunks of data asynchronously from the workflow based on the specified input and configuration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = {\n  configurable: {\n    thread_id: \"some_thread_id\",\n  },\n};\n\nfor await (const chunk of await myWorkflow.stream(someInput, config)) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Resuming Graph Execution After Dynamic Breakpoint in TypeScript\nDESCRIPTION: Demonstrates how to resume graph execution after hitting a dynamic breakpoint by updating the graph state to meet the breakpoint condition.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/breakpoints.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Update the state to pass the dynamic breakpoint\nawait graph.updateState({ input: \"foo\" }, threadConfig);\n\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Essay Generation Stream\nDESCRIPTION: Creates a streaming implementation for essay generation using the configured chain\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/reflection/reflection.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AIMessage, BaseMessage, HumanMessage } from \"@langchain/core/messages\";\n\nlet essay = \"\";\nconst request = new HumanMessage({\n  content:\n    \"Write an essay on why the little prince is relevant in modern childhood\",\n});\n\nfor await (\n  const chunk of await essayGenerationChain.stream({\n    messages: [request],\n  })\n) {\n  console.log(chunk.content);\n  essay += chunk.content;\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Tool Error Handling in the ReAct Agent\nDESCRIPTION: Code to test the error handling capability by invoking the state graph with a query that will trigger an error in the weather tool. Shows how the ToolNode captures and handles the error.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling-errors.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconst response = await app.invoke({\n  messages: [\n    { role: \"user\", content: \"what is the weather in san francisco?\"},\n  ]\n});\n\nfor (const message of response.messages) {\n  // Anthropic returns tool calls in content as well as in `AIMessage.tool_calls`\n  const content = JSON.stringify(message.content, null, 2);\n  console.log(`${message._getType().toUpperCase()}: ${content}`);\n}\n```\n\n----------------------------------------\n\nTITLE: Resuming Stream After Updating Tool Call\nDESCRIPTION: This snippet illustrates how to resume streaming the ReAct agent after updating a tool call to a recognized location. It processes messages as before and verifies correct tool functioning.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-human-in-the-loop.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nstream = await agent.stream(null, {\n  ...config,\n  streamMode: \"values\",\n});\n\nfor await (\n  const { messages } of stream\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  }\n  if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  }\n  console.log(\"-----\\n\");\n}\n\n```\n\n----------------------------------------\n\nTITLE: Setting Up ReAct Agent with Memory in Python\nDESCRIPTION: The snippet demonstrates how to import necessary modules and setup a prebuilt ReAct agent using LangGraphJS. It implements a weather tool and establishes in-memory checkpoint saving to enhance interaction capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-memory.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { tool } from '@langchain/core/tools';\nimport { z } from 'zod';\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst model = new ChatOpenAI({\n    model: \"gpt-4o\",\n  });\n\nconst getWeather = tool((input) => {\n    if (input.location === 'sf') {\n        return 'It\\'s always sunny in sf';\n    } else {\n        return 'It might be cloudy in nyc';\n    }\n}, {\n    name: 'get_weather',\n    description: 'Call to get the current weather.',\n    schema: z.object({\n        location: z.enum(['sf','nyc']).describe(\"Location to get the weather for.\"),\n    })\n})\n\n// Here we only save in-memory\nconst memory = new MemorySaver();\n\nconst agent = createReactAgent({ llm: model, tools: [getWeather], checkpointSaver: memory });\n```\n\n----------------------------------------\n\nTITLE: Continuing Conversation with Existing Thread in Python\nDESCRIPTION: This code shows how to resume interaction with the LangGraph workflow, reusing existing contextual information by leveraging the same thread configuration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nconst followupStream = await workflow.stream(\n  [{ role: \"user\", content: \"what's my name?\" }], \n  config,\n);\n\nfor await (const chunk of followupStream) {\n  console.log(\"=\".repeat(30), `${chunk.getType()} message`, \"=\".repeat(30));\n  console.log(chunk.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Custom Data from LangGraph Entrypoint\nDESCRIPTION: Shows how to stream custom data from an entrypoint using the 'write' method on the config object, allowing for writing to both custom and updates streams.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_26\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  entrypoint,\n  task,\n  MemorySaver,\n  LangGraphRunnableConfig,\n} from \"@langchain/langgraph\";\n\nconst addOne = task(\"addOne\", (x: number) => x + 1);\n\nconst addTwo = task(\"addTwo\", (x: number) => x + 2);\n\nconst checkpointer = new MemorySaver();\n\nconst main = entrypoint(\n  { checkpointer, name: \"main\" },\n  async (inputs: { number: number }, config: LangGraphRunnableConfig) => {\n    config.writer?.(\"hello\"); // Write some data to the `custom` stream\n    await addOne(inputs.number); // Will write data to the `updates` stream\n    config.writer?.(\"world\"); // Write some more data to the `custom` stream\n    await addTwo(inputs.number); // Will write data to the `updates` stream\n    return 5;\n  }\n);\n\nconst config = {\n  configurable: {\n    thread_id: \"1\",\n  },\n};\n\nconst stream = await main.stream(\n  { number: 1 },\n  { streamMode: [\"custom\", \"updates\"], ...config }\n);\n\nfor await (const chunk of stream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Message Processing and Graph Invocation in LangGraph.js\nDESCRIPTION: Demonstrates how to process different types of messages (Human, AI, Tool) and invoke a LangGraph instance with configuration. Includes message printing utility and handling of tool calls.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/pass-run-time-values-to-tools.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  BaseMessage,\n  isAIMessage,\n  isHumanMessage,\n  isToolMessage,\n  HumanMessage,\n  ToolMessage,\n} from \"@langchain/core/messages\";\n\nlet inputs = {\n  messages: [ new HumanMessage({ content: \"My favorite pet is a terrier. I saw a cute one on Twitter.\" }) ],\n};\n\nlet config = {\n  configurable: {\n    thread_id: \"1\",\n    userId: \"a-user\",\n  },\n};\n\nfunction printMessages(messages: BaseMessage[]) {\n  for (const message of messages) {\n    if (isHumanMessage(message)) {\n      console.log(`User: ${message.content}`);\n    } else if (isAIMessage(message)) {\n      const aiMessage = message as AIMessage;\n      if (aiMessage.content) {\n        console.log(`Assistant: ${aiMessage.content}`);\n      }\n      if (aiMessage.tool_calls) {\n        for (const toolCall of aiMessage.tool_calls) {\n          console.log(`Tool call: ${toolCall.name}(${JSON.stringify(toolCall.args)})`);\n        }\n      }\n    } else if (isToolMessage(message)) {\n      const toolMessage = message as ToolMessage;\n      console.log(`${toolMessage.name} tool output: ${toolMessage.content}`);\n    }\n  }\n}\n\nlet { messages } = await graph.invoke(inputs, config);\n\nprintMessages(messages);\n```\n\n----------------------------------------\n\nTITLE: Setting Recursion Limit for Graph Execution in TypeScript\nDESCRIPTION: The recursion limit restricts the number of super-steps a graph executes in LangGraphJS. This snippet sets this limit using a configuration parameter, preventing infinite executions or excessive resource consumption.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nawait graph.invoke(inputs, { recursionLimit: 50 });\n```\n\n----------------------------------------\n\nTITLE: Configuring Anthropic Model with Tool Binding for Tool Calling\nDESCRIPTION: Setting up the Anthropic chat model and binding the custom tools to it. This enables the model to understand and generate appropriate tool calls.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatAnthropic } from \"@langchain/anthropic\";\n\nconst modelWithTools = new ChatAnthropic({\n  model: \"claude-3-haiku-20240307\",\n  temperature: 0\n}).bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: Reviewing Tool Calls in TypeScript with LangGraph\nDESCRIPTION: Implements a human review mechanism for tool calls with multiple review actions including continue, update, and feedback modes\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt, Command } from \"@langchain/langgraph\";\n\nfunction humanReviewNode(state: typeof GraphAnnotation.State): Command {\n  const humanReview = interrupt({\n    question: \"Is this correct?\",\n    tool_call: toolCall,\n  });\n\n  const [reviewAction, reviewData] = humanReview;\n\n  if (reviewAction === \"continue\") {\n    return new Command({ goto: \"run_tool\" });\n  }\n  else if (reviewAction === \"update\") {\n    const updatedMsg = getUpdatedMsg(reviewData);\n    return new Command({\n      goto: \"run_tool\",\n      update: { messages: [updatedMsg] },\n    });\n  }\n  else if (reviewAction === \"feedback\") {\n    const feedbackMsg = getFeedbackMsg(reviewData);\n    return new Command({\n      goto: \"call_llm\",\n      update: { messages: [feedbackMsg] },\n    });\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing PregelLoop for Superstep Orchestration in TypeScript\nDESCRIPTION: This code shows the implementation of the PregelLoop class that manages the graph execution cycle, handling superstep orchestration, checkpoint creation, and processing writes from tasks.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-execution-model.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nclass PregelLoop {\n  // Channels hold state and pass messages\n  channels: Record<string, BaseChannel>;\n  \n  // Tasks scheduled for current superstep\n  tasks: PregelTask[];\n  \n  // Checkpointer for persistence\n  checkpointer?: BaseCheckpointSaver;\n  \n  // Executes a single superstep of the algorithm\n  async tick(params: { \n    config?: RunnableConfig,\n    signal?: AbortSignal\n  }): Promise<boolean> {\n    // Handle first execution or continue from checkpoint\n    if (firstTime) {\n      await this._first(inputKeys);\n    }\n    \n    // Prepare next tasks based on channel updates\n    this.tasks = _prepareNextTasks(\n      this.channels,\n      this.readEdges,\n      this.versions\n    );\n    \n    // Create checkpoint for this superstep\n    await this._putCheckpoint({ superstep: this.versions.superstep });\n    \n    // If no more tasks, we're done\n    return this.tasks.length > 0;\n  }\n  \n  // Save write operations from tasks\n  putWrites(taskId: string, writes: ChannelWrite[]): void {\n    this.writesFromTasks[taskId] = writes;\n  }\n  \n  // Process writes after tasks complete\n  async _processWritesFromTasks(): Promise<void> {\n    for (const [taskId, writes] of Object.entries(this.writesFromTasks)) {\n      await _applyWrites(\n        this.channels,\n        writes,\n        this.versions\n      );\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining StateGraph with Dynamic Interrupt in TypeScript\nDESCRIPTION: This snippet demonstrates how to create a StateGraph with three steps, where step2 includes a dynamic interrupt condition based on input length. It uses NodeInterrupt to throw an exception when the condition is met.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamic_breakpoints.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  Annotation,\n  MemorySaver,\n  NodeInterrupt,\n  StateGraph,\n} from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  input: Annotation<string>,\n});\n\nconst step1 = async (state: typeof StateAnnotation.State) => {\n  console.log(\"---Step 1---\");\n  return state;\n};\n\nconst step2 = async (state: typeof StateAnnotation.State) => {\n  // Let's optionally raise a NodeInterrupt\n  // if the length of the input is longer than 5 characters\n  if (state.input?.length > 5) {\n    throw new NodeInterrupt(`Received input that is longer than 5 characters: ${state.input}`);\n  }\n  console.log(\"---Step 2---\");\n  return state;\n};\n\nconst step3 = async (state: typeof StateAnnotation.State) => {\n  console.log(\"---Step 3---\");\n  return state;\n};\n\nconst checkpointer = new MemorySaver();\n\nconst graph = new StateGraph(StateAnnotation)\n  .addNode(\"step1\", step1)\n  .addNode(\"step2\", step2)\n  .addNode(\"step3\", step3)\n  .addEdge(\"__start__\", \"step1\")\n  .addEdge(\"step1\", \"step2\")\n  .addEdge(\"step2\", \"step3\")\n  .addEdge(\"step3\", \"__end__\")\n  .compile({ checkpointer });\n```\n\n----------------------------------------\n\nTITLE: Creating an Entrypoint with MemorySaver in LangGraph\nDESCRIPTION: Code that composes tasks into an entrypoint function with checkpointing via MemorySaver to manage state across interruptions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MemorySaver, entrypoint } from \"@langchain/langgraph\";\n\nconst checkpointer = new MemorySaver();\n\nconst graph = entrypoint({\n  name: \"graph\",\n  checkpointer,\n}, async (inputQuery: string) => {\n  const result1 = await step1(inputQuery);\n  const result2 = await humanFeedback(result1);\n  const result3 = await step3(result2);\n  return result3;\n});\n```\n\n----------------------------------------\n\nTITLE: Updating Graph State Dynamically in TypeScript\nDESCRIPTION: This snippet showcases how to update the graph's state using `updateState()`, allowing users to modify values while respecting reducers. It demonstrates how values are merged into the state based on the defined logic and whether a `checkpoint_id` is specified.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nawait graph.updateState(config, { foo: \"2\", bar: [\"b\"] });\n```\n\n----------------------------------------\n\nTITLE: Configuring Workflow with EntryPoint - TypeScript\nDESCRIPTION: This code snippet shows how to configure a workflow using the entrypoint wrapper function to utilize the previously created store instance. It represents a functional API implementation to handle inputs and manage persistence.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence-functional.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { entrypoint } from \"@langchain/langgraph\";\n\nconst workflow = entrypoint({\n  store,\n  name: \"myWorkflow\",\n}, async (input, config) => {\n  const foo = await myTask({input, store: config.store});\n  ...\n});\n```\n\n----------------------------------------\n\nTITLE: Disabling Streaming for a Node - TypeScript\nDESCRIPTION: This code snippet illustrates how to add a 'nostream' tag to a specific node in the state graph to prevent it from streaming its output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RunnableLambda } from \"@langchain/core/runnables\";\n\nconst unstreamed = async (_: typeof StateAnnotation.State) => {\n  const model = new ChatOpenAI({\n    model: \"gpt-4o-mini\",\n    temperature: 0,\n  });\n  const res = await model.invoke(\"How are you?\");\n  console.log(\"LOGGED UNSTREAMED MESSAGE\", res.content);\n  // Don't update the state, this is just to show a call that won't be streamed\n  return {};\n};\n\nconst agentWithNoStream = new StateGraph(StateAnnotation)\n  .addNode(\"unstreamed\",\n    // Add a \"nostream\" tag to the entire node\n    RunnableLambda.from(unstreamed).withConfig({\n      tags: [\"nostream\"]\n    })\n  )\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  // Run the unstreamed node before the agent\n  .addEdge(\"__start__\", \"unstreamed\")\n  .addEdge(\"unstreamed\", \"agent\")\n  .addConditionalEdges(\"agent\", routeMessage)\n  .addEdge(\"tools\", \"agent\")\n  .compile();\n\nconst stream = await agentWithNoStream.stream(\n  { messages: [{ role: \"user\", content: \"What's the current weather in Nepal?\" }] },\n  { streamMode: \"messages\" },\n);\n\nfor await (const [message, _metadata] of stream) {\n  if (isAIMessageChunk(message) && message.tool_call_chunks?.length) {\n    console.log(`${message.getType()} MESSAGE TOOL CALL CHUNK: ${message.tool_call_chunks[0].args}`);\n  } else {\n    console.log(`${message.getType()} MESSAGE CONTENT: ${message.content}`);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Channel-Pregel Interface in TypeScript\nDESCRIPTION: Defines the communication infrastructure between Channels and the Pregel system, including base interfaces and utility classes for managing subscriptions and writes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/langgraph-architecture-spec.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nabstract class BaseChannel<ValueType, UpdateType, CheckpointType> {\n  abstract update(values: UpdateType[]): boolean;\n  abstract get(): ValueType;\n  abstract checkpoint(): CheckpointType | undefined;\n  abstract fromCheckpoint(checkpoint?: CheckpointType): this;\n  consume(): boolean;\n}\n\nclass Pregel {\n  channels: Record<string, BaseChannel | ManagedValueSpec>;\n}\n\nclass Channel {\n  static subscribeTo(channel: string, options?): PregelNode;\n  static writeTo(channels: string[], writes?): ChannelWrite;\n}\n\nconst node = Channel.subscribeTo(\"input_channel\");\nconst write = Channel.writeTo([\"output_channel\"]);\n```\n\n----------------------------------------\n\nTITLE: Defining Chat Model and Tool in Langchain\nDESCRIPTION: This snippet sets up a chat model and a weather information retrieval tool. It makes use of the 'zod' library for schema validation and defines how the chat model can leverage tools. Required dependencies include Langchain's core and anthropic packages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-from-final-node.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport { z } from \"zod\";\nimport { tool } from \"@langchain/core/tools\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\n\nconst getWeather = tool(async ({ city }) => {\n  if (city === \"nyc\") {\n    return \"It might be cloudy in nyc\";\n  } else if (city === \"sf\") {\n    return \"It's always sunny in sf\";\n  } else {\n    throw new Error(\"Unknown city.\");\n  }\n}, {\n  name: \"get_weather\",\n  schema: z.object({\n    city: z.enum([\"nyc\", \"sf\"]),\n  }),\n  description: \"Use this to get weather information\",\n});\n\nconst tools = [getWeather];\n\nconst model = new ChatAnthropic({\n  model: \"claude-3-5-sonnet-20240620\",\n}).bindTools(tools);\n\n\n// We add a tag that we'll be using later to filter outputs\nconst finalModel = new ChatAnthropic({\n  model: \"claude-3-5-sonnet-20240620\",\n}).withConfig({\n  tags: [\"final_node\"],\n});\n```\n\n----------------------------------------\n\nTITLE: Verifying User Memories - TypeScript\nDESCRIPTION: This snippet shows how to query the in-memory store to verify that user memories have been stored correctly. It is essential for ensuring the functionality of the memory persistence system in the workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence-functional.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst memories = await inMemoryStore.search([\"memories\", \"1\"]);\nfor (const memory of memories) {\n  console.log(memory.value);\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Results from Parent Graph in LangGraphJS\nDESCRIPTION: Code to stream results from the parent graph execution. This shows the output of the graph including results from the subgraph execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await graph.stream({ foo: \"foo\" });\n\nfor await (const chunk of stream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Graph Execution with Conversational Query\nDESCRIPTION: This code snippet demonstrates how to stream the execution of a LangGraphJS graph with a simple conversational query. It passes a greeting message to the `graph.stream()` method with a specified `thread_id`. The value is streamed, and then logged to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nconst conversationalStream = await graph.stream({\n  messages: [{\n    role: \"user\",\n    content: \"How are you? I'm Cobb.\"\n  }]\n}, {\n  configurable: {\n    thread_id: \"conversational_testing_id\"\n  }\n});\n\nfor await (const value of conversationalStream) {\n  console.log(value);\n}\n```\n\n----------------------------------------\n\nTITLE: Executing RAG Workflow and Logging Results in Python\nDESCRIPTION: This snippet demonstrates how to execute the compiled RAG workflow with a sample input, stream the results, and log the output from each node in the process.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n\nconst inputs = {\n  messages: [\n    new HumanMessage(\n      \"What are the types of agent memory based on Lilian Weng's blog post?\",\n    ),\n  ],\n};\nlet finalState;\nfor await (const output of await app.stream(inputs)) {\n  for (const [key, value] of Object.entries(output)) {\n    const lastMsg = output[key].messages[output[key].messages.length - 1];\n    console.log(`Output from node: '${key}'`);\n    console.dir({\n      type: lastMsg._getType(),\n      content: lastMsg.content,\n      tool_calls: lastMsg.tool_calls,\n    }, { depth: null });\n    console.log(\"---\\n\");\n    finalState = value;\n  }\n}\n\nconsole.log(JSON.stringify(finalState, null, 2));\n```\n\n----------------------------------------\n\nTITLE: Creating Semantic Recall Function - Python\nDESCRIPTION: This snippet outlines the implementation of a function to retrieve memories based on the user's last message, enriching the system message with relevant context for the conversation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport { MessagesAnnotation } from \"@langchain/langgraph\";\n\nconst addMemories = async (\n  state: typeof MessagesAnnotation.State,\n  config: LangGraphRunnableConfig\n) => {\n  const store = config.store as InMemoryStore;\n\n  if (!store) {\n    throw new Error(\"No store provided to state modifier.\");\n  }\n  \n  // Search based on user's last message\n  const items = await store.search(\n    [\"user_123\", \"memories\"], \n    { \n      // Assume it's not a complex message\n      query: state.messages[state.messages.length - 1].content as string,\n      limit: 4 \n    }\n  );\n\n  const memories = items.length \n    ? `## Memories of user\\n${${\n      items.map(item => `${item.value.text} (similarity: ${item.score})`).join(\"\\n\")\n    }}` \n    : \"\";\n\n  // Add retrieved memories to system message\n  return [\n    { role: \"system\", content: `You are a helpful assistant.\\n${memories}` },\n    ...state.messages\n  ];\n};\n```\n\n----------------------------------------\n\nTITLE: State Editing via Human Input - LangGraph - TypeScript\nDESCRIPTION: This example demonstrates how to incorporate human feedback for editing the graph state using LangGraph's interrupt function. It pauses the graph for human review and edits the generated summary. The code requires LangGraph, and upon human input, updates the graph state with the edited text.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt } from \"@langchain/langgraph\";\n\nfunction humanEditing(state: typeof GraphAnnotation.State): Command {\n  const result = interrupt({\n    task: \"Review the output from the LLM and make any necessary edits.\",\n    llm_generated_summary: state.llm_generated_summary,\n  });\n\n  return {\n    llm_generated_summary: result.edited_text,\n  };\n}\n\nconst graph = graphBuilder\n  .addNode(\"human_editing\", humanEditing)\n  .compile({ checkpointer });\n\nconst threadConfig = { configurable: { thread_id: \"some_id\" } };\nawait graph.invoke(\n  new Command({ resume: { edited_text: \"The edited text\" } }),\n  threadConfig\n);\n```\n\n----------------------------------------\n\nTITLE: Integrating Graph API with Functional API in LangGraph\nDESCRIPTION: Shows how to combine the Functional API and Graph API in a single application by calling Graph API-defined graphs from within a Functional API entrypoint.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_24\n\nLANGUAGE: typescript\nCODE:\n```\nimport { entrypoint, StateGraph } from \"@langchain/langgraph\";\n\nconst builder = new StateGraph();\n...\nconst someGraph = builder.compile();\n\nconst someWorkflow = entrypoint(\n  { name: \"someWorkflow\" },\n  async (someInput: Record<string, any>) => {\n    // Call a graph defined using the graph API\n    const result1 = await someGraph.invoke(...);\n    // Call another graph defined using the graph API\n    const result2 = await anotherGraph.invoke(...);\n    return {\n      result1,\n      result2,\n    };\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Invoking Child Graph\nDESCRIPTION: This snippet demonstrates the invocation of a child graph and passing an initial state value for processing. The asynchronous function call executes the transformations set by the graph definition.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-transform-state.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nawait childGraph.invoke({ myChildKey: \"hi Bob\" })\n```\n\n----------------------------------------\n\nTITLE: Wrapping Tools in ToolNode for LangGraphJS\nDESCRIPTION: This code snippet demonstrates how to wrap defined tools into a ToolNode object in LangGraphJS, enabling tool execution by the language model when invoked. It requires the ToolNode class from '@langchain/langgraph/prebuilt'.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst toolNode = new ToolNode(tools);\n```\n\n----------------------------------------\n\nTITLE: Binding Tools to Chat Model in JavaScript\nDESCRIPTION: Binds predefined tools to the chat model, allowing the model to call these tools and use their outputs during processing. Binding is achieved using the bindTools method.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-values.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nconst boundModel = model.bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: Implementing Interruption Before Tool Execution\nDESCRIPTION: Creation of a graph with interruption before tool execution using interruptBefore option. This allows for human-in-the-loop validation and potential modification of the planned actions before they are executed.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nmemory = new MemorySaver();\nconst graphWithInterrupt = workflow.compile({\n  checkpointer: memory,\n  interruptBefore: [\"tools\"],\n});\n\ninputs = { messages: [{ role: \"user\", content: \"What's the weather like in SF currently?\" }] } as any;\nfor await (\n  const { messages } of await graphWithInterrupt.stream(inputs, {\n    ...config,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Weather Tool for the Agent - LangGraphJS - Python\nDESCRIPTION: This snippet creates a weather tool that the React agent can use to provide weather information for specific cities. It leverages Zod for input validation and accepts a city parameter to return weather information based on predefined conditions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-return-structured-output.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nconst weatherTool = tool(\n  async (input): Promise<string> => {\n    if (input.city === \"nyc\") {\n      return \"It might be cloudy in nyc\";\n    } else if (input.city === \"sf\") {\n      return \"It's always sunny in sf\";\n    } else {\n      throw new Error(\"Unknown city\");\n    }\n  },\n  {\n    name: \"get_weather\",\n    description: \"Use this to get weather information.\",\n    schema: z.object({\n      city: z.enum([\"nyc\", \"sf\"]).describe(\"The city to get weather for\"),\n    }),\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Running the LangGraph Agent and Processing Results\nDESCRIPTION: Executes the agent with a sample query and displays the output, demonstrating how to stream and process results from the LangGraph agent workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/agent_executor/base.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage, BaseMessage } from \"@langchain/core/messages\";\n\nlet finalResult: BaseMessage | undefined;\n\nconst prettyLogOutput = (output: Record<string, any>) => {\n  const keys = Object.keys(output);\n  const firstItem = output[keys[0]];\n  if (\"messages\" in firstItem) {\n    console.log(`(node) ${keys[0]}:`, firstItem.messages[0]);\n    console.log(\"----\\n\");\n  }\n}\n\nconst inputs = { messages: [new HumanMessage(\"Search the web for the weather in sf\")] };\nfor await (const s of await app.stream(inputs)) {\n  prettyLogOutput(s);\n  if (\"callModel\" in s && s.callModel.messages?.length) {\n    finalResult = s.callModel.messages[0];\n  }\n}\n\nconsole.log(\"Final Result: \", finalResult.content)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current Graph State\nDESCRIPTION: Retrieval of the current state of the graph using the getState method. This demonstrates how to access the saved state from a checkpoint, including messages and execution information.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nlet checkpoint = await graph.getState(config);\ncheckpoint.values;\n```\n\n----------------------------------------\n\nTITLE: Document Loading and Indexing Setup\nDESCRIPTION: Implementation of document loading, splitting, and vector store creation using local embeddings.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";\nimport { CheerioWebBaseLoader } from \"@langchain/community/document_loaders/web/cheerio\";\nimport { MemoryVectorStore } from \"langchain/vectorstores/memory\";\nimport { OllamaEmbeddings } from \"@langchain/ollama\";\n\nconst urls = [\n  \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n  \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n  \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n];\n\nconst docs = await Promise.all(urls.map((url) => {\n  const loader = new CheerioWebBaseLoader(url);\n  return loader.load();\n}));\n\nconst docsList = docs.flat();\n\nconst textSplitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 250,\n  chunkOverlap: 0,\n});\n\nconst splitDocs = await textSplitter.splitDocuments(docsList);\n\nconst embeddings = new OllamaEmbeddings({\n  model: \"mxbai-embed-large\",\n});\n\nconst vectorStore = await MemoryVectorStore.fromDocuments(\n  splitDocs,\n  embeddings,\n);\n\nconst retriever = vectorStore.asRetriever();\n```\n\n----------------------------------------\n\nTITLE: Specifying Thread ID in Config for Graph Invocation with TypeScript\nDESCRIPTION: This code snippet demonstrates how to specify a `thread_id` in the configuration object when invoking a graph with a checkpointer. It ensures that the graph maintains its state across multiple executions by associating checkpoint information with a specific thread.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n{\"configurable\": {\"thread_id\": \"1\"}}\n```\n\n----------------------------------------\n\nTITLE: Building a ReAct-style Agent with LangGraph.js\nDESCRIPTION: Creates a ReAct-style agent using LangGraph.js, including tool definition, model setup, and graph construction.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/delete-messages.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { tool } from \"@langchain/core/tools\";\nimport { MemorySaver } from \"@langchain/langgraph-checkpoint\";\nimport { MessagesAnnotation, StateGraph, START, END } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport { z } from \"zod\";\n\nconst memory = new MemorySaver();\n\nconst search = tool((_) => {\n  // This is a placeholder for the actual implementation\n  // Don't let the LLM know this though 😊\n  return [\n    \"It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\",\n  ];\n}, {\n  name: \"search\",\n  description: \"Call to surf the web.\",\n  schema: z.object({\n    query: z.string(),\n  })\n});\n\nconst tools = [search];\nconst toolNode = new ToolNode<typeof MessagesAnnotation.State>(tools);\nconst model = new ChatOpenAI({ model: \"gpt-4o\" });\nconst boundModel = model.bindTools(tools);\n\nfunction shouldContinue(state: typeof MessagesAnnotation.State): \"action\" | typeof END {\n  const lastMessage = state.messages[state.messages.length - 1];\n  if (\n    \"tool_calls\" in lastMessage &&\n    Array.isArray(lastMessage.tool_calls) &&\n    lastMessage.tool_calls.length\n  ) {\n    return \"action\";\n  }\n  // If there is no tool call, then we finish\n  return END;\n}\n\n// Define the function that calls the model\nasync function callModel(state: typeof MessagesAnnotation.State) {\n  const response = await boundModel.invoke(state.messages);\n  return { messages: [response] };\n}\n\n// Define a new graph\nconst workflow = new StateGraph(MessagesAnnotation)\n  // Define the two nodes we will cycle between\n  .addNode(\"agent\", callModel)\n  .addNode(\"action\", toolNode)\n  // Set the entrypoint as `agent`\n  // This means that this node is the first one called\n  .addEdge(START, \"agent\")\n  // We now add a conditional edge\n  .addConditionalEdges(\n    // First, we define the start node. We use `agent`.\n    // This means these are the edges taken after the `agent` node is called.\n    \"agent\",\n    // Next, we pass in the function that will determine which node is called next.\n    shouldContinue\n  )\n  // We now add a normal edge from `tools` to `agent`.\n  // This means that after `tools` is called, `agent` node is called next.\n  .addEdge(\"action\", \"agent\");\n\n// Finally, we compile it!\n// This compiles it into a LangChain Runnable,\n// meaning you can use it as you would any other runnable\nconst app = workflow.compile({ checkpointer: memory });\n```\n\n----------------------------------------\n\nTITLE: Implementing Question Rewriter with ChatPromptTemplate\nDESCRIPTION: Creates a question rewriter that optimizes input questions for vectorstore retrieval using a chat prompt template and LLM pipeline.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst REWRITER_PROMPT_TEMPLATE =\n  `You a question re-writer that converts an input question to a better version that is optimized\nfor vectorstore retrieval. Look at the initial and formulate an improved question.\n\nHere is the initial question:\n\n<question>\n{question}\n</question>\n\nRespond only with an improved question. Do not include any preamble or explanation.`;\n\nconst rewriterPrompt = ChatPromptTemplate.fromTemplate(\n  REWRITER_PROMPT_TEMPLATE,\n);\n\nconst rewriter = rewriterPrompt.pipe(llm).pipe(new StringOutputParser());\n\n// Test run\n\n// Test question is \"agent memory\"\nawait rewriter.invoke({ question: testQuestion2 });\n```\n\n----------------------------------------\n\nTITLE: Importing LangGraph.js from web entrypoint\nDESCRIPTION: This snippet demonstrates how to import LangGraph.js from the web-specific entrypoint and create a simple state graph that can run in browsers. It defines a graph state with a message reducer and a node function that returns a human message.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/use-in-web-environments.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// Import from \"@langchain/langgraph/web\"\nimport {\n  END,\n  START,\n  StateGraph,\n  Annotation,\n} from \"@langchain/langgraph/web\";\nimport { BaseMessage, HumanMessage } from \"@langchain/core/messages\";\n\nconst GraphState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n\nconst nodeFn = async (_state: typeof GraphState.State) => {\n  return { messages: [new HumanMessage(\"Hello from the browser!\")] };\n};\n\n// Define a new graph\nconst workflow = new StateGraph(GraphState)\n  .addNode(\"node\", nodeFn)\n  .addEdge(START, \"node\")\n  .addEdge(\"node\", END);\n\nconst app = workflow.compile({});\n\n// Use the Runnable\nconst finalState = await app.invoke(\n  { messages: [] },\n);\n\nconsole.log(finalState.messages[finalState.messages.length - 1].content);\n```\n\n----------------------------------------\n\nTITLE: Using entrypoint.final for Decoupling State in a Workflow\nDESCRIPTION: This code snippet shows how to use entrypoint.final within a workflow to decouple the return value from the checkpointed value, enabling more control over what is saved in checkpoints.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (number: number) => {\n    const previous = getPreviousState<number>();\n    // This will return the previous value to the caller, saving\n    // 2 * number to the checkpoint, which will be used in the next invocation\n    // for the previous state\n    return entrypoint.final({\n      value: previous ?? 0,\n      save: 2 * number,\n    });\n  }\n);\n\nconst config = {\n  configurable: {\n    thread_id: \"1\",\n  },\n};\n\nawait myWorkflow.invoke(3, config); // 0 (previous was undefined)\nawait myWorkflow.invoke(1, config); // 6 (previous was 3 * 2 from the previous invocation)\n```\n\n----------------------------------------\n\nTITLE: Executing a Tool in LangGraph with Weather Query\nDESCRIPTION: Execution of the graph with a query that requires tool use, demonstrating how the graph handles multi-step execution with tool calls and responses.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\ninputs = { messages: [{ role: \"user\", content: \"What's the weather like in SF currently?\" }] } as any;\nfor await (\n  const { messages } of await graph.stream(inputs, {\n    ...config,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Tool Node Execution with Research Results\nDESCRIPTION: An example invocation of the tool node using the output from the research node, demonstrating how tools are executed within the graph based on agent requests.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Example invocation\nawait toolNode.invoke(researchResults);\n```\n\n----------------------------------------\n\nTITLE: Replaying Actions in Langchain JavaScript\nDESCRIPTION: This snippet illustrates how to replay past actions from a specific checkpoint in a Langchain graph. By passing 'null' for inputs and specifying 'threadConfig', users can replay events from previous execution points. The snippet highlights acquiring the checkpoint ID, iterating through state history to gather checkpoints, and using checkpoint ID for replaying. Key inputs include 'threadConfig', while output logs the replayed events.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst threadConfig = { configurable: { thread_id: \"1\" } };\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst allCheckpoints = [];\nfor await (const state of app.getStateHistory(threadConfig)) {\n    allCheckpoints.push(state);\n}\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = { configurable: { thread_id: '1', checkpoint_id: 'xxx' }, streamMode: \"values\" as const };\nfor await (const event of await graph.stream(null, config)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up Tools and ToolExecutor\nDESCRIPTION: Define the tools to be used and create a ToolExecutor for handling tool invocations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToolExecutor } from \"@langchain/langgraph/prebuilt\";\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n\nconst tools = [new TavilySearchResults({ maxResults: 1 })];\n\nconst toolExecutor = new ToolExecutor({\n  tools,\n});\n```\n\n----------------------------------------\n\nTITLE: State Definition with Annotations\nDESCRIPTION: Defines the state object that passes between graph nodes using annotations for messages and next agent tracking.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/agent_supervisor.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport { END, Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n    default: () => [],\n  }),\n  next: Annotation<string>({\n    reducer: (x, y) => y ?? x ?? END,\n    default: () => END,\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Agent State for Document Writing Team in LangGraph.js\nDESCRIPTION: This code defines the agent state for the document writing team using `Annotation.Root`.  The state includes `messages` (a list of messages), `team_members` (an array of team member names), `next` (the next node in the graph), `current_files` (a string representing the current files in the workspace), and `instructions` (instructions for the agent).  Reducers are defined for each state variable to handle updates and defaults.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\n// This defines the agent state for the document writing team\nconst DocWritingState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({{\n    reducer: (x, y) => x.concat(y),\n  }}),\n  team_members: Annotation<string[]>({{\n    reducer: (x, y) => x.concat(y),\n  }}),\n  next: Annotation<string>({{\n    reducer: (x, y) => y ?? x,\n    default: () => \"supervisor\",\n  }}),\n  current_files: Annotation<string>({{\n    reducer: (x, y) => (y ? `${x}\\n${y}` : x),\n    default: () => \"No files written.\",\n  }}),\n  instructions: Annotation<string>({{\n    reducer: (x, y) => y ?? x,\n    default: () => \"Solve the human's question.\",\n  }})\n})\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Node for Forced Tool Calling\nDESCRIPTION: This function creates a node that returns an AIMessage with a tool call, forcing the agent to call the search tool first.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst firstModel = async (state: typeof AgentState.State) => {\n  const humanInput = state.messages[state.messages.length - 1].content || \"\";\n  return {\n    messages: [\n      new AIMessage({\n        content: \"\",\n        tool_calls: [\n          {\n            name: \"search\",\n            args: {\n              query: humanInput,\n            },\n            id: \"tool_abcd123\",\n          },\n        ],\n      }),\n    ],\n  };\n};\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current Graph State\nDESCRIPTION: Shows how to retrieve the current state of the graph to check the next node and identify that it's paused at the weather subgraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst state = await graph.getState({ configurable: { thread_id: \"3\" } })\nstate.next\n```\n\n----------------------------------------\n\nTITLE: Creating Dynamic Breakpoints with Conditional Logic in LangGraphJS\nDESCRIPTION: Implements a dynamic breakpoint using NodeInterrupt that triggers based on a condition, in this case when input length exceeds 5 characters. This allows for conditional graph interruption based on state values.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nfunction myNode(state: typeof GraphAnnotation.State): typeof GraphAnnotation.State {\n    if (state.input.length > 5) {\n        throw new NodeInterrupt(`Received input that is longer than 5 characters: ${state['input']}`);\n    }\n    return state;\n}\n```\n\n----------------------------------------\n\nTITLE: Hallucination Grader Implementation\nDESCRIPTION: Creation of a system to check generated answers for hallucinations against source context.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nconst HALLUCINATION_GRADER_TEMPLATE =\n  `You are a grader assessing whether an answer is grounded in / supported by a set of facts.\nHere are the facts used as context to generate the answer:\n\n<context>\n{context} \n</context>\n\nHere is the answer:\n\n<answer>\n{generation}\n</answer>\n\nGive a binary score 'yes' or 'no' score to indicate whether the answer is grounded in / supported by a set of facts.\nProvide the binary score as a JSON with a single key 'score' and no preamble or explanation.`;\n\nconst hallucinationGraderPrompt = ChatPromptTemplate.fromTemplate(\n  HALLUCINATION_GRADER_TEMPLATE,\n);\n\nconst hallucinationGrader = hallucinationGraderPrompt.pipe(llm).pipe(\n  new JsonOutputParser(),\n);\n\nconst generation2 = await ragChain.invoke({\n  context: formatDocs(docs3),\n  question: testQuestion2,\n});\n\nawait hallucinationGrader.invoke({ context: formatDocs(docs3), generation: generation2 });\n```\n\n----------------------------------------\n\nTITLE: Defining Model and Tool Calling Tasks for ReAct Agent\nDESCRIPTION: Implementation of tasks for calling a model and executing tool calls, including the newly defined human assistance tool.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  type BaseMessageLike,\n  AIMessage,\n  ToolMessage,\n} from \"@langchain/core/messages\";\nimport { type ToolCall } from \"@langchain/core/messages/tool\";\nimport { task } from \"@langchain/langgraph\";\n\nconst toolsByName = Object.fromEntries(tools.map((tool) => [tool.name, tool]));\n\nconst callModel = task(\"callModel\", async (messages: BaseMessageLike[]) => {\n  const response = await model.bindTools(tools).invoke(messages);\n  return response;\n});\n\nconst callTool = task(\n  \"callTool\",\n  async (toolCall: ToolCall): Promise<AIMessage> => {\n    const tool = toolsByName[toolCall.name];\n    const observation = await tool.invoke(toolCall.args);\n    return new ToolMessage({ content: observation, tool_call_id: toolCall.id });\n    // Can also pass toolCall directly into the tool to return a ToolMessage\n    // return tool.invoke(toolCall);\n  });\n```\n\n----------------------------------------\n\nTITLE: Defining a ReAct Agent Graph with LangGraph\nDESCRIPTION: This code defines a ReAct agent graph using LangGraph, incorporating a ChatOpenAI model and a custom tool for fetching weather information. It showcases how to create a functional agent that can interact with external resources.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-multiple.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { tool } from '@langchain/core/tools';\nimport { z } from 'zod';\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\nconst model = new ChatOpenAI({\n    model: \"gpt-4o\",\n  });\n\nconst getWeather = tool((input) => {\n  if ([\"sf\", \"san francisco\", \"san francisco, ca\"].includes(input.location.toLowerCase())) {\n    return \"It's 60 degrees and foggy.\";\n  } else {\n    return \"It's 90 degrees and sunny.\";\n  }\n}, {\n  name: \"get_weather\",\n  description: \"Call to get the current weather.\",\n  schema: z.object({\n    location: z.string().describe(\"Location to get the weather for.\"),\n  })\n})\n\nconst graph = createReactAgent({ llm: model, tools: [getWeather] });\n```\n\n----------------------------------------\n\nTITLE: Using the streamEvents Method for LLM Tokens - TypeScript\nDESCRIPTION: This snippet shows how to use the streamEvents method to receive streaming events from the agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst eventStream = await agent.streamEvents(\n  { messages: [{ role: \"user\", content: \"What's the weather like today?\" }] },\n  {\n    version: \"v2\",\n  }\n);\n\nfor await (const { event, data } of eventStream) {\n  if (event === \"on_chat_model_stream\" && isAIMessageChunk(data.chunk)) {\n    if (data.chunk.tool_call_chunks !== undefined && data.chunk.tool_call_chunks.length > 0) {\n      console.log(data.chunk.tool_call_chunks);\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Billing Support Node\nDESCRIPTION: This snippet defines the `billingSupport` node, simulating a billing support specialist. It uses a system template to guide the response and categorizes the user's issue to determine if a refund is needed. If a refund is deemed necessary, the conversation is routed to a refund handling node; otherwise, it continues conversationally. It returns the billing representative's response and the next representative's ID.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n\"const billingSupport = async (state: typeof StateAnnotation.State) => {\\n  const SYSTEM_TEMPLATE =\\n    `You are an expert billing support specialist for LangCorp, a company that sells computers.\\nHelp the user to the best of your ability, but be concise in your responses.\\nYou have the ability to authorize refunds, which you can do by transferring the user to another agent who will collect the required information.\\nIf you do, assume the other agent has all necessary information about the customer and their order.\\nYou do not need to ask the user for more information.\\n\\nHelp the user to the best of your ability, but be concise in your responses.`;\\n\\n  let trimmedHistory = state.messages;\\n  // Make the user's question the most recent message in the history.\\n  // This helps small models stay focused.\\n  if (trimmedHistory.at(-1)._getType() === \\\"ai\\\") {\\n    trimmedHistory = trimmedHistory.slice(0, -1);\\n  }\\n\\n  const billingRepResponse = await model.invoke([\\n    {\\n      role: \\\"system\\\",\\n      content: SYSTEM_TEMPLATE,\\n    },\\n    ...trimmedHistory,\\n  ]);\\n  const CATEGORIZATION_SYSTEM_TEMPLATE =\\n    `Your job is to detect whether a billing support representative wants to refund the user.`;\\n  const CATEGORIZATION_HUMAN_TEMPLATE =\\n    `The following text is a response from a customer support representative.\\nExtract whether they want to refund the user or not.\\nRespond with a JSON object containing a single key called \\\"nextRepresentative\\\" with one of the following values:\\n\\nIf they want to refund the user, respond only with the word \\\"REFUND\\\".\\nOtherwise, respond only with the word \\\"RESPOND\\\".\\n\\nHere is the text:\\n\\n<text>\\n${billingRepResponse.content}\\n</text>.`;\\n  const categorizationResponse = await model.invoke([\\n    {\\n      role: \\\"system\\\",\\n      content: CATEGORIZATION_SYSTEM_TEMPLATE,\\n    },\\n    {\\n      role: \\\"user\\\",\\n      content: CATEGORIZATION_HUMAN_TEMPLATE,\\n    }\\n  ], {\\n    response_format: {\\n      type: \\\"json_object\\\",\\n      schema: zodToJsonSchema(\\n        z.object({\\n          nextRepresentative: z.enum([\\\"REFUND\\\", \\\"RESPOND\\\"]),\\n        })\\n      )\\n    }\\n  });\\n  const categorizationOutput = JSON.parse(categorizationResponse.content as string);\\n  return {\\n    messages: billingRepResponse,\\n    nextRepresentative: categorizationOutput.nextRepresentative,\\n  };\\n};\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming Capabilities in TypeScript for LanggraphJS\nDESCRIPTION: This code snippet shows the implementation of streaming capabilities in LanggraphJS. It defines different streaming modes, a function to emit stream data, and methods to stream values and updates from a PregelLoop. This allows for real-time insights during execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-execution-model.md#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nenum StreamMode {\n  VALUES = \"values\",     // Complete state after each step\n  UPDATES = \"updates\",   // Only state changes\n  MESSAGES = \"messages\", // Internal node communication\n  DEBUG = \"debug\"        // Detailed execution events\n}\n\n// Stream handler function\nfunction _emit(\n  config: RunnableConfig,\n  mode: StreamMode,\n  values: any\n): void {\n  const handlers = config.configurable?.callbacks?.[mode];\n  if (handlers) {\n    for (const handler of handlers) {\n      handler(values);\n    }\n  }\n}\n\n// Stream values from PregelLoop\nPregelLoop.prototype._streamValues = function(\n  config: RunnableConfig,\n  snapshot: StateSnapshot\n): void {\n  _emit(config, StreamMode.VALUES, snapshot);\n};\n\n// Stream updates from PregelLoop\nPregelLoop.prototype._streamUpdates = function(\n  config: RunnableConfig,\n  updates: Record<string, any>\n): void {\n  _emit(config, StreamMode.UPDATES, updates);\n};\n```\n\n----------------------------------------\n\nTITLE: Define Complex Graph with Branches and Loops - TypeScript\nDESCRIPTION: This TypeScript snippet defines a more complex graph with branching and loops, including nodes 'a', 'b', 'c', and 'd'. It illustrates how the graph fans out to multiple nodes, handling concurrent execution and a defined loop condition.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/recursion-limit.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\n// Define the state with a reducer\nconst StateAnnotationWithLoops = Annotation.Root({\n  aggregate: Annotation<string[]>({\n    reducer: (a, b) => a.concat(b),\n    default: () => [],\n  }),\n});\n\n// Define nodes\nconst nodeA = async function (state: typeof StateAnnotationWithLoops.State) {\n  console.log(`Node A sees ${state.aggregate}`);\n  return { aggregate: [\"A\"] };\n}\n\nconst nodeB = async function (state: typeof StateAnnotationWithLoops.State) {\n  console.log(`Node B sees ${state.aggregate}`);\n  return { aggregate: [\"B\"] };\n}\n\nconst nodeC = async function (state: typeof StateAnnotationWithLoops.State) {\n  console.log(`Node C sees ${state.aggregate}`);\n  return { aggregate: [\"C\"] };\n}\n\nconst nodeD = async function (state: typeof StateAnnotationWithLoops.State) {\n  console.log(`Node D sees ${state.aggregate}`);\n  return { aggregate: [\"D\"] };\n}\n\n// Define edges\nconst loopRouter = async function (state: typeof StateAnnotationWithLoops.State) {\n  if (state.aggregate.length < 7) {\n    return \"b\";\n  } else {\n    return \"__end__\";\n  }\n}\n\n// Define the graph\nconst graphWithLoops = new StateGraph(StateAnnotationWithLoops)\n  .addNode(\"a\", nodeA)\n  .addNode(\"b\", nodeB)\n  .addNode(\"c\", nodeC)\n  .addNode(\"d\", nodeD)\n  .addEdge(\"__start__\", \"a\")\n  .addConditionalEdges(\"a\", loopRouter)\n  .addEdge(\"b\", \"c\")\n  .addEdge(\"b\", \"d\")\n  .addEdge([\"c\", \"d\"], \"a\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Defining Research Team Agents and Supervisor in TypeScript\nDESCRIPTION: Creates a research team with search and web scraping agents, along with a team supervisor. It uses the previously defined helper utilities to set up the agents and their state modifiers.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { Annotation } from \"@langchain/langgraph\";\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\nconst ResearchTeamState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n  team_members: Annotation<string[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n  next: Annotation<string>({\n    reducer: (x, y) => y ?? x,\n    default: () => \"supervisor\",\n  }),\n  instructions: Annotation<string>({\n    reducer: (x, y) => y ?? x,\n    default: () => \"Solve the human's question.\",\n  }),\n})\n\nconst llm = new ChatOpenAI({ modelName: \"gpt-4o\" });\n\nconst searchNode = (state: typeof ResearchTeamState.State) => {\n  const stateModifier = agentStateModifier(\n    \"You are a research assistant who can search for up-to-date info using the tavily search engine.\",\n    [tavilyTool],\n    state.team_members ?? [\"Search\"],\n  )\n  const searchAgent = createReactAgent({\n    llm,\n    tools: [tavilyTool],\n    stateModifier,\n  })\n  return runAgentNode({ state, agent: searchAgent, name: \"Search\" });\n};\n\nconst researchNode = (state: typeof ResearchTeamState.State) => {\n  const stateModifier = agentStateModifier(\n    \"You are a research assistant who can scrape specified urls for more detailed information using the scrapeWebpage function.\",\n    [scrapeWebpage],\n    state.team_members ?? [\"WebScraper\"],\n  )\n  const researchAgent = createReactAgent({\n    llm,\n    tools: [scrapeWebpage],\n    stateModifier,\n  })\n  return runAgentNode({ state, agent: researchAgent, name: \"WebScraper\" });\n}\n\nconst supervisorAgent = await createTeamSupervisor(\n  llm,\n  \"You are a supervisor tasked with managing a conversation between the\" +\n    \" following workers:  {team_members}. Given the following user request,\" +\n    \" respond with the worker to act next. Each worker will perform a\" +\n    \" task and respond with their results and status. When finished,\" +\n    \" respond with FINISH.\\n\\n\" +\n    \" Select strategically to minimize the number of steps taken.\",\n  [\"Search\", \"WebScraper\"],\n);\n```\n\n----------------------------------------\n\nTITLE: Resuming Graph Execution with Updated State in JavaScript\nDESCRIPTION: This snippet resumes the graph execution after updating the inner graph state. It streams the updates and logs them to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_18\n\nLANGUAGE: javascript\nCODE:\n```\nconst resumedStreamWithUpdatedState = await graph.stream(null, {\n  configurable: {\n    thread_id: \"4\",\n  },\n  streamMode: \"updates\",\n  subgraphs: true,\n})\n\nfor await (const update of resumedStreamWithUpdatedState) {\n  console.log(JSON.stringify(update, null, 2));\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Placeholder Search Tool\nDESCRIPTION: This code defines a placeholder search tool using Langchain's tool function and Zod for schema validation. The tool takes a query as input and returns a hardcoded weather response.  This serves as a basic example that can be extended with a real implementation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-updates.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst searchTool = tool(async ({ query: _query }: { query: string }) => {\n  // This is a placeholder for the actual implementation\n  return \"Cold, with a low of 3℃\";\n}, {\n  name: \"search\",\n  description:\n    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n});\n\nawait searchTool.invoke({ query: \"What's the weather like?\" });\n\nconst tools = [searchTool];\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Execution Node in Graph\nDESCRIPTION: Creates a tool node for the graph that can run the defined tools (search and chart generation). The ToolNode class from LangGraphJS handles the execution of tool calls within the graph's state management system.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst tools = [tavilyTool, chartTool];\n// This runs tools in the graph\nconst toolNode = new ToolNode<typeof AgentState.State>(tools);\n```\n\n----------------------------------------\n\nTITLE: Continuing Tool Call Execution with Command in LangGraph.js\nDESCRIPTION: Demonstrates how to approve the revised tool call and continue execution using a Command with a \"continue\" action. This processes the approved tool call and streams the resulting messages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: javascript\nCODE:\n```\nfor await (const event of await graph.stream(\n  new Command({\n    resume: {\n      action: \"continue\",\n    }\n  }),\n  config\n)) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Wrapping Tools in a ToolNode in JavaScript\nDESCRIPTION: Wraps the defined tools into a ToolNode, enabling them to be executed whenever invoked by LangGraph's nodes. This provides an interface to simulate executing tool functionalities within the graph environment.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-values.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst toolNode = new ToolNode(tools);\n```\n\n----------------------------------------\n\nTITLE: Running Persistent Workflow in LangChain with Config\nDESCRIPTION: This snippet shows how to execute a persistent graph in LangChainJS using MemorySaver, simulating a conversation that remembers past interactions. The code sets a configuration to isolate conversation states by thread IDs, maintaining context through sessions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nlet config = { configurable: { thread_id: \"conversation-num-1\" } };\ninputs = { messages: [{ role: \"user\", content: \"Hi I'm Jo, nice to meet you.\" }] };\nfor await (\n  const { messages } of await persistentGraph.stream(inputs, {\n    ...config,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n\ninputs = { messages: [{ role: \"user\", content: \"Remember my name?\"}] };\nfor await (\n  const { messages } of await persistentGraph.stream(inputs, {\n    ...config,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Search Tool in LangGraphJS\nDESCRIPTION: This snippet defines a simple placeholder search tool using LangGraphJS, designed to simulate web searches. It uses the 'tool' function from '@langchain/core/tools' and the 'zod' schema to define input validation for the query parameter. After setting up, it asynchronously invokes the tool to demonstrate its operation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst searchTool = tool(async ({}: { query: string }) => {\n  // This is a placeholder for the actual implementation\n  return \"Cold, with a low of 13 ℃\";\n}, {\n  name: \"search\",\n  description:\n    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n});\n\nawait searchTool.invoke({ query: \"What's the weather like?\" });\n\nconst tools = [searchTool];\n```\n\n----------------------------------------\n\nTITLE: Updating LangGraph State Manually\nDESCRIPTION: This code snippet shows how to manually update the graph state after an interruption, demonstrating the human-in-the-loop capability of LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconsole.log(\"Current state!\")\nconst currState = await graph.getState(graphStateConfig);\nconsole.log(currState.values)\n\nawait graph.updateState(graphStateConfig, { input: \"hello universe!\" })\n\nconsole.log(\"---\\n---\\nUpdated state!\")\nconst updatedState = await graph.getState(graphStateConfig);\nconsole.log(updatedState.values)\n```\n\n----------------------------------------\n\nTITLE: Streaming Results from Authoring Chain in LangGraph.js\nDESCRIPTION: This code snippet demonstrates how to stream results from the `authoringChain`. It invokes the chain with a user message asking to write a limerick and create a bar chart of the characters used. The results are streamed and each step of the stream is logged to the console, separated by '---'.  A recursion limit is set to 100.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: javascript\nCODE:\n```\nlet resultStream = await authoringChain.stream(\n  {{\n    messages: [\n      new HumanMessage(\n        \"Write a limerick and make a bar chart of the characters used.\",\n      ),\n    ],\n  }},\n  {{ recursionLimit: 100 }},\n);\n\nfor await (const step of resultStream) {{\n  console.log(step);\n  console.log(\"---\");\n}}\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Checkpointer-Pregel Interface in TypeScript\nDESCRIPTION: Defines the Pregel class with checkpointing capabilities and state management interfaces. Includes methods for retrieving and updating state snapshots.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/langgraph-architecture-spec.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nclass Pregel {\n  checkpointer?: BaseCheckpointSaver;\n  store?: BaseStore;\n\n  async getState(config?: RunnableConfig, options?: GetStateOptions): Promise<StateSnapshot> {\n    const cp = await this.checkpointer?.getTuple(config);\n    return this._prepareStateSnapshot(config, cp);\n  }\n\n  async getStateHistory(config?: RunnableConfig, options?: GetStateHistoryOptions): Promise<\n    AsyncIterable<StateSnapshot>\n  > {\n    // Returns history of checkpoints for time-travel\n  }\n  \n  async updateState(\n    inputConfig: RunnableConfig,\n    values: Record<string, any>,\n    asNode?: string\n  ): Promise<RunnableConfig> {\n    // Updates state from external inputs\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing a Configurable Graph Stream\nDESCRIPTION: This snippet demonstrates how to execute a compiled graph with runtime configuration parameters, including user data and model choice. It processes input messages, outputs responses, and logs intermediary data. Key dependencies include the LangGraphJS library.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/configuration.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n\nconst config = {\n  configurable: {\n    model: \"openai\",\n    user: \"user1\",\n  },\n};\nconst inputs = {\n  messages: [new HumanMessage(\"Could you remind me of my email??\")],\n};\nfor await (\n  const { messages } of await graph.stream(inputs, {\n    ...config,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Edge Logic for Conversation Flow Control\nDESCRIPTION: Implements the logic to determine when the conversation should end, either when the simulated user responds with 'FINISHED' or when the conversation exceeds a maximum number of messages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfunction shouldContinue(state: typeof MessagesAnnotation.State) {\n  const messages = state.messages;\n  if (messages.length > 6) {\n    return '__end__';\n  } else if (messages[messages.length - 1].content === 'FINISHED') {\n    return '__end__';\n  } else {\n    return 'continue';\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Graph Execution with Subgraph Events\nDESCRIPTION: Shows how to stream both parent graph and subgraph events by setting the subgraphs parameter to true, providing more detailed execution information.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nconst streamWithSubgraphs = await graph.stream({\n  messages: [{\n    role: \"user\",\n    content: \"what's the weather in sf\"\n  }]\n}, { configurable: { thread_id: \"3\" }, streamMode: \"updates\", subgraphs: true });\n\nfor await (const update of streamWithSubgraphs) {\n  console.log(update);\n}\n```\n\n----------------------------------------\n\nTITLE: Invoking the Compiled Workflow\nDESCRIPTION: Demonstrate how to use the compiled workflow with a sample input.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n\nconst inputs = {\n  messages: [new HumanMessage(\"what is the weather in sf\")],\n};\nawait app.invoke(inputs);\n```\n\n----------------------------------------\n\nTITLE: Agent Command in LangGraphJS\nDESCRIPTION: This TypeScript function represents a generic agent node in a LangGraphJS graph. It calls `getNextAgent` to determine the next agent to route to or halts if the agent can handle the user request, returning a command to update the graph's state and route to the next node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-multi-turn-convo.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nfunction agent(state: typeof MessagesAnnotation.State): Command {\n  // The condition for routing/halting can be anything, e.g. LLM tool call / structured output, etc.\n  const goto = getNextAgent(...); // 'agent' / 'anotherAgent'\n\n  if (goto) {\n    return new Command({\n      goto,\n      update: { myStateKey: \"myStateValue\" }\n    });\n  } else {\n    return new Command({\n      goto: \"human\"\n    });\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a LangGraph Workflow for Message Filtering\nDESCRIPTION: This code constructs a LangGraph workflow for message filtering, defining the nodes (agent and action), conditional edges based on the `shouldContinueMessageFiltering` function, and standard edges for transitioning between nodes.  The graph is then compiled into a LangChain Runnable.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-conversation-history.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Define a new graph\nconst messageFilteringWorkflow = new StateGraph(MessageFilteringAgentState)\n  // Define the two nodes we will cycle between\n  .addNode(\"agent\", callModelMessageFiltering)\n  .addNode(\"action\", messageFilteringToolNode)\n  // We now add a conditional edge\n  .addConditionalEdges(\n    // First, we define the start node. We use `agent`.\n    // This means these are the edges taken after the `agent` node is called.\n    \"agent\",\n    // Next, we pass in the function that will determine which node is called next.\n    shouldContinueMessageFiltering\n  )\n  // We now add a normal edge from `action` to `agent`.\n  // This means that after `action` is called, `agent` node is called next.\n  .addEdge(\"action\", \"agent\")\n  // Set the entrypoint as `agent`\n  // This means that this node is the first one called\n  .addEdge(START, \"agent\");\n\n// Finally, we compile it!\n// This compiles it into a LangChain Runnable,\n// meaning you can use it as you would any other runnable\nconst messageFilteringApp = messageFilteringWorkflow.compile({\n    checkpointer: messageFilteringMemory,\n});\n```\n\n----------------------------------------\n\nTITLE: Resuming Workflow Streaming in LangGraphJS\nDESCRIPTION: This snippet demonstrates how to resume streaming from a workflow after an interruption using a resume command in the configuration object, processing data chunks as they arrive.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Command } from \"@langchain/langgraph\";\n\nconst config = {\n  configurable: {\n    thread_id: \"some_thread_id\",\n  },\n};\n\nconst stream = await myWorkflow.stream(\n  new Command({ resume: someResumeValue }),\n  config,\n);\n\nfor await (const chunk of stream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Memory to LangGraph Multi-Agent Swarm\nDESCRIPTION: TypeScript code showing how to add short-term and long-term memory to a swarm multi-agent system using LangGraph's checkpointer and store.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-swarm/README.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MemorySaver, InMemoryStore } from \"@langchain/langgraph\";\n\n// short-term memory\nconst checkpointer = new MemorySaver()\n// long-term memory\nconst store = new InMemoryStore()\n\nalice = ...\nbob = ...\n\nconst workflow = createSwarm({\n  agents: [alice, bob],\n  defaultActiveAgent: \"Alice\",\n})\n\n// Compile with checkpointer/store\nconst app = workflow.compile({\n  checkpointer,\n  store\n})\n```\n\n----------------------------------------\n\nTITLE: Running the Plan-Execute Agent on a Sample Query\nDESCRIPTION: Demonstrates how to stream the agent's execution process for a sample question about the 2024 Australian Open winner's hometown. The code sets up recursion limits and streams each event in the execution process.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = { recursionLimit: 50 };\nconst inputs = {\n  input: \"what is the hometown of the 2024 Australian open winner?\",\n};\n\nfor await (const event of await app.stream(inputs, config)) {\n  console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring and Invoking a Graph in TypeScript\nDESCRIPTION: This code snippet shows setting runtime configurations for LangGraphJS to switch models or system prompts. Configuration is passed to the graph via a config object, and nodes can then access these configurations to modify behaviors accordingly.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = { configurable: { llm: \"anthropic\" } };\n\nawait graph.invoke(inputs, config);\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst nodeA = (state, config) => {\n  const llmType = config?.configurable?.llm;\n  let llm: BaseChatModel;\n  if (llmType) {\n    const llm = getLlm(llmType);\n  }\n  ...\n};\n```\n\n----------------------------------------\n\nTITLE: Setting up the ChatOpenAI Model\nDESCRIPTION: Initialize the ChatOpenAI model with streaming enabled and bind it with the tools.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { convertToOpenAIFunction } from \"@langchain/core/utils/function_calling\";\n\nconst model = new ChatOpenAI({\n  temperature: 0,\n  streaming: true,\n});\n\nconst toolsAsOpenAIFunctions = tools.map((tool) =>\n  convertToOpenAIFunction(tool)\n);\nconst newModel = model.bind({\n  functions: toolsAsOpenAIFunctions,\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Authentication Handler in TypeScript\nDESCRIPTION: This code snippet demonstrates how to implement a custom authentication handler using the LangGraph SDK. It validates an API key from the request headers, and returns user information or throws an HTTPException for invalid credentials.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/auth.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Auth, HTTPException } from \"@langchain/langgraph-sdk/auth\";\n\n// (1) Validate the credentials\nconst isValidKey = (key: string) => {\n  return true;\n};\n\nexport const auth = new Auth().authenticate(async (request: Request) => {\n  const apiKey = request.headers.get(\"x-api-key\");\n\n  if (!apiKey || !isValidKey(apiKey)) {\n    // (3) Raise an HTTPException\n    throw new HTTPException(401, { message: \"Invalid API key\" });\n  }\n\n  // (2) Return user information containing the user's identity and user information if valid\n  return {\n    // required, unique user identifier\n    identity: \"user-123\",\n    // required, list of permissions\n    permissions: [],\n    // optional, assumed `true` by default\n    is_authenticated: true,\n\n    // You can add more custom fields if you want to implement other auth patterns\n    role: \"admin\",\n    org_id: \"org-123\",\n  };\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Message Filtering Agent State and Tools in LangGraphJS\nDESCRIPTION: This code snippet initializes the agent state and defines tools for message filtering within a LangGraph. It sets up the agent's memory, search tool, and the language model for interacting with the user.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-conversation-history.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { tool } from \"@langchain/core/tools\";\nimport { BaseMessage, AIMessage } from \"@langchain/core/messages\";\nimport { StateGraph, Annotation, START, END } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport { MemorySaver } from \"@langchain/langgraph\";\nimport { z } from \"zod\";\n\nconst MessageFilteringAgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({ \n    reducer: (x, y) => x.concat(y),\n  }),\n});\n\nconst messageFilteringMemory = new MemorySaver();\n\nconst messageFilteringSearchTool = tool((_): string => {\n    // This is a placeholder for the actual implementation\n    // Don't let the LLM know this though 😊\n    return \"It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\"\n}, {\n    name: \"search\",\n    description: \"Call to surf the web.\",\n    schema: z.object({\n        query: z.string()\n    })\n})\n\n// We can re-use the same search tool as above as we don't need to change it for this example.\nconst messageFilteringTools = [messageFilteringSearchTool]\nconst messageFilteringToolNode = new ToolNode<typeof MessageFilteringAgentState.State>(messageFilteringTools)\nconst messageFilteringModel = new ChatAnthropic({ model: \"claude-3-haiku-20240307\" })\nconst boundMessageFilteringModel = messageFilteringModel.bindTools(messageFilteringTools)\n```\n\n----------------------------------------\n\nTITLE: Updating State to Bypass Dynamic Breakpoint in LangGraphJS\nDESCRIPTION: Shows how to modify the graph state to meet the conditions required to bypass a dynamic breakpoint, enabling execution to continue with updated state values.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Update the state to pass the dynamic breakpoint\nawait graph.updateState(threadConfig, { input: \"foo\" });\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Conditional Edges with Send in TypeScript\nDESCRIPTION: This snippet demonstrates how to dynamically manage node connections using the 'Send' object to handle scenarios where the edges are not predetermined. It returns 'Send' objects from a function to add conditional edges to a graph dynamically. Dependencies include LangGraphJS and basic JavaScript. Each 'Send' object maps to a new state containing the subject for processing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst continueToJokes = (state: { subjects: string[] }) => {\n  return state.subjects.map(\n    (subject) => new Send(\"generate_joke\", { subject })\n  );\n};\n\ngraph.addConditionalEdges(\"nodeA\", continueToJokes);\n```\n\n----------------------------------------\n\nTITLE: Single-Owner Resource Access Pattern - TypeScript\nDESCRIPTION: This snippet provides an example of a common single-owner resource access pattern. It ensures that all actions for threads include the owner's identity as metadata.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/auth.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Auth, HTTPException } from \"@langchain/langgraph-sdk/auth\";\n\nexport const auth = new Auth()\n  .authenticate(async (request: Request) => ({\n    identity: \"user-123\",\n    permissions: [\"threads:write\", \"threads:read\"],\n  }))\n  .on(\"*\", ({ value, user }) => {\n    if (\"metadata\" in value) {\n      value.metadata ??= {};\n      value.metadata.owner = user.identity;\n    }\n    return { owner: user.identity };\n  });\n```\n\n----------------------------------------\n\nTITLE: Running Graph with User Input in JavaScript\nDESCRIPTION: This code runs the main graph with a user input message about weather in San Francisco. It demonstrates how to initialize and stream a graph execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: javascript\nCODE:\n```\nconst graphStream = await graph.stream({\n  messages: [{\n    role: \"user\",\n    content: \"what's the weather in sf\"\n  }],\n}, {\n  configurable: {\n    thread_id: \"4\",\n  }\n});\n\nfor await (const update of graphStream) {\n  console.log(update);\n}\n```\n\n----------------------------------------\n\nTITLE: Updating LangGraph Agent State\nDESCRIPTION: This code snippet shows how to update the state of the LangGraph agent, specifically modifying the tool call arguments to change the search query.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n// First, lets get the current state\nconst currentState = await app.getState(config);\n\n// Let's now get the last message in the state\n// This is the one with the tool calls that we want to update\nlet lastMessage = currentState.values.messages[currentState.values.messages.length - 1]\n\n// Let's now update the args for that tool call\nlastMessage.tool_calls[0].args = { query: \"current weather in SF\" }\n\n// Let's now call `updateState` to pass in this message in the `messages` key\n// This will get treated as any other update to the state\n// It will get passed to the reducer function for the `messages` key\n// That reducer function will use the ID of the message to update it\n// It's important that it has the right ID! Otherwise it would get appended\n// as a new message\nawait app.updateState(config, { messages: lastMessage });\n```\n\n----------------------------------------\n\nTITLE: Skipping Interrupted Node in StateGraph Execution in TypeScript\nDESCRIPTION: This code demonstrates how to update the StateGraph's state to skip over the interrupted node entirely and resume execution from the next node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamic_breakpoints.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst config3 = {\n  configurable: {\n    thread_id: \"3\",\n  },\n  streamMode: \"values\" as const,\n};\n\nconst skipStream = await graph.stream({ input: \"hello world\" }, config3);\n\n// Run the graph until the first interruption\nfor await (const event of skipStream) {\n  console.log(event);\n}\n\n// NOTE: this update will skip the node `step2` entirely\nawait graph.updateState(config3, undefined, \"step2\");\n\n// Resume the stream\nfor await (const event of await graph.stream(null, config3)) {\n  console.log(event);\n}\n\nconst state5 = await graph.getState(config3);\nconsole.log(state5.next);\nconsole.log(state5.values);\n```\n\n----------------------------------------\n\nTITLE: Replaying LangGraph from Specific Checkpoint\nDESCRIPTION: This code snippet demonstrates how to replay a LangGraph execution from a specific checkpoint. The `checkpoint_id` is included in the `threadConfig` to specify the checkpoint to replay from. The code then streams events from the graph starting from the specified checkpoint and logs them to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/time-travel.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst threadConfig = { configurable: { thread_id: '1', checkpoint_id: 'xyz' }, streamMode: \"values\" };\n\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Custom Tool Executor for Handling Commands - Python\nDESCRIPTION: Example of a custom implementation that handles Command objects returned from tools without using prebuilt components, showing how to process mixed Command and non-Command outputs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/update-state-from-tools.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport {\n  MessagesAnnotation,\n  isCommand,\n  Command,\n  StateGraph,\n} from \"@langchain/langgraph\";\nimport { tool } from \"@langchain/core/tools\";\nimport { isAIMessage } from \"@langchain/core/messages\";\n\nimport { z } from \"zod\";\n\nconst myTool = tool(async () => {\n  return new Command({\n    update: {\n      messages: [\n        {\n          role: \"assistant\",\n          content: \"hi there!\",\n          name: \"Greeter\",\n        }\n      ],\n    },\n  });\n}, {\n  name: \"greeting\",\n  description: \"Updates the current state with a greeting\",\n  schema: z.object({}),\n});\n\nconst toolExecutor = async (state: typeof MessagesAnnotation.State) => {\n  const message = state.messages.at(-1);\n  if (!isAIMessage(message) || message.tool_calls === undefined || message.tool_calls.length === 0) {\n    throw new Error(\"Most recent message must be an AIMessage with a tool call.\")\n  }\n  const outputs = await Promise.all(\n    message.tool_calls.map(async (toolCall) => {\n      // Using a single tool for simplicity, would need to select tools by toolCall.name\n      // in practice.\n      const toolResult = await myTool.invoke(toolCall);\n      return toolResult;\n    })\n  );\n  // Handle mixed Command and non-Command outputs\n  const combinedOutputs = outputs.map((output) => {\n    if (isCommand(output)) {\n      return output;\n    }\n    // Tool invocation result is a ToolMessage, return a normal state update\n    return { messages: [output] };\n  });\n  // Return an array of values instead of an object\n  return combinedOutputs;\n};\n\n// Simple one node graph\nconst customGraph = new StateGraph(MessagesAnnotation)\n  .addNode(\"runTools\", toolExecutor)\n  .addEdge(\"__start__\", \"runTools\")\n  .compile();\n  \nawait customGraph.invoke({\n  messages: [{\n    role: \"user\",\n    content: \"how are you?\",\n  }, {\n    role: \"assistant\",\n    content: \"Let me call the greeting tool and find out!\",\n    tool_calls: [{\n      id: \"123\",\n      args: {},\n      name: \"greeting\",\n    }],\n  }],\n});\n```\n\n----------------------------------------\n\nTITLE: Invoking the Base Graph and Displaying Results\nDESCRIPTION: Code to execute the graph with an initial empty aggregate array and display the results.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Invoke the graph\nconst baseResult = await graph.invoke({ aggregate: [] });\nconsole.log(\"Base Result: \", baseResult);\n```\n\n----------------------------------------\n\nTITLE: Building the LangGraph State Graph with Checkpointing\nDESCRIPTION: Construction of a StateGraph with nodes for the agent and tools, routing logic for handling tool calls, and integration with a MemorySaver for in-memory checkpoint storage to enable time travel functionality.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\nimport { AIMessage } from \"@langchain/core/messages\";\nimport { RunnableConfig } from \"@langchain/core/runnables\";\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst routeMessage = (state: typeof StateAnnotation.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  // If no tools are called, we can finish (respond to the user)\n  if (!lastMessage?.tool_calls?.length) {\n    return END;\n  }\n  // Otherwise if there is, we continue and call the tools\n  return \"tools\";\n};\n\nconst callModel = async (\n  state: typeof StateAnnotation.State,\n  config?: RunnableConfig,\n): Promise<Partial<typeof StateAnnotation.State>> => {\n  const { messages } = state;\n  const response = await boundModel.invoke(messages, config);\n  return { messages: [response] };\n};\n\nconst workflow = new StateGraph(StateAnnotation)\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  .addEdge(START, \"agent\")\n  .addConditionalEdges(\"agent\", routeMessage)\n  .addEdge(\"tools\", \"agent\");\n\n// Here we only save in-memory\nlet memory = new MemorySaver();\nconst graph = workflow.compile({ checkpointer: memory });\n```\n\n----------------------------------------\n\nTITLE: Example: Writing Document with LangGraphJS Tool\nDESCRIPTION: Example invocation of the writeDocumentTool to create a simple text file in the working directory. This demonstrates how the document writing tool would be used by an agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nawait writeDocumentTool.invoke({\n  content: \"Hello from LangGraph!\",\n  file_name: \"hello.txt\",\n});\n```\n\n----------------------------------------\n\nTITLE: Replaying LangGraph from Current State\nDESCRIPTION: This code snippet demonstrates how to replay a LangGraph execution from the current state by passing `null` as the input along with a `threadConfig`. The `thread_id` identifies the thread, and `streamMode` is set to \"values\" to receive stream events. The loop iterates through the events and logs them to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/time-travel.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst threadConfig = { configurable: { thread_id: \"1\" }, streamMode: \"values\" };\n\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Using .streamEvents to Stream Custom Data - Python\nDESCRIPTION: This snippet defines a graph node that uses dispatchCustomEvent to emit custom events while streaming data. The node simulates progress reporting by dispatching events.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-content.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { dispatchCustomEvent } from \"@langchain/core/callbacks/dispatch\";\\n\\nconst graphNode = async (_state: typeof MessagesAnnotation.State) => {\\n  const chunks = [\\n    \"Four\",\\n    \"score\",\\n    \"and\",\\n    \"seven\",\\n    \"years\",\\n    \"ago\",\\n    \"our\",\\n    \"fathers\",\\n    \"...\",\\n  ];\\n  for (const chunk of chunks) {\\n    await dispatchCustomEvent(\"my_custom_event\", { chunk });\\n  }\\n  return {\\n    messages: [{\\n      role: \"assistant\",\\n      content: chunks.join(\" \"),\\n    }],\\n  };\\n};\\n\\nconst graphWithDispatch = new StateGraph(MessagesAnnotation)\\n  .addNode(\"model\", graphNode)\\n  .addEdge(\"__start__\", \"model\")\\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Defining the Graph and Streaming Custom Data - Python\nDESCRIPTION: This snippet defines a StateGraph and implements a node that streams custom data using the streamMode set to 'custom'. The function 'myNode' simulates streaming data by writing chunks to a writer located in the config object.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-content.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport {\\n  StateGraph,\\n  MessagesAnnotation,\\n  LangGraphRunnableConfig,\\n} from \"@langchain/langgraph\";\\n\\nconst myNode = async (\\n  _state: typeof MessagesAnnotation.State,\\n  config: LangGraphRunnableConfig\\n) => {\\n  const chunks = [\\n    \"Four\",\\n    \"score\",\\n    \"and\",\\n    \"seven\",\\n    \"years\",\\n    \"ago\",\\n    \"our\",\\n    \"fathers\",\\n    \"...\",\\n  ];\\n  for (const chunk of chunks) {\\n    // write the chunk to be streamed using streamMode=custom\\n    // Only populated if one of the passed stream modes is \"custom\".\\n    config.writer?.(chunk);\\n  }\\n  return {\\n    messages: [{\\n      role: \"assistant\",\\n      content: chunks.join(\" \"),\\n    }],\\n  };\\n};\\n\\nconst graph = new StateGraph(MessagesAnnotation)\\n  .addNode(\"model\", myNode)\\n  .addEdge(\"__start__\", \"model\")\\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Utilizing the Agent to Process Input in Python\nDESCRIPTION: This snippet demonstrates how to use the constructed agent to process input messages, capturing the output in a pretty print format that highlights tool usage.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport { HumanMessage, isAIMessage } from \"@langchain/core/messages\";\n\nconst prettyPrint = (message: BaseMessage) => {\n  let txt = `[${message._getType()}]: ${message.content}`;\n  if (\n    isAIMessage(message) && message?.tool_calls?.length\n  ) {\n    const tool_calls = message?.tool_calls\n      ?.map((tc) => `- ${tc.name}(${JSON.stringify(tc.args)})`)\n      .join(\"\\n\");\n    txt += ` \\nTools: \\n${tool_calls}`;\n  }\n  console.log(txt);\n};\n\nconst inputs = {\n  messages: [new HumanMessage(\"what is the weather in sf\")],\n};\n\nconst stream = await app.stream(inputs, { streamMode: \"values\" });\n\nfor await (const output of stream) {\n  const { messages } = output;\n  prettyPrint(messages[messages.length - 1]);\n  console.log(\"\\n---\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Create a Parent Graph with a Subgraph and Node Navigation\nDESCRIPTION: This snippet showcases how to define a subgraph and integrate it into a parent graph. The key feature is the ability for the subgraph (`nodeASubgraph`) to navigate to different nodes (`nodeB`, `nodeC`) within the parent graph using `Command.PARENT`.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/command.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst subgraph = new StateGraph(StateAnnotation)\n  .addNode(\"nodeA\", nodeASubgraph)\n  .addEdge(\"__start__\", \"nodeA\")\n  .compile();\n\nconst parentGraph= new StateGraph(StateAnnotation)\n  .addNode(\"subgraph\", subgraph, { ends: [\"nodeB\", \"nodeC\"] })\n  .addNode(\"nodeB\", nodeB)\n  .addNode(\"nodeC\", nodeC)\n  .addEdge(\"__start__\", \"subgraph\")\n  .compile();\n  \nawait parentGraph.invoke({ foo: \"\" });\n```\n\n----------------------------------------\n\nTITLE: Multi-Vector Indexing for Memory Storage in LangGraph.js\nDESCRIPTION: This snippet implements multi-vector indexing to store and search different aspects of memories separately. It configures a store to embed both memory content and emotional context, allowing more nuanced memory retrieval based on different search criteria.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\n// Configure store to embed both memory content and emotional context\nconst multiVectorStore = new InMemoryStore({\n  index: {\n    embeddings: embeddings,\n    dims: 1536,\n    fields: [\"memory\", \"emotional_context\"],\n  },\n});\n\n// Store memories with different content/emotion pairs\nawait multiVectorStore.put([\"user_123\", \"memories\"], \"mem1\", {\n  memory: \"Had pizza with friends at Mario's\",\n  emotional_context: \"felt happy and connected\",\n  this_isnt_indexed: \"I prefer ravioli though\",\n});\nawait multiVectorStore.put([\"user_123\", \"memories\"], \"mem2\", {\n  memory: \"Ate alone at home\",\n  emotional_context: \"felt a bit lonely\",\n  this_isnt_indexed: \"I like pie\",\n});\n\n// Search focusing on emotional state - matches mem2\nconst results = await multiVectorStore.search([\"user_123\", \"memories\"], {\n  query: \"times they felt isolated\",\n  limit: 1,\n});\n\nconsole.log(\"Expect mem 2\");\n\nfor (const r of results) {\n  console.log(`Item: ${r.key}; Score(${r.score})`);\n  console.log(`Memory: ${r.value.memory}`);\n  console.log(`Emotion: ${r.value.emotional_context}`);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Namespace for User Memories\nDESCRIPTION: This snippet defines a namespace for storing user-specific memories in the form of a tuple. The namespace includes a user ID and the string 'memories' to categorize the stored data. It emphasizes the arbitrary nature of the namespace choice, accommodating various data categorization needs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_8\n\nLANGUAGE: TypeScript\nCODE:\n```\nconst userId = \"1\";\nconst namespaceForMemory = [userId, \"memories\"];\n```\n\n----------------------------------------\n\nTITLE: Testing Multi-Turn Conversations with Langchain in JavaScript\nDESCRIPTION: This JavaScript snippet tests multi-turn conversations with the Langchain framework. It uses UUID for conversation thread configuration and demonstrates how to interrupt and resume conversation using the Command primitive. Dependencies include the Langchain Command and uuid modules. Inputs are structured as messages with user roles, and conversation progresses with the help of asynchronous iteration over inputs. The script outputs the conversation turns and AI responses. Assumes the presence of a 'graph' object capable of streaming conversation updates.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-multi-turn-convo.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { Command } from \"@langchain/langgraph\";\nimport { v4 as uuidv4 } from \"uuid\";\n\nconst threadConfig = { configurable: { thread_id: uuidv4() }, streamMode: \"values\" as const };\n\nconst inputs = [\n  // 1st round of conversation\n  {\n    messages: [\n      { role: \"user\", content: \"i wanna go somewhere warm in the caribbean\" }\n    ]\n  },\n  // Since we're using `interrupt`, we'll need to resume using the Command primitive.\n  // 2nd round of conversation\n  new Command({\n    resume: \"could you recommend a nice hotel in one of the areas and tell me which area it is.\"\n  }),\n  // Third round of conversation\n  new Command({ resume: \"could you recommend something to do near the hotel?\" }),\n]\n\nlet iter = 0;\nfor await (const userInput of inputs) {\n  iter += 1;\n  console.log(`\\n--- Conversation Turn ${iter} ---\\n`);\n  console.log(`User: ${JSON.stringify(userInput)}\\n`);\n\n  for await (const update of await graph.stream(userInput, threadConfig)) {\n    const lastMessage = update.messages ? update.messages[update.messages.length - 1] : undefined;\n    if (lastMessage && lastMessage._getType() === \"ai\") {\n      console.log(`${lastMessage.name}: ${lastMessage.content}`)\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Task Function in LangGraphJS\nDESCRIPTION: This snippet shows how to define a task in LangGraphJS using the task function, which wraps asynchronous operations, and highlights the need for output serialization for checkpointing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\nimport { task } from \"@langchain/langgraph\";\n\nconst slowComputation = task({\"slowComputation\", async (inputValue: any) => {\n  // Simulate a long-running operation\n  ...\n  return result;\n});\n```\n\n----------------------------------------\n\nTITLE: Resuming Subgraph Execution from Model Node in JavaScript\nDESCRIPTION: This snippet demonstrates how to resume execution from a specific node (modelNode) within a subgraph. It uses the previously retrieved subgraph state to configure the stream and logs the execution updates.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: javascript\nCODE:\n```\nconst resumeSubgraphStream = await graph.stream(null, {\n  ...subgraphStateBeforeModelNode.config,\n  streamMode: \"updates\",\n  subgraphs: true\n});\n\nfor await (const value of resumeSubgraphStream) {\n  console.log(value);\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing the StateGraph for ReAct Agent\nDESCRIPTION: Code to generate and display a visual representation of the StateGraph using Mermaid diagrams, providing a clearer understanding of the agent's workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraph = app.getGraph();\nconst image = await drawableGraph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Calling OpenAI Model with LangGraph Node - Python\nDESCRIPTION: This snippet defines a method `callModel` to call the OpenAI model using a LangGraph node. It streams data with custom callback events and handles model responses. Dependencies include `dispatchCustomEvent` and `wrapOpenAI` for tracing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-tokens-without-langchain.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { dispatchCustomEvent } from \"@langchain/core/callbacks/dispatch\";\nimport { wrapOpenAI } from \"langsmith/wrappers/openai\";\nimport { Annotation } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  messages: Annotation<OpenAI.ChatCompletionMessageParam[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n\nconst wrappedClient = wrapOpenAI(openaiClient);\n\nconst callModel = async (state: typeof StateAnnotation.State) => {\n  const { messages } = state;\n  const stream = await wrappedClient.chat.completions.create({\n    messages,\n    model: \"gpt-4o-mini\",\n    tools: [toolSchema],\n    stream: true,\n  });\n  let responseContent = \"\";\n  let role: string = \"assistant\";\n  let toolCallId: string | undefined;\n  let toolCallName: string | undefined;\n  let toolCallArgs = \"\";\n  for await (const chunk of stream) {\n    const delta = chunk.choices[0].delta;\n    if (delta.role !== undefined) {\n      role = delta.role;\n    }\n    if (delta.content) {\n      responseContent += delta.content;\n      await dispatchCustomEvent(\"streamed_token\", {\n        content: delta.content,\n      });\n    }\n    if (delta.tool_calls !== undefined && delta.tool_calls.length > 0) {\n      const toolCall = delta.tool_calls[0];\n      if (toolCall.function?.name !== undefined) {\n        toolCallName = toolCall.function.name;\n      }\n      if (toolCall.id !== undefined) {\n        toolCallId = toolCall.id;\n      }\n      await dispatchCustomEvent(\"streamed_tool_call_chunk\", toolCall);\n      toolCallArgs += toolCall.function?.arguments ?? \"\";\n    }\n  }\n  let finalToolCalls;\n  if (toolCallName !== undefined && toolCallId !== undefined) {\n    finalToolCalls = [{\n      id: toolCallId,\n      function: {\n        name: toolCallName,\n        arguments: toolCallArgs\n      },\n      type: \"function\" as const,\n    }];\n  }\n\n  const responseMessage = {\n    role: role as any,\n    content: responseContent,\n    tool_calls: finalToolCalls,\n  };\n  return { messages: [responseMessage] };\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a StateGraph with cross-thread persistence in LangGraph.js\nDESCRIPTION: Defines a StateGraph with a callModel node that uses the InMemoryStore for cross-thread persistence. The graph is compiled with the store and a MemorySaver for checkpointing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { v4 as uuidv4 } from \"uuid\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport {\n  Annotation,\n  StateGraph,\n  START,\n  MemorySaver,\n  LangGraphRunnableConfig,\n  messagesStateReducer,\n} from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: messagesStateReducer,\n    default: () => [],\n  }),\n});\n\nconst model = new ChatAnthropic({ modelName: \"claude-3-5-sonnet-20240620\" });\n\nconst callModel = async (\n  state: typeof StateAnnotation.State,\n  config: LangGraphRunnableConfig\n): Promise<{ messages: any }> => {\n  const store = config.store;\n  if (!store) {\n    if (!store) {\n      throw new Error(\"store is required when compiling the graph\");\n    }\n  }\n  if (!config.configurable?.userId) {\n    throw new Error(\"userId is required in the config\");\n  }\n  const namespace = [\"memories\", config.configurable?.userId];\n  const memories = await store.search(namespace);\n  const info = memories.map((d) => d.value.data).join(\"\\n\");\n  const systemMsg = `You are a helpful assistant talking to the user. User info: ${info}`;\n\n  // Store new memories if the user asks the model to remember\n  const lastMessage = state.messages[state.messages.length - 1];\n  if (\n    typeof lastMessage.content === \"string\" &&\n    lastMessage.content.toLowerCase().includes(\"remember\")\n  ) {\n    await store.put(namespace, uuidv4(), { data: lastMessage.content });\n  }\n\n  const response = await model.invoke([\n    { type: \"system\", content: systemMsg },\n    ...state.messages,\n  ]);\n  return { messages: response };\n};\n\nconst builder = new StateGraph(StateAnnotation)\n  .addNode(\"call_model\", callModel)\n  .addEdge(START, \"call_model\");\n\nconst graph = builder.compile({\n  checkpointer: new MemorySaver(),\n  store: inMemoryStore,\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Search Tool with Direct Return Option in TypeScript\nDESCRIPTION: This snippet defines a custom search tool using Zod schema, including a 'return_direct' option to allow the agent to decide whether to return results directly to the user.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamically-returning-directly.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { DynamicStructuredTool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst SearchTool = z.object({\n  query: z.string().describe(\"query to look up online\"),\n  // **IMPORTANT** We are adding an **extra** field here\n  // that isn't used directly by the tool - it's used by our\n  // graph instead to determine whether or not to return the\n  // result directly to the user\n  return_direct: z.boolean()\n    .describe(\n      \"Whether or not the result of this should be returned directly to the user without you seeing what it is\",\n    )\n    .default(false),\n});\n\nconst searchTool = new DynamicStructuredTool({\n  name: \"search\",\n  description: \"Call to surf the web.\",\n  // We are overriding the default schema here to\n  // add an extra field\n  schema: SearchTool,\n  func: async ({}: { query: string }) => {\n    // This is a placeholder for the actual implementation\n    // Don't let the LLM know this though 😊\n    return \"It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\";\n  },\n});\n\nconst tools = [searchTool];\n```\n\n----------------------------------------\n\nTITLE: Invoking Parent Graph\nDESCRIPTION: This snippet illustrates the invocation of a parent graph which coordinates the transitions through its child and grandchild graphs. Running this will process the initial state input and execute defined transformations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-transform-state.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nawait parentGraph.invoke({ myKey: \"Bob\" })\n```\n\n----------------------------------------\n\nTITLE: Defining the Routing Logic in Python\nDESCRIPTION: This snippet defines the logic for routing decisions within the state graph, determining whether to continue or end processing based on the last message's content.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport { AIMessage } from \"@langchain/core/messages\";\nimport { RunnableConfig } from \"@langchain/core/runnables\";\n\nconst route = (state: typeof GraphState.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  // If there is no function call, then we finish\n  if (!lastMessage.tool_calls || lastMessage.tool_calls.length === 0) {\n    return \"__end__\";\n  }\n  // Otherwise if there is, we need to check what type of function call it is\n  if (lastMessage.tool_calls[0].name === \"Response\") {\n    return \"__end__\";\n  }\n  // Otherwise we continue\n  return \"tools\";\n};\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAI Chat Model and Tool in JavaScript\nDESCRIPTION: This code snippet defines an OpenAI chat model and a placeholder tool for fetching weather information. The `ChatOpenAI` class is used to instantiate the model, and the `tool` decorator is used to define the `getWeather` tool with its schema and functionality. The weather tool returns hardcoded weather for specific locations, such as San Francisco and Boston.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n\"import { ChatOpenAI } from \\\"@langchain/openai\\\";\\nimport { tool } from \\\"@langchain/core/tools\\\";\\nimport { z } from \\\"zod\\\";\\n\\nconst model = new ChatOpenAI({\\n  model: \\\"gpt-4o-mini\\\",\\n});\\n\\nconst getWeather = tool(async ({ location }) => {\\n  const lowercaseLocation = location.toLowerCase();\\n  if (lowercaseLocation.includes(\\\"sf\\\") || lowercaseLocation.includes(\\\"san francisco\\\")) {\\n    return \\\"It's sunny!\\\";\\n  } else if (lowercaseLocation.includes(\\\"boston\\\")) {\\n    return \\\"It's rainy!\\\";\\n  } else {\\n    return `I am not sure what the weather is in ${location}`\\n  }\\n}, {\\n  name: \\\"getWeather\\\",\\n  schema: z.object({\\n    location: z.string().describe(\\\"location to get the weather for\\\"),\\n  }),\\n  description: \\\"Call to get the weather from a specific location.\\\"\\n});\\n\\nconst tools = [getWeather];\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Travel Advisor Agent - TypeScript\nDESCRIPTION: This snippet demonstrates the creation of a travel advisor agent using LangGraph's `createReactAgent` function, incorporating predefined tools including the transfer tool defined earlier.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst travelAdvisorTools = [transferToHotelAdvisor, ...];\nconst travelAdvisor = createReactAgent({\n  llm: model,\n  tools: travelAdvisorTools,\n});\n```\n\n----------------------------------------\n\nTITLE: Node Logic for Answer Generation in JavaScript\nDESCRIPTION: This snippet outlines the logic for generating the final answer by combining the retrieved documents with the original question. It joins the elements into a cohesive response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/pass_private_state.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nconst generate = async (state: typeof GenerateOutputAnnotation.State) => {\n  return {\n    answer: state.docs.concat([state.question]).join(\"\\n\\n\"),\n  };\n};\n```\n\n----------------------------------------\n\nTITLE: Initializing Game State and NPC Agents in TypeScript\nDESCRIPTION: Defines the game state structure and implements NPC agent behaviors using LangGraph's StateGraph. Includes state management for resources (wood, food, gold) and agent decision logic for villager, guard, merchant, and thief NPCs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Command, StateGraph, Annotation } from \"@langchain/langgraph\";\n\nconst GameStateAnnotation = Annotation.Root({\n  wood: Annotation<number>({\n    default: () => 0,\n    reducer: (a, b) => a + b,\n  }),\n  food: Annotation<number>({\n    default: () => 0,\n    reducer: (a, b) => a + b,\n  }),\n  gold: Annotation<number>({\n    default: () => 0,\n    reducer: (a, b) => a + b,\n  }),\n  guardOnDuty: Annotation<boolean>,\n});\n\nconst villager = async (state: typeof GameStateAnnotation.State) => {\n  const currentResources = state.wood + state.food;\n  if (currentResources < 15) {\n    console.log(\"Villager gathering resources.\");\n    return new Command({\n      goto: \"villager\",\n      update: {\n        wood: 3,\n        food: 1,\n      },\n    });\n  }\n  return new Command({\n    goto: \"__end__\",\n  });\n}\n\nconst guard = async (state: typeof GameStateAnnotation.State) => {\n  if (!state.guardOnDuty) {\n    return new Command({\n      goto: \"__end__\",\n    });\n  }\n  if (state.food > 0) {\n    console.log(\"Guard patrolling.\");\n    return new Command({\n      goto: \"guard\",\n      update: { food: -1 },\n    });\n  }\n  console.log(\"Guard leaving to get food.\");\n  return new Command({\n    goto: \"__end__\",\n    update: {\n      guardOnDuty: false,\n    },\n  });\n};\n\nconst merchant = async (state: typeof GameStateAnnotation.State) => {\n  if (state.wood >= 5) {\n    console.log(\"Merchant trading wood for gold.\");\n    return new Command({\n      goto: \"merchant\", \n      update: {\n        wood: -5,\n        gold: 1\n      }\n    });\n  }\n  return new Command({\n    goto: \"__end__\"\n  });\n};\n\nconst thief = async (state: typeof GameStateAnnotation.State) => {\n  if (!state.guardOnDuty) {\n    console.log(\"Thief stealing gold.\");\n    return new Command({\n      goto: \"__end__\",\n      update: { gold: -state.gold }\n    });\n  }\n  return new Command({\n    goto: \"thief\"\n  });\n};\n\nconst gameGraph = new StateGraph(GameStateAnnotation)\n  .addNode(\"villager\", villager, {\n    ends: [\"villager\", \"__end__\"],\n  })\n  .addNode(\"guard\", guard, {\n    ends: [\"guard\", \"__end__\"],\n  })\n  .addNode(\"merchant\", merchant, {\n    ends: [\"merchant\", \"__end__\"],\n  })\n  .addNode(\"thief\", thief, {\n    ends: [\"thief\", \"__end__\"],\n  })\n  .addEdge(\"__start__\", \"villager\")\n  .addEdge(\"__start__\", \"guard\")\n  .addEdge(\"__start__\", \"merchant\")\n  .addEdge(\"__start__\", \"thief\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Node Handlers for CUA Actions\nDESCRIPTION: Example of creating custom node handlers that run before and after computer actions, allowing for fine-grained control of the agent's workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createCua, CUAState, CUAUpdate } from \"@langchain/langgraph-cua\";\nimport { LangGraphRunnableConfig } from \"@langchain/langgraph\";\n\n// Custom node that runs before a computer action\nasync function customNodeBefore(\n  state: CUAState,\n  config: LangGraphRunnableConfig\n): Promise<CUAUpdate> {\n  console.log(\"Running before computer action\");\n  // You can modify the state here\n  return {};\n}\n\n// Custom node that runs after a computer action\nasync function customNodeAfter(\n  state: CUAState,\n  config: LangGraphRunnableConfig\n): Promise<CUAUpdate> {\n  console.log(\"Running after computer action\");\n  // You can process the results of the computer action here\n  return {};\n}\n\nconst cuaGraph = createCua({\n  nodeBeforeAction: customNodeBefore,\n  nodeAfterAction: customNodeAfter,\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing ChatOpenAI Model\nDESCRIPTION: This snippet shows how to initialize a ChatOpenAI model with specific parameters for use in the LangGraphJS workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o\",\n  temperature: 0,\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Graph State with Subgraph Details\nDESCRIPTION: Demonstrates how to get the complete state including subgraph details by setting the subgraphs parameter to true.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst stateWithSubgraphs = await graph.getState({ configurable: { thread_id: \"3\" } }, { subgraphs: true })\nJSON.stringify(stateWithSubgraphs.tasks, null, 2)\n```\n\n----------------------------------------\n\nTITLE: Examining Pending Tasks in Graph State\nDESCRIPTION: Displays the pending tasks in the current graph state, showing that there's a task for the weather subgraph waiting to be completed.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nJSON.stringify(state.tasks, null, 2);\n```\n\n----------------------------------------\n\nTITLE: Setting Up LangSmith Tracing for Observability\nDESCRIPTION: Optional setup for LangSmith tracing, which provides observability features for monitoring and debugging the agent's execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n// process.env.LANGCHAIN_TRACING_V2 = \"true\"\n// process.env.LANGCHAIN_API_KEY = \"YOUR_API_KEY\"\n// process.env.LANGCHAIN_PROJECT = \"YOUR_PROJECT_NAME\"\n```\n\n----------------------------------------\n\nTITLE: Node Logic for Query Generation in JavaScript\nDESCRIPTION: This snippet defines the logic for the node responsible for generating a search query based on the overall state. The query is derived from the user's question, simulating rephrasing for searching.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/pass_private_state.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst generateQuery = async (state: typeof OverallStateAnnotation.State) => {\n  // Replace this with real logic\n  return {\n    query: state.question + \" rephrased as a query!\",\n  };\n};\n```\n\n----------------------------------------\n\nTITLE: Node Logic for Document Retrieval in JavaScript\nDESCRIPTION: This snippet implements the logic for the node that retrieves documents based on the generated query. It simulates a document retrieval process by returning predefined documents.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/pass_private_state.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nconst retrieveDocuments = async (state: typeof QueryOutputAnnotation.State) => {\n  // Replace this with real logic\n  return {\n    docs: [state.query, \"some random document\"],\n  };\n};\n```\n\n----------------------------------------\n\nTITLE: Streaming Results from Parent Graph with Subgraph Output\nDESCRIPTION: Code to stream results from the parent graph with subgraph streaming enabled. This allows viewing intermediate outputs from the subgraph execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst streamWithSubgraphs = await graph.stream({ foo: \"foo\" }, { subgraphs: true });\n\nfor await (const chunk of streamWithSubgraphs) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Trimming Messages based on Token Count with LangChain\nDESCRIPTION: This snippet uses the trimMessages utility from LangChain to manage message sequences by trimming them based on token count. Configurable options include specifying the token retention strategy, model adjustment, and conversation history boundaries. The snippet demonstrates handling chat history to make it align with the model's expected input format, adhering to token limits.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/memory.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { trimMessages } from \"@langchain/core/messages\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\ntrimMessages(messages, {\n  // Keep the last <= n_count tokens of the messages.\n  strategy: \"last\",\n  // Remember to adjust based on your model\n  // or else pass a custom token_encoder\n  tokenCounter: new ChatOpenAI({ modelName: \"gpt-4\" }),\n  // Remember to adjust based on the desired conversation\n  // length\n  maxTokens: 45,\n  // Most chat models expect that chat history starts with either:\n  // (1) a HumanMessage or\n  // (2) a SystemMessage followed by a HumanMessage\n  startOn: \"human\",\n  // Most chat models expect that chat history ends with either:\n  // (1) a HumanMessage or\n  // (2) a ToolMessage\n  endOn: [\"human\", \"tool\"],\n  // Usually, we want to keep the SystemMessage\n  // if it's present in the original history.\n  // The SystemMessage has special instructions for the model.\n  includeSystem: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a ReAct Agent with Human-in-the-Loop Interaction\nDESCRIPTION: This Python snippet demonstrates the setup of a ReAct agent using `createReactAgent` function. It initializes a ChatOpenAI model, defines a weather tool, and incorporates a memory saver component to maintain context during interactions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-human-in-the-loop.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { tool } from '@langchain/core/tools';\nimport { z } from 'zod';\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst model = new ChatOpenAI({\n    model: \"gpt-4o\",\n  });\n\nconst getWeather = tool((input) => {\n    if (['sf', 'san francisco'].includes(input.location.toLowerCase())) {\n        return 'It\\'s always sunny in sf';\n    } else if (['nyc', 'new york city'].includes(input.location.toLowerCase())) {\n        return 'It might be cloudy in nyc';\n    }\n    else {\n        throw new Error(\"Unknown Location\");\n    }\n}, {\n    name: 'get_weather',\n    description: 'Call to get the current weather in a given location.',\n    schema: z.object({\n        location: z.string().describe(\"Location to get the weather for.\"),\n    })\n})\n\n// Here we only save in-memory\nconst memory = new MemorySaver();\n\nconst agent = createReactAgent({ llm: model, tools: [getWeather], interruptBefore: [\"tools\"], checkpointSaver: memory });\n\n```\n\n----------------------------------------\n\nTITLE: Handling Transient Errors in Workflow Streaming\nDESCRIPTION: This snippet illustrates how to stream data from a workflow while recovering from a transient error by passing null as the input. It continues to process incoming data chunks.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = {\n  configurable: {\n    thread_id: \"some_thread_id\",\n  },\n};\n\nfor await (const chunk of await myWorkflow.stream(null, config)) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Tool Implementation with Custom Strategy\nDESCRIPTION: Implements a haiku generator tool with basic error handling using Claude-3-Haiku model and custom strategy patterns.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling-errors.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StringOutputParser } from \"@langchain/core/output_parsers\";\n\nconst haikuRequestSchema = z.object({\n  topic: z.array(z.string()).length(3),\n});\n\nconst masterHaikuGenerator = tool(async ({ topic }) => {\n  const model = new ChatAnthropic({\n    model: \"claude-3-haiku-20240307\",\n    temperature: 0,\n  });\n  const chain = model.pipe(new StringOutputParser());\n  const topics = topic.join(\", \");\n  const haiku = await chain.invoke(`Write a haiku about ${topics}`);\n  return haiku;\n}, {\n  name: \"master_haiku_generator\",\n  description: \"Generates a haiku based on the provided topics.\",\n  schema: haikuRequestSchema,\n});\n\nconst customStrategyToolNode = new ToolNode([masterHaikuGenerator]);\n\nconst customStrategyModel = new ChatAnthropic({\n  model: \"claude-3-haiku-20240307\",\n  temperature: 0,\n});\nconst customStrategyModelWithTools = customStrategyModel.bindTools([masterHaikuGenerator]);\n\nconst customStrategyShouldContinue = async (state: typeof MessagesAnnotation.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1];\n  if (isAIMessage(lastMessage) && lastMessage.tool_calls?.length) {\n    return \"tools\";\n  }\n  return \"__end__\";\n}\n\nconst customStrategyCallModel = async (state: typeof MessagesAnnotation.State) => {\n  const { messages } = state;\n  const response = await customStrategyModelWithTools.invoke(messages);\n  return { messages: [response] };\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Workflow Stream with Thread Configuration\nDESCRIPTION: Demonstrates how to execute the workflow using streaming with a specific thread configuration. Processes a natural language task query and handles the stream output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nconst threadConfig = { configurable: { thread_id: \"123\" } };\nlet finalResult;\nconst stream = await app.stream(\n  {\n    task: \"what is the hometown of the winner of the 2023 australian open?\",\n  },\n  threadConfig,\n);\nfor await (const item of stream) {\n  console.log(item);\n  console.log(\"-----\");\n  finalResult = item;\n}\n```\n\n----------------------------------------\n\nTITLE: Running the ReAct Agent without Tool Call\nDESCRIPTION: This JavaScript code runs the ReAct agent with an input that does not require a tool call. It sends a simple question to the agent, streams the response, and logs the content, tool calls, or the raw message. The output is formatted for readability.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/create-react-agent.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n\"inputs = { messages: [{ role: \\\"user\\\", content: \\\"who built you?\\\" }] };\\n\\nstream = await agent.stream(inputs, {\\n  streamMode: \\\"values\\\",\\n});\\n\\nfor await (\\n  const { messages } of stream\\n) {\\n  let msg = messages[messages?.length - 1];\\n  if (msg?.content) {\\n    console.log(msg.content);\\n  } else if (msg?.tool_calls?.length > 0) {\\n    console.log(msg.tool_calls);\\n  } else {\\n    console.log(msg);\\n  }\\n  console.log(\\\"-----\\n\\\");\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Loading a Chat Model in LangGraphJS\nDESCRIPTION: This snippet configures a chat model using LangGraphJS to interface with messages and tools. It utilizes ChatOpenAI from '@langchain/openai', a prebuilt option for setting up models compatible with the LangGraphJS system. The model chosen is 'gpt-4o'.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({ model: \"gpt-4o\" });\n```\n\n----------------------------------------\n\nTITLE: Handling Follow-up Queries with Memory in Python\nDESCRIPTION: This snippet exemplifies how to manage follow-up questions by using the same agent instance. It retains the context provided by earlier interactions, allowing the agent to generate contextualized responses.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nconst followupStreamWithMemory = await agentWithMemory.stream([{\\n  role: \"user\",\\n  content: \"How does it compare to Boston, MA?\",\\n}], config);\\n\\nfor await (const step of followupStreamWithMemory) {\\n  for (const [taskName, update] of Object.entries(step)) {\\n    const message = update as BaseMessage;\\n    // Only print task updates\\n    if (taskName === \"agentWithMemory\") continue;\\n    console.log(`\\n${taskName}:`);\\n    prettyPrintMessage(message);\\n  }\\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing StateGraph for Workflow\nDESCRIPTION: Creates a state graph that combines generation and reflection into a complete workflow with conditional logic\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/reflection/reflection.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, MemorySaver, StateGraph, START, Annotation } from \"@langchain/langgraph\";\n\nconst State = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  })\n})\n\nconst generationNode = async (state: typeof State.State) => {\n  const { messages } = state;\n  return {\n    messages: [await essayGenerationChain.invoke({ messages })],\n  };\n};\n\nconst reflectionNode = async (state: typeof State.State) => {\n  const { messages } = state;\n  const clsMap: { [key: string]: new (content: string) => BaseMessage } = {\n    ai: HumanMessage,\n    human: AIMessage,\n  };\n  const translated = [\n    messages[0],\n    ...messages\n      .slice(1)\n      .map((msg) => new clsMap[msg._getType()](msg.content.toString())),\n  ];\n  const res = await reflect.invoke({ messages: translated });\n  return {\n    messages: [new HumanMessage({ content: res.content })],\n  };\n};\n\nconst workflow = new StateGraph(State)\n  .addNode(\"generate\", generationNode)\n  .addNode(\"reflect\", reflectionNode)\n  .addEdge(START, \"generate\");\n\nconst shouldContinue = (state: typeof State.State) => {\n  const { messages } = state;\n  if (messages.length > 6) {\n    return END;\n  }\n  return \"reflect\";\n};\n\nworkflow\n  .addConditionalEdges(\"generate\", shouldContinue)\n  .addEdge(\"reflect\", \"generate\");\n\nconst app = workflow.compile({ checkpointer: new MemorySaver() });\n```\n\n----------------------------------------\n\nTITLE: Displaying Graph with TSLab in JavaScript\nDESCRIPTION: Utilizes TSLab to visualize a LangGraph state graph, rendering it as a Mermaid diagram in JavaScript. The snippet includes fetching and displaying the image as a PNG.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/breakpoints.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraphGraphState = graph.getGraph();\nconst graphStateImage = await drawableGraphGraphState.drawMermaidPng();\nconst graphStateArrayBuffer = await graphStateImage.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(graphStateArrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Creating Memory Storage Tool - Python\nDESCRIPTION: This snippet describes how to define a tool that allows the agent to store new memories in a structured manner with unique identifiers, ensuring no key conflicts occur.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { LangGraphRunnableConfig } from \"@langchain/langgraph\";\n\nimport { z } from \"zod\";\nimport { v4 as uuidv4 } from \"uuid\";\n\nconst upsertMemoryTool = tool(async (\n  { content },\n  config: LangGraphRunnableConfig\n): Promise<string> => {\n  const store = config.store as InMemoryStore;\n  if (!store) {\n    throw new Error(\"No store provided to tool.\");\n  }\n  await store.put(\n    [\"user_123\", \"memories\"],\n    uuidv4(), // give each memory its own unique ID\n    { text: content }\n  );\n  return \"Stored memory.\";\n}, {\n  name: \"upsert_memory\",\n  schema: z.object({\n    content: z.string().describe(\"The content of the memory to store.\"),\n  }),\n  description: \"Upsert long-term memories.\",\n});\n```\n\n----------------------------------------\n\nTITLE: Getting Current State of LangGraphJS\nDESCRIPTION: This code retrieves the current state of the LangGraphJS graph for a specific `thread_id`. It uses `graph.getState()` to fetch the state and logs the current tasks in JSON format to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nconst currentState = await graph.getState({ configurable: { thread_id: \"refund_testing_id\" } });\n\nconsole.log(\"CURRENT TASKS\", JSON.stringify(currentState.tasks, null, 2));\n```\n\n----------------------------------------\n\nTITLE: Interact with Agent and Process Human Messages in LangGraph\nDESCRIPTION: Demonstrates the procedure to interact with a LangGraph agent by sending human messages and handling streamed responses, with a breakpoint before tool nodes, implemented in JavaScript.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/breakpoints.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n// Input\nconst inputs = new HumanMessage(\"search for the weather in sf now\");\n\n// Thread\nconst config = { configurable: { thread_id: \"3\" }, streamMode: \"values\" as const };\n\nfor await (const event of await app.stream({\n    messages: [inputs]\n}, config)) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Command to install dependencies for the LangGraph app using yarn.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/langgraph-platform/local-server.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ yarn\n```\n\n----------------------------------------\n\nTITLE: Reviewing Tool Calls in Langchain JavaScript\nDESCRIPTION: This snippet demonstrates how to set up a human-in-the-loop review for a tool call within a Langchain graph. The code uses a breakpoint to pause execution, allowing for tool call validation and potential modifications before proceeding. Dependencies include 'builder.compile', 'graph.stream', and 'graph.updateState'. Inputs are 'inputs' for the initial graph execution and 'threadConfig' for threading configuration. Outputs are logged events, indicating the process flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Compile our graph with a checkpointer and a breakpoint before the step to review the tool call from the LLM \nconst graph = builder.compile({ checkpointer, interruptBefore: [\"human_review\"] });\n\n// Run the graph up to the breakpoint\nfor await (const event of await graph.stream(inputs, threadConfig)) {\n    console.log(event);\n}\n    \n// Review the tool call and update it, if needed, as the human_review node\nawait graph.updateState(threadConfig, { tool_call: \"updated tool call\" }, \"human_review\");\n\n// Otherwise, approve the tool call and proceed with the graph execution with no edits \n\n// Continue the graph execution from either: \n// (1) the forked checkpoint created by human_review or \n// (2) the checkpoint saved when the tool call was originally made (no edits in human_review)\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Input and Handling Responses from ReAct Agent\nDESCRIPTION: This Python snippet demonstrates how to stream inputs to the ReAct agent and handle the output messages. It sets the input as user messages and processes the stream for output, including logging tool calls if they occur.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-human-in-the-loop.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlet inputs = { messages: [{ role: \"user\", content: \"what is the weather in SF california?\" }] };\nlet config = { configurable: { thread_id: \"1\" } };\n\nlet stream = await agent.stream(inputs, {\n  ...config,\n  streamMode: \"values\",\n});\n\nfor await (\n  const { messages } of stream\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  }\n  if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  }\n  console.log(\"-----\\n\");\n}\n\n```\n\n----------------------------------------\n\nTITLE: Streaming Graph Execution with Technical Query\nDESCRIPTION: This code snippet demonstrates how to stream the execution of a LangGraphJS graph with a technical support query. It passes a message describing a broken computer to the `graph.stream()` method, along with a `thread_id`. The output from each step of the graph's execution is then logged to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nconst technicalStream = await graph.stream({\n  messages: [{\n    role: \"user\",\n    content: \"My LangCorp computer isn't turning on because I dropped it in water.\",\n  }]\n}, {\n  configurable: {\n    thread_id: \"technical_testing_id\"\n  }\n});\n\nfor await (const value of technicalStream) {\n  console.log(value);\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Human Feedback Implementation\nDESCRIPTION: Implementation of a basic state graph with human feedback integration using interrupt() function and state management.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation, START, END, interrupt, MemorySaver } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  input: Annotation<string>,\n  userFeedback: Annotation<string>\n});\n\nconst step1 = (_state: typeof StateAnnotation.State) => {\n  console.log(\"---Step 1---\");\n  return {};\n}\n\nconst humanFeedback = (_state: typeof StateAnnotation.State) => {\n  console.log(\"--- humanFeedback ---\");\n  const feedback: string = interrupt(\"Please provide feedback\");\n  return {\n    userFeedback: feedback\n  };\n}\n\nconst step3 = (_state: typeof StateAnnotation.State) => {\n  console.log(\"---Step 3---\");\n  return {};\n}\n\nconst builder = new StateGraph(StateAnnotation)\n    .addNode(\"step1\", step1)\n    .addNode(\"humanFeedback\", humanFeedback)\n    .addNode(\"step3\", step3)\n    .addEdge(START, \"step1\")\n    .addEdge(\"step1\", \"humanFeedback\")\n    .addEdge(\"humanFeedback\", \"step3\")\n    .addEdge(\"step3\", END);\n\n\n// Set up memory\nconst memory = new MemorySaver()\n\n// Add \nconst graph = builder.compile({\n  checkpointer: memory,\n});\n```\n\n----------------------------------------\n\nTITLE: Executing Parallel Workflow with Functional API in TypeScript\nDESCRIPTION: This code snippet showcases the use of LangChain's Functional API in TypeScript to execute a parallel workflow. It sets up asynchronous tasks to generate a joke, a story, and a poem using LLMs and then aggregates these responses. The input is a topic string, and the LLM tasks run concurrently to produce diverse outputs, which are then combined into a single string. It requires the '@langchain/langgraph' dependency and the ability to handle async tasks.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_6\n\nLANGUAGE: ts\nCODE:\n```\nimport { task, entrypoint } from \"@langchain/langgraph\";\n\n// Tasks\n\n// First LLM call to generate initial joke\nconst callLlm1 = task(\"generateJoke\", async (topic: string) => {\n  const msg = await llm.invoke(`Write a joke about ${topic}`);\n  return msg.content;\n});\n\n// Second LLM call to generate story\nconst callLlm2 = task(\"generateStory\", async (topic: string) => {\n  const msg = await llm.invoke(`Write a story about ${topic}`);\n  return msg.content;\n});\n\n// Third LLM call to generate poem\nconst callLlm3 = task(\"generatePoem\", async (topic: string) => {\n  const msg = await llm.invoke(`Write a poem about ${topic}`);\n  return msg.content;\n});\n\n// Combine outputs\nconst aggregator = task(\"aggregator\", async (params: {\n  topic: string;\n  joke: string;\n  story: string;\n  poem: string;\n}) => {\n  const { topic, joke, story, poem } = params;\n  return `Here's a story, joke, and poem about ${topic}!\\n\\n` +\n    `STORY:\\n${story}\\n\\n` +\n    `JOKE:\\n${joke}\\n\\n` +\n    `POEM:\\n${poem}`;\n});\n\n// Build workflow\nconst workflow = entrypoint(\n  \"parallelWorkflow\",\n  async (topic: string) => {\n    const [joke, story, poem] = await Promise.all([\n      callLlm1(topic),\n      callLlm2(topic),\n      callLlm3(topic),\n    ]);\n\n    return aggregator({ topic, joke, story, poem });\n  }\n);\n\n// Invoke\nconst stream = await workflow.stream(\"cats\", {\n  streamMode: \"updates\",\n});\n\nfor await (const step of stream) {\n  console.log(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing ToolNode with Defined Tools\nDESCRIPTION: Creating a ToolNode instance and providing it with the custom tools defined earlier. The ToolNode will be responsible for executing tool calls.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToolNode } from '@langchain/langgraph/prebuilt';\n\nconst tools = [getWeather, getCoolestCities]\nconst toolNode = new ToolNode(tools)\n```\n\n----------------------------------------\n\nTITLE: Recalling Stored Memories in LangGraph.js Agent\nDESCRIPTION: This snippet shows how to test if the agent can recall previously stored information. It creates a new conversation (without checkpointing) and asks about the garbage schedule to verify if the memory was properly stored.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nresult = await agent.invoke({\n  messages: [\n    {\n      role: \"user\",\n      content: \"When am I supposed to take out the garbage?\",\n    },\n  ],\n});\n\nprintMessages(result.messages);\n```\n\n----------------------------------------\n\nTITLE: Binding Tools to the Model\nDESCRIPTION: This code binds the previously defined tools to the chat model using the `bindTools` method.  This ensures that the model is aware of the available tools and can use them during its operation. It returns a new model instance.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-updates.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst boundModel = model.bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: Evaluating Generation Support in Self-RAG Graph\nDESCRIPTION: This function determines whether the generated answer is supported by the documents based on the previously generated grade. It decides the next step in the graph flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nfunction gradeGenerationVDocuments(state: typeof GraphState.State) {\n  console.log(\"---GRADE GENERATION vs DOCUMENTS---\");\n\n  const grade = state.generationVDocumentsGrade;\n  if (grade === \"yes\") {\n    console.log(\"---DECISION: SUPPORTED, MOVE TO FINAL GRADE---\");\n    return \"supported\";\n  }\n\n  console.log(\"---DECISION: NOT SUPPORTED, GENERATE AGAIN---\");\n  return \"not supported\";\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating Generation Usefulness in Self-RAG Graph\nDESCRIPTION: This function determines whether the generated answer is useful in resolving the question based on the previously generated grade. It decides the final outcome of the graph flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nfunction gradeGenerationVQuestion(state: typeof GraphState.State) {\n  console.log(\"---GRADE GENERATION vs QUESTION---\");\n\n  const grade = state.generationVQuestionGrade;\n  if (grade === \"yes\") {\n    console.log(\"---DECISION: USEFUL---\");\n    return \"useful\";\n  }\n\n  console.log(\"---DECISION: NOT USEFUL---\");\n  return \"not useful\";\n}\n```\n\n----------------------------------------\n\nTITLE: Invoking Conditional Graph with Alternative Path\nDESCRIPTION: Second example of invoking the conditional graph with a different path selection value.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\ng2result = await graph2.invoke({ aggregate: [], which: \"cd\" });\nconsole.log(\"Result 2: \", g2result);\n\n```\n\n----------------------------------------\n\nTITLE: Creating Dynamic System Prompt Function - Python\nDESCRIPTION: A state modifier function that constructs a personalized system prompt based on the user information in the current state, which will be used by the LLM.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/update-state-from-tools.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconst stateModifier = (state: typeof StateAnnotation.State) => {\n  const userInfo = state.userInfo;\n  if (userInfo == null) {\n    return state.messages;\n  }\n  const systemMessage = `User name is ${userInfo.name}. User lives in ${userInfo.location}`;\n  return [{\n    role: \"system\",\n    content: systemMessage,\n  }, ...state.messages];\n};\n```\n\n----------------------------------------\n\nTITLE: Wrapping Tools in a ToolNode - TypeScript\nDESCRIPTION: This snippet shows how to wrap the defined tools in a prebuilt ToolNode to enable their invocation by the language model.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst toolNode = new ToolNode(tools);\n```\n\n----------------------------------------\n\nTITLE: Getting Next Tasks of LangGraphJS\nDESCRIPTION: This code retrieves and logs the next tasks in the LangGraphJS graph's execution. It accesses the `next` property of the `currentState` object, which contains information about the subsequent tasks to be executed.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nconsole.log(\"NEXT TASKS\", currentState.next);\n```\n\n----------------------------------------\n\nTITLE: Summarizing Chat History using ChatOpenAI\nDESCRIPTION: This TypeScript function, summarizeConversation, generates a summary of chat history using the ChatOpenAI model. It checks for an existing summary and constructs a prompt to extend the summary based on new messages. The function returns a new summary and deletes older messages to maintain the most recent ones. Dependencies include the ChatOpenAI model and HumanMessage components.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/memory.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { HumanMessage, RemoveMessage } from \"@langchain/core/messages\";\n\ntype State = typeof MyGraphAnnotation.State;\n\nasync function summarizeConversation(state: State) {\n  // First, we get any existing summary\n  const summary = state.summary || \"\";\n\n  // Create our summarization prompt\n  let summaryMessage: string;\n  if (summary) {\n    // A summary already exists\n    summaryMessage =\n      `This is a summary of the conversation to date: ${summary}\\n\\n` +\n      \"Extend the summary by taking into account the new messages above:\";\n  } else {\n    summaryMessage = \"Create a summary of the conversation above:\";\n  }\n\n  // Add prompt to our history\n  const messages = [\n    ...state.messages,\n    new HumanMessage({ content: summaryMessage }),\n  ];\n\n  // Assuming you have a ChatOpenAI model instance\n  const model = new ChatOpenAI();\n  const response = await model.invoke(messages);\n\n  // Delete all but the 2 most recent messages\n  const deleteMessages = state.messages\n    .slice(0, -2)\n    .map((m) => new RemoveMessage({ id: m.id }));\n\n  return {\n    summary: response.content,\n    messages: deleteMessages,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Subgraph as Function Node in TypeScript\nDESCRIPTION: Demonstrates adding a subgraph as a function that invokes the subgraph. This approach is useful when parent graph and subgraph have different state schemas requiring transformation before or after calling the subgraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\nconst subgraph = subgraphBuilder.compile();\n\nconst callSubgraph = async (state: typeof StateAnnotation.State) => {\n  return subgraph.invoke({ subgraph_key: state.parent_key });\n};\n\nbuilder.addNode(\"subgraph\", callSubgraph);\n```\n\n----------------------------------------\n\nTITLE: Defining Graph State in LangGraphJS\nDESCRIPTION: This snippet defines the graph's state interface in LangGraphJS using annotations to store message arrays. Dependencies include Annotation from '@langchain/langgraph' and BaseMessage from '@langchain/core/messages'. It uses a reducer function to concatenate messages in the state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst GraphState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Stream Output Format in LangGraph TypeScript\nDESCRIPTION: Demonstrates the structure of the stream output when using both 'custom' and 'updates' stream modes in LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_27\n\nLANGUAGE: typescript\nCODE:\n```\n[\"updates\", { addOne: 2 }][(\"updates\", { addTwo: 3 })][\"custom\", \"hello\"][\n  (\"custom\", \"world\")\n][(\"updates\", { main: 5 })];\n```\n\n----------------------------------------\n\nTITLE: Streaming Tokens with .streamEvents Method - Python\nDESCRIPTION: This snippet demonstrates using the `streamEvents` method on a graph to stream tokens and tool calls from the OpenAI model. It logs custom events streamed from the model with `console.log`.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-tokens-without-langchain.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nconst eventStream = await graph.streamEvents(\n  { messages: [{ role: \"user\", content: \"what's in the bedroom?\" }] },\n  { version: \"v2\" },\n);\n\nfor await (const { event, name, data } of eventStream) {\n  if (event === \"on_custom_event\") {\n    console.log(name, data);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running StateGraph with Long Input in TypeScript\nDESCRIPTION: This code shows how to run the StateGraph with an input that triggers the dynamic interrupt. It demonstrates the graph execution stopping at the interrupt point.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamic_breakpoints.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst longInput = { input: \"hello world\" };\nconst config2 = {\n  configurable: {\n    thread_id: \"2\",\n  },\n  streamMode: \"values\" as const,\n};\n\nconst streamWithInterrupt = await graph.stream(longInput, config2);\n\nfor await (const event of streamWithInterrupt) {\n  console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Interacting with ReAct Agent using Memory and Thread IDs\nDESCRIPTION: This snippet shows how to interact with the ReAct agent by utilizing memory for conversation continuity via thread IDs. It highlights maintaining dialogue context and demonstrates how the agent's responses vary with or without previous thread history.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-memory.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlet inputs = { messages: [{ role: \"user\", content: \"what is the weather in NYC?\" }] };\nlet config = { configurable: { thread_id: \"1\" } };\nlet stream = await agent.stream(inputs, {\n  ...config,\n  streamMode: \"values\",\n});\n\nfor await (\n  const { messages } of stream\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\nLANGUAGE: python\nCODE:\n```\ninputs = { messages: [{ role: \"user\", content: \"What's it known for?\" }] };\nstream = await agent.stream(inputs, {\n  ...config,\n  streamMode: \"values\",\n});\n\nfor await (\n    const { messages } of stream\n  ) {\n    let msg = messages[messages?.length - 1];\n    if (msg?.content) {\n      console.log(msg.content);\n    } else if (msg?.tool_calls?.length > 0) {\n      console.log(msg.tool_calls);\n    } else {\n      console.log(msg);\n    }\n    console.log(\"-----\\n\");\n  }\n```\n\nLANGUAGE: python\nCODE:\n```\ninputs = { messages: [{ role: \"user\", content: \"how close is it to boston?\" }] };\nconfig = { configurable: { thread_id: \"2\" } };\nstream = await agent.stream(inputs, {\n  ...config,\n  streamMode: \"values\",\n});\n\nfor await (\n    const { messages } of stream\n  ) {\n    let msg = messages[messages?.length - 1];\n    if (msg?.content) {\n      console.log(msg.content);\n    } else if (msg?.tool_calls?.length > 0) {\n      console.log(msg.tool_calls);\n    } else {\n      console.log(msg);\n    }\n    console.log(\"-----\\n\");\n  }\n```\n\n----------------------------------------\n\nTITLE: Visualizing Game Graph with Mermaid\nDESCRIPTION: Generates a visual representation of the game graph using Mermaid and displays it as a PNG image.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGameGraph = await gameGraph.getGraphAsync();\nconst gameImage = await drawableGameGraph.drawMermaidPng();\nconst gameArrayBuffer = await gameImage.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(gameArrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Example: Reading Document with LangGraphJS Tool\nDESCRIPTION: Example invocation of the readDocumentTool to retrieve content from a previously created text file. This demonstrates how agents can access and read documents.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nawait readDocumentTool.invoke({ file_name: \"hello.txt\" });\n```\n\n----------------------------------------\n\nTITLE: Defining Tasks with Interrupt for Human Input in LangGraph\nDESCRIPTION: Implementation of three tasks in LangGraph's Functional API, including a task that uses interrupt() to pause for human input before continuing execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { task, interrupt } from \"@langchain/langgraph\";\n\nconst step1 = task(\"step1\", async (inputQuery: string) => {\n  return `${inputQuery} bar`;\n});\n\nconst humanFeedback = task(\n  \"humanFeedback\",\n  async (inputQuery: string) => {\n    const feedback = interrupt(`Please provide feedback: ${inputQuery}`);\n    return `${inputQuery} ${feedback}`;\n  });\n\nconst step3 = task(\"step3\", async (inputQuery: string) => {\n  return `${inputQuery} qux`;\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Subgraph State Before Model Node in JavaScript\nDESCRIPTION: This snippet shows how to get the subgraph state before a specific node (modelNode) is executed. It uses the parent graph state to retrieve the subgraph's state history and finds the state where the next node is 'modelNode'.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: javascript\nCODE:\n```\nlet subgraphStateBeforeModelNode;\n\nconst subgraphHistories = await graph.getStateHistory(parentGraphStateBeforeSubgraph.tasks[0].state);\n\nfor await (const subgraphHistoryEntry of subgraphHistories) {\n  if (subgraphHistoryEntry.next[0] === \"modelNode\") {\n    subgraphStateBeforeModelNode = subgraphHistoryEntry;\n  }\n}\n\nconsole.log(subgraphStateBeforeModelNode);\n```\n\n----------------------------------------\n\nTITLE: Implementing Input Pattern for Human-in-the-loop in LangGraphJS\nDESCRIPTION: Shows how to implement the input pattern where a specific node in the graph is designated for collecting human input. This pattern updates state as if executed by the designated node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Compile our graph with a checkpointer and a breakpoint before the step to collect human input\nconst graph = builder.compile({ checkpointer, interruptBefore: [\"human_input\"] });\n\n// Run the graph up to the breakpoint\nfor await (const event of await graph.stream(inputs, threadConfig)) {\n    console.log(event);\n}\n    \n// Update the state with the user input as if it was the human_input node\nawait graph.updateState(threadConfig, { user_input: userInput }, \"human_input\");\n\n// Continue the graph execution from the checkpoint created by the human_input node\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Invoking the Agent to Get Weather Information - LangGraphJS - Python\nDESCRIPTION: This snippet demonstrates how to call the React agent to get structured weather information based on a user's query. It shows how to invoke the agent with messages, and how to access the structured response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-return-structured-output.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nconst response = await agent.invoke({\n  messages: [\n    {\n      role: \"user\",\n      content: \"What's the weather in NYC?\",\n    },\n  ],\n})\n```\n\n----------------------------------------\n\nTITLE: Incorrect Non-Deterministic Control Flow in TypeScript\nDESCRIPTION: Example of incorrect implementation with non-deterministic control flow where the workflow uses the current time directly, leading to different execution paths when resuming.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_20\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (inputs: { t0: number }) => {\n    // highlight-next-line\n    const t1 = Date.now();\n\n    const deltaT = t1 - inputs.t0;\n\n    if (deltaT > 1000) {\n      const result = await slowTask(1);\n      const value = interrupt(\"question\");\n      return { result, value };\n    } else {\n      const result = await slowTask(2);\n      const value = interrupt(\"question\");\n      return { result, value };\n    }\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Initiating Agent Stream and Processing Steps in Python\nDESCRIPTION: This code initiates an agent stream with a user message, processes the stream step by step, and pretty-prints each step. It demonstrates how to handle a request that requires both human assistance and a weather tool call.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nconst userMessage = {\n  role: \"user\",\n  content: [\n    \"Can you reach out for human assistance: what should I feed my cat?\",\n    \"Separately, can you check the weather in San Francisco?\"\n  ].join(\" \"),\n};\nconsole.log(userMessage);\n\nconst agentStream = await agent.stream([userMessage], {\n  configurable: {\n    thread_id: \"1\",\n  }\n});\n\nlet lastStep;\n\nfor await (const step of agentStream) {\n  prettyPrintStep(step);\n  lastStep = step;\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Document Creation and Management Tools\nDESCRIPTION: Implementation of document writing tools that allow agents to create outlines, read, write, and edit documents on the file system. These tools enable the document writing team to manage content creation and edit documents based on research findings.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nrequire(\"esm-hook\"); // Only for running this in TSLab in Jupyter. See: https://github.com/yunabe/tslab/issues/72\n// ----------ATTENTION----------\n// If attempting to run this notebook locally, you must follow these instructions\n// to install the necessary system dependencies for the `canvas` package.\n// https://www.npmjs.com/package/canvas#compiling\n// -----------------------------\nimport { createCanvas } from \"canvas\";\nimport * as d3 from \"d3\";\nimport * as tslab from \"tslab\";\nimport * as fs from \"fs/promises\";\nimport * as path from \"path\";\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst WORKING_DIRECTORY = \"./temp\";\nawait fs.mkdir(WORKING_DIRECTORY, { recursive: true });\n\nconst createOutlineTool = tool(\n  async ({ points, file_name }) => {\n    const filePath = path.join(WORKING_DIRECTORY, file_name);\n    const data = points\n      .map((point, index) => `${index + 1}. ${point}\\n`)\n      .join(\"\");\n    await fs.writeFile(filePath, data);\n    return `Outline saved to ${file_name}`;\n  },\n  {\n    name: \"create_outline\",\n    description: \"Create and save an outline.\",\n    schema: z.object({\n      points: z\n        .array(z.string())\n        .nonempty(\"List of main points or sections must not be empty.\"),\n      file_name: z.string(),\n    }),\n  }\n);\n\nconst readDocumentTool = tool(\n  async ({ file_name, start, end }) => {\n    const filePath = path.join(WORKING_DIRECTORY, file_name);\n    const data = await fs.readFile(filePath, \"utf-8\");\n    const lines = data.split(\"\\n\");\n    return lines.slice(start ?? 0, end).join(\"\\n\");\n  },\n  {\n    name: \"read_document\",\n    description: \"Read the specified document.\",\n    schema: z.object({\n      file_name: z.string(),\n      start: z.number().optional(),\n      end: z.number().optional(),\n    }),\n  }\n);\n\nconst writeDocumentTool = tool(\n  async ({ content, file_name }) => {\n    const filePath = path.join(WORKING_DIRECTORY, file_name);\n    await fs.writeFile(filePath, content);\n    return `Document saved to ${file_name}`;\n  },\n  {\n    name: \"write_document\",\n    description: \"Create and save a text document.\",\n    schema: z.object({\n      content: z.string(),\n      file_name: z.string(),\n    }),\n  }\n);\n\nconst editDocumentTool = tool(\n  async ({ file_name, inserts }) => {\n    const filePath = path.join(WORKING_DIRECTORY, file_name);\n    const data = await fs.readFile(filePath, \"utf-8\");\n    let lines = data.split(\"\\n\");\n\n    const sortedInserts = Object.entries(inserts).sort(\n      ([a], [b]) => parseInt(a) - parseInt(b),\n    );\n\n    for (const [line_number_str, text] of sortedInserts) {\n      const line_number = parseInt(line_number_str);\n      if (1 <= line_number && line_number <= lines.length + 1) {\n        lines.splice(line_number - 1, 0, text);\n      } else {\n        return `Error: Line number ${line_number} is out of range.`;\n      }\n    }\n\n    await fs.writeFile(filePath, lines.join(\"\\n\"));\n    return `Document edited and saved to ${file_name}`;\n  },\n  {\n    name: \"edit_document\",\n    description: \"Edit a document by inserting text at specific line numbers.\",\n    schema: z.object({\n      file_name: z.string(),\n      inserts: z.record(z.number(), z.string()),\n    }),\n  }\n);\n\nconst chartTool = tool(\n  async ({ data }) => {\n    const width = 500;\n    const height = 500;\n    const margin = { top: 20, right: 30, bottom: 30, left: 40 };\n\n    const canvas = createCanvas(width, height);\n    const ctx = canvas.getContext(\"2d\");\n\n    const x = d3\n      .scaleBand()\n      .domain(data.map((d) => d.label))\n      .range([margin.left, width - margin.right])\n      .padding(0.1);\n\n    const y = d3\n      .scaleLinear()\n      .domain([0, d3.max(data, (d) => d.value) ?? 0])\n      .nice()\n      .range([height - margin.bottom, margin.top]);\n\n    const colorPalette = [\n      \"#e6194B\",\n      \"#3cb44b\",\n      \"#ffe119\",\n      \"#4363d8\",\n      \"#f58231\",\n      \"#911eb4\",\n      \"#42d4f4\",\n      \"#f032e6\",\n      \"#bfef45\",\n      \"#fabebe\",\n    ];\n\n    for (let i = 0; i < data.length; i++) {\n      const d = data[i];\n      ctx.fillStyle = colorPalette[i % colorPalette.length];\n      ctx.fillRect(\n        x(d.label) ?? 0,\n        y(d.value),\n        x.bandwidth(),\n        height - margin.bottom - y(d.value),\n      ); \n    }\n\n    ctx.beginPath();\n    ctx.strokeStyle = \"black\";\n    ctx.moveTo(margin.left, height - margin.bottom);\n    ctx.lineTo(width - margin.right, height - margin.bottom);\n    ctx.stroke();\n\n    ctx.textAlign = \"center\";\n    ctx.textBaseline = \"top\";\n    x.domain().forEach((d) => {\n      const xCoord = (x(d) ?? 0) + x.bandwidth() / 2;\n      ctx.fillText(d, xCoord, height - margin.bottom + 6);\n    });\n\n    ctx.beginPath();\n    ctx.moveTo(margin.left, height - margin.top);\n    ctx.lineTo(margin.left, height - margin.bottom);\n    ctx.stroke();\n\n    ctx.textAlign = \"right\";\n    ctx.textBaseline = \"middle\";\n    const ticks = y.ticks();\n    ticks.forEach((d) => {\n      const yCoord = y(d);\n      ctx.moveTo(margin.left, yCoord);\n      ctx.lineTo(margin.left - 6, yCoord);\n      ctx.stroke();\n      ctx.fillText(d.toString(), margin.left - 8, yCoord);\n    });\n\n    tslab.display.png(canvas.toBuffer());\n    return \"Chart has been generated and displayed to the user!\";\n  },\n  {\n    name: \"generate_bar_chart\",\n    description:\n      \"Generates a bar chart from an array of data points using D3.js and displays it for the user.\",\n    schema: z.object({\n      data: z\n        .object({\n          label: z.string(),\n          value: z.number(),\n        })\n        .array(),\n    }),\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Invoking the Conditional Graph with Different Routes\nDESCRIPTION: Two examples of invoking the conditional branching graph with different 'which' values to demonstrate different execution paths.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Invoke the graph\nlet g2result = await graph2.invoke({ aggregate: [], which: \"bc\" });\nconsole.log(\"Result 1: \", g2result);\n```\n\n----------------------------------------\n\nTITLE: Setting API Keys for OpenAI and Tavily\nDESCRIPTION: Code snippet showing how to set environment variables for OpenAI and Tavily API keys, which are required for the LLM and search tool respectively.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"YOUR_API_KEY\"\n// process.env.TAVILY_API_KEY = \"YOUR_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Calling a Task from Within an Entrypoint\nDESCRIPTION: This snippet demonstrates how to call a task from within an entry point in a LangGraphJS workflow, facilitating asynchronous execution and checkpointing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (someInput: number) => {\n    return await slowComputation(someInput);\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Extending MessagesAnnotation with Summary\nDESCRIPTION: This snippet extends the existing MessagesAnnotation by adding a summary key to assist in managing chat conversations within LangGraph. It relies on importing the MessagesAnnotation and Annotation from the langgraph library. The snippet initializes a custom annotation named MyGraphAnnotation by incorporating a summary field to track conversation summaries.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/memory.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MessagesAnnotation, Annotation } from \"@langchain/langgraph\";\n\nconst MyGraphAnnotation = Annotation.Root({\n  ...MessagesAnnotation.spec,\n  summary: Annotation<string>,\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Checkpoints for Replaying\nDESCRIPTION: This code snippet retrieves all checkpoints for a specific thread. It iterates through the state history of the graph using `graph.getStateHistory(threadConfig)` and pushes each state (checkpoint) into the `allCheckpoints` array. This array can then be used to identify specific checkpoints for replaying.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/time-travel.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst allCheckpoints = [];\n\nfor await (const state of graph.getStateHistory(threadConfig)) {\n    allCheckpoints.push(state);\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieval Grader Implementation\nDESCRIPTION: Implementation of a grading system to assess relevance of retrieved documents to user questions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nconst GRADER_TEMPLATE =\n  `You are a grader assessing relevance of a retrieved document to a user question.\nHere is the retrieved document:\n\n<document>\n{content}\n</document>\n\nHere is the user question:\n<question>\n{question}\n</question>\n\nIf the document contains keywords related to the user question, grade it as relevant.\nIt does not need to be a stringent test. The goal is to filter out erroneous retrievals.\nGive a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\nProvide the binary score as a JSON with a single key 'score' and no preamble or explanation.`;\n\nconst graderPrompt = ChatPromptTemplate.fromTemplate(GRADER_TEMPLATE);\n\nconst retrievalGrader = graderPrompt.pipe(jsonModeLlm).pipe(\n  new JsonOutputParser(),\n);\n\nconst testQuestion = \"agent memory\";\n\nconst docs2 = await retriever.invoke(testQuestion);\n\nawait retrievalGrader.invoke({\n  question: testQuestion,\n  content: docs2[0].pageContent,\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving Workflow State\nDESCRIPTION: Shows how to retrieve the current state of the workflow using the thread configuration and access the result values.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nconst snapshot = await app.getState(threadConfig);\nconsole.log(snapshot.values.result);\n```\n\n----------------------------------------\n\nTITLE: Defining a Checkpointer in a Workflow\nDESCRIPTION: This code snippet defines a workflow entry point with a checkpointer, allowing for state management across workflow invocations using the getPreviousState function to access previous results.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (number: number) => {\n    const previous = getPreviousState<number>();\n    return number + (previous ?? 0);\n  }\n);\n\nconst config = {\n  configurable: {\n    thread_id: \"some_thread_id\",\n  },\n};\n\nawait myWorkflow.invoke(1, config); // 1 (previous was undefined)\nawait myWorkflow.invoke(2, config); // 3 (previous was 1 from the previous invocation)\n```\n\n----------------------------------------\n\nTITLE: Streaming Results for TV Show Query using LangGraph in JavaScript\nDESCRIPTION: This snippet demonstrates how to use a LangGraph to process a query about popular TV shows in 2023. It streams the results and logs each output, with a recursion limit of 100.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/agent_supervisor.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nlet streamResults = graph.stream(\n  {\n    messages: [\n      new HumanMessage({\n        content: \"What were the 3 most popular tv shows in 2023?\",\n      }),\n    ],\n  },\n  { recursionLimit: 100 },\n);\n\nfor await (const output of await streamResults) {\n  if (!output?.__end__) {\n    console.log(output);\n    console.log(\"----\");\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Placeholder Tool in LangGraphJS - TypeScript\nDESCRIPTION: This code snippet defines a simple placeholder search tool using the LangChain tool function and zod for schema validation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst searchTool = tool((_) => {\n  // This is a placeholder for the actual implementation\n  return \"Cold, with a low of 3℃\";\n}, {\n  name: \"search\",\n  description:\n    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n});\n\nawait searchTool.invoke({ query: \"What's the weather like?\" });\n\nconst tools = [searchTool];\n```\n\n----------------------------------------\n\nTITLE: Skipping a Node to Bypass Dynamic Breakpoint in LangGraphJS\nDESCRIPTION: Demonstrates how to completely skip a node that contains a dynamic breakpoint by updating the state with the node name as an argument and null for values.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// This update will skip the node `myNode` altogether\nawait graph.updateState(threadConfig, null, \"myNode\");\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Recursion Limit with GraphRecursionError - TypeScript\nDESCRIPTION: This TypeScript snippet showcases how to handle recursion limits in a state graph by setting a 'recursionLimit' option. A GraphRecursionError is caught to manage potential excessive recursion.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/recursion-limit.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GraphRecursionError } from \"@langchain/langgraph\";\n\ntry {\n  await graph.invoke(inputs, { recursionLimit: 3 });\n} catch (error) {\n  if (error instanceof GraphRecursionError) {\n    console.log(\"Recursion Error\");\n  } else {\n    throw error;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Edges for RAG Workflow Graph in Python\nDESCRIPTION: This snippet shows how to define the edges and conditional flows in the RAG workflow graph, connecting the various nodes and specifying the decision logic for traversal.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport { START } from \"@langchain/langgraph\";\n\n# Call agent node to decide to retrieve or not\nworkflow.addEdge(START, \"agent\");\n\n# Decide whether to retrieve\nworkflow.addConditionalEdges(\n  \"agent\",\n  # Assess agent decision\n  shouldRetrieve,\n);\n\nworkflow.addEdge(\"retrieve\", \"gradeDocuments\");\n\n# Edges taken after the `action` node is called.\nworkflow.addConditionalEdges(\n  \"gradeDocuments\",\n  # Assess agent decision\n  checkRelevance,\n  {\n    # Call tool node\n    yes: \"generate\",\n    no: \"rewrite\", # placeholder\n  },\n);\n\nworkflow.addEdge(\"generate\", END);\nworkflow.addEdge(\"rewrite\", \"agent\");\n\n# Compile\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Orchestrator-Worker Pattern with Graph API\nDESCRIPTION: Implements the complete orchestrator-worker workflow using LangGraph's Graph API. Includes state management, worker creation, and task synthesis functionality.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation, StateGraph, Send } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  topic: Annotation<string>,\n  sections: Annotation<Array<z.infer<typeof sectionSchema>>>,\n  completedSections: Annotation<string[]>({\n    default: () => [],\n    reducer: (a, b) => a.concat(b),\n  }),\n  finalReport: Annotation<string>,\n});\n\nconst WorkerStateAnnotation = Annotation.Root({\n  section: Annotation<z.infer<typeof sectionSchema>>,\n  completedSections: Annotation<string[]>({\n    default: () => [],\n    reducer: (a, b) => a.concat(b),\n  }),\n});\n\nasync function orchestrator(state: typeof StateAnnotation.State) {\n  const reportSections = await planner.invoke([\n    { role: \"system\", content: \"Generate a plan for the report.\" },\n    { role: \"user\", content: `Here is the report topic: ${state.topic}` },\n  ]);\n\n  return { sections: reportSections.sections };\n}\n\nasync function llmCall(state: typeof WorkerStateAnnotation.State) {\n  const section = await llm.invoke([\n    {\n      role: \"system\",\n      content: \"Write a report section following the provided name and description. Include no preamble for each section. Use markdown formatting.\",\n    },\n    {\n      role: \"user\",\n      content: `Here is the section name: ${state.section.name} and description: ${state.section.description}`,\n    },\n  ]);\n\n  return { completedSections: [section.content] };\n}\n\nasync function synthesizer(state: typeof StateAnnotation.State) {\n  const completedSections = state.completedSections;\n  const completedReportSections = completedSections.join(\"\\n\\n---\\n\\n\");\n  return { finalReport: completedReportSections };\n}\n\nfunction assignWorkers(state: typeof StateAnnotation.State) {\n  return state.sections.map((section) =>\n    new Send(\"llmCall\", { section })\n  );\n}\n\nconst orchestratorWorker = new StateGraph(StateAnnotation)\n  .addNode(\"orchestrator\", orchestrator)\n  .addNode(\"llmCall\", llmCall)\n  .addNode(\"synthesizer\", synthesizer)\n  .addEdge(\"__start__\", \"orchestrator\")\n  .addConditionalEdges(\n    \"orchestrator\",\n    assignWorkers,\n    [\"llmCall\"]\n  )\n  .addEdge(\"llmCall\", \"synthesizer\")\n  .addEdge(\"synthesizer\", \"__end__\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Call Review Function\nDESCRIPTION: Defines a function to interrupt and review tool calls with options for human intervention, including continuing, updating, or providing feedback\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nfunction reviewToolCall(toolCall: ToolCall): ToolCall | ToolMessage {\n  const humanReview = interrupt({\n    question: \"Is this correct?\",\n    tool_call: toolCall,\n  });\n\n  const { action, data } = humanReview;\n\n  if (action === \"continue\") {\n    return toolCall;\n  } else if (action === \"update\") {\n    return {\n      ...toolCall,\n      args: data,\n    };\n  } else if (action === \"feedback\") {\n    return new ToolMessage({\n      content: data,\n      name: toolCall.name,\n      tool_call_id: toolCall.id,\n    });\n  }\n  throw new Error(`Unsupported review action: ${action}`);\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Graph Execution with Billing Query\nDESCRIPTION: This code snippet demonstrates how to stream the execution of a LangGraphJS graph with a billing-related refund query. It passes a message with the user's request for a refund to the `graph.stream()` method along with a `thread_id` for configurable settings. The output from each step of the graph's execution is then logged to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nconst stream = await graph.stream({\n  messages: [\n    {\n      role: \"user\",\n      content: \"I've changed my mind and I want a refund for order #182818!\",\n    }\n  ]\n}, {\n  configurable: {\n    thread_id: \"refund_testing_id\",\n  }\n});\n\nfor await (const value of stream) {\n  console.log(\"---STEP---\");\n  console.log(value);\n  console.log(\"---END STEP---\");\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Automatic Message Deletion in LangGraph.js\nDESCRIPTION: Runs the modified graph with automatic message deletion and checks the resulting state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/delete-messages.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\nimport { v4 as uuidv4 } from \"uuid\";\n\nconst config2 = { configurable: { thread_id: \"3\" }, streamMode: \"values\" as const };\n\nconst inputMessage3 = new HumanMessage({\n  id: uuidv4(),\n  content: \"hi! I'm bob\",\n});\n\nconsole.log(\"--- FIRST ITERATION ---\\n\");\nfor await (const event of await app2.stream(\n  { messages: [inputMessage3] },\n  config2\n)) {\n  console.log(event.messages.map((message) => [message._getType(), message.content]));\n}\n\nconst inputMessage4 = new HumanMessage({\n  id: uuidv4(),\n  content: \"what's my name?\",\n});\n\nconsole.log(\"\\n\\n--- SECOND ITERATION ---\\n\");\nfor await (const event of await app2.stream(\n  { messages: [inputMessage4] },\n  config2\n)) {\n  console.log(event.messages.map((message) => [message._getType(), message.content]), \"\\n\");\n}\n\nconst messages3 = (await app.getState(config2)).values[\"messages\"]\nconsole.dir(\n  messages3.map((msg) => ({\n    id: msg.id,\n    type: msg._getType(),\n    content: msg.content,\n    tool_calls:\n    msg.tool_calls,\n  })),\n  { depth: null }\n);\n```\n\n----------------------------------------\n\nTITLE: Checking Graph State and Next Action in LangGraph.js\nDESCRIPTION: Retrieves the current state of the graph using the configuration and logs the next expected action. This is used to confirm that the graph is waiting for human review of a tool call.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nstate = await graph.getState(config);\nconsole.log(state.next);\n```\n\n----------------------------------------\n\nTITLE: Starting New Conversation Fresh Context in Python\nDESCRIPTION: This snippet demonstrates how to initiate a new conversation thread in a LangGraph workflow by altering the thread_id and clearing previous memory states for new interactions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nconst newStream = await workflow.stream(\n  [{ role: \"user\", content: \"what's my name?\" }],\n  {\n    configurable: {\n      thread_id: \"2\",\n    },\n    streamMode: \"values\",\n  },\n);\n\nfor await (const chunk of newStream) {\n  console.log(\"=\".repeat(30), `${chunk.getType()} message`, \"=\".repeat(30));\n  console.log(chunk.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Config Schema for Graph in TypeScript\nDESCRIPTION: This snippet defines a configuration schema using annotations to impose structure on `config.configurable` fields, showcasing type checking and error expectation during runtime. It uses LangGraphJS annotations to ensure compliance with expected fields.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/configuration.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MessagesAnnotation } from \"@langchain/langgraph\";\n\nconst ConfigurableAnnotation = Annotation.Root({\n  expectedField: Annotation<string>,\n});\n\nconst printNode = async (\n  state: typeof MessagesAnnotation.State,\n  config: RunnableConfig<typeof ConfigurableAnnotation.State>\n) => {\n  console.log(\"Expected\", config.configurable?.expectedField);\n  // @ts-expect-error This type will be present even though is not in the typing\n  console.log(\"Unexpected\", config.configurable?.unexpectedField);\n  return {};\n};\n\nconst graphWithConfigSchema = new StateGraph(MessagesAnnotation, ConfigurableAnnotation)\n  .addNode(\"printNode\", printNode)\n  .addEdge(START, \"printNode\")\n  .compile();\n\nconst result = await graphWithConfigSchema.invoke({\n  messages: [{ role: \"user\", content: \"Echo!\"} ]\n}, { configurable: { expectedField: \"I am expected\", unexpectedField: \"I am unexpected but present\" } });\n```\n\n----------------------------------------\n\nTITLE: Streaming Recommendations Through Agents in TypeScript\nDESCRIPTION: This snippet showcases a more complex interaction where the user requests detailed recommendations. The input invokes multiple agents in sequence to gather comprehensive information. The output is streamed back, demonstrating the communication and handoff between agents.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst recommendationStream = await graph.stream({\n  messages: [{\n    role: \"user\",\n    content: \"i wanna go somewhere warm in the caribbean. pick one destination, give me some things to do and hotel recommendations\",\n  }],\n});\n\nfor await (const chunk of recommendationStream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Constructing the State Graph and Invoking It in JavaScript\nDESCRIPTION: This snippet initializes the state graph and adds nodes for each operation in the RAG pipeline. It establishes the edges between nodes to control the flow of execution, and invokes the graph with a sample question.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/pass_private_state.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nconst graph = new StateGraph(OverallStateAnnotation)\n  .addNode(\"generate_query\", generateQuery)\n  .addNode(\"retrieve_documents\", retrieveDocuments, { input: QueryOutputAnnotation })\n  .addNode(\"generate\", generate, { input: GenerateOutputAnnotation })\n  .addEdge(\"__start__\", \"generate_query\")\n  .addEdge(\"generate_query\", \"retrieve_documents\")\n  .addEdge(\"retrieve_documents\", \"generate\")\n  .compile();\n\nawait graph.invoke({\n  question: \"How are you?\",\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Network Architecture in Multi-agent LangGraphJS\nDESCRIPTION: Shows how to implement a network architecture where each agent can communicate with every other agent. Each agent decides which agent to call next using LLM responses with structured output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/multi_agent.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport {\n  StateGraph,\n  Annotation,\n  MessagesAnnotation,\n  Command\n} from \"@langchain/langgraph\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o-mini\",\n});\n\nconst agent1 = async (state: typeof MessagesAnnotation.State) => {\n  // you can pass relevant parts of the state to the LLM (e.g., state.messages)\n  // to determine which agent to call next. a common pattern is to call the model\n  // with a structured output (e.g. force it to return an output with a \"next_agent\" field)\n  const response = await model.withStructuredOutput(...).invoke(...);\n  return new Command({\n    update: {\n      messages: [response.content],\n    },\n    goto: response.next_agent,\n  });\n};\n\nconst agent2 = async (state: typeof MessagesAnnotation.State) => {\n  const response = await model.withStructuredOutput(...).invoke(...);\n  return new Command({\n    update: {\n      messages: [response.content],\n    },\n    goto: response.next_agent,\n  });\n};\n\nconst agent3 = async (state: typeof MessagesAnnotation.State) => {\n  ...\n  return new Command({\n    update: {\n      messages: [response.content],\n    },\n    goto: response.next_agent,\n  });\n};\n\nconst graph = new StateGraph(MessagesAnnotation)\n  .addNode(\"agent1\", agent1, {\n    ends: [\"agent2\", \"agent3\" \"__end__\"],\n  })\n  .addNode(\"agent2\", agent2, {\n    ends: [\"agent1\", \"agent3\", \"__end__\"],\n  })\n  .addNode(\"agent3\", agent3, {\n    ends: [\"agent1\", \"agent2\", \"__end__\"],\n  })\n  .addEdge(\"__start__\", \"agent1\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Manually Invoking ToolNode with a Single Tool Call\nDESCRIPTION: Demonstrates manually creating an AIMessage with a single tool call and invoking the ToolNode with it. This shows the basic mechanism of tool calling without using a chat model.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AIMessage } from '@langchain/core/messages';\n\nconst messageWithSingleToolCall = new AIMessage({\n  content: \"\",\n  tool_calls: [\n    {\n      name: \"get_weather\",\n      args: { location: \"sf\" },\n      id: \"tool_call_id\",\n      type: \"tool_call\",\n    }\n  ]\n})\n\nawait toolNode.invoke({ messages: [messageWithSingleToolCall] })\n```\n\n----------------------------------------\n\nTITLE: Using the Stream Method for LLM Tokens - TypeScript\nDESCRIPTION: This code snippet shows how to use the stream method of the agent to access LLM tokens as they are produced.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { isAIMessageChunk } from \"@langchain/core/messages\";\n\nconst stream = await agent.stream(\n  { messages: [{ role: \"user\", content: \"What's the current weather in Nepal?\" }] },\n  { streamMode: \"messages\" },\n);\n\nfor await (const [message, _metadata] of stream) {\n  if (isAIMessageChunk(message) && message.tool_call_chunks?.length) {\n    console.log(`${message.getType()} MESSAGE TOOL CALL CHUNK: ${message.tool_call_chunks[0].args}`);\n  } else {\n    console.log(`${message.getType()} MESSAGE CONTENT: ${message.content}`);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Approving Tool Calls in LangGraph\nDESCRIPTION: This Python snippet captures the process of approving a tool call in the LangGraph workflow. It configures a stream for an LLM-initiated conversation about the weather and demonstrates how to manage human review by using the Command module to iterate a review node, assuming the graph and Command instances exist.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ninputs = { messages: [{ role: \"user\", content: \"what\\'s the weather in SF?\" }] };\nconfig = { configurable: { thread_id: \"2\" }, streamMode: \"values\" as const };\n\nstream = await graph.stream(inputs, config);\n\nfor await (const event of stream) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n\nstate = await graph.getState(config);\nconsole.log(state.next);\n\nimport { Command } from \"@langchain/langgraph\";\n\nfor await (const event of await graph.stream(\n  new Command({ resume: { action: \"continue\" } }),\n  config\n)) {\n  const recentMsg = event.messages[event.messages.length - 1];\n  console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n  console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Entrypoint with Checkpointer in LangGraphJS\nDESCRIPTION: This snippet demonstrates how to create an entrypoint for a workflow with a checkpointer to enable persistence and human-in-the-loop features. The entrypoint wraps a function that processes input and returns a result, with checkpointing to save state between executions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { entrypoint, MemorySaver } from \"@langchain/langgraph\";\n\nconst checkpointer = new MemorySaver();\n\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (someInput: Record<string, any>): Promise<number> => {\n    // some logic that may involve long-running tasks like API calls,\n    // and may be interrupted for human-in-the-loop.\n    return result;\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Verifying LangGraph Agent State Update\nDESCRIPTION: This code snippet demonstrates how to verify that the LangGraph agent state has been successfully updated by checking the current state of the application.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst newState = await app.getState(config);\nconst updatedStateToolCalls = newState.values.messages[newState.values.messages.length -1 ].tool_calls\nconsole.log(updatedStateToolCalls)\n```\n\n----------------------------------------\n\nTITLE: Initializing Tavily Web Search Tool\nDESCRIPTION: Sets up a web search tool using Tavily API integration to handle questions outside the scope of indexed documents.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n\nconst webSearchTool = new TavilySearchResults({ maxResults: 3 });\n\nawait webSearchTool.invoke(\"red robin\");\n```\n\n----------------------------------------\n\nTITLE: Multi-Turn Conversation Test with LangGraph\nDESCRIPTION: This snippet demonstrates a multi-turn conversation with a LangGraph application. It imports necessary modules from `uuid`, `@langchain/langgraph`, and `@langchain/core/messages`. It defines a thread configuration object, an array of user inputs/commands, and a function to run the conversation. The function iterates through the inputs, streams updates from the LangGraph application using `multiTurnGraph.stream`, and logs the AI-generated responses to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-multi-turn-convo-functional.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { v4 as uuidv4 } from 'uuid';\nimport { Command } from \"@langchain/langgraph\";\nimport { isBaseMessage } from \"@langchain/core/messages\";\n\nconst threadConfig = {\n  configurable: { \n    thread_id: uuidv4() \n  },\n  streamMode: \"updates\" as const,\n};\n\nconst inputs = [\n  // 1st round of conversation\n  [{ role: \"user\", content: \"i wanna go somewhere warm in the caribbean\" }],\n  // Since we're using `interrupt`, we'll need to resume using the Command primitive\n  // 2nd round of conversation\n  new Command({\n    resume: \"could you recommend a nice hotel in one of the areas and tell me which area it is.\"\n  }),\n  // 3rd round of conversation\n  new Command({\n    resume: \"i like the first one. could you recommend something to do near the hotel?\"\n  })\n];\n\nconst runConversation = async () => {\n  for (const [idx, userInput] of inputs.entries()) {\n    console.log();\n    console.log(`--- Conversation Turn ${idx + 1} ---`);\n    console.log();\n    console.log(`User: ${JSON.stringify(userInput, null, 2)}`);\n    console.log();\n    \n    const stream = await multiTurnGraph.stream(\n      userInput as any,\n      threadConfig,\n    );\n\n    for await (const update of stream) {\n      if (update.__metadata__?.cached) {\n        continue;\n      }\n      for (const [nodeId, value] of Object.entries(update)) {\n        if (Array.isArray(value) && value.length > 0) {\n          const lastMessage = value.at(-1);\n          if (isBaseMessage(lastMessage) && lastMessage?.getType() === \"ai\") {\n            console.log(`${nodeId}: ${lastMessage.content}`);\n          }\n        }\n      }\n    }\n  }\n};\n\n// Execute the conversation\ntry {\n  await runConversation();\n} catch (e) {\n  console.error(e);\n}\n```\n\n----------------------------------------\n\nTITLE: Correct Non-Deterministic Control Flow in TypeScript\nDESCRIPTION: Demonstrates proper handling of non-deterministic operations by encapsulating them in a task, ensuring consistent behavior when the workflow is resumed.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_21\n\nLANGUAGE: typescript\nCODE:\n```\nimport { task } from \"@langchain/langgraph\";\n\n// highlight-next-line\nconst getTime = task(\"getTime\", () => Date.now());\n\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (inputs: { t0: number }) => {\n    // highlight-next-line\n    const t1 = await getTime();\n\n    const deltaT = t1 - inputs.t0;\n\n    if (deltaT > 1000) {\n      const result = await slowTask(1);\n      const value = interrupt(\"question\");\n      return { result, value };\n    } else {\n      const result = await slowTask(2);\n      const value = interrupt(\"question\");\n      return { result, value };\n    }\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Adding edges to specify logic routing - TypeScript\nDESCRIPTION: This snippet illustrates how to define edges in the graph using the `addEdge` method to manage flow between different nodes, including entry and conditional edges.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { START } from \"@langchain/langgraph\";\n\ngraph.addEdge(START, \"nodeA\");\n```\n\n----------------------------------------\n\nTITLE: Advanced Custom ReAct Agent Implementation\nDESCRIPTION: Extended implementation with custom behavior and fine-grained control over the agent's execution logic.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/quickstart.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n// agent.ts\n\n// IMPORTANT - Add your API keys here. Be careful not to publish them.\nprocess.env.OPENAI_API_KEY = \"sk-...\";\nprocess.env.TAVILY_API_KEY = \"tvly-...\";\n\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { HumanMessage, AIMessage } from \"@langchain/core/messages\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport { StateGraph, MessagesAnnotation } from \"@langchain/langgraph\";\n\n// Define the tools for the agent to use\nconst tools = [new TavilySearchResults({ maxResults: 3 })];\nconst toolNode = new ToolNode(tools);\n\n// Create a model and give it access to the tools\nconst model = new ChatOpenAI({\n  model: \"gpt-4o-mini\",\n  temperature: 0,\n}).bindTools(tools);\n\n// Define the function that determines whether to continue or not\nfunction shouldContinue({ messages }: typeof MessagesAnnotation.State) {\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n\n  // If the LLM makes a tool call, then we route to the \"tools\" node\n  if (lastMessage.tool_calls?.length) {\n    return \"tools\";\n  }\n  // Otherwise, we stop (reply to the user) using the special \"__end__\" node\n  return \"__end__\";\n}\n\n// Define the function that calls the model\nasync function callModel(state: typeof MessagesAnnotation.State) {\n  const response = await model.invoke(state.messages);\n\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\n// Define a new graph\nconst workflow = new StateGraph(MessagesAnnotation)\n  .addNode(\"agent\", callModel)\n  .addEdge(\"__start__\", \"agent\") // __start__ is a special name for the entrypoint\n  .addNode(\"tools\", toolNode)\n  .addEdge(\"tools\", \"agent\")\n  .addConditionalEdges(\"agent\", shouldContinue);\n\n// Finally, we compile it into a LangChain Runnable.\nconst app = workflow.compile();\n\n// Use the agent\nconst finalState = await app.invoke({\n  messages: [new HumanMessage(\"what is the weather in sf\")],\n});\nconsole.log(finalState.messages[finalState.messages.length - 1].content);\n\nconst nextState = await app.invoke({\n  // Including the messages from the previous run gives the LLM context.\n  // This way it knows we're asking about the weather in NY\n  messages: [...finalState.messages, new HumanMessage(\"what about ny\")],\n});\nconsole.log(nextState.messages[nextState.messages.length - 1].content);\n```\n\n----------------------------------------\n\nTITLE: Saving Auth States with Scrapybara SDK\nDESCRIPTION: Shows how to save authentication states using the Scrapybara SDK client.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ScrapybaraClient } from \"scrapybara\";\n\nconst client = new ScrapybaraClient({ apiKey: \"<api_key>\" });\nconst instance = await client.get(\"<instance_id>\");\nconst authStateId = (await instance.saveAuth({ name: \"example_site\" })).authStateId;\n```\n\n----------------------------------------\n\nTITLE: Replaying Past Graph State\nDESCRIPTION: Demonstrates replaying a previous graph state by streaming with its saved configuration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfor await (\n  const { messages } of await graphWithInterrupt.stream(null, {\n    ...toReplay.config,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Moving Side Effects to Separate Nodes (Good Practice)\nDESCRIPTION: This example shows how to separate side effects into dedicated nodes. This approach ensures side effects are properly isolated and only execute once, improving reliability in workflows with interrupts.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt } from \"@langchain/langgraph\";\n\nfunction humanNode(state: typeof GraphAnnotation.State) {\n  /**\n   * Human node with validation.\n   */\n\n  const answer = interrupt(question);\n\n  return {\n    answer\n  };\n}\n\nfunction apiCallNode(state: typeof GraphAnnotation.State) {\n  apiCall(); // OK as it's in a separate node\n}\n```\n\n----------------------------------------\n\nTITLE: Verifying Summarization Results\nDESCRIPTION: Checking the conversation state after summarization to confirm that it now contains a summary and only the most recent messages, as configured in the summarizeConversation function.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nconst values2 = (await app.getState(config)).values\nconsole.log(values2)\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI SDK and Tool Schema - Python\nDESCRIPTION: This snippet sets up the OpenAI SDK and defines a tool schema with a function `get_items`. The `toolSchema` will be populated with OpenAI's format, requiring a `place` parameter to specify the location for item lookup.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-tokens-without-langchain.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport OpenAI from \"openai\";\n\nconst openaiClient = new OpenAI({});\n\nconst toolSchema: OpenAI.ChatCompletionTool = {\n  type: \"function\",\n  function: {\n    name: \"get_items\",\n    description: \"Use this tool to look up which items are in the given place.\",\n    parameters: {\n      type: \"object\",\n      properties: {\n        place: {\n          type: \"string\",\n        },\n      },\n      required: [\"place\"],\n    }\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Implementing Re-Planning Capability\nDESCRIPTION: Creates a component for updating the plan based on completed steps. This allows the agent to adapt its plan dynamically as it gains new information through execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { JsonOutputToolsParser } from \"@langchain/core/output_parsers/openai_tools\";\n\nconst response = zodToJsonSchema(\n  z.object({\n    response: z.string().describe(\"Response to user.\"),\n  }),\n);\n\nconst responseTool = {\n  type: \"function\",\n  function: {\n    name: \"response\",\n    description: \"Response to user.\",\n    parameters: response,\n  },\n};\n\nconst replannerPrompt = ChatPromptTemplate.fromTemplate(\n  `For the given objective, come up with a simple step by step plan. \nThis plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps.\nThe result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n\nYour objective was this:\n{input}\n\nYour original plan was this:\n{plan}\n\nYou have currently done the follow steps:\n{pastSteps}\n\nUpdate your plan accordingly. If no more steps are needed and you can return to the user, then respond with that and use the 'response' function.\nOtherwise, fill out the plan.  \nOnly add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.`,\n);\n\nconst parser = new JsonOutputToolsParser();\nconst replanner = replannerPrompt\n  .pipe(\n    new ChatOpenAI({ model: \"gpt-4o\" }).bindTools([\n      planTool,\n      responseTool,\n    ]),\n  )\n  .pipe(parser);\n```\n\n----------------------------------------\n\nTITLE: Implementing Channel-Based Message Passing in TypeScript\nDESCRIPTION: Functions that handle the channel-based message passing between nodes, including reading from channels nodes subscribe to and writing to channels to share data.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-execution-model.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Nodes read from channels they subscribe to\nfunction _readFromChannels(\n  node: string,\n  channels: Record<string, BaseChannel>,\n  readEdges: ReadEdges\n): Record<string, any> {\n  const reads: Record<string, any> = {};\n  \n  for (const channelName of readEdges.get(node) || []) {\n    reads[channelName] = channels[channelName].get();\n  }\n  \n  return reads;\n}\n\n// Nodes write to channels to share data\nfunction _writeToChannels(\n  writes: ChannelWrite[],\n  channels: Record<string, BaseChannel>,\n  versions: Versions\n): void {\n  for (const write of writes) {\n    const channel = channels[write.channel];\n    const updated = channel.update(write.values);\n    \n    if (updated) {\n      versions.channelVersions[write.channel] += 1;\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Placeholder Search Tool in JavaScript\nDESCRIPTION: Defines a placeholder tool that simulates a search engine, which can be integrated into the LangGraph system. Zod library is used to define the input schema for this tool.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-values.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst searchTool = tool(async ({ query: _query }: { query: string }) => {\n  // This is a placeholder for the actual implementation\n  return \"Cold, with a low of 3\\u2103\";\n}, {\n  name: \"search\",\n  description:\n    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n});\n\nawait searchTool.invoke({ query: \"What's the weather like?\" });\n\nconst tools = [searchTool];\n```\n\n----------------------------------------\n\nTITLE: Creating a ReAct Execution Agent\nDESCRIPTION: Sets up the execution agent that will perform individual tasks. Uses OpenAI's GPT-4o model and the previously defined tools to create a ReAct-style agent capable of executing individual steps.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\nconst agentExecutor = createReactAgent({\n  llm: new ChatOpenAI({ model: \"gpt-4o\" }),\n  tools: tools,\n});\n```\n\n----------------------------------------\n\nTITLE: Loading Chat Model in LangGraphJS - TypeScript\nDESCRIPTION: This code snippet demonstrates how to load a chat model using OpenAI's model with specified parameters.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o-mini\",\n  temperature: 0,\n});\n```\n\n----------------------------------------\n\nTITLE: Checking Next State in LangGraph with Python\nDESCRIPTION: This snippet demonstrates how to check the next state of the LangGraph application after an interaction.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nconsole.log(\"next: \", (await messagesApp.getState(config2)).next)\n```\n\n----------------------------------------\n\nTITLE: Resuming Workflow After Human Review in LangGraphJS\nDESCRIPTION: This code demonstrates how to resume a workflow after receiving human input. It uses the Command object to pass the human review response back to the interrupted workflow, allowing it to continue execution from where it left off.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Get review from a user (e.g., via a UI)\n// In this case, we're using a bool, but this can be any json-serializable value.\nconst humanReview = true;\n\nfor await (const item of await workflow.stream(new Command({ resume: humanReview }), config)) {\n  console.log(item);\n}\n```\n\n----------------------------------------\n\nTITLE: Output of LangGraph Event Streaming\nDESCRIPTION: This shell output shows the event sequence generated when running a LangGraph with streamEvents. It demonstrates the lifecycle of events from graph start to completion, including LLM streaming events, node execution events, and channel writes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/streaming.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\non_chain_start: LangGraph\non_chain_start: __start__\non_chain_end: __start__\non_chain_start: callModel\non_chat_model_start: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_stream: ChatOpenAI\non_chat_model_end: ChatOpenAI\non_chain_start: ChannelWrite<callModel,messages>\non_chain_end: ChannelWrite<callModel,messages>\non_chain_stream: callModel\non_chain_end: callModel\non_chain_stream: LangGraph\non_chain_end: LangGraph\n```\n\n----------------------------------------\n\nTITLE: Interacting with LangGraph Agent and Streaming Responses\nDESCRIPTION: Interaction with the compiled graph by sending a user message and streaming the responses. The code demonstrates how to process different types of messages, including text content and tool calls.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nlet config = { configurable: { thread_id: \"conversation-num-1\" } };\nlet inputs = { messages: [{ role: \"user\", content: \"Hi I'm Jo.\" }] } as any;\nfor await (\n  const { messages } of await graph.stream(inputs, {\n    ...config,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic LangGraph with Breakpoints\nDESCRIPTION: This code snippet demonstrates setting up a simple LangGraph with breakpoints, a checkpointer, and state updates. It includes three steps and uses the StateGraph class.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, START, END, Annotation } from \"@langchain/langgraph\";\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst GraphState = Annotation.Root({\n  input: Annotation<string>\n});\n\nconst step1 = (state: typeof GraphState.State) => {\n  console.log(\"---Step 1---\");\n  return state;\n}\n\nconst step2 = (state: typeof GraphState.State) => {\n  console.log(\"---Step 2---\");\n  return state;\n}\n\nconst step3 = (state: typeof GraphState.State) => {\n  console.log(\"---Step 3---\");\n  return state;\n}\n\n\nconst builder = new StateGraph(GraphState)\n  .addNode(\"step1\", step1)\n  .addNode(\"step2\", step2)\n  .addNode(\"step3\", step3)\n  .addEdge(START, \"step1\")\n  .addEdge(\"step1\", \"step2\")\n  .addEdge(\"step2\", \"step3\")\n  .addEdge(\"step3\", END);\n\n\n// Set up memory\nconst graphStateMemory = new MemorySaver()\n\nconst graph = builder.compile({\n  checkpointer: graphStateMemory,\n  interruptBefore: [\"step2\"]\n});\n```\n\n----------------------------------------\n\nTITLE: LLM with Structured Output and Tool Calling\nDESCRIPTION: Demonstrates how to augment an LLM with structured output schemas and tools. Shows creating a schema for search queries and a multiplication tool, then invoking the augmented LLM instances.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst searchQuerySchema = z.object({\n  searchQuery: z.string().describe(\"Query that is optimized web search.\"),\n  justification: z.string(\"Why this query is relevant to the user's request.\"),\n});\n\n// Augment the LLM with schema for structured output\nconst structuredLlm = llm.withStructuredOutput(searchQuerySchema, {\n  name: \"searchQuery\",\n});\n\n// Invoke the augmented LLM\nconst output = await structuredLlm.invoke(\n  \"How does Calcium CT score relate to high cholesterol?\"\n);\n\nconst multiply = tool(\n  async ({ a, b }) => {\n    return a * b;\n  },\n  {\n    name: \"multiply\",\n    description: \"multiplies two numbers together\",\n    schema: z.object({\n      a: z.number(\"the first number\"),\n      b: z.number(\"the second number\"),\n    }),\n  }\n);\n\n// Augment the LLM with tools\nconst llmWithTools = llm.bindTools([multiply]);\n\n// Invoke the LLM with input that triggers the tool call\nconst message = await llmWithTools.invoke(\"What is 2 times 3?\");\n\nconsole.log(message.tool_calls);\n```\n\n----------------------------------------\n\nTITLE: Building Parallel Workflow with Graph API in TypeScript\nDESCRIPTION: This code snippet demonstrates the creation of a parallel workflow in TypeScript using LangChain's Graph API. It involves defining state annotations, setting up tasks to generate a joke, a story, and a poem using LLMs, and finally aggregating these tasks into a combined output. Dependencies include the '@langchain/langgraph' package and a functional LLM instance. Input parameters include a topic string, and the output is a combined string containing the generated joke, story, and poem.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\n// Graph state\nconst StateAnnotation = Annotation.Root({\n  topic: Annotation<string>,\n  joke: Annotation<string>,\n  story: Annotation<string>,\n  poem: Annotation<string>,\n  combinedOutput: Annotation<string>,\n});\n\n// Nodes\n// First LLM call to generate initial joke\nasync function callLlm1(state: typeof StateAnnotation.State) {\n  const msg = await llm.invoke(`Write a joke about ${state.topic}`);\n  return { joke: msg.content };\n}\n\n// Second LLM call to generate story\nasync function callLlm2(state: typeof StateAnnotation.State) {\n  const msg = await llm.invoke(`Write a story about ${state.topic}`);\n  return { story: msg.content };\n}\n\n// Third LLM call to generate poem\nasync function callLlm3(state: typeof StateAnnotation.State) {\n  const msg = await llm.invoke(`Write a poem about ${state.topic}`);\n  return { poem: msg.content };\n}\n\n// Combine the joke, story and poem into a single output\nasync function aggregator(state: typeof StateAnnotation.State) {\n  const combined = `Here's a story, joke, and poem about ${state.topic}!\\n\\n` +\n    `STORY:\\n${state.story}\\n\\n` +\n    `JOKE:\\n${state.joke}\\n\\n` +\n    `POEM:\\n${state.poem}`;\n  return { combinedOutput: combined };\n}\n\n// Build workflow\nconst parallelWorkflow = new StateGraph(StateAnnotation)\n  .addNode(\"callLlm1\", callLlm1);\n  .addNode(\"callLlm2\", callLlm2);\n  .addNode(\"callLlm3\", callLlm3);\n  .addNode(\"aggregator\", aggregator);\n  .addEdge(\"__start__\", \"callLlm1\");\n  .addEdge(\"__start__\", \"callLlm2\");\n  .addEdge(\"__start__\", \"callLlm3\");\n  .addEdge(\"callLlm1\", \"aggregator\");\n  .addEdge(\"callLlm2\", \"aggregator\");\n  .addEdge(\"callLlm3\", \"aggregator\");\n  .addEdge(\"aggregator\", \"__end__\");\n  .compile();\n\n// Invoke\nconst result = await parallelWorkflow.invoke({ topic: \"cats\" });\nconsole.log(result.combinedOutput);\n```\n\n----------------------------------------\n\nTITLE: Streaming Events from Final Node in LanggraphJS\nDESCRIPTION: This snippet illustrates how to initiate streaming of events from the final node of a graph using LanggraphJS. Inputs are set, and the streaming process checks for specific tags and event types. Non-empty content is output to the console, but empty content is ignored, which could indicate a model tool call requirement.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-from-final-node.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconst inputs = { messages: [new HumanMessage(\"What's the weather in nyc?\")] };\n\nconst eventStream = await graph.streamEvents(inputs, { version: \"v2\"});\n\nfor await (const { event, tags, data } of eventStream) {\n  if (event === \"on_chat_model_stream\" && tags.includes(\"final_node\")) {\n    if (data.chunk.content) {\n      // Empty content in the context of OpenAI or Anthropic usually means\n      // that the model is asking for a tool to be invoked.\n      // So we only print non-empty content\n      console.log(data.chunk.content, \"|\");\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Setting Anthropic and LangSmith API Keys in Shell\nDESCRIPTION: Sets environment variables for Anthropic API and optionally Langchain tracing API. It requires valid API keys and configuration for enabling LangBrown's callback features.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/breakpoints.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ANTHROPIC_API_KEY=your-api-key\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\nexport LANGCHAIN_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Storing Memory Structure - Python\nDESCRIPTION: This snippet illustrates how to store a structured memory entry into the memory store using a composite key made up of a namespace and a unique memory key.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nlet namespace = [\"user_123\", \"memories\"]\nlet memoryKey = \"favorite_food\"\nlet memoryValue = {\"text\": \"I love pizza\"}\n\nawait store.put(namespace, memoryKey, memoryValue)\n```\n\n----------------------------------------\n\nTITLE: Running the Simulation and Monitoring the Conversation\nDESCRIPTION: Executes the chat bot evaluation simulation and logs the conversation flow, showing messages from both the simulated user and the chat bot as they interact.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nasync function runSimulation() {\n  const simulation = createSimulation()\n  for await (const chunk of await simulation.stream({})) {\n    const nodeName = Object.keys(chunk)[0];\n    const messages = chunk[nodeName].messages;\n    console.log(`${nodeName}: ${messages[0].content}`);\n    console.log('\\n---\\n');\n  }\n}\n\n\nawait runSimulation();\n```\n\n----------------------------------------\n\nTITLE: Executing Graph with Interruption before Weather Node in JavaScript\nDESCRIPTION: This code runs the graph with a user input, interrupts before the weather node, retrieves the interrupted state, and then updates the state by acting as the weather node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_19\n\nLANGUAGE: javascript\nCODE:\n```\nconst streamWithAsNode = await graph.stream({\n  messages: [{\n    role: \"user\",\n    content: \"What's the weather in sf\",\n  }]\n}, {\n  configurable: {\n    thread_id: \"14\",\n  }\n});\n\nfor await (const update of streamWithAsNode) {\n  console.log(update);\n}\n\nconsole.log(\"interrupted!\");\n\nconst interruptedState = await graph.getState({\n  configurable: {\n    thread_id: \"14\",\n  }\n}, { subgraphs: true });\n\nconsole.log(interruptedState);\n\nawait graph.updateState((interruptedState.tasks[0].state as StateSnapshot).config, {\n  messages: [{\n    \"role\": \"assistant\",\n    \"content\": \"rainy\"\n  }]\n}, \"weatherNode\");\n\n\nconst resumedStreamWithAsNode = await graph.stream(null, {\n  configurable: {\n    thread_id: \"14\",\n  },\n  streamMode: \"updates\",\n  subgraphs: true,\n});\n\nfor await (const update of resumedStreamWithAsNode) {\n  console.log(update);\n}\n\nconsole.log(await graph.getState({\n  configurable: {\n    thread_id: \"14\",\n  }\n}, { subgraphs: true }));\n```\n\n----------------------------------------\n\nTITLE: Displaying the Generated Graph with TSLab in TypeScript\nDESCRIPTION: This snippet uses TSLab to generate and display a visual representation of the created agent graph. It retrieves the graph structure asynchronously and converts it to an image format for display. Necessary dependencies include the tslab library.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraph = await graph.getGraphAsync();\nconst image = await drawableGraph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Building the Plan-Execute Agent Graph\nDESCRIPTION: Constructs the workflow graph for the plan-execute agent, defining how steps, planning, and replanning connect together. This implements the core logic of the agent's operation flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\nimport { RunnableConfig } from \"@langchain/core/runnables\";\n\nasync function executeStep(\n  state: typeof PlanExecuteState.State,\n  config?: RunnableConfig,\n): Promise<Partial<typeof PlanExecuteState.State>> {\n  const task = state.plan[0];\n  const input = {\n    messages: [new HumanMessage(task)],\n  };\n  const { messages } = await agentExecutor.invoke(input, config);\n\n  return {\n    pastSteps: [[task, messages[messages.length - 1].content.toString()]],\n    plan: state.plan.slice(1),\n  };\n}\n\nasync function planStep(\n  state: typeof PlanExecuteState.State,\n): Promise<Partial<typeof PlanExecuteState.State>> {\n  const plan = await planner.invoke({ objective: state.input });\n  return { plan: plan.steps };\n}\n\nasync function replanStep(\n  state: typeof PlanExecuteState.State,\n): Promise<Partial<typeof PlanExecuteState.State>> {\n  const output = await replanner.invoke({\n    input: state.input,\n    plan: state.plan.join(\"\\n\"),\n    pastSteps: state.pastSteps\n      .map(([step, result]) => `${step}: ${result}`)\n      .join(\"\\n\"),\n  });\n  const toolCall = output[0];\n\n  if (toolCall.type == \"response\") {\n    return { response: toolCall.args?.response };\n  }\n\n  return { plan: toolCall.args?.steps };\n}\n\nfunction shouldEnd(state: typeof PlanExecuteState.State) {\n  return state.response ? \"true\" : \"false\";\n}\n\nconst workflow = new StateGraph(PlanExecuteState)\n  .addNode(\"planner\", planStep)\n  .addNode(\"agent\", executeStep)\n  .addNode(\"replan\", replanStep)\n  .addEdge(START, \"planner\")\n  .addEdge(\"planner\", \"agent\")\n  .addEdge(\"agent\", \"replan\")\n  .addConditionalEdges(\"replan\", shouldEnd, {\n    true: END,\n    false: \"agent\",\n  });\n\n// Finally, we compile it!\n// This compiles it into a LangChain Runnable,\n// meaning you can use it as you would any other runnable\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Resuming Agent Execution with Human Input in Python\nDESCRIPTION: This code demonstrates how to resume the agent's execution after receiving human input. It creates a Command object with the human response and streams the resumed execution, pretty-printing each step.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport { Command } from \"@langchain/langgraph\";\n\nconst humanResponse = \"You should feed your cat a fish.\";\nconst humanCommand = new Command({\n  resume: { data: humanResponse },\n});\n\nconst resumeStream2 = await agent.stream(humanCommand, config);\n\nfor await (const step of resumeStream2) {\n  prettyPrintStep(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Transient Errors in Workflow Invocation\nDESCRIPTION: This code snippet shows how to invoke a workflow with a null value to handle transient errors effectively. It assumes that the error has been resolved and execution can proceed.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = {\n  configurable: {\n    thread_id: \"some_thread_id\",\n  },\n};\n\nawait myWorkflow.invoke(null, config);\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Route with Hono in TypeScript\nDESCRIPTION: TypeScript code to create a custom route using Hono in a LangGraph application. It defines a simple '/hello' endpoint that returns a JSON response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/http/custom_routes.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// ./src/agent/app.ts\nimport { Hono } from \"hono\";\n\nexport const app = new Hono();\n\napp.get(\"/hello\", (c) => c.json({ hello: \"world\" }));\n```\n\n----------------------------------------\n\nTITLE: Retrieving Parent Graph State Before Subgraph in JavaScript\nDESCRIPTION: This code snippet demonstrates how to retrieve the parent graph state before a subgraph is executed. It iterates through the graph's state history to find the state where the next node is 'weatherGraph'.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\nlet parentGraphStateBeforeSubgraph;\n\nconst histories = await graph.getStateHistory({ configurable: { thread_id: \"3\" } });\n\nfor await (const historyEntry of histories) {\n  if (historyEntry.next[0] === \"weatherGraph\") {\n    parentGraphStateBeforeSubgraph = historyEntry;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing the Simulated User Node with Role Swapping\nDESCRIPTION: Defines a node for the simulated user in the LangGraph workflow, including logic to swap the roles of messages between AI and Human, so the simulated user can properly respond to the chat bot's messages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport { BaseMessage, HumanMessage } from \"@langchain/core/messages\";\n\n// MessagesAnnotation coerces all message likes to base message classes\nfunction swapRoles(messages: BaseMessage[]) {\n  return messages.map((m) =>\n    m instanceof AIMessage\n      ? new HumanMessage({ content: m.content })\n      : new AIMessage({ content: m.content }),\n  )\n}\n\nasync function simulatedUserNode (state: typeof MessagesAnnotation.State) {\n  const messages = state.messages\n  const newMessages = swapRoles(messages)\n  // This returns a runnable directly, so we need to use `.invoke` below:\n  const simulateUser = await createSimulatedUser();\n  const response = await simulateUser.invoke({ messages: newMessages })\n\n  return { messages: [{ role: \"user\", content: response.content }] }\n}\n```\n\n----------------------------------------\n\nTITLE: Invoking Workflow in LangGraphJS\nDESCRIPTION: This code snippet demonstrates how to invoke a workflow using the 'invoke' method while passing a configuration object. It waits for the result of the operation based on the provided input.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = {\n  configurable: {\n    thread_id: \"some_thread_id\",\n  },\n};\nawait myWorkflow.invoke(someInput, config);  // Wait for the result\n```\n\n----------------------------------------\n\nTITLE: Visualizing the Graph in Python\nDESCRIPTION: This snippet retrieves and visualizes the constructed graph using the TSLab visualization library, enabling a graphical representation of the workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst graph = app.getGraph();\nconst image = await graph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Generating Custom Tool Message with Feedback\nDESCRIPTION: Creates a Command with the 'feedback' action to provide instructions on how to format the location data. This allows for custom messaging to guide the tool call reformatting.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\n// highlight-next-line\nconst humanInput3 = new Command({\n  // highlight-next-line\n  resume: {\n    // highlight-next-line\n    action: \"feedback\",\n    // highlight-next-line\n    data: \"Please format as <City>, <State>.\",\n    // highlight-next-line\n  },\n  // highlight-next-line\n});\n\nconst resumedStream3 = await agent.stream(humanInput3, config3)\n\nfor await (const step of resumedStream3) {\n  printStep(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Getting Full State History of the Graph Execution in TypeScript\nDESCRIPTION: This snippet demonstrates how to retrieve the complete history of the graph's execution for a specified thread by calling `getStateHistory`. The returned data provides a chronological list of state snapshots from all checkpoints associated with the thread.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = { configurable: { thread_id: \"1\" } };\nconst history = await graph.getStateHistory(config);\n```\n\n----------------------------------------\n\nTITLE: Getting Grandparent Graph State in LangGraph.js\nDESCRIPTION: This example retrieves the state of the grandparent graph, including the states of its nested parent and subgraph, using LangGraph.js. It then logs the values of each graph's state to the console for inspection.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nconst grandparentGraphState = await grandparentGraph.getState(\n  grandparentConfig, \n  { subgraphs: true }\n);\n\nconst parentGraphState = grandparentGraphState.tasks[0].state as StateSnapshot;\nconst subgraphState = parentGraphState.tasks[0].state as StateSnapshot;\n\nconsole.log(\"Grandparent State:\");\nconsole.log(grandparentGraphState.values);\nconsole.log(\"---------------\");\nconsole.log(\"Parent Graph State:\");\nconsole.log(parentGraphState.values);\nconsole.log(\"---------------\");\nconsole.log(\"Subgraph State:\");\nconsole.log(subgraphState.values);\n```\n\n----------------------------------------\n\nTITLE: Jest Integration Example\nDESCRIPTION: Example of integrating the validation tool into an existing Jest-compatible test suite by importing and using the validate function.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint-validation/README.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { validate } from \"@langchain/langgraph-validation\";\n\nvalidate(MyCheckpointerInitializer);\n```\n\n----------------------------------------\n\nTITLE: Constructing the StateGraph for LangGraphJS\nDESCRIPTION: This code constructs the StateGraph using the previously defined nodes and edges, and compiles it into a LangChain Runnable.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { START, StateGraph } from \"@langchain/langgraph\";\n\nconst workflow = new StateGraph(AgentState)\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  .addEdge(START, \"agent\")\n  .addConditionalEdges(\n    \"agent\",\n    shouldContinue,\n  )\n  .addEdge(\"tools\", \"agent\");\n\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Error Recovery in LangGraph.js Workflow\nDESCRIPTION: Demonstrates how to implement a workflow with error recovery using checkpointing. The example includes a task that fails on first attempt but succeeds on retry, and a slow task to showcase checkpoint-based resumption.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_28\n\nLANGUAGE: typescript\nCODE:\n```\nimport { entrypoint, task, MemorySaver } from \"@langchain/langgraph\";\n\n// Global variable to track the number of attempts\nlet attempts = 0;\n\nconst getInfo = task(\"getInfo\", () => {\n  /*\n   * Simulates a task that fails once before succeeding.\n   * Throws an error on the first attempt, then returns \"OK\" on subsequent tries.\n   */\n  attempts += 1;\n\n  if (attempts < 2) {\n    throw new Error(\"Failure\"); // Simulate a failure on the first attempt\n  }\n  return \"OK\";\n});\n\n// Initialize an in-memory checkpointer for persistence\nconst checkpointer = new MemorySaver();\n\nconst slowTask = task(\"slowTask\", async () => {\n  /*\n   * Simulates a slow-running task by introducing a 1-second delay.\n   */\n  await new Promise((resolve) => setTimeout(resolve, 1000));\n  return \"Ran slow task.\";\n});\n\nconst main = entrypoint(\n  { checkpointer, name: \"main\" },\n  async (inputs: Record<string, any>) => {\n    /*\n     * Main workflow function that runs the slowTask and getInfo tasks sequentially.\n     *\n     * Parameters:\n     * - inputs: Record<string, any> containing workflow input values.\n     *\n     * The workflow first executes `slowTask` and then attempts to execute `getInfo`,\n     * which will fail on the first invocation.\n     */\n    const slowTaskResult = await slowTask(); // Blocking call to slowTask\n    await getInfo(); // Error will be thrown here on the first attempt\n    return slowTaskResult;\n  }\n);\n\n// Workflow execution configuration with a unique thread identifier\nconst config = {\n  configurable: {\n    thread_id: \"1\", // Unique identifier to track workflow execution\n  },\n};\n\n// This invocation will take ~1 second due to the slowTask execution\ntry {\n  // First invocation will throw an error due to the `getInfo` task failing\n  await main.invoke({ anyInput: \"foobar\" }, config);\n} catch (err) {\n  // Handle the failure gracefully\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Tools and Tool-Calling Node - Python\nDESCRIPTION: The snippet defines `getItems` function which responds with items based on the place queried and `callTools` function which processes model-populated tool calls. Valid tool calls are executed based on a predefined map.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-tokens-without-langchain.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nconst getItems = async ({ place }: { place: string }) => {\n  if (place.toLowerCase().includes(\"bed\")) {\n    return \"socks, shoes and dust bunnies\";\n  } else if (place.toLowerCase().includes(\"shelf\")) {\n    return \"books, pencils and pictures\";\n  } else {\n    return \"cat snacks\";\n  }\n};\n\nconst callTools = async (state: typeof StateAnnotation.State) => {\n  const { messages } = state;\n  const mostRecentMessage = messages[messages.length - 1];\n  const toolCalls = (mostRecentMessage as OpenAI.ChatCompletionAssistantMessageParam).tool_calls;\n  if (toolCalls === undefined || toolCalls.length === 0) {\n    throw new Error(\"No tool calls passed to node.\");\n  }\n  const toolNameMap = {\n    get_items: getItems,\n  };\n  const functionName = toolCalls[0].function.name;\n  const functionArguments = JSON.parse(toolCalls[0].function.arguments);\n  const response = await toolNameMap[functionName](functionArguments);\n  const toolMessage = {\n    tool_call_id: toolCalls[0].id,\n    role: \"tool\" as const,\n    name: functionName,\n    content: response,\n  }\n  return { messages: [toolMessage] };\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring the Conversational Thread in Python\nDESCRIPTION: This snippet shows how to configure the conversational thread for the agent by setting a thread ID. It is essential for enabling the persistence of conversational context across multiple interactions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nconst config = { configurable: { thread_id: \"1\" } };\n```\n\n----------------------------------------\n\nTITLE: Testing Multi-Agent Communication with LangChain\nDESCRIPTION: Demonstrates testing of the agent network using an asynchronous stream to process real-time user input. Executes the networkGraph function and uses prettyPrintMessages to print results.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\nconst stream = await networkGraph.stream([{\\n  role: \"user\",\\n  content: \"i wanna go somewhere warm in the caribbean. pick one destination and give me hotel recommendations\"\\n}], { subgraphs: true })\\n\\nfor await (const chunk of stream) {\\n  prettyPrintMessages(chunk);\\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Branch from Past State\nDESCRIPTION: Updates a previous checkpoint with new tool message data to create a branch for alternate execution paths.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nconst tool_calls =\n  toReplay.values.messages[toReplay.values.messages.length - 1].tool_calls;\nconst branchConfig = await graphWithInterrupt.updateState(\n  toReplay.config,\n  {\n    messages: [\n      { role: \"tool\", content: \"It's sunny out, with a high of 38 ℃.\", tool_call_id: tool_calls[0].id },\n    ],\n  },\n  \"tools\",\n);\n\nconst branchState = await graphWithInterrupt.getState(branchConfig);\nconsole.log(branchState.values);\nconsole.log(branchState.next);\n```\n\n----------------------------------------\n\nTITLE: Compiling Graph with In-Memory Checkpointer in LangGraphJS\nDESCRIPTION: This snippet demonstrates how to compile a LangGraphJS graph using an in-memory checkpointer called MemorySaver, allowing conversation-level memory across interactions. Dependencies include MemorySaver from '@langchain/langgraph'. The code creates and initializes a MemorySaver instance, which is then used in compiling a graph with thread-level persistence.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst checkpointer = new MemorySaver();\nconst graph = workflow.compile({ checkpointer });\n```\n\n----------------------------------------\n\nTITLE: Storing Memory in InMemoryStore\nDESCRIPTION: Demonstrates how to use the InMemoryStore 'put' method to store a memory object associated with a specific memory ID. The UUID library is used to generate unique identifiers for each memory entry, ensuring distinct memory keys for data integrity.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_9\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { v4 as uuid4 } from 'uuid';\n\nconst memoryId = uuid4();\nconst memory = { food_preference: \"I like pizza\" };\nawait inMemoryStore.put(namespaceForMemory, memoryId, memory);\n```\n\n----------------------------------------\n\nTITLE: Updating Subgraph State in LangGraph.js\nDESCRIPTION: This snippet updates the state of the subgraph within the grandparent graph in LangGraph.js. It uses the subgraph's configuration to send a new message and then streams updates from the grandparent graph to observe the effects of the state change.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nawait grandparentGraph.updateState(subgraphState.config, {\n  messages: [{\n    role: \"assistant\",\n    content: \"rainy\"\n  }]\n}, \"weatherNode\");\n\nconst updatedGrandparentGraphStream = await grandparentGraph.stream(null, {\n  ...grandparentConfig,\n  streamMode: \"updates\",\n  subgraphs: true,\n});\n\nfor await (const update of updatedGrandparentGraphStream) {\n  console.log(update);\n}\n\nconsole.log((await grandparentGraph.getState(grandparentConfig)).values.messages)\n```\n\n----------------------------------------\n\nTITLE: Implementing State Annotation with Dynamic List Management\nDESCRIPTION: Demonstrates a custom state reducer for managing a dynamic list of messages with support for selective retention and deletion of historical context\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/memory.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  myList: Annotation<any[]>({\n    reducer: (\n      existing: string[],\n      updates: string[] | { type: string; from: number; to?: number }\n    ) => {\n      if (Array.isArray(updates)) {\n        return [...existing, ...updates];\n      } else if (typeof updates === \"object\" && updates.type === \"keep\") {\n        return existing.slice(updates.from, updates.to);\n      }\n      return existing;\n    },\n    default: () => [],\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Tool Creation for Research and Charts\nDESCRIPTION: Creates tools for web research using Tavily Search and chart generation using D3.js with canvas.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/agent_supervisor.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nrequire(\"esm-hook\");\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\nimport { DynamicStructuredTool } from \"@langchain/core/tools\";\nimport * as d3 from \"d3\";\nimport { createCanvas } from \"canvas\";\nimport { z } from \"zod\";\nimport * as tslab from \"tslab\";\n\nconst chartTool = new DynamicStructuredTool({\n  name: \"generate_bar_chart\",\n  description: \"Generates a bar chart from an array of data points using D3.js and displays it for the user.\",\n  schema: z.object({\n    data: z.object({\n      label: z.string(),\n      value: z.number(),\n    }).array(),\n  }),\n  func: async ({ data }) => {\n    // ... chart generation code ...\n  },\n});\n\nconst tavilyTool = new TavilySearchResults();\n```\n\n----------------------------------------\n\nTITLE: Creating a Utility Function to Print Updates\nDESCRIPTION: Defining a helper function that prints updates from the LangGraph application, including displaying messages and summaries in a formatted way.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconst printUpdate = (update: Record<string, any>) => {\n  Object.keys(update).forEach((key) => {\n    const value = update[key];\n\n    if (\"messages\" in value && Array.isArray(value.messages)) {\n      value.messages.forEach((msg) => {\n        console.log(`\\n================================ ${msg._getType()} Message =================================`)\n        console.log(msg.content);\n      })\n    }\n    if (\"summary\" in value && value.summary) {\n      console.log(value.summary);\n    }\n  })\n}\n```\n\n----------------------------------------\n\nTITLE: Binding Tools to Chat Model in LangChain\nDESCRIPTION: In this snippet, tools are bound to a chat model in LangGraphJS, using the 'bindTools' method to ensure the model is aware of available tools. Requires an instance of ChatOpenAI and the previously defined tools. This binding allows the model to generate appropriate tool calls in its output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nconst boundModel = model.bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: Defining Transfer Tool for Agent Handoffs - TypeScript\nDESCRIPTION: This snippet defines a tool using Zod for schema validation, which signals the intent to transfer control to another agent, specifically the hotel advisor. It returns a success message upon invocation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst transferToHotelAdvisor = tool(async () => {\n  return \"Successfully transferred to hotel advisor\";\n}, {\n  name: \"transferToHotelAdvisor\",\n  description: \"Ask hotel advisor agent for help.\",\n  schema: z.object({}),\n  returnDirect: true,\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Connection Pool Using Connection String in Python-like Syntax\nDESCRIPTION: This code illustrates how to create a Postgres connection pool by passing a connection string to the `PostgresSaver.fromConnString` method. It sets up a react agent for LangGraph.js with a checkpointer configured for state persistence. The snippet requires valid connection details for proper operation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-postgres.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconst checkpointerFromConnString = PostgresSaver.fromConnString(\n  \"postgresql://user:password@localhost:5434/testdb\"\n);\n\nconst graph2 = createReactAgent({\n  tools: [getWeather],\n  llm: new ChatOpenAI({\n    model: \"gpt-4o-mini\",\n  }),\n  checkpointSaver: checkpointerFromConnString,\n});\nconst config2 = { configurable: { thread_id: \"2\" } };\n\nawait graph2.invoke({\n  messages: [{\n    role: \"user\",\n    content: \"what's the weather in sf\"\n  }],\n}, config2);\n```\n\nLANGUAGE: python\nCODE:\n```\nawait checkpointerFromConnString.get(config2);\n```\n\n----------------------------------------\n\nTITLE: Implementing Multi-Agent System with Supervisor\nDESCRIPTION: Complete example showing how to create specialized agents and a supervisor to manage them, including tool definitions and workflow setup.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-supervisor/README.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { createSupervisor } from \"@langchain/langgraph-supervisor\";\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst model = new ChatOpenAI({ modelName: \"gpt-4o\" });\n\n// Create specialized agents\nconst add = tool(\n  async (args) => args.a + args.b,\n  {\n    name: \"add\",\n    description: \"Add two numbers.\",\n    schema: z.object({\n      a: z.number(),\n      b: z.number()\n    })\n  }\n);\n\nconst multiply = tool(\n  async (args) => args.a * args.b,\n  {\n    name: \"multiply\", \n    description: \"Multiply two numbers.\",\n    schema: z.object({\n      a: z.number(),\n      b: z.number()\n    })\n  }\n);\n\nconst webSearch = tool(\n  async (args) => {\n    return (\n      \"Here are the headcounts for each of the FAANG companies in 2024:\\n\" +\n      \"1. **Facebook (Meta)**: 67,317 employees.\\n\" +\n      \"2. **Apple**: 164,000 employees.\\n\" +\n      \"3. **Amazon**: 1,551,000 employees.\\n\" +\n      \"4. **Netflix**: 14,000 employees.\\n\" +\n      \"5. **Google (Alphabet)**: 181,269 employees.\"\n    );\n  },\n  {\n    name: \"web_search\",\n    description: \"Search the web for information.\",\n    schema: z.object({\n      query: z.string()\n    })\n  }\n);\n\nconst mathAgent = createReactAgent({\n  llm: model,\n  tools: [add, multiply],\n  name: \"math_expert\",\n  prompt: \"You are a math expert. Always use one tool at a time.\"\n});\n\nconst researchAgent = createReactAgent({\n  llm: model,\n  tools: [webSearch],\n  name: \"research_expert\",\n  prompt: \"You are a world class researcher with access to web search. Do not do any math.\"\n});\n\n// Create supervisor workflow\nconst workflow = createSupervisor({\n  agents: [researchAgent, mathAgent],\n  llm: model,\n  prompt: \n    \"You are a team supervisor managing a research expert and a math expert. \" +\n    \"For current events, use research_agent. \" +\n    \"For math problems, use math_agent.\"\n});\n\n// Compile and run\nconst app = workflow.compile();\nconst result = await app.invoke({\n  messages: [\n    {\n      role: \"user\",\n      content: \"what's the combined headcount of the FAANG companies in 2024??\"\n    }\n  ]\n});\n```\n\n----------------------------------------\n\nTITLE: Defining a Tool with LLM Integration\nDESCRIPTION: Defines a LangChain tool named 'get_items' that uses a ChatAnthropic model to generate descriptions of items found in a given place. It applies a custom tag ('tool_llm') to the LLM Runnable for event filtering during streaming.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-events-from-within-tools.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { z } from \"zod\";\nimport { tool } from \"@langchain/core/tools\";\nimport { ChatPromptTemplate } from \"@langchain/core/prompts\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\n\nconst model = new ChatAnthropic({\n  model: \"claude-3-5-sonnet-20240620\",\n  temperature: 0,\n});\n\nconst getItems = tool(\n  async (input, config) => {\n    const template = ChatPromptTemplate.fromMessages([\n      [\n        \"human\",\n        \"Can you tell me what kind of items i might find in the following place: '{place}'. \" +\n          \"List at least 3 such items separating them by a comma. And include a brief description of each item..\",\n      ],\n    ]);\n\n    const modelWithConfig = model.withConfig({\n      runName: \"Get Items LLM\",\n      tags: [\"tool_llm\"],\n    });\n\n    const chain = template.pipe(modelWithConfig);\n    const result = await chain.invoke(input, config);\n    return result.content;\n  },\n  {\n    name: \"get_items\",\n    description: \"Use this tool to look up which items are in the given place.\",\n    schema: z.object({\n      place: z.string().describe(\"The place to look up items for. E.g 'shelf'\"),\n    }),\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Wrapping Tools with ToolNode\nDESCRIPTION: This snippet wraps the defined tools within a ToolNode, which is part of LangGraph's prebuilt functionalities. The ToolNode is responsible for executing the tools (functions) when invoked by the language model within the graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-updates.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst toolNode = new ToolNode(tools);\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for LangGraph.js and OpenAI\nDESCRIPTION: Installs the necessary npm packages for working with LangGraph.js, OpenAI, and other required dependencies.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/delete-messages.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/openai @langchain/core zod uuid\n```\n\n----------------------------------------\n\nTITLE: Running Game Simulation with Initial State\nDESCRIPTION: Executes the game simulation with initial resource values and displays the evolving game state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst gameStream = await gameGraph.stream({\n  wood: 10,\n  food: 3,\n  gold: 10,\n  guardOnDuty: true,\n}, {\n  streamMode: \"values\",\n});\n\nfor await (const state of gameStream) {\n  console.log(\"Game state\", state);\n  console.log(\"-\".repeat(50));\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Child Graph with State Transformation\nDESCRIPTION: Defines a child graph in LangGraph that invokes a grandchild graph, applying transformations to bridge state channels between different graph layers. This involves transforming the state from child to grandchild keys and back. Dependencies include langgraph's StateGraph and Annotation classes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-transform-state.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph, START, Annotation } from \"@langchain/langgraph\";\n\nconst ChildAnnotation = Annotation.Root({\n    myChildKey: Annotation<string>,\n});\n\nconst callGrandchildGraph = async (state: typeof ChildAnnotation.State) => {\n    // NOTE: parent or grandchild keys won't be accessible here\n    // we're transforming the state from the child state channels (`myChildKey`)\n    // to the grandchild state channels (`myGrandchildKey`)\n    const grandchildGraphInput = { myGrandchildKey: state.myChildKey };\n    // we're transforming the state from the grandchild state channels (`myGrandchildKey`)\n    // back to the child state channels (`myChildKey`)\n    const grandchildGraphOutput = await grandchildGraph.invoke(grandchildGraphInput);\n    return {\n        myChildKey: grandchildGraphOutput.myGrandchildKey + \" today?\"\n    };\n};\n\nconst child = new StateGraph(ChildAnnotation)\n    // NOTE: we're passing a function here instead of just compiled graph (`childGraph`)\n    .addNode(\"child1\", callGrandchildGraph)\n    .addEdge(START, \"child1\");\n\nconst childGraph = child.compile();\n```\n\n----------------------------------------\n\nTITLE: Invoke the StateGraph\nDESCRIPTION: This snippet invokes the LangGraph with an initial state, triggering the execution of the graph's nodes and edges. The initial state includes an empty `foo` property.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/command.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nawait graph.invoke({ foo: \"\" });\n```\n\n----------------------------------------\n\nTITLE: Defining Agent State for LangGraphJS StateGraph\nDESCRIPTION: This code defines the agent state using Annotation from LangGraphJS, setting up a messages array that can be appended to by graph nodes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamically-returning-directly.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Memory in Supervisor Systems\nDESCRIPTION: Example showing how to add short-term and long-term memory capabilities to a supervisor multi-agent system using checkpointers and stores.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-supervisor/README.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MemorySaver, InMemoryStore } from \"@langchain/langgraph\";\n\nconst checkpointer = new MemorySaver()\nconst store = new InMemoryStore()\n\nconst model = ...\nconst researchAgent = ...\nconst mathAgent = ...\n\nconst workflow = createSupervisor({\n  agents: [researchAgent, mathAgent],\n  llm: model,\n  prompt: \"You are a team supervisor managing a research expert and a math expert.\",\n})\n\n// Compile with checkpointer/store\nconst app = workflow.compile({\n  checkpointer,\n  store\n})\n```\n\n----------------------------------------\n\nTITLE: Invoking Graph with Memory Recollection\nDESCRIPTION: Illustrates invoking a graph using a new thread ID but the same user ID, demonstrating how stored memories persist across different conversation threads, ensuring continuity in user-specific data management.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_15\n\nLANGUAGE: TypeScript\nCODE:\n```\n// Invoke the graph\nconst config = { configurable: { thread_id: \"2\", user_id: \"1\" } };\n\n// Let's say hi again\nconst stream = await graph.stream(\n  { messages: [{ role: \"user\", content: \"hi, tell me about my memories\" }] },\n  { ...config, streamMode: \"updates\" },\n);\n\nfor await (const update of stream) {\n  console.log(update);\n}\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for JavaScript LangGraph Application\nDESCRIPTION: Example directory structure for a JavaScript LangGraph application using package.json for dependencies. Shows the organization of source code, configuration files, and environment variables.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/application_structure.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmy-app/\n├── src # all project code lies within here\n│   ├── utils # optional utilities for your graph\n│   │   ├── tools.ts # tools for your graph\n│   │   ├── nodes.ts # node functions for you graph\n│   │   └── state.ts # state definition of your graph\n│   └── agent.ts # code for constructing your graph\n├── package.json # package dependencies\n├── .env # environment variables\n└── langgraph.json # configuration file for LangGraph\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Graph Invocation (JavaScript)\nDESCRIPTION: Asynchronously invoke and stream a RemoteGraph with messages in TypeScript\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// invoke the graph\nconst result = await remoteGraph.invoke({\n    messages: [{role: \"user\", content: \"what's the weather in sf\"}]\n})\n\n// stream outputs from the graph\nfor await (const chunk of await remoteGraph.stream({\n    messages: [{role: \"user\", content: \"what's the weather in la\"}]\n})):\n    console.log(chunk)\n```\n\n----------------------------------------\n\nTITLE: Resuming Workflow Invocation in LangGraphJS\nDESCRIPTION: This snippet shows how to resume a suspended workflow execution by passing a 'resume' command in a configuration object. It utilizes the Command class from LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Command } from \"@langchain/langgraph\";\n\nconst config = {\n  configurable: {\n    thread_id: \"some_thread_id\",\n  },\n};\n\nawait myWorkflow.invoke(new Command({ resume: someResumeValue }), config);\n```\n\n----------------------------------------\n\nTITLE: Querying LangGraph for User 1's remembered information\nDESCRIPTION: Runs the LangGraph again for User 1, asking for the previously stored name to demonstrate cross-thread memory persistence.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nconfig = { configurable: { thread_id: \"2\", userId: \"1\" } };\ninputMessage = { type: \"user\", content: \"what is my name?\" };\n\nfor await (const chunk of await graph.stream(\n  { messages: [inputMessage] },\n  { ...config, streamMode: \"values\" }\n)) {\n  console.log(chunk.messages[chunk.messages.length - 1]);\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Current Conversation State\nDESCRIPTION: Retrieving and displaying the current state of the conversation to check the message count before summarization is triggered.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nconst values = (await app.getState(config)).values\nconsole.log(values)\n```\n\n----------------------------------------\n\nTITLE: Visualizing the LangGraph Workflow with Mermaid\nDESCRIPTION: Generates and displays a visualization of the LangGraph workflow using Mermaid PNG rendering, showing the structure of the conversation simulation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraph = createSimulation().getGraph();\nconst image = await drawableGraph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Implementing a Simple Airline Customer Support Chat Bot with OpenAI\nDESCRIPTION: Defines a chat bot function that uses the OpenAI API to generate responses as an airline customer support agent. The function takes a list of messages and returns an AI response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatOpenAI } from '@langchain/openai'\nimport type { AIMessageChunk, BaseMessageLike } from \"@langchain/core/messages\";\n\nconst llm = new ChatOpenAI({ model: \"gpt-4o-mini\" });\n\nasync function myChatBot(messages: BaseMessageLike[]): Promise<AIMessageChunk> {\n  const systemMessage = {\n    role: 'system',\n    content: 'You are a customer support agent for an airline.',\n  };\n  const allMessages = [systemMessage, ...messages];\n  \n  const response = await llm.invoke(allMessages)\n  return response\n}\n\n// Test the chat bot\nconst response = await myChatBot([{ role: 'user', content: 'hi!' }]);\n\nconsole.log(response);\n```\n\n----------------------------------------\n\nTITLE: Initializing Schema and Planner with Zod\nDESCRIPTION: Sets up TypeScript schemas using Zod for structured output validation in report planning. Defines section schema and augments LLM with structured output capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\n\nconst sectionSchema = z.object({\n  name: z.string().describe(\"Name for this section of the report.\"),\n  description: z.string().describe(\n    \"Brief overview of the main topics and concepts to be covered in this section.\"\n  ),\n});\n\nconst sectionsSchema = z.object({\n  sections: z.array(sectionSchema).describe(\"Sections of the report.\"),\n});\n\nconst planner = llm.withStructuredOutput(sectionsSchema);\n```\n\n----------------------------------------\n\nTITLE: Creating a Simulated User for Chat Bot Testing\nDESCRIPTION: Implements a function that creates a simulated user with specific instructions to test the chat bot. The user is configured to persistently request a refund for a trip that happened five years ago.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { type Runnable } from \"@langchain/core/runnables\";\nimport { AIMessage } from \"@langchain/core/messages\";\nimport { ChatPromptTemplate } from \"@langchain/core/prompts\";\n\nasync function createSimulatedUser(): Promise<Runnable<{ messages: BaseMessageLike[] }, AIMessage>> {\n    const systemPromptTemplate = `You are a customer of an airline company. You are interacting with a user who is a customer support person \n    \n{instructions}\n\nIf you have nothing more to add to the conversation, you must respond only with a single word: \"FINISHED\"`;\n    \n    const prompt = ChatPromptTemplate.fromMessages([\n      ['system', systemPromptTemplate],\n      [\"placeholder\", '{messages}'],\n    ]);\n    \n    const instructions = `Your name is Harrison. You are trying to get a refund for the trip you took to Alaska.\nYou want them to give you ALL the money back. Be extremely persistent. This trip happened 5 years ago.`;\n\n    const partialPrompt = await prompt.partial({ instructions });\n    \n    const simulatedUser = partialPrompt.pipe(llm);\n    return simulatedUser;\n}\n\n// Test the simulated user\nconst messages = [{role: \"user\", content: 'Hi! How can I help you?'}];\nconst simulatedUser = await createSimulatedUser()\nconst simulatedUserResponse = await simulatedUser.invoke({ messages });\nconsole.log(simulatedUserResponse);\n```\n\n----------------------------------------\n\nTITLE: Using the LangGraphJS Agent\nDESCRIPTION: This snippet demonstrates how to use the compiled LangGraphJS agent by streaming its output for a given input message.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n\nconst inputs = {\n  messages: [new HumanMessage(\"what is the weather in sf\")],\n};\n\nfor await (const output of await app.stream(inputs)) {\n  console.log(output);\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Decision Making in Self-RAG Graph\nDESCRIPTION: This function decides whether to generate an answer or re-generate a question based on the relevance of filtered documents. It returns the next node to call in the graph flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nfunction decideToGenerate(state: typeof GraphState.State) {\n  console.log(\"---DECIDE TO GENERATE---\");\n\n  const filteredDocs = state.documents;\n  if (filteredDocs.length === 0) {\n    // All documents have been filtered checkRelevance\n    // We will re-generate a new query\n    console.log(\"---DECISION: TRANSFORM QUERY---\");\n    return \"transformQuery\";\n  }\n\n  // We have relevant documents, so generate answer\n  console.log(\"---DECISION: GENERATE---\");\n  return \"generate\";\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing and Invoking the Graph - Python\nDESCRIPTION: This Python snippet shows how to visualize the state graph using a drawing library and how to invoke the graph to observe its traversal between nodes 'a' and 'b', terminating after meeting the loop condition.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/recursion-limit.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraph = graph.getGraph();\nconst image = await drawableGraph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\nLANGUAGE: python\nCODE:\n```\nawait graph.invoke({ aggregate: [] });\n```\n\n----------------------------------------\n\nTITLE: Compiling Graph with InMemoryStore\nDESCRIPTION: Displays how to compile a graph using a MemorySaver as a checkpointer and an InMemoryStore for memory management, allowing for persistent data sharing across conversation threads. This setup ensures state-saving capabilities are integrated within the execution graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_11\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst checkpointer = new MemorySaver();\n\n// ... Define the graph ...\n\nconst graph = builder.compile({\n  checkpointer,\n  store: inMemoryStore\n});\n```\n\n----------------------------------------\n\nTITLE: Defining LangGraph State with Annotations in TypeScript\nDESCRIPTION: Creates a GraphState object using Annotations to define the structure and behavior of the shared state in the LangGraph. Includes fields for task, plan, steps, results, and the final result with appropriate reducers.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\n\nconst GraphState = Annotation.Root({\n  task: Annotation<string>({\n    reducer: (x, y) => (y ?? x),\n    default: () => \"\",\n  }),\n  planString: Annotation<string>({\n    reducer: (x, y) => (y ?? x),\n    default: () => \"\",\n  }),\n  steps: Annotation<string[][]>({\n    reducer: (x, y) => x.concat(y),\n    default: () => [],\n  }),\n  results: Annotation<Record<string, any>>({\n    reducer: (x, y) => ({ ...x, ...y }),\n    default: () => ({}),\n  }),\n  result: Annotation<string>({\n    reducer: (x, y) => (y ?? x),\n    default: () => \"\",\n  }),\n})\n```\n\n----------------------------------------\n\nTITLE: Deploying LangGraph with Custom Hono Server\nDESCRIPTION: A basic deployment example using Hono framework to set up a server endpoint for a LangGraph application. Suitable for simple applications with straightforward deployment needs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/langgraph_platform.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Hono } from \"hono\";\nimport { StateGraph } from \"@langchain/langgraph\";\n\nconst graph = new StateGraph(...);\n\nconst app = new Hono();\n\napp.get(\"/foo\", (c) => {\n  const res = await graph.invoke(...);\n  return c.json(res);\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Content with .streamEvents - Python\nDESCRIPTION: This snippet demonstrates how to consume custom events emitted from the graph's streamEvents method, processing the events as they occur in real-time.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-content.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconst eventStream = await graphWithDispatch.streamEvents(\\n  {\\n    messages: [{\\n      role: \"user\",\\n      content: \"What are you thinking about?\",\\n    }]\\n  },\\n  {\\n    version: \"v2\",\\n  },\\n);\\n\\nfor await (const { event, name, data } of eventStream) {\\n  if (event === \"on_custom_event\" && name === \"my_custom_event\") {\\n    console.log(`${data.chunk}|`);\\n  }\\n}\n```\n\n----------------------------------------\n\nTITLE: Using MemorySaver Checkpointer in LangGraph.js\nDESCRIPTION: Demonstrates how to use the MemorySaver checkpointer to store, load, and list checkpoints in a LangGraph.js application. It includes setting up configurations, creating a checkpointer, and performing operations like put, get, and list.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint/README.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MemorySaver } from \"@langchain/langgraph-checkpoint\";\n\nconst writeConfig = {\n  configurable: {\n    thread_id: \"1\",\n    checkpoint_ns: \"\"\n  }\n};\nconst readConfig = {\n  configurable: {\n    thread_id: \"1\"\n  }\n};\n\nconst checkpointer = new MemorySaver();\nconst checkpoint = {\n  v: 1,\n  ts: \"2024-07-31T20:14:19.804150+00:00\",\n  id: \"1ef4f797-8335-6428-8001-8a1503f9b875\",\n  channel_values: {\n    my_key: \"meow\",\n    node: \"node\"\n  },\n  channel_versions: {\n    __start__: 2,\n    my_key: 3,\n    \"start:node\": 3,\n    node: 3\n  },\n  versions_seen: {\n    __input__: {},\n    __start__: {\n      __start__: 1\n    },\n    node: {\n      \"start:node\": 2\n    }\n  },\n  pending_sends: [],\n}\n\n// store checkpoint\nawait checkpointer.put(writeConfig, checkpoint, {}, {})\n\n// load checkpoint\nawait checkpointer.get(readConfig)\n\n// list checkpoints\nfor await (const checkpoint of checkpointer.list(readConfig)) {\n  console.log(checkpoint);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Typed Routing Function in Python for LangGraph\nDESCRIPTION: Shows how to define a routing function with explicit typing using Python's Literal type. This approach helps in specifying the exact nodes that the routing function can map to, improving graph visualization accuracy.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/langgraph_studio.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef routing_function(state: GraphState) -> Literal[\"node_b\",\"node_c\"]:\n    if state['some_condition'] == True:\n        return \"node_b\"\n    else:\n        return \"node_c\"\n```\n\n----------------------------------------\n\nTITLE: Testing Research Agent Node in Isolation\nDESCRIPTION: An example invocation of the research node with a human message about US primaries in 2024, demonstrating how the agent node processes input and generates output within the state management system.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/multi_agent_collaboration.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Example invocation\nconst researchResults = await researchNode({\n  messages: [new HumanMessage(\"Research the US primaries in 2024\")],\n  sender: \"User\",\n});\n\nresearchResults;\n```\n\n----------------------------------------\n\nTITLE: Resolving Concurrent Update Issues with Reducer in TypeScript\nDESCRIPTION: This code snippet shows how to define a state annotation with a reducer that combines multiple values, allowing for safe concurrent updates in parallel execution contexts.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst StateAnnotation = Annotation.Root({\n  someKey: Annotation<string[]>({\n    default: () => [],\n    reducer: (a, b) => a.concat(b),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory Store with Semantic Search - Python\nDESCRIPTION: This snippet demonstrates how to create an in-memory store with semantic search capabilities by configuring an index with OpenAI embeddings.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { OpenAIEmbeddings } from \"@langchain/openai\";\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\nconst embeddings = new OpenAIEmbeddings({\n  model: \"text-embedding-3-small\",\n});\n\nconst store = new InMemoryStore({\n  index: {\n    embeddings,\n    dims: 1536,\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Adding Edges and Conditional Edges for Support Nodes\nDESCRIPTION: This code snippet adds a regular edge from `technical_support` to `__end__` and a conditional edge from `billing_support`. The conditional edge checks for `REFUND` in the state and routes execution to `handle_refund` if present, otherwise it routes to `__end__`. An edge is also added from `handle_refund` to `__end__`.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nbuilder = builder\n  .addEdge(\"technical_support\", \"__end__\")\n  .addConditionalEdges(\"billing_support\", async (state) => {\n    if (state.nextRepresentative.includes(\"REFUND\")) {\n      return \"refund\";\n    } else {\n      return \"__end__\";\n    }\n  }, {\n    refund: \"handle_refund\",\n    __end__: \"__end__\",\n  })\n  .addEdge(\"handle_refund\", \"__end__\");\n\nconsole.log(\"Added edges!\");\n```\n\n----------------------------------------\n\nTITLE: Testing the Execution Agent\nDESCRIPTION: Example showing how to invoke the execution agent with a sample query about the US Open winner. The agent responds to the human message using its reasoning capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n\nawait agentExecutor.invoke({\n  messages: [new HumanMessage(\"who is the winner of the us open\")],\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Agent Logic with Command in TypeScript\nDESCRIPTION: This code snippet defines an agent function utilizing the Command object for routing within a multi-agent system. It determines the next agent to call based on conditions and returns state updates via a Command object. Dependencies include the LangChain libraries for handling commands and state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst agent = async (state) => {\n  // the condition for routing/halting can be anything\n  // e.g. LLM tool call / structured output, etc.\n  const goto = getNextAgent(...); // \"agent\" / \"another_agent\"\n  if (goto) {\n    return new Command({\n      goto,\n      update: {\n        myStateKey: \"my_state_value\",\n      }\n    });\n  }\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Channel-Checkpointer Interface in TypeScript\nDESCRIPTION: Defines the base channel class with checkpointing capabilities and includes a utility function for creating checkpoints from channel collections. Implements core functionality for state management and serialization.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/langgraph-architecture-spec.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nabstract class BaseChannel<ValueType, UpdateType, CheckpointType> {\n  abstract checkpoint(): CheckpointType | undefined;\n  abstract fromCheckpoint(checkpoint?: CheckpointType): this;\n\n  abstract update(values: UpdateType[]): boolean;\n  abstract get(): ValueType;\n  consume(): boolean;\n}\n\nfunction createCheckpoint(\n  channels: Record<string, BaseChannel>,\n  includeEphemeral: boolean = false\n): Record<string, unknown> {\n  return Object.fromEntries(\n    Object.entries(channels)\n      .filter(([_, c]) => includeEphemeral || !c.isEphemeral)\n      .map(([k, c]) => [k, c.checkpoint()])\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Updating StateGraph State and Resuming Execution in TypeScript\nDESCRIPTION: This snippet shows how to update the StateGraph's state to bypass the interrupt condition and resume graph execution from the breakpoint.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamic_breakpoints.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nawait graph.updateState(config2, { input: \"short\" });\n\nconst updatedStream = await graph.stream(null, config2);\n\nfor await (const event of updatedStream) {\n  console.log(event);\n}\n\nconst state4 = await graph.getState(config2);\nconsole.log(state4.next);\nconsole.log(state4.values);\n```\n\n----------------------------------------\n\nTITLE: Grading Generation Against Question in Self-RAG Graph\nDESCRIPTION: This function assesses whether the generated answer is useful in resolving the input question. It uses a structured output from the language model to produce a binary score.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nasync function generateGenerationVQuestionGrade(\n  state: typeof GraphState.State\n): Promise<Partial<typeof GraphState.State>> {\n  console.log(\"---GENERATE GENERATION vs QUESTION GRADE---\");\n\n  const llmWithTool = model.withStructuredOutput(\n    z\n      .object({\n        binaryScore: z\n          .enum([\"yes\", \"no\"])\n          .describe(\"Relevance score 'yes' or 'no'\"),\n      })\n      .describe(\n        \"Grade the relevance of the retrieved documents to the question. Either 'yes' or 'no'.\"\n      ),\n    {\n      name: \"grade\",\n    }\n  );\n\n  const prompt = ChatPromptTemplate.fromTemplate(\n    `You are a grader assessing whether an answer is useful to resolve a question.\n  Here is the answer:\n  \\n ------- \\n\n  {generation} \n  \\n ------- \\n\n  Here is the question: {question}\n  Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question.`\n  );\n\n  const chain = prompt.pipe(llmWithTool);\n\n  const score = await chain.invoke({\n    question: state.question,\n    generation: state.generation,\n  });\n\n  return {\n    generationVQuestionGrade: score.binaryScore,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Agent with Long-term Memory - Python\nDESCRIPTION: This snippet illustrates the assembly of a React agent equipped with tools for memory storage and mechanisms for recalling memory based on the context of user messages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\nconst agent = createReactAgent({\n  llm: new ChatOpenAI({ model: \"gpt-4o-mini\" }),\n  tools: [upsertMemoryTool],\n  prompt: addMemories,\n  store: store\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing state with MessagesAnnotation - TypeScript\nDESCRIPTION: This snippet shows how to initialize a graph using the prebuilt `MessagesAnnotation`, which simplifies managing a list of messages and setting up the graph. It highlights the use of annotations to define the state structure.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MessagesAnnotation, StateGraph } from \"@langchain/langgraph\";\n\nconst graph = new StateGraph(MessagesAnnotation)\n  .addNode(...)\n  ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Entrypoint with Tool Call Review\nDESCRIPTION: Creates an agent entrypoint that incorporates human-in-the-loop tool call review, with support for interrupting, validating, and executing tool calls\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport {\n  MemorySaver,\n  addMessages,\n  entrypoint,\n  getPreviousState,\n} from \"@langchain/langgraph\";\n\nconst checkpointer = new MemorySaver();\n\nconst agent = entrypoint({\n  checkpointer,\n  name: \"agent\",\n}, async (messages: BaseMessageLike[]) => {\n  const previous = getPreviousState<BaseMessageLike[]>() ?? [];\n  let currentMessages = addMessages(previous, messages);\n  let llmResponse = await callModel(currentMessages);\n  while (true) {\n    if (!llmResponse.tool_calls?.length) {\n      break;\n    }\n    const toolResults: ToolMessage[] = [];\n    const toolCalls: ToolCall[] = [];\n    \n    for (let i = 0; i < llmResponse.tool_calls.length; i++) {\n      const review = await reviewToolCall(llmResponse.tool_calls[i]);\n      if (review instanceof ToolMessage) {\n        toolResults.push(review);\n      } else {\n        toolCalls.push(review);\n        if (review !== llmResponse.tool_calls[i]) {\n          llmResponse.tool_calls[i] = review;\n        }\n      }\n    }\n    const remainingToolResults = await Promise.all(\n      toolCalls.map((toolCall) => callTool(toolCall))\n    );\n    \n    currentMessages = addMessages(\n      currentMessages,\n      [llmResponse, ...toolResults, ...remainingToolResults]\n    );\n\n    llmResponse = await callModel(currentMessages);\n  }\n  currentMessages = addMessages(currentMessages, llmResponse);\n  return entrypoint.final({\n    value: llmResponse,\n    save: currentMessages\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Checking Next Node in Subgraph State in JavaScript\nDESCRIPTION: This code checks the 'next' parameter of the subgraph state to confirm that the correct state snapshot has been retrieved.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: javascript\nCODE:\n```\nsubgraphStateBeforeModelNode.next;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Latest State Snapshot using Graph State in TypeScript\nDESCRIPTION: The code snippet demonstrates how to retrieve the latest state snapshot of the graph by calling `getState` with the appropriate configuration. It uses the specified `thread_id` to target the correct thread for state retrieval.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Get the latest state snapshot\nconst config = { configurable: { thread_id: \"1\" } };\nconst state = await graph.getState(config);\n```\n\n----------------------------------------\n\nTITLE: Creating a Mock Weather Tool with Input Restrictions\nDESCRIPTION: Implementation of a mock weather tool using Zod for schema validation. The tool intentionally has hidden restrictions on input queries to simulate real-world error cases.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling-errors.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport { z } from \"zod\";\nimport { tool } from \"@langchain/core/tools\";\n\nconst getWeather = tool(async ({ location }) => {\n  if (location === \"SAN FRANCISCO\") {\n    return \"It's 60 degrees and foggy\";\n  } else if (location.toLowerCase() === \"san francisco\") {\n    throw new Error(\"Input queries must be all capitals\");\n  } else {\n    throw new Error(\"Invalid input.\");\n  }\n}, {\n  name: \"get_weather\",\n  description: \"Call to get the current weather\",\n  schema: z.object({\n    location: z.string(),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Model and Tools for the Graph in Python-like Syntax\nDESCRIPTION: This code defines a tool within the LangGraph.js framework for retrieving weather information based on city input. The tool utilizes the `@langchain/core/tools` module and `zod` for schema validation. The function `getWeather` can be extended to other cities, but currently supports 'sf' and 'nyc' only.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-postgres.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { z } from \"zod\";\nimport { tool } from \"@langchain/core/tools\";\n\nconst getWeather = tool(async (input: { city: \"sf\" | \"nyc\" }) => {\n  if (input.city === \"nyc\") {\n    return \"It might be cloudy in nyc\";\n  } else if (input.city === \"sf\") {\n    return \"It's always sunny in sf\";\n  } else {\n    throw new Error(\"Unknown city\");\n  }\n}, {\n  name: \"get_weather\",\n  description: \"Use this to get weather information.\",\n  schema: z.object({\n    city: z.enum([\"sf\", \"nyc\"])\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Orchestrator-Worker Pattern with Functional API\nDESCRIPTION: Shows an alternative implementation using LangGraph's Functional API (beta). Demonstrates a more streamlined approach with task definitions and workflow composition.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\nimport { task, entrypoint } from \"@langchain/langgraph\";\n\nconst sectionSchema = z.object({\n  name: z.string().describe(\"Name for this section of the report.\"),\n  description: z.string().describe(\n    \"Brief overview of the main topics and concepts to be covered in this section.\"\n  ),\n});\n\nconst sectionsSchema = z.object({\n  sections: z.array(sectionSchema).describe(\"Sections of the report.\"),\n});\n\nconst planner = llm.withStructuredOutput(sectionsSchema);\n\nconst orchestrator = task(\"orchestrator\", async (topic: string) => {\n  const reportSections = await planner.invoke([\n    { role: \"system\", content: \"Generate a plan for the report.\" },\n    { role: \"user\", content: `Here is the report topic: ${topic}` },\n  ]);\n\n  return reportSections.sections;\n});\n\nconst llmCall = task(\"sectionWriter\", async (section: z.infer<typeof sectionSchema>) => {\n  const result = await llm.invoke([\n    {\n      role: \"system\",\n      content: \"Write a report section.\",\n    },\n    {\n      role: \"user\",\n      content: `Here is the section name: ${section.name} and description: ${section.description}`,\n    },\n  ]);\n\n  return result.content;\n});\n\nconst synthesizer = task(\"synthesizer\", async (completedSections: string[]) => {\n  return completedSections.join(\"\\n\\n---\\n\\n\");\n});\n\nconst workflow = entrypoint(\n  \"orchestratorWorker\",\n  async (topic: string) => {\n    const sections = await orchestrator(topic);\n    const completedSections = await Promise.all(\n      sections.map((section) => llmCall(section))\n    );\n    return synthesizer(completedSections);\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Visualizing the Conditional Branching Graph\nDESCRIPTION: Code to render the conditional branching graph as a PNG image for visualization.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst representation2 = graph2.getGraph();\nconst image2 = await representation2.drawMermaidPng();\nconst arrayBuffer2 = await image2.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer2));\n```\n\n----------------------------------------\n\nTITLE: Stream Processing Implementation\nDESCRIPTION: Demonstrates streaming response handling for the haiku generator with error visibility.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling-errors.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst stream = await app2.stream(\n  { messages: [{ role: \"user\", content: \"Write me an incredible haiku about water.\" }] },\n  { recursionLimit: 10 },\n)\n\nfor await (const chunk of stream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Running LangGraph with cross-thread persistence for User 1\nDESCRIPTION: Executes the LangGraph for User 1, demonstrating how to set user-specific configuration and stream the model's response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nlet config = { configurable: { thread_id: \"1\", userId: \"1\" } };\nlet inputMessage = { type: \"user\", content: \"Hi! Remember: my name is Bob\" };\n\nfor await (const chunk of await graph.stream(\n  { messages: [inputMessage] },\n  { ...config, streamMode: \"values\" }\n)) {\n  console.log(chunk.messages[chunk.messages.length - 1]);\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Inner Graph State in TypeScript\nDESCRIPTION: This code updates the state of the inner graph by changing the 'city' parameter to 'la'. It uses the updateState method with the inner graph's configuration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { StateSnapshot } from \"@langchain/langgraph\";\n\nawait graph.updateState((outerGraphState.tasks[0].state as StateSnapshot).config, { city: \"la\" });\n```\n\n----------------------------------------\n\nTITLE: Implementing Versioning System for Pregel Execution in TypeScript\nDESCRIPTION: The versioning system that tracks changes to determine which nodes to execute, including the Versions interface and the function to determine if a node should execute based on versions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-execution-model.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\ninterface Versions {\n  // Current superstep number\n  superstep: number;\n  \n  // Version number for each channel\n  channelVersions: Record<string, number>;\n  \n  // Last seen version by each node\n  nodeLastSeenVersions: Record<string, Record<string, number>>;\n  \n  // Tasks waiting to be executed\n  pendingPushes: PendingPushTask[];\n}\n\n// Determine if a node should execute based on versions\nfunction _shouldExecuteNode(\n  node: string,\n  channels: Record<string, BaseChannel>,\n  readEdges: ReadEdges,\n  versions: Versions\n): boolean {\n  const nodeEdges = readEdges.get(node) || [];\n  \n  for (const channelName of nodeEdges) {\n    const channel = channels[channelName];\n    if (!channel.isEmpty()) {\n      const lastSeenVersion = versions.nodeLastSeenVersions[node]?.[channelName] || 0;\n      const currentVersion = versions.channelVersions[channelName];\n      \n      // If node hasn't seen the latest version, it should execute\n      if (lastSeenVersion < currentVersion) {\n        return true;\n      }\n    }\n  }\n  \n  return false;\n}\n```\n\n----------------------------------------\n\nTITLE: Interacting with LangGraph Agent\nDESCRIPTION: This code snippet demonstrates how to interact with the LangGraph agent, showing that it stops before calling a tool as specified in the graph compilation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Thread\nconst config = { configurable: { thread_id: \"3\" }, streamMode: \"values\" as const };\n\nfor await (const event of await app.stream({\n    messages: [{ role: \"human\", content: \"search for the weather in sf now\" }]\n}, config)) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Resuming Execution After Breakpoint\nDESCRIPTION: Shows how to resume graph execution after a breakpoint by streaming with the same thread ID, including subgraph information in the output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst resumedStream = await graph.stream(null, {\n  configurable: { thread_id: \"3\" },\n  streamMode: \"values\",\n  subgraphs: true,\n});\n\nfor await (const update of resumedStream) {\n  console.log(update);\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Tavily Search Tool for ReWOO Agent\nDESCRIPTION: Initializes the TavilySearchResults tool to be used as the \"Google\" search capability in the ReWOO agent implementation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n\nconst search = new TavilySearchResults();\n```\n\n----------------------------------------\n\nTITLE: Wrapping Tools in ToolNode in Python\nDESCRIPTION: This snippet wraps the defined tools in a ToolNode, allowing them to be integrated into the state graph for function calls.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst toolNode = new ToolNode<typeof GraphState.State>(tools);\n```\n\n----------------------------------------\n\nTITLE: Increasing Recursion Limit in LangGraph StateGraph Invocation (TypeScript)\nDESCRIPTION: This code snippet shows how to increase the recursion limit when invoking a StateGraph. By passing a higher 'recursionLimit' value in the config object, you can allow more iterations for complex graphs that may naturally require more steps.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nawait graph.invoke({...}, { recursionLimit: 100 });\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent Stream with Weather Query\nDESCRIPTION: Sets up an agent configuration with a thread ID and processes a user message asking about weather. The stream results are then processed iteratively.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nconst config = {\n  configurable: {\n    thread_id: \"1\"\n  }\n};\n\nconst userMessage = {\n  role: \"user\",\n  content: \"What's the weather in san francisco?\"\n};\nconsole.log(userMessage);\n\nconst stream = await agent.stream([userMessage], config);\n\nfor await (const step of stream) {\n  printStep(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Editing Pattern for Human-in-the-loop in LangGraphJS\nDESCRIPTION: Demonstrates the editing pattern where a human can review and modify the agent's state before execution continues. This creates a forked checkpoint with the edited state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Compile our graph with a checkpointer and a breakpoint before the step to review\nconst graph = builder.compile({ checkpointer, interruptBefore: [\"node_2\"] });\n\n// Run the graph up to the breakpoint\nfor await (const event of await graph.stream(inputs, threadConfig)) {\n    console.log(event);\n}\n    \n// Review the state, decide to edit it, and create a forked checkpoint with the new state\nawait graph.updateState(threadConfig, { state: \"new state\" });\n\n// Continue the graph execution from the forked checkpoint\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Chat Model\nDESCRIPTION: This code initializes a ChatOpenAI model, specifying \"gpt-4o\" as the model to be used. This model will be used for generating responses and interacting with the defined tools.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-updates.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({ model: \"gpt-4o\" });\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dependencies for LangGraph\nDESCRIPTION: This snippet provides bash commands to install required packages and set API keys for using LangGraph with Anthropic, also including optional setup for LangSmith tracing to provide enhanced observability. These dependencies and configurations are prerequisites for executing the LangGraph flow effectively.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport ANTHROPIC_API_KEY=your-api-key\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\nexport LANGCHAIN_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Creating a ToolNode for LangGraphJS\nDESCRIPTION: This code creates a ToolNode instance using the previously defined tools, which will be used in the StateGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst toolNode = new ToolNode<typeof AgentState.State>(tools);\n```\n\n----------------------------------------\n\nTITLE: Retrieving Graph State History\nDESCRIPTION: Retrieves and iterates through the history of graph states, identifying a specific state for replay based on message count.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nlet toReplay;\nconst states = await graphWithInterrupt.getStateHistory(config);\nfor await (const state of states) {\n  console.log(state);\n  console.log(\"--\");\n  if (state.values?.messages?.length === 2) {\n    toReplay = state;\n  }\n}\nif (!toReplay) {\n  throw new Error(\"No state to replay\");\n}\n```\n\n----------------------------------------\n\nTITLE: Binding Tools to ChatOpenAI Model\nDESCRIPTION: This code binds the previously defined tools to the ChatOpenAI model, enabling tool usage in conversations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst boundModel = model.bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: Visualizing Tool-Integrated State Graph with TSLab\nDESCRIPTION: Uses TSLab to render a LangGraph agent workflow as a visual representation using the Mermaid diagram, facilitating evaluation and review of the tool-assisted state graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/breakpoints.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraph = app.getGraph();\nconst image = await drawableGraph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Creating a Dynamic Structured Search Tool\nDESCRIPTION: This code defines a dynamic structured tool for search functionality using Zod for schema validation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { DynamicStructuredTool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst searchTool = new DynamicStructuredTool({\n  name: \"search\",\n  description:\n    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n  func: async ({}: { query: string }) => {\n    // This is a placeholder for the actual implementation\n    return \"Cold, with a low of 13 ℃\";\n  },\n});\n\nawait searchTool.invoke({ query: \"What's the weather like?\" });\n\nconst tools = [searchTool];\n```\n\n----------------------------------------\n\nTITLE: Reading User Memories\nDESCRIPTION: This snippet demonstrates fetching stored memories from the InMemoryStore for a specific namespace. It illustrates the 'search' method usage to retrieve all memory entries for a given user, detailing the format of returned memory objects which include timestamps and unique keys.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_10\n\nLANGUAGE: TypeScript\nCODE:\n```\nconst memories = await inMemoryStore.search(namespaceForMemory);\nconsole.log(memories.at(-1));\n\n/*\n  {\n    'value': {'food_preference': 'I like pizza'},\n    'key': '07e0caf4-1631-47b7-b15f-65515d4c1843',\n    'namespace': ['1', 'memories'],\n    'created_at': '2024-10-02T17:22:31.590602+00:00',\n    'updated_at': '2024-10-02T17:22:31.590605+00:00'\n  }\n*/\n```\n\n----------------------------------------\n\nTITLE: Compiling the Graph with MemorySaver in TypeScript\nDESCRIPTION: This snippet shows how to compile a parent graph in LangGraph using an in-memory checkpointer. It sets up a checkpointer that will be automatically propagated to child subgraphs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-persistence.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MemorySaver } from \"@langchain/langgraph-checkpoint\";\n\nconst checkpointer = new MemorySaver();\n\n// You must only pass checkpointer when compiling the parent graph.\n// LangGraph will automatically propagate the checkpointer to the child subgraphs.\n\nconst graph = builder.compile({\n  checkpointer: checkpointer\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up an Agent with Breakpoints and Tool Integration\nDESCRIPTION: Builds a simple ReAct-style agent with LangGraph, embedding breakpoints for user intervention. It includes setting up nodes, models, toolcalling, and executing conditional edges within LangChain, using JavaScript.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/breakpoints.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n// Set up the tool\nimport { ChatAnthropic } from \"@langchain/anthropic\";\nimport { tool } from \"@langchain/core/tools\";\nimport { StateGraph, START, END } from \"@langchain/langgraph\";\nimport { MemorySaver, Annotation } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport { BaseMessage, AIMessage } from \"@langchain/core/messages\";\nimport { z } from \"zod\";\n\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n\nconst search = tool((_) => {\n    return \"It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\";\n}, {\n    name: \"search\",\n    description: \"Call to surf the web.\",\n    schema: z.string(),\n})\n\nconst tools = [search]\nconst toolNode = new ToolNode<typeof AgentState.State>(tools)\n\n// Set up the model\nconst model = new ChatAnthropic({ model: \"claude-3-5-sonnet-20240620\" })\nconst modelWithTools = model.bindTools(tools)\n\n\n// Define nodes and conditional edges\n\n// Define the function that determines whether to continue or not\nfunction shouldContinue(state: typeof AgentState.State): \"action\" | typeof END {\n    const lastMessage = state.messages[state.messages.length - 1];\n    // If there is no function call, then we finish\n    if (lastMessage && !(lastMessage as AIEmail).tool_calls?.length) {\n        return END;\n    }\n    // Otherwise if there is, we continue\n    return \"action\";\n}\n\n// Define the function that calls the model\nasync function callModel(state: typeof AgentState.State): Promise<Partial<typeof AgentState.State>> {\n    const messages = state.messages;\n    const response = await modelWithTools.invoke(messages);\n    // We return an object with a messages property, because this will get added to the existing list\n    return { messages: [response] };\n}\n\n// Define a new graph\nconst workflow = new StateGraph(AgentState)\n    // Define the two nodes we will cycle between\n    .addNode(\"agent\", callModel)\n    .addNode(\"action\", toolNode)\n    // We now add a conditional edge\n    .addConditionalEdges(\n        // First, we define the start node. We use `agent`.\n        // This means these are the edges taken after the `agent` node is called.\n        \"agent\",\n        // Next, we pass in the function that will determine which node is called next.\n        shouldContinue\n    )\n    // We now add a normal edge from `action` to `agent`.\n    // This means that after `action` is called, `agent` node is called next.\n    .addEdge(\"action\", \"agent\")\n    // Set the entrypoint as `agent`\n    // This means that this node is the first one called\n    .addEdge(START, \"agent\");\n\n\n// Setup memory\nconst memory = new MemorySaver();\n\n// Finally, we compile it!\n// This compiles it into a LangChain Runnable,\n// meaning you can use it as you would any other runnable\nconst app = workflow.compile({\n    checkpointer: memory,\n    interruptBefore: [\"action\"]\n});\n```\n\n----------------------------------------\n\nTITLE: Calling Other Entrypoints in LangGraph TypeScript\nDESCRIPTION: Demonstrates how to call other entrypoints from within an entrypoint or task, with automatic checkpointer inheritance from the parent entrypoint.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_25\n\nLANGUAGE: typescript\nCODE:\n```\nconst someOtherWorkflow = entrypoint(\n  { name: \"someOtherWorkflow\" }, // Will automatically use the checkpointer from the parent entrypoint\n  async (inputs: { value: number }) => {\n    return inputs.value;\n  }\n);\n\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (inputs: Record<string, any>) => {\n    const value = await someOtherWorkflow.invoke([{ value: 1 }]);\n    return value;\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Skipping Node with Dynamic Breakpoint in TypeScript\nDESCRIPTION: Shows how to skip a node with a dynamic breakpoint by performing a graph update with the node name, effectively bypassing the breakpoint condition.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/breakpoints.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// This update will skip the node `myNode` altogether\nawait graph.updateState(null, threadConfig, \"myNode\");\n\nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Test Channel for Channel Reading/Writing in TypeScript\nDESCRIPTION: Defines a simple TestChannel class for use in testing channel reading and writing operations. This implementation provides basic functionality for updating and retrieving channel values.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-testing-plan.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nclass TestChannel {\n  constructor(private value: any = null) {}\n  update(values: any[]) {\n    if (values.length > 0) {\n      this.value = values[values.length - 1];\n      return true;\n    }\n    return false;\n  }\n  get() { return this.value; }\n}\n```\n\n----------------------------------------\n\nTITLE: Preference Verification in LangGraph.js\nDESCRIPTION: Shows how to verify stored preferences across different conversation threads by creating a new thread ID while maintaining user context.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/pass-run-time-values-to-tools.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninputs = { messages: [new HumanMessage({ content: \"What're my favorite pets and what did I say when I told you about them?\" })] };\nconfig = {\n  configurable: {\n    thread_id: \"2\", // New thread ID, so the conversation history isn't present.\n    userId: \"a-user\"\n  }\n};\n\nmessages = (await graph.invoke(inputs, config)).messages;\n\nprintMessages(messages);\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring a State Graph with Breakpoints\nDESCRIPTION: Creates a state graph in JavaScript using LangGraph to handle different steps with defined breakpoints. It demonstrates setting up nodes, edges, and checkpoint storage for process interruption and resuming capability.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/breakpoints.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph, START, END, Annotation } from \"@langchain/langgraph\";\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst GraphState = Annotation.Root({\n  input: Annotation<string>\n});\n\nconst step1 = (state: typeof GraphState.State) => {\n  console.log(\"---Step 1---\");\n  return state;\n}\n\nconst step2 = (state: typeof GraphState.State) => {\n  console.log(\"---Step 2---\");\n  return state;\n}\n\nconst step3 = (state: typeof GraphState.State) => {\n  console.log(\"---Step 3---\");\n  return state;\n}\n\n\nconst builder = new StateGraph(GraphState)\n  .addNode(\"step1\", step1)\n  .addNode(\"step2\", step2)\n  .addNode(\"step3\", step3)\n  .addEdge(START, \"step1\")\n  .addEdge(\"step1\", \"step2\")\n  .addEdge(\"step2\", \"step3\")\n  .addEdge(\"step3\", END);\n\n\n// Set up memory\nconst graphStateMemory = new MemorySaver()\n\nconst graph = builder.compile({\n  checkpointer: graphStateMemory,\n  interruptBefore: [\"step3\"]\n});\n```\n\n----------------------------------------\n\nTITLE: Visualizing StateGraph with Mermaid in TypeScript\nDESCRIPTION: This code snippet shows how to generate and display a Mermaid diagram of the defined StateGraph using tslab for visualization.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamic_breakpoints.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst representation = graph.getGraph();\nconst image = await representation.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Configuring langgraph.json for Custom Routes\nDESCRIPTION: JSON configuration for langgraph.json file to include the custom app and other necessary settings for the LangGraph application.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/http/custom_routes.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"graphs\": {\n    \"agent\": \"./src/agent/graph.ts:graph\"\n  },\n  \"env\": \".env\",\n  \"http\": {\n    \"app\": \"./src/agent/app.ts:app\"\n  }\n  // Other configuration options like auth, store, etc.\n}\n```\n\n----------------------------------------\n\nTITLE: Workflow Completion Output After Human Review\nDESCRIPTION: This snippet shows the console output after a workflow is resumed with human input. It displays the final result object containing both the essay and the approval status from the human reviewer.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n{ workflow: { essay: 'An essay about topic: cat', isApproved: true } }\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LangGraphJS ReAct Agent\nDESCRIPTION: This snippet shows the command to install the necessary packages for building a ReAct agent with LangGraphJS, including @langchain/langgraph, @langchain/openai, and @langchain/core.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamically-returning-directly.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/openai @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Printing Messages in a Conversation - Python\nDESCRIPTION: This snippet defines a helper function to nicely format and print messages in the conversation, determining the type of each message and outputting relevant information.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport {\n  BaseMessage,\n  isSystemMessage,\n  isAIMessage,\n  isHumanMessage,\n  isToolMessage,\n  AIMessage,\n  HumanMessage,\n  ToolMessage,\n  SystemMessage,\n} from \"@langchain/core/messages\";\n\nfunction printMessages(messages: BaseMessage[]) {\n  for (const message of messages) {\n    if (isSystemMessage(message)) {\n      const systemMessage = message as SystemMessage;\n      console.log(`System: ${systemMessage.content}`);\n    } else if (isHumanMessage(message)) {\n      const humanMessage = message as HumanMessage;\n      console.log(`User: ${humanMessage.content}`);\n    } else if (isAIMessage(message)) {\n      const aiMessage = message as AIMessage;\n      if (aiMessage.content) {\n        console.log(`Assistant: ${aiMessage.content}`);\n      }\n      if (aiMessage.tool_calls) {\n        for (const toolCall of aiMessage.tool_calls) {\n          console.log(`\\t${toolCall.name}(${JSON.stringify(toolCall.args)})`);\n        }\n      }\n    } else if (isToolMessage(message)) {\n      const toolMessage = message as ToolMessage;\n      console.log(\n        `\\t\\t${toolMessage.name} -> ${JSON.stringify(toolMessage.content)}\"\n      );\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Next Execution Steps\nDESCRIPTION: Checking the 'next' property of the checkpoint to see if there are any pending execution steps. This is empty when the graph has already terminated by transitioning to the END state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\ncheckpoint.next;\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key and LangSmith Tracing for LangGraphJS\nDESCRIPTION: This code snippet demonstrates how to set the OpenAI API key and optionally enable LangSmith tracing for enhanced observability in the LangGraphJS project.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamically-returning-directly.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\"\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"Direct Return: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Creating Tools for Travel and Hotel Recommendations in LangChain\nDESCRIPTION: Defines tools in LangChain for getting travel and hotel recommendations. Dependencies include '@langchain/core/tools' and 'zod'. No parameters are needed for getTravelRecommendations, but the getHotelRecommendations tool requires a location input. These responses are randomized from predefined lists.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\n// Tool for getting travel recommendations\nconst getTravelRecommendations = tool(async () => {\n  const destinations = [\"aruba\", \"turks and caicos\"];\n  return destinations[Math.floor(Math.random() * destinations.length)];\n}, {\n  name: \"getTravelRecommendations\",\n  description: \"Get recommendation for travel destinations\",\n  schema: z.object({}),\n});\n\n// Tool for getting hotel recommendations\nconst getHotelRecommendations = tool(async (input: { location: \"aruba\" | \"turks and caicos\" }) => {\n  const recommendations = {\n    \"aruba\": [\n      \"The Ritz-Carlton, Aruba (Palm Beach)\",\n      \"Bucuti & Tara Beach Resort (Eagle Beach)\"\n    ],\n    \"turks and caicos\": [\"Grace Bay Club\", \"COMO Parrot Cay\"]\n  };\n  return recommendations[input.location];\n}, {\n  name: \"getHotelRecommendations\",\n  description: \"Get hotel recommendations for a given destination.\",\n  schema: z.object({\n    location: z.enum([\"aruba\", \"turks and caicos\"])\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Stream for Tool Call Feedback Example in LangGraph.js\nDESCRIPTION: Sets up a new stream with a different thread ID to demonstrate providing feedback to a tool call. This initializes the graph with a user query and streams the resulting messages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\ninputs = { messages: [{ role: \"user\", content: \"what's the weather in SF?\" }] };\nconfig = { configurable: { thread_id: \"4\" }, streamMode: \"values\" as const };\n\nstream = await graph.stream(inputs, config);\n\nfor await (const event of stream) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Dynamic Structured Tool for Search\nDESCRIPTION: This snippet demonstrates how to create a placeholder search tool using DynamicStructuredTool from LangChain Core.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { DynamicStructuredTool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst searchTool = new DynamicStructuredTool({\n  name: \"search\",\n  description: \"Call to surf the web.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n  func: async ({}: { query: string }) => {\n    // This is a placeholder, but don't tell the LLM that...\n    return \"Try again in a few seconds! Checking with the weathermen... Call be again next.\";\n  },\n});\n\nconst tools = [searchTool];\n```\n\n----------------------------------------\n\nTITLE: Markdown Table of LangGraph Adopters\nDESCRIPTION: A structured table containing company information, industry classification, use cases, and reference links for organizations using LangGraph in their operations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/adopters.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Company | Industry | Use case | Reference |\n| --- | --- | --- | --- |\n| [AirTop](https://www.airtop.ai/) | Software & Technology (GenAI Native) | Browser automation for AI agents | [Case study, 2024](https://blog.langchain.dev/customers-airtop/) |\n| [AppFolio](https://www.appfolio.com/) | Real Estate | Copilot for domain-specific task | [Case study, 2024](https://blog.langchain.dev/customers-appfolio/) |\n| [Athena Intelligence](https://www.athenaintel.com/) | Software & Technology (GenAI Native) | Research & summarization | [Case study, 2024](https://blog.langchain.dev/customers-athena-intelligence/) |\n[...]\n```\n\n----------------------------------------\n\nTITLE: Running and Interrupting LangGraph Execution\nDESCRIPTION: This code snippet demonstrates how to run the LangGraph until the first interruption, which occurs before step 2 as specified in the graph compilation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Input\nconst initialInput = { input: \"hello world\" };\n\n// Thread\nconst graphStateConfig = { configurable: { thread_id: \"1\" }, streamMode: \"values\" as const };\n\n// Run the graph until the first interruption\nfor await (const event of await graph.stream(initialInput, graphStateConfig)) {\n    console.log(`--- ${event.input} ---`);\n}\n\n// Will log when the graph is interrupted, after step 2.\nconsole.log(\"--- GRAPH INTERRUPTED ---\");\n```\n\n----------------------------------------\n\nTITLE: Testing the Planning Component\nDESCRIPTION: Demonstrates invoking the planner with a sample question about the Australian Open winner's hometown. The planner will generate a sequence of steps to answer this query.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nawait planner.invoke({\n  objective: \"what is the hometown of the current Australia open winner?\",\n});\n```\n\n----------------------------------------\n\nTITLE: Resuming LangGraph.js Workflow After Error\nDESCRIPTION: Shows how to resume a previously failed workflow execution using the same configuration. The checkpoint system allows skipping previously completed tasks.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_29\n\nLANGUAGE: typescript\nCODE:\n```\nawait main.invoke(null, config);\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LangGraph Agent\nDESCRIPTION: Installs the necessary npm packages to build a LangGraph agent, including LangChain components, Anthropic integration, and core modules.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/agent_executor/base.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/community @langchain/anthropic @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Initializing a ToolNode for LangGraph\nDESCRIPTION: Creation of a ToolNode instance that will execute tools when invoked by the LLM in the graph. This connects the defined tools to the graph's execution flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst toolNode = new ToolNode(tools);\n```\n\n----------------------------------------\n\nTITLE: Streaming Results from Graph with Function-Invoked Subgraph\nDESCRIPTION: Code to stream results from a graph that contains a node function invoking a subgraph, with subgraph streaming enabled.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst graphWithFunctionStream = await graphWithFunction.stream({ foo: \"foo\" }, { subgraphs: true });\nfor await (const chunk of graphWithFunctionStream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Multiple Inputs Pattern in LangGraph TypeScript Entrypoint\nDESCRIPTION: Shows how to pass multiple inputs to an entrypoint function using an object, as input is restricted to the first argument of the function.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_22\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (inputs: { value: number; anotherValue: number }) => {\n    const value = inputs.value;\n    const anotherValue = inputs.anotherValue;\n    ...\n  }\n);\n\nawait myWorkflow.invoke([{ value: 1, anotherValue: 2 }]);\n```\n\n----------------------------------------\n\nTITLE: Testing Graph with Non-Weather Query in LangGraph\nDESCRIPTION: Example of streaming execution of the graph with a generic greeting input to demonstrate how non-weather queries are processed by the normal LLM node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = { configurable: { thread_id: \"1\" } };\n\nconst inputs = { messages: [{ role: \"user\", content: \"hi!\" }] };\n\nconst stream = await graph.stream(inputs, { ...config, streamMode: \"updates\" });\n\nfor await (const update of stream) {\n  console.log(update);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables in JavaScript\nDESCRIPTION: This snippet sets up several environment variables for tracing in LangSmith and managing API keys necessary for interacting with LLMs. It includes settings for enabling tracing and specifying the project name.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/configuration.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\";\n// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"Configuration: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Implementing Checkpointing System for Pregel in TypeScript\nDESCRIPTION: The checkpointing system that enables persistence and time-travel capabilities, including functions to create checkpoints after each superstep and restore from checkpoints.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-execution-model.md#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// Create checkpoint after each superstep\nasync function _putCheckpoint(\n  channels: Record<string, BaseChannel>,\n  checkpointer: BaseCheckpointSaver,\n  config: RunnableConfig,\n  metadata: CheckpointMetadata\n): Promise<string | undefined> {\n  // Collect channel states\n  const checkpoint = Object.fromEntries(\n    Object.entries(channels)\n      .filter(([_, c]) => !c.isEphemeral)\n      .map(([k, c]) => [k, c.checkpoint()])\n  );\n  \n  // Save checkpoint\n  return checkpointer.put(config, checkpoint, metadata);\n}\n\n// Restore from checkpoint\nasync function _restoreFromCheckpoint(\n  channels: Record<string, BaseChannel>,\n  store: BaseStore,\n  checkpointId: string\n): Promise<void> {\n  const checkpoint = await store.get(checkpointId);\n  \n  // Restore each channel\n  for (const [name, state] of Object.entries(checkpoint.checkpoint)) {\n    channels[name]?.fromCheckpoint(state);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Authentication in TypeScript for LangGraph\nDESCRIPTION: This snippet demonstrates how to create a custom authentication handler using the Auth class from LangGraph SDK. It verifies a token from the request headers and applies access control rules based on the authenticated user.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/auth/custom_auth.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Auth, HTTPException } from \"@langchain/langgraph-sdk/auth\";\n\nexport const auth = new Auth()\n  .authenticate(async (request: Request) => {\n    const authorization = request.headers.get(\"authorization\");\n    const token = authorization?.split(\" \").at(-1);\n\n    try {\n      const userId = (await verifyToken(token)) as string;\n      return userId;\n    } catch (error) {\n      throw new HTTPException(401, { message: \"Invalid token\", cause: error });\n    }\n  })\n  .on(\"*\", ({ value, user }) => {\n    // Add owner to the resource metadata\n    if (\"metadata\" in value) {\n      value.metadata ??= {};\n      value.metadata.owner = user.identity;\n    }\n\n    // Filter the resource by the owner\n    return { owner: user.identity };\n  })\n  .on(\"store\", ({ user, value }) => {\n    if (value.namespace != null) {\n      // Assuming you organize information in store like (user_id, resource_type, resource_id)\n      const [userId, resourceType, resourceId] = value.namespace;\n      if (userId !== user.identity) {\n        throw new HTTPException(403, { message: \"Not authorized\" });\n      }\n    }\n  });\n```\n\n----------------------------------------\n\nTITLE: Running StateGraph with Short Input in TypeScript\nDESCRIPTION: This snippet demonstrates running the StateGraph with an input that doesn't trigger the interrupt condition. It uses a stream to process the graph execution and logs the events.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamic_breakpoints.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst initialInput = { input: \"hello\" };\nconst config = {\n  configurable: {\n    thread_id: \"1\",\n  },\n  streamMode: \"values\" as const,\n};\n\nconst stream = await graph.stream(initialInput, config);\n\nfor await (const event of stream) {\n  console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Tool Call Arguments in Agent State\nDESCRIPTION: This Python code snippet demonstrates how to retrieve the current state and modify tool call arguments for the ReAct agent. It specifically updates the location argument of the last tool call to correct an unknown location error.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-human-in-the-loop.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n// First, lets get the current state\nconst currentState = await agent.getState(config);\n\n// Let's now get the last message in the state\n// This is the one with the tool calls that we want to update\nlet lastMessage = currentState.values.messages[currentState.values.messages.length - 1]\n\n// Let's now update the args for that tool call\nlastMessage.tool_calls[0].args = { location: \"San Francisco\" }\n\n// Let's now call `updateState` to pass in this message in the `messages` key\n// This will get treated as any other update to the state\n// It will get passed to the reducer function for the `messages` key\n// That reducer function will use the ID of the message to update it\n// It's important that it has the right ID! Otherwise it would get appended\n// as a new message\nawait agent.updateState(config, { messages: lastMessage });\n```\n\n----------------------------------------\n\nTITLE: Initializing RetryPolicy in LangGraphJS\nDESCRIPTION: This code snippet demonstrates how to instantiate a `RetryPolicy` object with default parameters in LangGraphJS.  It imports the `RetryPolicy` type from the `@langchain/langgraph` module. The `retryPolicy` object can then be customized with specific configurations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/node-retry-policies.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RetryPolicy } from \"@langchain/langgraph\"\n\nconst retryPolicy: RetryPolicy = {};\n```\n\n----------------------------------------\n\nTITLE: Incorrect config handling for nested Runnables\nDESCRIPTION: This example shows a graph with a nested Runnable function that doesn't pass the config object correctly. As a result, streaming events from the nested function won't work properly in web environments without async_hooks.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/use-in-web-environments.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// Import from \"@langchain/langgraph/web\"\nimport {\n  END,\n  START,\n  StateGraph,\n  Annotation,\n} from \"@langchain/langgraph/web\";\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { RunnableLambda } from \"@langchain/core/runnables\";\nimport { type StreamEvent } from \"@langchain/core/tracers/log_stream\";\n\nconst GraphState2 = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n\nconst nodeFn2 = async (_state: typeof GraphState2.State) => {\n  // Note that we do not pass any `config` through here\n  const nestedFn = RunnableLambda.from(async (input: string) => {\n    return new HumanMessage(`Hello from ${input}!`);\n  }).withConfig({ runName: \"nested\" });\n  const responseMessage = await nestedFn.invoke(\"a nested function\");\n  return { messages: [responseMessage] };\n};\n\n// Define a new graph\nconst workflow2 = new StateGraph(GraphState2)\n  .addNode(\"node\", nodeFn2)\n  .addEdge(START, \"node\")\n  .addEdge(\"node\", END);\n\nconst app2 = workflow2.compile({});\n\n// Stream intermediate steps from the graph\nconst eventStream2 = app2.streamEvents(\n  { messages: [] },\n  { version: \"v2\" },\n  { includeNames: [\"nested\"] },\n);\n\nconst events2: StreamEvent[] = [];\nfor await (const event of eventStream2) {\n  console.log(event);\n  events2.push(event);\n}\n\nconsole.log(`Received ${events2.length} events from the nested function`);\n```\n\n----------------------------------------\n\nTITLE: Resuming LangGraph Agent Execution\nDESCRIPTION: This code snippet shows how to resume the LangGraph agent execution after updating the state, demonstrating the continuation of the workflow with the modified tool call.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nfor await (const event of await app.stream(null, config)) {\n    console.log(event)\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    if (recentMsg._getType() === \"tool\") {\n        console.log({\n            name: recentMsg.name,\n            content: recentMsg.content\n        })\n    } else if (recentMsg._getType() === \"ai\") {\n        console.log(recentMsg.content)\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Checking State Before Continuing Execution in LangGraph.js\nDESCRIPTION: Retrieves and logs the current state of the graph after providing feedback, showing that a new breakpoint has been reached with a revised tool call awaiting approval.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\nstate = await graph.getState(config);\nconsole.log(state.next);\n```\n\n----------------------------------------\n\nTITLE: Handling Scenarios Without Human Review in LangGraph\nDESCRIPTION: This Python code demonstrates how to execute a LangGraph stream and handle scenarios where no human review is required. It assumes prior setup of a graph instance (`graph`) and involves streaming events from the graph with configured input data, printing output messages when no tool calls trigger the review node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nlet inputs = { messages: [{ role: \"user\", content: \"hi!\" }] };\nlet config = { configurable: { thread_id: \"1\" }, streamMode: \"values\" as const };\n\nlet stream = await graph.stream(inputs, config);\n\nfor await (const event of stream) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n\nlet state = await graph.getState(config);\nconsole.log(state.next);\n```\n\n----------------------------------------\n\nTITLE: Executing LangGraphJS ReAct Agent with Direct Return Option\nDESCRIPTION: This snippet demonstrates how to use the compiled LangGraphJS ReAct agent, including a function to pretty-print messages and examples of running the agent with and without direct return.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamically-returning-directly.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage, isAIMessage } from \"@langchain/core/messages\";\n\nconst prettyPrint = (message: BaseMessage) => {\n  let txt = `[${message._getType()}]: ${message.content}`;\n  if (\n    isAIMessage(message) && (message as AIMessage)?.tool_calls?.length || 0 > 0\n  ) {\n    const tool_calls = (message as AIMessage)?.tool_calls\n      ?.map((tc) => `- ${tc.name}(${JSON.stringify(tc.args)})`)\n      .join(\"\\n\");\n    txt += ` \\nTools: \\n${tool_calls}`;\n  }\n  console.log(txt);\n};\n\nconst inputs = { messages: [new HumanMessage(\"what is the weather in sf\")] };\nfor await (const output of await app.stream(inputs, { streamMode: \"values\" })) {\n  const lastMessage = output.messages[output.messages.length - 1];\n  prettyPrint(lastMessage);\n  console.log(\"-----\\n\");\n}\n\nconst inputs2 = {\n  messages: [\n    new HumanMessage(\n      \"what is the weather in sf? return this result directly by setting return_direct = True\",\n    ),\n  ],\n};\nfor await (\n  const output of await app.stream(inputs2, { streamMode: \"values\" })\n) {\n  const lastMessage = output.messages[output.messages.length - 1];\n  prettyPrint(lastMessage);\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Pregel-Graph Interface in TypeScript\nDESCRIPTION: Defines the high-level Graph API built on top of the Pregel system, including workflow structure definition and compilation into executable graphs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/langgraph-architecture-spec.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nclass Graph {\n  nodes: Record<string, NodeSpecType>;\n  edges: Set<[string, string]>;\n  branches: Record<string, Record<string, Branch>>;\n\n  compile(): CompiledGraph;\n}\n\nclass CompiledGraph extends Pregel {\n  builder: Graph;\n\n  attachNode(key: string, node: NodeSpec): void;\n  attachEdge(start: string, end: string): void;\n  attachBranch(start: string, name: string, branch: Branch): void;\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables\nDESCRIPTION: Set the required API keys for OpenAI, Tavily, and optionally LangSmith tracing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\nexport TAVILY_API_KEY=\nexport LANGCHAIN_TRACING_V2=true\nexport LANGCHAIN_API_KEY=\n```\n\n----------------------------------------\n\nTITLE: Creating Test Fixtures for Execution Engine in TypeScript\nDESCRIPTION: Defines test fixtures for the execution engine, including a TestCheckpointer class for in-memory checkpointing and a function to create a test PregelLoop instance with controllable state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-testing-plan.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nclass TestCheckpointer {\n  checkpoints = new Map();\n  async put(config, checkpoint, metadata) {\n    const id = `cp-${Date.now()}`;\n    this.checkpoints.set(id, { config, checkpoint, metadata });\n    return id;\n  }\n  async get(id) {\n    return this.checkpoints.get(id);\n  }\n}\n\nconst createTestLoop = () => {\n  const channels = {\n    input: new TestChannel(\"input value\"),\n    output: new TestChannel(),\n  };\n\n  const versions = {\n    superstep: 0,\n    channelVersions: { input: 0, output: 0 },\n    nodeLastSeenVersions: {},\n    pendingPushes: [],\n  };\n\n  return new PregelLoop(channels, versions, new TestCheckpointer());\n};\n```\n\n----------------------------------------\n\nTITLE: Streaming Grandparent Graph Updates in LangGraph.js\nDESCRIPTION: This snippet demonstrates how to stream updates from the grandparent graph using LangGraph.js. It configures the graph for streaming mode with subgraph support, sends a message to initiate processing, and logs the updates as they are received.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nconst grandparentConfig = {\n  configurable: { thread_id: \"123\" },\n};\n\nconst grandparentGraphStream = await grandparentGraph.stream({\n  messages: [{\n    role: \"user\",\n    content: \"what's the weather in SF\"\n  }],\n}, {\n  ...grandparentConfig,\n  streamMode: \"updates\",\n  subgraphs: true\n});\n\nfor await (const update of grandparentGraphStream) {\n  console.log(update);\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Events from the Graph\nDESCRIPTION: Streams events from the compiled agent graph, filtering for events with the 'tool_llm' tag. It logs the type and content of each chunk received, and stores the final event.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-events-from-within-tools.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nlet finalEvent;\n\nfor await (const event of agent.streamEvents(\n  {\n    messages: [\n      [\n        \"human\",\n        \"what items are on the shelf? You should call the get_items tool.\",\n      ],\n    ],\n  },\n  {\n    version: \"v2\",\n  },\n  {\n    includeTags: [\"tool_llm\"],\n  }\n)) {\n  if (\"chunk\" in event.data) {\n    console.dir({\n      type: event.data.chunk._getType(),\n      content: event.data.chunk.content,\n    })\n  }\n  finalEvent = event;\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Graph State in Python\nDESCRIPTION: This snippet imports necessary modules and creates the GraphState using LangChain's Annotation to manage state and messages for the agent's processing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { Annotation, messagesStateReducer } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst GraphState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: messagesStateReducer,\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Full-stack LangGraph Application\nDESCRIPTION: Command to quickly set up a full-stack LangGraph application using the create-agent-chat-app CLI tool.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-agent-chat-app@latest\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Tool for Search in Python\nDESCRIPTION: This snippet defines a search tool using LangChain's tool function, which includes a placeholder response and input schema defined with zod to validate the query input.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst searchTool = tool((_) => {\n  // This is a placeholder, but don't tell the LLM that...\n  return \"67 degrees. Cloudy with a chance of rain.\";\n}, {\n  name: \"search\",\n  description: \"Call to surf the web.\",\n  schema: z.object({\n    query: z.string().describe(\"The query to use in your search.\"),\n  }),\n});\n\nconst tools = [searchTool];\n```\n\n----------------------------------------\n\nTITLE: Invoking Grandchild Graph\nDESCRIPTION: This snippet shows how to invoke a previously defined grandchild graph and pass an initial state value. It demonstrates asynchronous invocation using the await keyword.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-transform-state.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nawait grandchildGraph.invoke({ myGrandchildKey: \"hi Bob\" })\n```\n\n----------------------------------------\n\nTITLE: Workflow Execution Output for Essay Generation and Interrupt\nDESCRIPTION: This snippet shows the console output when executing the essay workflow, displaying the generated essay and the interrupt data that would be shown to a client application requesting human input.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n{ write_essay: 'An essay about topic: cat' }\n{ __interrupt__: [{\n  value: { essay: 'An essay about topic: cat', action: 'Please approve/reject the essay' },\n  resumable: true,\n  ns: ['workflow:f7b8508b-21c0-8b4c-5958-4e8de74d2684'],\n  when: 'during'\n}] }\n```\n\n----------------------------------------\n\nTITLE: Accepting a Tool Call with Command\nDESCRIPTION: Creates a Command object to accept a tool call by specifying 'continue' as the action. This allows the previously generated tool call to proceed without modification.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Command } from \"@langchain/langgraph\";\n\n// highlight-next-line\nconst humanInput = new Command({\n  // highlight-next-line\n  resume: {\n    // highlight-next-line\n    action: \"continue\",\n    // highlight-next-line\n  },\n  // highlight-next-line\n});\n\nconst resumedStream = await agent.stream(humanInput, config)\n\nfor await (const step of resumedStream) {\n  printStep(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining State Annotation in LangGraphJS - TypeScript\nDESCRIPTION: This snippet demonstrates how to create a root annotation for the state that consolidates messages using a reducer.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport type { BaseMessageLike } from \"@langchain/core/messages\";\n\nconst StateAnnotation = Annotation.Root({\n  messages: Annotation<BaseMessageLike[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Testing API with Python SDK (Sync)\nDESCRIPTION: Python code to test the LangGraph API using the synchronous version of the Python SDK. It sends a message to the assistant and streams the response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/langgraph-platform/local-server.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph_sdk import get_sync_client\n\nclient = get_sync_client(url=\"http://localhost:2024\")\n\nfor chunk in client.runs.stream(\n    None,  # Threadless run\n    \"agent\", # Name of assistant. Defined in langgraph.json.\n    input={\n        \"messages\": [{\n            \"role\": \"human\",\n            \"content\": \"What is LangGraph?\",\n        }],\n    },\n    stream_mode=\"updates\",\n):\n    print(f\"Receiving new event of type: {chunk.event}...\")\n    print(chunk.data)\n    print(\"\\n\\n\")\n```\n\n----------------------------------------\n\nTITLE: Permission-Based Access Pattern - TypeScript\nDESCRIPTION: This snippet demonstrates a permission-based access pattern that checks user permissions before allowing actions on threads. It ensures secure access based on defined permissions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/auth.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Auth, HTTPException } from \"@langchain/langgraph-sdk/auth\";\n\nexport const auth = new Auth()\n  .authenticate(async (request: Request) => ({\n    identity: \"user-123\",\n    permissions: [\"threads:write\", \"threads:read\"],\n  }))\n  .on(\"threads:create\", ({ value, user, permissions }) => {\n    if (!permissions.includes(\"threads:write\")) {\n      throw new HTTPException(403, { message: \"Unauthorized\" });\n    }\n    if (\"metadata\" in value) {\n      value.metadata ??= {};\n      value.metadata.owner = user.identity;\n    }\n    return { owner: user.identity };\n  })\n  .on(\"threads:read\", ({ user, permissions }) => {\n    if (!permissions.includes(\"threads:read\") && !permissions.includes(\"threads:write\")) {\n      throw new HTTPException(403, { message: \"Unauthorized\" });\n    }\n    return { owner: user.identity };\n  });\n```\n\n----------------------------------------\n\nTITLE: Resuming Agent Execution in LangGraph After Interruption\nDESCRIPTION: Provides a method to continue the execution of an agent flow in LangGraph after a manual interruption. It highlights how to handle null inputs to resume process without affecting previous workflow stages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/breakpoints.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfor await (const event of await app.stream(null, config)) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages - Bash\nDESCRIPTION: This snippet demonstrates how to install necessary packages for using the LangChain and OpenAI APIs using yarn. The packages include langgraph, openai, and core which are essential to utilize the functionalities of the ReAct agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-system-prompt.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/openai @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Basic ReAct Agent Implementation\nDESCRIPTION: Initial implementation of a ReAct Agent using LangGraph with Tavily search integration and OpenAI.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/quickstart.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n// agent.ts\n\n// IMPORTANT - Add your API keys here. Be careful not to publish them.\nprocess.env.OPENAI_API_KEY = \"sk-...\";\nprocess.env.TAVILY_API_KEY = \"tvly-...\";\n\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { MemorySaver } from \"@langchain/langgraph\";\nimport { HumanMessage } from \"@langchain/core/messages\";\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\n// Define the tools for the agent to use\nconst agentTools = [new TavilySearchResults({ maxResults: 3 })];\nconst agentModel = new ChatOpenAI({ temperature: 0 });\n\n// Initialize memory to persist state between graph runs\nconst agentCheckpointer = new MemorySaver();\nconst agent = createReactAgent({\n  llm: agentModel,\n  tools: agentTools,\n  checkpointSaver: agentCheckpointer,\n});\n\n// Now it's time to use!\nconst agentFinalState = await agent.invoke(\n  { messages: [new HumanMessage(\"what is the current weather in sf\")] },\n  { configurable: { thread_id: \"42\" } },\n);\n\nconsole.log(\n  agentFinalState.messages[agentFinalState.messages.length - 1].content,\n);\n\nconst agentNextState = await agent.invoke(\n  { messages: [new HumanMessage(\"what about ny\")] },\n  { configurable: { thread_id: \"42\" } },\n);\n\nconsole.log(\n  agentNextState.messages[agentNextState.messages.length - 1].content,\n);\n```\n\n----------------------------------------\n\nTITLE: Loading Chat Model in JavaScript\nDESCRIPTION: Initializes a chat model from LangGraph using OpenAI's GPT-4o as a backbone. This model is configured to process message inputs and integrate tool calling capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-values.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({ model: \"gpt-4o\" });\n```\n\n----------------------------------------\n\nTITLE: Specifying a Retry Policy for a Task\nDESCRIPTION: This code snippet illustrates how to define a retry policy for a task in LangGraphJS using the task function, allowing control over the number of attempts before failure.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nconst slowComputation = task(\n  {\n    name: \"slowComputation\",\n    // only attempt to run this task once before giving up\n    retry: { maxAttempts: 1 },\n  },\n  async (inputValue: any) => {\n    // A long-running operation that may fail\n    return result;\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Defining the State Graph in Python\nDESCRIPTION: This snippet constructs the state graph for the agent, adding nodes for the agent and tools, along with defining the flow of execution through conditional edges.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph } from \"@langchain/langgraph\";\n\nconst workflow = new StateGraph(GraphState)\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  .addEdge(\"__start__\", \"agent\")\n  .addConditionalEdges(\n    \"agent\",\n    route,\n    {\n      __end__: \"__end__\",\n      tools: \"tools\",\n    }\n  )\n  .addEdge(\"tools\", \"agent\");\n\nconst app = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraphJS dependencies\nDESCRIPTION: This command installs the necessary LangGraphJS packages, including @langchain/langgraph, @langchain/openai, and @langchain/core, using yarn. These packages provide the core functionality for building and running LangGraph applications, integrating with OpenAI models, and defining custom tools.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/create-react-agent.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"yarn add @langchain/langgraph @langchain/openai @langchain/core\"\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph CLI\nDESCRIPTION: Command to install the LangGraph CLI tool, which is required for building the Docker image.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/deploy-self-hosted.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install -U langgraph-cli\n```\n\n----------------------------------------\n\nTITLE: Implementing Prompt Chaining with Functional API\nDESCRIPTION: Implementation of the same joke enhancement workflow using LangGraph's Functional API (beta). Demonstrates a more linear, function-based approach to creating sequential LLM processing with conditional branching.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { task, entrypoint } from \"@langchain/langgraph\";\n\n// Tasks\n\n// First LLM call to generate initial joke\nconst generateJoke = task(\"generateJoke\", async (topic: string) => {\n  const msg = await llm.invoke(`Write a short joke about ${topic}`);\n  return msg.content;\n});\n\n// Gate function to check if the joke has a punchline\nfunction checkPunchline(joke: string) {\n  // Simple check - does the joke contain \"?\" or \"!\"\n  if (joke.includes(\"?\") || joke.includes(\"!\")) {\n    return \"Pass\";\n  }\n  return \"Fail\";\n}\n\n  // Second LLM call to improve the joke\nconst improveJoke = task(\"improveJoke\", async (joke: string) => {\n  const msg = await llm.invoke(\n    `Make this joke funnier by adding wordplay: ${joke}`\n  );\n  return msg.content;\n});\n\n// Third LLM call for final polish\nconst polishJoke = task(\"polishJoke\", async (joke: string) => {\n  const msg = await llm.invoke(\n    `Add a surprising twist to this joke: ${joke}`\n  );\n  return msg.content;\n});\n\nconst workflow = entrypoint(\n  \"jokeMaker\",\n  async (topic: string) => {\n    const originalJoke = await generateJoke(topic);\n    if (checkPunchline(originalJoke) === \"Pass\") {\n      return originalJoke;\n    }\n    const improvedJoke = await improveJoke(originalJoke);\n    const polishedJoke = await polishJoke(improvedJoke);\n    return polishedJoke;\n  }\n);\n\nconst stream = await workflow.stream(\"cats\", {\n  streamMode: \"updates\",\n});\n\nfor await (const step of stream) {\n  console.log(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Adding nodes to a StateGraph - TypeScript\nDESCRIPTION: This code snippet demonstrates how to define nodes for the graph using the `addNode` method. It also shows how to access node parameters and use them within the graph's logic.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RunnableConfig } from \"@langchain/core/runnables\";\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\nconst GraphAnnotation = Annotation.Root({\n  input: Annotation<string>,\n  results: Annotation<string>,\n});\n\nconst myNode = (state: typeof GraphAnnotation.State, config?: RunnableConfig) => {\n  console.log(\"In node: \", config.configurable?.user_id);\n  return {\n    results: `Hello, ${state.input}!`\n  };\n};\n\nconst myOtherNode = (state: typeof GraphAnnotation.State) => {\n  return state;\n};\n\nconst builder = new StateGraph(GraphAnnotation)\n  .addNode(\"myNode\", myNode)\n  .addNode(\"myOtherNode\", myOtherNode)\n  ...\n```\n\n----------------------------------------\n\nTITLE: Binding Tools to the Model - TypeScript\nDESCRIPTION: This snippet shows how to bind the previously defined tools to the chat model to make them available for calling.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst boundModel = model.bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: RemoteGraph as Subgraph (JavaScript)\nDESCRIPTION: Use a RemoteGraph as a subgraph within another graph in TypeScript\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { MessagesAnnotation, StateGraph, START } from \"@langchain/langgraph\";\nimport { RemoteGraph } from \"@langchain/langgraph/remote\";\n\nconst url = `<DEPLOYMENT_URL>`;\nconst graphName = \"agent\";\nconst remoteGraph = new RemoteGraph({ graphId: graphName, url });\n\n// define parent graph and add remote graph directly as a node\nconst graph = new StateGraph(MessagesAnnotation)\n  .addNode(\"child\", remoteGraph)\n  .addEdge(\"START\", \"child\")\n  .compile()\n\n// invoke the parent graph\nconst result = await graph.invoke({\n  messages: [{ role: \"user\", content: \"what's the weather in sf\" }]\n});\nconsole.log(result);\n```\n\n----------------------------------------\n\nTITLE: Continuing Graph Execution After Dynamic Breakpoint in LangGraphJS\nDESCRIPTION: Demonstrates how to resume graph execution after hitting a dynamic breakpoint. The code shows that without state changes, the breakpoint will trigger again when execution resumes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/v0-human-in-the-loop.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Attempt to continue the graph execution with no change to state after we hit the dynamic breakpoint \nfor await (const event of await graph.stream(null, threadConfig)) {\n    console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Subgraph as Function with State Transformation in TypeScript\nDESCRIPTION: Shows how to create a subgraph with a completely different schema from the parent graph. The approach transforms the parent state to the subgraph state before invocation and transforms the results back to the parent state afterward.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n});\n\nconst SubgraphStateAnnotation = Annotation.Root({\n  // note that none of these keys are shared with the parent graph state\n  bar: Annotation<string>,\n  baz: Annotation<string>,\n});\n\n// Define subgraph\nconst subgraphNode = async (state: typeof SubgraphStateAnnotation.State) => {\n  return { bar: state.bar + \"baz\" };\n};\n\nconst subgraph = new StateGraph(SubgraphStateAnnotation)\n  .addNode(\"subgraph\", subgraphNode);\n  ...\n  .compile();\n\n// Define parent graph\nconst subgraphWrapperNode = async (state: typeof StateAnnotation.State) => {\n  // transform the state to the subgraph state\n  const response = await subgraph.invoke({\n    bar: state.foo,\n  });\n  // transform response back to the parent state\n  return {\n    foo: response.bar,\n  };\n}\n\nconst parentGraph = new StateGraph(StateAnnotation)\n  .addNode(\"subgraph\", subgraphWrapperNode)\n  ...\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Binding Tools to the Model in Python\nDESCRIPTION: This snippet binds the previously defined tools to the model, creating a cohesive structure to manage response generation based on the tools available.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nconst Response = z.object({\n  temperature: z.number().describe(\"the temperature\"),\n  other_notes: z.string().describe(\"any other notes about the weather\"),\n});\n\nconst finalResponseTool = tool(async () => \"mocked value\", {\n  name: \"Response\",\n  description: \"Always respond to the user using this tool.\",\n  schema: Response\n})\n\nconst boundModel = model.bindTools([\n  ...tools,\n  finalResponseTool\n]);\n```\n\n----------------------------------------\n\nTITLE: Connecting to LangGraph with Authentication using Python RemoteGraph\nDESCRIPTION: This Python code shows how to use RemoteGraph to connect to a LangGraph deployment with custom authentication headers.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/auth/custom_auth.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.pregel.remote import RemoteGraph\n\nmy_token = \"your-token\" # In practice, you would generate a signed token with your auth provider\nremote_graph = RemoteGraph(\n    \"agent\",\n    url=\"http://localhost:2024\",\n    headers={\"Authorization\": f\"Bearer {my_token}\"}\n)\nthreads = await remote_graph.ainvoke(...)\n```\n\n----------------------------------------\n\nTITLE: Changing User Config in LangGraphJS Execution\nDESCRIPTION: The code shows how to adjust runtime parameters to change the user context in a LangGraphJS graph execution, affecting the retrieved data and model interaction. The modification of the user ID allows for dynamic testing of user-specific processing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/configuration.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst config2 = {\n  configurable: {\n    model: \"openai\",\n    user: \"user2\",\n  },\n};\nconst inputs2 = {\n  messages: [new HumanMessage(\"Could you remind me of my email??\")],\n};\nfor await (\n  const { messages } of await graph.stream(inputs2, {\n    ...config2,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Required Packages with Yarn in Bash\nDESCRIPTION: This snippet demonstrates how to install the necessary packages for the LangChain project using Yarn. It emphasizes the need for specific LangChain packages to enable multi-agent functionalities. The command should be executed in a terminal with Yarn installed.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/openai @langchain/core zod\n```\n\n----------------------------------------\n\nTITLE: Updating State and Control Flow with Command in TypeScript\nDESCRIPTION: The 'Command' object combines state updates and node routing into a single operation in LangGraphJS. It uses a state annotation for type safety and updates states while deciding the next node. The snippet demonstrates the use of 'Command' with and without dynamic behavior, which is similar to conditional edges. Prerequisites include 'LangGraphJS' library and basic TypeScript knowledge.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation, Command } from \"@langchain/langgraph\";\n\nconst StateAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n});\n\nconst myNode = (state: typeof StateAnnotation.State) => {\n  return new Command({\n    // state update\n    update: {\n      foo: \"bar\",\n    },\n    // control flow\n    goto: \"myOtherNode\",\n  });\n};\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst myNode = async (state: typeof StateAnnotation.State) => {\n  if (state.foo === \"bar\") {\n    return new Command({\n      update: {\n        foo: \"baz\",\n      },\n      goto: \"myOtherNode\",\n    });\n  }\n  // ...\n};\n```\n\n----------------------------------------\n\nTITLE: Streaming Graph Execution in LangGraph with Configuration\nDESCRIPTION: Code that demonstrates how to stream the execution of a LangGraph, which will pause at the interrupt point.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = {\n  configurable: {\n    thread_id: \"1\"\n  }\n};\n\nconst stream = await graph.stream(\"foo\", config);\n\nfor await (const event of stream) {\n  console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Research Team Chain in TypeScript\nDESCRIPTION: Demonstrates how to query the compiled research team chain with a sample question. It streams the results and logs the output, showcasing the hierarchical team's functionality.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst streamResults = researchChain.stream(\n  {\n    messages: [new HumanMessage(\"What's the price of a big mac in Argentina?\")],\n  },\n  { recursionLimit: 100 },\n);\nfor await (const output of await streamResults) {\n  if (!output?.__end__) {\n    console.log(output);\n    console.log(\"----\");\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example: Generating Chart with LangGraphJS Tool\nDESCRIPTION: Example invocation of the chartTool to create a bar chart comparing two data points. This demonstrates the data visualization capabilities available to the document writing team.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nawait chartTool.invoke({\n  data: [\n    { label: \"People who like graphs\", value: 5000 },\n    {\n      label: \"People who like LangGraph\",\n      value: 10000,\n    },\n  ],\n});\n```\n\n----------------------------------------\n\nTITLE: Invoking the Graph with Questions\nDESCRIPTION: Examples of running the graph with different types of questions, demonstrating both RAG and web search paths with thread management.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nawait app.invoke(\n  {\n    question: \"What are some features of long-term memory?\",\n  },\n  { configurable: { thread_id: \"1\" } },\n);\n\nawait app.invoke(\n  {\n    question: \"Where are the 2024 Euros being held?\",\n  },\n  { configurable: { thread_id: \"2\" } },\n);\n\nawait app.invoke(null, { configurable: { thread_id: \"2\" } });\n```\n\n----------------------------------------\n\nTITLE: Setting Up LangSmith Tracing Environment Variables\nDESCRIPTION: Optional configuration to enable LangSmith tracing for enhanced observability during agent execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/agent_executor/base.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGCHAIN_TRACING_V2=true\nexport LANGCHAIN_API_KEY=\n```\n\n----------------------------------------\n\nTITLE: Configuring langgraph.json for Custom Middleware\nDESCRIPTION: JSON configuration for langgraph.json file to include the custom app with middleware.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/http/custom_middleware.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"graphs\": {\n    \"agent\": \"./src/agent/graph.ts:graph\"\n  },\n  \"env\": \".env\",\n  \"http\": {\n    \"app\": \"./src/agent/app.ts:app\"\n  }\n  // Other configuration options like auth, store, etc.\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Environment Variables\nDESCRIPTION: Sets up environment variables for the application using dotenv\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/reflection/reflection.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport \"dotenv/config\";\n```\n\n----------------------------------------\n\nTITLE: Initializing InMemoryStore for LangGraph.js\nDESCRIPTION: Creates an instance of InMemoryStore to be used for storing and retrieving memories across threads in the LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\nconst inMemoryStore = new InMemoryStore();\n```\n\n----------------------------------------\n\nTITLE: Running the LangGraph.js Agent\nDESCRIPTION: Demonstrates how to run the compiled LangGraph.js agent with input messages and stream the results.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/delete-messages.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\nimport { v4 as uuidv4 } from \"uuid\";\n\nconst config = { configurable: { thread_id: \"2\" }, streamMode: \"values\" as const };\nconst inputMessage = new HumanMessage({\n  id: uuidv4(),\n  content: \"hi! I'm bob\",\n});\n\nfor await (const event of await app.stream(\n  { messages: [inputMessage] },\n  config,\n)) {\n  const lastMsg = event.messages[event.messages.length - 1];\n  console.dir(\n    {\n      type: lastMsg._getType(),\n      content: lastMsg.content,\n      tool_calls: lastMsg.tool_calls,\n    },\n    { depth: null }\n  )\n}\n\nconst inputMessage2 = new HumanMessage({\n  id: uuidv4(),\n  content: \"What's my name?\",\n});\nfor await (const event of await app.stream(\n  { messages: [inputMessage2] },\n  config,\n)) {\n  const lastMsg = event.messages[event.messages.length - 1];\n  console.dir(\n    {\n      type: lastMsg._getType(),\n      content: lastMsg.content,\n      tool_calls: lastMsg.tool_calls,\n    },\n    { depth: null }\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Defining State Annotation for LangGraph\nDESCRIPTION: Creation of a state annotation using LangGraph's Annotation system to define the structure of the graph state, including a messages field with a reducer function to concatenate messages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst StateAnnotation = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing RemoteGraph with URL (JavaScript)\nDESCRIPTION: Create a RemoteGraph instance by providing a deployment URL and graph name in TypeScript\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RemoteGraph } from \"@langchain/langgraph/remote\";\n\nconst url = `<DEPLOYMENT_URL>`;\nconst graphName = \"agent\";\nconst remoteGraph = new RemoteGraph({ graphId: graphName, url });\n```\n\n----------------------------------------\n\nTITLE: Setting Up the Chat Model in Python\nDESCRIPTION: This snippet initializes the ChatOpenAI model with specific parameters such as temperature and model version necessary for generating responses.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  temperature: 0,\n  model: \"gpt-4o\",\n});\n```\n\n----------------------------------------\n\nTITLE: Running Linter for LangGraph Project in Bash\nDESCRIPTION: Commands to run ESLint for checking and fixing linting issues in the project.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nyarn lint\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn lint:fix\n```\n\n----------------------------------------\n\nTITLE: Placing Side Effects After Interrupt (Good Practice)\nDESCRIPTION: This example demonstrates the correct approach of placing side effects after an interrupt call. API calls placed after interrupts only execute once the node has resumed, preventing duplicate execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt } from \"@langchain/langgraph\";\n\nfunction humanNode(state: typeof GraphAnnotation.State) {\n  /**\n   * Human node with validation.\n   */\n\n  const answer = interrupt(question);\n\n  apiCall(answer); // OK as it's after the interrupt\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for LangGraph Tool Calling\nDESCRIPTION: Command to install the necessary npm packages including LangGraph, Anthropic integration, LangChain core, and Zod for schema validation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core zod\n```\n\n----------------------------------------\n\nTITLE: Configuring Essay Generation Chain\nDESCRIPTION: Sets up the ChatPromptTemplate and Fireworks LLM model for essay generation with specific parameters and system prompts\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/reflection/reflection.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatFireworks } from \"@langchain/community/chat_models/fireworks\";\nimport {\n  ChatPromptTemplate,\n  MessagesPlaceholder,\n} from \"@langchain/core/prompts\";\n\nconst prompt = ChatPromptTemplate.fromMessages([\n  [\n    \"system\",\n    `You are an essay assistant tasked with writing excellent 5-paragraph essays.\nGenerate the best essay possible for the user's request.  \nIf the user provides critique, respond with a revised version of your previous attempts.`,\n  ],\n  new MessagesPlaceholder(\"messages\"),\n]);\nconst llm = new ChatFireworks({\n  model: \"accounts/fireworks/models/firefunction-v2\",\n  temperature: 0,\n  modelKwargs: {\n    max_tokens: 32768,\n  },\n});\nconst essayGenerationChain = prompt.pipe(llm);\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph.js CLI using yarn\nDESCRIPTION: Command to install LangGraph.js CLI using yarn package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/langgraph_cli.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph-cli\n```\n\n----------------------------------------\n\nTITLE: Connecting to LangGraph with Authentication using JavaScript RemoteGraph\nDESCRIPTION: This JavaScript code shows how to use RemoteGraph to connect to a LangGraph deployment with custom authentication headers.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/auth/custom_auth.md#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nimport { RemoteGraph } from \"@langchain/langgraph/remote\";\n\nconst my_token = \"your-token\"; // In practice, you would generate a signed token with your auth provider\nconst remoteGraph = new RemoteGraph({\n  graphId: \"agent\",\n  url: \"http://localhost:2024\",\n  headers: { Authorization: `Bearer ${my_token}` },\n});\nconst threads = await remoteGraph.invoke(...);\n```\n\n----------------------------------------\n\nTITLE: Streaming Content with Custom Mode - Python\nDESCRIPTION: This snippet demonstrates how to stream content using the StateGraph's .stream method while specifying a custom stream mode. It shows how to consume chunks of streamed data asynchronously.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-content.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nconst inputs = [{\\n  role: \"user\",\\n  content: \"What are you thinking about?\",\\n}];\\n\\nconst stream = await graph.stream(\\n  { messages: inputs },\\n  { streamMode: \"custom\" }\\n);\\n\\nfor await (const chunk of stream) {\\n  console.log(chunk);\\n}\n```\n\n----------------------------------------\n\nTITLE: Setting API Keys for LLM and Search Tool\nDESCRIPTION: Sets the required environment variables for Anthropic Claude (LLM) and Tavily (search tool) API keys.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/agent_executor/base.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ANTHROPIC_API_KEY=\nexport TAVILY_API_KEY=\n```\n\n----------------------------------------\n\nTITLE: Correct Side Effect Handling in TypeScript Workflow\nDESCRIPTION: Shows the proper way to handle side effects by encapsulating them in a task, ensuring consistent execution upon workflow resumption.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_19\n\nLANGUAGE: typescript\nCODE:\n```\nimport { task } from \"@langchain/langgraph\";\n\n// highlight-next-line\nconst writeToFile = task(\"writeToFile\", async () => {\n  await fs.writeFile(\"output.txt\", \"Side effect executed\");\n});\n\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (inputs: Record<string, any>) => {\n    // The side effect is now encapsulated in a task.\n    await writeToFile();\n    const value = interrupt(\"question\");\n    return value;\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Incorrect Side Effect Handling in TypeScript Workflow\nDESCRIPTION: Demonstrates the incorrect approach to handling side effects in a workflow where writing to a file is directly included in the workflow, causing it to execute twice when resuming.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow = entrypoint(\n  { checkpointer, name: \"myWorkflow\" },\n  async (inputs: Record<string, any>) => {\n    // This code will be executed a second time when resuming the workflow.\n    // Which is likely not what you want.\n    // highlight-next-line\n    await fs.writeFile(\"output.txt\", \"Side effect executed\");\n    const value = interrupt(\"question\");\n    return value;\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Streaming Structured Output in Python\nDESCRIPTION: This snippet showcases how to stream events from the agent's processing, capturing relevant outputs as they become available and logging the final tool call output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport { concat } from \"@langchain/core/utils/stream\";\n\nconst eventStream = await app.streamEvents(inputs, { version: \"v2\" });\n\nlet aggregatedChunk;\nfor await (const { event, data } of eventStream) {\n  if (event === \"on_chat_model_stream\") {\n    const { chunk } = data;\n    if (aggregatedChunk === undefined) {\n      aggregatedChunk = chunk;\n    } else {\n      aggregatedChunk = concat(aggregatedChunk, chunk);\n    }\n    const currentToolCalls = aggregatedChunk.tool_calls;\n    if (\n      currentToolCalls.length === 0 ||\n      currentToolCalls[0].name === \"\" ||\n      !finalResponseTool.name.startsWith(currentToolCalls[0].name)\n    ) {\n      aggregatedChunk = undefined;\n    } else if (currentToolCalls[0].name === finalResponseTool.name) {\n      console.log(aggregatedChunk.tool_call_chunks[0].args);\n      console.log(\"---\");\n    }\n  }\n}\nconsole.log(aggregatedChunk.tool_calls);\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow with State Management in Python\nDESCRIPTION: This extensive code snippet outlines the creation of a task and a workflow in LangGraph using persistence and state functionalities. It processes messages and outputs through the entrypoint, retaining context across executions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport type { BaseMessage, BaseMessageLike } from \"@langchain/core/messages\";\nimport {\n  addMessages,\n  entrypoint,\n  task,\n  getPreviousState,\n  MemorySaver,\n} from \"@langchain/langgraph\";\n\nconst callModel = task(\"callModel\", async (messages: BaseMessageLike[]) => {\n  const response = model.invoke(messages);\n  return response;\n});\n\nconst checkpointer = new MemorySaver();\n\nconst workflow = entrypoint({\n  name: \"workflow\",\n  checkpointer,\n}, async (inputs: BaseMessageLike[]) => {\n  const previous = getPreviousState<BaseMessage>() ?? [];\n  const messages = addMessages(previous, inputs);\n  const response = await callModel(messages);\n  return entrypoint.final({\n    value: response,\n    save: addMessages(messages, response),\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing RemoteGraph with Clients (JavaScript)\nDESCRIPTION: Create a RemoteGraph instance using LangGraph client in TypeScript\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@langchain/langgraph-sdk\";\nimport { RemoteGraph } from \"@langchain/langgraph/remote\";\n\nconst client = new Client({ apiUrl: `<DEPLOYMENT_URL>` });\nconst graphName = \"agent\";\nconst remoteGraph = new RemoteGraph({ graphId: graphName, client });\n```\n\n----------------------------------------\n\nTITLE: Programmatically Deleting Messages in LangGraph.js\nDESCRIPTION: Demonstrates how to modify the graph to automatically delete old messages at the end of each run.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/delete-messages.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RemoveMessage } from \"@langchain/core/messages\";\nimport { StateGraph, START, END } from \"@langchain/langgraph\";\nimport { MessagesAnnotation } from \"@langchain/langgraph\";\n\nfunction deleteMessages(state: typeof MessagesAnnotation.State) {\n  const messages = state.messages;\n  if (messages.length > 3) {\n    return { messages: messages.slice(0, -3).map(m => new RemoveMessage({ id: m.id })) };\n  }\n  return {};\n}\n\n// We need to modify the logic to call deleteMessages rather than end right away\nfunction shouldContinue2(state: typeof MessagesAnnotation.State): \"action\" | \"delete_messages\" {\n  const lastMessage = state.messages[state.messages.length - 1];\n  if (\n    \"tool_calls\" in lastMessage &&\n    Array.isArray(lastMessage.tool_calls) &&\n    lastMessage.tool_calls.length\n  ) {\n    return \"action\";\n  }\n  // Otherwise if there aren't, we finish\n  return \"delete_messages\";\n}\n\n// Define a new graph\nconst workflow2 = new StateGraph(MessagesAnnotation)\n  .addNode(\"agent\", callModel)\n  .addNode(\"action\", toolNode)\n  // This is our new node we're defining\n  .addNode(\"delete_messages\", deleteMessages)\n  .addEdge(START, \"agent\")\n  .addConditionalEdges(\n    \"agent\",\n    shouldContinue2\n  )\n  .addEdge(\"action\", \"agent\")\n  // This is the new edge we're adding: after we delete messages, we finish\n  .addEdge(\"delete_messages\", END);\n\nconst app2 = workflow2.compile({ checkpointer: memory });\n```\n\n----------------------------------------\n\nTITLE: Setting up StateGraph with LanggraphJS\nDESCRIPTION: This snippet defines a node graph using LanggraphJS, where nodes represent states managed by a message annotation and connections define transitions. It sets up conditional routing based on the AI model's output, with calls to a tool node and a final node. Dependencies include StateGraph and MessagesAnnotation from Langchain.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-from-final-node.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph, MessagesAnnotation } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\nimport { AIMessage, HumanMessage, SystemMessage } from \"@langchain/core/messages\";\n\nconst shouldContinue = async (state: typeof MessagesAnnotation.State) => {\n  const messages = state.messages;\n  const lastMessage: AIMessage = messages[messages.length - 1];\n  // If the LLM makes a tool call, then we route to the \"tools\" node\n  if (lastMessage.tool_calls?.length) {\n    return \"tools\";\n  }\n  // Otherwise, we stop (reply to the user)\n  return \"final\";\n};\n\nconst callModel = async (state: typeof MessagesAnnotation.State) => {\n  const messages = state.messages;\n  const response = await model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n};\n\nconst callFinalModel = async (state: typeof MessagesAnnotation.State) => {\n  const messages = state.messages;\n  const lastAIMessage = messages[messages.length - 1];\n  const response = await finalModel.invoke([\n    new SystemMessage(\"Rewrite this in the voice of Al Roker\"),\n    new HumanMessage({ content: lastAIMessage.content })\n  ]);\n  // MessagesAnnotation allows you to overwrite messages from the agent\n  // by returning a message with the same id\n  response.id = lastAIMessage.id;\n  return { messages: [response] };\n}\n\nconst toolNode = new ToolNode<typeof MessagesAnnotation.State>(tools);\n\nconst graph = new StateGraph(MessagesAnnotation)\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  // add a separate final node\n  .addNode(\"final\", callFinalModel)\n  .addEdge(\"__start__\", \"agent\")\n  // Third parameter is optional and only here to draw a diagram of the graph\n  .addConditionalEdges(\"agent\", shouldContinue, {\n    tools: \"tools\",\n    final: \"final\",\n  })\n  .addEdge(\"tools\", \"agent\")\n  .addEdge(\"final\", \"__end__\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Test Node and Graph Setup for Algorithm Components in TypeScript\nDESCRIPTION: Defines functions to create test nodes and set up a simple test graph for algorithm component testing. This includes creating nodes with custom input/output channels and processing functions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-testing-plan.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst createTestNode = (name, inputChannels, outputChannels, fn) => ({\n  name,\n  readEdges: new Map([[name, inputChannels]]),\n  writeEdges: new Map([[name, outputChannels]]),\n  bound: {\n    invoke: (input) => fn(input),\n  },\n});\n\nconst setupTestGraph = () => {\n  const channels = {\n    input: new TestChannel(\"initial\"),\n    middle: new TestChannel(),\n    output: new TestChannel(),\n  };\n\n  const nodes = {\n    node1: createTestNode(\"node1\", [\"input\"], [\"middle\"], (input) => ({\n      result: `processed ${input.input}`,\n    })),\n    node2: createTestNode(\"node2\", [\"middle\"], [\"output\"], (input) => ({\n      result: `finalized ${input.middle}`,\n    })),\n  };\n\n  return { channels, nodes };\n};\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies with npm\nDESCRIPTION: Command to install all necessary npm packages for implementing a LangGraph retrieval agent, including cheerio for web scraping, zod for schema validation, and various LangChain packages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install cheerio zod zod-to-json-schema langchain @langchain/openai @langchain/core @langchain/community @langchain/textsplitters\n```\n\n----------------------------------------\n\nTITLE: Define a Subgraph Node with Command to Navigate to Parent Graph\nDESCRIPTION: This snippet defines `nodeASubgraph` as a single-node graph that dictates navigation to the parent graph using `Command.PARENT`. It updates state and randomly directs to \"nodeB\" or \"nodeC\" in the parent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/command.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Define the nodes\nconst nodeASubgraph = async (_state: typeof StateAnnotation.State) => {\n  console.log(\"Called A\");\n  // this is a replacement for a real conditional edge function\n  const goto = Math.random() > .5 ? \"nodeB\" : \"nodeC\";\n  // note how Command allows you to BOTH update the graph state AND route to the next node\n  return new Command({\n    update: {\n      foo: \"a\",\n    },\n    goto,\n    // this tells LangGraph to navigate to node_b or node_c in the parent graph\n    // NOTE: this will navigate to the closest parent graph relative to the subgraph\n    graph: Command.PARENT,\n  });\n};\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Commands to install necessary npm packages including cheerio, langchain, and related dependencies.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install cheerio langchain @langchain/community @langchain/ollama @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Display Graph as PNG\nDESCRIPTION: This snippet uses the `tslab` library to display the LangGraph as a PNG image within a notebook environment.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/command.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraph = await graph.getGraphAsync();\nconst image = await drawableGraph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Answer Generation Chain Implementation\nDESCRIPTION: Setup of the RAG chain for generating answers based on retrieved documents.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport * as hub from \"langchain/hub\";\nimport { StringOutputParser } from \"@langchain/core/output_parsers\";\nimport type { Document } from \"@langchain/core/documents\";\n\nconst ragPrompt = await hub.pull(\"rlm/rag-prompt\");\n\nconst formatDocs = (docs: Document[]) => {\n  return docs.map((doc) => doc.pageContent).join(\"\\n\\n\");\n};\n\nconst llm = new ChatOllama({\n  model: \"llama3\",\n  temperature: 0,\n});\n\nconst ragChain = ragPrompt.pipe(llm).pipe(new StringOutputParser());\n\nconst testQuestion2 = \"agent memory\";\nconst docs3 = await retriever.invoke(testQuestion2);\n\nawait ragChain.invoke({ context: formatDocs(docs3), question: testQuestion2 });\n```\n\n----------------------------------------\n\nTITLE: Executing the LangGraph for Joke Generation in Python\nDESCRIPTION: This Python snippet shows how to call the compiled LangGraph application to generate jokes about a given topic (animals in this case) and stream the results.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/map-reduce.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n// Call the graph: here we call it to generate a list of jokes\nfor await (const s of await app.stream({ topic: \"animals\" })) {\n  console.log(s);\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing State Annotation for CUA Agent\nDESCRIPTION: Example of extending the default CUA state annotation to add custom fields, enabling domain-specific functionality and additional context storage.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createCua, CUAAnnotation } from \"@langchain/langgraph-cua\";\nimport { Annotation } from \"@langchain/langgraph\";\n\n// Create a custom state annotation that extends the default CUA state\nconst CustomStateAnnotation = Annotation.Root({\n  ...CUAAnnotation.spec,\n  // Add your custom fields here\n  customField: Annotation.Field({\n    default: \"default value\",\n  }),\n});\n\nconst cuaGraph = createCua({\n  stateModifier: CustomStateAnnotation,\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LangGraphJS\nDESCRIPTION: This snippet shows how to install necessary packages for setting up the LangGraphJS environment using Yarn. The required packages include langgraph, openai, and core libraries from LangChain.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-human-in-the-loop.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/openai @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Environment Variable Setup in Python\nDESCRIPTION: This Python code snippet sets environment variables required for interacting with OpenAI and LangSmith. It enables tracing, specifies the LangChain project, and configures the OpenAI API key.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-multi-turn-convo.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\";\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"Time Travel: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: RemoteGraph as Subgraph (Python)\nDESCRIPTION: Use a RemoteGraph as a subgraph within another graph in Python\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph_sdk import get_sync_client\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom typing import TypedDict\n\nurl = <DEPLOYMENT_URL>\ngraph_name = \"agent\"\nremote_graph = RemoteGraph(graph_name, url=url)\n\n# define parent graph\nbuilder = StateGraph(MessagesState)\n# add remote graph directly as a node\nbuilder.add_node(\"child\", remote_graph)\nbuilder.add_edge(START, \"child\")\ngraph = builder.compile()\n\n# invoke the parent graph\nresult = graph.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf\"}]\n})\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: User Information Dictionary Definition - Python\nDESCRIPTION: A simple dictionary that maps user IDs to user information objects, used for demonstration purposes in the user lookup tool.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/update-state-from-tools.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nconst USER_ID_TO_USER_INFO = {\n  abc123: {\n    user_id: \"abc123\",\n    name: \"Bob Dylan\",\n    location: \"New York, NY\",\n  },\n  zyx987: {\n    user_id: \"zyx987\",\n    name: \"Taylor Swift\",\n    location: \"Beverly Hills, CA\",\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Defining Agent State\nDESCRIPTION: Define the agent state using Annotation, specifying the structure and reducer for messages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { Annotation } from \"@langchain/langgraph\";\n\nconst AgentState = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  })\n})\n```\n\n----------------------------------------\n\nTITLE: Resuming Graph Execution from Checkpoint\nDESCRIPTION: Shows how to resume graph execution from a checkpoint by streaming with null input. Processes and logs messages or tool calls from the execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfor await (\n  const { messages } of await graphWithInterrupt.stream(null, {\n    ...snapshot.config,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Defining the Agent with Memory in Python\nDESCRIPTION: This snippet creates a conversational agent with memory capabilities by using the MemorySaver. It handles incoming messages, processes tool calls, and appends responses while maintaining the entire message context.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nconst agentWithMemory = entrypoint({\\n  name: \"agentWithMemory\",\\n  // highlight-next-line\\n  checkpointer,\\n}, async (messages: BaseMessageLike[]) => {\\n  const previous = getPreviousState<BaseMessage>() ?? [];\\n  let currentMessages = addMessages(previous, messages);\\n  let llmResponse = await callModel(currentMessages);\\n  while (true) {\\n    if (!llmResponse.tool_calls?.length) {\\n      break;\\n    }\\n\\n    // Execute tools\\n    const toolResults = await Promise.all(\\n      llmResponse.tool_calls.map((toolCall) => {\\n        return callTool(toolCall);\\n      })\\n    );\\n    \\n    // Append to message list\\n    currentMessages = addMessages(currentMessages, [llmResponse, ...toolResults]);\\n\\n    // Call model again\\n    llmResponse = await callModel(currentMessages);\\n  }\\n  \\n  // Append final response for storage\\n  currentMessages = addMessages(currentMessages, llmResponse);\\n\\n  // highlight-next-line\\n  return entrypoint.final({\\n    // highlight-next-line\\n    value: llmResponse,\\n    // highlight-next-line\\n    save: currentMessages,\\n    // highlight-next-line\\n  });\\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Message History Output Modes\nDESCRIPTION: Examples showing different ways to configure how agent messages are included in the conversation history.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-supervisor/README.md#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = createSupervisor({\n  agents: [agent1, agent2],\n  outputMode: \"full_history\"\n})\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow = createSupervisor({\n  agents: [agent1, agent2],\n  outputMode: \"last_message\"\n})\n```\n\n----------------------------------------\n\nTITLE: Defining User Lookup Tool with State Annotation - Python\nDESCRIPTION: Implementation of a tool that looks up user information from a dictionary and returns a Command to update the graph state with the retrieved user information.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/update-state-from-tools.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport { Annotation, Command, MessagesAnnotation } from \"@langchain/langgraph\";\nimport { tool } from \"@langchain/core/tools\";\n\nimport { z } from \"zod\";\n\nconst StateAnnotation = Annotation.Root({\n  ...MessagesAnnotation.spec,\n  // user provided\n  lastName: Annotation<string>,\n  // updated by the tool\n  userInfo: Annotation<Record<string, any>>,\n});\n\nconst lookupUserInfo = tool(async (_, config) => {\n  const userId = config.configurable?.user_id;\n  if (userId === undefined) {\n    throw new Error(\"Please provide a user id in config.configurable\");\n  }\n  if (USER_ID_TO_USER_INFO[userId] === undefined) {\n    throw new Error(`User \"${userId}\" not found`);\n  }\n  // Populated when a tool is called with a tool call from a model as input\n  const toolCallId = config.toolCall.id;\n  return new Command({\n    update: {\n      // update the state keys\n      userInfo: USER_ID_TO_USER_INFO[userId],\n      // update the message history\n      messages: [\n        {\n          role: \"tool\",\n          content: \"Successfully looked up user information\",\n          tool_call_id: toolCallId,\n        },\n      ],\n    },\n  })\n}, {\n  name: \"lookup_user_info\",\n  description: \"Always use this to look up information about the user to better assist them with their questions.\",\n  schema: z.object({}),\n});\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph.js and Core Dependencies\nDESCRIPTION: Command to install @langchain/langgraph and @langchain/core packages using npm. This ensures that the core package is installed as a peer dependency.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-ecosystem-dependencies.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ npm install @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Visualizing Graph using TSLab - Python\nDESCRIPTION: This snippet demonstrates how to visualize a constructed graph using TSLab. It converts the graph representation to an image and displays it as a PNG using TSLab’s display functionality.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-tokens-without-langchain.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst representation = graph.getGraph();\nconst image = await representation.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Creating a ReAct Agent Entrypoint with Human-in-the-Loop Capability\nDESCRIPTION: Implementation of an entrypoint for a ReAct agent that can use both standard tools and request human assistance through interruption.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { entrypoint, addMessages, MemorySaver } from \"@langchain/langgraph\";\n\nconst agent = entrypoint({\n  name: \"agent\",\n  checkpointer: new MemorySaver(),\n}, async (messages: BaseMessageLike[]) => {\n  let currentMessages = messages;\n  let llmResponse = await callModel(currentMessages);\n  while (true) {\n    if (!llmResponse.tool_calls?.length) {\n      break;\n    }\n\n    // Execute tools\n    const toolResults = await Promise.all(\n      llmResponse.tool_calls.map((toolCall) => {\n        return callTool(toolCall);\n      })\n    );\n    \n    // Append to message list\n    currentMessages = addMessages(currentMessages, [llmResponse, ...toolResults]);\n\n    // Call model again\n    llmResponse = await callModel(currentMessages);\n  }\n\n  return llmResponse;\n});\n```\n\n----------------------------------------\n\nTITLE: Defining and Compiling LangGraph\nDESCRIPTION: This snippet defines the structure of the LangGraph, including nodes, edges, and conditional edges. It sets up the workflow by adding an agent node, a tools node, and defines how the graph transitions between them based on whether the agent calls a tool or not. The graph is then compiled for execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-updates.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\nimport { AIMessage } from \"@langchain/core/messages\";\n\nconst routeMessage = (state: typeof StateAnnotation.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  // If no tools are called, we can finish (respond to the user)\n  if (!lastMessage?.tool_calls?.length) {\n    return END;\n  } \n  // Otherwise if there is, we continue and call the tools\n  return \"tools\";\n};\n\nconst callModel = async (\n  state: typeof StateAnnotation.State,\n) => {\n  const { messages } = state;\n  const responseMessage = await boundModel.invoke(messages);\n  return { messages: [responseMessage] };\n};\n\nconst workflow = new StateGraph(StateAnnotation)\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  .addEdge(START, \"agent\")\n  .addConditionalEdges(\"agent\", routeMessage)\n  .addEdge(\"tools\", \"agent\");\n\nconst graph = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for OpenAI and LangSmith\nDESCRIPTION: Configuration of environment variables for OpenAI API access and LangSmith tracing to enable observability.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\"\n// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"Branching: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Installing Required NPM Dependencies\nDESCRIPTION: Installs necessary npm packages including cheerio, zod, langchain and related modules\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_crag.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install cheerio zod langchain @langchain/community @langchain/openai @langchain/core @langchain/textsplitters @langchain/langgraph\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages\nDESCRIPTION: Installing the necessary npm packages for building a chatbot with conversation history summarization capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core uuid\n```\n\n----------------------------------------\n\nTITLE: Initializing RemoteGraph with URL (Python)\nDESCRIPTION: Create a RemoteGraph instance by providing a deployment URL and graph name in Python\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.pregel.remote import RemoteGraph\n\nurl = <DEPLOYMENT_URL>\ngraph_name = \"agent\"\nremote_graph = RemoteGraph(graph_name, url=url)\n```\n\n----------------------------------------\n\nTITLE: Getting Grandparent Graph State History in LangGraph.js\nDESCRIPTION: This code retrieves and iterates through the state history of the grandparent graph using LangGraph.js.  It prints each state object to the console, allowing developers to track the evolution of the graph's state over time.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nconst grandparentStateHistories = await grandparentGraph.getStateHistory(grandparentConfig);\nfor await (const state of grandparentStateHistories) {\n  console.log(state);\n  console.log(\"-----\");\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Anthropic API Key\nDESCRIPTION: Setting the environment variable for Anthropic API authentication to use their LLM services.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nprocess.env.ANTHROPIC_API_KEY = 'YOUR_API_KEY'\n```\n\n----------------------------------------\n\nTITLE: Navigating Between Agent Subgraphs in LangGraphJS\nDESCRIPTION: Demonstrates how to navigate from a node in one agent subgraph to a different agent in the parent graph. The Command.PARENT flag allows specifying that the navigation should occur at the parent graph level.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/multi_agent.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst some_node_inside_alice = (state) => {\n    return new Command({\n      goto: \"bob\",\n      update: {\n          foo: \"bar\",\n      },\n      // specify which graph to navigate to (defaults to the current graph)\n      graph: Command.PARENT,\n    })\n}\n```\n\n----------------------------------------\n\nTITLE: Task Definition for Calling Travel Advisor - TypeScript\nDESCRIPTION: This snippet defines a task that allows calling the travel advisor agent by invoking it with a set of messages and returning the response messages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst callTravelAdvisor = task(\"callTravelAdvisor\", async (messages: BaseMessage[]) => {\n  const response = travelAdvisor.invoke({ messages });\n  return response.messages;\n});\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image with LangGraph CLI\nDESCRIPTION: Command to build a Docker image for the LangGraph application using the LangGraph CLI.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/deploy-self-hosted.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nlanggraph build -t my-image\n```\n\n----------------------------------------\n\nTITLE: Visualizing the State Graph with Mermaid\nDESCRIPTION: Code to generate and display a visual representation of the state graph using Mermaid diagram. This helps understand the flow of the ReAct agent implementation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling-errors.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst graph = app.getGraph();\nconst image = await graph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Inspecting InMemoryStore contents in LangGraph.js\nDESCRIPTION: Retrieves and logs the memories stored for User 1 from the InMemoryStore to verify persistence.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nconst memories = await inMemoryStore.search([\"memories\", \"1\"]);\nfor (const memory of memories) {\n    console.log(await memory.value);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing RemoteGraph with Clients (Python)\nDESCRIPTION: Create a RemoteGraph instance using LangGraph clients in Python\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph_sdk import get_client, get_sync_client\nfrom langgraph.pregel.remote import RemoteGraph\n\nurl = <DEPLOYMENT_URL>\ngraph_name = \"agent\"\nclient = get_client(url=url)\nsync_client = get_sync_client(url=url)\nremote_graph = RemoteGraph(graph_name, client=client, sync_client=sync_client)\n```\n\n----------------------------------------\n\nTITLE: Testing LangGraph Deployment\nDESCRIPTION: cURL command to test if the LangGraph application is running correctly after deployment.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/deploy-self-hosted.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncurl --request GET --url 0.0.0.0:8123/ok\n```\n\n----------------------------------------\n\nTITLE: Initializing Together AI Chat Model for LanggraphJS\nDESCRIPTION: Configures a ChatTogetherAI instance with Meta's Llama 3.1 8B Instruct Turbo model. Sets temperature to 0 for deterministic outputs, which is useful for consistent customer support responses.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatTogetherAI } from \"@langchain/community/chat_models/togetherai\";\n\nconst model = new ChatTogetherAI({\n  model: \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n  temperature: 0,\n});\n```\n\n----------------------------------------\n\nTITLE: Multi-Turn Conversation with Human Input Node\nDESCRIPTION: Demonstrates creating a human input node for collecting user input across multiple agents, with flexible routing and interaction mechanisms\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt } from \"@langchain/langgraph\";\n\nfunction humanInput(state: typeof GraphAnnotation.State) {\n  const humanMessage = interrupt(\"human_input\");\n\n  return {\n    messages: [{\n      role: \"human\",\n      content: humanMessage\n    }]\n  };\n}\n```\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt, Command, MessagesAnnotation } from \"@langchain/langgraph\";\n\nfunction humanNode(state: typeof MessagesAnnotation.State): Command {\n  const userInput = interrupt(\"Ready for user input.\");\n\n  const activeAgent = ...;\n\n  return new Command({\n    goto: activeAgent,\n    update: {\n      messages: [{\n        role: \"human\",\n        content: userInput,\n      }]\n    }\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a ToolNode for Tool Execution\nDESCRIPTION: This snippet creates a ToolNode that can execute the defined tools based on the LLM's generated tool calls.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst toolNode = new ToolNode(tools);\n```\n\n----------------------------------------\n\nTITLE: Creating a React Agent with a System Prompt - Python\nDESCRIPTION: This snippet illustrates how to create a React agent using the createReactAgent function from the LangChain library. It defines a weather tool and integrates a custom prompt to ensure the agent responds in Italian.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-system-prompt.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { tool } from '@langchain/core/tools';\nimport { z } from 'zod';\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n\nconst model = new ChatOpenAI({\n    model: \"gpt-4o\",\n  });\n\nconst getWeather = tool((input) => {\n    if (input.location === 'sf') {\n        return 'It\\'s always sunny in sf';\n    } else {\n        return 'It might be cloudy in nyc';\n    }\n}, {\n    name: 'get_weather',\n    description: 'Call to get the current weather.',\n    schema: z.object({\n        location: z.enum(['sf','nyc']).describe(\"Location to get the weather for.\"),\n    })\n})\n\n// We can add our system prompt here\nconst prompt = \"Respond in Italian\"\n\nconst agent = createReactAgent({ llm: model, tools: [getWeather], stateModifier: prompt });\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Channels and Invoking Pregel Graph in TypeScript\nDESCRIPTION: This snippet demonstrates creating a simple Pregel graph with a single node that modifies an input using a channel subscription, and how the graph processes and returns output. Dependencies include 'jest' for mocking functions and 'Channel' and 'Pregel' for graph processing. The graph subscribes to 'inputChannelName', increments the input by one, and outputs the result to 'outputChannelName'.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst addOne = jest.fn((x: number): number => x + 1);\nconst chain = Channel.subscribeTo(\"inputChannelName\")\n  .pipe(addOne)\n  .pipe(Channel.writeTo(\"outputChannelName\"));\n\nconst app = new Pregel({\n  nodes: { nodeOne: chain },\n  input: [\"inputChannelName\"],\n  output: [\"outputChannelName\"],\n});\n\nexpect(await app.invoke({ input: 2 })).toEqual({ output: 3 });\n```\n\n----------------------------------------\n\nTITLE: Resolving Core Dependencies with NPM\nDESCRIPTION: Example package.json configuration for npm, using the 'overrides' field to specify an exact version of @langchain/core to resolve version conflicts.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-ecosystem-dependencies.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"your-project\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"engines\": {\n    \"node\": \">=18\"\n  },\n  \"dependencies\": {\n    \"@langchain/anthropic\": \"^0.2.15\",\n    \"@langchain/langgraph\": \"^0.2.0\"\n  },\n  \"overrides\": {\n    \"@langchain/core\": \"0.2.31\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring LangGraph Thread and Checkpoint IDs in TypeScript\nDESCRIPTION: Examples of valid configurations for specifying thread_id and optionally checkpoint_id when invoking a LangGraph graph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint/README.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n{ configurable: { thread_id: \"1\" } }  // valid config\n{ configurable: { thread_id: \"1\", checkpoint_id: \"0c62ca34-ac19-445d-bbb0-5b4984975b2a\" } }  // also valid config\n```\n\n----------------------------------------\n\nTITLE: Initializing InMemoryStore in TypeScript\nDESCRIPTION: This snippet initializes an InMemoryStore instance from the @langchain/langgraph package. The purpose of this store is to persist user-related data that is accessible across multiple conversation threads. No additional dependencies are required apart from the LangGraph package.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_7\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { InMemoryStore } from \"@langchain/langgraph\";\n\nconst inMemoryStore = new InMemoryStore();\n```\n\n----------------------------------------\n\nTITLE: Installing Hono Dependency for LangGraph\nDESCRIPTION: Command to install the Hono package as a dependency for the LangGraph project.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/http/custom_routes.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install hono\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-level Hierarchical Systems\nDESCRIPTION: Example demonstrating how to create nested supervisor hierarchies by combining multiple supervisor instances.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-supervisor/README.md#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst researchTeam = createSupervisor({\n  agents: [researchAgent, mathAgent],\n  llm: model,\n}).compile({ name: \"research_team\" })\n\nconst writingTeam = createSupervisor({\n  agents: [writingAgent, publishingAgent],\n  llm: model,\n}).compile({ name: \"writing_team\" })\n\nconst topLevelSupervisor = createSupervisor({\n  agents: [researchTeam, writingTeam],\n  llm: model,\n}).compile({ name: \"top_level_supervisor\" })\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraphJS Dependencies\nDESCRIPTION: Command to install the required npm packages for implementing tool calling error handling in LangGraphJS.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling-errors.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ npm install @langchain/langgraph @langchain/anthropic @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Creating LangGraph Project with CLI\nDESCRIPTION: Command to create a new LangGraph project from a template using the CLI.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/http/custom_middleware.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm create langgraph\n```\n\n----------------------------------------\n\nTITLE: Invoking LangGraph with Invalid Node Return (TypeScript)\nDESCRIPTION: This snippet demonstrates how invoking a LangGraph with an invalid node return value will result in an error. It shows the method call that would trigger the error.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nawait graph.invoke({ someKey: \"someval\" });\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for LangChain\nDESCRIPTION: This Python snippet sets up several environment variables required for the OpenAI GPT-4o model and LangSmith tracing in the LangChain framework. It includes optional tracing configurations for observability.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-human-in-the-loop.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\"\n// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"ReAct Agent with human-in-the-loop: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Compiling LangGraph Graph with TypeScript\nDESCRIPTION: This snippet demonstrates compiling a graph using the LangGraph library in TypeScript. The process includes defining state annotations, nodes, and edges, and requires the graph to be compiled using the .compile method before invocation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nconst graph = graphBuilder.compile(...);\n```\n\n----------------------------------------\n\nTITLE: Setting Optional API Keys for LangSmith in Python\nDESCRIPTION: This snippet optionally sets API keys and configurations for LangSmith tracing to enhance observability of the agent's execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n// process.env.LANGCHAIN_API_KEY = \"ls...\";\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"Respond in Format: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Starting LangGraph Server Locally\nDESCRIPTION: Command to start the LangGraph server locally for testing the custom middleware.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/http/custom_middleware.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpx langgraph-cli@latest dev --no-browser\n```\n\n----------------------------------------\n\nTITLE: Initializing StateGraph with Potential Concurrent Update Issue in TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize a StateGraph with a state annotation that could potentially lead to concurrent update errors if used in a parallel execution context.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst StateAnnotation = Annotation.Root({\n  someKey: Annotation<string>,\n});\n\nconst graph = new StateGraph(StateAnnotation)\n  .addNode(...)\n  ...\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Save Graph Visualization\nDESCRIPTION: Code to save the agent's graph visualization as a PNG file.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/quickstart.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { writeFileSync } from \"node:fs\";\n\nconst graphStateImage = await drawableGraphGraphState.drawMermaidPng();\nconst graphStateArrayBuffer = await graphStateImage.arrayBuffer();\n\nconst filePath = \"./graphState.png\";\nwriteSync(filePath, new Uint8Array(graphStateArrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph.js Dependencies\nDESCRIPTION: Command to install LangGraph.js and its core dependencies using Yarn package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/branching.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Compiling LangGraphJS with MemorySaver\nDESCRIPTION: This code snippet compiles the LangGraphJS graph builder into a runnable graph. It uses `MemorySaver` from `@langchain/langgraph` to store the graph's state in memory. The `compile` method finalizes the graph structure and prepares it for execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport { MemorySaver } from \"@langchain/langgraph\";\n\nconst checkpointer = new MemorySaver();\n\nconst graph = builder.compile({\n  checkpointer,\n});\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraphJS and OpenAI packages\nDESCRIPTION: This snippet illustrates the command for installing the required packages to work with LangGraphJS and OpenAI within a Node.js environment. It is a prerequisite for setting up the ReAct agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-memory.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/openai @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Configuring Screenshot Upload in LangGraph CUA\nDESCRIPTION: Example showing how to configure screenshot upload functionality in LangGraph CUA by implementing a custom upload handler that stores images in S3.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createCua } from \"@langgraph/cua\";\n\nconst cuaGraph = createCua({\n  uploadScreenshot: async (base64Screenshot) => {\n    // Upload screenshot to storage service\n    const publicImageUrl = await uploadToS3(base64Screenshot);\n    return publicImageUrl;\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Workflow Communication in Python\nDESCRIPTION: This snippet illustrates how to use the LangGraph workflow to generate message responses and manage thread contexts using different configurations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nconst config = {\n  configurable: { thread_id: \"1\" },\n  streamMode: \"values\" as const,\n};\nconst inputMessage = { role: \"user\", content: \"hi! I'm bob\" };\n\nconst stream = await workflow.stream(\n  [inputMessage],\n  config,\n);\n\nfor await (const chunk of stream) {\n  console.log(\"=\".repeat(30), `${chunk.getType()} message`, \"=\".repeat(30));\n  console.log(chunk.content);\n}\n```\n\n----------------------------------------\n\nTITLE: LangGraph Invalid Node Return Error Message (TypeScript)\nDESCRIPTION: This snippet shows the error message that would be thrown when a LangGraph node returns an invalid value type. It includes the error text and a troubleshooting URL.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nInvalidUpdateError: Expected node \"badNode\" to return an object, received number\n\nTroubleshooting URL: https://js.langchain.com/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE\n```\n\n----------------------------------------\n\nTITLE: Visualizing LangGraph with Mermaid in Python\nDESCRIPTION: This snippet demonstrates how to generate a visual representation of the constructed LangGraph using Mermaid in a Python environment. The tslab library is used to handle the graphical display operations, requiring a LangGraph instance (`graph`) and the tslab module.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraph = graph.getGraph();\nconst image = await drawableGraph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Adding New Information After Summarization\nDESCRIPTION: Sending a message with new information about sports preferences to demonstrate how the conversation continues normally after summarization.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nconst inputMessage7 = new HumanMessage(\"i like the patriots!\");\nconsole.log(inputMessage7.content)\nfor await (const event of await app.stream({ messages: [inputMessage7] }, config)) {\n  printUpdate(event)\n}\n```\n\n----------------------------------------\n\nTITLE: Disabling Checkpointing for LangGraph Subgraph Compilation\nDESCRIPTION: Shows how to disable checkpointing when compiling a subgraph to avoid the multiple subgraphs restriction. This allows the subgraph to be called multiple times within a single node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/MULTIPLE_SUBGRAPHS.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n.compile({ checkpointer: false })\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for LangGraph\nDESCRIPTION: Command for installing the necessary npm packages to work with LangGraph, Anthropic's Claude, and LangChain Core.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/anthropic @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Inspecting Last Step of Agent Execution in Python\nDESCRIPTION: This snippet shows how to inspect the last step of the agent's execution, which is particularly useful for understanding where the execution was interrupted for human assistance.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nconsole.log(JSON.stringify(lastStep));\n```\n\n----------------------------------------\n\nTITLE: Python LangGraph Configuration File Example\nDESCRIPTION: Example of a langgraph.json configuration file for a Python LangGraph application. Specifies both external and local package dependencies, a single graph from a specific file, and environment variables loaded from a .env file.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/application_structure.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"dependencies\": [\n        \"langchain_openai\",\n        \"./your_package\"\n    ],\n    \"graphs\": {\n        \"my_agent\": \"./your_package/your_file.py:agent\"\n    },\n    \"env\": \"./.env\"\n}\n```\n\n----------------------------------------\n\nTITLE: Initiating Agent Interaction in LangGraph with Python and JavaScript\nDESCRIPTION: This snippet shows how to start an interaction with an agent, asking it to inquire about the user's location and then look up the weather. It uses a mix of Python-like syntax with JavaScript objects.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n// Input\nconst input = {\n  role: \"user\",\n  content: \"Use the search tool to ask the user where they are, then look up the weather there\",\n}\n\n// Thread\nconst config2 = { configurable: { thread_id: \"3\" }, streamMode: \"values\" as const };\n\nfor await (const event of await messagesApp.stream({\n  messages: [input]\n}, config2)) {\n  const recentMsg = event.messages[event.messages.length - 1];\n  console.log(`================================ ${recentMsg.getType()} Message (1) =================================`)\n  console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Memory by Key - Python\nDESCRIPTION: This snippet shows how to store multiple entries in the memory and later retrieve a specific memory by key to verify proper storage.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nawait store.put(\n  [\"user_123\", \"memories\"],\n  \"italian_food\",\n  {\"text\": \"I prefer Italian food\"}\n)\nawait store.put(\n  [\"user_123\", \"memories\"],\n  \"spicy_food\",\n  {\"text\": \"I don't like spicy food\"}\n)\nawait store.put(\n  [\"user_123\", \"memories\"],\n  \"occupation\",\n  {\"text\": \"I am an airline pilot\"}\n)\n\n// That occupation is too lofty - let's overwrite\n// it with something more... down-to-earth\nawait store.put(\n  [\"user_123\", \"memories\"],\n  \"occupation\",\n  {\"text\": \"I am a tunnel engineer\"}\n)\n\n// now let's check that our occupation memory was overwritten\nconst occupation = await store.get([\"user_123\", \"memories\"], \"occupation\")\nconsole.log(occupation.value.text)\n```\n\n----------------------------------------\n\nTITLE: Setting LangSmith Tracing Configuration\nDESCRIPTION: These commands set up environment variables for LangSmith tracing, enabling advanced observability features for LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\nexport LANGCHAIN_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Configuring LangSmith Tracing in Node.js\nDESCRIPTION: This snippet shows how to set up optional LangSmith tracing for enhanced observability in a Node.js environment.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\";\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"Managing Agent Steps: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Node.js\nDESCRIPTION: This line sets the OpenAI API key as an environment variable. This is necessary to authenticate requests to the OpenAI API when using OpenAI models.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"process.env.OPENAI_API_KEY = \\\"YOUR_API_KEY\\\";\"\n```\n\n----------------------------------------\n\nTITLE: Configure LangSmith Environment\nDESCRIPTION: Optional environment variable configuration for LangSmith observability setup.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/quickstart.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\";\n// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n// process.env.LANGCHAIN_TRACING_V2 = \"true\";\n// process.env.LANGCHAIN_PROJECT = \"Quickstart: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Defining Chat Model with ChatAnthropic in TypeScript\nDESCRIPTION: This snippet defines a chat model using the ChatAnthropic class from the @langchain/anthropic package, specifying model parameters for creating a LangGraph workflow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatAnthropic } from \"@langchain/anthropic\";\n\nconst model = new ChatAnthropic({\n  model: \"claude-3-5-sonnet-latest\",\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LangGraphJS Agent\nDESCRIPTION: This command installs the necessary packages for creating a LangGraphJS agent with OpenAI integration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/openai @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Adding a Compiled Subgraph as a Node in LangGraphJS\nDESCRIPTION: Example demonstrating how to define a subgraph that shares state keys with the parent graph, compile it, and add it as a node in the parent graph. The subgraph and parent graph communicate through a shared 'foo' state key.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\nconst SubgraphStateAnnotation = Annotation.Root({\n  foo: Annotation<string>, // note that this key is shared with the parent graph state\n  bar: Annotation<string>,\n});\n\nconst subgraphNode1 = async (state: typeof SubgraphStateAnnotation.State) => {\n  return { bar: \"bar\" };\n};\n\nconst subgraphNode2 = async (state: typeof SubgraphStateAnnotation.State) => {\n  // note that this node is using a state key ('bar') that is only available in the subgraph\n  // and is sending update on the shared state key ('foo')\n  return { foo: state.foo + state.bar };\n};\n\nconst subgraphBuilder = new StateGraph(SubgraphStateAnnotation)\n  .addNode(\"subgraphNode1\", subgraphNode1)\n  .addNode(\"subgraphNode2\", subgraphNode2)\n  .addEdge(\"__start__\", \"subgraphNode1\")\n  .addEdge(\"subgraphNode1\", \"subgraphNode2\")\n\nconst subgraph = subgraphBuilder.compile();\n\n// Define parent graph\nconst ParentStateAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n});\n\nconst node1 = async (state: typeof ParentStateAnnotation.State) => {\n  return {\n    foo: \"hi! \" + state.foo,\n  };\n}\n\nconst builder = new StateGraph(ParentStateAnnotation)\n  .addNode(\"node1\", node1)\n  // note that we're adding the compiled subgraph as a node to the parent graph\n  .addNode(\"node2\", subgraph)\n  .addEdge(\"__start__\", \"node1\")\n  .addEdge(\"node1\", \"node2\")\n\nconst graph = builder.compile();\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to LangGraph Project Directory in Bash\nDESCRIPTION: Commands to clone the LangGraph repository and navigate to the project directory.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd langgraph\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph Dependencies\nDESCRIPTION: Installs the necessary npm packages for using LangGraph, Anthropic, and Zod.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-events-from-within-tools.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"npm install @langchain/langgraph @langchain/anthropic @langchain/core zod\"\n```\n\n----------------------------------------\n\nTITLE: Graph Visualization Setup\nDESCRIPTION: Setup for visualizing the state graph using Mermaid PNG rendering through tslab.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling-errors.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst graph2 = app2.getGraph();\nconst image2 = await graph2.drawMermaidPng();\nconst arrayBuffer2 = await image2.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer2));\n```\n\n----------------------------------------\n\nTITLE: Updating LangGraph Configuration for Custom Authentication\nDESCRIPTION: This JSON snippet shows how to update the langgraph.json configuration file to include the path to the custom authentication file.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/auth/custom_auth.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"node_version\": \"20\",\n  \"graphs\": {\n    \"agent\": \"./agent.mts:graph\"\n  },\n  \"env\": \".env\",\n  \"auth\": {\n    \"path\": \"./auth.mts:auth\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Third Agent Stream for Weather Query\nDESCRIPTION: Sets up a third agent configuration with a different thread ID to demonstrate providing custom feedback for a tool call.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nconst config3 = {\n  configurable: {\n    thread_id: \"3\"\n  }\n};\n\nconst userMessage3 = {\n  role: \"user\",\n  content: \"What's the weather in san francisco?\"\n};\n\nconsole.log(userMessage3);\n\nconst stream3 = await agent.stream([userMessage3], config3);\n\nfor await (const step of stream3) {\n  printStep(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Passing Model-Generated Tool Calls to ToolNode\nDESCRIPTION: Demonstrating how to invoke the ToolNode with a message containing tool calls that were generated by the chat model rather than manually created.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/tool-calling.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nawait toolNode.invoke({ messages: [await modelWithTools.invoke(\"what's the weather in sf?\")] })\n```\n\n----------------------------------------\n\nTITLE: Configuring LangSmith Tracing\nDESCRIPTION: Setting up optional environment variables for LangSmith tracing to enable observability of the langchain application.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nprocess.env.LANGCHAIN_TRACING_V2 = 'true'\nprocess.env.LANGCHAIN_API_KEY = 'YOUR_API_KEY'\n```\n\n----------------------------------------\n\nTITLE: Modifying Auth States with Scrapybara SDK\nDESCRIPTION: Example of how to modify existing authentication states using the Scrapybara SDK.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ScrapybaraClient } from \"scrapybara\";\n\nconst client = new ScrapybaraClient({ apiKey: \"<api_key>\" });\nconst instance = await client.get(\"<instance_id>\");\nawait instance.modifyAuth({ authStateId: \"your_existing_auth_state_id\", name: \"renamed_auth_state\" });\n```\n\n----------------------------------------\n\nTITLE: Creating a New LangGraph App\nDESCRIPTION: Command to create a new LangGraph app using the npm create command.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/langgraph-platform/local-server.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ npm create langgraph\n```\n\n----------------------------------------\n\nTITLE: Defining Grandchild Graph in LangGraph\nDESCRIPTION: This snippet defines a grandchild graph using LangGraph, which consists of a single node that modifies a state key. The code relies on the StateGraph and Annotation classes from the langgraph package.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-transform-state.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph, START, Annotation } from \"@langchain/langgraph\";\n\nconst GrandChildAnnotation = Annotation.Root({\n    myGrandchildKey: Annotation<string>,\n})\n\nconst grandchild1 = (state: typeof GrandChildAnnotation.State) => {\n    // NOTE: child or parent keys will not be accessible here\n    return {\n        myGrandchildKey: state.myGrandchildKey + \", how are you\"\n    }\n}\n\nconst grandchild = new StateGraph(GrandChildAnnotation)\n    .addNode(\"grandchild1\", grandchild1)\n    .addEdge(START, \"grandchild1\")\n\nconst grandchildGraph = grandchild.compile();\n```\n\n----------------------------------------\n\nTITLE: Setting API Key for Anthropic LLM - TypeScript\nDESCRIPTION: This snippet demonstrates how to set the API key for Anthropic, which is necessary for utilizing their language model within the LangGraph framework.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nprocess.env.ANTHROPIC_API_KEY = \"YOUR_API_KEY\";\n```\n\n----------------------------------------\n\nTITLE: Initializing Anthropic Chat Model\nDESCRIPTION: Code to initialize a ChatAnthropic model for use with LangGraph. Sets up the API key and creates a chat model instance using Claude 3.5 Sonnet.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/workflows/index.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatAnthropic } from \"@langchain/anthropic\";\n\nprocess.env.ANTHROPIC_API_KEY = \"<your_anthropic_key>\";\n\nconst llm = new ChatAnthropic({\n  model: \"claude-3-5-sonnet-latest\",\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI and LangSmith\nDESCRIPTION: Sets up environment variables for API keys and optional LangSmith tracing configuration for the simulation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n// Optional tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"sk_...\";\n// process.env.LANGCHAIN_TRACING_V2 = \"true\";\n// process.env.LANGCHAIN_PROJECT = \"Agent Simulation Evaluation: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Rendering Agent Outputs in LangChain Framework\nDESCRIPTION: Implements a helper function to format and output agent messages to the console. Recognizes updates and prints them categorically for AI, human, and tool messages while filtering unnecessary information.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\nconst prettyPrintMessages = (update: Record<string, any>) => {\n  // Handle tuple case with namespace\n  if (Array.isArray(update)) {\n    const [ns, updateData] = update;\n    // Skip parent graph updates in the printouts\n    if (ns.length === 0) {\n      return;\n    }\n\n    const graphId = ns[ns.length - 1].split(\":\")[0];\n    console.log(`Update from subgraph ${graphId}:\\n`);\n    update = updateData;\n  }\n\n  if (update.__metadata__?.cached) {\n    return;\n  }\n  // Print updates for each node\n  for (const [nodeName, updateValue] of Object.entries(update)) {\n    console.log(`Update from node ${nodeName}:\\n`);\n\n    const coercedMessages = addMessages([], updateValue.messages);\n    for (const message of coercedMessages) {\n      const textContent = typeof message.content === \"string\"\n        ? message.content\n        : JSON.stringify(message.content);\n      // Print message content based on role\n      if (message.getType() === \"ai\") {\n        console.log(\"=\".repeat(33) + \" Assistant Message \" + \"=\".repeat(33));\n        console.log(textContent);\n        console.log();\n      } else if (message.getType() === \"human\") {\n        console.log(\"=\".repeat(33) + \" Human Message \" + \"=\".repeat(33));\n        console.log(textContent);\n        console.log();\n      } else if (message.getType() === \"tool\") {\n        console.log(\"=\".repeat(33) + \" Tool Message \" + \"=\".repeat(33));\n        console.log(textContent);\n        console.log();\n      }\n    }\n    console.log(\"\\n\");\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Streaming Messages with the Message Filtering Agent\nDESCRIPTION: This snippet demonstrates how to stream messages to and from the message filtering agent. It configures the agent for streaming and processes the incoming messages, logging the content of the recent message to the console.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-conversation-history.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n\nconst messageFilteringConfig = { configurable: { thread_id: \"2\"}, streamMode: \"values\" as const }\n\nconst messageFilteringInput = new HumanMessage(\"hi! I'm bob\");\nfor await (const event of await messageFilteringApp.stream({\n    messages: [messageFilteringInput]\n}, messageFilteringConfig)) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n\nconsole.log(\"\\n\\n================================= END =================================\\n\\n\")\n\nconst messageFilteringInput2 = new HumanMessage(\"what's my name?\");\nfor await (const event of await messageFilteringApp.stream(\n  {\n    messages: [messageFilteringInput2]\n  },\n  messageFilteringConfig\n)) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (2) =================================`)\n    console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Necessary Packages using npm\nDESCRIPTION: Installs required packages for LangGraph JS workflow using npm. These packages include @langchain/langgraph, @langchain/anthropic, and @langchain/core.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/breakpoints.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Connecting to LangGraph with Authentication using Python Client\nDESCRIPTION: This Python code demonstrates how to connect to a LangGraph deployment using the Python client with custom authentication headers.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/auth/custom_auth.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph_sdk import get_client\n\nmy_token = \"your-token\" # In practice, you would generate a signed token with your auth provider\nclient = get_client(\n    url=\"http://localhost:2024\",\n    headers={\"Authorization\": f\"Bearer {my_token}\"}\n)\nthreads = await client.threads.search()\n```\n\n----------------------------------------\n\nTITLE: Invoking Agent and Printing Results - Python\nDESCRIPTION: This snippet demonstrates how to invoke the agent with user input and print the conversation messages to see the agents' memory context in action.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nlet result = await agent.invoke({\n  messages: [\n    {\n      role: \"user\",\n      content: \"I'm hungry. What should I eat?\",\n    },\n  ],\n});\n\nprintMessages(result.messages);\n```\n\n----------------------------------------\n\nTITLE: Connecting to LangGraph with Authentication using JavaScript Client\nDESCRIPTION: This JavaScript code demonstrates how to connect to a LangGraph deployment using the JavaScript client with custom authentication headers.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/auth/custom_auth.md#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst my_token = \"your-token\"; // In practice, you would generate a signed token with your auth provider\nconst client = new Client({\n  apiUrl: \"http://localhost:2024\",\n  headers: { Authorization: `Bearer ${my_token}` },\n});\nconst threads = await client.threads.search();\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph.js CLI using npx\nDESCRIPTION: Command to install LangGraph.js CLI using npx package runner.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/langgraph_cli.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx @langchain/langgraph-cli\n```\n\n----------------------------------------\n\nTITLE: Parallel Execution Pattern in LangGraph TypeScript\nDESCRIPTION: Demonstrates how to execute tasks in parallel by using Promise.all with mapped task calls, which is useful for improving performance in IO-bound operations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_23\n\nLANGUAGE: typescript\nCODE:\n```\nconst addOne = task(\"addOne\", (number: number) => number + 1);\n\nconst graph = entrypoint(\n  { checkpointer, name: \"graph\" },\n  async (numbers: number[]) => {\n    return await Promise.all(numbers.map(addOne));\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Commands for installing necessary npm packages including LangGraph, Anthropic, and other dependencies.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core zod\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph.js CLI using bun\nDESCRIPTION: Command to install LangGraph.js CLI using bun package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/langgraph_cli.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nbun add @langchain/langgraph-cli\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph CLI\nDESCRIPTION: Commands to install the LangGraph CLI either using npx or globally via npm.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/langgraph-platform/local-server.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ npx @langchain/langgraph-cli@latest\n\n# Or install globally, will be available as `langgraphjs`\n$ npm install -g @langchain/langgraph-cli\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for Python LangGraph Application with requirements.txt\nDESCRIPTION: Example directory structure for a Python LangGraph application using requirements.txt for dependency management. Shows the organization of modules, utilities, and configuration files.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/application_structure.md#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nmy-app/\n├── my_agent # all project code lies within here\n│   ├── utils # utilities for your graph\n│   │   ├── __init__.py\n│   │   ├── tools.py # tools for your graph\n│   │   ├── nodes.py # node functions for you graph\n│   │   └── state.py # state definition of your graph\n│   ├── requirements.txt # package dependencies\n│   ├── __init__.py\n│   └── agent.py # code for constructing your graph\n├── .env # environment variables\n└── langgraph.json # configuration file for LangGraph\n```\n\n----------------------------------------\n\nTITLE: Install LangGraph and Core packages\nDESCRIPTION: This command installs the necessary packages for using LangGraph: `@langchain/langgraph` and `@langchain/core`.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/command.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Defining Subgraph Nodes and Parent Graph in TypeScript\nDESCRIPTION: This snippet demonstrates how to define a simple graph with a subgraph node using TypeScript. The subgraph consists of two nodes that manage shared state, showcasing the use of annotations and graph edges.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-persistence.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { StateGraph, Annotation } from \"@langchain/langgraph\";\n\n// subgraph\n\nconst SubgraphStateAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n  bar: Annotation<string>,\n});\n\nconst subgraphNode1 = async (state: typeof SubgraphStateAnnotation.State) => {\n  return { bar: \"bar\" };\n};\n\nconst subgraphNode2 = async (state: typeof SubgraphStateAnnotation.State) => {\n  // note that this node is using a state key ('bar') that is only available in the subgraph\n  // and is sending update on the shared state key ('foo')\n  return { foo: state.foo + state.bar };\n};\n\nconst subgraph = new StateGraph(SubgraphStateAnnotation)\n  .addNode(\"subgraphNode1\", subgraphNode1)\n  .addNode(\"subgraphNode2\", subgraphNode2)\n  .addEdge(\"__start__\", \"subgraphNode1\")\n  .addEdge(\"subgraphNode1\", \"subgraphNode2\")\n  .compile();\n  \n// parent graph\nconst StateAnnotation = Annotation.Root({\n  foo: Annotation<string>,\n});\n\nconst node1 = async (state: typeof StateAnnotation.State) => {\n  return {\n    foo: \"hi! \" + state.foo,\n  };\n};\n\nconst builder = new StateGraph(StateAnnotation)\n  .addNode(\"node1\", node1)\n  // note that we're adding the compiled subgraph as a node to the parent graph\n  .addNode(\"node2\", subgraph)\n  .addEdge(\"__start__\", \"node1\")\n  .addEdge(\"node1\", \"node2\");\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables\nDESCRIPTION: Example of environment variables needed for the LangGraph app, including API keys for various services.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/langgraph-platform/local-server.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nLANGSMITH_API_KEY=lsv2...\nTAVILY_API_KEY=tvly-...\nANTHROPIC_API_KEY=sk-\nOPENAI_API_KEY=sk-...\n```\n\n----------------------------------------\n\nTITLE: Setting Anthropic API Key in TypeScript\nDESCRIPTION: This code sets up the Anthropic API key as an environment variable, necessary for utilizing Anthropic model features in LangGraph applications.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nprocess.env.ANTHROPIC_API_KEY = \"YOUR_API_KEY\";\n```\n\n----------------------------------------\n\nTITLE: Generating Graph Diagram in TSlab\nDESCRIPTION: This code snippet retrieves a graph representation, draws it using the Mermaid engine, and displays it as a PNG image using the TSlab notebook environment. It requires TSlab to be set up to run the code correctly.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-from-final-node.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst diagram = graph.getGraph();\nconst image = await diagram.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\ntslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Importing dotenv Configuration for Environment Variables in JavaScript\nDESCRIPTION: Imports the dotenv configuration to load environment variables from a .env file, specifically for the Tavily API key needed by the search tool.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport \"dotenv/config\";\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for LangGraph\nDESCRIPTION: Docker Compose YAML configuration for setting up LangGraph with Redis and PostgreSQL services.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/deploy-self-hosted.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nvolumes:\n    langgraph-data:\n        driver: local\nservices:\n    langgraph-redis:\n        image: redis:6\n        healthcheck:\n            test: redis-cli ping\n            interval: 5s\n            timeout: 1s\n            retries: 5\n    langgraph-postgres:\n        image: postgres:16\n        ports:\n            - \"5433:5432\"\n        environment:\n            POSTGRES_DB: postgres\n            POSTGRES_USER: postgres\n            POSTGRES_PASSWORD: postgres\n        volumes:\n            - langgraph-data:/var/lib/postgresql/data\n        healthcheck:\n            test: pg_isready -U postgres\n            start_period: 10s\n            timeout: 1s\n            retries: 5\n            interval: 5s\n    langgraph-api:\n        image: ${IMAGE_NAME}\n        ports:\n            - \"8123:8000\"\n        depends_on:\n            langgraph-redis:\n                condition: service_healthy\n            langgraph-postgres:\n                condition: service_healthy\n        env_file:\n            - .env\n        environment:\n            REDIS_URI: redis://langgraph-redis:6379\n            LANGSMITH_API_KEY: ${LANGSMITH_API_KEY}\n            POSTGRES_URI: postgres://postgres:postgres@langgraph-postgres:5432/postgres?sslmode=disable\n```\n\n----------------------------------------\n\nTITLE: Importing Pregel from LangGraph in TypeScript\nDESCRIPTION: Example of importing the Pregel class from a specific subpath in LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Pregel } from \"@langchain/langgraph/pregel\";\n```\n\n----------------------------------------\n\nTITLE: Creating Chart Generating Agent Node in LangGraph.js\nDESCRIPTION: This code snippet defines a node for a chart-generating agent within a LangGraph.js graph. It utilizes `agentStateModifier` to create a state modifier that includes the current files in the directory. The agent is constructed with `createReactAgent`, supplied with a language model (`docWritingLlm`), visualization tools (`readDocumentTool`, `chartTool`), and the generated state modifier. `prelude.pipe` adds file information into the agent's prompt. Finally, the node returns `runAgentNode` with the agent's state, the context-aware agent, and a name for the node.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_14\n\nLANGUAGE: javascript\nCODE:\n```\nconst chartGeneratingNode = async (\n  state: typeof DocWritingState.State,\n) => {{\n  const stateModifier = agentStateModifier(\n    \"You are a data viz expert tasked with generating charts for a research project.\" +\n    `${state.current_files}`,\n    [readDocumentTool, chartTool],\n    state.team_members ?? [],\n  )\n  const chartGeneratingAgent = createReactAgent({{\n    llm: docWritingLlm,\n    tools: [readDocumentTool, chartTool],\n    stateModifier,\n  }})\n  const contextAwareChartGeneratingAgent = prelude.pipe(chartGeneratingAgent);\n  return runAgentNode({ state, agent: contextAwareChartGeneratingAgent, name: \"ChartGenerator\" });\n}}\n\n```\n\n----------------------------------------\n\nTITLE: MkDocs Dependencies for Documentation Site\nDESCRIPTION: A list of MkDocs packages and plugins required for building the LanggraphJS documentation. Includes core MkDocs, API documentation generators, and various formatting and enhancement plugins.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs-requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmkdocs\nmkdocstrings\nmkdocs-jupyter\nmkdocs-redirects\nmkdocs-minify-plugin\nmkdocs-open-in-new-tab\nmkdocs-rss-plugin\nmkdocs-typedoc\nmarkdown-include\nmarkdown-callouts\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment and Dependencies\nDESCRIPTION: Installation commands for the complete setup including OpenAI integration and API key configuration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-supervisor/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph-supervisor @langchain/langgraph @langchain/core @langchain/openai\n\nexport OPENAI_API_KEY=<your_api_key>\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph.js CLI using npm\nDESCRIPTION: Command to install LangGraph.js CLI using npm package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/langgraph_cli.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph-cli\n```\n\n----------------------------------------\n\nTITLE: LangSmith Tracing Configuration\nDESCRIPTION: Optional environment variable setup for LangSmith tracing functionality.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n// process.env.LANGCHAIN_TRACING_V2 = \"true\";\n// process.env.LANGCHAIN_ENDPOINT = \"https://api.smith.langchain.com\";\n// process.env.LANGCHAIN_API_KEY = \"<your-api-key>\"\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages in Bash\nDESCRIPTION: This Bash command installs necessary packages for utilizing the Postgres checkpointer in LangGraph.js. The packages include `@langchain/langgraph`, `@langchain/core`, and `@langchain/langgraph-checkpoint-postgres`. These are prerequisites for using the PostgresSaver class.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-postgres.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/core @langchain/langgraph-checkpoint-postgres\n```\n\n----------------------------------------\n\nTITLE: Starting New Conversational Thread in LangChain\nDESCRIPTION: This code snippet sets up a new conversational thread in a persistent LangChain workflow, switching context by changing the thread_id. This change ensures that the new conversation doesn't share memory with previous threads, effectively starting fresh.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nconfig = { configurable: { thread_id: \"conversation-2\" } };\ninputs = { messages: [{ role: \"user\", content: \"you forgot?\" }] };\nfor await (\n  const { messages } of await persistentGraph.stream(inputs, {\n    ...config,\n    streamMode: \"values\",\n  })\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph Dependencies\nDESCRIPTION: Commands for installing the required npm packages for LangGraph supervisor implementation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-supervisor/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph-supervisor @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Setting Static Breakpoints at Run Time in TypeScript\nDESCRIPTION: Shows how to set static breakpoints before and after node execution at run time, execute the graph until a breakpoint, update the graph state, and continue execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/breakpoints.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nawait graph.invoke(\n    inputs,\n    { \n        configurable: { thread_id: \"someThread\" },\n        interruptBefore: [\"nodeA\"],\n        interruptAfter: [\"nodeB\", \"nodeC\"]\n    }\n);\n\nconst threadConfig = {\n    configurable: {\n        thread_id: \"someThread\"\n    }\n};\n\n// Run the graph until the breakpoint\nawait graph.invoke(inputs, threadConfig);\n\n// Optionally update the graph state based on user input\nawait graph.updateState(update, threadConfig);\n\n// Resume the graph\nawait graph.invoke(null, threadConfig);\n```\n\n----------------------------------------\n\nTITLE: Getting Graph State in LangGraph.js\nDESCRIPTION: Demonstrates how to fetch the latest graph checkpoint using getState() method. Returns a snapshot containing the current state and configuration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nlet snapshot = await graphWithInterrupt.getState(config);\nsnapshot.next;\n```\n\n----------------------------------------\n\nTITLE: Setup LangGraph Dependencies with npm\nDESCRIPTION: This bash command installs the necessary dependencies for running the LangGraph workflow with persistence features. It includes packages from langchain and core utilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence-functional.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core zod\n```\n\n----------------------------------------\n\nTITLE: Configuring LangSmith Tracing in TypeScript\nDESCRIPTION: Optional setup for enabling LangSmith tracing for enhanced observability.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/delete-messages.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_API_KEY = \"YOUR_API_KEY\";\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: This command sets the OpenAI API key as an environment variable. The API key is essential for authenticating requests to the OpenAI service and utilizing its language models.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-multiple.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Formatting Code in LangGraph Project using Bash\nDESCRIPTION: Commands to run Prettier for formatting and checking code style in the project.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nyarn format\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn format:check\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable in JavaScript\nDESCRIPTION: This snippet comments out a line of code for setting an environment variable needed for accessing the OpenAI API. It should be uncommented and replaced with a valid API key when actually used.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-values.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk-...\";\n```\n\n----------------------------------------\n\nTITLE: Adding Conditional Edges in Python for LangGraph\nDESCRIPTION: Demonstrates how to add conditional edges to a graph in Python using the add_conditional_edges method. This snippet shows how to define path maps for routing function outputs.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/langgraph_studio.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ngraph.add_conditional_edges(\"node_a\", routing_function, {True: \"node_b\", False: \"node_c\"})\n```\n\n----------------------------------------\n\nTITLE: Verifying Agent State Before Continuing\nDESCRIPTION: This Python snippet retrieves the current state of the ReAct agent to check whether the graph has paused correctly. The output indicates the next state the agent should proceed with.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-human-in-the-loop.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconst state = await agent.getState(config)\nconsole.log(state.next)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages - Bash\nDESCRIPTION: This snippet shows the command to install the necessary packages for using LangGraphJS with the OpenAI model and Zod for schema validation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-return-structured-output.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/openai @langchain/core zod\n```\n\n----------------------------------------\n\nTITLE: Setting Anthropic API Key\nDESCRIPTION: Sets the Anthropic API key as an environment variable. Replace 'YOUR_API_KEY' with your actual API key.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-events-from-within-tools.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"process.env.ANTHROPIC_API_KEY = 'YOUR_API_KEY'\"\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in TypeScript\nDESCRIPTION: Sets the OpenAI API key as an environment variable for authentication.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/delete-messages.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nprocess.env.OPENAI_API_KEY = 'YOUR_API_KEY';\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph.js CLI using pnpm\nDESCRIPTION: Command to install LangGraph.js CLI using pnpm package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/langgraph_cli.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @langchain/langgraph-cli\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI and LangGraph Packages - Bash\nDESCRIPTION: This snippet installs the necessary `openai`, `@langchain/langgraph`, and `@langchain/core` packages using npm to stream tokens from OpenAI models. Ensure the system has Node.js installed and environmental variables set for the OpenAI API key.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-tokens-without-langchain.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ npm install openai @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Environment Configuration Setup\nDESCRIPTION: Sets up environment variables for OpenAI, Tavily API keys and optional LangSmith tracing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/agent_supervisor.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n// process.env.TAVILY_API_KEY = \"sk_...\";\n// Optional tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"sk_...\";\n// process.env.LANGCHAIN_TRACING_V2 = \"true\";\n// process.env.LANGCHAIN_PROJECT = \"Agent Supervisor: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Connecting to LangGraph with Authentication using CURL\nDESCRIPTION: This bash command demonstrates how to make an authenticated request to a LangGraph deployment using CURL with a bearer token.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/auth/custom_auth.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -H \"Authorization: Bearer ${your-token}\" http://localhost:2024/threads\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LangGraph\nDESCRIPTION: Command to install necessary npm packages for working with LangGraph, LangChain Core, and OpenAI integration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/core @langchain/openai\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for LangGraph Human-in-the-Loop Example\nDESCRIPTION: Command to install the required npm packages for implementing human-in-the-loop workflows with LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/openai @langchain/core zod\n```\n\n----------------------------------------\n\nTITLE: Running Documentation Server for LangGraph Project in Bash\nDESCRIPTION: Commands to set up and run the documentation server locally.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\npip install -r docs-requirements.txt\nmake serve-docs\n```\n\n----------------------------------------\n\nTITLE: LangGraph.js Workflow Success Response\nDESCRIPTION: Shows the successful response from the resumed workflow execution after error recovery.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/functional_api.md#2025-04-21_snippet_30\n\nLANGUAGE: typescript\nCODE:\n```\n\"Ran slow task.\";\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key - Bash\nDESCRIPTION: This snippet illustrates how to set the OpenAI API key as an environment variable, which is required for the language model to function correctly.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Defining Model and Tools for Weather Retrieval\nDESCRIPTION: Sets up an OpenAI chat model and a weather retrieval tool with location-based weather prediction logic\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o-mini\",\n});\n\nconst getWeather = tool(async ({ location }) => {\n  const lowercaseLocation = location.toLowerCase();\n  if (lowercaseLocation.includes(\"sf\") || lowercaseLocation.includes(\"san francisco\")) {\n    return \"It's sunny!\";\n  } else if (lowercaseLocation.includes(\"boston\")) {\n    return \"It's rainy!\";\n  } else {\n    return `I am not sure what the weather is in ${location}`;\n  }\n}, {\n  name: \"getWeather\",\n  schema: z.object({\n    location: z.string().describe(\"Location to get the weather for\"),\n  }),\n  description: \"Call to get the weather from a specific location.\",\n});\n\nconst tools = [getWeather];\n```\n\n----------------------------------------\n\nTITLE: Starting LangGraph Development Server\nDESCRIPTION: Command to start the LangGraph development server locally without opening the browser automatically.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/http/custom_routes.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpx langgraph-cli@latest dev --no-browser\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables - Python\nDESCRIPTION: This code snippet sets environment variables required for configuring the OpenAI API key and optional tracing in LangSmith. This configuration enables tracing and background processing for the LangChain agent functionalities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-system-prompt.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\"\n// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"ReAct Agent with system prompt: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph CUA with Yarn\nDESCRIPTION: Command to install LangGraph CUA and its required peer dependencies using Yarn package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph-cua @langchain/langgraph @langchain/core @langchain/openai\n```\n\n----------------------------------------\n\nTITLE: Setting Together AI API Key Environment Variable\nDESCRIPTION: Sets the environment variable for authenticating with Together AI's API, which is required to use their hosted Llama 3.1 model.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nTOGETHER_AI_API_KEY=\"your_key_here\"\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph and OpenAI Packages\nDESCRIPTION: This command installs the required packages for using LangGraph with OpenAI. It ensures that all the necessary dependencies are available for building and running the LangGraph application.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-multiple.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/openai @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for LangChain and OpenAI\nDESCRIPTION: This snippet demonstrates how to configure environment variables for OpenAI API and LangChain tracing, which are optional but facilitate enhanced observability when interacting with the ReAct agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-memory.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\"\n// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"ReAct Agent with memory: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Revising a Tool Call with Updated Arguments\nDESCRIPTION: Creates a Command to update the previously generated tool call by providing new location data ('SF, CA'). This demonstrates how to modify tool call arguments before execution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n// highlight-next-line\nconst humanInput2 = new Command({\n  // highlight-next-line\n  resume: {\n    // highlight-next-line\n    action: \"update\",\n    // highlight-next-line\n    data: { location: \"SF, CA\" },\n    // highlight-next-line\n  },\n  // highlight-next-line\n});\n\nconst resumedStream2 = await agent.stream(humanInput2, config2)\n\nfor await (const step of resumedStream2) {\n  printStep(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Loading Environment Variables with dotenv\nDESCRIPTION: Code for loading environment variables from a .env file in the root of the examples folder. This is commented out code that would use dotenv to configure environment variables.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_agentic_rag.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n// import dotenv from 'dotenv';\n\n// dotenv.config();\n```\n\n----------------------------------------\n\nTITLE: Installing Hono Dependency\nDESCRIPTION: Command to install the Hono package as a dependency for the LangGraph project.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/http/custom_middleware.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install hono\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for API Keys\nDESCRIPTION: This snippet demonstrates how to set environment variables for Anthropic API key and optionally for LangSmith tracing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-conversation-history.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ANTHROPIC_API_KEY=your_api_key\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\nexport LANGCHAIN_API_KEY=your_api_key\n```\n\n----------------------------------------\n\nTITLE: Simple Markdown Documentation\nDESCRIPTION: Documentation detailing self-hosted deployment options and requirements for LangGraph Platform, including both Enterprise and Lite versions, along with infrastructure setup instructions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/self_hosted.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Self-Hosted\n\n!!! note Prerequisites\n\n    - [LangGraph Platform](./langgraph_platform.md)\n    - [Deployment Options](./deployment_options.md)\n\n## Versions\n\nThere are two versions of the self hosted deployment: [Self-Hosted Enterprise](./deployment_options.md#self-hosted-enterprise) and [Self-Hosted Lite](./deployment_options.md#self-hosted-lite).\n\n### Self-Hosted Lite\n\nThe Self-Hosted Lite version is a limited version of LangGraph Platform that you can run locally or in a self-hosted manner (up to 1 million nodes executed).\n\nWhen using the Self-Hosted Lite version, you authenticate with a [LangSmith](https://smith.langchain.com/) API key.\n\n### Self-Hosted Enterprise\n\nThe Self-Hosted Enterprise version is the full version of LangGraph Platform.\n\nTo use the Self-Hosted Enterprise version, you must acquire a license key that you will need to pass in when running the Docker image. To acquire a license key, please email sales@langchain.dev.\n\n## Requirements\n\n- You use `langgraph-cli` and/or [LangGraph Studio](./langgraph_studio.md) app to test graph locally.\n- You use `langgraph build` command to build image.\n\n## How it works\n\n- Deploy Redis and Postgres instances on your own infrastructure.\n- Build the docker image for [LangGraph Server](./langgraph_server.md) using the [LangGraph CLI](./langgraph_cli.md)\n- Deploy a web server that will run the docker image and pass in the necessary environment variables.\n\nSee the [how-to guide](../how-tos/deploy-self-hosted.md)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LangGraph and LangChain\nDESCRIPTION: This snippet shows how to install the necessary packages for working with LangGraph and LangChain using yarn.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-conversation-history.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add langchain @langchain/anthropic @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Setting API Keys for OpenAI in Python\nDESCRIPTION: This snippet sets the OpenAI API key in the environment to enable communication with the OpenAI language model. The API key needs to be configured for authorization.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LanggraphJS Customer Support Chatbot\nDESCRIPTION: Installs the necessary dependencies including LanggraphJS, LangChain Community, and LangChain Core packages using Yarn package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/community @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Using Synchronous Python Client for LangGraph SDK\nDESCRIPTION: Example of initializing and using the synchronous client for the LangGraph SDK in Python. It shows how to import the synchronous client, initialize it with a URL and API key, and perform a synchronous search operation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/sdk.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph_sdk import get_sync_client\n\nclient = get_sync_client(url=..., api_key=...)\nclient.assistants.search()\n```\n\n----------------------------------------\n\nTITLE: Loading Environment Variables in Node.js\nDESCRIPTION: Imports dotenv configuration to load environment variables from a .env file in the root directory.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport \"dotenv/config\";\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages\nDESCRIPTION: Install the necessary packages for the chat agent executor using yarn.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add langchain @langchain/openai @langchain/langgraph\n```\n\n----------------------------------------\n\nTITLE: Initializing Test Checkpointer with Local PostgreSQL\nDESCRIPTION: Example of initializing a PostgresSaver instance with a local test database connection string.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint-postgres/README.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst testCheckpointer = PostgresSaver.fromConnString(\n  \"postgresql://user:password@localhost:5434/testdb\"\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for API Keys - JavaScript\nDESCRIPTION: This code snippet shows how to set up environment variables for the OpenAI API key and LangChain API key optionally for tracing purposes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-tokens.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\";\n// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n// process.env.LANGCHAIN_TRACING = \"true\";\n// process.env.LANGCHAIN_PROJECT = \"Stream Tokens: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Resolving Core Dependencies with Yarn\nDESCRIPTION: Example package.json configuration for yarn, using the 'resolutions' field to specify an exact version of @langchain/core to resolve version conflicts.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-ecosystem-dependencies.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"your-project\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"engines\": {\n    \"node\": \">=18\"\n  },\n  \"dependencies\": {\n    \"@langchain/anthropic\": \"^0.2.15\",\n    \"@langchain/langgraph\": \"^0.2.0\"\n  },\n  \"resolutions\": {\n    \"@langchain/core\": \"0.2.31\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Self-RAG Graph Components in TypeScript\nDESCRIPTION: This snippet sets up the necessary imports and initializes the language model for use throughout the graph. It includes imports from Zod, LangChain, and other dependencies required for the Self-RAG implementation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { z } from \"zod\";\nimport { ChatPromptTemplate } from \"@langchain/core/prompts\";\nimport { pull } from \"langchain/hub\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { StringOutputParser } from \"@langchain/core/output_parsers\";\nimport type { RunnableConfig } from \"@langchain/core/runnables\";\nimport { formatDocumentsAsString } from \"langchain/util/document\";\n\n// Define the LLM once. We'll reuse it throughout the graph.\nconst model = new ChatOpenAI({\n  model: \"gpt-4o\",\n  temperature: 0,\n});\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph.js with npm\nDESCRIPTION: Command to install the LangGraph.js library and its core dependency using npm package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Message Deletion and Management with LangGraph\nDESCRIPTION: Shows techniques for adding and removing messages from the state using RemoveMessage and MessagesAnnotation, enabling fine-grained control over conversation history\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/memory.md#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { RemoveMessage, AIMessage } from \"@langchain/core/messages\";\nimport { MessagesAnnotation } from \"@langchain/langgraph\";\n\ntype State = typeof MessagesAnnotation.State;\n\nfunction myNode1(state: State) {\n  return { messages: [new AIMessage({ content: \"Hi\" })] };\n}\n\nfunction myNode2(state: State) {\n  const deleteMessages = state.messages\n    .slice(0, -2)\n    .map((m) => new RemoveMessage({ id: m.id }));\n  return { messages: deleteMessages };\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Anthropic API Key\nDESCRIPTION: This command sets the environment variable for the Anthropic API key, which is required for using their LLM in the example.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ANTHROPIC_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Setting LangSmith Tracing Keys - Bash\nDESCRIPTION: This snippet shows how to optionally configure LangSmith tracing by setting corresponding environment variables, enhancing observability for the memory store operations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGCHAIN_TRACING_V2=\"true\"\\nexport LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\\nexport LANGCHAIN_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph and LangCore Packages\nDESCRIPTION: This code snippet demonstrates how to install the necessary packages for LangGraph development using npm. These packages are required to create and manage graphs in LangGraph projects.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph-transform-state.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Resolving Core Dependencies with PNPM\nDESCRIPTION: Example package.json configuration for pnpm, using the nested 'pnpm.overrides' field to specify an exact version of @langchain/core to resolve version conflicts.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/manage-ecosystem-dependencies.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"your-project\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"engines\": {\n    \"node\": \">=18\"\n  },\n  \"dependencies\": {\n    \"@langchain/anthropic\": \"^0.2.15\",\n    \"@langchain/langgraph\": \"^0.2.0\"\n  },\n  \"pnpm\": {\n    \"overrides\": {\n      \"@langchain/core\": \"0.2.31\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Triggering Conversation Summarization\nDESCRIPTION: Sending an additional message that exceeds the threshold of 6 messages, which triggers the summarization process. This demonstrates how the system automatically summarizes the conversation history.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nconst inputMessage4 = new HumanMessage(\"i like how much they win\")\nconsole.log(inputMessage4.content)\nfor await (const event of await app.stream({ messages: [inputMessage4] }, config)) {\n  printUpdate(event)\n}\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Node.js\nDESCRIPTION: This code snippet demonstrates how to set the OpenAI API key as an environment variable in a Node.js application.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n```\n\n----------------------------------------\n\nTITLE: Tool Integration with Command for State Update in TypeScript\nDESCRIPTION: The snippet demonstrates how to integrate tools with the 'Command' object to update graph states. It involves looking up user information and updating the state accordingly, ensuring that returned messages include 'ToolMessage' for maintaining message history integrity. Dependencies include 'LangGraphJS' and 'LangChainJS' libraries.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/low_level.md#2025-04-21_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tool } from \"@langchain/core/tools\";\n\nconst lookupUserInfo = tool(async (input, config) => {\n  const userInfo = getUserInfo(config);\n  return new Command({\n    // update state keys\n    update: {\n      user_info: userInfo,\n      messages: [\n        new ToolMessage({\n          content: \"Successfully looked up user information\",\n          tool_call_id: config.toolCall.id,\n        }),\n      ],\n    },\n  });\n}, {\n  name: \"lookup_user_info\",\n  description: \"Use this to look up user information to better assist them with their questions.\",\n  schema: z.object(...)\n});\n```\n\n----------------------------------------\n\nTITLE: Initialize Project Directory\nDESCRIPTION: Commands to create and navigate to the project directory.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/quickstart.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir langgraph-agent\ncd langgraph-agent\n```\n\n----------------------------------------\n\nTITLE: Using the React Agent to Get Weather in Italian - Python\nDESCRIPTION: This snippet shows how to utilize the created React agent to fetch weather information based on user input. The output is logged to the console, demonstrating the agent's responsiveness to the system prompt.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-system-prompt.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlet inputs = { messages: [{ role: \"user\", content: \"what is the weather in NYC?\" }] };\nlet stream = await agent.stream(inputs, {\n  streamMode: \"values\",\n});\n\nfor await (\n  const { messages } of stream\n) {\n  let msg = messages[messages?.length - 1];\n  if (msg?.content) {\n    console.log(msg.content);\n  } else if (msg?.tool_calls?.length > 0) {\n    console.log(msg.tool_calls);\n  } else {\n    console.log(msg);\n  }\n  console.log(\"-----\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Using Asynchronous Python Client for LangGraph SDK\nDESCRIPTION: Example of initializing and using the asynchronous client for the LangGraph SDK in Python. It demonstrates importing the client, initializing it with a URL and API key, and performing an asynchronous search operation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/sdk.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=..., api_key=...)\nawait client.assistants.search()\n```\n\n----------------------------------------\n\nTITLE: Adding New Entrypoint in LangGraph JavaScript Configuration\nDESCRIPTION: Example of adding a new entrypoint in the LangGraph project configuration.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nconst entrypoints = {\n  // ...\n  tools: \"tools/index\",\n};\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph Dependencies\nDESCRIPTION: Command to install the required npm packages for building LangGraph applications.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraph.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LangGraph\nDESCRIPTION: This command installs the necessary npm packages for using LangGraph with Anthropic's API and Zod for schema validation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/edit-graph-state.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core zod\n```\n\n----------------------------------------\n\nTITLE: Initializing Second Agent Stream for Weather Query\nDESCRIPTION: Sets up another agent configuration with a different thread ID and processes a similar weather query. This configuration is used to demonstrate tool call revision.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nconst config2 = {\n  configurable: {\n    thread_id: \"2\"\n  }\n};\n\nconst userMessage2 = {\n  role: \"user\",\n  content: \"What's the weather in san francisco?\"\n};\n\nconsole.log(userMessage2);\n\nconst stream2 = await agent.stream([userMessage2], config2);\n\nfor await (const step of stream2) {\n  printStep(step);\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up the OpenAI Chat Model\nDESCRIPTION: This code initializes the ChatOpenAI model and binds the defined tools to it for function calling capabilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  temperature: 0,\n  model: \"gpt-4o\",\n});\n\nconst boundModel = model.bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: Visualizing Authentication Flow with Mermaid Diagram\nDESCRIPTION: This diagram illustrates the typical interaction between a client application, authentication provider, and LangGraph backend during the authentication process. It shows the flow from login to resource access, including token validation and user info fetching.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/auth.md#2025-04-21_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client as Client App\n    participant Auth as Auth Provider\n    participant LG as LangGraph Backend\n\n    Client->>Auth: 1. Login (username/password)\n    Auth-->>Client: 2. Return token\n    Client->>LG: 3. Request with token\n    Note over LG: 4. Validate token (authenticate())\n    LG-->>Auth:  5. Fetch user info\n    Auth-->>LG: 6. Confirm validity\n    Note over LG: 7. Apply access control (on())\n    LG-->>Client: 8. Return resources\n```\n\n----------------------------------------\n\nTITLE: Running Tests for LangGraph Project in Bash\nDESCRIPTION: Commands to run unit tests, integration tests, and single tests in the project.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nyarn test\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn test:single /path/to/yourtest.test.ts\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn test:int\n```\n\n----------------------------------------\n\nTITLE: Downloading Ollama Models\nDESCRIPTION: Command to pull required Llama3 and mxbai-embed-large models using Ollama.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_adaptive_rag_local.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nollama pull llama3 mxbai-embed-large\n```\n\n----------------------------------------\n\nTITLE: Initializing ChatOpenAI Model for ReWOO Planner\nDESCRIPTION: Instantiates a ChatOpenAI model with GPT-4o and zero temperature for deterministic outputs, to be used as the planner component of the ReWOO agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o\",\n  temperature: 0,\n});\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph.js and Core Dependencies\nDESCRIPTION: Command to install LangGraph.js and its core dependencies using npm.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Development Setup Commands for LangGraph\nDESCRIPTION: Series of bash commands for setting up a local development environment for LangGraph CUA.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/langchain-ai/langgraphjs.git\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn install\n```\n\nLANGUAGE: bash\nCODE:\n```\ncd libs/langgraph-cua\n```\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\nLANGUAGE: bash\nCODE:\n```\nyarn test:single src/tests/cua.int.test.ts\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for LangGraph - Bash\nDESCRIPTION: This snippet shows how to install the required dependencies for the LangGraph example, ensuring compatibility with the specified version of the library.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-network-functional.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core zod\n```\n\n----------------------------------------\n\nTITLE: Initializing RunnableLambda for file system prelude in LangGraph.js\nDESCRIPTION: This code snippet initializes a `RunnableLambda` function that retrieves a list of files in a specified directory (`WORKING_DIRECTORY`) and formats it into a string. This string is then added to the agent's state, so that the agent is aware of existing files.  The function first checks if the directory exists and creates it if it doesn't. It handles potential errors during directory reading.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nimport { RunnableLambda } from \"@langchain/core/runnables\";\n\nconst prelude = new RunnableLambda({\n  func: async (state: {\n    messages: BaseMessage[];\n    next: string;\n    instructions: string;\n  }) => {\n    let writtenFiles: string[] = [];\n    if (\n      !(await fs\n        .stat(WORKING_DIRECTORY)\n        .then(() => true)\n        .catch(() => false))\n    ) {\n      await fs.mkdir(WORKING_DIRECTORY, { recursive: true });\n    }\n    try {\n      const files = await fs.readdir(WORKING_DIRECTORY);\n      for (const file of files) {\n        writtenFiles.push(file);\n      }\n    } catch (error) {\n      console.error(error);\n    }\n    const filesList = writtenFiles.length > 0\n      ? \"\\nBelow are files your team has written to the directory:\\n\" +\n        writtenFiles.map((f) => ` - ${f}`).join(\"\\n\")\n      : \"No files written.\";\n    return { ...state, current_files: filesList };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for Python LangGraph Application with pyproject.toml\nDESCRIPTION: Example directory structure for a Python LangGraph application using pyproject.toml for modern dependency management. Shows the organization of modules, utilities, and configuration files.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/application_structure.md#2025-04-21_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nmy-app/\n├── my_agent # all project code lies within here\n│   ├── utils # utilities for your graph\n│   │   ├── __init__.py\n│   │   ├── tools.py # tools for your graph\n│   │   ├── nodes.py # node functions for you graph\n│   │   └── state.py # state definition of your graph\n│   ├── __init__.py\n│   └── agent.py # code for constructing your graph\n├── .env # environment variables\n├── langgraph.json  # configuration file for LangGraph\n└── pyproject.toml # dependencies for your project\n```\n\n----------------------------------------\n\nTITLE: Running Next.js Development Server\nDESCRIPTION: Commands to start the Next.js development server using npm, yarn, or pnpm. This allows developers to run the project locally for development and testing purposes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/environment_tests/test-exports-vercel/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: LangChain Environment Configuration for GPT-4o\nDESCRIPTION: The setup snippet shows optional environment variable configuration for integrating LangSmith tracing with OpenAI's GPT-4o model. This setup helps achieve observability using API keys. The environment requires specific variables, such as LANGCHAIN_CALLBACKS_BACKGROUND, LANGCHAIN_TRACING_V2, and LANGCHAIN_PROJECT, to enable features for better tracing of different processes.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"Persistence: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Interacting with the Chatbot\nDESCRIPTION: Demonstrating how to interact with the chatbot by sending messages, streaming responses, and checking the conversation state. This shows how the summarization triggers after exceeding the message threshold.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport { HumanMessage } from \"@langchain/core/messages\";\n\nconst config = { configurable: { thread_id: \"4\" }, streamMode: \"updates\" as const }\n\nconst inputMessage = new HumanMessage(\"hi! I'm bob\")\nconsole.log(inputMessage.content)\nfor await (const event of await app.stream({ messages: [inputMessage] }, config)) {\n  printUpdate(event)\n}\n\nconst inputMessage2 = new HumanMessage(\"What did I sat my name was?\")\nconsole.log(inputMessage2.content)\nfor await (const event of await app.stream({ messages: [inputMessage2] }, config)) {\n  printUpdate(event)\n}\n\nconst inputMessage3 = new HumanMessage(\"i like the celtics!\")\nconsole.log(inputMessage3.content)\nfor await (const event of await app.stream({ messages: [inputMessage3] }, config)) {\n  printUpdate(event)\n}\n```\n\n----------------------------------------\n\nTITLE: Running Graph with Human Interruption and Resumption\nDESCRIPTION: Executes a configured LangGraph state graph to illustrate interruptions and continuation of execution using JavaScript. It shows the effects of the predefined breakpoints and how user approval affects graph flow.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/breakpoints.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n// Input\nconst initialInput = { input: \"hello world\" };\n\n// Thread\nconst graphStateConfig = { configurable: { thread_id: \"1\" }, streamMode: \"values\" as const };\n\n// Run the graph until the first interruption\nfor await (const event of await graph.stream(initialInput, graphStateConfig)) {\n  console.log(`--- ${event.input} ---`);\n}\n\n// Will log when the graph is interrupted, after step 2.\nconsole.log(\"---GRAPH INTERRUPTED---\");\n\n// If approved, continue the graph execution. We must pass `null` as\n// the input here, or the graph will\nfor await (const event of await graph.stream(null, graphStateConfig)) {\n  console.log(`--- ${event.input} ---`);\n}\n\n```\n\n----------------------------------------\n\nTITLE: Creating Tasks for Model and Tool Interactions\nDESCRIPTION: Defines tasks for calling the language model and executing tool calls with support for tool-based message generation\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls-functional.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport {\n  type BaseMessageLike,\n  AIMessage,\n  ToolMessage,\n} from \"@langchain/core/messages\";\nimport { type ToolCall } from \"@langchain/core/messages/tool\";\nimport { task } from \"@langchain/langgraph\";\n\nconst toolsByName = Object.fromEntries(tools.map((tool) => [tool.name, tool]));\n\nconst callModel = task(\"callModel\", async (messages: BaseMessageLike[]) => {\n  const response = await model.bindTools(tools).invoke(messages);\n  return response;\n});\n\nconst callTool = task(\n  \"callTool\",\n  async (toolCall: ToolCall): Promise<AIMessage> => {\n    const tool = toolsByName[toolCall.name];\n    const observation = await tool.invoke(toolCall.args);\n    return new ToolMessage({ content: observation, tool_call_id: toolCall.id });\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Invoking Graph with Thread and User ID\nDESCRIPTION: This snippet highlights invoking a compiled graph with specified thread and user configurations. It simulates a user interaction with a chatbot using memory storage, where data from previous conversations is accessible for use in new threads.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/persistence.md#2025-04-21_snippet_12\n\nLANGUAGE: TypeScript\nCODE:\n```\n// Invoke the graph\nconst user_id = \"1\";\nconst config = { configurable: { thread_id: \"1\", user_id } };\n\n// First let's just say hi to the AI\nconst stream = await graph.stream(\n  { messages: [{ role: \"user\", content: \"hi\" }] },\n  { ...config, streamMode: \"updates\" },\n);\n\nfor await (const update of stream) {\n  console.log(update);\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Required NPM Dependencies for LangGraph Project\nDESCRIPTION: Bash command to install the necessary npm packages for the LangGraph project, including LangChain and OpenAI integrations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install langchain @langchain/community @langchain/openai @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Invalid Node Return in LangGraph StateGraph (TypeScript)\nDESCRIPTION: This snippet shows how to set up a LangGraph StateGraph with a node that incorrectly returns an array instead of an object, which will cause an error.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst StateAnnotation = Annotation.Root({\n  someKey: Annotation<string>,\n});\n\nconst graph = new StateGraph(StateAnnotation)\n  .addNode(\"badNode\", async (state) => {\n    // Should return an empty object, one with a value for \"someKey\", or undefined\n    return [\"whoops!\"];\n  })\n  ...\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAI Model and Weather Tool for ReAct Agent\nDESCRIPTION: Implementation of an OpenAI chat model and a sample weather tool for use in a ReAct agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { tool } from \"@langchain/core/tools\";\nimport { z } from \"zod\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o-mini\",\n});\n\nconst getWeather = tool(async ({ location }) => {\n  // This is a placeholder for the actual implementation\n  const lowercaseLocation = location.toLowerCase();\n  if (lowercaseLocation.includes(\"sf\") || lowercaseLocation.includes(\"san francisco\")) {\n    return \"It's sunny!\";\n  } else if (lowercaseLocation.includes(\"boston\")) {\n    return \"It's rainy!\";\n  } else {\n    return `I am not sure what the weather is in ${location}`;\n  }\n}, {\n  name: \"getWeather\",\n  schema: z.object({\n    location: z.string().describe(\"Location to get the weather for\"),\n  }),\n  description: \"Call to get the weather from a specific location.\",\n});\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Side Effects Before Interrupt (Bad Practice)\nDESCRIPTION: This code example shows the incorrect way of placing side effects before an interrupt call. API calls placed before interrupts will be re-executed when the node is resumed, which can lead to duplicate calls and unexpected behavior.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt } from \"@langchain/langgraph\";\n\nfunction humanNode(state: typeof GraphAnnotation.State) {\n  /**\n   * Human node with validation.\n   */\n  apiCall(); // This code will be re-executed when the node is resumed.\n\n  const answer = interrupt(question);\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Required NPM Packages - Bash\nDESCRIPTION: This snippet outlines the npm command used to install all required dependencies for the LangGraph example demonstrating cross-thread persistence.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence-functional.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/openai @langchain/anthropic @langchain/core uuid\n```\n\n----------------------------------------\n\nTITLE: Initializing Potentially Infinite Loop in LangGraph StateGraph (TypeScript)\nDESCRIPTION: This code snippet demonstrates a StateGraph configuration that could potentially cause an infinite loop. It creates a graph with two nodes, 'a' and 'b', with edges connecting them in both directions, which may lead to endless recursion.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst graph = new StateGraph(...)\n  .addNode(\"a\", ...)\n  .addNode(\"b\", ...)\n  .addEdge(\"a\", \"b\")\n  .addEdge(\"b\", \"a\")\n  ...\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Keys for OpenAI and LangSmith\nDESCRIPTION: This snippet sets up the environment variables for OpenAI API key and optionally LangSmith tracing for observability.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/force-calling-a-tool-first.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\";\n// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"Force Calling a Tool First: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Inspecting the Final Event\nDESCRIPTION: Inspects the final event to get the last message from the agent.  It logs the type, content, and tool calls of the final message.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-events-from-within-tools.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nconst finalMessage = finalEvent?.data.output;\nconsole.dir(\n  {\n    type: finalMessage._getType(),\n    content: finalMessage.content,\n    tool_calls: finalMessage.tool_calls,\n  },\n  { depth: null }\n);\n```\n\n----------------------------------------\n\nTITLE: Creating the LangGraph Workflow for Agent Simulation\nDESCRIPTION: Sets up the StateGraph in LangGraph.js that defines the workflow between the chat bot and simulated user nodes, including the conditional edges for conversation flow control.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph, END, START } from \"@langchain/langgraph\";\n\nfunction createSimulation() {\n  const workflow = new StateGraph(MessagesAnnotation)\n    .addNode('user', simulatedUserNode)\n    .addNode('chatbot', chatBotNode)\n    .addEdge('chatbot', 'user')\n    .addConditionalEdges('user', shouldContinue, {\n      [END]: END,\n      continue: 'chatbot',\n    })\n    .addEdge(START, 'chatbot')\n\n  const simulation = workflow.compile()\n  return simulation;\n}\n```\n\n----------------------------------------\n\nTITLE: Continuing Conversation After Summarization\nDESCRIPTION: Demonstrating that the chatbot retains context from the summary by sending messages that reference information from earlier in the conversation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nconst inputMessage5 = new HumanMessage(\"what's my name?\");\nconsole.log(inputMessage5.content)\nfor await (const event of await app.stream({ messages: [inputMessage5] }, config)) {\n  printUpdate(event)\n}\n```\n\n----------------------------------------\n\nTITLE: Global Installation and Execution\nDESCRIPTION: Commands for globally installing the validation tool via NPM and running it with the validate-checkpointer command.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint-validation/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install -g @langchain/langgraph-checkpoint-validation\nvalidate-checkpointer ./src/my_initializer.ts\n```\n\n----------------------------------------\n\nTITLE: Testing Context Retention with Sports Preferences\nDESCRIPTION: Testing if the chatbot can recall information from the summarized portion of the conversation by asking about sports preferences mentioned earlier.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/add-summary-conversation-history.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nconst inputMessage6 = new HumanMessage(\"what NFL team do you think I like?\");\nconsole.log(inputMessage6.content)\nfor await (const event of await app.stream({ messages: [inputMessage6] }, config)) {\n  printUpdate(event)\n}\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph SDK for JavaScript\nDESCRIPTION: Command to install the LangGraph SDK for JavaScript using Yarn package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/sdk.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph-sdk\n```\n\n----------------------------------------\n\nTITLE: Using the Agent with Bob Dylan's User ID - Python\nDESCRIPTION: Demonstrates invoking the agent with a user query and Bob Dylan's user ID, which will be used to look up and incorporate the user's information into the response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/update-state-from-tools.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nconst stream = await agent.stream({\n  messages: [{\n    role: \"user\",\n    content: \"hi, what should i do this weekend?\",\n  }],\n  \n}, {\n  // provide user ID in the config\n  configurable: { user_id: \"abc123\" }\n});\n\nfor await (const chunk of stream) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment Variables for LangGraph JS\nDESCRIPTION: Configuration of environment variables for OpenAI API and optional LangSmith tracing settings to enable observability for the LangGraph application.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/time-travel.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"ls__...\";\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\nprocess.env.LANGCHAIN_TRACING_V2 = \"true\";\nprocess.env.LANGCHAIN_PROJECT = \"Time Travel: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Visualizing and Running Complex Graph with Recursion Limit - Python\nDESCRIPTION: This Python snippet demonstrates visualizing a complex graph with loops and branching using a drawing tool, and executing the graph while handling recursion limits via GraphRecursionError exception management.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/recursion-limit.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraphWithLoops = graphWithLoops.getGraph();\nconst imageWithLoops = await drawableGraphWithLoops.drawMermaidPng();\nconst arrayBufferWithLoops = await imageWithLoops.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBufferWithLoops));\n```\n\nLANGUAGE: python\nCODE:\n```\nawait graphWithLoops.invoke({ aggregate: [] })\n```\n\nLANGUAGE: python\nCODE:\n```\nimport { GraphRecursionError } from \"@langchain/langgraph\";\n\ntry {\n  await graphWithLoops.invoke({ aggregate: [] }, { recursionLimit: 4 });\n} catch (error) {\n  if (error instanceof GraphRecursionError) {\n    console.log(\"Recursion Error\");\n  } else {\n    throw error;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Error Codes and Troubleshooting Links in Markdown\nDESCRIPTION: This snippet lists common LangGraph error codes with links to their respective troubleshooting pages. It uses Markdown syntax for creating an unordered list with hyperlinks.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/troubleshooting/errors/index.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- [GRAPH_RECURSION_LIMIT](/langgraphjs/troubleshooting/errors/GRAPH_RECURSION_LIMIT)\n- [INVALID_CONCURRENT_GRAPH_UPDATE](/langgraphjs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE)\n- [INVALID_GRAPH_NODE_RETURN_VALUE](/langgraphjs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE)\n- [MULTIPLE_SUBGRAPHS](/langgraphjs/troubleshooting/errors/MULTIPLE_SUBGRAPHS)\n- [UNREACHABLE_NODE](/langgraphjs/troubleshooting/errors/UNREACHABLE_NODE)\n```\n\n----------------------------------------\n\nTITLE: Validating Human Input with Interrupt Loops\nDESCRIPTION: Implements a human input validation mechanism using multiple interrupt calls within a single node, demonstrating input verification and re-prompting\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport { interrupt } from \"@langchain/langgraph\";\n\nfunction humanNode(state: typeof GraphAnnotation.State) {\n  let question = \"What is your age?\";\n\n  while (true) {\n    const answer = interrupt(question);\n\n    if (typeof answer !== \"number\" || answer < 0) {\n      question = `'${answer}' is not a valid age. What is your age?`;\n      continue;\n    } else {\n      break;\n    }\n  }\n\n  console.log(`The human in the loop is ${answer} years old.);\n\n  return {\n    age: answer,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Search Tool for Agent\nDESCRIPTION: Imports and initializes the Tavily search tool which will be used by the agent for retrieving information. Configures it to return a maximum of 3 search results.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n\nconst tools = [new TavilySearchResults({ maxResults: 3 })];\n```\n\n----------------------------------------\n\nTITLE: Building State Graph for Stream Events - Python\nDESCRIPTION: This snippet builds a `StateGraph` that coordinates model execution and tools execution based on certain state conditions. It uses `addNode` and `addConditionalEdges` methods to define the graph transitions.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-tokens-without-langchain.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport { StateGraph } from \"@langchain/langgraph\";\nimport OpenAI from \"openai\";\n\nconst shouldContinue = (state: typeof StateAnnotation.State) => {\n  const { messages } = state;\n  const lastMessage =\n    messages[messages.length - 1] as OpenAI.ChatCompletionAssistantMessageParam;\n  if (lastMessage?.tool_calls !== undefined && lastMessage?.tool_calls.length > 0) {\n    return \"tools\";\n  }\n  return \"__end__\";\n}\n\nconst graph = new StateGraph(StateAnnotation)\n  .addNode(\"model\", callModel)\n  .addNode(\"tools\", callTools)\n  .addEdge(\"__start__\", \"model\")\n  .addConditionalEdges(\"model\", shouldContinue, {\n    tools: \"tools\",\n    __end__: \"__end__\",\n  })\n  .addEdge(\"tools\", \"model\")\n  .compile();\n```\n\n----------------------------------------\n\nTITLE: Thread-level Persistence (JavaScript)\nDESCRIPTION: Create a thread and invoke a RemoteGraph with thread-specific configuration in TypeScript\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@langchain/langgraph-sdk\";\nimport { RemoteGraph } from \"@langchain/langgraph/remote\";\n\nconst url = `<DEPLOYMENT_URL>`;\nconst graphName = \"agent\";\nconst client = new Client({ apiUrl: url });\nconst remoteGraph = new RemoteGraph({ graphId: graphName, url });\n\n// create a thread (or use an existing thread instead)\nconst thread = await client.threads.create();\n\n// invoke the graph with the thread config\nconst config = { configurable: { thread_id: thread.thread_id }};\nconst result = await remoteGraph.invoke({\n  messages: [{ role: \"user\", content: \"what's the weather in sf\" }],\n  config\n});\n\n// verify that the state was persisted to the thread\nconst threadState = await remoteGraph.getState(config);\nconsole.log(threadState);\n```\n\n----------------------------------------\n\nTITLE: Setting up environment variables for LangGraph.js\nDESCRIPTION: Sets up API keys for OpenAI and LangSmith, and configures LangSmith tracing for LangGraph development.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/cross-thread-persistence.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"sk_...\";\n\n// Optional, add tracing in LangSmith\n// process.env.LANGCHAIN_API_KEY = \"lsv2__...\";\n// process.env.ANTHROPIC_API_KEY = \"your api key\";\n// process.env.LANGCHAIN_TRACING_V2 = \"true\";\n// process.env.LANGCHAIN_PROJECT = \"Cross-thread persistence: LangGraphJS\";\n```\n\n----------------------------------------\n\nTITLE: Implementing Main Execution Flow in Pregel\nDESCRIPTION: Pseudo-code demonstrating the main execution flow of the Pregel algorithm, showing initialization, the main execution loop with supersteps, and result finalization.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-execution-model.md#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// Pseudo-code for the main execution flow:\nconst loop = PregelLoop.initialize({\n  channels,\n  checkpointer,\n  modules,\n  readEdges\n});\n\nconst runner = new PregelRunner();\n\n// Initial input\nconst config = await _first(input, checkpointOpts);\n\n// Main execution loop\nwhile (await loop.tick({ config })) {\n  await runner.tick({\n    timeout,\n    retryPolicy,\n    onStepWrite\n  });\n}\n\n// Final state\nconst result = await loop.finishAndHandleError();\n```\n\n----------------------------------------\n\nTITLE: Calling the Model in Python\nDESCRIPTION: This snippet encapsulates the logic for invoking the bound model with the current state, handling the response and packaging it appropriately for further processing.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nconst callModel = async (\n  state: typeof GraphState.State,\n  config?: RunnableConfig,\n) => {\n  const { messages } = state;\n  const response = await boundModel.invoke(messages, config);\n  // We return an object, because this will get added to the existing list\n  return { messages: [response] };\n};\n```\n\n----------------------------------------\n\nTITLE: Sample ReWOO Plan Format in Plain Text\nDESCRIPTION: Shows the format for plans that will be generated by the ReWOO planner, with reasoning steps and tool calls that include variable references for result substitution.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rewoo/rewoo.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: text\nCODE:\n```\nPlan: <reasoning>\n#E1 = Tool[argument for tool]\nPlan: <reasoning>\n#E2 = Tool[argument for tool with #E1 variable substitution]\n...\n```\n\n----------------------------------------\n\nTITLE: Resuming Graph Execution in LangGraph with Python and JavaScript\nDESCRIPTION: This snippet shows how to continue graph execution after an interruption, providing a location value to resume the process. It uses the Command class from LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Command } from \"@langchain/langgraph\";\n\n// Continue the graph execution\nfor await (const event of await messagesApp.stream(\n  new Command({ resume: \"San Francisco\" }),\n  config2,\n)) {\n  console.log(event);\n  console.log(\"\\n====\\n\");\n}\n```\n\n----------------------------------------\n\nTITLE: Running LangGraph Docker Image\nDESCRIPTION: Docker command to run the LangGraph application, specifying required environment variables.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/deploy-self-hosted.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n    -e REDIS_URI=\"foo\" \\\n    -e DATABASE_URI=\"bar\" \\\n    -e LANGSMITH_API_KEY=\"baz\" \\\n    my-image\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key for LangGraph Example\nDESCRIPTION: Code snippet showing how to set the OpenAI API key as an environment variable for use with LangGraph.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input-functional.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nprocess.env.OPENAI_API_KEY = \"YOUR_API_KEY\";\n```\n\n----------------------------------------\n\nTITLE: Customizing System Prompt for Structured Output - LangGraphJS - Python\nDESCRIPTION: This snippet describes how to further customize the React agent's behavior by adding a system prompt to influence the output format of the structured response. The response format parameter can include both prompt and schema details.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-return-structured-output.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconst agent = createReactAgent({\n  llm: new ChatOpenAI({ model: \"gpt-4o\", temperature: 0 }),\n  tools: tools,\n  responseFormat: {\n    prompt: \"Always return capitalized weather conditions\",\n    schema: WeatherResponseSchema,\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Visualizing LangGraphJS graph\nDESCRIPTION: This code snippet retrieves a mermaid representation of the graph and displays it as a PNG image using `tslab`. It obtains the graph structure using `graph.getGraph()`, converts it to a PNG image, and displays the image within the `tslab` environment.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_small_model.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst representation = graph.getGraph();\nconst image = await representation.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Launching LangGraph Server\nDESCRIPTION: Command to start the LangGraph API server locally using the LangGraph CLI.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/langgraph-platform/local-server.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ npx @langchain/langgraph-cli@latest dev\n```\n\n----------------------------------------\n\nTITLE: Streaming Multiple Modes - Python\nDESCRIPTION: This snippet illustrates the capability of streaming data using multiple modes, allowing access to both custom data and state updates concurrently.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/streaming-content.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nconst streamMultiple = await graph.stream(\\n  { messages: inputs },\\n  { streamMode: [\"custom\", \"updates\"] }\\n);\\n\\nfor await (const chunk of streamMultiple) {\\n  console.log(chunk);\\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing the LangGraph Using Mermaid in Python\nDESCRIPTION: This Python snippet demonstrates how to generate and display a visual representation of the LangGraph using Mermaid and tslab for PNG output.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/map-reduce.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst representation = app.getGraph();\nconst image = await representation.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\ntslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables\nDESCRIPTION: Configuration of API keys for Anthropic and optional LangSmith tracing setup.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/wait-user-input.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ANTHROPIC_API_KEY=your-api-key\n\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\nexport LANGCHAIN_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Displaying BYOC Architecture Diagram in Markdown\nDESCRIPTION: Inserts an image of the BYOC architecture diagram using Markdown syntax. The image is located in the 'img' directory and named 'byoc_architecture.png'.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/bring_your_own_cloud.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n![Architecture](img/byoc_architecture.png)\n```\n\n----------------------------------------\n\nTITLE: Building LangGraph Project in Bash\nDESCRIPTION: Command to build the LangGraph project using Yarn.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn build\n```\n\n----------------------------------------\n\nTITLE: Draw LangGraph Graph in TSLab\nDESCRIPTION: This Python code snippet utilizes the `tslab` library to visualize the LangGraph graph. It retrieves the graph, draws it as a Mermaid PNG image, converts the image to an array buffer, and then displays it within the TSLab environment.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/multi-agent-multi-turn-convo.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport * as tslab from \"tslab\";\n\nconst drawableGraph = graph.getGraph();\nconst image = await drawableGraph.drawMermaidPng();\nconst arrayBuffer = await image.arrayBuffer();\n\nawait tslab.display.png(new Uint8Array(arrayBuffer));\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies - Bash\nDESCRIPTION: Commands to install the necessary npm packages and set up environment variables needed for the LangGraph application.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/update-state-from-tools.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/openai @langchain/core\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Setting Anthropic API Key in TypeScript\nDESCRIPTION: This code sets the Anthropic API key as an environment variable in TypeScript. It's a prerequisite for using the Anthropic API in the example.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/map-reduce.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nprocess.env.ANTHROPIC_API_KEY = 'YOUR_API_KEY'\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Middleware in TypeScript\nDESCRIPTION: TypeScript code for creating a Hono app with custom middleware that adds a header to all responses.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/http/custom_middleware.md#2025-04-21_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Hono } from \"hono\";\n\nexport const app = new Hono();\n\napp.use(async (c, next) => {\n  c.header(\"X-Custom-Header\", \"Hello World\");\n  await next();\n});\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment for LangGraph Multi-Agent Swarm\nDESCRIPTION: Commands to install additional dependencies and set up the OpenAI API key for the quickstart example.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-swarm/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph-swarm @langchain/langgraph @langchain/core @langchain/openai\n\nexport OPENAI_API_KEY=<your_api_key>\n```\n\n----------------------------------------\n\nTITLE: Defining State Annotation\nDESCRIPTION: This snippet defines the state for the LangGraph using Langchain's Annotation feature. It specifies that the state consists of messages, which are concatenated using a reducer function.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-updates.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Annotation } from \"@langchain/langgraph\";\nimport { BaseMessage } from \"@langchain/core/messages\";\n\nconst StateAnnotation = Annotation.Root({\n  messages: Annotation<BaseMessage[]>({\n    reducer: (x, y) => x.concat(y),\n  }),\n});\n```\n\n----------------------------------------\n\nTITLE: Incorrect Usage of Multiple Interrupts with Dynamic Node Structure\nDESCRIPTION: This example demonstrates a problematic implementation using multiple interrupts within a single node with dynamic structure changes. The code changes interrupt patterns based on state, leading to index mismatches and unexpected behavior during resume operations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/human_in_the_loop.md#2025-04-21_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { v4 as uuidv4 } from \"uuid\";\nimport {\n  StateGraph,\n  MemorySaver,\n  START,\n  interrupt,\n  Command,\n  Annotation\n} from \"@langchain/langgraph\";\n\nconst GraphAnnotation = Annotation.Root({\n  name: Annotation<string>(),\n  age: Annotation<string>()\n});\n\nfunction humanNode(state: typeof GraphAnnotation.State) {\n  let name;\n  if (!state.name) {\n    name = interrupt(\"what is your name?\");\n  } else {\n    name = \"N/A\";\n  }\n\n  let age;\n  if (!state.age) {\n    age = interrupt(\"what is your age?\");\n  } else {\n    age = \"N/A\";\n  }\n\n  console.log(`Name: ${name}. Age: ${age}`);\n\n  return {\n    age,\n    name,\n  };\n}\n\nconst builder = new StateGraph(GraphAnnotation)\n  .addNode(\"human_node\", humanNode);\n  .addEdge(START, \"human_node\");\n\n// A checkpointer must be enabled for interrupts to work!\nconst checkpointer = new MemorySaver();\n\nconst graph = builder.compile({ checkpointer });\n\nconst config = {\n  configurable: {\n    thread_id: uuidv4(),\n  }\n};\n\nfor await (const chunk of await graph.stream({ age: undefined, name: undefined }, config)) {\n  console.log(chunk);\n}\n\nfor await (const chunk of await graph.stream(\n  new Command({ resume: \"John\", update: { name: \"foo\" } }),\n  config\n)) {\n  console.log(chunk);\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies with npm\nDESCRIPTION: Command to install necessary npm packages including cheerio, zod, langchain, and various langchain extensions for web loading, OpenAI integration, and text splitting.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_self_rag.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install cheerio zod langchain @langchain/community @langchain/openai @langchain/core @langchain/textsplitters\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for LangGraph Project in Bash\nDESCRIPTION: Command to install project dependencies using Yarn package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/CONTRIBUTING.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyarn\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow in LangGraphJS without Checkpointer\nDESCRIPTION: This snippet illustrates compiling a workflow in LangGraphJS, connecting nodes for agent decision-making and tool execution. It sets the conditional logic for whether to continue with tool calls based on message insights, using classes like StateGraph, AIMessage, and RunnableConfig from the LangGraph framework.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/persistence.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport { END, START, StateGraph } from \"@langchain/langgraph\";\nimport { AIMessage } from \"@langchain/core/messages\";\nimport { RunnableConfig } from \"@langchain/core/runnables\";\n\nconst routeMessage = (state: typeof GraphState.State) => {\n  const { messages } = state;\n  const lastMessage = messages[messages.length - 1] as AIMessage;\n  // If no tools are called, we can finish (respond to the user)\n  if (!lastMessage.tool_calls?.length) {\n    return END;\n  }\n  // Otherwise if there is, we continue and call the tools\n  return \"tools\";\n};\n\nconst callModel = async (\n  state: typeof GraphState.State,\n  config?: RunnableConfig,\n) => {\n  const { messages } = state;\n  const response = await boundModel.invoke(messages, config);\n  return { messages: [response] };\n};\n\nconst workflow = new StateGraph(GraphState)\n  .addNode(\"agent\", callModel)\n  .addNode(\"tools\", toolNode)\n  .addEdge(START, \"agent\")\n  .addConditionalEdges(\"agent\", routeMessage)\n  .addEdge(\"tools\", \"agent\");\n\nconst graph = workflow.compile();\n```\n\n----------------------------------------\n\nTITLE: Implementing Human-in-the-Loop Interrupts in TypeScript\nDESCRIPTION: This code snippet demonstrates how to implement and handle human-in-the-loop interrupts in LanggraphJS. It includes a function to trigger interrupts and a try-catch block to handle them in the main execution loop, allowing for saving checkpoints and returning interrupt information.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph/spec/pregel-execution-model.md#2025-04-21_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Interrupt execution to wait for human input\nfunction interruptFor(\n  reason: string,\n  metadata: Record<string, any> = {}\n): never {\n  throw new InterruptError(reason, metadata);\n}\n\n// Handle interrupts in the main execution loop\ntry {\n  while (await loop.tick(config)) {\n    await runner.tick();\n  }\n} catch (e) {\n  if (e instanceof InterruptError) {\n    // Save current state\n    const checkpoint = await loop._putCheckpoint({\n      superstep: versions.superstep,\n      reason: e.reason,\n      metadata: e.metadata\n    });\n    \n    // Return to caller with interrupt info\n    return {\n      checkpoint,\n      reason: e.reason,\n      metadata: e.metadata\n    };\n  }\n  throw e;\n}\n```\n\n----------------------------------------\n\nTITLE: CLI Execution with NPX\nDESCRIPTION: Example of running the checkpointer validation tool using NPX to validate a custom checkpointer implementation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint-validation/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx @langchain/langgraph-checkpoint-validation ./src/my_initializer.ts\n```\n\n----------------------------------------\n\nTITLE: CLI Execution with Yarn\nDESCRIPTION: Example of running the checkpointer validation tool using Yarn to validate a custom checkpointer implementation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint-validation/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyarn dlx @langchain/langgraph-checkpoint-validation ./src/my_initializer.ts\n```\n\n----------------------------------------\n\nTITLE: Loading Environment Variables with dotenv\nDESCRIPTION: Imports and configures environment variables from a .env file\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/rag/langgraph_crag.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport \"dotenv/config\";\n```\n\n----------------------------------------\n\nTITLE: Testing API with REST API\nDESCRIPTION: Curl command to test the LangGraph API using a direct REST API call. It sends a message to the assistant and streams the response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/langgraph-platform/local-server.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl -s --request POST \\\n    --url \"http://localhost:2024/runs/stream\" \\\n    --header 'Content-Type: application/json' \\\n    --data \"{\n        \\\"assistant_id\\\": \\\"agent\\\",\n        \\\"input\\\": {\n            \\\"messages\\\": [\n                {\n                    \\\"role\\\": \\\"human\\\",\n                    \\\"content\\\": \\\"What is LangGraph?\\\"\n                }\n            ]\n        },\n        \\\"stream_mode\\\": \\\"updates\\\"\n    }\" \n```\n\n----------------------------------------\n\nTITLE: Thread-level Persistence (Python)\nDESCRIPTION: Create a thread and invoke a RemoteGraph with thread-specific configuration in Python\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph_sdk import get_sync_client\nurl = <DEPLOYMENT_URL>\ngraph_name = \"agent\"\nsync_client = get_sync_client(url=url)\nremote_graph = RemoteGraph(graph_name, url=url)\n\n# create a thread (or use an existing thread instead)\nthread = sync_client.threads.create()\n\n# invoke the graph with the thread config\nconfig = {\"configurable\": {\"thread_id\": thread[\"thread_id\"]}}\nresult = remote_graph.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf\"}], config=config\n})\n\n# verify that the state was persisted to the thread\nthread_state = remote_graph.get_state(config)\nprint(thread_state)\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph SDK for Python\nDESCRIPTION: Command to install the LangGraph SDK for Python using pip package manager.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/concepts/sdk.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install langgraph-sdk\n```\n\n----------------------------------------\n\nTITLE: Testing API with Python SDK (Async)\nDESCRIPTION: Python code to test the LangGraph API using the async version of the Python SDK. It sends a message to the assistant and streams the response.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/tutorials/langgraph-platform/local-server.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=\"http://localhost:2024\")\n\nasync for chunk in client.runs.stream(\n    None,  # Threadless run\n    \"agent\", # Name of assistant. Defined in langgraph.json.\n    input={\n        \"messages\": [{\n            \"role\": \"human\",\n            \"content\": \"What is LangGraph?\",\n        }],\n    },\n    stream_mode=\"updates\",\n):\n    print(f\"Receiving new event of type: {chunk.event}...\")\n    print(chunk.data)\n    print(\"\\n\\n\")\n```\n\n----------------------------------------\n\nTITLE: Searching Memories with Natural Language - Python\nDESCRIPTION: This snippet enables searching the memory store using natural language queries, allowing retrieval of memories based on semantic similarity rather than specific keys.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nconst memories = await store.search([\"user_123\", \"memories\"], {\n  query: \"What is my occupation?\",\n  limit: 3,\n});\n\nfor (const memory of memories) {\n  console.log(`Memory: ${memory.value.text} (similarity: ${memory.score})`);\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for API Keys\nDESCRIPTION: Commands to set the required environment variables for OpenAI and Scrapybara API keys needed by LangGraph CUA.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-cua/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=<your_api_key>\nexport SCRAPYBARA_API_KEY=<your_api_key>\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Graph Invocation (Python)\nDESCRIPTION: Asynchronously invoke and stream a RemoteGraph with messages in Python\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/docs/docs/how-tos/use-remote-graph.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# invoke the graph\nresult = await remote_graph.ainvoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf\"}]\n})\n\n# stream outputs from the graph\nasync for chunk in remote_graph.astream({\n    \"messages\": [(\"user\", \"what's the weather in la?\")]\n}):\n    print(chunk)\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain and Core Packages - Bash\nDESCRIPTION: This Bash snippet provides the command to install the required LangChain and Core packages using npm, facilitating graph setup and invocation with LangGraphJS.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/recursion-limit.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Streaming LLM Messages with Initial Tool Call in LangGraph.js\nDESCRIPTION: Creates a stream to process LLM responses for a weather query, displaying each message as it's generated. The code initializes inputs with a user message and configures the graph with a thread ID and streaming mode.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/review-tool-calls.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\ninputs = { messages: [{ role: \"user\", content: \"what's the weather in SF?\" }] };\nconfig = { configurable: { thread_id: \"3\" }, streamMode: \"values\" as const };\n\nstream = await graph.stream(inputs, config);\n\nfor await (const event of stream) {\n    const recentMsg = event.messages[event.messages.length - 1];\n    console.log(`================================ ${recentMsg._getType()} Message (1) =================================`)\n    console.log(recentMsg.content);\n}\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key for LangGraph\nDESCRIPTION: JavaScript code snippet showing how to set the OpenAI API key as an environment variable for LangGraph usage (commented out as an example).\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/subgraphs-manage-state.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// process.env.OPENAI_API_KEY = \"YOUR_API_KEY\";\n```\n\n----------------------------------------\n\nTITLE: Defining ReAct Agent Graph with OpenAI - Python\nDESCRIPTION: Creating a ReAct-style agent using LangGraph's prebuilt components, connecting the LLM, tools, state schema, and state modifier function.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/update-state-from-tools.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport { createReactAgent } from \"@langchain/langgraph/prebuilt\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  model: \"gpt-4o\",\n});\n\nconst agent = createReactAgent({\n  llm: model,\n  tools: [lookupUserInfo],\n  stateSchema: StateAnnotation,\n  stateModifier: stateModifier,\n})\n```\n\n----------------------------------------\n\nTITLE: Install Dependencies\nDESCRIPTION: NPM command to install required packages including LangGraph, OpenAI, and community packages.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/quickstart.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/core @langchain/langgraph @langchain/openai @langchain/community\n```\n\n----------------------------------------\n\nTITLE: Setting Up ChatOpenAI Model with Tool Binding for LangGraphJS\nDESCRIPTION: This snippet initializes a ChatOpenAI model and binds it with the previously defined tools, preparing it for use in the LangGraphJS ReAct agent.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/dynamically-returning-directly.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst model = new ChatOpenAI({\n  temperature: 0,\n  model: \"gpt-3.5-turbo\",\n});\n// This formats the tools as json schema for the model API.\n// The model then uses this like a system prompt.\nconst boundModel = model.bindTools(tools);\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key and LangSmith Tracing\nDESCRIPTION: This JavaScript code sets the OpenAI API key as an environment variable.  It configures LangSmith tracing by setting environment variables to enable tracing, background callbacks, and specify the project name. Note that the OPENAI_API_KEY and LANGCHAIN_API_KEY are commented out.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/create-react-agent.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\"// process.env.OPENAI_API_KEY = \\\"sk_...\";\\n\\n// Optional, add tracing in LangSmith\\n// process.env.LANGCHAIN_API_KEY = \\\"ls__...\\\"\\n// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \\\"true\\\";\\nprocess.env.LANGCHAIN_CALLBACKS_BACKGROUND = \\\"true\\\";\\nprocess.env.LANGCHAIN_TRACING_V2 = \\\"true\\\";\\nprocess.env.LANGCHAIN_PROJECT = \\\"ReAct Agent: LangGraphJS\\\";\"\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph Multi-Agent Swarm Dependencies\nDESCRIPTION: Command to install the necessary npm packages for using the LangGraph Multi-Agent Swarm library.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/langgraph-swarm/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph-swarm @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Setting Up PostgreSQL Docker Container for Testing\nDESCRIPTION: Commands to start a PostgreSQL Docker container for testing the checkpoint implementation.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/libs/checkpoint-postgres/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d && docker-compose logs -f\n```\n\n----------------------------------------\n\nTITLE: Initializing MemorySaver Checkpointer in Python\nDESCRIPTION: This snippet demonstrates how to import and initialize the MemorySaver checkpointer for thread-level persistence in a conversational agent. It prepares the agent to handle previous messages and retain conversation state.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/react-agent-from-scratch-functional.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport {\\n  MemorySaver,\\n  getPreviousState,\\n} from \"@langchain/langgraph\";\\n\\n// highlight-next-line\\nconst checkpointer = new MemorySaver();\n```\n\n----------------------------------------\n\nTITLE: Setting LangSmith API Keys (Optional)\nDESCRIPTION: These commands optionally set the API keys for LangSmith tracing. LangSmith provides observability features, allowing developers to trace and debug their LangChain applications effectively.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/stream-multiple.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\nexport LANGCHAIN_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies - Bash\nDESCRIPTION: This snippet installs necessary dependencies for setting up the agent's memory store system, which includes Langchain libraries and other utilities.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/semantic-search.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install \\\n  @langchain/langgraph \\\n  @langchain/openai \\\n  @langchain/core \\\n  uuid \\\n  zod\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LangGraph Agent\nDESCRIPTION: This command installs the necessary npm packages for building a plan-and-execute agent, including LangGraph, LangChain, and OpenAI integrations.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/plan-and-execute/plan-and-execute.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/openai langchain @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for LangGraph and Anthropic\nDESCRIPTION: This snippet shows how to install the required npm packages for the LangGraph example, including LangGraph itself and the Anthropic API client.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/map-reduce.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @langchain/langgraph @langchain/anthropic @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages in Bash\nDESCRIPTION: This snippet installs the necessary packages to work with LangChain and its components using yarn. Required packages include LangChain's core, anthropic, langgraph, and others essential for the project.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/respond-in-format.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add langchain @langchain/anthropic @langchain/langgraph @langchain/core\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LangGraphJS\nDESCRIPTION: This snippet shows how to install the necessary packages for the LangGraphJS project using yarn.\nSOURCE: https://github.com/langchain-ai/langgraphjs/blob/main/examples/how-tos/managing-agent-steps.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @langchain/langgraph @langchain/openai @langchain/core\n```"
  }
]