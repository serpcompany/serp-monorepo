[
  {
    "owner": "stacklok",
    "repo": "codegate",
    "content": "TITLE: Installing CodeGate with Docker\nDESCRIPTION: Command to run CodeGate as a Docker container with necessary port mappings and volume configuration. This creates a persistent volume for CodeGate data and exposes the required ports for the API, dashboard, and services.\nSOURCE: https://github.com/stacklok/codegate/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --name codegate -d -p 8989:8989 -p 9090:9090 -p 8990:8990 \\\n  --mount type=volume,src=codegate_volume,dst=/app/codegate_volume \\\n  --restart unless-stopped ghcr.io/stacklok/codegate:latest\n```\n\n----------------------------------------\n\nTITLE: CodeGate Project Structure Overview\nDESCRIPTION: This snippet provides an overview of the CodeGate project structure, showing the main directories and files. It helps developers understand the organization of the codebase.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_3\n\nLANGUAGE: plain\nCODE:\n```\ncodegate/\n├── pyproject.toml    # Project configuration and dependencies\n├── poetry.lock      # Lock file (committed to version control)\n├── prompts/         # System prompts configuration\n│   └── default.yaml # Default system prompts\n├── src/\n│   └── codegate/    # Source code\n│       ├── __init__.py\n│       ├── cli.py           # Command-line interface\n│       ├── config.py        # Configuration management\n│       ├── exceptions.py    # Shared exceptions\n│       ├── codegate_logging.py       # Logging setup\n│       ├── prompts.py       # Prompts management\n│       ├── server.py        # Main server implementation\n│       └── providers/       # External service providers\n│           ├── anthropic/   # Anthropic provider implementation\n│           ├── openai/      # OpenAI provider implementation\n│           ├── vllm/        # vLLM provider implementation\n│           └── base.py      # Base provider interface\n├── tests/           # Test files\n└── docs/            # Documentation\n```\n\n----------------------------------------\n\nTITLE: Cloning and Setting Up the CodeGate Repository\nDESCRIPTION: This snippet shows how to clone the CodeGate repository and install project dependencies using Poetry. It's the initial setup process for developers starting to work on the project.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/stacklok/codegate.git\ncd codegate\npoetry install --with dev\n```\n\n----------------------------------------\n\nTITLE: Starting the CodeGate Server\nDESCRIPTION: Command to start the CodeGate server with various configuration options.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Configuring Provider URLs in CodeGate YAML Config\nDESCRIPTION: This snippet demonstrates how to configure AI provider URLs in the CodeGate YAML configuration file. It shows the structure for setting URLs for vLLM, OpenAI, Anthropic, and Ollama providers.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nprovider_urls:\n  vllm: \"https://vllm.example.com\"\n  openai: \"https://api.openai.com/v1\"\n  anthropic: \"https://api.anthropic.com/v1\"\n  ollama: \"http://localhost:11434\" # /api path added automatically\n```\n\n----------------------------------------\n\nTITLE: Installing Python with SQLite Support using Pyenv and Homebrew\nDESCRIPTION: This snippet demonstrates how to install a specific Python version with SQLite support using pyenv and Homebrew on macOS. It's necessary because the project requires SQLite functionality not available in the default macOS SQLite installation.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# substitute for your version of choice\nPYTHON_VERSION=3.12.9\nbrew install sqlite\nLDFLAGS=\"-L$(brew --prefix sqlite)/lib\" CPPFLAGS=\"-I$(brew --prefix sqlite)/include\" PYTHON_CONFIGURE_OPTS=\"--enable-loadable-sqlite-extensions\" pyenv install -v $PYTHON_VERSION\npoetry env use $PYTHON_VERSION\n```\n\n----------------------------------------\n\nTITLE: Docker Deployment Commands for CodeGate\nDESCRIPTION: This set of snippets shows various Docker commands for deploying CodeGate, including building the image, running the container with different configurations, and setting environment variables.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmake image-build\n```\n\nLANGUAGE: bash\nCODE:\n```\n# Basic usage with local image\ndocker run -p 8989:8989 -p 9090:9090 codegate:latest\n\n# With pre-built pulled image\ndocker pull ghcr.io/stacklok/codegate:latest\ndocker run --name codegate -d -p 8989:8989 -p 9090:9090 ghcr.io/stacklok/codegate:latest\n\n# It will mount a volume to /app/codegate_volume\n# The directory supports storing Llama CPP models under subdirectory /models\n# A sqlite DB with the messages and alerts is stored under the subdirectory /db\ndocker run --name codegate -d -v /path/to/volume:/app/codegate_volume -p 8989:8989 -p 9090:9090 ghcr.io/stacklok/codegate:latest\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 8989:8989 -p 9090:9090 -e CODEGATE_OLLAMA_URL=http://1.2.3.4:11434/api ghcr.io/stacklok/codegate:latest\n```\n\n----------------------------------------\n\nTITLE: Setting Provider URLs via CLI Flags in CodeGate\nDESCRIPTION: This snippet demonstrates how to set AI provider URLs using command-line interface flags when starting the CodeGate server. It shows examples for vLLM and Ollama providers.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve --vllm-url https://vllm.example.com --ollama-url http://localhost:11434\n```\n\n----------------------------------------\n\nTITLE: Setting Provider URLs via Environment Variables in CodeGate\nDESCRIPTION: This snippet shows how to set AI provider URLs using environment variables in CodeGate. It includes examples for vLLM, OpenAI, Anthropic, Ollama, and LM Studio providers.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nexport CODEGATE_PROVIDER_VLLM_URL=https://vllm.example.com\nexport CODEGATE_PROVIDER_OPENAI_URL=https://api.openai.com/v1\nexport CODEGATE_PROVIDER_ANTHROPIC_URL=https://api.anthropic.com/v1\nexport CODEGATE_PROVIDER_OLLAMA_URL=http://localhost:11434\nexport CODEGATE_PROVIDER_LM_STUDIO_URL=http://localhost:1234\n```\n\n----------------------------------------\n\nTITLE: Using the Main CodeGate CLI Command\nDESCRIPTION: The main command structure for the CodeGate CLI tool, showing the basic command syntax.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncodegate [OPTIONS] COMMAND [ARGS]...\n```\n\n----------------------------------------\n\nTITLE: Implementing New Provider Class in Python\nDESCRIPTION: This snippet shows how to create a new provider class by extending BaseProvider. It includes initializing the provider with normalizers and handlers, and implementing required methods.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom codegate.providers.base import BaseProvider\n\nclass NewProvider(BaseProvider):\n    def __init__(self, ...):\n        super().__init__(\n            InputNormalizer(),\n            OutputNormalizer(),\n            completion_handler,\n            pipeline_processor,\n            fim_pipeline_processor\n        )\n\n    @property\n    def provider_route_name(self) -> str:\n        return \"provider_name\"\n\n    def _setup_routes(self):\n        # Implement route setup\n        pass\n```\n\n----------------------------------------\n\nTITLE: Displaying System Prompts\nDESCRIPTION: Command to display the loaded system prompts, optionally from a custom file.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncodegate show-prompts [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Generating Certificates\nDESCRIPTION: Command to generate SSL certificates for the CodeGate server with customizable options.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncodegate generate-certs [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Starting Server with Default Settings\nDESCRIPTION: Example of starting the CodeGate server with default configuration settings.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve\n```\n\n----------------------------------------\n\nTITLE: Starting Server with Custom Port and Host\nDESCRIPTION: Example of starting the CodeGate server on a specific port and host.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve --port 8989 --host localhost\n```\n\n----------------------------------------\n\nTITLE: Starting Server with Custom Logging\nDESCRIPTION: Example of starting the CodeGate server with custom logging level and format.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve --log-level DEBUG --log-format TEXT\n```\n\n----------------------------------------\n\nTITLE: Starting Server with Configuration File\nDESCRIPTION: Example of starting the CodeGate server using a custom configuration file.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve --config my-config.yaml\n```\n\n----------------------------------------\n\nTITLE: Starting Server with Custom vLLM Endpoint\nDESCRIPTION: Example of starting the CodeGate server with a custom vLLM endpoint URL.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve --vllm-url https://vllm.example.com\n```\n\n----------------------------------------\n\nTITLE: Starting Server with Custom Ollama Endpoint\nDESCRIPTION: Example of starting the CodeGate server with a custom Ollama endpoint URL.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve --ollama-url http://localhost:11434\n```\n\n----------------------------------------\n\nTITLE: Starting Server with Custom LM Studio Endpoint\nDESCRIPTION: Example of starting the CodeGate server with a custom LM Studio endpoint URL.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve --lm-studio-url https://lmstudio.example.com\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Prompts in YAML\nDESCRIPTION: This snippet demonstrates the format for creating custom prompts in a YAML file. It shows how to define multiple prompts with their respective text content.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nprompt_name: \"Prompt text content\"\nanother_prompt: \"More prompt text\"\n```\n\n----------------------------------------\n\nTITLE: Using Custom Prompts via CLI and Configuration in Bash\nDESCRIPTION: This snippet shows different ways to specify custom prompts when using Codegate. It includes examples for using the CLI, config file, and environment variables.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# Via CLI\ncodegate serve --prompts my-prompts.yaml\n\n# Via config.yaml\nprompts: \"path/to/prompts.yaml\"\n\n# Via environment\nexport CODEGATE_PROMPTS_FILE=path/to/prompts.yaml\n```\n\n----------------------------------------\n\nTITLE: Testing Prompts in Python\nDESCRIPTION: This snippet demonstrates how to write a test for custom prompts in Python. It shows loading a configuration with custom prompts and asserting the expected prompt text.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef test_custom_prompts():\n    config = Config.load(prompts_path=\"path/to/test/prompts.yaml\")\n    assert config.prompts.my_prompt == \"Expected prompt text\"\n```\n\n----------------------------------------\n\nTITLE: Using Codegate CLI Commands in Bash\nDESCRIPTION: This snippet shows various CLI commands for using Codegate. It includes examples for starting the server with default settings, custom configurations, custom prompts, and custom provider URL.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n# Start server with default settings\ncodegate serve\n\n# Start with custom configuration\ncodegate serve --port 8989 --host localhost --log-level DEBUG\n\n# Start with custom prompts\ncodegate serve --prompts my-prompts.yaml\n\n# Start with custom provider URL\ncodegate serve --vllm-url https://vllm.example.com\n```\n\n----------------------------------------\n\nTITLE: Demonstrating JSON Log Format in CodeGate\nDESCRIPTION: Shows the structure of a JSON-formatted log entry in CodeGate, including timestamp, log level, module, event, and extra fields.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/logging.md#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"timestamp\": \"YYYY-MM-DDThh:mm:ss.mmmZ\",\n  \"log_level\": \"LOG_LEVEL\",\n  \"module\": \"MODULE_NAME\",\n  \"event\": \"Log message\",\n  \"extra\": {\n    // Additional fields as you desire\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Starting Server with Custom Prompts\nDESCRIPTION: Example of starting the CodeGate server with custom prompts file.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve --prompts my-prompts.yaml\n```\n\n----------------------------------------\n\nTITLE: Illustrating Text Log Format in CodeGate\nDESCRIPTION: Demonstrates the pattern for text-formatted log entries in CodeGate, including timestamp, level, name, and message.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/logging.md#2025-04-22_snippet_1\n\nLANGUAGE: plain\nCODE:\n```\nYYYY-MM-DDThh:mm:ss.mmmZ - LEVEL - NAME - MESSAGE\n```\n\n----------------------------------------\n\nTITLE: Basic Logging Examples in Python using structlog\nDESCRIPTION: Demonstrates basic logging operations using structlog in Python, including different log levels such as info, debug, error, and warning.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/logging.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport structlog\n\nlogger = structlog.get_logger(__name__)\n\n# Different log levels\nlogger.info(\"This is an info message\")\nlogger.debug(\"This is a debug message\")\nlogger.error(\"This is an error message\")\nlogger.warning(\"This is a warning message\")\n```\n\n----------------------------------------\n\nTITLE: Logging with Extra Fields in Python using structlog\nDESCRIPTION: Shows how to include additional contextual information in log messages using extra fields with structlog in Python.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/logging.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlogger.info(\"Server starting\", extra={\n    \"host\": \"0\",\n    \"port\": 8989,\n    \"environment\": \"production\"\n})\n```\n\n----------------------------------------\n\nTITLE: Exception Logging in Python with structlog\nDESCRIPTION: Demonstrates how to log exceptions with full stack trace information using structlog in Python.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/logging.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntry:\n    # Some code that might raise an exception\n    raise ValueError(\"Something went wrong\")\nexcept Exception as e:\n    logger.error(\"Error occurred\", exc_info=True)\n```\n\n----------------------------------------\n\nTITLE: Configuring CodeGate Logging via CLI Arguments\nDESCRIPTION: Shows how to configure the CodeGate logging system using command-line interface arguments for log level and format.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/logging.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncodegate serve --log-level DEBUG --log-format TEXT\n```\n\n----------------------------------------\n\nTITLE: Setting CodeGate Logging Configuration via Environment Variables\nDESCRIPTION: Demonstrates how to set logging configuration for CodeGate using environment variables for log level and format.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/logging.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nexport APP_LOG_LEVEL=DEBUG\nexport CODEGATE_LOG_FORMAT=TEXT\n```\n\n----------------------------------------\n\nTITLE: Configuring CodeGate Logging in YAML Configuration File\nDESCRIPTION: Illustrates how to configure CodeGate logging settings using a YAML configuration file, specifying log level and format.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/logging.md#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nlog_level: DEBUG\nlog_format: TEXT\n```\n\n----------------------------------------\n\nTITLE: Best Practice: Contextual Logging in Python with structlog\nDESCRIPTION: Demonstrates a best practice for including relevant context in log messages using extra fields with structlog in Python.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/logging.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nlogger.info(\"User action\", extra={\n    \"user_id\": \"123\",\n    \"action\": \"login\",\n    \"ip_address\": \"192.168.1.1\"\n})\n```\n\n----------------------------------------\n\nTITLE: Debugging FIM Stream Response in TypeScript\nDESCRIPTION: Code addition to log raw stream data in Continue's streamSse function for debugging FIM (Fill-In-Middle) responses\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/debugging_clients.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconsole.log('Raw stream data:', value);\n```\n\n----------------------------------------\n\nTITLE: CodeGate Provider Configuration in JSON\nDESCRIPTION: Configuration template for setting up CodeGate as an intermediary between Continue and the LLM provider, specifying model details and API endpoints\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/debugging_clients.md#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"tabAutocompleteModel\": {\n    \"title\": \"CodeGate - Provider\",\n    \"provider\": \"openai\",\n    \"model\": \"<model>\",\n    \"apiKey\": \"<insert-api-key-if-required>\",\n    \"apiBase\": \"http://localhost:8989/<provider>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Direct Provider Configuration in JSON\nDESCRIPTION: Configuration template for directly connecting Continue to the LLM provider, bypassing CodeGate for debugging purposes\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/debugging_clients.md#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"tabAutocompleteModel\": {\n    \"title\": \"Provider\",\n    \"provider\": \"openai\",\n    \"model\": \"<model>\",\n    \"apiKey\": \"<insert-api-key-if-required>\",\n    \"apiBase\": \"<provider-url>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Git Commit Message Format Example\nDESCRIPTION: Example showing the standard format for commit messages in the CodeGate project, following Chris Beams' guidelines.\nSOURCE: https://github.com/stacklok/codegate/blob/main/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n1. Separate subject from body with a blank line\n2. Limit the subject line to 50 characters\n3. Capitalize the subject line\n4. Do not end the subject line with a period\n5. Use the imperative mood in the subject line\n6. Use the body to explain what and why vs. how\n```\n\n----------------------------------------\n\nTITLE: Setting Up CodeGate UI Development Environment\nDESCRIPTION: This set of snippets outlines the process for setting up the local development environment for the CodeGate UI dashboard. It includes cloning the repository, installing dependencies, and running the development server.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/stacklok/codegate-ui\ncd codegate-ui\n```\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\n```\n\nLANGUAGE: bash\nCODE:\n```\nnpm run preview\n```\n\n----------------------------------------\n\nTITLE: Generating Certificates with Default Settings\nDESCRIPTION: Example of generating SSL certificates with default settings.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ncodegate generate-certs\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests for CodeGate\nDESCRIPTION: This set of snippets demonstrates how to set up and run integration tests for CodeGate. It includes creating an environment file, importing test data, starting the CodeGate server, and executing the tests.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/development.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nENV_OPENAI_KEY=<YOUR_KEY>\nENV_VLLM_KEY=<YOUR_KEY>\nENV_ANTHROPIC_KEY=<YOUR_KEY>\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python scripts/import_packages.py\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry run codegate serve --log-level DEBUG --log-format TEXT\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python tests/integration/integration_tests.py\n```\n\nLANGUAGE: bash\nCODE:\n```\nCODEGATE_PROVIDERS=copilot CA_CERT_FILE=./codegate_volume/certs/ca.crt poetry run python tests/integration/integration_tests.py\n```\n\n----------------------------------------\n\nTITLE: Displaying Default System Prompts\nDESCRIPTION: Example of showing the default system prompts.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncodegate show-prompts\n```\n\n----------------------------------------\n\nTITLE: Displaying Prompts from Custom File\nDESCRIPTION: Example of showing prompts from a custom file.\nSOURCE: https://github.com/stacklok/codegate/blob/main/docs/cli.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ncodegate show-prompts --prompts my-prompts.yaml\n```\n\n----------------------------------------\n\nTITLE: GPT-4 Chat Completion Content Chunk\nDESCRIPTION: First content chunk from streaming response containing partial completion text\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/openai/streaming_messages.txt#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"id\":\"chatcmpl-B0szUPll9BiFva49CokSsI1pVPjA6\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"content 1\"}}],\"created\":1739551084,\"model\":\"gpt-4o-2024-08-06\",\"service_tier\":\"default\",\"system_fingerprint\":\"fp_523b9b6e5f\",\"object\":\"chat.completion.chunk\"}\n```\n\n----------------------------------------\n\nTITLE: GPT-4 Chat Completion Second Chunk\nDESCRIPTION: Second content chunk from streaming response containing additional completion text\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/openai/streaming_messages.txt#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\"id\":\"chatcmpl-B0szUPll9BiFva49CokSsI1pVPjA6\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"content 2\"}}],\"created\":1739551084,\"model\":\"gpt-4o-2024-08-06\",\"service_tier\":\"default\",\"system_fingerprint\":\"fp_523b9b6e5f\",\"object\":\"chat.completion.chunk\"}\n```\n\n----------------------------------------\n\nTITLE: GPT-4 Chat Completion Final Response with Usage Stats\nDESCRIPTION: Final chunk containing usage statistics including token counts and details about completion and prompt tokens\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/openai/streaming_messages.txt#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\"id\":\"chatcmpl-B0szUPll9BiFva49CokSsI1pVPjA6\",\"choices\":[],\"created\":1739551084,\"model\":\"gpt-4o-2024-08-06\",\"service_tier\":\"default\",\"system_fingerprint\":\"fp_523b9b6e5f\",\"object\":\"chat.completion.chunk\",\"usage\":{\"completion_tokens\":394,\"prompt_tokens\":15675,\"total_tokens\":16069,\"completion_tokens_details\":{\"accepted_prediction_tokens\":0,\"audio_tokens\":0,\"reasoning_tokens\":0,\"rejected_prediction_tokens\":0},\"prompt_tokens_details\":{\"audio_tokens\":0,\"cached_tokens\":4352}}}\n```\n\n----------------------------------------\n\nTITLE: Message Start Event JSON\nDESCRIPTION: Initial message event configuration with model and token usage information\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/anthropic/streaming_messages.txt#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"type\":\"message_start\",\"message\":{\"id\":\"msg_014p7gG3wDgGV9EUtLvnow3U\",\"type\":\"message\",\"role\":\"assistant\",\"model\":\"claude-3-haiku-20240307\",\"stop_sequence\":null,\"usage\":{\"input_tokens\":472,\"output_tokens\":2},\"content\":[],\"stop_reason\":null}}\n```\n\n----------------------------------------\n\nTITLE: Weather Tool Input JSON\nDESCRIPTION: Tool use event containing location and temperature unit parameters for weather lookup\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/anthropic/streaming_messages.txt#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\"location\": \"San Francisco, CA\", \"unit\": \"fahrenheit\"}\n```\n\n----------------------------------------\n\nTITLE: Message Start Event\nDESCRIPTION: Initial message event containing metadata about the assistant's response including model and token usage.\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/anthropic/streaming_messages_simple.txt#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"type\":\"message_start\",\"message\":{\"id\":\"msg_014p7gG3wDgGV9EUtLvnow3U\",\"type\":\"message\",\"role\":\"assistant\",\"model\":\"claude-3-haiku-20240307\",\"stop_sequence\":null,\"usage\":{\"input_tokens\":472,\"output_tokens\":2},\"content\":[],\"stop_reason\":null}}\n```\n\n----------------------------------------\n\nTITLE: Content Block Events\nDESCRIPTION: Series of events showing content block initialization, text deltas, and block completion.\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/anthropic/streaming_messages_simple.txt#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\"type\":\"content_block_start\",\"index\":0,\"content_block\":{\"type\":\"text\",\"text\":\"some random text\"}}\n```\n\n----------------------------------------\n\nTITLE: Tool Usage Events\nDESCRIPTION: Events demonstrating tool initialization and JSON input construction for a weather tool.\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/anthropic/streaming_messages_simple.txt#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\"type\":\"content_block_start\",\"index\":1,\"content_block\":{\"type\":\"tool_use\",\"id\":\"toolu_01T1x1fJ34qAmk2tNTrN7Up6\",\"name\":\"get_weather\",\"input\":{}}}\n```\n\n----------------------------------------\n\nTITLE: Message Completion Events\nDESCRIPTION: Final events indicating message completion with stop reason and token usage.\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/anthropic/streaming_messages_simple.txt#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\"type\":\"message_delta\",\"delta\":{\"stop_reason\":\"tool_use\",\"stop_sequence\":null},\"usage\":{\"output_tokens\":89}}\n```\n\n----------------------------------------\n\nTITLE: DeepSeek R1 JSON Stream Messages\nDESCRIPTION: Example of JSON stream messages showing the format of model responses. Each message contains the model name, timestamp, role, content and completion status flags. The final message includes additional performance metrics.\nSOURCE: https://github.com/stacklok/codegate/blob/main/tests/types/ollama/streaming_messages.txt#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"model\":\"deepseek-r1:7b\",\"created_at\":\"2025-02-13T17:26:25.855925728Z\",\"message\":{\"role\":\"assistant\",\"content\":\"content 1\"},\"done\":false}\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"model\":\"deepseek-r1:7b\",\"created_at\":\"2025-02-13T17:26:25.864123608Z\",\"message\":{\"role\":\"assistant\",\"content\":\"content 2\"},\"done\":false}\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"model\":\"deepseek-r1:7b\",\"created_at\":\"2025-02-13T17:26:25.872463411Z\",\"message\":{\"role\":\"assistant\",\"content\":\"content 3\"},\"done\":true,\"done_reason\":\"stop\",\"total_duration\":0,\"load_duration\":0,\"prompt_eval_count\":0,\"prompt_eval_duration\":0,\"eval_count\":0,\"eval_duration\":0}\n```"
  }
]