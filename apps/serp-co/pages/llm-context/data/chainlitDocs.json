[
  {
    "owner": "chainlit",
    "repo": "docs",
    "content": "TITLE: Implementing Mistral AI Chat Completion with Chainlit in Python\nDESCRIPTION: This code snippet demonstrates how to set up a Chainlit application that uses Mistral AI for chat completion. It initializes the Mistral client, defines a message handler function, and sends responses back to the user interface.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/mistralai.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport chainlit as cl\nfrom mistralai import Mistral\n\n# Initialize the Mistral client\nclient = Mistral(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    response = await client.chat.complete_async(\n        model=\"mistral-small-latest\",\n        max_tokens=100,\n        temperature=0.5,\n        stream=False,\n        # ... more setting\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful bot, you always reply in French.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": message.content # Content of the user message\n            }\n        ]\n    )\n    await cl.Message(content=response.choices[0].message.content).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Sync LCEL Chat with LangChain and Chainlit\nDESCRIPTION: Creates a synchronous chat application using LangChain Expression Language (LCEL) with streaming capabilities. Similar to the async version but uses synchronous streaming approach.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/langchain.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_openai import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.schema import StrOutputParser\nfrom langchain.schema.runnable import Runnable\nfrom langchain.schema.runnable.config import RunnableConfig\n\nimport chainlit as cl\n\n@cl.on_chat_start\nasync def on_chat_start():\n    model = ChatOpenAI(streaming=True)\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", \"You're a very knowledgeable historian who provides accurate and eloquent answers to historical questions.\"),\n        (\"human\", \"{question}\")\n    ])\n    runnable = prompt | model | StrOutputParser()\n    cl.user_session.set(\"runnable\", runnable)\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    runnable = cl.user_session.get(\"runnable\")\n    msg = cl.Message(content=\"\")\n    for chunk in await cl.make_async(runnable.stream)(\n        {\"question\": message.content},\n        config=RunnableConfig(callbacks=[cl.LangchainCallbackHandler()])\n    ):\n        await msg.stream_token(chunk)\n    await msg.send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Llama Index with Chainlit in Python\nDESCRIPTION: This code sets up a Chainlit application integrated with Llama Index. It initializes a vector store index, creates a query engine, and handles chat interactions. The script uses OpenAI's language model and embeddings, and implements callback handlers for streaming responses to the UI.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/llama-index.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport openai\nimport chainlit as cl\n\nfrom llama_index.core import (\n    Settings,\n    StorageContext,\n    VectorStoreIndex,\n    SimpleDirectoryReader,\n    load_index_from_storage,\n)\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.core.query_engine.retriever_query_engine import RetrieverQueryEngine\nfrom llama_index.core.callbacks import CallbackManager\nfrom llama_index.core.service_context import ServiceContext\n\nopenai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\ntry:\n    # rebuild storage context\n    storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n    # load index\n    index = load_index_from_storage(storage_context)\nexcept:\n    documents = SimpleDirectoryReader(\"./data\").load_data(show_progress=True)\n    index = VectorStoreIndex.from_documents(documents)\n    index.storage_context.persist()\n\n\n@cl.on_chat_start\nasync def start():\n    Settings.llm = OpenAI(\n        model=\"gpt-3.5-turbo\", temperature=0.1, max_tokens=1024, streaming=True\n    )\n    Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n    Settings.context_window = 4096\n\n    service_context = ServiceContext.from_defaults(callback_manager=CallbackManager([cl.LlamaIndexCallbackHandler()]))\n    query_engine = index.as_query_engine(streaming=True, similarity_top_k=2, service_context=service_context)\n    cl.user_session.set(\"query_engine\", query_engine)\n\n    await cl.Message(\n        author=\"Assistant\", content=\"Hello! Im an AI assistant. How may I help you?\"\n    ).send()\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    query_engine = cl.user_session.get(\"query_engine\") # type: RetrieverQueryEngine\n\n    msg = cl.Message(content=\"\", author=\"Assistant\")\n\n    res = await cl.make_async(query_engine.query)(message.content)\n\n    for token in res.response_gen:\n        await msg.stream_token(token)\n    await msg.send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Chainlit Application with OpenAI-compatible Inference Server in Python\nDESCRIPTION: This Python script sets up a Chainlit application that uses an OpenAI-compatible inference server. It imports necessary packages, configures the client, and defines a message handler function that sends requests to the LLM and returns responses.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/message-based.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncOpenAI\nimport chainlit as cl\nclient = AsyncOpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n# Instrument the OpenAI client\ncl.instrument_openai()\n\nsettings = {\n    \"model\": \"gpt-3.5-turbo\",\n    \"temperature\": 0,\n    # ... more settings\n}\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    response = await client.chat.completions.create(\n        messages=[\n            {\n                \"content\": \"You are a helpful bot, you always reply in Spanish\",\n                \"role\": \"system\"\n            },\n            {\n                \"content\": message.content,\n                \"role\": \"user\"\n            }\n        ],\n        **settings\n    )\n    await cl.Message(content=response.choices[0].message.content).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenAI Message Streaming with Chainlit\nDESCRIPTION: This code demonstrates how to implement token-by-token streaming with OpenAI API in a Chainlit application. It initializes a chat session, processes user messages, streams the AI response tokens incrementally, and updates the message history. The example uses AsyncOpenAI client and Chainlit's streaming capabilities.\nSOURCE: https://github.com/chainlit/docs/blob/main/advanced-features/streaming.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncOpenAI\nimport chainlit as cl\n\nclient = AsyncOpenAI(api_key=\"YOUR_OPENAI_API_KEY\")\n\n\nsettings = {\n    \"model\": \"gpt-3.5-turbo\",\n    \"temperature\": 0.7,\n    \"max_tokens\": 500,\n    \"top_p\": 1,\n    \"frequency_penalty\": 0,\n    \"presence_penalty\": 0,\n}\n\n\n@cl.on_chat_start\ndef start_chat():\n    cl.user_session.set(\n        \"message_history\",\n        [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}],\n    )\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    message_history = cl.user_session.get(\"message_history\")\n    message_history.append({\"role\": \"user\", \"content\": message.content})\n\n    msg = cl.Message(content=\"\")\n\n    stream = await client.chat.completions.create(\n        messages=message_history, stream=True, **settings\n    )\n\n    async for part in stream:\n        if token := part.choices[0].delta.content or \"\":\n            await msg.stream_token(token)\n\n    message_history.append({\"role\": \"assistant\", \"content\": msg.content})\n    await msg.update()\n```\n\n----------------------------------------\n\nTITLE: Implementing Semantic Kernel and Chainlit Integration in Python\nDESCRIPTION: This code snippet demonstrates how to set up a Semantic Kernel, add a custom WeatherPlugin, and integrate it with Chainlit. It includes the necessary imports, kernel setup, plugin definition, and chat handling functions.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/semantic-kernel.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nimport semantic_kernel as sk\nfrom semantic_kernel.connectors.ai import FunctionChoiceBehavior\nfrom semantic_kernel.connectors.ai.open_ai import (\n    OpenAIChatCompletion,\n    OpenAIChatPromptExecutionSettings,\n)\nfrom semantic_kernel.functions import kernel_function\nfrom semantic_kernel.contents import ChatHistory\n\nrequest_settings = OpenAIChatPromptExecutionSettings(\n    function_choice_behavior=FunctionChoiceBehavior.Auto(filters={\"excluded_plugins\": [\"ChatBot\"]})\n)\n\n# Example Native Plugin (Tool)\nclass WeatherPlugin:\n    @kernel_function(name=\"get_weather\", description=\"Gets the weather for a city\")\n    def get_weather(self, city: str) -> str:\n        \"\"\"Retrieves the weather for a given city.\"\"\"\n        if \"paris\" in city.lower():\n            return f\"The weather in {city} is 20°C and sunny.\"\n        elif \"london\" in city.lower():\n            return f\"The weather in {city} is 15°C and cloudy.\"\n        else:\n            return f\"Sorry, I don't have the weather for {city}.\"\n\n@cl.on_chat_start\nasync def on_chat_start():\n    # Setup Semantic Kernel\n    kernel = sk.Kernel()\n\n    # Add your AI service (e.g., OpenAI)\n    # Make sure OPENAI_API_KEY and OPENAI_ORG_ID are set in your environment\n    ai_service = OpenAIChatCompletion(service_id=\"default\", ai_model_id=\"gpt-4o\")\n    kernel.add_service(ai_service)\n\n    # Import the WeatherPlugin\n    kernel.add_plugin(WeatherPlugin(), plugin_name=\"Weather\")\n    \n    # Instantiate and add the Chainlit filter to the kernel\n    # This will automatically capture function calls as Steps\n    sk_filter = cl.SemanticKernelFilter(kernel=kernel)\n\n    cl.user_session.set(\"kernel\", kernel)\n    cl.user_session.set(\"ai_service\", ai_service)\n    cl.user_session.set(\"chat_history\", ChatHistory())\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    kernel = cl.user_session.get(\"kernel\") # type: sk.Kernel\n    ai_service = cl.user_session.get(\"ai_service\") # type: OpenAIChatCompletion\n    chat_history = cl.user_session.get(\"chat_history\") # type: ChatHistory\n\n    # Add user message to history\n    chat_history.add_user_message(message.content)\n\n    # Create a Chainlit message for the response stream\n    answer = cl.Message(content=\"\")\n\n    async for msg in ai_service.get_streaming_chat_message_content(\n        chat_history=chat_history,\n        user_input=message.content,\n        settings=request_settings,\n        kernel=kernel,\n    ):\n        if msg.content:\n            await answer.stream_token(msg.content)\n\n    # Add the full assistant response to history\n    chat_history.add_assistant_message(answer.content)\n\n    # Send the final message\n    await answer.send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Chainlit Message Handler in Python\nDESCRIPTION: Core implementation of a Chainlit message handler that processes user input and sends responses. Uses the @cl.on_message decorator to handle incoming messages and the Message class to send responses back to the user interface.\nSOURCE: https://github.com/chainlit/docs/blob/main/get-started/pure-python.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    # Your custom logic goes here...\n\n    # Send a response back to the user\n    await cl.Message(\n        content=f\"Received: {message.content}\",\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Streaming a Message with Chainlit\nDESCRIPTION: This snippet shows how to stream a message token by token to the UI using Chainlit. It demonstrates creating an empty message, streaming tokens one by one, and then finalizing by sending the complete message.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/message.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\ntoken_list = [\"the\", \"quick\", \"brown\", \"fox\"]\n\n\n@cl.on_chat_start\nasync def main():\n    msg = cl.Message(content=\"\")\n    for token in token_list:\n        await msg.stream_token(token)\n\n    await msg.send()\n```\n\n----------------------------------------\n\nTITLE: Implementing LiteLLM Proxy Integration in Chainlit Application (Python)\nDESCRIPTION: This code snippet demonstrates how to create a Chainlit application integrated with LiteLLM Proxy. It sets up an AsyncOpenAI client, configures settings, and defines a message handler function that uses the proxy to generate responses.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/litellm.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncOpenAI\nimport chainlit as cl\nclient = AsyncOpenAI(\n    api_key=\"anything\",            # litellm proxy virtual key\n    base_url=\"http://0.0.0.0:4000\" # litellm proxy base_url\n)\n\n# Instrument the OpenAI client\ncl.instrument_openai()\n\nsettings = {\n    \"model\": \"gpt-3.5-turbo\", # model you want to send litellm proxy\n    \"temperature\": 0,\n    # ... more settings\n}\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    response = await client.chat.completions.create(\n        messages=[\n            {\n                \"content\": \"You are a helpful bot, you always reply in Spanish\",\n                \"role\": \"system\"\n            },\n            {\n                \"content\": message.content,\n                \"role\": \"user\"\n            }\n        ],\n        **settings\n    )\n    await cl.Message(content=response.choices[0].message.content).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Document QA Chatbot with LangChain and Chainlit\nDESCRIPTION: This Python script sets up a document QA chatbot using LangChain and Chainlit. It handles file uploading, text processing, vector store creation, and question answering using a conversational retrieval chain.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/qa.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.chains import (\n    ConversationalRetrievalChain,\n)\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\n\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain.memory import ConversationBufferMemory\n\nimport chainlit as cl\n\nos.environ[\"OPENAI_API_KEY\"] = (\n    \"OPENAI_API_KEY\"\n)\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n\n\n@cl.on_chat_start\nasync def on_chat_start():\n    files = None\n\n    # Wait for the user to upload a file\n    while files is None:\n        files = await cl.AskFileMessage(\n            content=\"Please upload a text file to begin!\",\n            accept=[\"text/plain\"],\n            max_size_mb=20,\n            timeout=180,\n        ).send()\n\n    file = files[0]\n\n    msg = cl.Message(content=f\"Processing `{file.name}`...\")\n    await msg.send()\n\n    with open(file.path, \"r\", encoding=\"utf-8\") as f:\n        text = f.read()\n\n    # Split the text into chunks\n    texts = text_splitter.split_text(text)\n\n    # Create a metadata for each chunk\n    metadatas = [{\"source\": f\"{i}-pl\"} for i in range(len(texts))]\n\n    # Create a Chroma vector store\n    embeddings = OpenAIEmbeddings()\n    docsearch = await cl.make_async(Chroma.from_texts)(\n        texts, embeddings, metadatas=metadatas\n    )\n\n    message_history = ChatMessageHistory()\n\n    memory = ConversationBufferMemory(\n        memory_key=\"chat_history\",\n        output_key=\"answer\",\n        chat_memory=message_history,\n        return_messages=True,\n    )\n\n    # Create a chain that uses the Chroma vector store\n    chain = ConversationalRetrievalChain.from_llm(\n        ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True),\n        chain_type=\"stuff\",\n        retriever=docsearch.as_retriever(),\n        memory=memory,\n        return_source_documents=True,\n    )\n\n    # Let the user know that the system is ready\n    msg.content = f\"Processing `{file.name}` done. You can now ask questions!\"\n    await msg.update()\n\n    cl.user_session.set(\"chain\", chain)\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    chain = cl.user_session.get(\"chain\")  # type: ConversationalRetrievalChain\n    cb = cl.AsyncLangchainCallbackHandler()\n\n    res = await chain.acall(message.content, callbacks=[cb])\n    answer = res[\"answer\"]\n    source_documents = res[\"source_documents\"]  # type: List[Document]\n\n    text_elements = []  # type: List[cl.Text]\n\n    if source_documents:\n        for source_idx, source_doc in enumerate(source_documents):\n            source_name = f\"source_{source_idx}\"\n            # Create the text element referenced in the message\n            text_elements.append(\n                cl.Text(\n                    content=source_doc.page_content, name=source_name, display=\"side\"\n                )\n            )\n        source_names = [text_el.name for text_el in text_elements]\n\n        if source_names:\n            answer += f\"\\nSources: {', '.join(source_names)}\"\n        else:\n            answer += \"\\nNo sources found\"\n\n    await cl.Message(content=answer, elements=text_elements).send()\n```\n\n----------------------------------------\n\nTITLE: Initializing LlamaIndex Callback Handler with Chainlit\nDESCRIPTION: Shows how to configure a LlamaIndex ServiceContext with Chainlit's callback handler to enable UI feedback. This setup is done when the chat session starts using the @cl.on_chat_start decorator.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/integrations/llamaindex.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core.callbacks import CallbackManager\nfrom llama_index.core.service_context import ServiceContext\nimport chainlit as cl\n\n\n\n@cl.on_chat_start\nasync def start():\n    service_context = ServiceContext.from_defaults(callback_manager=CallbackManager([cl.LlamaIndexCallbackHandler()]))\n    # use the service context to create the predictor\n```\n\n----------------------------------------\n\nTITLE: Creating SQL Schema for SQLAlchemy Data Layer\nDESCRIPTION: This SQL script initializes the database schema with tables for users, threads, steps, elements, and feedbacks. These tables are structured to support UUID keys and JSONB metadata, with foreign key constraints for referential integrity. It is tested with PostgreSQL but should support other databases via SQL Alchemy.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-layers/sqlalchemy.mdx#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE users (\n    \"id\" UUID PRIMARY KEY,\n    \"identifier\" TEXT NOT NULL UNIQUE,\n    \"metadata\" JSONB NOT NULL,\n    \"createdAt\" TEXT\n);\n\nCREATE TABLE IF NOT EXISTS threads (\n    \"id\" UUID PRIMARY KEY,\n    \"createdAt\" TEXT,\n    \"name\" TEXT,\n    \"userId\" UUID,\n    \"userIdentifier\" TEXT,\n    \"tags\" TEXT[],\n    \"metadata\" JSONB,\n    FOREIGN KEY (\"userId\") REFERENCES users(\"id\") ON DELETE CASCADE\n);\n\nCREATE TABLE IF NOT EXISTS steps (\n    \"id\" UUID PRIMARY KEY,\n    \"name\" TEXT NOT NULL,\n    \"type\" TEXT NOT NULL,\n    \"threadId\" UUID NOT NULL,\n    \"parentId\" UUID,\n    \"streaming\" BOOLEAN NOT NULL,\n    \"waitForAnswer\" BOOLEAN,\n    \"isError\" BOOLEAN,\n    \"metadata\" JSONB,\n    \"tags\" TEXT[],\n    \"input\" TEXT,\n    \"output\" TEXT,\n    \"createdAt\" TEXT,\n    \"command\" TEXT,\n    \"start\" TEXT,\n    \"end\" TEXT,\n    \"generation\" JSONB,\n    \"showInput\" TEXT,\n    \"language\" TEXT,\n    \"indent\" INT,\n    FOREIGN KEY (\"threadId\") REFERENCES threads(\"id\") ON DELETE CASCADE\n);\n\nCREATE TABLE IF NOT EXISTS elements (\n    \"id\" UUID PRIMARY KEY,\n    \"threadId\" UUID,\n    \"type\" TEXT,\n    \"url\" TEXT,\n    \"chainlitKey\" TEXT,\n    \"name\" TEXT NOT NULL,\n    \"display\" TEXT,\n    \"objectKey\" TEXT,\n    \"size\" TEXT,\n    \"page\" INT,\n    \"language\" TEXT,\n    \"forId\" UUID,\n    \"mime\" TEXT,\n    \"props\" JSONB,\n    FOREIGN KEY (\"threadId\") REFERENCES threads(\"id\") ON DELETE CASCADE\n);\n\nCREATE TABLE IF NOT EXISTS feedbacks (\n    \"id\" UUID PRIMARY KEY,\n    \"forId\" UUID NOT NULL,\n    \"threadId\" UUID NOT NULL,\n    \"value\" INT NOT NULL,\n    \"comment\" TEXT,\n    FOREIGN KEY (\"threadId\") REFERENCES threads(\"id\") ON DELETE CASCADE\n);\n\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenAI Chat Completion with Chainlit\nDESCRIPTION: Main application code that sets up an async OpenAI client with Chainlit integration. The code creates a chat completion endpoint that responds in Spanish using GPT-3.5-turbo model, demonstrating message handling and response generation.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/openai.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncOpenAI\nimport chainlit as cl\nclient = AsyncOpenAI()\n\n# Instrument the OpenAI client\ncl.instrument_openai()\n\nsettings = {\n    \"model\": \"gpt-3.5-turbo\",\n    \"temperature\": 0,\n    # ... more settings\n}\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    response = await client.chat.completions.create(\n        messages=[\n            {\n                \"content\": \"You are a helpful bot, you always reply in Spanish\",\n                \"role\": \"system\"\n            },\n            {\n                \"content\": message.content,\n                \"role\": \"user\"\n            }\n        ],\n        **settings\n    )\n    await cl.Message(content=response.choices[0].message.content).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing ChatSettings with Multiple Input Widgets in Python\nDESCRIPTION: Demonstrates how to create a dynamic settings form using ChatSettings class with various input widgets including Select, Switch, and Slider components. The example shows configuration for both OpenAI and Stability AI parameters with event handlers for chat start and settings updates.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/chat-settings.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nfrom chainlit.input_widget import Select, Switch, Slider\n\n\n@cl.on_chat_start\nasync def start():\n    settings = await cl.ChatSettings(\n        [\n            Select(\n                id=\"Model\",\n                label=\"OpenAI - Model\",\n                values=[\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-4\", \"gpt-4-32k\"],\n                initial_index=0,\n            ),\n            Switch(id=\"Streaming\", label=\"OpenAI - Stream Tokens\", initial=True),\n            Slider(\n                id=\"Temperature\",\n                label=\"OpenAI - Temperature\",\n                initial=1,\n                min=0,\n                max=2,\n                step=0.1,\n            ),\n            Slider(\n                id=\"SAI_Steps\",\n                label=\"Stability AI - Steps\",\n                initial=30,\n                min=10,\n                max=150,\n                step=1,\n                description=\"Amount of inference steps performed on image generation.\",\n            ),\n            Slider(\n                id=\"SAI_Cfg_Scale\",\n                label=\"Stability AI - Cfg_Scale\",\n                initial=7,\n                min=1,\n                max=35,\n                step=0.1,\n                description=\"Influences how strongly your generation is guided to match your prompt.\",\n            ),\n            Slider(\n                id=\"SAI_Width\",\n                label=\"Stability AI - Image Width\",\n                initial=512,\n                min=256,\n                max=2048,\n                step=64,\n                tooltip=\"Measured in pixels\",\n            ),\n            Slider(\n                id=\"SAI_Height\",\n                label=\"Stability AI - Image Height\",\n                initial=512,\n                min=256,\n                max=2048,\n                step=64,\n                tooltip=\"Measured in pixels\",\n            ),\n        ]\n    ).send()\n\n\n@cl.on_settings_update\nasync def setup_agent(settings):\n    print(\"on_settings_update\", settings)\n```\n\n----------------------------------------\n\nTITLE: Implementing Async LCEL Chat with LangChain and Chainlit\nDESCRIPTION: Creates an asynchronous chat application using LangChain Expression Language (LCEL) with streaming capabilities. Implements a historian chatbot using ChatOpenAI model and custom prompt template.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/langchain.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_openai import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.schema import StrOutputParser\nfrom langchain.schema.runnable import Runnable\nfrom langchain.schema.runnable.config import RunnableConfig\nfrom typing import cast\n\nimport chainlit as cl\n\n@cl.on_chat_start\nasync def on_chat_start():\n    model = ChatOpenAI(streaming=True)\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", \"You're a very knowledgeable historian who provides accurate and eloquent answers to historical questions.\"),\n        (\"human\", \"{question}\")\n    ])\n    runnable = prompt | model | StrOutputParser()\n    cl.user_session.set(\"runnable\", runnable)\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    runnable = cast(Runnable, cl.user_session.get(\"runnable\"))\n    msg = cl.Message(content=\"\")\n    async for chunk in runnable.astream(\n        {\"question\": message.content},\n        config=RunnableConfig(callbacks=[cl.LangchainCallbackHandler()])\n    ):\n        await msg.stream_token(chunk)\n    await msg.send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Chainlit Starters with Chat Profiles\nDESCRIPTION: Shows how to integrate starters with chat profiles using @cl.set_chat_profiles decorator. The implementation includes role-based access control and creates a chat profile with two starter suggestions.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/starters.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@cl.set_chat_profiles\nasync def chat_profile(current_user: cl.User):\n    if current_user.metadata[\"role\"] != \"ADMIN\":\n        return None\n\n    return [\n        cl.ChatProfile(\n            name=\"My Chat Profile\",\n            icon=\"https://picsum.photos/250\",\n            markdown_description=\"The underlying LLM model is **GPT-3.5**, a *175B parameter model* trained on 410GB of text data.\",\n            starters=[\n                cl.Starter(\n                    label=\"Morning routine ideation\",\n                    message=\"Can you help me create a personalized morning routine that would help increase my productivity throughout the day? Start by asking me about my current habits and what activities energize me in the morning.\",\n                    icon=\"/public/idea.svg\",\n                ),\n                cl.Starter(\n                    label=\"Explain superconductors\",\n                    message=\"Explain superconductors like I'm five years old.\",\n                    icon=\"/public/learn.svg\",\n                ),\n            ],\n        )\n    ]\n```\n\n----------------------------------------\n\nTITLE: Implementing SQLAlchemy Data Layer in Chainlit\nDESCRIPTION: This snippet demonstrates how to import and implement the SQLAlchemy data layer in a Chainlit application. It uses the @cl.data_layer decorator to define a function that returns an instance of SQLAlchemyDataLayer with a connection string.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-layers/overview.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\nfrom chainlit.data.sql_alchemy import SQLAlchemyDataLayer\n\n@cl.data_layer\ndef get_data_layer():\n    return SQLAlchemyDataLayer(conninfo=\"...\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Chainlit Application with Embedchain Integration in Python\nDESCRIPTION: This code snippet demonstrates how to create a Chainlit application integrated with Embedchain. It sets up the necessary environment, initializes the Embedchain app, and defines functions to handle chat sessions and incoming messages.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/embedchain.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nfrom embedchain import Pipeline as App\n\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\"\n\n@cl.on_chat_start\nasync def on_chat_start():\n    app = App.from_config(config={\n        'app': {\n            'config': {\n                'name': 'chainlit-app'\n            }\n        },\n        'llm': {\n            'config': {\n                'stream': True,\n            }\n        }\n    })\n    # import your data here\n    app.add(\"https://www.forbes.com/profile/elon-musk/\")\n    app.collect_metrics = False\n    cl.user_session.set(\"app\", app)\n\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    app = cl.user_session.get(\"app\")\n    msg = cl.Message(content=\"\")\n    for chunk in await cl.make_async(app.chat)(message.content):\n        await msg.stream_token(chunk)\n    \n    await msg.send()\n```\n\n----------------------------------------\n\nTITLE: Implementing LangGraph Weather Assistant with Chainlit\nDESCRIPTION: Creates a weather assistant using LangGraph with custom tools and multiple model nodes. Implements a state graph for handling tool calls and message processing with Al Roker's voice styling.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/langchain.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Literal\nfrom langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.prebuilt import ToolNode\nfrom langchain.schema.runnable.config import RunnableConfig\nfrom langchain_core.messages import HumanMessage\n\nimport chainlit as cl\n\n@tool\ndef get_weather(city: Literal[\"nyc\", \"sf\"]):\n    \"\"\"Use this to get weather information.\"\"\"\n    if city == \"nyc\":\n        return \"It might be cloudy in nyc\"\n    elif city == \"sf\":\n        return \"It's always sunny in sf\"\n    else:\n        raise AssertionError(\"Unknown city\")\n\ntools = [get_weather]\nmodel = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\nfinal_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n\nmodel = model.bind_tools(tools)\nfinal_model = final_model.with_config(tags=[\"final_node\"])\ntool_node = ToolNode(tools=tools)\n\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import MessagesState\nfrom langchain_core.messages import BaseMessage, SystemMessage, HumanMessage\n\ndef should_continue(state: MessagesState) -> Literal[\"tools\", \"final\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if last_message.tool_calls:\n        return \"tools\"\n    return \"final\"\n\ndef call_model(state: MessagesState):\n    messages = state[\"messages\"]\n    response = model.invoke(messages)\n    return {\"messages\": [response]}\n\ndef call_final_model(state: MessagesState):\n    messages = state[\"messages\"]\n    last_ai_message = messages[-1]\n    response = final_model.invoke([\n        SystemMessage(\"Rewrite this in the voice of Al Roker\"),\n        HumanMessage(last_ai_message.content)\n    ])\n    response.id = last_ai_message.id\n    return {\"messages\": [response]}\n\nbuilder = StateGraph(MessagesState)\nbuilder.add_node(\"agent\", call_model)\nbuilder.add_node(\"tools\", tool_node)\nbuilder.add_node(\"final\", call_final_model)\nbuilder.add_edge(START, \"agent\")\nbuilder.add_conditional_edges(\"agent\", should_continue)\nbuilder.add_edge(\"tools\", \"agent\")\nbuilder.add_edge(\"final\", END)\ngraph = builder.compile()\n\n@cl.on_message\nasync def on_message(msg: cl.Message):\n    config = {\"configurable\": {\"thread_id\": cl.context.session.id}}\n    cb = cl.LangchainCallbackHandler()\n    final_answer = cl.Message(content=\"\")\n    for msg, metadata in graph.stream({\"messages\": [HumanMessage(content=msg.content)]}, stream_mode=\"messages\", config=RunnableConfig(callbacks=[cb], **config)):\n        if (msg.content and not isinstance(msg, HumanMessage) and metadata[\"langgraph_node\"] == \"final\"):\n            await final_answer.stream_token(msg.content)\n    await final_answer.send()\n```\n\n----------------------------------------\n\nTITLE: Implementing ChainLit Message Handler and Starter Queries\nDESCRIPTION: Implementation of the main message handler with streaming response and starter query functionality. Includes decorators for ChainLit message handling and starter query definition.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/openai-sql.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@cl.set_starters\nasync def starters():\n    return [\n       cl.Starter(\n           label=\">50 minutes watched\",\n           message=\"Compute the number of customers who watched more than 50 minutes of video this month.\"\n       )\n    ]\n\n@cl.on_message\nasync def main(message: cl.Message):\n    stream = await client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": template.format(input=message.content),\n            }\n        ], stream=True, **settings\n    )\n\n    msg = await cl.Message(content=\"\", language=\"sql\").send()\n\n    async for part in stream:\n        if token := part.choices[0].delta.content or \"\":\n            await msg.stream_token(token)\n\n    await msg.update()\n```\n\n----------------------------------------\n\nTITLE: Creating and Handling Action Buttons in Chainlit Python\nDESCRIPTION: This code snippet demonstrates how to create action buttons, attach them to messages, and handle user interactions with these buttons in a Chainlit chatbot. It includes setting up an action callback and sending a message with an attached action button.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/action.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.action_callback(\"action_button\")\nasync def on_action(action):\n    await cl.Message(content=f\"Executed {action.name}\").send()\n    # Optionally remove the action button from the chatbot user interface\n    await action.remove()\n\n@cl.on_chat_start\nasync def start():\n    # Sending an action button within a chatbot message\n    actions = [\n        cl.Action(name=\"action_button\", payload={\"value\": \"example_value\"}, label=\"Click me!\")\n    ]\n\n    await cl.Message(content=\"Interact with this action button:\", actions=actions).send()\n```\n\n----------------------------------------\n\nTITLE: Specifying Message Author Directly in Chainlit with Python\nDESCRIPTION: This example shows how to set a custom author name when creating a new message object in Chainlit. It demonstrates integration with LangChain and OpenAI, and specifies the author at the time of message creation.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/author-rename.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain import OpenAI, LLMMathChain\nimport chainlit as cl\n\n@cl.on_message\nasync def main(message: cl.Message):\n    llm = OpenAI(temperature=0)\n    llm_math = LLMMathChain.from_llm(llm=llm)\n    res = await llm_math.acall(message.content, callbacks=[cl.AsyncLangchainCallbackHandler()])\n\n    # Specify the author at message creation\n    response_message = cl.Message(content=\"Hello\", author=\"NewChatBotName\")\n    await response_message.send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Langchain Callback Handler in Python\nDESCRIPTION: Demonstrates how to pass a callback handler to a Langchain LLM chain. Uses OpenAI LLM with LLMMathChain and integrates with Chainlit messaging.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/integrations/langchain.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nllm = OpenAI(temperature=0)\nllm_math = LLMMathChain.from_llm(llm=llm)\n\n@cl.on_message\nasync def main(message: cl.Message):\n\n    res = await llm_math.acall(message.content, callbacks=[cl.LangchainCallbackHandler()])\n\n    await cl.Message(content=\"Hello\").send()\n```\n\n----------------------------------------\n\nTITLE: Requesting Text File Upload in Python using Chainlit\nDESCRIPTION: Example demonstrating how to request a text file upload from users, process the file contents, and provide feedback. Uses an async function with a while loop to ensure file upload completion.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/ask/ask-for-file.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_chat_start\nasync def start():\n    files = None\n\n    # Wait for the user to upload a file\n    while files == None:\n        files = await cl.AskFileMessage(\n            content=\"Please upload a text file to begin!\", accept=[\"text/plain\"]\n        ).send()\n\n    text_file = files[0]\n\n    with open(text_file.path, \"r\", encoding=\"utf-8\") as f:\n        text = f.read()\n\n    # Let the user know that the system is ready\n    await cl.Message(\n        content=f\"`{text_file.name}` uploaded, it contains {len(text)} characters!\"\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Creating an Interactive Counter with Chainlit Custom Element\nDESCRIPTION: This example shows how to create an interactive counter element with increment and remove buttons using Chainlit's CustomElement. It demonstrates how to update element properties and handle user interactions.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/custom.mdx#2025-04-21_snippet_3\n\nLANGUAGE: jsx\nCODE:\n```\nimport { Button } from \"@/components/ui/button\"\nimport { X, Plus } from 'lucide-react';\n\nexport default function Counter() {\n    return (\n        <div id=\"custom-counter\" className=\"mt-4 flex flex-col gap-2\">\n                <div>Count: {props.count}</div>\n                <Button id=\"increment\" onClick={() => updateElement(Object.assign(props, {count: props.count + 1}))}><Plus /> Increment</Button>\n                <Button id=\"remove\" onClick={deleteElement}><X /> Remove</Button>\n        </div>\n    );\n}\n```\n\n----------------------------------------\n\nTITLE: Using the on_message Decorator in Chainlit\nDESCRIPTION: Example of how to implement a message handler using the on_message decorator in Chainlit. This function will be called every time a new message is received from the UI, allowing developers to process user messages and implement custom logic.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/lifecycle-hooks/on-message.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\ndef main(message: cl.Message):\n  content = message.content\n  # do something\n```\n\n----------------------------------------\n\nTITLE: Creating and Sending an Image in Chainlit (Python)\nDESCRIPTION: This example demonstrates how to create an Image object and send it as part of a message in a Chainlit application. It uses the on_chat_start event to send an image when the chat begins.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/image.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    image = cl.Image(path=\"./cat.jpeg\", name=\"image1\", display=\"inline\")\n\n    # Attach the image to the message\n    await cl.Message(\n        content=\"This message has an image!\",\n        elements=[image],\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Displaying Inline PDF in Chainlit Chatbot\nDESCRIPTION: This example demonstrates how to send a local PDF file to be displayed inline in the chatbot UI using Chainlit. It uses the on_chat_start event to send a message with a PDF element attached.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/pdf.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    # Sending a pdf with the local file path\n    elements = [\n      cl.Pdf(name=\"pdf1\", display=\"inline\", path=\"./pdf1.pdf\", page=1)\n    ]\n\n    await cl.Message(content=\"Look at this local pdf!\", elements=elements).send()\n```\n\n----------------------------------------\n\nTITLE: Basic Chainlit-Slack Integration Example\nDESCRIPTION: Python example showing basic Chainlit app setup with Slack integration, including message handling and file attachment access\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/slack.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def on_message(msg: cl.Message):\n    # Access the original slack event\n    print(cl.user_session.get(\"slack_event\"))\n    # Access the slack user\n    print(cl.user_session.get(\"user\"))\n\n    # Access potential attached files\n    attached_files = msg.elements\n\n    await cl.Message(content=\"Hello World\").send()\n```\n\n----------------------------------------\n\nTITLE: Mounting Chainlit in FastAPI Application\nDESCRIPTION: FastAPI application setup that includes a basic endpoint and mounts a Chainlit application at a specified path\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/fastapi.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\nfrom chainlit.utils import mount_chainlit\n\napp = FastAPI()\n\n\n@app.get(\"/app\")\ndef read_main():\n    return {\"message\": \"Hello World from main app\"}\n\nmount_chainlit(app=app, target=\"my_cl_app.py\", path=\"/chainlit\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Calls with Chainlit Steps in Python\nDESCRIPTION: This example demonstrates how to create a simple Chain of Thought using Chainlit. It defines a tool function decorated with @cl.step and an on_message handler that calls the tool and sends a final response.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/step.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.step(type=\"tool\")\nasync def tool():\n    # Simulate a running task\n    await cl.sleep(2)\n\n    return \"Response from the tool!\"\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    # Call the tool\n    tool_res = await tool()\n\n    # Send the final answer.\n    await cl.Message(content=\"This is the final answer\").send()\n```\n\n----------------------------------------\n\nTITLE: Displaying Audio in Chainlit Chatbot UI\nDESCRIPTION: This example demonstrates how to use the Audio class to display an audio player in a Chainlit chatbot interface. It creates an Audio element with a local file path and sends it as part of a message on chat start.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/audio.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    elements = [\n        cl.Audio(name=\"example.mp3\", path=\"./example.mp3\", display=\"inline\"),\n    ]\n    await cl.Message(\n        content=\"Here is an audio file\",\n        elements=elements,\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Creating and Displaying an Interactive Plotly Chart in Chainlit\nDESCRIPTION: This example demonstrates how to create a Plotly bar chart and display it inline with a message in a Chainlit chatbot. The code sets up a simple figure with a bar chart and attaches it to a message as an inline element.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/plotly.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport plotly.graph_objects as go\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    fig = go.Figure(\n        data=[go.Bar(y=[2, 1, 3])],\n        layout_title_text=\"An example figure\",\n    )\n    elements = [cl.Plotly(name=\"chart\", figure=fig, display=\"inline\")]\n\n    await cl.Message(content=\"This message has a chart\", elements=elements).send()\n```\n\n----------------------------------------\n\nTITLE: Streaming Output in Chainlit Steps with OpenAI\nDESCRIPTION: This code shows how to stream tokens from OpenAI's API within a Chainlit step. It creates a chat completion stream and sends tokens to the UI as they arrive.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/step-decorator.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncOpenAI\n\nimport chainlit as cl\n\nclient = AsyncOpenAI(api_key=\"YOUR_API_KEY\")\n\n@cl.step(type=\"llm\")\nasync def gpt4():\n    settings = {\n        \"model\": \"gpt-4\",\n        \"temperature\": 0,\n    }\n\n    stream = await client.chat.completions.create(\n        messages=message_history, stream=True, **settings\n    )\n\n    current_step = cl.context.current_step\n\n    async for part in stream:\n        delta = part.choices[0].delta\n\n        if delta.content:\n            # Stream the output of the step\n            await current_step.stream_token(delta.content)\n```\n\n----------------------------------------\n\nTITLE: Implementing Authentication-Based Chat Profiles in Chainlit\nDESCRIPTION: This snippet shows how to create chat profiles with authentication. It includes a password authentication callback and conditionally returns chat profiles based on the user's role. The example also demonstrates how to access user information in the chat start handler.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/chat-profiles.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\n\nimport chainlit as cl\n\n\n@cl.set_chat_profiles\nasync def chat_profile(current_user: cl.User):\n    if current_user.metadata[\"role\"] != \"ADMIN\":\n        return None\n\n    return [\n        cl.ChatProfile(\n            name=\"GPT-3.5\",\n            markdown_description=\"The underlying LLM model is **GPT-3.5**, a *175B parameter model* trained on 410GB of text data.\",\n        ),\n        cl.ChatProfile(\n            name=\"GPT-4\",\n            markdown_description=\"The underlying LLM model is **GPT-4**, a *1.5T parameter model* trained on 3.5TB of text data.\",\n            icon=\"https://picsum.photos/250\",\n        ),\n        cl.ChatProfile(\n            name=\"GPT-5\",\n            markdown_description=\"The underlying LLM model is **GPT-5**.\",\n            icon=\"https://picsum.photos/200\",\n        ),\n    ]\n\n\n@cl.password_auth_callback\ndef auth_callback(username: str, password: str) -> Optional[cl.User]:\n    if (username, password) == (\"admin\", \"admin\"):\n        return cl.User(identifier=\"admin\", metadata={\"role\": \"ADMIN\"})\n    else:\n        return None\n\n\n@cl.on_chat_start\nasync def on_chat_start():\n    user = cl.user_session.get(\"user\")\n    chat_profile = cl.user_session.get(\"chat_profile\")\n    await cl.Message(\n        content=f\"starting chat with {user.identifier} using the {chat_profile} chat profile\"\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing TaskList in Chainlit Python Application\nDESCRIPTION: Demonstrates how to create and manage a TaskList in a Chainlit chatbot application. Shows creation of tasks, updating their statuses, and linking tasks to messages. The example includes creating running and ready tasks, updating their statuses to done/failed, and managing the overall TaskList status.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/tasklist.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    # Create the TaskList\n    task_list = cl.TaskList()\n    task_list.status = \"Running...\"\n\n    # Create a task and put it in the running state\n    task1 = cl.Task(title=\"Processing data\", status=cl.TaskStatus.RUNNING)\n    await task_list.add_task(task1)\n    # Create another task that is in the ready state\n    task2 = cl.Task(title=\"Performing calculations\")\n    await task_list.add_task(task2)\n\n    # Optional: link a message to each task to allow task navigation in the chat history\n    message = await cl.Message(content=\"Started processing data\").send()\n    task1.forId = message.id\n\n    # Update the task list in the interface\n    await task_list.send()\n\n    # Perform some action on your end\n    await cl.sleep(1)\n\n    # Update the task statuses\n    task1.status = cl.TaskStatus.DONE\n    task2.status = cl.TaskStatus.FAILED\n    task_list.status = \"Failed\"\n    await task_list.send()\n```\n\n----------------------------------------\n\nTITLE: Creating and Displaying a Matplotlib Pyplot Chart with Chainlit\nDESCRIPTION: This example demonstrates how to create a simple Matplotlib plot and display it inline using Chainlit's Pyplot class. It uses the on_chat_start decorator to define a function that creates the plot and sends it as part of a message.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/pyplot.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3, 4], [1, 4, 2, 3])\n\n    elements = [\n        cl.Pyplot(name=\"plot\", figure=fig, display=\"inline\"),\n    ]\n    await cl.Message(\n        content=\"Here is a simple plot\",\n        elements=elements,\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing PII Detection in Chainlit Application\nDESCRIPTION: This code snippet demonstrates how to create an async context manager that uses Presidio Analyzer to detect PII in incoming messages. It prompts the user to continue or cancel if PII is detected.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/security.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom presidio_analyzer import AnalyzerEngine\nfrom contextlib import asynccontextmanager\n\nanalyzer = AnalyzerEngine()\n\n@asynccontextmanager\nasync def check_text(text: str):\n  pii_results = analyzer.analyze(text=text, language=\"en\")\n\n  if pii_results:\n    response = await cl.AskActionMessage(\n      content=\"PII detected\",\n      actions=[\n        cl.Action(name=\"continue\", payload={\"value\": \"continue\"}, label=\"✅ Continue\"),\n        cl.Action(name=\"cancel\", payload={\"value\": \"continue\"}, label=\"❌ Cancel\"),\n      ],\n    ).send()\n\n    if response is None or response.get(\"payload\").get(\"value\") == \"cancel\":\n      raise InterruptedError\n\n  yield\n\n# ...\n\n@cl.on_message\nasync def main(message: cl.Message):\n  async with check_text(message.content):\n    # This block is only executed when the user press \"Continue\"\n    response = await cl.Message(\n        content=f\"Received: {message.content}\",\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Switch Input Widget in Chainlit Python\nDESCRIPTION: This code snippet demonstrates how to use the Switch input widget in a Chainlit application. It creates a chat settings dialog with a switch for toggling OpenAI token streaming. The switch value can be retrieved from the settings dictionary.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/input-widgets/switch.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nfrom chainlit.input_widget import Switch\n\n\n@cl.on_chat_start\nasync def start():\n    settings = await cl.ChatSettings(\n        [\n            Switch(id=\"Streaming\", label=\"OpenAI - Stream Tokens\", initial=True),\n        ]\n    ).send()\n    value = settings[\"Streaming\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring Streaming with Langchain in Chainlit\nDESCRIPTION: This code snippet shows how to enable streaming when using Chainlit with Langchain integration. It demonstrates the simple configuration needed to activate streaming by setting the streaming parameter to true when instantiating the OpenAI LLM.\nSOURCE: https://github.com/chainlit/docs/blob/main/advanced-features/streaming.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nllm = OpenAI(temperature=0, streaming=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Password Authentication Callback in Python with Chainlit\nDESCRIPTION: This code snippet demonstrates how to use the @cl.password_auth_callback decorator to implement a password authentication system in Chainlit. It verifies the username and password, and returns a cl.User object for successful authentication or None for failed attempts.\nSOURCE: https://github.com/chainlit/docs/blob/main/authentication/password.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\nimport chainlit as cl\n\n@cl.password_auth_callback\ndef auth_callback(username: str, password: str):\n    # Fetch the user matching username from your database\n    # and compare the hashed password with the value stored in the database\n    if (username, password) == (\"admin\", \"admin\"):\n        return cl.User(\n            identifier=\"admin\", metadata={\"role\": \"admin\", \"provider\": \"credentials\"}\n        )\n    else:\n        return None\n```\n\n----------------------------------------\n\nTITLE: Implementing Chainlit Slider Widget in Python\nDESCRIPTION: Example demonstrating how to create and configure a slider widget in Chainlit for temperature control. The slider is initialized with custom parameters and its value can be retrieved from settings. This example shows integration with OpenAI temperature parameter.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/input-widgets/slider.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nfrom chainlit.input_widget import Slider\n\n\n@cl.on_chat_start\nasync def start():\n    settings = await cl.ChatSettings(\n        [\n            Slider(\n                id=\"Temperature\",\n                label=\"OpenAI - Temperature\",\n                initial=1,\n                min=0,\n                max=2,\n                step=0.1,\n            ),\n        ]\n    ).send()\n    value = settings[\"Temperature\"]\n\n```\n\n----------------------------------------\n\nTITLE: Handling Chainlit Function Calls in Python\nDESCRIPTION: Illustrates function call handling on the Chainlit server, responding to messages from the client. The Python function creates a CopilotFunction instance, makes an asynchronous call, and sends the result back to the client. Dependencies include a working Chainlit server and an event listener in the client app.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/copilot.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def on_message(msg: cl.Message):\n    if cl.context.session.client_type == \"copilot\":\n        fn = cl.CopilotFunction(name=\"test\", args={\"msg\": msg.content})\n        res = await fn.acall()\n        await cl.Message(content=res).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Linear Ticket Status App in Chainlit\nDESCRIPTION: A Python example that creates and displays a custom Linear ticket element in Chainlit. The code simulates fetching ticket data and renders it using a CustomElement.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/custom.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\nasync def get_ticket():\n    \"\"\"Pretending to fetch data from linear\"\"\"\n    return {\n        \"title\": \"Fix Authentication Bug\",\n        \"status\": \"in-progress\",\n        \"assignee\": \"Sarah Chen\",\n        \"deadline\": \"2025-01-15\",\n        \"tags\": [\"security\", \"high-priority\", \"backend\"]\n    }\n\n@cl.on_message\nasync def on_message(msg: cl.Message):\n    # Let's pretend the user is asking about a linear ticket.\n    # Usually an LLM with tool calling would be used to decide to render the component or not.\n    \n    props = await get_ticket()\n    \n    ticket_element = cl.CustomElement(name=\"LinearTicket\", props=props)\n    # Store the element if we want to update it server side at a later stage.\n    cl.user_session.set(\"ticket_el\", ticket_element)\n    \n    await cl.Message(content=\"Here is the ticket information!\", elements=[ticket_element]).send()\n```\n\n----------------------------------------\n\nTITLE: Defining SQL Query Template and LLM Settings\nDESCRIPTION: Configuration of the prompt template for SQL tables and columns, along with OpenAI model parameters including temperature and token limits.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/openai-sql.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntemplate = \"\"\"SQL tables (and columns):\n* Customers(customer_id, signup_date)\n* Streaming(customer_id, video_id, watch_date, watch_minutes)\n\nA well-written SQL query that {input}:\n```\"\"\"\n\n\nsettings = {\n    \"model\": \"gpt-3.5-turbo\",\n    \"temperature\": 0,\n    \"max_tokens\": 500,\n    \"top_p\": 1,\n    \"frequency_penalty\": 0,\n    \"presence_penalty\": 0,\n    \"stop\": [\"```\"],\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Message Counter Using User Session in Python\nDESCRIPTION: This snippet shows the correct implementation of a message counter using Chainlit's user session. It initializes a counter for each chat session and increments it individually for each user.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/user-session.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\ndef on_chat_start():\n    cl.user_session.set(\"counter\", 0)\n\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    counter = cl.user_session.get(\"counter\")\n    counter += 1\n    cl.user_session.set(\"counter\", counter)\n\n    await cl.Message(content=f\"You sent {counter} message(s)!\").send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Chainlit Starters\nDESCRIPTION: Demonstrates how to set up basic starter suggestions using the @cl.set_starters decorator. The code shows implementation of four different starters with labels, messages, and icons for morning routine, superconductors explanation, Python scripting, and wedding invitation scenarios.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/starters.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.set_starters\nasync def set_starters():\n    return [\n        cl.Starter(\n            label=\"Morning routine ideation\",\n            message=\"Can you help me create a personalized morning routine that would help increase my productivity throughout the day? Start by asking me about my current habits and what activities energize me in the morning.\",\n            icon=\"/public/idea.svg\",\n            ),\n\n        cl.Starter(\n            label=\"Explain superconductors\",\n            message=\"Explain superconductors like I'm five years old.\",\n            icon=\"/public/learn.svg\",\n            ),\n        cl.Starter(\n            label=\"Python script for daily email reports\",\n            message=\"Write a script to automate sending daily email reports in Python, and walk me through how I would set it up.\",\n            icon=\"/public/terminal.svg\",\n            ),\n        cl.Starter(\n            label=\"Text inviting friend to wedding\",\n            message=\"Write a text asking a friend to be my plus-one at a wedding next month. I want to keep it super short and casual, and offer an out.\",\n            icon=\"/public/write.svg\",\n            )\n        ]\n# ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Text Element in Chainlit Chatbot\nDESCRIPTION: This example demonstrates how to create and send a text element in a Chainlit application. It creates a simple text element with inline display and sends it as part of a message when the chat starts.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/text.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    text_content = \"Hello, this is a text element.\"\n    elements = [\n        cl.Text(name=\"simple_text\", content=text_content, display=\"inline\")\n    ]\n\n    await cl.Message(\n        content=\"Check out this text element!\",\n        elements=elements,\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Chainlit Function Call Event Listener in JavaScript\nDESCRIPTION: Sets up a JavaScript event listener on the client side to handle function calls triggered by the Chainlit Copilot. The listener processes the function name and arguments, then executes a callback with the response. No external dependencies are required.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/copilot.mdx#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nwindow.addEventListener(\"chainlit-call-fn\", (e) => {\n  const { name, args, callback } = e.detail;\n  if (name === \"test\") {\n    console.log(name, args);\n    callback(\"You sent: \" + args.msg);\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Simple Chat Profiles in Chainlit\nDESCRIPTION: This snippet demonstrates how to create a basic list of chat profiles using the @cl.set_chat_profiles decorator. It defines two profiles (GPT-3.5 and GPT-4) with names, descriptions, and icons.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/chat-profiles.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.set_chat_profiles\nasync def chat_profile():\n    return [\n        cl.ChatProfile(\n            name=\"GPT-3.5\",\n            markdown_description=\"The underlying LLM model is **GPT-3.5**.\",\n            icon=\"https://picsum.photos/200\",\n        ),\n        cl.ChatProfile(\n            name=\"GPT-4\",\n            markdown_description=\"The underlying LLM model is **GPT-4**.\",\n            icon=\"https://picsum.photos/250\",\n        ),\n    ]\n\n@cl.on_chat_start\nasync def on_chat_start():\n    chat_profile = cl.user_session.get(\"chat_profile\")\n    await cl.Message(\n        content=f\"starting chat using the {chat_profile} chat profile\"\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Converting Synchronous Function to Asynchronous with make_async in Python\nDESCRIPTION: This example demonstrates how to use the make_async function to convert a simple synchronous function that sleeps for 5 seconds into an asynchronous function. The converted function is then used in a Chainlit message handler.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/make-async.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport time\nimport chainlit as cl\n\ndef sync_func():\n    time.sleep(5)\n    return \"Hello!\"\n\n@cl.on_message\nasync def main(message: cl.Message):\n    answer = await cl.make_async(sync_func)()\n    await cl.Message(\n        content=answer,\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing PII Anonymization in Chainlit Application\nDESCRIPTION: This code snippet extends the previous example to include PII anonymization using Presidio Anonymizer. It returns anonymized text when PII is detected and the user chooses to continue.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/security.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom presidio_anonymizer import AnonymizerEngine\n\nanonymizer = AnonymizerEngine()\n\n@asynccontextmanager\nasync def check_text(text: str):\n  pii_results = analyzer.analyze(text=text, language=\"en\")\n\n  if pii_results:\n    response = await cl.AskActionMessage(\n      content=\"PII detected\",\n      actions=[\n        cl.Action(name=\"continue\", payload={\"value\": \"continue\"}, label=\"✅ Continue\"),\n        cl.Action(name=\"cancel\", payload={\"value\": \"continue\"}, label=\"❌ Cancel\"),\n      ],\n    ).send()\n\n    if response is None or response.get(\"payload\").get(\"value\") == \"cancel\":\n      raise InterruptedError\n\n    yield anonymizer.anonymize(\n      text=text,\n      analyzer_results=pii_results,\n    ).text\n  else:\n    yield text\n\n# ...\n\n@cl.on_message\nasync def main(message: cl.Message):\n  async with check_text(message.content) as anonymized_message:\n    response = await llm_chain.arun(\n      anonymized_message\n      callbacks=[cl.AsyncLangchainCallbackHandler()]\n    )\n```\n\n----------------------------------------\n\nTITLE: Displaying Side and Page PDFs in Chainlit Chatbot\nDESCRIPTION: This example shows how to send a local PDF file to be displayed in the side panel or as a separate page in the chatbot UI using Chainlit. It demonstrates the importance of including the PDF name in the message content for creating a link.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/pdf.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    # Sending a pdf with the local file path\n    elements = [\n      cl.Pdf(name=\"pdf1\", display=\"side\", path=\"./pdf1.pdf\", page=1)\n    ]\n    # Reminder: The name of the pdf must be in the content of the message\n    await cl.Message(content=\"Look at this local pdf1!\", elements=elements).send()\n```\n\n----------------------------------------\n\nTITLE: Displaying an Image Element with 'Page' Option in Python\nDESCRIPTION: This code demonstrates the 'page' display option for an Image element. The image name appears as a clickable link in the message, redirecting to a dedicated page when clicked.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/element.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_start\nasync def start():\n    # Notice the display option\n    image = cl.Image(path=\"./cat.jpeg\", name=\"cat image\", display=\"page\")\n\n    await cl.Message(\n        # Notice that the name of the image is referenced in the message content\n        content=\"Here is the cat image!\",\n        elements=[image],\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing on_chat_end Hook in Chainlit Python\nDESCRIPTION: This example demonstrates how to implement both on_chat_start and on_chat_end hooks in Chainlit. The on_chat_start function prints a greeting with the user's ID when they connect, while the on_chat_end function prints a goodbye message with the user's ID when they disconnect.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/lifecycle-hooks/on-chat-end.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\ndef start():\n    print(\"hello\", cl.user_session.get(\"id\"))\n\n\n@cl.on_chat_end\ndef end():\n    print(\"goodbye\", cl.user_session.get(\"id\"))\n\n```\n\n----------------------------------------\n\nTITLE: Implementing on_chat_start Hook in Python with Chainlit\nDESCRIPTION: This code snippet demonstrates how to use the on_chat_start hook in Chainlit to interact with a user upon connection. It asks for the user's name and responds with a confirmation message.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/lifecycle-hooks/on-chat-start.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom chainlit import AskUserMessage, Message, on_chat_start\n\n\n@on_chat_start\nasync def main():\n    res = await AskUserMessage(content=\"What is your name?\", timeout=30).send()\n    if res:\n        await Message(\n            content=f\"Your name is: {res['content']}.\\nChainlit installation is working!\\nYou can now start building your own chainlit apps!\",\n        ).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Select Widget in Chainlit Python Application\nDESCRIPTION: This code demonstrates how to create and use a Select dropdown widget in a Chainlit application. The example creates a model selection dropdown with OpenAI model options and retrieves the selected value from the settings. The widget is initialized when a chat starts using the on_chat_start decorator.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/input-widgets/select.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nfrom chainlit.input_widget import Select\n\n\n@cl.on_chat_start\nasync def start():\n    settings = await cl.ChatSettings(\n        [\n            Select(\n                id=\"Model\",\n                label=\"OpenAI - Model\",\n                values=[\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-4\", \"gpt-4-32k\"],\n                initial_index=0,\n            )\n        ]\n    ).send()\n    value = settings[\"Model\"]\n\n```\n\n----------------------------------------\n\nTITLE: Embedding Chainlit Copilot Script in HTML\nDESCRIPTION: This snippet demonstrates how to embed the Chainlit Copilot into a web page by including the Copilot script and setting up event listeners to handle function calls from the Chainlit server. Dependencies include a running Chainlit server and a web server to serve the HTML file.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/copilot.mdx#2025-04-21_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<head>\n  <meta charset=\"utf-8\" />\n</head>\n<body>\n  <!-- ... -->\n  <script src=\"http://localhost:8000/copilot/index.js\"></script>\n  <script>\n    window.addEventListener(\"chainlit-call-fn\", (e) => {\n      const { name, args, callback } = e.detail;\n      callback(\"You sent: \" + args.msg);\n    });\n  </script>\n  <script>\n    window.mountChainlitWidget({\n      chainlitServer: \"http://localhost:8000\",\n    });\n  </script>\n</body>\n```\n\n----------------------------------------\n\nTITLE: Implementing User Input Dialog with Chainlit\nDESCRIPTION: Example showing how to create an interactive user input dialog using the AskUserMessage class. The code demonstrates handling user responses with timeout functionality and displaying the response back to the user.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/ask/ask-for-input.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    res = await cl.AskUserMessage(content=\"What is your name?\", timeout=10).send()\n    if res:\n        await cl.Message(\n            content=f\"Your name is: {res['output']}\",\n        ).send()\n```\n\n----------------------------------------\n\nTITLE: Managing Chat Context with Chainlit\nDESCRIPTION: Demonstrates how to access and use the chat context feature in Chainlit. Shows how to retrieve conversation history in OpenAI format for context-aware responses.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/message.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    # Get all the messages in the conversation in the OpenAI format\n    print(cl.chat_context.to_openai())\n\n    # Send the response\n    response = f\"Hello, you just sent: {message.content}!\"\n    await cl.Message(response).send()\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Client and ChainLit\nDESCRIPTION: Setting up the AsyncOpenAI client with API key and instrumenting OpenAI with ChainLit for monitoring.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/openai-sql.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncOpenAI\n\n\nimport chainlit as cl\n\ncl.instrument_openai()\n\nclient = AsyncOpenAI(api_key=\"YOUR_OPENAI_API_KEY\")\n```\n\n----------------------------------------\n\nTITLE: Handling User Messages in Chainlit Python Application\nDESCRIPTION: Implements a message handler using @cl.on_message decorator that processes incoming user messages. The handler receives a Message object containing the message content.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/chat-lifecycle.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_message\ndef on_message(msg: cl.Message):\n    print(\"The user sent: \", msg.content)\n```\n\n----------------------------------------\n\nTITLE: Renaming Message Authors with author_rename Decorator in Python\nDESCRIPTION: This snippet demonstrates how to use the @cl.author_rename decorator to dynamically rename message authors. It includes a rename function that maps original author names to new ones, and shows integration with LangChain and OpenAI.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/author-rename.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain import OpenAI, LLMMathChain\nimport chainlit as cl\n\n\n@cl.author_rename\ndef rename(orig_author: str):\n    rename_dict = {\"LLMMathChain\": \"Albert Einstein\", \"Chatbot\": \"Assistant\"}\n    return rename_dict.get(orig_author, orig_author)\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    llm = OpenAI(temperature=0)\n    llm_math = LLMMathChain.from_llm(llm=llm)\n    res = await llm_math.acall(message.content, callbacks=[cl.AsyncLangchainCallbackHandler()])\n\n    await cl.Message(content=\"Hello\").send()\n```\n\n----------------------------------------\n\nTITLE: Processing Attached Files in Chainlit Messages\nDESCRIPTION: This code snippet demonstrates how to handle file attachments in Chainlit messages. It processes attached images, reads the first image file, and sends a response indicating the number of images received.\nSOURCE: https://github.com/chainlit/docs/blob/main/advanced-features/multi-modal.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_message\nasync def on_message(msg: cl.Message):\n    if not msg.elements:\n        await cl.Message(content=\"No file attached\").send()\n        return\n\n    # Processing images exclusively\n    images = [file for file in msg.elements if \"image\" in file.mime]\n\n    # Read the first image\n    with open(images[0].path, \"r\") as f:\n        pass\n\n    await cl.Message(content=f\"Received {len(images)} image(s)\").send()\n\n```\n\n----------------------------------------\n\nTITLE: Controlling Element Sidebar Programmatically in Python\nDESCRIPTION: This code demonstrates how to control the Element Sidebar from Python in Chainlit. It shows setting elements and title on chat start, updating them on message, and closing the sidebar by setting elements to an empty array.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/element.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    # Define the elements you want to display\n    elements = [\n        cl.Image(path=\"./cat.jpeg\", name=\"image1\"),\n        cl.Pdf(path=\"./dummy.pdf\", name=\"pdf1\"),\n        cl.Text(content=\"Here is a side text document\", name=\"text1\"),\n        cl.Text(content=\"Here is a page text document\", name=\"text2\"),\n    ]\n\n    # Setting elements will open the sidebar\n    await cl.ElementSidebar.set_elements(elements)\n    await cl.ElementSidebar.set_title(\"Test title\")\n\n@cl.on_message\nasync def message(msg: cl.Message):\n    # You can update the elements\n    await cl.ElementSidebar.set_elements([cl.Text(content=\"Text changed!\")])\n    # You can update the title\n    await cl.ElementSidebar.set_title(\"Title changed!\")\n\n    await cl.sleep(2)\n\n    # Setting the elements to an empty array will close the sidebar\n    await cl.ElementSidebar.set_elements([])\n```\n\n----------------------------------------\n\nTITLE: Setting and Handling Chainlit Commands in Python\nDESCRIPTION: This code snippet demonstrates how to set available commands using cl.context.emitter.set_commands and handle command selection in the on_message event. It includes examples of command definitions and basic command handling logic.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/command.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\ncommands = [\n    {\"id\": \"Picture\", \"icon\": \"image\", \"description\": \"Use DALL-E\"},\n    {\"id\": \"Search\", \"icon\": \"globe\", \"description\": \"Find on the web\"},\n    {\n        \"id\": \"Canvas\",\n        \"icon\": \"pen-line\",\n        \"description\": \"Collaborate on writing and code\",\n    },\n]\n\n@cl.on_chat_start\nasync def start():\n    await cl.context.emitter.set_commands(commands)\n\n@cl.on_message\nasync def message(msg: cl.Message):\n    if msg.command == \"Picture\":\n        # User is using the Picture command\n        pass\n    pass\n```\n\n----------------------------------------\n\nTITLE: Calling Functions from Python in Chainlit Custom Elements\nDESCRIPTION: This example shows how to call JavaScript functions from Python code using CopilotFunction in Chainlit. It includes both the Python implementation and the JSX component that responds to function calls.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/custom.mdx#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_chat_start\nasync def start():\n    element = cl.CustomElement(name=\"CallFn\")\n    await cl.Message(content=\"Hello\", elements=[element]).send()\n    \n@cl.on_message\nasync def on_msg(msg: cl.Message):\n    fn = cl.CopilotFunction(name=\"test\", args={\"content\": msg.content})\n    res = await fn.acall()\n```\n\n----------------------------------------\n\nTITLE: Implementing Tags Input Widget in Chainlit Python Application\nDESCRIPTION: Example demonstrating how to create and use a Tags input widget in a Chainlit chat application. The code shows initialization of ChatSettings with a Tags widget for collecting stop sequences, which can be retrieved using the widget's ID.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/input-widgets/tags.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nfrom chainlit.input_widget import Tags\n\n\n@cl.on_chat_start\nasync def start():\n    settings = await cl.ChatSettings(\n        [\n            Tags(id=\"StopSequence\", label=\"OpenAI - StopSequence\", initial=[\"Answer:\"]),\n        ]\n    ).send()\n    value = settings[\"StopSequence\"]\n\n```\n\n----------------------------------------\n\nTITLE: Sending Messages from Parent Window to Chainlit Iframe\nDESCRIPTION: Shows how to send messages from a parent window to a Chainlit iframe using the postMessage API.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/webapp.mdx#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst iframe = document.getElementById('the-iframe');\niframe.contentWindow.postMessage('Client: Hello from parent window', '*');\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Message Reply in Chainlit\nDESCRIPTION: Example showing how to create a simple assistant that responds to user messages with a greeting. Uses the @cl.on_message decorator to handle incoming messages.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/message.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    response = f\"Hello, you just sent: {message.content}!\"\n    await cl.Message(response).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Session Management with useChatSession Hook\nDESCRIPTION: Demonstrates how to establish and manage WebSocket connections for chat sessions using the useChatSession hook. Includes connection initialization with optional user environment variables and authentication token.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/react/usage.mdx#2025-04-21_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\nimport { useChatSession } from '@chainlit/react-client';\n\nconst ChatComponent = () => {\n  const { connect, disconnect, chatProfile, setChatProfile } = useChatSession();\n\n  // Connect to the WebSocket server\n  useEffect(() => {\n    connect({\n      userEnv: {\n        /* user environment variables */\n      },\n      accessToken: 'Bearer YOUR ACCESS TOKEN', // Optional Chainlit auth token\n    });\n\n    return () => {\n      disconnect();\n    };\n  }, []);\n\n  // Rest of your component logic\n};\n```\n\n----------------------------------------\n\nTITLE: Creating a JSX Component to Handle Function Calls from Python\nDESCRIPTION: This JSX component listens for function calls from Python using Chainlit's callFnState. It demonstrates how to respond to specific function names and process their arguments.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/custom.mdx#2025-04-21_snippet_8\n\nLANGUAGE: jsx\nCODE:\n```\nimport { useEffect } from 'react';\nimport { useRecoilValue } from 'recoil';\nimport { callFnState } from '@chainlit/react-client';\n\nexport default function CallFnExample() {\n    const callFn = useRecoilValue(callFnState);\n\n    useEffect(() => {\n        if (callFn?.name === \"test\") {\n          // Replace the console log with your actual function\n          console.log(\"Function called with\", callFn.args.content)\n          callFn.callback()\n        }\n      }, [callFn]);\n\n      return null\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Video in Chainlit Chatbot UI\nDESCRIPTION: This example demonstrates how to use the Video class to display a video file inline within a Chainlit chatbot message. It shows the creation of a Video element and sending it as part of a Message object.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/video.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    elements = [\n        cl.Video(name=\"example.mp4\", path=\"./example.mp4\", display=\"inline\"),\n    ]\n    await cl.Message(\n        content=\"Here is an video file\",\n        elements=elements,\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Async Message Handler in Chainlit\nDESCRIPTION: Example of creating an asynchronous message handler in Chainlit using the @cl.on_message decorator to process incoming messages.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/sync-async.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def main(message: cl.Message):\n    # Your custom logic goes here\n\n    # Send a response back to the user\n    await cl.Message(\n        content=f\"Received: {message.content}\",\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Caching for Time-Consuming Processes in Python with Chainlit\nDESCRIPTION: This snippet demonstrates how to use the cl.cache decorator to cache the results of a time-consuming function. It includes a simulated delay and shows how to use the cached value in a message handler.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/cache.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport time\nimport chainlit as cl\n\n@cl.cache\ndef to_cache():\n    time.sleep(5)  # Simulate a time-consuming process\n    return \"Hello!\"\n\nvalue = to_cache()\n\n@cl.on_message\nasync def main(message: cl.Message):\n    await cl.Message(\n        content=value,\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Sending Window Messages from Chainlit Server\nDESCRIPTION: Demonstrates how to send messages from the Chainlit server to the parent window using cl.send_window_message.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/webapp.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def message():\n  await cl.send_window_message(\"Server: Hello from Chainlit\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Starters with Chat Profiles\nDESCRIPTION: Example demonstrating how to use Starters with Chat Profiles, including role-based access control\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/1.1.300.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@cl.set_chat_profiles\nasync def chat_profile(current_user: cl.User):\n    if current_user.metadata[\"role\"] != \"ADMIN\":\n        return None\n\n    return [\n        cl.ChatProfile(\n            name=\"My Chat Profile\",\n            icon=\"https://picsum.photos/250\",\n            markdown_description=\"The underlying LLM model is **GPT-3.5**, a *175B parameter model* trained on 410GB of text data.\",\n            starters=[\n                cl.Starter(\n                    label=\"Morning routine ideation\",\n                    message=\"Can you help me create a personalized morning routine that would help increase my productivity throughout the day? Start by asking me about my current habits and what activities energize me in the morning.\",\n                    icon=\"/public/idea.svg\",\n                ),\n                cl.Starter(\n                    label=\"Explain superconductors\",\n                    message=\"Explain superconductors like I'm five years old.\",\n                    icon=\"/public/learn.svg\",\n                ),\n            ],\n        )\n    ]\n```\n\n----------------------------------------\n\nTITLE: Updating Custom Element Props from Python in Chainlit\nDESCRIPTION: This example demonstrates how to update a custom element's properties from Python code by storing the element in the user session and calling the update method.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/custom.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_chat_start\nasync def start():\n    element = cl.CustomElement(name=\"Foo\", props={\"foo\": \"bar\"})\n    cl.user_session.set(\"element\", element)\n\n@cl.on_message\nasync def on_message():\n    element = cl.user_session.get(\"element\")\n    element.props[\"foo\"] = \"baz\"\n    await element.update()\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for PostgreSQL and Azure\nDESCRIPTION: Use this command to install the necessary Python dependencies for setting up and using the SQLAlchemy data layer with PostgreSQL and Azure Blob Storage. It includes the asyncpg driver for asynchronous communication and Azure identity and storage packages for interaction with Azure services.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-layers/sqlalchemy.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install asyncpg SQLAlchemy azure-identity azure-storage-file-datalake aiohttp greenlet\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat History for Discord Integration\nDESCRIPTION: Python code to implement chat history functionality in the Discord-integrated Chainlit app. It retrieves the last 10 messages from the Discord channel and adds them to the chat history.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/discord.mdx#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom chainlit.discord.app import client as discord_client\n\nimport chainlit as cl\nimport discord\n\n@cl.on_message\nasync def on_message(msg: cl.Message):\n    # The user session resets on every Discord message.\n    # So we add previous chat messages manually.\n    messages = cl.user_session.get(\"messages\", [])\n    channel: discord.abc.MessageableChannel = cl.user_session.get(\"discord_channel\")\n\n    if channel:\n        cl.user_session.get(\"messages\")\n        discord_messages = [message async for message in channel.history(limit=10)]\n\n        # Go through last 10 messages and remove the current message.\n        for x in discord_messages[::-1][:-1]:\n            messages.append({\n                \"role\": \"assistant\" if x.author.name == discord_client.user.name else \"user\",\n                \"content\": x.clean_content if x.clean_content else x.channel.name # first message is empty\n            })\n\n    # Your code here\n```\n\n----------------------------------------\n\nTITLE: Implementing Header Authentication Callback in Chainlit Python\nDESCRIPTION: This code snippet demonstrates how to implement a header authentication callback function in Chainlit. The function validates a custom header value and returns a User object with identifier and metadata if authenticated, or None otherwise.\nSOURCE: https://github.com/chainlit/docs/blob/main/authentication/header.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\n\nimport chainlit as cl\n\n\n@cl.header_auth_callback\ndef header_auth_callback(headers: Dict) -> Optional[cl.User]:\n  # Verify the signature of a token in the header (ex: jwt token)\n  # or check that the value is matching a row from your database\n  if headers.get(\"test-header\") == \"test-value\":\n    return cl.User(identifier=\"admin\", metadata={\"role\": \"admin\", \"provider\": \"header\"})\n  else:\n    return None\n```\n\n----------------------------------------\n\nTITLE: Styling with Tailwind CSS in Chainlit Custom Elements\nDESCRIPTION: This example demonstrates how to use Tailwind CSS classes in a Chainlit custom element, creating a div with primary background color and rounded borders.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/custom.mdx#2025-04-21_snippet_1\n\nLANGUAGE: jsx\nCODE:\n```\nexport default function TailwindExample() {\n    return <div className=\"bg-primary rounded-md h-4 w-full\" />\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Chat Data with useChatData Hook\nDESCRIPTION: Illustrates how to access various chat-related states and data including connection status, actions, user prompts, and settings using the useChatData hook.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/react/usage.mdx#2025-04-21_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\nimport { useChatData } from '@chainlit/react-client';\n\nconst ChatStatusComponent = () => {\n  const { connected, loading, error, actions, askUser, chatSettingsValue } = useChatData();\n\n  return (\n    <div>\n      <h2>Chat Status</h2>\n      {loading && <p>Loading chat...</p>}\n      {error && <p>There was an error with the chat session.</p>}\n      <p>{connected ? 'Connected to chat.' : 'Disconnected from chat.'}</p>\n\n      <h3>Available Actions</h3>\n      <ul>\n        {actions.map((action) => (\n          <li key={action.id}>{action.name}</li>\n        ))}\n      </ul>\n\n      {askUser && (\n        <div>\n          <h3>User Prompt</h3>\n          <p>{askUser.message}</p>\n        </div>\n      )}\n\n      <h3>Chat Settings</h3>\n      <pre>{JSON.stringify(chatSettingsValue, null, 2)}</pre>\n    </div>\n  );\n```\n\n----------------------------------------\n\nTITLE: Sending a Step in Chainlit\nDESCRIPTION: This snippet demonstrates how to create and send a step using the Step class as a context manager. The step is sent when the context is entered and updated when exited.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/step-class.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def main():\n    async with cl.Step(name=\"Test\") as step:\n        # Step is sent as soon as the context manager is entered\n        step.input = \"hello\"\n        step.output = \"world\"\n\n    # Step is updated when the context manager is exited\n```\n\n----------------------------------------\n\nTITLE: Creating and Sending a Dataframe in Chainlit Python\nDESCRIPTION: This example demonstrates how to create a pandas DataFrame, wrap it in a Chainlit Dataframe element, and send it as part of a message in a Chainlit application. It shows the usage of the Dataframe class with inline display and includes sample data with multiple columns.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/dataframe.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    # Create a sample DataFrame with more than 10 rows to test pagination functionality\n    data = {\n        \"Name\": [\n            \"Alice\",\n            \"David\",\n            \"Charlie\",\n            \"Bob\",\n            \"Eva\",\n            \"Grace\",\n            \"Hannah\",\n            \"Jack\",\n            \"Frank\",\n            \"Kara\",\n            \"Liam\",\n            \"Ivy\",\n            \"Mia\",\n            \"Noah\",\n            \"Olivia\",\n        ],\n        \"Age\": [25, 40, 35, 30, 45, 55, 60, 70, 50, 75, 80, 65, 85, 90, 95],\n        \"City\": [\n            \"New York\",\n            \"Houston\",\n            \"Chicago\",\n            \"Los Angeles\",\n            \"Phoenix\",\n            \"San Antonio\",\n            \"San Diego\",\n            \"San Jose\",\n            \"Philadelphia\",\n            \"Austin\",\n            \"Fort Worth\",\n            \"Dallas\",\n            \"Jacksonville\",\n            \"Columbus\",\n            \"Charlotte\",\n        ],\n        \"Salary\": [\n            70000,\n            100000,\n            90000,\n            80000,\n            110000,\n            130000,\n            140000,\n            160000,\n            120000,\n            170000,\n            180000,\n            150000,\n            190000,\n            200000,\n            210000,\n        ],\n    }\n\n    df = pd.DataFrame(data)\n\n    elements = [cl.Dataframe(data=df, display=\"inline\", name=\"Dataframe\")]\n\n    await cl.Message(content=\"This message has a Dataframe\", elements=elements).send()\n```\n\n----------------------------------------\n\nTITLE: Sending a Message with Chainlit\nDESCRIPTION: This snippet demonstrates how to send a new message to the UI using the Chainlit library. The example shows a typical response pattern that echoes back the user's message content.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/message.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    await cl.Message(\n        content=f\"Received: {message.content}\",\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Adding Metadata and Tags to Chainlit Step\nDESCRIPTION: Demonstrates how to attach metadata and tags to a Chainlit step using the context object. Metadata allows adding custom key-value pairs, while tags provide additional labeling for tracking and filtering.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-persistence/tags-metadata.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@cl.step(type=\"run\")\nasync def func(input):\n    # some code\n    cl.context.current_step.metadata = {\"experiment\":\"1\"}\n    cl.context.current_step.tags = [\"to review\"]\n    # some code\n    return output\n```\n\n----------------------------------------\n\nTITLE: Chainlit Custom Element API Interface\nDESCRIPTION: Type definition for the APIs available to Chainlit custom elements, including functions to update elements, delete elements, call actions, and send user messages.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/custom.mdx#2025-04-21_snippet_2\n\nLANGUAGE: ts\nCODE:\n```\ninterface APIs {\n    // Update the element props. This will re-render the element.\n    updateElement: (nextProps: Record<string, any>) => Promise<{success: boolean}>;\n    // Delete the element entirely.\n    deleteElement: () => Promise<{success: boolean}>;\n    // Call an action defined in the Chainlit app\n    callAction: (action: {name: string, payload: Record<string, unknown>}) =>Promise<{success: boolean}>;\n    // Send a user message\n    sendUserMessage: (message: string) => void;\n}\n```\n\n----------------------------------------\n\nTITLE: Sending Window Messages to Parent Window in Chainlit\nDESCRIPTION: This code shows how to send messages to the parent window using cl.send_window_message function. The example is within a message handler decorated with @cl.on_message, demonstrating integration with Chainlit's messaging system.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/window-message.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_message\nasync def message():\n  await cl.send_window_message(\"Server: Hello from Chainlit\")\n```\n\n----------------------------------------\n\nTITLE: Attaching an Image Element to a Message in Python\nDESCRIPTION: This code demonstrates how to instantiate an Image element and attach it to a message in Chainlit. It uses the on_chat_start event to send a message with an inline image when the chat begins.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/element.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    image = cl.Image(path=\"./cat.jpeg\", name=\"image1\", display=\"inline\")\n\n    # Attach the image to the message\n    await cl.Message(\n        content=\"This message has an image!\",\n        elements=[image],\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Accessing Authenticated User in Chainlit\nDESCRIPTION: Example showing how to access the current authenticated user through the User Session and display a personalized greeting message. Uses the on_chat_start event handler and accesses the user identifier.\nSOURCE: https://github.com/chainlit/docs/blob/main/authentication/overview.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_start\nasync def on_chat_start():\n    app_user = cl.user_session.get(\"user\")\n    await cl.Message(f\"Hello {app_user.identifier}\").send()\n```\n\n----------------------------------------\n\nTITLE: Implementing on_audio_end Hook in Python\nDESCRIPTION: Demonstrates how to define an asynchronous handler for the on_audio_end event in Chainlit. This hook is triggered when audio recording from the user's microphone ends.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/lifecycle-hooks/on-audio-end.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom io import BytesIO\nimport chainlit as cl\n\n\n@cl.on_audio_end\nasync def on_audio_end():\n    pass\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom CSS Path in Chainlit\nDESCRIPTION: Configuration snippet showing how to specify a custom CSS stylesheet path in the Chainlit config.toml file. The stylesheet can be either a local file in the public directory or a URL.\nSOURCE: https://github.com/chainlit/docs/blob/main/customisation/custom-css.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[UI]\n# ...\n# This can either be a css file in your `public` dir or a URL\ncustom_css = '/public/stylesheet.css'\n```\n\n----------------------------------------\n\nTITLE: Receiving Window Messages with on_window_message Decorator in Chainlit\nDESCRIPTION: This code demonstrates how to use the @cl.on_window_message decorator to listen for messages from the parent window. The decorated function is called when a message is received, with the message content passed as a parameter.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/window-message.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_window_message\ndef main(message: str):\n  # do something\n```\n\n----------------------------------------\n\nTITLE: Implementing User Logout Handler with Chainlit\nDESCRIPTION: Example showing how to use the @cl.on_logout decorator to handle user logout events. The handler receives FastAPI Request and Response objects and demonstrates clearing a cookie when a user logs out.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/lifecycle-hooks/on-logout.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import Request, Response\n\nimport chainlit as cl\n\n\n@cl.on_logout\ndef main(request: Request, response: Response):\n    response.delete_cookie(\"my_cookie\")\n```\n\n----------------------------------------\n\nTITLE: Streaming Output in Chainlit Step\nDESCRIPTION: This example shows how to stream the output of a step using the OpenAI API. It creates a step, sets its input, and then streams the output token by token.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/step-class.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncOpenAI\n\nimport chainlit as cl\n\nclient = AsyncOpenAI()\n\n@cl.on_message\nasync def main(msg: cl.Message):\n\n    async with cl.Step(name=\"gpt4\", type=\"llm\") as step:\n        step.input = msg.content\n\n        stream = await client.chat.completions.create(\n            messages=[{\"role\": \"user\", \"content\": msg.content}],\n            stream=True,\n            model=\"gpt-4\",\n            temperature=0,\n        )\n\n        async for part in stream:\n            delta = part.choices[0].delta\n            if delta.content:\n                # Stream the output of the step\n                await step.stream_token(delta.content)\n```\n\n----------------------------------------\n\nTITLE: Nesting Steps in Chainlit\nDESCRIPTION: This example shows how to nest steps in Chainlit. When a step-decorated function calls another step-decorated function, the child step will be nested under the parent step in the UI.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/step-decorator.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.step\nasync def parent_step():\n    await child_step()\n    return \"Parent step output\"\n\n@cl.step\nasync def child_step():\n    return \"Child step output\"\n\n@cl.on_chat_start\nasync def main():\n    await parent_step()\n```\n\n----------------------------------------\n\nTITLE: Configuring Slack App Manifest\nDESCRIPTION: YAML configuration for setting up the Slack app permissions and features\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/slack.mdx#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ndisplay_information:\n  name: { APP_NAME }\nfeatures:\n  bot_user:\n    display_name: { APP_NAME }\n    always_online: false\noauth_config:\n  scopes:\n    user:\n      - im:history\n      - channels:history\n    bot:\n      - app_mentions:read\n      - channels:read\n      - chat:write\n      - files:read\n      - files:write\n      - im:history\n      - im:read\n      - im:write\n      - users:read\n      - users:read.email\n      - channels:history\n      - groups:history\nsettings:\n  event_subscriptions:\n    request_url: https://{ CHAINLIT_APP_HOST }/slack/events\n    bot_events:\n      - app_home_opened\n      - app_mention\n      - message.im\n  interactivity:\n    is_enabled: true\n    request_url: https://{ CHAINLIT_APP_HOST }/slack/events\n  org_deploy_enabled: false\n  socket_mode_enabled: false\n  token_rotation_enabled: false\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Features in TOML\nDESCRIPTION: TOML configuration for enabling and controlling MCP connection types, including SSE and stdio settings with security allowlists.\nSOURCE: https://github.com/chainlit/docs/blob/main/advanced-features/mcp.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[features.mcp.sse]\n    enabled = true\n\n[features.mcp.stdio]\n    enabled = true\n    allowed_executables = [ \"npx\", \"uvx\" ]\n```\n\n----------------------------------------\n\nTITLE: Nesting Steps in Chainlit\nDESCRIPTION: This snippet illustrates how to nest steps within each other using the Step class. It creates a parent step and a child step within it.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/step-class.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    async with cl.Step(name=\"Parent step\") as parent_step:\n        parent_step.input = \"Parent step input\"\n\n        async with cl.Step(name=\"Child step\") as child_step:\n            child_step.input = \"Child step input\"\n            child_step.output = \"Child step output\"\n\n        parent_step.output = \"Parent step output\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Action Button Callback\nDESCRIPTION: Shows how to define a callback function that handles user clicks on an action button. The callback is decorated with @cl.action_callback and receives the action object containing the payload.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/action.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@cl.action_callback(\"action_button\")\nasync def on_action(action: cl.Action):\n    print(action.payload)\n```\n\n----------------------------------------\n\nTITLE: Using AskActionMessage in Chainlit Python Application\nDESCRIPTION: This code snippet demonstrates how to use the AskActionMessage class to prompt the user for an action. It sets up two actions (continue and cancel) and sends a message based on the user's response.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/ask/ask-for-action.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    res = await cl.AskActionMessage(\n        content=\"Pick an action!\",\n        actions=[\n            cl.Action(name=\"continue\", payload={\"value\": \"continue\"}, label=\"✅ Continue\"),\n            cl.Action(name=\"cancel\", payload={\"value\": \"cancel\"}, label=\"❌ Cancel\"),\n        ],\n    ).send()\n\n    if res and res.get(\"payload\").get(\"value\") == \"continue\":\n        await cl.Message(\n            content=\"Continue!\",\n        ).send()\n```\n\n----------------------------------------\n\nTITLE: Converting Sync to Async Function with make_async\nDESCRIPTION: Demonstrates how to convert a long-running synchronous function into an asynchronous one using Chainlit's make_async utility.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/sync-async.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom chainlit import make_async\n\ndef my_sync_function():\n    # Your synchronous code goes here\n    import time\n    time.sleep(10)\n    return 0\n\nasync_function = make_async(my_sync_function)\n\nasync def main():\n    result = await async_function()\n```\n\n----------------------------------------\n\nTITLE: Chat Interaction Implementation with useChatInteract Hook\nDESCRIPTION: Shows how to implement chat interactions like sending messages, replying, and clearing chat using the useChatInteract hook.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/react/usage.mdx#2025-04-21_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\nimport { useChatInteract } from '@chainlit/react-client';\n\nconst ChatInteraction = () => {\n  const { sendMessage, replyMessage, clear } = useChatInteract();\n\n  return (\n    <div>\n      <button onClick={() => sendMessage({ content: 'Hello!' })}>Send</button>\n      <button onClick={() => replyMessage({ content: 'Reply!' })}>Reply</button>\n      <button onClick={clear}>Clear</button>\n    </div>\n  );\n};\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic Custom JSX Component in Chainlit\nDESCRIPTION: This code shows how to define a simple JSX component for use with Chainlit's CustomElement. The component returns a div with 'Hello World' text.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/custom.mdx#2025-04-21_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\nexport default function MyComponent() {\n    return <div>Hello World</div>\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Slack Chat History\nDESCRIPTION: Python example demonstrating how to fetch message history from Slack threads or DM channels\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/slack.mdx#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nimport discord\n\n\n@cl.on_message\nasync def on_message(msg: cl.Message):\n    fetch_slack_message_history = cl.user_session.get(\"fetch_slack_message_history\")\n\n    if fetch_slack_message_history:\n        print(await fetch_slack_message_history(limit=10))\n\n    # Your code here\n```\n\n----------------------------------------\n\nTITLE: Creating and Sending File Element in Chainlit\nDESCRIPTION: Example showing how to create a File element and send it within a Message in a Chainlit application. The code demonstrates using the on_chat_start event handler to initialize and send a file with inline display mode.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/file.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    elements = [\n        cl.File(\n            name=\"hello.py\",\n            path=\"./hello.py\",\n            display=\"inline\",\n        ),\n    ]\n\n    await cl.Message(\n        content=\"This message has a file element\", elements=elements\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit with Production Flags\nDESCRIPTION: Command line options for running Chainlit in production environments, including host configuration and root path settings.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/overview.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run -h --host 0.0.0.0 --root-path /chainlit\n```\n\n----------------------------------------\n\nTITLE: Implementing OAuth Callback Function in Python\nDESCRIPTION: Example of implementing the oauth_callback decorator in Chainlit to handle user authentication. This example allows all users who pass OAuth authentication by returning the default_user object provided by the OAuth provider.\nSOURCE: https://github.com/chainlit/docs/blob/main/authentication/oauth.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict, Optional\nimport chainlit as cl\n\n\n@cl.oauth_callback\ndef oauth_callback(\n  provider_id: str,\n  token: str,\n  raw_user_data: Dict[str, str],\n  default_user: cl.User,\n) -> Optional[cl.User]:\n  return default_user\n```\n\n----------------------------------------\n\nTITLE: Managing Chat Resume Events in Chainlit Python Application\nDESCRIPTION: Defines an async handler using @cl.on_chat_resume decorator for resuming previous chat sessions. Requires authentication and data persistence to be enabled.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/chat-lifecycle.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom chainlit.types import ThreadDict\n\n@cl.on_chat_resume\nasync def on_chat_resume(thread: ThreadDict):\n    print(\"The user resumed a previous chat session!\")\n```\n\n----------------------------------------\n\nTITLE: Updating a Message with Chainlit\nDESCRIPTION: This example demonstrates how to update a message that has already been sent to the UI. It shows creating and sending an initial message, waiting for a brief period, then modifying the content and updating the message.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/message.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    msg = cl.Message(content=\"Hello!\")\n    await msg.send()\n\n    await cl.sleep(2)\n\n    msg.content = \"Hello again!\"\n    await msg.update()\n```\n\n----------------------------------------\n\nTITLE: Linting Translations using Chainlit CLI\nDESCRIPTION: Command to lint translations in a Chainlit project using the Chainlit CLI. This helps ensure consistency and correctness across translation files.\nSOURCE: https://github.com/chainlit/docs/blob/main/customisation/translation.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit lint-translations\n```\n\n----------------------------------------\n\nTITLE: Implementing OAuth Callback for Google Domain Restriction in Chainlit\nDESCRIPTION: This function defines an OAuth callback that allows only users from a specific Google domain ('example.org') to access the application. It checks the 'hd' field in the raw user data to verify the user's domain.\nSOURCE: https://github.com/chainlit/docs/blob/main/authentication/oauth.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict, Optional\nimport chainlit as cl\n\n\n@cl.oauth_callback\ndef oauth_callback(\n  provider_id: str,\n  token: str,\n  raw_user_data: Dict[str, str],\n  default_user: cl.User,\n) -> Optional[cl.User]:\n  if provider_id == \"google\":\n    if raw_user_data[\"hd\"] == \"example.org\":\n      return default_user\n  return None\n```\n\n----------------------------------------\n\nTITLE: Implementing Stop Handler in Chainlit Python Application\nDESCRIPTION: Defines a handler using @cl.on_stop decorator that executes when the user clicks the stop button during a running task.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/chat-lifecycle.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_stop\ndef on_stop():\n    print(\"The user wants to stop the task!\")\n```\n\n----------------------------------------\n\nTITLE: Configuring SQLAlchemy Data Layer Function\nDESCRIPTION: This Python snippet demonstrates how to configure a custom SQLAlchemy data layer within a Chainlit application using an Azure storage client. You need to provide connection information and specify the data layer using the @cl.data_layer decorator. Ensure the conninfo string includes +asyncpg for the asyncpg driver.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-layers/sqlalchemy.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nfrom chainlit.data.sql_alchemy import SQLAlchemyDataLayer\nfrom chainlit.data.storage_clients.azure import AzureStorageClient\n\nstorage_client = AzureStorageClient(account_url=\"<your_account_url>\", container=\"<your_container>\")\n\n@cl.data_layer\ndef get_data_layer():\n    return SQLAlchemyDataLayer(conninfo=\"<your conninfo>\", storage_provider=storage_client)\n```\n\n----------------------------------------\n\nTITLE: Running the Document QA Chatbot Application\nDESCRIPTION: This bash command runs the Chainlit application using the qa.py script, which contains the implementation of the document QA chatbot.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/qa.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run qa.py\n```\n\n----------------------------------------\n\nTITLE: TypeScript Function for Generating JWT Access Tokens\nDESCRIPTION: Demonstrates how to create JWT access tokens in TypeScript using the 'jsonwebtoken' library. The function encodes user information and metadata, with an expiration set to 15 days. Tokens authenticate users on the Chainlit server, needing a shared secret for encoding.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/copilot.mdx#2025-04-21_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport jwt from \"jsonwebtoken\";\n\nconst CHAINLIT_AUTH_SECRET = \"your-secret\";\n\ninterface Metadata {\n  [key: string]: any;\n}\n\nfunction createJwt(identifier: string, metadata: Metadata): string {\n  const toEncode = {\n    identifier: identifier,\n    metadata: metadata,\n    exp: Math.floor(Date.now() / 1000) + 60 * 60 * 24 * 15, // 15 days\n  };\n  const encodedJwt = jwt.sign(toEncode, CHAINLIT_AUTH_SECRET, {\n    algorithm: \"HS256\",\n  });\n  return encodedJwt;\n}\n\nconst accessToken = createJwt(\"user-1\", { name: \"John Doe\" });\n```\n\n----------------------------------------\n\nTITLE: Handling Chat End Events in Chainlit Python Application\nDESCRIPTION: Implements a handler using @cl.on_chat_end decorator that executes when a chat session ends due to user disconnection or starting a new session.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/chat-lifecycle.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_end\ndef on_chat_end():\n    print(\"The user disconnected!\")\n```\n\n----------------------------------------\n\nTITLE: Basic Chainlit Teams Integration Example\nDESCRIPTION: Sample Python code demonstrating a basic Chainlit application that can respond to Teams messages and handle attachments\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/teams.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def on_message(msg: cl.Message):\n    # Access the teams user\n    print(cl.user_session.get(\"user\"))\n\n    # Access potential attached files\n    attached_files = msg.elements\n\n    await cl.Message(content=\"Hello World\").send()\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application\nDESCRIPTION: Command to start the Chainlit application with auto-reloading enabled for development purposes.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/langchain.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Implementing MCP Connection Handlers in Python\nDESCRIPTION: Python handlers for MCP connection events, including connection establishment and disconnection callbacks.\nSOURCE: https://github.com/chainlit/docs/blob/main/advanced-features/mcp.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nfrom mcp import ClientSession\n\n@cl.on_mcp_connect\nasync def on_mcp_connect(connection, session: ClientSession):\n    \"\"\"Called when an MCP connection is established\"\"\"\n    # Your connection initialization code here\n    # This handler is required for MCP to work\n    \n@cl.on_mcp_disconnect\nasync def on_mcp_disconnect(name: str, session: ClientSession):\n    \"\"\"Called when an MCP connection is terminated\"\"\"\n    # Your cleanup code here\n    # This handler is optional\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit UI Settings with TOML\nDESCRIPTION: Default TOML configuration for Chainlit UI settings. Includes options for app name, description, content display preferences, chain of thought mode, GitHub repository link, and theme customization. Comments explain each setting's purpose.\nSOURCE: https://github.com/chainlit/docs/blob/main/backend/config/ui.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[UI]\n# Name of the app and chatbot.\nname = \"Chatbot\"\n\n# Description of the app and chatbot. This is used for HTML tags.\n# description = \"\"\n\n# Large size content are by default collapsed for a cleaner ui\ndefault_collapse_content = true\n\n# The default value for the expand messages settings.\ndefault_expand_messages = false\n\n# Chain of Thought (CoT) display mode. Can be \"hidden\", \"tool_call\" or \"full\".\ncot = \"full\"\n\n# Link to your github repo. This will add a github button in the UI's header.\n# github = \"\"\n\n# Specify a CSS file that can be used to customize the user interface.\n# The CSS file can be served from the public directory or via an external link.\n# custom_css = \"/public/test.css\"\n\n[UI.theme]\n  #layout = \"wide\"\n  #font_family = \"Inter, sans-serif\"\n  # Override default MUI light theme. (Check theme.ts)\n  [UI.theme.light]\n      #background = \"#FAFAFA\"\n      #paper = \"#FFFFFF\"\n\n      [UI.theme.light.primary]\n          #main = \"#F80061\"\n          #dark = \"#980039\"\n          #light = \"#FFE7EB\"\n\n  # Override default MUI dark theme. (Check theme.ts)\n  [UI.theme.dark]\n      #background = \"#FAFAFA\"\n      #paper = \"#FFFFFF\"\n\n      [UI.theme.dark.primary]\n          #main = \"#F80061\"\n          #dark = \"#980039\"\n          #light = \"#FFE7EB\"\n```\n\n----------------------------------------\n\nTITLE: Implementing TextInput Widget in Chainlit\nDESCRIPTION: Example demonstrating how to create and use a TextInput widget in a Chainlit chat application. Shows initialization of a chat settings panel with a text input for Agent Name, and retrieving the input value from settings.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/input-widgets/textinput.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\nfrom chainlit.input_widget import TextInput\n\n\n@cl.on_chat_start\nasync def start():\n    settings = await cl.ChatSettings(\n        [\n            TextInput(id=\"AgentName\", label=\"Agent Name\", initial=\"AI\"),\n        ]\n    ).send()\n    value = settings[\"AgentName\"]\n\n```\n\n----------------------------------------\n\nTITLE: Accessing user-provided environment variables in Chainlit\nDESCRIPTION: Code snippet demonstrating how to access environment variables that users have provided through the 'user_env' configuration in a public-facing Chainlit application. This allows each user to provide their own API keys rather than using the developer's credentials.\nSOURCE: https://github.com/chainlit/docs/blob/main/backend/env-variables.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\nuser_env = cl.user_session.get(\"env\")\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application from Command Line\nDESCRIPTION: This command demonstrates how to run the Chainlit application from the terminal. It uses the chainlit CLI to execute the app.py file with the -w flag for hot reloading.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/embedchain.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application with Auto-reloading\nDESCRIPTION: This command starts the Chainlit application with auto-reloading enabled, allowing developers to see changes without restarting the server.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/semantic-kernel.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic on_chat_resume Decorator in Python\nDESCRIPTION: This code snippet demonstrates the basic usage of the @cl.on_chat_resume decorator in Chainlit. It's used to define an asynchronous function that will be called when resuming a chat. The function takes a 'thread' parameter which contains the persisted chat information.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/lifecycle-hooks/on-chat-resume.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_resume\nasync def on_chat_resume(thread):\n    pass\n```\n\n----------------------------------------\n\nTITLE: API Integration with useApi Hook\nDESCRIPTION: Shows how to fetch data and handle API responses using the useApi hook with SWR integration for efficient data fetching.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/react/usage.mdx#2025-04-21_snippet_5\n\nLANGUAGE: tsx\nCODE:\n```\nimport { useApi } from '@chainlit/react-client';\n\nconst Settings = () => {\n  const { data, error, isLoading } = useApi('/project/settings');\n\n  if (isLoading) return <p>Loading...</p>;\n  if (error) return <p>Error: {error.message}</p>;\n\n  return <pre>{JSON.stringify(data, null, 2)}</pre>;\n};\n```\n\n----------------------------------------\n\nTITLE: Handling Window Messages in Chainlit Server\nDESCRIPTION: Demonstrates how to receive and process window messages from a parent window in a Chainlit server using the @cl.on_window_message decorator.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/webapp.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_window_message\nasync def window_message(message: str):\n  if message.startswith(\"Client: \"):\n    await cl.Message(content=f\"Window message received: {message}\").send()\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application with Auto-reloading (Bash)\nDESCRIPTION: This command starts the Chainlit application with auto-reloading enabled. It runs the app.py file and makes the chatbot UI accessible at http://localhost:8000.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/litellm.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Installing Chainlit via pip\nDESCRIPTION: Command to install Chainlit using pip. Requires Python 3.9 or higher.\nSOURCE: https://github.com/chainlit/docs/blob/main/get-started/installation.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install chainlit\n```\n\n----------------------------------------\n\nTITLE: Implementing on_audio_chunk Hook in Python with Chainlit\nDESCRIPTION: This snippet shows how to use the '@cl.on_audio_chunk' decorator to define a function that handles incoming audio chunks. The function takes an 'InputAudioChunk' object as a parameter, allowing for processing of the audio data.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/lifecycle-hooks/on-audio-chunk.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom io import BytesIO\nimport chainlit as cl\n\n\n@cl.on_audio_chunk\nasync def on_audio_chunk(chunk: cl.InputAudioChunk):\n    pass\n```\n\n----------------------------------------\n\nTITLE: Authentication Management with useAuth Hook\nDESCRIPTION: Demonstrates user authentication handling including user profile display and logout functionality using the useAuth hook.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/react/usage.mdx#2025-04-21_snippet_4\n\nLANGUAGE: tsx\nCODE:\n```\nimport { useAuth } from '@chainlit/react-client';\n\nconst UserProfile = () => {\n  const { user, logout } = useAuth();\n\n  if (!user) return <p>No user logged in.</p>;\n\n  return (\n    <div>\n      <p>Username: {user.username}</p>\n      <button onClick={logout}>Logout</button>\n    </div>\n  );\n};\n```\n\n----------------------------------------\n\nTITLE: Integrating MCP with LLMs in Python\nDESCRIPTION: Python code demonstrating how to integrate MCP tools with Language Learning Models that support tool calling.\nSOURCE: https://github.com/chainlit/docs/blob/main/advanced-features/mcp.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nasync def call_model_with_tools():\n    # Get tools from all MCP connections\n    mcp_tools = cl.user_session.get(\"mcp_tools\", {})\n    all_tools = [tool for connection_tools in mcp_tools.values() for tool in connection_tools]\n    \n    # Call your LLM with the tools\n    response = await your_llm_client.call(\n        messages=messages,\n        tools=all_tools\n    )\n    \n    # Handle tool calls if needed\n    if response.has_tool_calls():\n        # Process tool calls\n        pass\n        \n    return response\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip\nDESCRIPTION: Installation of required Python packages chainlit and openai using pip package manager.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/openai-sql.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install chainlit openai\n```\n\n----------------------------------------\n\nTITLE: Defining Basic Async Function in Python\nDESCRIPTION: Demonstrates the basic syntax for creating an asynchronous function using async/await keywords in Python.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/sync-async.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nasync def my_async_function():\n    # Your async code goes here\n```\n\n----------------------------------------\n\nTITLE: Managing Chat Messages with useChatMessages Hook\nDESCRIPTION: Shows how to access and display chat messages, thread ID, and first interaction using the useChatMessages hook. Uses Recoil for state management and reactive updates.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/react/usage.mdx#2025-04-21_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\nimport { useChatMessages } from '@chainlit/react-client';\n\nconst MessagesComponent = () => {\n  const { messages, firstInteraction, threadId } = useChatMessages();\n\n  return (\n    <div>\n      <h2>Thread ID: {threadId}</h2>\n      {firstInteraction && <p>First Interaction: {firstInteraction}</p>}\n      {messages.map((message) => (\n        <p key={message.id}>{message.content}</p>\n      ))}\n    </div>\n  );\n};\n```\n\n----------------------------------------\n\nTITLE: Configuring DynamoDB Data Layer with S3 Storage in Python\nDESCRIPTION: Python code to set up the DynamoDB data layer with S3 storage in a Chainlit application. It imports necessary modules, creates an S3 storage client, and configures the data layer.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-layers/dynamodb.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit.data as cl_data\nfrom chainlit.data.dynamodb import DynamoDBDataLayer\nfrom chainlit.data.storage_clients.s3 import S3StorageClient\n\nstorage_client = S3StorageClient(bucket=\"<Your Bucket>\")\n\ncl_data._data_layer = DynamoDBDataLayer(table_name=\"<Your Table>\", storage_provider=storage_client)\n```\n\n----------------------------------------\n\nTITLE: Installing Chainlit Update via pip\nDESCRIPTION: Command to upgrade Chainlit to the latest version using pip package manager.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/1.1.404.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade chainlit\n```\n\n----------------------------------------\n\nTITLE: Handling User Messages in Chainlit Application\nDESCRIPTION: This snippet shows the basic structure of a Chainlit message handler. It receives a message and sends a response confirming receipt.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/security.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def main(message: cl.Message):\n    # Notice that the message is passed as is\n    response = await cl.Message(\n        content=f\"Received: {message.content}\",\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Setting Literal AI API Key in Environment File for Chainlit\nDESCRIPTION: This snippet shows how to set the Literal AI API key in a .env file for use with a Chainlit application. The API key is stored as an environment variable named LITERAL_API_KEY.\nSOURCE: https://github.com/chainlit/docs/blob/main/llmops/literalai.mdx#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nLITERAL_API_KEY=\"your key\"\n```\n\n----------------------------------------\n\nTITLE: Creating Action Button in Chainlit Message\nDESCRIPTION: Demonstrates how to create and send an action button within a Chainlit message. The action includes a name, icon, payload, and label that will be displayed in the UI.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/action.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_chat_start\nasync def start():\n    # Sending an action button within a chatbot message\n    actions = [\n        cl.Action(\n            name=\"action_button\",\n            icon=\"mouse-pointer-click\",\n            payload={\"value\": \"example_value\"},\n            label=\"Click me!\"\n        )\n    ]\n\n    await cl.Message(content=\"Interact with this action button:\", actions=actions).send()\n```\n\n----------------------------------------\n\nTITLE: Updating a Step in Chainlit\nDESCRIPTION: This example shows how to update a step after it has been created and sent. It creates a step, waits for 2 seconds, then updates the step's output.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/step-class.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    async with cl.Step(name=\"Parent step\") as step:\n        step.input = \"Parent step input\"\n        step.output = \"Parent step output\"\n\n    await cl.sleep(2)\n\n    step.output = \"Parent step output updated\"\n    await step.update()\n```\n\n----------------------------------------\n\nTITLE: Installing Chainlit Update\nDESCRIPTION: Command to upgrade Chainlit to the latest version using pip\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/1.1.300.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade chainlit\n```\n\n----------------------------------------\n\nTITLE: Configuring Logging for DynamoDB Data Layer in Python\nDESCRIPTION: Python code to configure logging for the DynamoDB data layer in a Chainlit application. It sets the log level to DEBUG for the DynamoDB child logger.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-layers/dynamodb.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom chainlit import logger\n\nlogger.getChild(\"DynamoDB\").setLevel(logging.DEBUG)\n```\n\n----------------------------------------\n\nTITLE: Configuring Literal AI Server URL in Environment File\nDESCRIPTION: Sets up the LITERAL_API_URL environment variable in a .env file to point to a self-hosted Literal AI server instance for data persistence.\nSOURCE: https://github.com/chainlit/docs/blob/main/llmops/enterprise.mdx#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nLITERAL_API_URL=\"https://cloud.your_literal.com\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Linear Ticket Status Card Component in JSX\nDESCRIPTION: This JSX component renders a Linear ticket card with title, status, progress bar, assignee, deadline, and tags. It's designed to work with Chainlit's CustomElement feature and styled using Tailwind and shadcn components.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/elements/custom.mdx#2025-04-21_snippet_5\n\nLANGUAGE: jsx\nCODE:\n```\nimport { Card, CardHeader, CardTitle, CardContent } from \"@/components/ui/card\"\nimport { Badge } from \"@/components/ui/badge\"\nimport { Progress } from \"@/components/ui/progress\"\nimport { Clock, User, Tag } from \"lucide-react\"\n\nexport default function TicketStatusCard() {\n  const getProgressValue = (status) => {\n    const progress = {\n      'open': 25,\n      'in-progress': 50,\n      'resolved': 75,\n      'closed': 100\n    }\n    return progress[status] || 0\n  }\n\n  return (\n    <Card className=\"w-full max-w-md\">\n      <CardHeader className=\"pb-2\">\n        <div className=\"flex justify-between items-center\">\n          <CardTitle className=\"text-lg font-medium\">\n            {props.title || 'Untitled Ticket'}\n          </CardTitle>\n          <Badge \n            variant=\"outline\" \n          >\n            {props.status || 'Unknown'}\n          </Badge>\n        </div>\n      </CardHeader>\n      <CardContent>\n        <div className=\"space-y-4\">\n          <Progress value={getProgressValue(props.status)} className=\"h-2\" />\n          \n          <div className=\"grid grid-cols-2 gap-4 text-sm\">\n            <div className=\"flex items-center gap-2\">\n              <User className=\"h-4 w-4 opacity-70\" />\n              <span>{props.assignee || 'Unassigned'}</span>\n            </div>\n            <div className=\"flex items-center gap-2\">\n              <Clock className=\"h-4 w-4 opacity-70\" />\n              <span>{props.deadline || 'No deadline'}</span>\n            </div>\n            <div className=\"flex items-center gap-2 col-span-2\">\n              <Tag className=\"h-4 w-4 opacity-70\" />\n              <span>{props.tags?.join(', ') || 'No tags'}</span>\n            </div>\n          </div>\n        </div>\n      </CardContent>\n    </Card>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Removing a Message with Chainlit\nDESCRIPTION: This snippet shows how to remove a message from the UI using Chainlit. It demonstrates sending a message, waiting for a period of time, and then removing the message from the display.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/message.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    msg = cl.Message(content=\"Message 1\")\n    await msg.send()\n    await cl.sleep(2)\n    await msg.remove()\n```\n\n----------------------------------------\n\nTITLE: Installing Slack Bolt Package\nDESCRIPTION: Command to install the required Slack Bolt library for Chainlit integration\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/slack.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install slack_bolt\n```\n\n----------------------------------------\n\nTITLE: Defining Entity Types for DynamoDB Single Table Design in TypeScript\nDESCRIPTION: TypeScript definitions for the entity types used in the DynamoDB single table design. It includes User, Thread, Step, and Element types with their respective attributes and key structures.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-layers/dynamodb.mdx#2025-04-21_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\ntype User = {\n    PK: \"USER#{user.identifier}\"\n    SK: \"USER\"\n    // ...PersistedUser\n}\n\ntype Thread = {\n    PK: f\"THREAD#{thread_id}\"\n    SK: \"THREAD\"\n    // GSI: UserThread for querying in list_threads\n    UserThreadPK: f\"USER#{user_id}\"\n    UserThreadSK: f\"TS#{ts}\"\n    // ...ThreadDict\n}\n\ntype Step = {\n    PK: f\"THREAD#{threadId}\"\n    SK: f\"STEP#{stepId}\"\n    // ...StepDict\n\n    // feedback is stored as part of step. \n    // NOTE: feedback.value is stored as Decimal in dynamo which is not json serializable\n    feedback?: Feedback\n}\n\ntype Element = {\n    \"PK\": f\"THREAD#{threadId}\"\n    \"SK\": f\"ELEMENT#{element.id}\"\n    // ...ElementDict\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying an Image Element with 'Side' Option in Python\nDESCRIPTION: This snippet shows how to use the 'side' display option for an Image element. The image name is referenced in the message content and will be displayed as a clickable link, opening the image on the side when clicked.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/element.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_start\nasync def start():\n    # Notice the display option\n    image = cl.Image(path=\"./cat.jpeg\", name=\"cat image\", display=\"side\")\n\n    await cl.Message(\n        # Notice that the name of the image is referenced in the message content\n        content=\"Here is the cat image!\",\n        elements=[image],\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit Project Settings using TOML\nDESCRIPTION: Default TOML configuration for a Chainlit project. This configuration controls telemetry collection, user environment variables, session timeout duration, caching behavior, and symlink handling for asset mounting.\nSOURCE: https://github.com/chainlit/docs/blob/main/backend/config/project.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[project]\n# Whether to enable telemetry (default: true). No personal data is collected.\nenable_telemetry = true\n\n# List of environment variables to be provided by each user to use the app.\nuser_env = []\n\n# Duration (in seconds) during which the session is saved when the connection is lost\nsession_timeout = 3600\n\n# Enable third parties caching (e.g LangChain cache)\ncache = false\n\n# Follow symlink for asset mount (see https://github.com/Chainlit/chainlit/issues/317)\n# follow_symlink = false\n```\n\n----------------------------------------\n\nTITLE: Setting Discord Bot Token Environment Variable\nDESCRIPTION: Command to set the Discord bot token as an environment variable for the Chainlit app.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/discord.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nDISCORD_BOT_TOKEN=your_bot_token\n```\n\n----------------------------------------\n\nTITLE: Displaying an Image Element with 'Inline' Option in Python\nDESCRIPTION: This snippet illustrates the 'inline' display option for an Image element. The image is displayed directly below the message content, regardless of whether it's referenced in the text.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/element.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_start\nasync def start():\n    # Notice the display option\n    image = cl.Image(path=\"./cat.jpeg\", name=\"cat image\", display=\"inline\")\n\n    await cl.Message(\n        # Notice that the name of the image is NOT referenced in the message content\n        content=\"Hello!\",\n        elements=[image],\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit with Inline Literal AI API Key\nDESCRIPTION: This command demonstrates how to run a Chainlit application while setting the Literal AI API key inline. It allows for immediate use of Literal AI integration without modifying environment files.\nSOURCE: https://github.com/chainlit/docs/blob/main/llmops/literalai.mdx#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nLITERAL_API_KEY=\"your key\" chainlit run main.py\n```\n\n----------------------------------------\n\nTITLE: Removing a Step in Chainlit\nDESCRIPTION: This snippet demonstrates how to remove a step after it has been created and sent. It creates a step, waits for 2 seconds, then removes the step.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/step-class.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def main():\n    async with cl.Step(name=\"Parent step\") as step:\n        step.input = \"Parent step input\"\n        step.output = \"Parent step output\"\n\n    await cl.sleep(2)\n\n    await step.remove()\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Start Hook in Python with Chainlit\nDESCRIPTION: Defines a hook that executes when a new chat session begins using the @cl.on_chat_start decorator.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/chat-lifecycle.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_start\ndef on_chat_start():\n    print(\"A new chat session has started!\")\n```\n\n----------------------------------------\n\nTITLE: Setting Teams App ID Environment Variable\nDESCRIPTION: Environment variable configuration for Teams App ID\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/teams.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nTEAMS_APP_ID=your_app_id\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit Theme Variables in JSON\nDESCRIPTION: Complete theme configuration file that defines CSS variables for both light and dark themes, including fonts, colors, and UI element styling. Colors are specified in HSL format and the configuration includes variables for main content area and sidebar styling.\nSOURCE: https://github.com/chainlit/docs/blob/main/customisation/theme.mdx#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"custom_fonts\": [],\n    \"variables\": {\n        \"light\": {\n            \"--font-sans\": \"'Inter', sans-serif\",\n            \"--font-mono\": \"source-code-pro, Menlo, Monaco, Consolas, 'Courier New', monospace\",\n            \"--background\": \"0 0% 100%\",\n            \"--foreground\": \"0 0% 5%\",\n            \"--card\": \"0 0% 100%\",\n            \"--card-foreground\": \"0 0% 5%\",\n            \"--popover\": \"0 0% 100%\",\n            \"--popover-foreground\": \"0 0% 5%\",\n            \"--primary\": \"340 92% 52%\",\n            \"--primary-foreground\": \"0 0% 100%\",\n            \"--secondary\": \"210 40% 96.1%\",\n            \"--secondary-foreground\": \"222.2 47.4% 11.2%\",\n            \"--muted\": \"0 0% 90%\",\n            \"--muted-foreground\": \"0 0% 36%\",\n            \"--accent\": \"0 0% 95%\",\n            \"--accent-foreground\": \"222.2 47.4% 11.2%\",\n            \"--destructive\": \"0 84.2% 60.2%\",\n            \"--destructive-foreground\": \"210 40% 98%\",\n            \"--border\": \"0 0% 90%\",\n            \"--input\": \"0 0% 90%\",\n            \"--ring\": \"340 92% 52%\",\n            \"--radius\": \"0.75rem\",\n            \"--sidebar-background\": \"0 0% 98%\",\n            \"--sidebar-foreground\": \"240 5.3% 26.1%\",\n            \"--sidebar-primary\": \"240 5.9% 10%\",\n            \"--sidebar-primary-foreground\": \"0 0% 98%\",\n            \"--sidebar-accent\": \"240 4.8% 95.9%\",\n            \"--sidebar-accent-foreground\": \"240 5.9% 10%\",\n            \"--sidebar-border\": \"220 13% 91%\",\n            \"--sidebar-ring\": \"217.2 91.2% 59.8%\"\n        },\n        \"dark\": {\n            \"--font-sans\": \"'Inter', sans-serif\",\n            \"--font-mono\": \"source-code-pro, Menlo, Monaco, Consolas, 'Courier New', monospace\",\n            \"--background\": \"0 0% 13%\",\n            \"--foreground\": \"0 0% 93%\",\n            \"--card\": \"0 0% 18%\",\n            \"--card-foreground\": \"210 40% 98%\",\n            \"--popover\": \"0 0% 18%\",\n            \"--popover-foreground\": \"210 40% 98%\",\n            \"--primary\": \"340 92% 52%\",\n            \"--primary-foreground\": \"0 0% 100%\",\n            \"--secondary\": \"0 0% 19%\",\n            \"--secondary-foreground\": \"210 40% 98%\",\n            \"--muted\": \"0 1% 26%\",\n            \"--muted-foreground\": \"0 0% 71%\",\n            \"--accent\": \"0 0% 26%\",\n            \"--accent-foreground\": \"210 40% 98%\",\n            \"--destructive\": \"0 62.8% 30.6%\",\n            \"--destructive-foreground\": \"210 40% 98%\",\n            \"--border\": \"0 1% 26%\",\n            \"--input\": \"0 1% 26%\",\n            \"--ring\": \"340 92% 52%\",\n            \"--sidebar-background\": \"0 0% 9%\",\n            \"--sidebar-foreground\": \"240 4.8% 95.9%\",\n            \"--sidebar-primary\": \"224.3 76.3% 48%\",\n            \"--sidebar-primary-foreground\": \"0 0% 100%\",\n            \"--sidebar-accent\": \"0 0% 13%\",\n            \"--sidebar-accent-foreground\": \"240 4.8% 95.9%\",\n            \"--sidebar-border\": \"240 3.7% 15.9%\",\n            \"--sidebar-ring\": \"217.2 91.2% 59.8%\"\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit Widget in TypeScript\nDESCRIPTION: Defines the widget configuration interface in TypeScript, specifying options such as server URL, access token, theme, and button styling. These configurations are required for customizing the appearance and behavior of the Chainlit Copilot widget.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/copilot.mdx#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nexport interface IWidgetConfig {\n  chainlitServer: string;\n  accessToken?: string;\n  theme?: \"light\" | \"dark\";\n  button?: {\n    containerId?: string;\n    imageUrl?: string;\n    className?: string;\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Fonts to Chainlit Theme\nDESCRIPTION: Example of how to add custom Google Fonts to the Chainlit theme configuration through the custom_fonts array in theme.json.\nSOURCE: https://github.com/chainlit/docs/blob/main/customisation/theme.mdx#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\ncustom_fonts: [\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap\"]\n```\n\n----------------------------------------\n\nTITLE: Exposing Local Chainlit App Using ngrok\nDESCRIPTION: Command to use ngrok for exposing a local Chainlit app to the internet, enabling it to receive incoming Discord messages.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/discord.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nngrok http 8000\n```\n\n----------------------------------------\n\nTITLE: Running a Chainlit Application with the run Command\nDESCRIPTION: The 'run' command starts a Chainlit application with various configuration options including watch mode, headless mode, debug logging, and server configuration.\nSOURCE: https://github.com/chainlit/docs/blob/main/backend/command-line.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run [OPTIONS] TARGET\n```\n\n----------------------------------------\n\nTITLE: Calling Async Function with Await\nDESCRIPTION: Shows how to properly call an async function using the await keyword within another async function.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/sync-async.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nasync def another_async_function():\n    result = await my_async_function()\n```\n\n----------------------------------------\n\nTITLE: Executing MCP Tools in Python\nDESCRIPTION: Python implementation for executing tools using MCP sessions with step decoration.\nSOURCE: https://github.com/chainlit/docs/blob/main/advanced-features/mcp.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@cl.step(type=\"tool\") \nasync def call_tool(tool_use):\n    tool_name = tool_use.name\n    tool_input = tool_use.input\n    \n    # Find appropriate MCP connection for this tool\n    mcp_name = find_mcp_for_tool(tool_name)\n    \n    # Get the MCP session\n    mcp_session, _ = cl.context.session.mcp_sessions.get(mcp_name)\n    \n    # Call the tool\n    result = await mcp_session.call_tool(tool_name, tool_input)\n    \n    return result\n```\n\n----------------------------------------\n\nTITLE: Setting up Local Development Tunnel\nDESCRIPTION: Command to expose local Chainlit application to the internet using ngrok for testing\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/slack.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nngrok http 8000\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom JavaScript in Chainlit's config.toml\nDESCRIPTION: This TOML configuration snippet demonstrates how to specify a custom JavaScript file in the Chainlit config.toml file. It allows users to inject their own JavaScript into the application, either from a local file in the public directory or from a URL.\nSOURCE: https://github.com/chainlit/docs/blob/main/customisation/custom-js.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[UI]\n# ...\n# This can either be a css file in your `public` dir or a URL\ncustom_js = '/public/my_js_script.js'\n```\n\n----------------------------------------\n\nTITLE: Requesting Python File Upload with Specific Extension\nDESCRIPTION: Shows how to request a Python file upload by specifying the file extension (.py) for the text/plain mime type using a dictionary in the accept parameter.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/ask/ask-for-file.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\nfile = await cl.AskFileMessage(\n        content=\"Please upload a python file to begin!\", accept={\"text/plain\": [\".py\"]}\n      ).send()\n```\n\n----------------------------------------\n\nTITLE: Running Async Function from Sync Context\nDESCRIPTION: Shows how to execute an async function from within a synchronous function using Chainlit's run_sync utility.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/sync-async.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom chainlit import run_sync\n\nasync def my_async_function():\n    # Your asynchronous code goes here\n\ndef main():\n    result = run_sync(my_async_function())\n\nmain()\n```\n\n----------------------------------------\n\nTITLE: Configuring Final Answer Streaming in Langchain Callback Handler\nDESCRIPTION: Shows how to enable final answer streaming in the Langchain callback handler with custom prefix tokens. This configuration allows streaming of the final answer in addition to intermediate steps.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/integrations/langchain.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Optionally, you can also pass the prefix tokens that will be used to identify the final answer\nanswer_prefix_tokens=[\"FINAL\", \"ANSWER\"]\n\ncl.LangchainCallbackHandler(\n        stream_final_answer=True,\n        answer_prefix_tokens=answer_prefix_tokens,\n    )\n```\n\n----------------------------------------\n\nTITLE: Customizing UI Text in JSON Translation File\nDESCRIPTION: Example of modifying a translation key in a JSON file to customize UI text. This snippet changes the label of a navigation tab from 'Readme' to 'Documentation'.\nSOURCE: https://github.com/chainlit/docs/blob/main/customisation/translation.mdx#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\"components.organisms.header.readme\": \"Documentation\"\n```\n\n----------------------------------------\n\nTITLE: Setting Slack Environment Variables\nDESCRIPTION: Environment variable configuration for Slack bot token and signing secret\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/slack.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nSLACK_BOT_TOKEN=your_bot_token\n```\n\nLANGUAGE: bash\nCODE:\n```\nSLACK_SIGNING_SECRET=your_signing_secret\n```\n\n----------------------------------------\n\nTITLE: Retrieving MCP Tools in Python\nDESCRIPTION: Python code for discovering and storing available tools from an MCP service after connection.\nSOURCE: https://github.com/chainlit/docs/blob/main/advanced-features/mcp.mdx#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_mcp_connect\nasync def on_mcp(connection, session: ClientSession):\n    # List available tools\n    result = await session.list_tools()\n    \n    # Process tool metadata\n    tools = [{\n        \"name\": t.name,\n        \"description\": t.description,\n        \"input_schema\": t.inputSchema,\n    } for t in result.tools]\n    \n    # Store tools for later use\n    mcp_tools = cl.user_session.get(\"mcp_tools\", {})\n    mcp_tools[connection.name] = tools\n    cl.user_session.set(\"mcp_tools\", mcp_tools)\n```\n\n----------------------------------------\n\nTITLE: Resetting Translations in Chainlit Application\nDESCRIPTION: Bash command to run a Chainlit application after removing the translations directory. This resets the translations to their default state.\nSOURCE: https://github.com/chainlit/docs/blob/main/customisation/translation.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run my-app.py\n```\n\n----------------------------------------\n\nTITLE: Configuring CORS in Chainlit\nDESCRIPTION: Setting allow_origins in the Chainlit configuration file to handle cross-origin requests when embedding the UI on different websites.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/overview.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nallow_origins = [\"your-domain.com\"]\n```\n\n----------------------------------------\n\nTITLE: Creating DynamoDB Table Structure with CloudFormation in JSON\nDESCRIPTION: CloudFormation template in JSON format to create the DynamoDB table with the required structure for the Chainlit data layer. It defines the table name, attributes, key schema, and global secondary index.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-layers/dynamodb.mdx#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"AWSTemplateFormatVersion\": \"2010-09-09\",\n  \"Resources\": {\n    \"DynamoDBTable\": {\n      \"Type\": \"AWS::DynamoDB::Table\",\n      \"Properties\": {\n        \"TableName\": \"<YOUR-TABLE-NAME>\",\n        \"AttributeDefinitions\": [\n          {\n            \"AttributeName\": \"PK\",\n            \"AttributeType\": \"S\"\n          },\n          {\n            \"AttributeName\": \"SK\",\n            \"AttributeType\": \"S\"\n          },\n          {\n            \"AttributeName\": \"UserThreadPK\",\n            \"AttributeType\": \"S\"\n          },\n          {\n            \"AttributeName\": \"UserThreadSK\",\n            \"AttributeType\": \"S\"\n          }\n        ],\n        \"KeySchema\": [\n          {\n            \"AttributeName\": \"PK\",\n            \"KeyType\": \"HASH\"\n          },\n          {\n            \"AttributeName\": \"SK\",\n            \"KeyType\": \"RANGE\"\n          }\n        ],\n        \"GlobalSecondaryIndexes\": [\n          {\n            \"IndexName\": \"UserThread\",\n            \"KeySchema\": [\n              {\n                \"AttributeName\": \"UserThreadPK\",\n                \"KeyType\": \"HASH\"\n              },\n              {\n                \"AttributeName\": \"UserThreadSK\",\n                \"KeyType\": \"RANGE\"\n              }\n            ],\n            \"Projection\": {\n              \"ProjectionType\": \"INCLUDE\",\n              \"NonKeyAttributes\": [\"id\", \"name\"]\n            }\n          }\n        ],\n        \"BillingMode\": \"PAY_PER_REQUEST\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing New Chain of Thought\nDESCRIPTION: Example of the reworked Chain of Thought implementation that focuses on tool usage\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/1.1.300.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.step(type=\"tool\")\nasync def tool():\n    # Faking a tool\n    await cl.sleep(2)\n    return \"Tool Response\"\n\n@cl.on_message\nasync def on_message():\n    msg = await cl.Message(\"\").send()\n    msg.content = await tool()\n    await msg.update()\n```\n\n----------------------------------------\n\nTITLE: Starting FastAPI Server\nDESCRIPTION: Command to start the FastAPI server with Chainlit integration on port 80\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/fastapi.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuvicorn main:app --host 0.0.0.0 --port 80\n```\n\n----------------------------------------\n\nTITLE: Python Script for Creating JWT Access Tokens\nDESCRIPTION: Provides a Python function to generate JWT tokens for Chainlit authentication, utilizing the 'jwt' library. The script requires a predefined secret and involves setting the token expiration time. Tokens are used to authenticate users with the Chainlit server.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/copilot.mdx#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport jwt\nfrom datetime import datetime, timedelta\n\nCHAINLIT_AUTH_SECRET = \"your-secret\"\n\ndef create_jwt(identifier: str, metadata: dict) -> str:\n    to_encode = {\n      \"identifier\": identifier,\n      \"metadata\": metadata,\n      \"exp\": datetime.utcnow() + timedelta(minutes=60 * 24 * 15),  # 15 days\n      }\n\n    encoded_jwt = jwt.encode(to_encode, CHAINLIT_AUTH_SECRET, algorithm=\"HS256\")\n    return encoded_jwt\n\naccess_token = create_jwt(\"user-1\", {\"name\": \"John Doe\"})\n```\n\n----------------------------------------\n\nTITLE: Updating Chainlit using pip\nDESCRIPTION: This command upgrades Chainlit to the latest version using pip. It's the first step in the migration process to v1.0.500.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/1.0.500.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade chainlit\n```\n\n----------------------------------------\n\nTITLE: Starting Chainlit App with Slack Integration\nDESCRIPTION: Command to run the Chainlit application in headless mode for Slack integration\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/slack.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run my_app.py -h\n```\n\n----------------------------------------\n\nTITLE: Implementing Chainlit Starters\nDESCRIPTION: Example showing how to implement the new Starters feature with four different starter suggestions and custom icons\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/1.1.300.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.set_starters\nasync def set_starters():\n    return [\n        cl.Starter(\n            label=\"Morning routine ideation\",\n            message=\"Can you help me create a personalized morning routine that would help increase my productivity throughout the day? Start by asking me about my current habits and what activities energize me in the morning.\",\n            icon=\"/public/idea.svg\",\n            ),\n\n        cl.Starter(\n            label=\"Explain superconductors\",\n            message=\"Explain superconductors like I'm five years old.\",\n            icon=\"/public/learn.svg\",\n            ),\n        cl.Starter(\n            label=\"Python script for daily email reports\",\n            message=\"Write a script to automate sending daily email reports in Python, and walk me through how I would set it up.\",\n            icon=\"/public/terminal.svg\",\n            ),\n        cl.Starter(\n            label=\"Text inviting friend to wedding\",\n            message=\"Write a text asking a friend to be my plus-one at a wedding next month. I want to keep it super short and casual, and offer an out.\",\n            icon=\"/public/write.svg\",\n            )\n        ]\n```\n\n----------------------------------------\n\nTITLE: Launching Chainlit Application with Auto-Reloading\nDESCRIPTION: This command starts the Chainlit application with auto-reloading enabled. It runs the app.py script and makes the chatbot UI accessible at http://localhost:8000.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/llama-index.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Document QA Chatbot\nDESCRIPTION: This bash command installs the necessary Python packages for the document QA chatbot project, including LangChain, Chroma, and OpenAI libraries.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/qa.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install langchain langchain-community chromadb tiktoken openai langchain-openai\n```\n\n----------------------------------------\n\nTITLE: Implementing Message Counter (Naive Approach) in Python\nDESCRIPTION: This snippet demonstrates a naive approach to counting messages in a chat session. It uses a global counter variable, which can lead to issues in multi-user scenarios.\nSOURCE: https://github.com/chainlit/docs/blob/main/concepts/user-session.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\ncounter = 0\n\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    global counter\n    counter += 1\n\n    await cl.Message(content=f\"You sent {counter} message(s)!\").send()\n```\n\n----------------------------------------\n\nTITLE: Installing Botbuilder Core Package\nDESCRIPTION: Command to install the required botbuilder-core package for Teams integration\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/teams.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install botbuilder-core\n```\n\n----------------------------------------\n\nTITLE: Starting Chainlit App for Discord Integration\nDESCRIPTION: Command to start the Chainlit app without opening the default UI, as it will be used with Discord.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/discord.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run my_app.py -h\n```\n\n----------------------------------------\n\nTITLE: Inline Literal AI Server Configuration\nDESCRIPTION: Demonstrates how to set the LITERAL_API_URL environment variable inline when running a Chainlit application for connecting to a self-hosted Literal AI server.\nSOURCE: https://github.com/chainlit/docs/blob/main/llmops/enterprise.mdx#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nLITERAL_API_URL=\"https://cloud.your_literal.com\" chainlit run main.py\n```\n\n----------------------------------------\n\nTITLE: Defining Directory Structure for Custom Avatars in Chainlit\nDESCRIPTION: This snippet shows the directory structure for placing custom avatar images in a Chainlit application. The 'public/avatars' folder is used to store avatar images, which should be named after the author of the message.\nSOURCE: https://github.com/chainlit/docs/blob/main/customisation/avatars.mdx#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\npublic/\n└── avatars/\n    └── my_assistant.png\n```\n\n----------------------------------------\n\nTITLE: Installing @chainlit/react-client package\nDESCRIPTION: Command to install the @chainlit/react-client package using npm. This package provides React hooks and an API client for connecting to Chainlit applications.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/react/installation-and-setup.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @chainlit/react-client\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application in Headless Mode\nDESCRIPTION: Command to start the Chainlit application in headless mode for Teams integration\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/teams.mdx#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run my_app.py -h\n```\n\n----------------------------------------\n\nTITLE: Configuring Login Page Background in Chainlit\nDESCRIPTION: TOML configuration for customizing the login page background image and its visual filters. Allows setting custom image path and applying Tailwind filters for both light and dark modes.\nSOURCE: https://github.com/chainlit/docs/blob/main/customisation/custom-logo-and-favicon.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[UI]\n# Custom login page image, relative to public directory or external URL\nlogin_page_image = \"/public/custom-background.jpg\"\n\n# Custom login page image filter (Tailwind internal filters, no dark/light variants)\n# login_page_image_filter = \"brightness-50 grayscale\"\n# login_page_image_dark_filter = \"contrast-200 blur-sm\"\n```\n\n----------------------------------------\n\nTITLE: Accessing the Current Step in Chainlit\nDESCRIPTION: This example demonstrates how to access the current step object using cl.context.current_step and override its input and output values.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/step-decorator.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.step\nasync def my_step():\n    current_step = cl.context.current_step\n\n    # Override the input of the step\n    current_step.input = \"My custom input\"\n\n    # Override the output of the step\n    current_step.output = \"My custom output\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit API and Recoil in React application\nDESCRIPTION: React setup code that demonstrates how to initialize the Chainlit API client, wrap the application in a RecoilRoot for state management, and provide the API client through a context. This configuration is necessary for using the @chainlit/react-client package in a React application.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/react/installation-and-setup.mdx#2025-04-21_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport { RecoilRoot } from 'recoil';\n\nimport { ChainlitAPI, ChainlitContext } from '@chainlit/react-client';\n\nconst CHAINLIT_SERVER_URL = 'http://localhost:8000';\n\nconst apiClient = new ChainlitAPI(CHAINLIT_SERVER_URL, 'webapp');\n\nReactDOM.createRoot(document.getElementById('root') as HTMLElement).render(\n  <React.StrictMode>\n    <ChainlitContext.Provider value={apiClient}>\n      <RecoilRoot>\n        <MyApp />\n      </RecoilRoot>\n    </ChainlitContext.Provider>\n  </React.StrictMode>\n);\n```\n\n----------------------------------------\n\nTITLE: Initializing a Chainlit Project with the init Command\nDESCRIPTION: The 'init' command creates a new Chainlit project by generating a configuration file at '.chainlit/config.toml'.\nSOURCE: https://github.com/chainlit/docs/blob/main/backend/command-line.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nchainlit init\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for PII Analysis\nDESCRIPTION: This shell command installs the necessary Python packages for PII analysis and anonymization, including Presidio Analyzer, Presidio Anonymizer, and spaCy.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/security.mdx#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install presidio-analyzer presidio-anonymizer spacy\npython -m spacy download en_core_web_lg\n```\n\n----------------------------------------\n\nTITLE: Creating a .env file for Chainlit applications\nDESCRIPTION: An example of how to structure a .env file to store API keys for local Chainlit development. The file should be placed in the root directory of the project and added to .gitignore to prevent accidentally committing sensitive information.\nSOURCE: https://github.com/chainlit/docs/blob/main/backend/env-variables.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=sk-...\nPINECONE_API_KEY=...\n```\n\n----------------------------------------\n\nTITLE: Installing Discord Library for Chainlit\nDESCRIPTION: Command to install the Discord library, which is not included in Chainlit dependencies and must be installed manually.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/discord.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install discord\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application Command\nDESCRIPTION: Command line instruction to start the Chainlit application with auto-reloading enabled. The -w flag enables hot reloading for development convenience.\nSOURCE: https://github.com/chainlit/docs/blob/main/get-started/pure-python.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Receiving Messages in Parent Window from Chainlit\nDESCRIPTION: Shows how to listen for and handle messages sent from the Chainlit server in the parent window using the message event listener.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/webapp.mdx#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nwindow.addEventListener('message', (event) => {\n  if (event.data.startsWith(\"Server: \")) {\n    console.log('Parent window received:', event.data);\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Boto3 for DynamoDB Data Layer in Python\nDESCRIPTION: Command to install the boto3 library, which is required for interacting with AWS services including DynamoDB.\nSOURCE: https://github.com/chainlit/docs/blob/main/data-layers/dynamodb.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install boto3\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application\nDESCRIPTION: Command to start the Chainlit application with auto-reloading enabled. The -w flag enables watch mode for development.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/openai.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Setting OAuth Prompt Environment Variables in Bash\nDESCRIPTION: Example of how to set environment variables to configure OAuth prompt behavior. The first variable sets the default prompt behavior for all providers, while the second overrides this setting specifically for GitHub.\nSOURCE: https://github.com/chainlit/docs/blob/main/authentication/oauth.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Force consent prompt for all providers\nOAUTH_PROMPT=consent\n\n# Override specific provider to force login\nOAUTH_GITHUB_PROMPT=login\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit hello command\nDESCRIPTION: Command to test Chainlit installation by running a simple hello world program. This should launch the Chainlit UI and prompt for the user's name.\nSOURCE: https://github.com/chainlit/docs/blob/main/get-started/installation.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit hello\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application with Auto-reloading in Bash\nDESCRIPTION: This command starts the Chainlit application with auto-reloading enabled. It runs the app.py file and makes the chatbot UI accessible at http://localhost:8000.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/mistralai.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Embedding Chainlit Chatbot UI using HTML iframe\nDESCRIPTION: This code snippet demonstrates how to embed a Chainlit Chatbot UI into an existing webpage using an HTML iframe. It includes essential attributes for sizing, styling, and accessibility.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/iframe.mdx#2025-04-21_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n    src=\"https://your-chainlit-instance.com\"  /* URL of the chatbot interface */\n    width=\"100%\"  /* The iframe takes the full width of the parent element */\n    height=\"600px\"  /* Fixed height of the iframe */\n    frameBorder=\"0\"  /* No border around the iframe */\n    title=\"Embedded Webpage\"  /* Descriptive title for accessibility purposes */\n    style={{ border: 'none' }}  /* Additional styling options */\n></iframe>\n```\n\n----------------------------------------\n\nTITLE: Running Local Ngrok Tunnel\nDESCRIPTION: Command to create a public URL for local development using ngrok\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/teams.mdx#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nngrok http 8000\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application with Auto-reloading in Bash\nDESCRIPTION: This Bash command starts the Chainlit application with auto-reloading enabled. It runs the Python script 'app.py' and makes the chatbot UI accessible at http://localhost:8000.\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/message-based.mdx#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Running the ChainLit Application\nDESCRIPTION: Command to start the ChainLit application in watch mode for development.\nSOURCE: https://github.com/chainlit/docs/blob/main/examples/openai-sql.mdx#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Configuring Default Theme\nDESCRIPTION: Configuration example for setting the default theme in config.toml\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/1.1.300.mdx#2025-04-21_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[UI]\n  [UI.theme]\n      default = \"dark\"\n```\n\n----------------------------------------\n\nTITLE: Installing Chainlit v2.0.0 via pip\nDESCRIPTION: Command to upgrade Chainlit to the latest version using pip package manager.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/2.0.0.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade chainlit\n```\n\n----------------------------------------\n\nTITLE: Upgrading Chainlit using pip in Bash\nDESCRIPTION: Command to upgrade Chainlit to the latest version using pip package manager. This step is essential for migrating to Chainlit v1.1.0.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/1.1.0.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade chainlit\n```\n\n----------------------------------------\n\nTITLE: Setting Literal AI API Key in Windows PowerShell for Chainlit\nDESCRIPTION: This PowerShell command shows how to set the Literal AI API key as an environment variable and run a Chainlit application in Windows. It enables Literal AI integration for Windows users.\nSOURCE: https://github.com/chainlit/docs/blob/main/llmops/literalai.mdx#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ENV:LITERAL_API_KEY=\"your key\"; chainlit run main.py\n```\n\n----------------------------------------\n\nTITLE: Updating Chainlit Package using pip\nDESCRIPTION: Command to upgrade Chainlit to the latest version using pip package manager. This is the first step in the migration process to version 1.1.400.\nSOURCE: https://github.com/chainlit/docs/blob/main/guides/migration/1.1.400.mdx#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade chainlit\n```\n\n----------------------------------------\n\nTITLE: Setting Teams App Password Environment Variable\nDESCRIPTION: Environment variable configuration for Teams App secret\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/teams.mdx#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nTEAMS_APP_PASSWORD=your_app_secret\n```\n\n----------------------------------------\n\nTITLE: Installing Mintlify CLI\nDESCRIPTION: Command to install the Mintlify CLI globally using npm for local documentation preview\nSOURCE: https://github.com/chainlit/docs/blob/main/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm i -g mintlify\n```\n\n----------------------------------------\n\nTITLE: Running Mintlify Development Server\nDESCRIPTION: Command to start the local development server for preview, must be run from the documentation root directory containing mint.json\nSOURCE: https://github.com/chainlit/docs/blob/main/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmintlify dev\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application in Debug Mode (Python)\nDESCRIPTION: This code snippet demonstrates how to add the Chainlit context to your main application script or test files. It imports the run_chainlit function from the chainlit.cli module and executes it with the current file as an argument when the script is run directly.\nSOURCE: https://github.com/chainlit/docs/blob/main/advanced-features/test-debug.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    from chainlit.cli import run_chainlit\n    run_chainlit(__file__)\n```\n\n----------------------------------------\n\nTITLE: Default Chainlit Features Configuration in TOML\nDESCRIPTION: This TOML configuration snippet shows the default settings for Chainlit features. It includes configurations for message editing, HTML processing, LaTeX support, file upload parameters, and thread tagging options.\nSOURCE: https://github.com/chainlit/docs/blob/main/backend/config/features.mdx#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[features]\nedit_message = true\nunsafe_allow_html = false\nlatex = false\n[features.spontaneous_file_upload]\n    enabled = true\n    accept = [\"*/*\"]\n    max_files = 20\n    max_size_mb = 500\nauto_tag_thread = true\n```\n\n----------------------------------------\n\nTITLE: Simple Chainlit App for Discord Integration\nDESCRIPTION: Example of a basic Chainlit app that can communicate with Discord. It prints the original Discord message and user, and sends a 'Hello World' message in response.\nSOURCE: https://github.com/chainlit/docs/blob/main/deploy/discord.mdx#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def on_message(msg: cl.Message):\n    # Access the original discord message\n    print(cl.user_session.get(\"discord_message\"))\n    # Access the discord user\n    print(cl.user_session.get(\"user\"))\n\n    # Access potential attached files\n    attached_files = msg.elements\n\n    await cl.Message(content=\"Hello World\").send()\n```\n\n----------------------------------------\n\nTITLE: Using make_async with LangChain Agent in Python\nDESCRIPTION: This snippet shows how to use make_async with a LangChain agent. The agent is converted to an asynchronous function and executed with a LangchainCallbackHandler. The result is then sent as a Chainlit message.\nSOURCE: https://github.com/chainlit/docs/blob/main/api-reference/make-async.mdx#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\nres = await cl.make_async(agent)(input_str, callbacks=[cl.LangchainCallbackHandler()])\nawait cl.Message(content=res[\"text\"]).send()\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Chainlit Application\nDESCRIPTION: Simple Chainlit application that sends a 'Hello World' message when a chat session starts\nSOURCE: https://github.com/chainlit/docs/blob/main/integrations/fastapi.mdx#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_chat_start\nasync def main():\n    await cl.Message(content=\"Hello World\").send()\n```"
  }
]