[
  {
    "owner": "crewaiinc",
    "repo": "crewai",
    "content": "TITLE: Implementing Advanced Analysis Flow in Python with CrewAI\nDESCRIPTION: Demonstrates a structured workflow implementation using CrewAI's Flow architecture with market analysis. Shows state management, agent creation, task definition, and conditional routing based on confidence levels.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass MarketState(BaseModel):\n    sentiment: str = \"neutral\"\n    confidence: float = 0.0\n    recommendations: list = []\n\nclass AdvancedAnalysisFlow(Flow[MarketState]):\n    @start()\n    def fetch_market_data(self):\n        # Demonstrate low-level control with structured state\n        self.state.sentiment = \"analyzing\"\n        return {\"sector\": \"tech\", \"timeframe\": \"1W\"}\n\n    @listen(fetch_market_data)\n    def analyze_with_crew(self, market_data):\n        # Show crew agency through specialized roles\n        analyst = Agent(\n            role=\"Senior Market Analyst\",\n            goal=\"Conduct deep market analysis with expert insight\",\n            backstory=\"You're a veteran analyst known for identifying subtle market patterns\"\n        )\n        researcher = Agent(\n            role=\"Data Researcher\",\n            goal=\"Gather and validate supporting market data\",\n            backstory=\"You excel at finding and correlating multiple data sources\"\n        )\n\n        analysis_task = Task(\n            description=\"Analyze {sector} sector data for the past {timeframe}\",\n            expected_output=\"Detailed market analysis with confidence score\",\n            agent=analyst\n        )\n        research_task = Task(\n            description=\"Find supporting data to validate the analysis\",\n            expected_output=\"Corroborating evidence and potential contradictions\",\n            agent=researcher\n        )\n\n        # Demonstrate crew autonomy\n        analysis_crew = Crew(\n            agents=[analyst, researcher],\n            tasks=[analysis_task, research_task],\n            process=Process.sequential,\n            verbose=True\n        )\n        return analysis_crew.kickoff(inputs=market_data)\n\n    @router(analyze_with_crew)\n    def determine_next_steps(self):\n        # Show flow control with conditional routing\n        if self.state.confidence > 0.8:\n            return \"high_confidence\"\n        elif self.state.confidence > 0.5:\n            return \"medium_confidence\"\n        return \"low_confidence\"\n\n    @listen(\"high_confidence\")\n    def execute_strategy(self):\n        # Demonstrate complex decision making\n        strategy_crew = Crew(\n            agents=[\n                Agent(role=\"Strategy Expert\",\n                      goal=\"Develop optimal market strategy\")\n            ],\n            tasks=[\n                Task(description=\"Create detailed strategy based on analysis\",\n                     expected_output=\"Step-by-step action plan\")\n            ]\n        )\n        return strategy_crew.kickoff()\n\n    @listen(or_(\"medium_confidence\", \"low_confidence\"))\n    def request_additional_analysis(self):\n        self.state.recommendations.append(\"Gather more data\")\n        return \"Additional analysis required\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Code Development Agent with Execution Capabilities\nDESCRIPTION: Configuration for a Python development agent that can execute code in a safe environment. Includes longer execution timeouts and additional retry attempts for complex coding tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/agents.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndev_agent = Agent(\n    role=\"Senior Python Developer\",\n    goal=\"Write and debug Python code\",\n    backstory=\"Expert Python developer with 10 years of experience\",\n    allow_code_execution=True,\n    code_execution_mode=\"safe\",  # Uses Docker for safety\n    max_execution_time=300,  # 5-minute timeout\n    max_retry_limit=3  # More retries for complex code tasks\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing the CrewAI Class for AI Development Research\nDESCRIPTION: This Python code defines the main crew class that orchestrates agents and tasks for AI development research. It creates researcher and reporting analyst agents with specific tools and configures tasks in a sequential process flow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# src/latest_ai_development/crew.py\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai.project import CrewBase, agent, crew, task\nfrom crewai_tools import SerperDevTool\nfrom crewai.agents.agent_builder.base_agent import BaseAgent\nfrom typing import List\n\n@CrewBase\nclass LatestAiDevelopmentCrew():\n  \"\"\"LatestAiDevelopment crew\"\"\"\n\n  agents: List[BaseAgent]\n  tasks: List[Task]\n\n  @agent\n  def researcher(self) -> Agent:\n    return Agent(\n      config=self.agents_config['researcher'], # type: ignore[index]\n      verbose=True,\n      tools=[SerperDevTool()]\n    )\n\n  @agent\n  def reporting_analyst(self) -> Agent:\n    return Agent(\n      config=self.agents_config['reporting_analyst'], # type: ignore[index]\n      verbose=True\n    )\n\n  @task\n  def research_task(self) -> Task:\n    return Task(\n      config=self.tasks_config['research_task'], # type: ignore[index]\n    )\n\n  @task\n  def reporting_task(self) -> Task:\n    return Task(\n      config=self.tasks_config['reporting_task'], # type: ignore[index]\n      output_file='output/report.md' # This is the file that will be contain the final report.\n    )\n\n  @crew\n  def crew(self) -> Crew:\n    \"\"\"Creates the LatestAiDevelopment crew\"\"\"\n    return Crew(\n      agents=self.agents, # Automatically created by the @agent decorator\n      tasks=self.tasks, # Automatically created by the @task decorator\n      process=Process.sequential,\n      verbose=True,\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing a Research Crew for Market Analysis with CrewAI\nDESCRIPTION: This code creates a research crew with two specialized agents: a market researcher and an analyst. The crew follows a sequential process where the researcher first gathers market data on AI healthcare solutions, and then the analyst processes this information to identify investment opportunities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/concepts/evaluating-use-cases.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Example: Research Crew for market analysis\nfrom crewai import Agent, Crew, Process, Task\n\n# Create specialized agents\nresearcher = Agent(\n    role=\"Market Research Specialist\",\n    goal=\"Find comprehensive market data on emerging technologies\",\n    backstory=\"You are an expert at discovering market trends and gathering data.\"\n)\n\nanalyst = Agent(\n    role=\"Market Analyst\",\n    goal=\"Analyze market data and identify key opportunities\",\n    backstory=\"You excel at interpreting market data and spotting valuable insights.\"\n)\n\n# Define their tasks\nresearch_task = Task(\n    description=\"Research the current market landscape for AI-powered healthcare solutions\",\n    expected_output=\"Comprehensive market data including key players, market size, and growth trends\",\n    agent=researcher\n)\n\nanalysis_task = Task(\n    description=\"Analyze the market data and identify the top 3 investment opportunities\",\n    expected_output=\"Analysis report with 3 recommended investment opportunities and rationale\",\n    agent=analyst,\n    context=[research_task]\n)\n\n# Create the crew\nmarket_analysis_crew = Crew(\n    agents=[researcher, analyst],\n    tasks=[research_task, analysis_task],\n    process=Process.sequential,\n    verbose=True\n)\n\n# Run the crew\nresult = market_analysis_crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Implementing AI Development Crew Class\nDESCRIPTION: Python class definition for the LatestAiDevelopmentCrew using CrewAI framework with researcher and reporting analyst agents\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai.project import CrewBase, agent, crew, task\nfrom crewai_tools import SerperDevTool\nfrom crewai.agents.agent_builder.base_agent import BaseAgent\nfrom typing import List\n\n@CrewBase\nclass LatestAiDevelopmentCrew():\n\t\"\"\"LatestAiDevelopment crew\"\"\"\n\tagents: List[BaseAgent]\n\ttasks: List[Task]\n\n\t@agent\n\tdef researcher(self) -> Agent:\n\t\treturn Agent(\n\t\t\tconfig=self.agents_config['researcher'],\n\t\t\tverbose=True,\n\t\t\ttools=[SerperDevTool()]\n\t\t)\n\n\t@agent\n\tdef reporting_analyst(self) -> Agent:\n\t\treturn Agent(\n\t\t\tconfig=self.agents_config['reporting_analyst'],\n\t\t\tverbose=True\n\t\t)\n\n\t@task\n\tdef research_task(self) -> Task:\n\t\treturn Task(\n\t\t\tconfig=self.tasks_config['research_task'],\n\t\t)\n\n\t@task\n\tdef reporting_task(self) -> Task:\n\t\treturn Task(\n\t\t\tconfig=self.tasks_config['reporting_task'],\n\t\t\toutput_file='report.md'\n\t\t)\n\n\t@crew\n\tdef crew(self) -> Crew:\n\t\t\"\"\"Creates the LatestAiDevelopment crew\"\"\"\n\t\treturn Crew(\n\t\t\tagents=self.agents,\n\t\t\ttasks=self.tasks,\n\t\t\tprocess=Process.sequential,\n\t\t\tverbose=True,\n\t\t)\n```\n\n----------------------------------------\n\nTITLE: Building a Customer Support Flow with Structured Processing in CrewAI\nDESCRIPTION: This code implements a customer support workflow using CrewAI's Flow. It processes support tickets through defined steps including receipt, categorization, routing based on issue type, and resolution. The flow maintains structured state using Pydantic models and demonstrates conditional logic for different ticket categories.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/concepts/evaluating-use-cases.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Example: Customer Support Flow with structured processing\nfrom crewai.flow.flow import Flow, listen, router, start\nfrom pydantic import BaseModel\nfrom typing import List, Dict\n\n# Define structured state\nclass SupportTicketState(BaseModel):\n    ticket_id: str = \"\"\n    customer_name: str = \"\"\n    issue_description: str = \"\"\n    category: str = \"\"\n    priority: str = \"medium\"\n    resolution: str = \"\"\n    satisfaction_score: int = 0\n\nclass CustomerSupportFlow(Flow[SupportTicketState]):\n    @start()\n    def receive_ticket(self):\n        # In a real app, this might come from an API\n        self.state.ticket_id = \"TKT-12345\"\n        self.state.customer_name = \"Alex Johnson\"\n        self.state.issue_description = \"Unable to access premium features after payment\"\n        return \"Ticket received\"\n\n    @listen(receive_ticket)\n    def categorize_ticket(self, _):\n        # Use a direct LLM call for categorization\n        from crewai import LLM\n        llm = LLM(model=\"openai/gpt-4o-mini\")\n\n        prompt = f\"\"\"\n        Categorize the following customer support issue into one of these categories:\n        - Billing\n        - Account Access\n        - Technical Issue\n        - Feature Request\n        - Other\n\n        Issue: {self.state.issue_description}\n\n        Return only the category name.\n        \"\"\"\n\n        self.state.category = llm.call(prompt).strip()\n        return self.state.category\n\n    @router(categorize_ticket)\n    def route_by_category(self, category):\n        # Route to different handlers based on category\n        return category.lower().replace(\" \", \"_\")\n\n    @listen(\"billing\")\n    def handle_billing_issue(self):\n        # Handle billing-specific logic\n        self.state.priority = \"high\"\n        # More billing-specific processing...\n        return \"Billing issue handled\"\n\n    @listen(\"account_access\")\n    def handle_access_issue(self):\n        # Handle access-specific logic\n        self.state.priority = \"high\"\n        # More access-specific processing...\n        return \"Access issue handled\"\n\n    # Additional category handlers...\n\n    @listen(\"billing\", \"account_access\", \"technical_issue\", \"feature_request\", \"other\")\n    def resolve_ticket(self, resolution_info):\n        # Final resolution step\n        self.state.resolution = f\"Issue resolved: {resolution_info}\"\n        return self.state.resolution\n\n# Run the flow\nsupport_flow = CustomerSupportFlow()\nresult = support_flow.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Implementing Conditional Tasks with crewAI for Dynamic Workflow Management in Python\nDESCRIPTION: A complete example of implementing conditional tasks in crewAI. The code demonstrates how to create a crew with three agents that fetch, process, and summarize data about events in San Francisco. It includes a condition function that determines whether a task should be executed based on the previous task's output, enabling dynamic workflow adaptation.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/conditional-tasks.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nfrom pydantic import BaseModel\nfrom crewai import Agent, Crew\nfrom crewai.tasks.conditional_task import ConditionalTask\nfrom crewai.tasks.task_output import TaskOutput\nfrom crewai.task import Task\nfrom crewai_tools import SerperDevTool\n\n# Define a condition function for the conditional task\n# If false, the task will be skipped, if true, then execute the task.\ndef is_data_missing(output: TaskOutput) -> bool:\n    return len(output.pydantic.events) < 10  # this will skip this task\n\n# Define the agents\ndata_fetcher_agent = Agent(\n    role=\"Data Fetcher\",\n    goal=\"Fetch data online using Serper tool\",\n    backstory=\"Backstory 1\",\n    verbose=True,\n    tools=[SerperDevTool()]\n)\n\ndata_processor_agent = Agent(\n    role=\"Data Processor\",\n    goal=\"Process fetched data\",\n    backstory=\"Backstory 2\",\n    verbose=True\n)\n\nsummary_generator_agent = Agent(\n    role=\"Summary Generator\",\n    goal=\"Generate summary from fetched data\",\n    backstory=\"Backstory 3\",\n    verbose=True\n)\n\nclass EventOutput(BaseModel):\n    events: List[str]\n\ntask1 = Task(\n    description=\"Fetch data about events in San Francisco using Serper tool\",\n    expected_output=\"List of 10 things to do in SF this week\",\n    agent=data_fetcher_agent,\n    output_pydantic=EventOutput,\n)\n\nconditional_task = ConditionalTask(\n    description=\"\"\"\n        Check if data is missing. If we have less than 10 events,\n        fetch more events using Serper tool so that\n        we have a total of 10 events in SF this week..\n        \"\"\",\n    expected_output=\"List of 10 Things to do in SF this week\",\n    condition=is_data_missing,\n    agent=data_processor_agent,\n)\n\ntask3 = Task(\n    description=\"Generate summary of events in San Francisco from fetched data\",\n    expected_output=\"A complete report on the customer and their customers and competitors, including their demographics, preferences, market positioning and audience engagement.\",\n    agent=summary_generator_agent,\n)\n\n# Create a crew with the tasks\ncrew = Crew(\n    agents=[data_fetcher_agent, data_processor_agent, summary_generator_agent],\n    tasks=[task1, conditional_task, task3],\n    verbose=True,\n    planning=True\n)\n\n# Run the crew\nresult = crew.kickoff()\nprint(\"results\", result)\n```\n\n----------------------------------------\n\nTITLE: Using Custom LLM with CrewAI Agents and Crews\nDESCRIPTION: Example showing how to integrate a custom LLM implementation with CrewAI's Agent and Crew classes. Demonstrates initialization of the custom LLM, creating agents and tasks, and executing them both individually and as part of a crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom typing import Dict, Any\n\n# Create your custom LLM instance\njwt_llm = JWTAuthLLM(\n    jwt_token=\"your.jwt.token\", \n    endpoint=\"https://your-llm-endpoint.com/v1/chat/completions\"\n)\n\n# Use it with an agent\nagent = Agent(\n    role=\"Research Assistant\",\n    goal=\"Find information on a topic\",\n    backstory=\"You are a research assistant tasked with finding information.\",\n    llm=jwt_llm,\n)\n\n# Create a task for the agent\ntask = Task(\n    description=\"Research the benefits of exercise\",\n    agent=agent,\n    expected_output=\"A summary of the benefits of exercise\",\n)\n\n# Execute the task\nresult = agent.execute_task(task)\nprint(result)\n\n# Or use it with a crew\ncrew = Crew(\n    agents=[agent],\n    tasks=[task],\n    manager_llm=jwt_llm,  # Use your custom LLM for the manager\n)\n\n# Run the crew\nresult = crew.kickoff()\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Implementing Content Creation Crew in Python with CrewAI\nDESCRIPTION: Defines a ContentCrew class that manages content writing and reviewing agents, along with their associated tasks. Uses CrewAI decorators to establish relationships between agents and tasks in a sequential process.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai.project import CrewBase, agent, crew, task\nfrom crewai.agents.agent_builder.base_agent import BaseAgent\nfrom typing import List\n\n@CrewBase\nclass ContentCrew():\n    \"\"\"Content writing crew\"\"\"\n\n    agents: List[BaseAgent]\n    tasks: List[Task]\n\n    @agent\n    def content_writer(self) -> Agent:\n        return Agent(\n            config=self.agents_config['content_writer'],\n            verbose=True\n        )\n\n    @agent\n    def content_reviewer(self) -> Agent:\n        return Agent(\n            config=self.agents_config['content_reviewer'],\n            verbose=True\n        )\n\n    @task\n    def write_section_task(self) -> Task:\n        return Task(\n            config=self.tasks_config['write_section_task']\n        )\n\n    @task\n    def review_section_task(self) -> Task:\n        return Task(\n            config=self.tasks_config['review_section_task'],\n            context=[self.write_section_task()]\n        )\n\n    @crew\n    def crew(self) -> Crew:\n        \"\"\"Creates the content writing crew\"\"\"\n        return Crew(\n            agents=self.agents,\n            tasks=self.tasks,\n            process=Process.sequential,\n            verbose=True,\n        )\n```\n\n----------------------------------------\n\nTITLE: Implementing a Basic Custom LLM Class in Python\nDESCRIPTION: A complete implementation of a custom LLM class that inherits from CrewAI's BaseLLM. It includes initialization with API key and endpoint validation, methods for handling LLM calls with proper error handling, and required methods for indicating LLM capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import BaseLLM\nfrom typing import Any, Dict, List, Optional, Union\n\nclass CustomLLM(BaseLLM):\n    def __init__(self, api_key: str, endpoint: str):\n        super().__init__()  # Initialize the base class to set default attributes\n        if not api_key or not isinstance(api_key, str):\n            raise ValueError(\"Invalid API key: must be a non-empty string\")\n        if not endpoint or not isinstance(endpoint, str):\n            raise ValueError(\"Invalid endpoint URL: must be a non-empty string\")\n        self.api_key = api_key\n        self.endpoint = endpoint\n        self.stop = []  # You can customize stop words if needed\n        \n    def call(\n        self,\n        messages: Union[str, List[Dict[str, str]]],\n        tools: Optional[List[dict]] = None,\n        callbacks: Optional[List[Any]] = None,\n        available_functions: Optional[Dict[str, Any]] = None,\n    ) -> Union[str, Any]:\n        \"\"\"Call the LLM with the given messages.\n        \n        Args:\n            messages: Input messages for the LLM.\n            tools: Optional list of tool schemas for function calling.\n            callbacks: Optional list of callback functions.\n            available_functions: Optional dict mapping function names to callables.\n            \n        Returns:\n            Either a text response from the LLM or the result of a tool function call.\n            \n        Raises:\n            TimeoutError: If the LLM request times out.\n            RuntimeError: If the LLM request fails for other reasons.\n            ValueError: If the response format is invalid.\n        \"\"\"\n        # Implement your own logic to call the LLM\n        # For example, using requests:\n        import requests\n        \n        try:\n            headers = {\n                \"Authorization\": f\"Bearer {self.api_key}\",\n                \"Content-Type\": \"application/json\"\n            }\n            \n            # Convert string message to proper format if needed\n            if isinstance(messages, str):\n                messages = [{\"role\": \"user\", \"content\": messages}]\n            \n            data = {\n                \"messages\": messages,\n                \"tools\": tools\n            }\n            \n            response = requests.post(\n                self.endpoint, \n                headers=headers, \n                json=data,\n                timeout=30  # Set a reasonable timeout\n            )\n            response.raise_for_status()  # Raise an exception for HTTP errors\n            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n        except requests.Timeout:\n            raise TimeoutError(\"LLM request timed out\")\n        except requests.RequestException as e:\n            raise RuntimeError(f\"LLM request failed: {str(e)}\")\n        except (KeyError, IndexError, ValueError) as e:\n            raise ValueError(f\"Invalid response format: {str(e)}\")\n        \n    def supports_function_calling(self) -> bool:\n        \"\"\"Check if the LLM supports function calling.\n        \n        Returns:\n            True if the LLM supports function calling, False otherwise.\n        \"\"\"\n        # Return True if your LLM supports function calling\n        return True\n        \n    def supports_stop_words(self) -> bool:\n        \"\"\"Check if the LLM supports stop words.\n        \n        Returns:\n            True if the LLM supports stop words, False otherwise.\n        \"\"\"\n        # Return True if your LLM supports stop words\n        return True\n        \n    def get_context_window_size(self) -> int:\n        \"\"\"Get the context window size of the LLM.\n        \n        Returns:\n            The context window size as an integer.\n        \"\"\"\n        # Return the context window size of your LLM\n        return 8192\n```\n\n----------------------------------------\n\nTITLE: Implementing a Complete CrewAI System with Code Execution\nDESCRIPTION: This comprehensive example shows the full implementation of a CrewAI system with code execution capabilities. It demonstrates creating an agent, defining a task that requires code execution, setting up a crew, and executing the workflow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/coding-agents.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\n\n# Create an agent with code execution enabled\ncoding_agent = Agent(\n    role=\"Python Data Analyst\",\n    goal=\"Analyze data and provide insights using Python\",\n    backstory=\"You are an experienced data analyst with strong Python skills.\",\n    allow_code_execution=True\n)\n\n# Create a task that requires code execution\ndata_analysis_task = Task(\n    description=\"Analyze the given dataset and calculate the average age of participants.\",\n    agent=coding_agent\n)\n\n# Create a crew and add the task\nanalysis_crew = Crew(\n    agents=[coding_agent],\n    tasks=[data_analysis_task]\n)\n\n# Execute the crew\nresult = analysis_crew.kickoff()\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Comparing Generic vs. Specialized Agent Definitions in CrewAI\nDESCRIPTION: Demonstrates the difference between a generic agent role definition and a specialized one. Specialized agents deliver more precise and relevant outputs for specific tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nrole: \"Writer\"\n\nrole: \"Technical Blog Writer specializing in explaining complex AI concepts to non-technical audiences\"\n```\n\n----------------------------------------\n\nTITLE: Guide Creator Flow Implementation with CrewAI and LLM Integration\nDESCRIPTION: Implements a comprehensive guide creation flow that combines user input, LLM-based outline generation, and content creation using crews. Includes state management, structured data models, and event-driven flow control.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n#!/usr/bin/env python\nimport json\nimport os\nfrom typing import List, Dict\nfrom pydantic import BaseModel, Field\nfrom crewai import LLM\nfrom crewai.flow.flow import Flow, listen, start\nfrom guide_creator_flow.crews.content_crew.content_crew import ContentCrew\n\nclass Section(BaseModel):\n    title: str = Field(description=\"Title of the section\")\n    description: str = Field(description=\"Brief description of what the section should cover\")\n\nclass GuideOutline(BaseModel):\n    title: str = Field(description=\"Title of the guide\")\n    introduction: str = Field(description=\"Introduction to the topic\")\n    target_audience: str = Field(description=\"Description of the target audience\")\n    sections: List[Section] = Field(description=\"List of sections in the guide\")\n    conclusion: str = Field(description=\"Conclusion or summary of the guide\")\n\nclass GuideCreatorState(BaseModel):\n    topic: str = \"\"\n    audience_level: str = \"\"\n    guide_outline: GuideOutline = None\n    sections_content: Dict[str, str] = {}\n\nclass GuideCreatorFlow(Flow[GuideCreatorState]):\n    \"\"\"Flow for creating a comprehensive guide on any topic\"\"\"\n\n    @start()\n    def get_user_input(self):\n        \"\"\"Get input from the user about the guide topic and audience\"\"\"\n        print(\"\\n=== Create Your Comprehensive Guide ===\\n\")\n\n        self.state.topic = input(\"What topic would you like to create a guide for? \")\n\n        while True:\n            audience = input(\"Who is your target audience? (beginner/intermediate/advanced) \").lower()\n            if audience in [\"beginner\", \"intermediate\", \"advanced\"]:\n                self.state.audience_level = audience\n                break\n            print(\"Please enter 'beginner', 'intermediate', or 'advanced'\")\n\n        print(f\"\\nCreating a guide on {self.state.topic} for {self.state.audience_level} audience...\\n\")\n        return self.state\n\n    @listen(get_user_input)\n    def create_guide_outline(self, state):\n        \"\"\"Create a structured outline for the guide using a direct LLM call\"\"\"\n        print(\"Creating guide outline...\")\n\n        llm = LLM(model=\"openai/gpt-4o-mini\", response_format=GuideOutline)\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n            {\"role\": \"user\", \"content\": f\"\"\"\n            Create a detailed outline for a comprehensive guide on \"{state.topic}\" for {state.audience_level} level learners.\n\n            The outline should include:\n            1. A compelling title for the guide\n            2. An introduction to the topic\n            3. 4-6 main sections that cover the most important aspects of the topic\n            4. A conclusion or summary\n\n            For each section, provide a clear title and a brief description of what it should cover.\n            \"\"\"}\n        ]\n\n        response = llm.call(messages=messages)\n        outline_dict = json.loads(response)\n        self.state.guide_outline = GuideOutline(**outline_dict)\n\n        os.makedirs(\"output\", exist_ok=True)\n\n        with open(\"output/guide_outline.json\", \"w\") as f:\n            json.dump(outline_dict, f, indent=2)\n\n        print(f\"Guide outline created with {len(self.state.guide_outline.sections)} sections\")\n        return self.state.guide_outline\n\n    @listen(create_guide_outline)\n    def write_and_compile_guide(self, outline):\n        \"\"\"Write all sections and compile the guide\"\"\"\n        print(\"Writing guide sections and compiling...\")\n        completed_sections = []\n\n        for section in outline.sections:\n            print(f\"Processing section: {section.title}\")\n\n            previous_sections_text = \"\"\n            if completed_sections:\n                previous_sections_text = \"# Previously Written Sections\\n\\n\"\n                for title in completed_sections:\n                    previous_sections_text += f\"## {title}\\n\\n\"\n                    previous_sections_text += self.state.sections_content.get(title, \"\") + \"\\n\\n\"\n            else:\n                previous_sections_text = \"No previous sections written yet.\"\n\n            result = ContentCrew().crew().kickoff(inputs={\n                \"section_title\": section.title,\n                \"section_description\": section.description,\n                \"audience_level\": self.state.audience_level,\n                \"previous_sections\": previous_sections_text,\n                \"draft_content\": \"\"\n            })\n\n            self.state.sections_content[section.title] = result.raw\n            completed_sections.append(section.title)\n            print(f\"Section completed: {section.title}\")\n\n        guide_content = f\"# {outline.title}\\n\\n\"\n        guide_content += f\"## Introduction\\n\\n{outline.introduction}\\n\\n\"\n\n        for section in outline.sections:\n            section_content = self.state.sections_content.get(section.title, \"\")\n            guide_content += f\"\\n\\n{section_content}\\n\\n\"\n\n        guide_content += f\"## Conclusion\\n\\n{outline.conclusion}\\n\\n\"\n\n        with open(\"output/complete_guide.md\", \"w\") as f:\n            f.write(guide_content)\n\n        print(\"\\nComplete guide compiled and saved to output/complete_guide.md\")\n        return \"Guide creation completed successfully\"\n\ndef kickoff():\n    \"\"\"Run the guide creator flow\"\"\"\n    GuideCreatorFlow().kickoff()\n    print(\"\\n=== Flow Complete ===\")\n    print(\"Your comprehensive guide is ready in the output directory.\")\n    print(\"Open output/complete_guide.md to view it.\")\n\ndef plot():\n    \"\"\"Generate a visualization of the flow\"\"\"\n    flow = GuideCreatorFlow()\n    flow.plot(\"guide_creator_flow\")\n    print(\"Flow visualization saved to guide_creator_flow.html\")\n\nif __name__ == \"__main__\":\n    kickoff()\n```\n\n----------------------------------------\n\nTITLE: Configuring Crew Execution Process in Python\nDESCRIPTION: Demonstrates how to create a crew with agents and tasks, specifying the execution process (sequential or hierarchical).\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ncrew = Crew(\n    agents=[agent1, agent2],\n    tasks=[task1, task2],\n    process=Process.sequential  # or Process.hierarchical\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Parallel Data Analysis with CrewAI\nDESCRIPTION: Example shows how to create a CrewAI setup that processes multiple datasets using kickoff_for_each(). The code creates a Python Data Analyst agent, configures a data analysis task, and executes it across multiple age datasets. The agent is configured with code execution capabilities to perform numerical analysis.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/kickoff-for-each.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task\n\n# Create an agent with code execution enabled\ncoding_agent = Agent(\n    role=\"Python Data Analyst\",\n    goal=\"Analyze data and provide insights using Python\",\n    backstory=\"You are an experienced data analyst with strong Python skills.\",\n    allow_code_execution=True\n)\n\n# Create a task that requires code execution\ndata_analysis_task = Task(\n    description=\"Analyze the given dataset and calculate the average age of participants. Ages: {ages}\",\n    agent=coding_agent,\n    expected_output=\"The average age calculated from the dataset\"\n)\n\n# Create a crew and add the task\nanalysis_crew = Crew(\n    agents=[coding_agent],\n    tasks=[data_analysis_task],\n    verbose=True,\n    memory=False\n)\n\ndatasets = [\n  { \"ages\": [25, 30, 35, 40, 45] },\n  { \"ages\": [20, 25, 30, 35, 40] },\n  { \"ages\": [30, 35, 40, 45, 50] }\n]\n\n# Execute the crew\nresult = analysis_crew.kickoff_for_each(inputs=datasets)\n```\n\n----------------------------------------\n\nTITLE: Configuring a Basic Research Agent in CrewAI\nDESCRIPTION: Creating a simple research agent with search capability using SerperDevTool. This configuration enables verbose logging for debugging and focuses on information retrieval tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/agents.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nresearch_agent = Agent(\n    role=\"Research Analyst\",\n    goal=\"Find and summarize information about specific topics\",\n    backstory=\"You are an experienced researcher with attention to detail\",\n    tools=[SerperDevTool()],\n    verbose=True  # Enable logging for debugging\n)\n```\n\n----------------------------------------\n\nTITLE: Subclassing BaseTool for Custom Tool Creation in Python\nDESCRIPTION: Demonstrates how to create a custom tool by subclassing BaseTool, defining input schema, and implementing the _run method. This approach allows for detailed tool configuration and input validation.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/create-custom-tools.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Type\nfrom crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\n\nclass MyToolInput(BaseModel):\n    \"\"\"Input schema for MyCustomTool.\"\"\"\n    argument: str = Field(..., description=\"Description of the argument.\")\n\nclass MyCustomTool(BaseTool):\n    name: str = \"Name of my tool\"\n    description: str = \"What this tool does. It's vital for effective utilization.\"\n    args_schema: Type[BaseModel] = MyToolInput\n\n    def _run(self, argument: str) -> str:\n        # Your tool's logic here\n        return \"Tool's result\"\n```\n\n----------------------------------------\n\nTITLE: Accessing CrewAI Crew Outputs\nDESCRIPTION: This snippet demonstrates how to access and interact with the output of a CrewAI crew execution. It shows how to retrieve raw output, JSON output, Pydantic output, task outputs, and token usage information.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/crews.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Example crew execution\ncrew = Crew(\n    agents=[research_agent, writer_agent],\n    tasks=[research_task, write_article_task],\n    verbose=True\n)\n\ncrew_output = crew.kickoff()\n\n# Accessing the crew output\nprint(f\"Raw Output: {crew_output.raw}\")\nif crew_output.json_dict:\n    print(f\"JSON Output: {json.dumps(crew_output.json_dict, indent=2)}\")\nif crew_output.pydantic:\n    print(f\"Pydantic Output: {crew_output.pydantic}\")\nprint(f\"Tasks Output: {crew_output.tasks_output}\")\nprint(f\"Token Usage: {crew_output.token_usage}\")\n```\n\n----------------------------------------\n\nTITLE: Adding Multiple Tools to a Research Agent\nDESCRIPTION: Example of creating and adding multiple tools to an agent for enhanced capabilities. The agent uses both search and Wikipedia tools to perform comprehensive research tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/agents.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\nfrom crewai_tools import SerperDevTool, WikipediaTools\n\n# Create tools\nsearch_tool = SerperDevTool()\nwiki_tool = WikipediaTools()\n\n# Add tools to agent\nresearcher = Agent(\n    role=\"AI Technology Researcher\",\n    goal=\"Research the latest AI developments\",\n    tools=[search_tool, wiki_tool],\n    verbose=True\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Tasks for Content Writer Crew\nDESCRIPTION: YAML configuration defining specific writing and reviewing tasks with detailed instructions for content creation. Includes parameters for section titles, audience level, and previous content for maintaining consistency.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# src/guide_creator_flow/crews/content_crew/config/tasks.yaml\nwrite_section_task:\n  description: >\n    Write a comprehensive section on the topic: \"{section_title}\"\n\n    Section description: {section_description}\n    Target audience: {audience_level} level learners\n\n    Your content should:\n    1. Begin with a brief introduction to the section topic\n    2. Explain all key concepts clearly with examples\n    3. Include practical applications or exercises where appropriate\n    4. End with a summary of key points\n    5. Be approximately 500-800 words in length\n\n    Format your content in Markdown with appropriate headings, lists, and emphasis.\n\n    Previously written sections:\n    {previous_sections}\n\n    Make sure your content maintains consistency with previously written sections\n    and builds upon concepts that have already been explained.\n  expected_output: >\n    A well-structured, comprehensive section in Markdown format that thoroughly\n    explains the topic and is appropriate for the target audience.\n  agent: content_writer\n\nreview_section_task:\n  description: >\n    Review and improve the following section on \"{section_title}\":\n\n    {draft_content}\n\n    Target audience: {audience_level} level learners\n\n    Previously written sections:\n    {previous_sections}\n\n    Your review should:\n    1. Fix any grammatical or spelling errors\n    2. Improve clarity and readability\n    3. Ensure content is comprehensive and accurate\n    4. Verify consistency with previously written sections\n    5. Enhance the structure and flow\n    6. Add any missing key information\n\n    Provide the improved version of the section in Markdown format.\n  expected_output: >\n    An improved, polished version of the section that maintains the original\n    structure but enhances clarity, accuracy, and consistency.\n  agent: content_reviewer\n  context:\n    - write_section_task\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic CrewAI Flow with OpenAI Integration\nDESCRIPTION: Demonstrates how to create a basic CrewAI Flow that generates a random city and a fun fact about it using OpenAI. Shows usage of @start() and @listen() decorators for task coordination.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\nfrom dotenv import load_dotenv\nfrom litellm import completion\n\n\nclass ExampleFlow(Flow):\n    model = \"gpt-4o-mini\"\n\n    @start()\n    def generate_city(self):\n        print(\"Starting flow\")\n        # Each flow state automatically gets a unique ID\n        print(f\"Flow State ID: {self.state['id']}\")\n\n        response = completion(\n            model=self.model,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Return the name of a random city in the world.\",\n                },\n            ],\n        )\n\n        random_city = response[\"choices\"][0][\"message\"][\"content\"]\n        # Store the city in our state\n        self.state[\"city\"] = random_city\n        print(f\"Random City: {random_city}\")\n\n        return random_city\n\n    @listen(generate_city)\n    def generate_fun_fact(self, random_city):\n        response = completion(\n            model=self.model,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Tell me a fun fact about {random_city}\",\n                },\n            ],\n        )\n\n        fun_fact = response[\"choices\"][0][\"message\"][\"content\"]\n        # Store the fun fact in our state\n        self.state[\"fun_fact\"] = fun_fact\n        return fun_fact\n\n\n\nflow = ExampleFlow()\nresult = flow.kickoff()\n\nprint(f\"Generated fun fact: {result}\")\n```\n\n----------------------------------------\n\nTITLE: Before and After Example: Content Creation Agent Definition in CrewAI\nDESCRIPTION: A comparative example showing how to transform a basic content creation agent definition into a detailed, specialized one using the Role-Goal-Backstory framework.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nrole: \"Writer\"\ngoal: \"Write good content\"\nbackstory: \"You are a writer who creates content for websites.\"\n\nrole: \"B2B Technology Content Strategist\"\ngoal: \"Create compelling, technically accurate content that explains complex topics in accessible language while driving reader engagement and supporting business objectives\"\nbackstory: \"You have spent a decade creating content for leading technology companies, specializing in translating technical concepts for business audiences. You excel at research, interviewing subject matter experts, and structuring information for maximum clarity and impact. You believe that the best B2B content educates first and sells second, building trust through genuine expertise rather than marketing hype.\"\n```\n\n----------------------------------------\n\nTITLE: Configuring LLMs Directly in Python Code\nDESCRIPTION: Demonstrates how to configure LLM settings directly in Python code for maximum flexibility. Shows both basic and advanced configuration options with parameters like temperature, timeout, and response format.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM\n\n# Basic configuration\nllm = LLM(model=\"gpt-4\")\n\n# Advanced configuration with detailed parameters\nllm = LLM(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,        # Higher for more creative outputs\n    timeout=120,           # Seconds to wait for response\n    max_tokens=4000,       # Maximum length of response\n    top_p=0.9,            # Nucleus sampling parameter\n    frequency_penalty=0.1, # Reduce repetition\n    presence_penalty=0.1,  # Encourage topic diversity\n    response_format={\"type\": \"json\"},  # For structured outputs\n    seed=42               # For reproducible results\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Manager Agent in CrewAI with Python\nDESCRIPTION: This code snippet demonstrates how to create a custom manager agent in CrewAI. It defines agents, tasks, and a manager agent, then instantiates a crew with the custom manager. The example includes creating researcher and writer agents, defining a task, and setting up a project manager as the custom manager agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-manager-agent.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom crewai import Agent, Task, Crew, Process\n\n# Define your agents\nresearcher = Agent(\n    role=\"Researcher\",\n    goal=\"Conduct thorough research and analysis on AI and AI agents\",\n    backstory=\"You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.\",\n    allow_delegation=False,\n)\n\nwriter = Agent(\n    role=\"Senior Writer\",\n    goal=\"Create compelling content about AI and AI agents\",\n    backstory=\"You're a senior writer, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently writing content for a new client.\",\n    allow_delegation=False,\n)\n\n# Define your task\ntask = Task(\n    description=\"Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.\",\n    expected_output=\"5 bullet points, each with a paragraph and accompanying notes.\",\n)\n\n# Define the manager agent\nmanager = Agent(\n    role=\"Project Manager\",\n    goal=\"Efficiently manage the crew and ensure high-quality task completion\",\n    backstory=\"You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.\",\n    allow_delegation=True,\n)\n\n# Instantiate your crew with a custom manager\ncrew = Crew(\n    agents=[researcher, writer],\n    tasks=[task],\n    manager_agent=manager,\n    process=Process.hierarchical,\n)\n\n# Start the crew's work\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Implementing CrewAI Crew with Decorators and YAML Configuration\nDESCRIPTION: This snippet demonstrates how to create a CrewAI crew using decorators and YAML configuration files. It includes methods for defining agents, tasks, and the crew itself, as well as hooks for pre- and post-execution processing.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/crews.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Task, Process\nfrom crewai.project import CrewBase, agent, task, crew, before_kickoff, after_kickoff\nfrom crewai.agents.agent_builder.base_agent import BaseAgent\nfrom typing import List\n\n@CrewBase\nclass YourCrewName:\n    \"\"\"Description of your crew\"\"\"\n\n    agents: List[BaseAgent]\n    tasks: List[Task]\n\n    # Paths to your YAML configuration files\n    # To see an example agent and task defined in YAML, checkout the following:\n    # - Task: https://docs.crewai.com/concepts/tasks#yaml-configuration-recommended\n    # - Agents: https://docs.crewai.com/concepts/agents#yaml-configuration-recommended\n    agents_config = 'config/agents.yaml' \n    tasks_config = 'config/tasks.yaml' \n\n    @before_kickoff\n    def prepare_inputs(self, inputs):\n        # Modify inputs before the crew starts\n        inputs['additional_data'] = \"Some extra information\"\n        return inputs\n\n    @after_kickoff\n    def process_output(self, output):\n        # Modify output after the crew finishes\n        output.raw += \"\\nProcessed after kickoff.\"\n        return output\n\n    @agent\n    def agent_one(self) -> Agent:\n        return Agent(\n            config=self.agents_config['agent_one'], # type: ignore[index]\n            verbose=True\n        )\n\n    @agent\n    def agent_two(self) -> Agent:\n        return Agent(\n            config=self.agents_config['agent_two'], # type: ignore[index]\n            verbose=True\n        )\n\n    @task\n    def task_one(self) -> Task:\n        return Task(\n            config=self.tasks_config['task_one'] # type: ignore[index]\n        )\n\n    @task\n    def task_two(self) -> Task:\n        return Task(\n            config=self.tasks_config['task_two'] # type: ignore[index]\n        )\n\n    @crew\n    def crew(self) -> Crew:\n        return Crew(\n            agents=self.agents,  # Automatically collected by the @agent decorator\n            tasks=self.tasks,    # Automatically collected by the @task decorator. \n            process=Process.sequential,\n            verbose=True,\n        )\n```\n\n----------------------------------------\n\nTITLE: Implementing Human Input in CrewAI Agent Execution Workflow\nDESCRIPTION: Complete implementation example showing how to integrate human input into CrewAI agent execution. The code sets up two agents (researcher and writer) with specific tasks that require human validation before completion, utilizing the human_input flag to enable interactive feedback.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/human-input-on-execution.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import SerperDevTool\n\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\"  # serper.dev API key\nos.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\n\n# Loading Tools\nsearch_tool = SerperDevTool()\n\n# Define your agents with roles, goals, tools, and additional attributes\nresearcher = Agent(\n    role='Senior Research Analyst',\n    goal='Uncover cutting-edge developments in AI and data science',\n    backstory=(\n        \"You are a Senior Research Analyst at a leading tech think tank. \"\n        \"Your expertise lies in identifying emerging trends and technologies in AI and data science. \"\n        \"You have a knack for dissecting complex data and presenting actionable insights.\"\n    ),\n    verbose=True,\n    allow_delegation=False,\n    tools=[search_tool]\n)\nwriter = Agent(\n    role='Tech Content Strategist',\n    goal='Craft compelling content on tech advancements',\n    backstory=(\n        \"You are a renowned Tech Content Strategist, known for your insightful and engaging articles on technology and innovation. \"\n        \"With a deep understanding of the tech industry, you transform complex concepts into compelling narratives.\"\n    ),\n    verbose=True,\n    allow_delegation=True,\n    tools=[search_tool],\n    cache=False,  # Disable cache for this agent\n)\n\n# Create tasks for your agents\ntask1 = Task(\n    description=(\n        \"Conduct a comprehensive analysis of the latest advancements in AI in 2025. \"\n        \"Identify key trends, breakthrough technologies, and potential industry impacts. \"\n        \"Compile your findings in a detailed report. \"\n        \"Make sure to check with a human if the draft is good before finalizing your answer.\"\n    ),\n    expected_output='A comprehensive full report on the latest AI advancements in 2025, leave nothing out',\n    agent=researcher,\n    human_input=True\n)\n\ntask2 = Task(\n    description=(\n        \"Using the insights from the researcher\\'s report, develop an engaging blog post that highlights the most significant AI advancements. \"\n        \"Your post should be informative yet accessible, catering to a tech-savvy audience. \"\n        \"Aim for a narrative that captures the essence of these breakthroughs and their implications for the future.\"\n    ),\n    expected_output='A compelling 3 paragraphs blog post formatted as markdown about the latest AI advancements in 2025',\n    agent=writer,\n    human_input=True\n)\n\n# Instantiate your crew with a sequential process\ncrew = Crew(\n    agents=[researcher, writer],\n    tasks=[task1, task2],\n    verbose=True,\n    memory=True,\n    planning=True  # Enable planning feature for the crew\n)\n\n# Get your crew to work!\nresult = crew.kickoff()\n\nprint(\"######################\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Using CodeInterpreterTool with CrewAI Agent\nDESCRIPTION: Example demonstrating how to use the CodeInterpreterTool with a CrewAI agent to write and execute Python code for solving problems.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/codeinterpretertool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew, Process\nfrom crewai_tools import CodeInterpreterTool\n\n# Initialize the tool\ncode_interpreter = CodeInterpreterTool()\n\n# Define an agent that uses the tool\nprogrammer_agent = Agent(\n    role=\"Python Programmer\",\n    goal=\"Write and execute Python code to solve problems\",\n    backstory=\"An expert Python programmer who can write efficient code to solve complex problems.\",\n    tools=[code_interpreter],\n    verbose=True,\n)\n\n# Example task to generate and execute code\ncoding_task = Task(\n    description=\"Write a Python function to calculate the Fibonacci sequence up to the 10th number and print the result.\",\n    expected_output=\"The Fibonacci sequence up to the 10th number.\",\n    agent=programmer_agent,\n)\n\n# Create and run the crew\ncrew = Crew(\n    agents=[programmer_agent],\n    tasks=[coding_task],\n    verbose=True,\n    process=Process.sequential,\n)\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Defining Specialized Agent Roles in CrewAI\nDESCRIPTION: Examples of effective agent role definitions that demonstrate specificity and specialization. These roles align with real-world professions and include domain expertise to create more capable AI agents.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nrole: \"Senior UX Researcher specializing in user interview analysis\"\nrole: \"Full-Stack Software Architect with expertise in distributed systems\"\nrole: \"Corporate Communications Director specializing in crisis management\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Hierarchical Process with CrewAI in Python\nDESCRIPTION: This code snippet demonstrates how to set up a crew using the hierarchical process in CrewAI. It defines researcher and writer agents, and establishes a crew with specific configurations including the process type, manager LLM, and planning option.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/hierarchical-process.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Process, Agent\n\n# Agents are defined with attributes for backstory, cache, and verbose mode\nresearcher = Agent(\n    role='Researcher',\n    goal='Conduct in-depth analysis',\n    backstory='Experienced data analyst with a knack for uncovering hidden trends.',\n)\nwriter = Agent(\n    role='Writer',\n    goal='Create engaging content',\n    backstory='Creative writer passionate about storytelling in technical domains.',\n)\n\n# Establishing the crew with a hierarchical process and additional configurations\nproject_crew = Crew(\n    tasks=[...],  # Tasks to be delegated and executed under the manager's supervision\n    agents=[researcher, writer],\n    manager_llm=\"gpt-4o\",  # Specify which LLM the manager should use\n    process=Process.hierarchical,  \n    planning=True, \n)\n```\n\n----------------------------------------\n\nTITLE: Implementing String-Based Knowledge Source in CrewAI\nDESCRIPTION: This snippet demonstrates how to create and use a string-based knowledge source with an AI agent in CrewAI. It includes setting up the knowledge source, creating an agent with the knowledge, and executing a task using the crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew, Process, LLM\nfrom crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n\n# Create a knowledge source\ncontent = \"Users name is John. He is 30 years old and lives in San Francisco.\"\nstring_source = StringKnowledgeSource(\n    content=content,\n)\n\n# Create an LLM with a temperature of 0 to ensure deterministic outputs\nllm = LLM(model=\"gpt-4o-mini\", temperature=0)\n\n# Create an agent with the knowledge store\nagent = Agent(\n    role=\"About User\",\n    goal=\"You know everything about the user.\",\n    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    llm=llm,\n)\ntask = Task(\n    description=\"Answer the following questions about the user: {question}\",\n    expected_output=\"An answer to the question.\",\n    agent=agent,\n)\n\ncrew = Crew(\n    agents=[agent],\n    tasks=[task],\n    verbose=True,\n    process=Process.sequential,\n    knowledge_sources=[string_source], # Enable knowledge by adding the sources here. You can also add more sources to the sources list.\n)\n\nresult = crew.kickoff(inputs={\"question\": \"What city does John live in and how old is he?\"})\n```\n\n----------------------------------------\n\nTITLE: Complete CrewAI RAG Workflow Implementation\nDESCRIPTION: Comprehensive example demonstrating PDF text extraction, OpenAI embedding generation, Qdrant storage, and CrewAI agent workflow setup for semantic search capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/qdrantvectorsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport uuid\nimport pdfplumber\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\nfrom crewai import Agent, Task, Crew, Process, LLM\nfrom crewai_tools import QdrantVectorSearchTool\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.models import PointStruct, Distance, VectorParams\n\n# Load environment variables\nload_dotenv()\n\n# Initialize OpenAI client\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# Extract text from PDF\ndef extract_text_from_pdf(pdf_path):\n    text = []\n    with pdfplumber.open(pdf_path) as pdf:\n        for page in pdf.pages:\n            page_text = page.extract_text()\n            if page_text:\n                text.append(page_text.strip())\n    return text\n\n# Generate OpenAI embeddings\ndef get_openai_embedding(text):\n    response = client.embeddings.create(\n        input=text,\n        model=\"text-embedding-3-small\"\n    )\n    return response.data[0].embedding\n\n# Store text and embeddings in Qdrant\ndef load_pdf_to_qdrant(pdf_path, qdrant, collection_name):\n    # Extract text from PDF\n    text_chunks = extract_text_from_pdf(pdf_path)\n    \n    # Create Qdrant collection\n    if qdrant.collection_exists(collection_name):\n        qdrant.delete_collection(collection_name)\n    qdrant.create_collection(\n        collection_name=collection_name,\n        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n    )\n\n    # Store embeddings\n    points = []\n    for chunk in text_chunks:\n        embedding = get_openai_embedding(chunk)\n        points.append(PointStruct(\n            id=str(uuid.uuid4()),\n            vector=embedding,\n            payload={\"text\": chunk}\n        ))\n    qdrant.upsert(collection_name=collection_name, points=points)\n\n# Initialize Qdrant client and load data\nqdrant = QdrantClient(\n    url=os.getenv(\"QDRANT_URL\"),\n    api_key=os.getenv(\"QDRANT_API_KEY\")\n)\ncollection_name = \"example_collection\"\npdf_path = \"path/to/your/document.pdf\"\nload_pdf_to_qdrant(pdf_path, qdrant, collection_name)\n\n# Initialize Qdrant search tool\nqdrant_tool = QdrantVectorSearchTool(\n    qdrant_url=os.getenv(\"QDRANT_URL\"),\n    qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n    collection_name=collection_name,\n    limit=3,\n    score_threshold=0.35\n)\n\n# Create CrewAI agents\nsearch_agent = Agent(\n    role=\"Senior Semantic Search Agent\",\n    goal=\"Find and analyze documents based on semantic search\",\n    backstory=\"\"\"You are an expert research assistant who can find relevant \n    information using semantic search in a Qdrant database.\"\"\",\n    tools=[qdrant_tool],\n    verbose=True\n)\n\nanswer_agent = Agent(\n    role=\"Senior Answer Assistant\",\n    goal=\"Generate answers to questions based on the context provided\",\n    backstory=\"\"\"You are an expert answer assistant who can generate \n    answers to questions based on the context provided.\"\"\",\n    tools=[qdrant_tool],\n    verbose=True\n)\n\n# Define tasks\nsearch_task = Task(\n    description=\"\"\"Search for relevant documents about the {query}.\n    Your final answer should include:\n    - The relevant information found\n    - The similarity scores of the results\n    - The metadata of the relevant documents\"\"\",\n    agent=search_agent\n)\n\nanswer_task = Task(\n    description=\"\"\"Given the context and metadata of relevant documents,\n    generate a final answer based on the context.\"\"\",\n    agent=answer_agent\n)\n\n# Run CrewAI workflow\ncrew = Crew(\n    agents=[search_agent, answer_agent],\n    tasks=[search_task, answer_task],\n    process=Process.sequential,\n    verbose=True\n)\n\nresult = crew.kickoff(\n    inputs={\"query\": \"What is the role of X in the document?\"}\n)\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Defining Tasks Directly in Python Code\nDESCRIPTION: Shows how to create tasks directly in Python code without using YAML configuration, specifying the task description, expected output, agent assignment, and output file.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Task\n\nresearch_task = Task(\n    description=\"\"\"\n        Conduct a thorough research about AI Agents.\n        Make sure you find any interesting and relevant information given\n        the current year is 2025.\n    \"\"\",\n    expected_output=\"\"\"\n        A list with 10 bullet points of the most relevant information about AI Agents\n    \"\"\",\n    agent=researcher\n)\n\nreporting_task = Task(\n    description=\"\"\"\n        Review the context you got and expand each topic into a full section for a report.\n        Make sure the report is detailed and contains any and all relevant information.\n    \"\"\",\n    expected_output=\"\"\"\n        A fully fledge reports with the mains topics, each with a full section of information.\n        Formatted as markdown without '```'\n    \"\"\",\n    agent=reporting_analyst,\n    output_file=\"report.md\"\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a CrewAI Agent with Full Parameter Configuration\nDESCRIPTION: A comprehensive example showing all available parameters when creating a CrewAI Agent. This includes configuration for the agent's role, capabilities, execution limits, and tool usage.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/agents.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nagent = Agent(\n    role=\"Senior Data Scientist\",\n    goal=\"Analyze and interpret complex datasets to provide actionable insights\",\n    backstory=\"With over 10 years of experience in data science and machine learning, \"\n              \"you excel at finding patterns in complex datasets.\",\n    llm=\"gpt-4\",  # Default: OPENAI_MODEL_NAME or \"gpt-4\"\n    function_calling_llm=None,  # Optional: Separate LLM for tool calling\n    memory=True,  # Default: True\n    verbose=False,  # Default: False\n    allow_delegation=False,  # Default: False\n    max_iter=20,  # Default: 20 iterations\n    max_rpm=None,  # Optional: Rate limit for API calls\n    max_execution_time=None,  # Optional: Maximum execution time in seconds\n    max_retry_limit=2,  # Default: 2 retries on error\n    allow_code_execution=False,  # Default: False\n    code_execution_mode=\"safe\",  # Default: \"safe\" (options: \"safe\", \"unsafe\")\n    respect_context_window=True,  # Default: True\n    use_system_prompt=True,  # Default: True\n    tools=[SerperDevTool()],  # Optional: List of tools\n    knowledge_sources=None,  # Optional: List of knowledge sources\n    embedder=None,  # Optional: Custom embedder configuration\n    system_template=None,  # Optional: Custom system prompt template\n    prompt_template=None,  # Optional: Custom prompt template\n    response_template=None,  # Optional: Custom response template\n    step_callback=None,  # Optional: Callback function for monitoring\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Multiple Asynchronous Crew Executions in Python\nDESCRIPTION: This example shows how to kickoff multiple crews asynchronously and wait for all of them to complete using asyncio.gather(). It creates two crews with different tasks and executes them concurrently.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/kickoff-async.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crewai import Crew, Agent, Task\n\n# Create an agent with code execution enabled\ncoding_agent = Agent(\n    role=\"Python Data Analyst\",\n    goal=\"Analyze data and provide insights using Python\",\n    backstory=\"You are an experienced data analyst with strong Python skills.\",\n    allow_code_execution=True\n)\n\n# Create tasks that require code execution\ntask_1 = Task(\n    description=\"Analyze the first dataset and calculate the average age of participants. Ages: {ages}\",\n    agent=coding_agent,\n    expected_output=\"The average age of the participants.\"\n)\n\ntask_2 = Task(\n    description=\"Analyze the second dataset and calculate the average age of participants. Ages: {ages}\",\n    agent=coding_agent,\n    expected_output=\"The average age of the participants.\"\n)\n\n# Create two crews and add tasks\ncrew_1 = Crew(agents=[coding_agent], tasks=[task_1])\ncrew_2 = Crew(agents=[coding_agent], tasks=[task_2])\n\n# Async function to kickoff multiple crews asynchronously and wait for all to finish\nasync def async_multiple_crews():\n    result_1 = crew_1.kickoff_async(inputs={\"ages\": [25, 30, 35, 40, 45]})\n    result_2 = crew_2.kickoff_async(inputs={\"ages\": [20, 22, 24, 28, 30]})\n\n    # Wait for both crews to finish\n    results = await asyncio.gather(result_1, result_2)\n\n    for i, result in enumerate(results, 1):\n        print(f\"Crew {i} Result:\", result)\n\n# Run the async function\nasyncio.run(async_multiple_crews())\n```\n\n----------------------------------------\n\nTITLE: Detailed Agent Integration Example\nDESCRIPTION: Comprehensive example showing how to integrate the YoutubeChannelSearchTool with a CrewAI agent for data science content analysis\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubechannelsearchtool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import YoutubeChannelSearchTool\n\n# Initialize the tool\nyoutube_channel_tool = YoutubeChannelSearchTool()\n\n# Define an agent that uses the tool\nchannel_researcher = Agent(\n    role=\"Channel Researcher\",\n    goal=\"Extract and analyze information from YouTube channels\",\n    backstory=\"\"\"You are an expert channel researcher who specializes in extracting \n    and analyzing information from YouTube channels. You have a keen eye for detail \n    and can quickly identify key points and insights from video content across an entire channel.\"\"\",\n    tools=[youtube_channel_tool],\n    verbose=True,\n)\n\n# Create a task for the agent\nresearch_task = Task(\n    description=\"\"\"\n    Search for information about data science projects and tutorials \n    in the YouTube channel {youtube_channel_handle}. \n    \n    Focus on:\n    1. Key data science techniques covered\n    2. Popular tutorial series\n    3. Most viewed or recommended videos\n    \n    Provide a comprehensive summary of these points.\n    \"\"\",\n    expected_output=\"A detailed summary of data science content available on the channel.\",\n    agent=channel_researcher,\n)\n\n# Run the task\ncrew = Crew(agents=[channel_researcher], tasks=[research_task])\nresult = crew.kickoff(inputs={\"youtube_channel_handle\": \"@exampleDataScienceChannel\"})\n```\n\n----------------------------------------\n\nTITLE: Creating a complete CrewAI workflow with Weave integration\nDESCRIPTION: A comprehensive example showing how to create agents, tasks, and a crew in CrewAI that will be automatically traced by Weave. Includes setting up the LLM, defining agents with specific roles, creating tasks, and executing the workflow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/weave-integration.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew, LLM, Process\n\n# Create an LLM with a temperature of 0 to ensure deterministic outputs\nllm = LLM(model=\"gpt-4o\", temperature=0)\n\n# Create agents\nresearcher = Agent(\n    role='Research Analyst',\n    goal='Find and analyze the best investment opportunities',\n    backstory='Expert in financial analysis and market research',\n    llm=llm,\n    verbose=True,\n    allow_delegation=False,\n)\n\nwriter = Agent(\n    role='Report Writer',\n    goal='Write clear and concise investment reports',\n    backstory='Experienced in creating detailed financial reports',\n    llm=llm,\n    verbose=True,\n    allow_delegation=False,\n)\n\n# Create tasks\nresearch_task = Task(\n    description='Deep research on the {topic}',\n    expected_output='Comprehensive market data including key players, market size, and growth trends.',\n    agent=researcher\n)\n\nwriting_task = Task(\n    description='Write a detailed report based on the research',\n    expected_output='The report should be easy to read and understand. Use bullet points where applicable.',\n    agent=writer\n)\n\n# Create a crew\ncrew = Crew(\n    agents=[researcher, writer],\n    tasks=[research_task, writing_task],\n    verbose=True,\n    process=Process.sequential,\n)\n\n# Run the crew\nresult = crew.kickoff(inputs={\"topic\": \"AI in material science\"})\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Optimizing CrewAI for Llama 3.3 Model\nDESCRIPTION: Advanced Python example showing how to customize CrewAI prompts for the Llama 3.3 model. This snippet defines custom templates for system, user, and assistant messages, and creates an agent using these Llama-specific layouts.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/advanced/customizing-prompts.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Task, Process\nfrom crewai_tools import DirectoryReadTool, FileReadTool\n\n# Define templates for system, user (prompt), and assistant (response) messages\nsystem_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{ .System }}<|eot_id|>\"\"\"\nprompt_template = \"\"\"<|start_header_id|>user<|end_header_id|>{{ .Prompt }}<|eot_id|>\"\"\"\nresponse_template = \"\"\"<|start_header_id|>assistant<|end_header_id|>{{ .Response }}<|eot_id|>\"\"\"\n\n# Create an Agent using Llama-specific layouts\nprincipal_engineer = Agent(\n    role=\"Principal Engineer\",\n    goal=\"Oversee AI architecture and make high-level decisions\",\n    backstory=\"You are the lead engineer responsible for critical AI systems\",\n    verbose=True,\n    llm=\"groq/llama-3.3-70b-versatile\",  # Using the Llama 3 model\n    system_template=system_template,\n    prompt_template=prompt_template,\n    response_template=response_template,\n    tools=[DirectoryReadTool(), FileReadTool()]\n)\n\n# Define a sample task\nengineering_task = Task(\n    description=\"Review AI implementation files for potential improvements\",\n    expected_output=\"A summary of key findings and recommendations\",\n    agent=principal_engineer\n)\n\n# Create a Crew for the task\nllama_crew = Crew(\n    agents=[principal_engineer],\n    tasks=[engineering_task],\n    process=Process.sequential,\n    verbose=True\n)\n\n# Execute the crew\nresult = llama_crew.kickoff()\nprint(result.raw)\n```\n\n----------------------------------------\n\nTITLE: Advanced CrewAI Task Execution Methods\nDESCRIPTION: Comprehensive example demonstrating all available kickoff methods including synchronous, asynchronous, and batch processing with different input types.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/crews.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Start the crew's task execution\nresult = my_crew.kickoff()\nprint(result)\n\n# Example of using kickoff_for_each\ninputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]\nresults = my_crew.kickoff_for_each(inputs=inputs_array)\nfor result in results:\n    print(result)\n\n# Example of using kickoff_async\ninputs = {'topic': 'AI in healthcare'}\nasync_result = my_crew.kickoff_async(inputs=inputs)\nprint(async_result)\n\n# Example of using kickoff_for_each_async\ninputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]\nasync_results = my_crew.kickoff_for_each_async(inputs=inputs_array)\nfor async_result in async_results:\n    print(async_result)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using MultiOnTool with CrewAI\nDESCRIPTION: Example showing how to initialize the MultiOnTool, create an agent with the tool, define a task, and run it with a crew. Demonstrates basic setup and execution of web browsing capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/multiontool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import MultiOnTool\n\n# Initialize the tool\nmultion_tool = MultiOnTool(api_key=\"YOUR_MULTION_API_KEY\", local=False)\n\n# Define an agent that uses the tool\nbrowser_agent = Agent(\n    role=\"Browser Agent\",\n    goal=\"Control web browsers using natural language\",\n    backstory=\"An expert browsing agent.\",\n    tools=[multion_tool],\n    verbose=True,\n)\n\n# Example task to search and summarize news\nbrowse_task = Task(\n    description=\"Summarize the top 3 trending AI News headlines\",\n    expected_output=\"A summary of the top 3 trending AI News headlines\",\n    agent=browser_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[browser_agent], tasks=[browse_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Creating CrewAI Agents and Tasks for Blog Post Generation\nDESCRIPTION: Implementation of a CrewAI application with two agents (researcher and writer) collaborating to research and write a blog post about AI advancements. Includes agent definitions, task creation, and crew setup.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/arize-phoenix-observability.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai_tools import SerperDevTool\n\nsearch_tool = SerperDevTool()\n\n# Define your agents with roles and goals\nresearcher = Agent(\n    role=\"Senior Research Analyst\",\n    goal=\"Uncover cutting-edge developments in AI and data science\",\n    backstory=\"\"\"You work at a leading tech think tank.\n    Your expertise lies in identifying emerging trends.\n    You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[search_tool],\n)\nwriter = Agent(\n    role=\"Tech Content Strategist\",\n    goal=\"Craft compelling content on tech advancements\",\n    backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\n    You transform complex concepts into compelling narratives.\"\"\",\n    verbose=True,\n    allow_delegation=True,\n)\n\n# Create tasks for your agents\ntask1 = Task(\n    description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n    Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n    expected_output=\"Full analysis report in bullet points\",\n    agent=researcher,\n)\n\ntask2 = Task(\n    description=\"\"\"Using the insights provided, develop an engaging blog\n    post that highlights the most significant AI advancements.\n    Your post should be informative yet accessible, catering to a tech-savvy audience.\n    Make it sound cool, avoid complex words so it doesn't sound like AI.\"\"\",\n    expected_output=\"Full blog post of at least 4 paragraphs\",\n    agent=writer,\n)\n\n# Instantiate your crew with a sequential process\ncrew = Crew(\n    agents=[researcher, writer], tasks=[task1, task2], verbose=1, process=Process.sequential\n)\n\n# Get your crew to work!\nresult = crew.kickoff()\n\nprint(\"######################\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Advanced Multimodal Agent Usage with Context in CrewAI\nDESCRIPTION: This snippet demonstrates advanced usage of a multimodal agent with specific context and analysis requirements. It creates a detailed task for visual quality inspection of a product image.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/multimodal-agents.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\n\n# Create a multimodal agent for detailed analysis\nexpert_analyst = Agent(\n    role=\"Visual Quality Inspector\",\n    goal=\"Perform detailed quality analysis of product images\",\n    backstory=\"Senior quality control expert with expertise in visual inspection\",\n    multimodal=True  # AddImageTool is automatically included\n)\n\n# Create a task with specific analysis requirements\ninspection_task = Task(\n    description=\"\"\"\n    Analyze the product image at https://example.com/product.jpg with focus on:\n    1. Quality of materials\n    2. Manufacturing defects\n    3. Compliance with standards\n    Provide a detailed report highlighting any issues found.\n    \"\"\",\n    expected_output=\"A detailed report highlighting any issues found\",\n    agent=expert_analyst\n)\n\n# Create and run the crew\ncrew = Crew(\n    agents=[expert_analyst],\n    tasks=[inspection_task]\n)\n\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Implementing 'and' Conditional Logic in CrewAI Flow (Python)\nDESCRIPTION: Shows how to use the and_ function in CrewAI Flows to listen to multiple methods and trigger a listener method only when all specified methods emit an output. This enables complex flow control based on multiple conditions being met.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, and_, listen, start\n\nclass AndExampleFlow(Flow):\n\n    @start()\n    def start_method(self):\n        self.state[\"greeting\"] = \"Hello from the start method\"\n\n    @listen(start_method)\n    def second_method(self):\n        self.state[\"joke\"] = \"What do computers eat? Microchips.\"\n\n    @listen(and_(start_method, second_method))\n    def logger(self):\n        print(\"---- Logger ----\")\n        print(self.state)\n\nflow = AndExampleFlow()\nflow.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Creating and Running CrewAI Agent\nDESCRIPTION: Example of creating and executing a CrewAI agent with Portkey integration. Demonstrates agent definition, task creation, and crew execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/portkey-observability.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\n\n# Define your agents with roles and goals\ncoder = Agent(\n    role='Software developer',\n    goal='Write clear, concise code on demand',\n    backstory='An expert coder with a keen eye for software trends.',\n    llm=gpt_llm\n)\n\n# Create tasks for your agents\ntask1 = Task(\n    description=\"Define the HTML for making a simple website with heading- Hello World! Portkey is working!\",\n    expected_output=\"A clear and concise HTML code\",\n    agent=coder\n)\n\n# Instantiate your crew\ncrew = Crew(\n    agents=[coder],\n    tasks=[task1],\n)\n\nresult = crew.kickoff()\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Implementing CrewAI Tools with Agents and Tasks\nDESCRIPTION: Comprehensive example showing how to set up and use CrewAI tools with agents and tasks, including API key configuration, tool instantiation, agent creation, task definition, and crew execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tools.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom crewai import Agent, Task, Crew\n# Importing crewAI tools\nfrom crewai_tools import (\n    DirectoryReadTool,\n    FileReadTool,\n    SerperDevTool,\n    WebsiteSearchTool\n)\n\n# Set up API keys\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\nos.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\n\n# Instantiate tools\ndocs_tool = DirectoryReadTool(directory='./blog-posts')\nfile_tool = FileReadTool()\nsearch_tool = SerperDevTool()\nweb_rag_tool = WebsiteSearchTool()\n\n# Create agents\nresearcher = Agent(\n    role='Market Research Analyst',\n    goal='Provide up-to-date market analysis of the AI industry',\n    backstory='An expert analyst with a keen eye for market trends.',\n    tools=[search_tool, web_rag_tool],\n    verbose=True\n)\n\nwriter = Agent(\n    role='Content Writer',\n    goal='Craft engaging blog posts about the AI industry',\n    backstory='A skilled writer with a passion for technology.',\n    tools=[docs_tool, file_tool],\n    verbose=True\n)\n\n# Define tasks\nresearch = Task(\n    description='Research the latest trends in the AI industry and provide a summary.',\n    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',\n    agent=researcher\n)\n\nwrite = Task(\n    description='Write an engaging blog post about the AI industry, based on the research analyst\\'s summary. Draw inspiration from the latest blog posts in the directory.',\n    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',\n    agent=writer,\n    output_file='blog-posts/new_post.md'  # The final blog post will be saved here\n)\n\n# Assemble a crew with planning enabled\ncrew = Crew(\n    agents=[researcher, writer],\n    tasks=[research, write],\n    verbose=True,\n    planning=True,  # Enable planning feature\n)\n\n# Execute tasks\ncrew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Implementing Structured LLM Responses with Pydantic in Python\nDESCRIPTION: This code example shows how to use a Pydantic model to define a structured response format for LLM calls in CrewAI. It demonstrates parsing and validating the LLM output into a structured Python object.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM\n\nclass Dog(BaseModel):\n    name: str\n    age: int\n    breed: str\n\n\nllm = LLM(model=\"gpt-4o\", response_format=Dog)\n\nresponse = llm.call(\n    \"Analyze the following messages and return the name, age, and breed. \"\n    \"Meet Kona! She is 3 years old and is a black german shepherd.\"\n)\nprint(response)\n\n# Output:\n# Dog(name='Kona', age=3, breed='black german shepherd')\n```\n\n----------------------------------------\n\nTITLE: Implementing 'or' Conditional Logic in CrewAI Flow (Python)\nDESCRIPTION: Demonstrates the use of the or_ function in CrewAI Flows to listen to multiple methods and trigger a listener method when any of the specified methods emit an output. This allows for flexible flow control based on multiple conditions.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, or_, start\n\nclass OrExampleFlow(Flow):\n\n    @start()\n    def start_method(self):\n        return \"Hello from the start method\"\n\n    @listen(start_method)\n    def second_method(self):\n        return \"Hello from the second method\"\n\n    @listen(or_(start_method, second_method))\n    def logger(self, result):\n        print(f\"Logger: {result}\")\n\n\n\nflow = OrExampleFlow()\nflow.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Implementing CrewAI Crew with Direct Code Definition\nDESCRIPTION: This snippet shows how to create a CrewAI crew using direct code definition without YAML files. It includes methods for defining agents, tasks, and the crew, providing more control but potentially less maintainable for larger projects.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/crews.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Task, Process\nfrom crewai_tools import YourCustomTool\n\nclass YourCrewName:\n    def agent_one(self) -> Agent:\n        return Agent(\n            role=\"Data Analyst\",\n            goal=\"Analyze data trends in the market\",\n            backstory=\"An experienced data analyst with a background in economics\",\n            verbose=True,\n            tools=[YourCustomTool()]\n        )\n\n    def agent_two(self) -> Agent:\n        return Agent(\n            role=\"Market Researcher\",\n            goal=\"Gather information on market dynamics\",\n            backstory=\"A diligent researcher with a keen eye for detail\",\n            verbose=True\n        )\n\n    def task_one(self) -> Task:\n        return Task(\n            description=\"Collect recent market data and identify trends.\",\n            expected_output=\"A report summarizing key trends in the market.\",\n            agent=self.agent_one()\n        )\n\n    def task_two(self) -> Task:\n        return Task(\n            description=\"Research factors affecting market dynamics.\",\n            expected_output=\"An analysis of factors influencing the market.\",\n            agent=self.agent_two()\n        )\n\n    def crew(self) -> Crew:\n        return Crew(\n            agents=[self.agent_one(), self.agent_two()],\n            tasks=[self.task_one(), self.task_two()],\n            process=Process.sequential,\n            verbose=True\n        )\n```\n\n----------------------------------------\n\nTITLE: Implementing Function Calling in Custom LLM\nDESCRIPTION: Implementation of a call method that handles function calling logic in a custom LLM. The method processes messages, makes API requests with JWT authentication, handles function calls, and manages response processing. Includes error handling for timeouts and invalid responses.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport json\nfrom typing import Any, Dict, List, Optional, Union\n\ndef call(\n    self,\n    messages: Union[str, List[Dict[str, str]]],\n    tools: Optional[List[dict]] = None,\n    callbacks: Optional[List[Any]] = None,\n    available_functions: Optional[Dict[str, Any]] = None,\n) -> Union[str, Any]:\n    import requests\n    \n    try:\n        headers = {\n            \"Authorization\": f\"Bearer {self.jwt_token}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # Convert string message to proper format if needed\n        if isinstance(messages, str):\n            messages = [{\"role\": \"user\", \"content\": messages}]\n        \n        data = {\n            \"messages\": messages,\n            \"tools\": tools\n        }\n        \n        response = requests.post(\n            self.endpoint,\n            headers=headers,\n            json=data,\n            timeout=30\n        )\n        response.raise_for_status()\n        response_data = response.json()\n        \n        # Check if the LLM wants to call a function\n        if response_data[\"choices\"][0][\"message\"].get(\"tool_calls\"):\n            tool_calls = response_data[\"choices\"][0][\"message\"][\"tool_calls\"]\n            \n            # Process each tool call\n            for tool_call in tool_calls:\n                function_name = tool_call[\"function\"][\"name\"]\n                function_args = json.loads(tool_call[\"function\"][\"arguments\"])\n                \n                if available_functions and function_name in available_functions:\n                    function_to_call = available_functions[function_name]\n                    function_response = function_to_call(**function_args)\n                    \n                    # Add the function response to the messages\n                    messages.append({\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call[\"id\"],\n                        \"name\": function_name,\n                        \"content\": str(function_response)\n                    })\n            \n            # Call the LLM again with the updated messages\n            return self.call(messages, tools, callbacks, available_functions)\n        \n        # Return the text response if no function call\n        return response_data[\"choices\"][0][\"message\"][\"content\"]\n    except requests.Timeout:\n        raise TimeoutError(\"LLM request timed out\")\n    except requests.RequestException as e:\n        raise RuntimeError(f\"LLM request failed: {str(e)}\")\n    except (KeyError, IndexError, ValueError) as e:\n        raise ValueError(f\"Invalid response format: {str(e)}\")\n```\n\n----------------------------------------\n\nTITLE: Structured Output Using Pydantic Models\nDESCRIPTION: Demonstrates how to use Pydantic models to enforce structured output from tasks and access the results in multiple ways. Includes blog content generation example with type validation.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nfrom crewai import Agent, Crew, Process, Task\nfrom pydantic import BaseModel\n\n\nclass Blog(BaseModel):\n    title: str\n    content: str\n\n\nblog_agent = Agent(\n    role=\"Blog Content Generator Agent\",\n    goal=\"Generate a blog title and content\",\n    backstory=\"\"\"You are an expert content creator, skilled in crafting engaging and informative blog posts.\"\"\",\n    verbose=False,\n    allow_delegation=False,\n    llm=\"gpt-4o\",\n)\n\ntask1 = Task(\n    description=\"\"\"Create a blog title and content on a given topic. Make sure the content is under 200 words.\"\"\",\n    expected_output=\"A compelling blog title and well-written content.\",\n    agent=blog_agent,\n    output_pydantic=Blog,\n)\n\n# Instantiate your crew with a sequential process\ncrew = Crew(\n    agents=[blog_agent],\n    tasks=[task1],\n    verbose=True,\n    process=Process.sequential,\n)\n\nresult = crew.kickoff()\n\n# Option 1: Accessing Properties Using Dictionary-Style Indexing\nprint(\"Accessing Properties - Option 1\")\ntitle = result[\"title\"]\ncontent = result[\"content\"]\nprint(\"Title:\", title)\nprint(\"Content:\", content)\n\n# Option 2: Accessing Properties Directly from the Pydantic Model\nprint(\"Accessing Properties - Option 2\")\ntitle = result.pydantic.title\ncontent = result.pydantic.content\nprint(\"Title:\", title)\nprint(\"Content:\", content)\n\n# Option 3: Accessing Properties Using the to_dict() Method\nprint(\"Accessing Properties - Option 3\")\noutput_dict = result.to_dict()\ntitle = output_dict[\"title\"]\ncontent = output_dict[\"content\"]\nprint(\"Title:\", title)\nprint(\"Content:\", content)\n\n# Option 4: Printing the Entire Blog Object\nprint(\"Accessing Properties - Option 5\")\nprint(\"Blog:\", result)\n```\n\n----------------------------------------\n\nTITLE: Defining Agent Configurations using YAML\nDESCRIPTION: Creates a YAML configuration file to define agent settings including role, goal, backstory, and the LLM to use. This method is ideal for version control and team collaboration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nresearcher:\n    role: Research Specialist\n    goal: Conduct comprehensive research and analysis\n    backstory: A dedicated research professional with years of experience\n    verbose: true\n    llm: openai/gpt-4o-mini # your model here\n    # (see provider configuration examples below for more)\n```\n\n----------------------------------------\n\nTITLE: Implementing JSON Output with Pydantic Models in CrewAI\nDESCRIPTION: Demonstrates how to use output_json property with Pydantic models to structure task outputs. Shows blog content generation with defined JSON schema and multiple ways to access the output.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nfrom crewai import Agent, Crew, Process, Task\nfrom pydantic import BaseModel\n\n\n# Define the Pydantic model for the blog\nclass Blog(BaseModel):\n    title: str\n    content: str\n\n\n# Define the agent\nblog_agent = Agent(\n    role=\"Blog Content Generator Agent\",\n    goal=\"Generate a blog title and content\",\n    backstory=\"\"\"You are an expert content creator, skilled in crafting engaging and informative blog posts.\"\"\",\n    verbose=False,\n    allow_delegation=False,\n    llm=\"gpt-4o\",\n)\n\n# Define the task with output_json set to the Blog model\ntask1 = Task(\n    description=\"\"\"Create a blog title and content on a given topic. Make sure the content is under 200 words.\"\"\",\n    expected_output=\"A JSON object with 'title' and 'content' fields.\",\n    agent=blog_agent,\n    output_json=Blog,\n)\n\n# Instantiate the crew with a sequential process\ncrew = Crew(\n    agents=[blog_agent],\n    tasks=[task1],\n    verbose=True,\n    process=Process.sequential,\n)\n\n# Kickoff the crew to execute the task\nresult = crew.kickoff()\n\n# Option 1: Accessing Properties Using Dictionary-Style Indexing\nprint(\"Accessing Properties - Option 1\")\ntitle = result[\"title\"]\ncontent = result[\"content\"]\nprint(\"Title:\", title)\nprint(\"Content:\", content)\n\n# Option 2: Printing the Entire Blog Object\nprint(\"Accessing Properties - Option 2\")\nprint(\"Blog:\", result)\n```\n\n----------------------------------------\n\nTITLE: CrewAI Agent Integration with RagTool\nDESCRIPTION: Demonstrates complete integration of RagTool with a CrewAI agent, including initialization and content addition from multiple sources.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/ragtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\nfrom crewai.project import agent\nfrom crewai_tools import RagTool\n\n# Initialize the tool and add content\nrag_tool = RagTool()\nrag_tool.add(data_type=\"web_page\", url=\"https://docs.crewai.com\")\nrag_tool.add(data_type=\"file\", path=\"company_data.pdf\")\n\n# Define an agent with the RagTool\n@agent\ndef knowledge_expert(self) -> Agent:\n    return Agent(\n        config=self.agents_config[\"knowledge_expert\"],\n        allow_delegation=False,\n        tools=[rag_tool]\n    )\n```\n\n----------------------------------------\n\nTITLE: Basic Crew Memory Configuration in Python\nDESCRIPTION: Demonstrates how to configure basic memory capabilities for a CrewAI crew instance with default settings. Enables memory system with default OpenAI embeddings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\n# Assemble your crew with memory capabilities\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Python Agent with Code Execution Capabilities in CrewAI\nDESCRIPTION: This snippet demonstrates how to create a CrewAI agent with code execution enabled by setting the 'allow_code_execution' parameter to True. The agent is configured as a Senior Python Developer with specific goals and backstory.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/coding-agents.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\n\ncoding_agent = Agent(\n    role=\"Senior Python Developer\",\n    goal=\"Craft well-designed and thought-out code\",\n    backstory=\"You are a senior Python developer with extensive experience in software architecture and best practices.\",\n    allow_code_execution=True\n)\n```\n\n----------------------------------------\n\nTITLE: Event-Driven Flow Structure in CrewAI\nDESCRIPTION: Demonstrates the event-driven architecture used in CrewAI flows. It shows how decorators are used to establish relationships between components, creating a clear and declarative structure for the application.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@start()\ndef get_user_input(self):\n    # First step in the flow\n    # ...\n\n@listen(get_user_input)\ndef create_guide_outline(self, state):\n    # This runs when get_user_input completes\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Complex Validation Chain Implementation\nDESCRIPTION: Implements a multi-step validation chain for task outputs with sequential validation steps and comprehensive error handling. Shows how to chain multiple validation checks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any, Dict, List, Tuple, Union\nfrom crewai import TaskOutput\n\ndef complex_validation(result: TaskOutput) -> Tuple[bool, Any]:\n    \"\"\"Chain multiple validation steps.\"\"\"\n    # Step 1: Basic validation\n    if not result:\n        return (False, \"Empty result\")\n\n    # Step 2: Content validation\n    try:\n        validated = validate_content(result)\n        if not validated:\n            return (False, \"Invalid content\")\n\n        # Step 3: Format validation\n        formatted = format_output(validated)\n        return (True, formatted)\n    except Exception as e:\n        return (False, str(e))\n```\n\n----------------------------------------\n\nTITLE: Implementing Sequential Process in CrewAI with Python\nDESCRIPTION: This code snippet demonstrates how to set up a sequential process in CrewAI. It includes defining agents, creating tasks, forming a crew with a sequential process, and executing the crew. The example also shows how to access type-safe output from the execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/sequential-process.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Process, Agent, Task, TaskOutput, CrewOutput\n\n# Define your agents\nresearcher = Agent(\n  role='Researcher',\n  goal='Conduct foundational research',\n  backstory='An experienced researcher with a passion for uncovering insights'\n)\nanalyst = Agent(\n  role='Data Analyst',\n  goal='Analyze research findings',\n  backstory='A meticulous analyst with a knack for uncovering patterns'\n)\nwriter = Agent(\n  role='Writer',\n  goal='Draft the final report',\n  backstory='A skilled writer with a talent for crafting compelling narratives'\n)\n\n# Define your tasks\nresearch_task = Task(\n  description='Gather relevant data...', \n  agent=researcher, \n  expected_output='Raw Data'\n)\nanalysis_task = Task(\n  description='Analyze the data...', \n  agent=analyst, \n  expected_output='Data Insights'\n)\nwriting_task = Task(\n  description='Compose the report...', \n  agent=writer, \n  expected_output='Final Report'\n)\n\n# Form the crew with a sequential process\nreport_crew = Crew(\n  agents=[researcher, analyst, writer],\n  tasks=[research_task, analysis_task, writing_task],\n  process=Process.sequential\n)\n\n# Execute the crew\nresult = report_crew.kickoff()\n\n# Accessing the type-safe output\ntask_output: TaskOutput = result.tasks[0].output\ncrew_output: CrewOutput = result.output\n```\n\n----------------------------------------\n\nTITLE: Creating Effective Agent Goals in CrewAI\nDESCRIPTION: Examples of well-defined goals for AI agents that are clear, outcome-focused, and include quality standards. These goals help direct the agent's efforts and shape their decision-making process.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ngoal: \"Uncover actionable user insights by analyzing interview data and identifying recurring patterns, unmet needs, and improvement opportunities\"\ngoal: \"Design robust, scalable system architectures that balance performance, maintainability, and cost-effectiveness\"\ngoal: \"Craft clear, empathetic crisis communications that address stakeholder concerns while protecting organizational reputation\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Structured Tool with API Wrapper in Python\nDESCRIPTION: Shows how to create a structured tool that wraps an API call using CrewStructuredTool. This approach provides a structured interface for complex functionalities, enabling robust validation and consistent execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tools.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.tools.structured_tool import CrewStructuredTool\nfrom pydantic import BaseModel\n\n# Define the schema for the tool's input using Pydantic\nclass APICallInput(BaseModel):\n    endpoint: str\n    parameters: dict\n\n# Wrapper function to execute the API call\ndef tool_wrapper(*args, **kwargs):\n    # Here, you would typically call the API using the parameters\n    # For demonstration, we'll return a placeholder string\n    return f\"Call the API at {kwargs['endpoint']} with parameters {kwargs['parameters']}\"\n\n# Create and return the structured tool\ndef create_structured_tool():\n    return CrewStructuredTool.from_function(\n        name='Wrapper API',\n        description=\"A tool to wrap API calls with structured input.\",\n        args_schema=APICallInput,\n        func=tool_wrapper,\n    )\n\n# Example usage\nstructured_tool = create_structured_tool()\n\n# Execute the tool with structured input\nresult = structured_tool._run(**{\n    \"endpoint\": \"https://example.com/api\",\n    \"parameters\": {\"key1\": \"value1\", \"key2\": \"value2\"}\n})\nprint(result)  # Output: Call the API at https://example.com/api with parameters {'key1': 'value1', 'key2': 'value2'}\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using AIMindTool\nDESCRIPTION: Example showing how to initialize the AIMindTool with PostgreSQL connection parameters and execute a natural language query against house sales data.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/aimindtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import AIMindTool\n\n# Initialize the AIMindTool\naimind_tool = AIMindTool(\n    datasources=[\n        {\n            \"description\": \"house sales data\",\n            \"engine\": \"postgres\",\n            \"connection_data\": {\n                \"user\": \"demo_user\",\n                \"password\": \"demo_password\",\n                \"host\": \"samples.mindsdb.com\",\n                \"port\": 5432,\n                \"database\": \"demo\",\n                \"schema\": \"demo_data\"\n            },\n            \"tables\": [\"house_sales\"]\n        }\n    ]\n)\n\n# Run a natural language query\nresult = aimind_tool.run(\"How many 3 bedroom houses were sold in 2008?\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Basic Task Guardrail Implementation\nDESCRIPTION: Demonstrates implementation of a basic validation guardrail for blog content including word count check and error handling. Shows how to create and apply guardrail function to tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Tuple, Union, Dict, Any\nfrom crewai import TaskOutput\n\ndef validate_blog_content(result: TaskOutput) -> Tuple[bool, Any]:\n    \"\"\"Validate blog content meets requirements.\"\"\"\n    try:\n        # Check word count\n        word_count = len(result.split())\n        if word_count > 200:\n            return (False, \"Blog content exceeds 200 words\")\n\n        # Additional validation logic here\n        return (True, result.strip())\n    except Exception as e:\n        return (False, \"Unexpected error during validation\")\n\nblog_task = Task(\n    description=\"Write a blog post about AI\",\n    expected_output=\"A blog post under 200 words\",\n    agent=blog_agent,\n    guardrail=validate_blog_content  # Add the guardrail function\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Task for Space News Analysis in Python\nDESCRIPTION: This code creates a task for the Space News Analyst agent to answer a user's question based on recent space news. It demonstrates how to integrate user input with the agent's knowledge source.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntask = Task(\n    description=f\"Answer the following question based on recent space news: {user_question}\",\n    agent=space_news_analyst\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Task Outputs in CrewAI\nDESCRIPTION: Demonstrates how to create and execute a task, then access various output formats including raw, JSON, and Pydantic outputs. Shows basic task setup with research agent and output retrieval methods.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Example task\ntask = Task(\n    description='Find and summarize the latest AI news',\n    expected_output='A bullet list summary of the top 5 most important AI news',\n    agent=research_agent,\n    tools=[search_tool]\n)\n\n# Execute the crew\ncrew = Crew(\n    agents=[research_agent],\n    tasks=[task],\n    verbose=True\n)\n\nresult = crew.kickoff()\n\n# Accessing the task output\ntask_output = task.output\n\nprint(f\"Task Description: {task_output.description}\")\nprint(f\"Task Summary: {task_output.summary}\")\nprint(f\"Raw Output: {task_output.raw}\")\nif task_output.json_dict:\n    print(f\"JSON Output: {json.dumps(task_output.json_dict, indent=2)}\")\nif task_output.pydantic:\n    print(f\"Pydantic Output: {task_output.pydantic}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing LlamaIndexTool from LlamaIndex FunctionTool\nDESCRIPTION: Example of creating a LlamaIndexTool from a LlamaIndex FunctionTool and using it with a CrewAI Agent. Demonstrates tool creation, wrapping, and agent definition.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/llamaindextool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import LlamaIndexTool\nfrom crewai import Agent\nfrom llama_index.core.tools import FunctionTool\n\n# Example 1: Initialize from FunctionTool\ndef search_data(query: str) -> str:\n    \"\"\"Search for information in the data.\"\"\"\n    # Your implementation here\n    return f\"Results for: {query}\"\n\n# Create a LlamaIndex FunctionTool\nog_tool = FunctionTool.from_defaults(\n    search_data, \n    name=\"DataSearchTool\",\n    description=\"Search for information in the data\"\n)\n\n# Wrap it with LlamaIndexTool\ntool = LlamaIndexTool.from_tool(og_tool)\n\n# Define an agent that uses the tool\n@agent\ndef researcher(self) -> Agent:\n    '''\n    This agent uses the LlamaIndexTool to search for information.\n    '''\n    return Agent(\n        config=self.agents_config[\"researcher\"],\n        tools=[tool]\n    )\n```\n\n----------------------------------------\n\nTITLE: Managing State in CrewAI Flows\nDESCRIPTION: Demonstrates structured state management in CrewAI Flows using Pydantic models, showing how to update and access state across different flow methods.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\nfrom pydantic import BaseModel\n\nclass ExampleState(BaseModel):\n    counter: int = 0\n    message: str = \"\"\n\nclass StateExampleFlow(Flow[ExampleState]):\n\n    @start()\n    def first_method(self):\n        self.state.message = \"Hello from first_method\"\n        self.state.counter += 1\n\n    @listen(first_method)\n    def second_method(self):\n        self.state.message += \" - updated by second_method\"\n        self.state.counter += 1\n        return self.state.message\n\nflow = StateExampleFlow()\nfinal_output = flow.kickoff()\nprint(f\"Final Output: {final_output}\")\nprint(\"Final State:\")\nprint(flow.state)\n```\n\n----------------------------------------\n\nTITLE: Optimizing LLM Performance in Python\nDESCRIPTION: This code snippet shows how to optimize LLM performance in CrewAI by configuring appropriate settings such as model selection, temperature, maximum tokens, and timeout based on the task requirements.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_42\n\nLANGUAGE: python\nCODE:\n```\n# Configure model with appropriate settings\nllm = LLM(\n    model=\"openai/gpt-4-turbo-preview\",\n    temperature=0.7,    # Adjust based on task\n    max_tokens=4096,    # Set based on output needs\n    timeout=300        # Longer timeout for complex tasks\n)\n```\n\n----------------------------------------\n\nTITLE: Breaking Down Complex Tasks in CrewAI\nDESCRIPTION: Illustrates how to break down a complex 'God Task' into multiple focused tasks with clear dependencies using YAML in CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n# Task 1: Research\nmarket_research_task:\n  description: \"Research current market trends in the SaaS project management space.\"\n  expected_output: \"A markdown summary of key market trends.\"\n\n# Task 2: Competitive Analysis\ncompetitor_analysis_task:\n  description: \"Analyze strategies of the top 3 competitors based on the market research.\"\n  expected_output: \"A comparison table of competitor strategies.\"\n  context: [market_research_task]\n\n# Continue with additional focused tasks...\n```\n\n----------------------------------------\n\nTITLE: Configuring CrewAI Agent with Search Tool\nDESCRIPTION: Example showing how to initialize a CrewAI agent with a search tool and advanced configuration options. Demonstrates setting API keys, configuring tools, and specifying agent attributes like role, goal, and performance parameters.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/customizing-agents.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom crewai import Agent\nfrom crewai_tools import SerperDevTool\n\n# Set API keys for tool initialization\nos.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\"\n\n# Initialize a search tool\nsearch_tool = SerperDevTool()\n\n# Initialize the agent with advanced options\nagent = Agent(\n  role='Research Analyst',\n  goal='Provide up-to-date market analysis',\n  backstory='An expert analyst with a keen eye for market trends.',\n  tools=[search_tool],\n  memory=True, # Enable memory\n  verbose=True,\n  max_rpm=None, # No limit on requests per minute\n  max_iter=25, # Default value for maximum iterations\n)\n```\n\n----------------------------------------\n\nTITLE: Training CrewAI Agents Programmatically in Python\nDESCRIPTION: Implement training logic for CrewAI agents directly in Python code. This snippet demonstrates setting up training parameters, handling errors, and executing the training process with specific iterations and inputs.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/training.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nn_iterations = 2\ninputs = {\"topic\": \"CrewAI Training\"}\nfilename = \"your_model.pkl\"\n\ntry:\n    YourCrewName_Crew().crew().train(\n      n_iterations=n_iterations, \n      inputs=inputs, \n      filename=filename\n    )\n\nexcept Exception as e:\n    raise Exception(f\"An error occurred while training the crew: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Data Passing Between Flow Steps in Python\nDESCRIPTION: Demonstrates how to pass data between flow steps using the @start and @listen decorators, combining direct data passing with state updates.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\n\nclass DataPassingFlow(Flow):\n    @start()\n    def generate_data(self):\n        # This return value will be passed to listening methods\n        return \"Generated data\"\n\n    @listen(generate_data)\n    def process_data(self, data_from_previous_step):\n        print(f\"Received: {data_from_previous_step}\")\n        # You can modify the data and pass it along\n        processed_data = f\"{data_from_previous_step} - processed\"\n        # Also update state\n        self.state[\"last_processed\"] = processed_data\n        return processed_data\n\n    @listen(process_data)\n    def finalize_data(self, processed_data):\n        print(f\"Received processed data: {processed_data}\")\n        # Access both the passed data and state\n        last_processed = self.state.get(\"last_processed\", \"\")\n        return f\"Final: {processed_data} (from state: {last_processed})\"\n```\n\n----------------------------------------\n\nTITLE: Implementing VisionTool with CrewAI Agent\nDESCRIPTION: Example showing how to integrate the VisionTool into a CrewAI agent. Requires OPENAI_API_KEY environment variable to be set. The tool is added to the agent's toolset for image text extraction capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/visiontool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import VisionTool\n\nvision_tool = VisionTool()\n\n@agent\ndef researcher(self) -> Agent:\n    '''\n    This agent uses the VisionTool to extract text from images.\n    '''\n    return Agent(\n        config=self.agents_config[\"researcher\"],\n        allow_delegation=False,\n        tools=[vision_tool]\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing BedrockKBRetrieverTool with CrewAI\nDESCRIPTION: Example showing how to initialize and use BedrockKBRetrieverTool with a CrewAI agent, including setting up the tool, creating an agent, defining tasks, and running the crew\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bedrockkbretriever.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools.aws.bedrock.knowledge_base.retriever_tool import BedrockKBRetrieverTool\n\n# Initialize the tool\nkb_tool = BedrockKBRetrieverTool(\n    knowledge_base_id=\"your-kb-id\",\n    number_of_results=5\n)\n\n# Create a CrewAI agent that uses the tool\nresearcher = Agent(\n    role='Knowledge Base Researcher',\n    goal='Find information about company policies',\n    backstory='I am a researcher specialized in retrieving and analyzing company documentation.',\n    tools=[kb_tool],\n    verbose=True\n)\n\n# Create a task for the agent\nresearch_task = Task(\n    description=\"Find our company's remote work policy and summarize the key points.\",\n    agent=researcher\n)\n\n# Create a crew with the agent\ncrew = Crew(\n    agents=[researcher],\n    tasks=[research_task],\n    verbose=2\n)\n\n# Run the crew\nresult = crew.kickoff()\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Task Context and Dependencies Configuration in CrewAI\nDESCRIPTION: Demonstrates how to configure task dependencies and context relationships between multiple tasks. Shows both synchronous and asynchronous task execution patterns.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nresearch_ai_task = Task(\n    description=\"Research the latest developments in AI\",\n    expected_output=\"A list of recent AI developments\",\n    async_execution=True,\n    agent=research_agent,\n    tools=[search_tool]\n)\n\nresearch_ops_task = Task(\n    description=\"Research the latest developments in AI Ops\",\n    expected_output=\"A list of recent AI Ops developments\",\n    async_execution=True,\n    agent=research_agent,\n    tools=[search_tool]\n)\n\nwrite_blog_task = Task(\n    description=\"Write a full blog post about the importance of AI and its latest news\",\n    expected_output=\"Full blog post that is 4 paragraphs long\",\n    agent=writer_agent,\n    context=[research_ai_task, research_ops_task]\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Storage for External Memory in CrewAI\nDESCRIPTION: This snippet demonstrates how to create and use custom storage for external memory in CrewAI. It includes defining a CustomStorage class and integrating it with the Crew setup.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai.memory.external.external_memory import ExternalMemory\nfrom crewai.memory.storage.interface import Storage\n\n\nclass CustomStorage(Storage):\n    def __init__(self):\n        self.memories = []\n\n    def save(self, value, metadata=None, agent=None):\n        self.memories.append({\"value\": value, \"metadata\": metadata, \"agent\": agent})\n\n    def search(self, query, limit=10, score_threshold=0.5):\n        # Implement your search logic here\n        return []\n\n    def reset(self):\n        self.memories = []\n\n\n# Create external memory with custom storage\nexternal_memory = ExternalMemory(\n    storage=CustomStorage(),\n    embedder_config={\"provider\": \"mem0\", \"config\": {\"user_id\": \"U-123\"}},\n)\n\nagent = Agent(\n    role=\"You are a helpful assistant\",\n    goal=\"Plan a vacation for the user\",\n    backstory=\"You are a helpful assistant that can plan a vacation for the user\",\n    verbose=True,\n)\ntask = Task(\n    description=\"Give things related to the user's vacation\",\n    expected_output=\"A plan for the vacation\",\n    agent=agent,\n)\n\ncrew = Crew(\n    agents=[agent],\n    tasks=[task],\n    verbose=True,\n    process=Process.sequential,\n    external_memory=external_memory,\n)\n\ncrew.kickoff(\n    inputs={\"question\": \"which destination is better for a beach vacation?\"}\n)\n```\n\n----------------------------------------\n\nTITLE: Using @tool Decorator for Simplified Tool Creation in Python\nDESCRIPTION: Shows how to use the @tool decorator to create a custom tool with a single function. This method offers a more concise way to define tools with basic functionality.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/create-custom-tools.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.tools import tool\n\n@tool(\"Tool Name\")\ndef my_simple_tool(question: str) -> str:\n    \"\"\"Tool description for clarity.\"\"\"\n    # Tool logic here\n    return \"Tool output\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Research Crew Runner in Python\nDESCRIPTION: Main script to set up and execute the research crew. Creates output directory, defines research topic, and runs the crew with specified inputs. Results are printed and saved to a markdown file.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/crews/first-crew.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create output directory if it doesn't exist\nos.makedirs('output', exist_ok=True)\n\ndef run():\n    \"\"\"\n    Run the research crew.\n    \"\"\"\n    inputs = {\n        'topic': 'Artificial Intelligence in Healthcare'\n    }\n\n    # Create and run the crew\n    result = ResearchCrew().crew().kickoff(inputs=inputs)\n\n    # Print the result\n    print(\"\\n\\n=== FINAL REPORT ===\\n\\n\")\n    print(result.raw)\n\n    print(\"\\n\\nReport has been saved to output/report.md\")\n\nif __name__ == \"__main__\":\n    run()\n```\n\n----------------------------------------\n\nTITLE: Implementing AgentOps Event Listener in Python\nDESCRIPTION: Implementation of an event listener that integrates CrewAI with AgentOps platform for monitoring and observability. The listener handles crew kickoff, tool usage, and error events while managing AgentOps sessions.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\n\nfrom crewai.utilities.events import (\n    CrewKickoffCompletedEvent,\n    ToolUsageErrorEvent,\n    ToolUsageStartedEvent,\n)\nfrom crewai.utilities.events.base_event_listener import BaseEventListener\nfrom crewai.utilities.events.crew_events import CrewKickoffStartedEvent\nfrom crewai.utilities.events.task_events import TaskEvaluationEvent\n\ntry:\n    import agentops\n    AGENTOPS_INSTALLED = True\nexcept ImportError:\n    AGENTOPS_INSTALLED = False\n\nclass AgentOpsListener(BaseEventListener):\n    tool_event: Optional[\"agentops.ToolEvent\"] = None\n    session: Optional[\"agentops.Session\"] = None\n\n    def __init__(self):\n        super().__init__()\n\n    def setup_listeners(self, crewai_event_bus):\n        if not AGENTOPS_INSTALLED:\n            return\n\n        @crewai_event_bus.on(CrewKickoffStartedEvent)\n        def on_crew_kickoff_started(source, event: CrewKickoffStartedEvent):\n            self.session = agentops.init()\n            for agent in source.agents:\n                if self.session:\n                    self.session.create_agent(\n                        name=agent.role,\n                        agent_id=str(agent.id),\n                    )\n\n        @crewai_event_bus.on(CrewKickoffCompletedEvent)\n        def on_crew_kickoff_completed(source, event: CrewKickoffCompletedEvent):\n            if self.session:\n                self.session.end_session(\n                    end_state=\"Success\",\n                    end_state_reason=\"Finished Execution\",\n                )\n\n        @crewai_event_bus.on(ToolUsageStartedEvent)\n        def on_tool_usage_started(source, event: ToolUsageStartedEvent):\n            self.tool_event = agentops.ToolEvent(name=event.tool_name)\n            if self.session:\n                self.session.record(self.tool_event)\n\n        @crewai_event_bus.on(ToolUsageErrorEvent)\n        def on_tool_usage_error(source, event: ToolUsageErrorEvent):\n            agentops.ErrorEvent(exception=event.error, trigger_event=self.tool_event)\n```\n\n----------------------------------------\n\nTITLE: Specifying Structured Output in CrewAI Tasks\nDESCRIPTION: Demonstrates how to define a task with a structured output format (JSON) for machine-readable results in CrewAI using YAML.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\ndata_extraction_task:\n  description: \"Extract key metrics from the quarterly report.\"\n  expected_output: \"JSON object with the following keys: revenue, growth_rate, customer_acquisition_cost, and retention_rate.\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom SpaceNewsKnowledgeSource in Python\nDESCRIPTION: This code snippet defines a custom SpaceNewsKnowledgeSource class that extends BaseKnowledgeSource. It fetches space news articles from an API, formats them, and makes them available for CrewAI agents to use.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass SpaceNewsKnowledgeSource(BaseKnowledgeSource):\n    def __init__(self, api_endpoint, limit=10):\n        self.api_endpoint = api_endpoint\n        self.limit = limit\n        self.content = \"\"\n\n    def load_content(self):\n        response = requests.get(f\"{self.api_endpoint}?limit={self.limit}\")\n        articles = response.json()\n        return self._format_articles(articles)\n\n    def _format_articles(self, articles):\n        formatted_content = \"\"\n        for article in articles:\n            formatted_content += f\"Title: {article['title']}\\n\"\n            formatted_content += f\"Summary: {article['summary']}\\n\"\n            formatted_content += f\"Published: {article['published_at']}\\n\"\n            formatted_content += f\"URL: {article['url']}\\n\\n\"\n        return formatted_content\n\n    def add(self):\n        self.content = self.load_content()\n        return self.content\n```\n\n----------------------------------------\n\nTITLE: Integrating Agents for Market Research Flow\nDESCRIPTION: Implements a market research flow using CrewAI agents. Includes structured data models, async execution, and formatted output handling for market analysis.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom typing import Any, Dict, List\n\nfrom crewai_tools import SerperDevTool\nfrom pydantic import BaseModel, Field\n\nfrom crewai.agent import Agent\nfrom crewai.flow.flow import Flow, listen, start\n\n\n# Define a structured output format\nclass MarketAnalysis(BaseModel):\n    key_trends: List[str] = Field(description=\"List of identified market trends\")\n    market_size: str = Field(description=\"Estimated market size\")\n    competitors: List[str] = Field(description=\"Major competitors in the space\")\n\n\n# Define flow state\nclass MarketResearchState(BaseModel):\n    product: str = \"\"\n    analysis: MarketAnalysis | None = None\n\n\n# Create a flow class\nclass MarketResearchFlow(Flow[MarketResearchState]):\n    @start()\n    def initialize_research(self) -> Dict[str, Any]:\n        print(f\"Starting market research for {self.state.product}\")\n        return {\"product\": self.state.product}\n\n    @listen(initialize_research)\n    async def analyze_market(self) -> Dict[str, Any]:\n        # Create an Agent for market research\n        analyst = Agent(\n            role=\"Market Research Analyst\",\n            goal=f\"Analyze the market for {self.state.product}\",\n            backstory=\"You are an experienced market analyst with expertise in \"\n            \"identifying market trends and opportunities.\",\n            tools=[SerperDevTool()],\n            verbose=True,\n        )\n\n        # Define the research query\n        query = f\"\"\"\n        Research the market for {self.state.product}. Include:\n        1. Key market trends\n        2. Market size\n        3. Major competitors\n\n        Format your response according to the specified structure.\n        \"\"\"\n\n        # Execute the analysis with structured output format\n        result = await analyst.kickoff_async(query, response_format=MarketAnalysis)\n        if result.pydantic:\n            print(\"result\", result.pydantic)\n        else:\n            print(\"result\", result)\n\n        # Return the analysis to update the state\n        return {\"analysis\": result.pydantic}\n\n    @listen(analyze_market)\n    def present_results(self, analysis) -> None:\n        print(\"\\nMarket Analysis Results\")\n        print(\"=====================\")\n\n        if isinstance(analysis, dict):\n            # If we got a dict with 'analysis' key, extract the actual analysis object\n            market_analysis = analysis.get(\"analysis\")\n        else:\n            market_analysis = analysis\n\n        if market_analysis and isinstance(market_analysis, MarketAnalysis):\n            print(\"\\nKey Market Trends:\")\n            for trend in market_analysis.key_trends:\n                print(f\"- {trend}\")\n\n            print(f\"\\nMarket Size: {market_analysis.market_size}\")\n\n            print(\"\\nMajor Competitors:\")\n            for competitor in market_analysis.competitors:\n                print(f\"- {competitor}\")\n        else:\n            print(\"No structured analysis data available.\")\n            print(\"Raw analysis:\", analysis)\n\n\n# Usage example\nasync def run_flow():\n    flow = MarketResearchFlow()\n    result = await flow.kickoff_async(inputs={\"product\": \"AI-powered chatbots\"})\n    return result\n\n\n# Run the flow\nif __name__ == \"__main__\":\n    asyncio.run(run_flow())\n```\n\n----------------------------------------\n\nTITLE: Implementing Multi-Crew Flow Control\nDESCRIPTION: Example of main flow implementation connecting multiple crews together with state management and execution control.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n#!/usr/bin/env python\nfrom random import randint\n\nfrom pydantic import BaseModel\nfrom crewai.flow.flow import Flow, listen, start\nfrom .crews.poem_crew.poem_crew import PoemCrew\n\nclass PoemState(BaseModel):\n    sentence_count: int = 1\n    poem: str = \"\"\n\nclass PoemFlow(Flow[PoemState]):\n\n    @start()\n    def generate_sentence_count(self):\n        print(\"Generating sentence count\")\n        self.state.sentence_count = randint(1, 5)\n\n    @listen(generate_sentence_count)\n    def generate_poem(self):\n        print(\"Generating poem\")\n        result = PoemCrew().crew().kickoff(inputs={\"sentence_count\": self.state.sentence_count})\n\n        print(\"Poem generated\", result.raw)\n        self.state.poem = result.raw\n\n    @listen(generate_poem)\n    def save_poem(self):\n        print(\"Saving poem\")\n        with open(\"poem.txt\", \"w\") as f:\n            f.write(self.state.poem)\n\ndef kickoff():\n    poem_flow = PoemFlow()\n    poem_flow.kickoff()\n\n\ndef plot():\n    poem_flow = PoemFlow()\n    poem_flow.plot()\n\nif __name__ == \"__main__\":\n    kickoff()\n```\n\n----------------------------------------\n\nTITLE: Using YoutubeVideoSearchTool with CrewAI Agent\nDESCRIPTION: Example demonstrating how to initialize the YoutubeVideoSearchTool, create a CrewAI agent with the tool, define a task, and run the crew to search for information in a YouTube video.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubevideosearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import YoutubeVideoSearchTool\n\n# Initialize the tool for general YouTube video searches\nyoutube_search_tool = YoutubeVideoSearchTool()\n\n# Define an agent that uses the tool\nvideo_researcher = Agent(\n    role=\"Video Researcher\",\n    goal=\"Extract relevant information from YouTube videos\",\n    backstory=\"An expert researcher who specializes in analyzing video content.\",\n    tools=[youtube_search_tool],\n    verbose=True,\n)\n\n# Example task to search for information in a specific video\nresearch_task = Task(\n    description=\"Search for information about machine learning frameworks in the YouTube video at {youtube_video_url}\",\n    expected_output=\"A summary of the key machine learning frameworks mentioned in the video.\",\n    agent=video_researcher,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[video_researcher], tasks=[research_task])\nresult = crew.kickoff(inputs={\"youtube_video_url\": \"https://youtube.com/watch?v=example\"})\n```\n\n----------------------------------------\n\nTITLE: Implementing CrewAI Agents with Python Class\nDESCRIPTION: Python implementation showing how to create a crew class that uses YAML configuration to instantiate agents. Demonstrates the use of decorators and inheritance from CrewBase.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/agents.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# src/latest_ai_development/crew.py\nfrom crewai import Agent, Crew, Process\nfrom crewai.project import CrewBase, agent, crew\nfrom crewai_tools import SerperDevTool\n\n@CrewBase\nclass LatestAiDevelopmentCrew():\n  \"\"\"LatestAiDevelopment crew\"\"\"\n\n  agents_config = \"config/agents.yaml\"\n\n  @agent\n  def researcher(self) -> Agent:\n    return Agent(\n      config=self.agents_config['researcher'], # type: ignore[index]\n      verbose=True,\n      tools=[SerperDevTool()]\n    )\n\n  @agent\n  def reporting_analyst(self) -> Agent:\n    return Agent(\n      config=self.agents_config['reporting_analyst'], # type: ignore[index]\n      verbose=True\n    )\n```\n\n----------------------------------------\n\nTITLE: Visualizing CrewAI Flow Structure\nDESCRIPTION: Shows how to generate a visual representation of the flow structure using the CrewAI CLI. This command creates an HTML file that illustrates the relationships between different steps and data flow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncrewai flow plot\n```\n\n----------------------------------------\n\nTITLE: Implementing After Kickoff Hook in CrewAI\nDESCRIPTION: This snippet shows how to define an after kickoff function in a CrewAI implementation. The hook is used for post-processing results after the crew has completed its tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/before-and-after-kickoff-hooks.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import CrewBase, after_kickoff\n\n@CrewBase\nclass MyCrew:\n    @after_kickoff\n    def log_results(self, result):\n        # Log or modify the results\n        print(\"Crew execution completed with result:\", result)\n        return result\n\n# ...\n```\n\n----------------------------------------\n\nTITLE: Configuring JSONSearchTool with Custom Settings\nDESCRIPTION: Example of configuring the JSONSearchTool with custom settings for the language model and embedding model. This allows users to select different providers and models for embeddings and summarization based on their specific requirements.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/jsonsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = JSONSearchTool(\n    config={\n        \"llm\": {\n            \"provider\": \"ollama\",  # Other options include google, openai, anthropic, llama2, etc.\n            \"config\": {\n                \"model\": \"llama2\",\n                # Additional optional configurations can be specified here.\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            },\n        },\n        \"embedding_model\": {\n            \"provider\": \"google\", # or openai, ollama, ...\n            \"config\": {\n                \"model\": \"models/embedding-001\",\n                \"task_type\": \"retrieval_document\",\n                # Further customization options can be added here.\n            },\n        },\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Manager Agent for Hierarchical Process in CrewAI\nDESCRIPTION: This code snippet shows how to create a custom manager agent with specific attributes and use it in a crew setup. It demonstrates defining a manager agent with a specific role, goal, and backstory, and then incorporating it into the crew configuration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/hierarchical-process.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Define a custom manager agent\nmanager = Agent(\n    role=\"Project Manager\",\n    goal=\"Efficiently manage the crew and ensure high-quality task completion\",\n    backstory=\"You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success.\",\n    allow_delegation=True,\n)\n\n# Use the custom manager in your crew\nproject_crew = Crew(\n    tasks=[...],\n    agents=[researcher, writer],\n    manager_agent=manager,  # Use your custom manager agent\n    process=Process.hierarchical,\n    planning=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Using State for Progress Tracking in Long-Running Flows with Python\nDESCRIPTION: This snippet demonstrates how to use state to track progress in long-running flows. It includes methods for initializing progress, updating progress, and completing steps while updating the progress percentage.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nclass ProgressTrackingFlow(Flow):\n    @start()\n    def initialize(self):\n        self.state[\"total_steps\"] = 3\n        self.state[\"current_step\"] = 0\n        self.state[\"progress\"] = 0.0\n        self.update_progress()\n        return \"Initialized\"\n\n    def update_progress(self):\n        \"\"\"Helper method to calculate and update progress\"\"\"\n        if self.state.get(\"total_steps\", 0) > 0:\n            self.state[\"progress\"] = (self.state.get(\"current_step\", 0) /\n                                    self.state[\"total_steps\"]) * 100\n            print(f\"Progress: {self.state['progress']:.1f}%\")\n\n    @listen(initialize)\n    def step_one(self, _):\n        # Do work...\n        self.state[\"current_step\"] = 1\n        self.update_progress()\n        return \"Step 1 complete\"\n\n    # Additional steps...\n```\n\n----------------------------------------\n\nTITLE: Implementing Metrics Collection for Custom LLM\nDESCRIPTION: A custom LLM implementation with metrics collection capabilities. Tracks total calls, tokens, errors, and latency metrics for monitoring and analysis.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport time\nfrom typing import Any, Dict, List, Optional, Union\n\nclass MetricsCollectingLLM(BaseLLM):\n    def __init__(self, api_key: str, endpoint: str):\n        super().__init__()\n        self.api_key = api_key\n        self.endpoint = endpoint\n        self.metrics: Dict[str, Any] = {\n            \"total_calls\": 0,\n            \"total_tokens\": 0,\n            \"errors\": 0,\n            \"latency\": []\n        }\n        \n    def call(\n        self,\n        messages: Union[str, List[Dict[str, str]]],\n        tools: Optional[List[dict]] = None,\n        callbacks: Optional[List[Any]] = None,\n        available_functions: Optional[Dict[str, Any]] = None,\n    ) -> Union[str, Any]:\n        start_time = time.time()\n        self.metrics[\"total_calls\"] += 1\n        \n        try:\n            response = self._make_api_call(messages, tools)\n            # Estimate tokens (simplified)\n            if isinstance(messages, str):\n                token_estimate = len(messages) // 4\n            else:\n                token_estimate = sum(len(m.get(\"content\", \"\")) // 4 for m in messages)\n            self.metrics[\"total_tokens\"] += token_estimate\n            return response\n        except Exception as e:\n            self.metrics[\"errors\"] += 1\n            raise\n        finally:\n            latency = time.time() - start_time\n            self.metrics[\"latency\"].append(latency)\n            \n    def get_metrics(self) -> Dict[str, Any]:\n        avg_latency = sum(self.metrics[\"latency\"]) / len(self.metrics[\"latency\"]) if self.metrics[\"latency\"] else 0\n        return {\n            **self.metrics,\n            \"avg_latency\": avg_latency\n        }\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Tool with Decorator in Python\nDESCRIPTION: Demonstrates how to create a custom tool using the @tool decorator in CrewAI. This method allows for easy integration of custom functions as tools for agents to use.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tools.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.tools import tool\n@tool(\"Name of my tool\")\ndef my_tool(question: str) -> str:\n    \"\"\"Clear description for what this tool is useful for, your agent will need this information to use it.\"\"\"\n    # Function logic here\n    return \"Result from your custom tool\"\n```\n\n----------------------------------------\n\nTITLE: Initializing RagTool with Basic Data Sources\nDESCRIPTION: Demonstrates how to create a RagTool instance and add content from files and web pages. Shows basic integration with a CrewAI agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/ragtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import RagTool\n\n# Create a RAG tool with default settings\nrag_tool = RagTool()\n\n# Add content from a file\nrag_tool.add(data_type=\"file\", path=\"path/to/your/document.pdf\")\n\n# Add content from a web page\nrag_tool.add(data_type=\"web_page\", url=\"https://example.com\")\n\n# Define an agent with the RagTool\n@agent\ndef knowledge_expert(self) -> Agent:\n    '''\n    This agent uses the RagTool to answer questions about the knowledge base.\n    '''\n    return Agent(\n        config=self.agents_config[\"knowledge_expert\"],\n        allow_delegation=False,\n        tools=[rag_tool]\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Event Listener in Python for CrewAI\nDESCRIPTION: Example showing how to create a custom event listener class that inherits from BaseEventListener and implements handlers for different CrewAI events including crew kickoff and agent execution events.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.utilities.events import (\n    CrewKickoffStartedEvent,\n    CrewKickoffCompletedEvent,\n    AgentExecutionCompletedEvent,\n)\nfrom crewai.utilities.events.base_event_listener import BaseEventListener\n\nclass MyCustomListener(BaseEventListener):\n    def __init__(self):\n        super().__init__()\n\n    def setup_listeners(self, crewai_event_bus):\n        @crewai_event_bus.on(CrewKickoffStartedEvent)\n        def on_crew_started(source, event):\n            print(f\"Crew '{event.crew_name}' has started execution!\")\n\n        @crewai_event_bus.on(CrewKickoffCompletedEvent)\n        def on_crew_completed(source, event):\n            print(f\"Crew '{event.crew_name}' has completed execution!\")\n            print(f\"Output: {event.output}\")\n\n        @crewai_event_bus.on(AgentExecutionCompletedEvent)\n        def on_agent_execution_completed(source, event):\n            print(f\"Agent '{event.agent.role}' completed task\")\n            print(f\"Output: {event.output}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Structured State Management in CrewAI Flow\nDESCRIPTION: This example shows how to use structured state management with Pydantic models in a CrewAI Flow. It demonstrates type-safe state definition, initialization, and access across flow methods.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\nfrom pydantic import BaseModel, Field\nfrom typing import List, Dict, Optional\n\n# Define your state model\nclass UserPreferences(BaseModel):\n    theme: str = \"light\"\n    language: str = \"English\"\n\nclass AppState(BaseModel):\n    user_name: str = \"\"\n    preferences: UserPreferences = UserPreferences()\n    items: List[str] = []\n    processed: bool = False\n    completion_percentage: float = 0.0\n\n# Create a flow with typed state\nclass StructuredStateFlow(Flow[AppState]):\n    @start()\n    def initialize_data(self):\n        print(\"Initializing flow data\")\n        # Set state values (type-checked)\n        self.state.user_name = \"Taylor\"\n        self.state.preferences.theme = \"dark\"\n\n        # The ID field is automatically available\n        print(f\"Flow ID: {self.state.id}\")\n\n        return \"Initialized\"\n\n    @listen(initialize_data)\n    def process_data(self, previous_result):\n        print(f\"Processing data for {self.state.user_name}\")\n\n        # Modify state (with type checking)\n        self.state.items.append(\"item1\")\n        self.state.items.append(\"item2\")\n        self.state.processed = True\n        self.state.completion_percentage = 50.0\n\n        return \"Processed\"\n\n    @listen(process_data)\n    def generate_summary(self, previous_result):\n        # Access state (with autocompletion)\n        summary = f\"User {self.state.user_name} has {len(self.state.items)} items \"\n        summary += f\"with {self.state.preferences.theme} theme. \"\n        summary += \"Data is processed.\" if self.state.processed else \"Data is not processed.\"\n        summary += f\" Completion: {self.state.completion_percentage}%\"\n\n        return summary\n\n# Run the flow\nflow = StructuredStateFlow()\nresult = flow.kickoff()\nprint(f\"Final result: {result}\")\nprint(f\"Final state: {flow.state}\")\n```\n\n----------------------------------------\n\nTITLE: Basic ScrapegraphScrapeTool Usage Example\nDESCRIPTION: Example showing how to initialize and use the ScrapegraphScrapeTool with a CrewAI agent and task.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapegraphscrapetool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import ScrapegraphScrapeTool\n\n# Initialize the tool\nscrape_tool = ScrapegraphScrapeTool(api_key=\"your_api_key\")\n\n# Define an agent that uses the tool\nweb_scraper_agent = Agent(\n    role=\"Web Scraper\",\n    goal=\"Extract specific information from websites\",\n    backstory=\"An expert in web scraping who can extract targeted content from web pages.\",\n    tools=[scrape_tool],\n    verbose=True,\n)\n\n# Example task to extract product information from an e-commerce site\nscrape_task = Task(\n    description=\"Extract product names, prices, and descriptions from the featured products section of example.com.\",\n    expected_output=\"A structured list of product information including names, prices, and descriptions.\",\n    agent=web_scraper_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Initializing LangGraph Agent Adapter for Reporter in Python\nDESCRIPTION: Creates a LangGraph Agent Adapter for a reporter role using OpenAI's GPT-4 model. The agent is responsible for reporting task results and has delegation capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nreporter_agent = LangGraphAgentAdapter(\n    role=\"Reporter\",\n    goal=\"Report the results of the tasks.\",\n    backstory=\"You are a reporter who reports the results of the other tasks\",\n    llm=ChatOpenAI(model=\"gpt-4o\"),\n    allow_delegation=True,\n    verbose=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Sequential and Hierarchical Processes in CrewAI\nDESCRIPTION: This code demonstrates how to create a crew with either sequential or hierarchical process types. For hierarchical processes, a manager language model (manager_llm) or a custom manager agent (manager_agent) must be specified to oversee task execution, delegation, and validation.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/processes.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Process\n\n# Example: Creating a crew with a sequential process\ncrew = Crew(\n    agents=my_agents,\n    tasks=my_tasks,\n    process=Process.sequential\n)\n\n# Example: Creating a crew with a hierarchical process\n# Ensure to provide a manager_llm or manager_agent\ncrew = Crew(\n    agents=my_agents,\n    tasks=my_tasks,\n    process=Process.hierarchical,\n    manager_llm=\"gpt-4o\"\n    # or\n    # manager_agent=my_manager_agent\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Text File Knowledge Source in CrewAI\nDESCRIPTION: This example demonstrates how to create and use a text file knowledge source in CrewAI. It shows how to set up the source with multiple text files and integrate it with an agent or crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.knowledge.source.text_file_knowledge_source import TextFileKnowledgeSource\n\n# Create a text file knowledge source\ntext_source = TextFileKnowledgeSource(\n    file_paths=[\"document.txt\", \"another.txt\"]\n)\n\n# Create crew with text file source on agents or crew level\nagent = Agent(\n    ...\n    knowledge_sources=[text_source]\n)\n\ncrew = Crew(\n    ...\n    knowledge_sources=[text_source]\n)\n```\n\n----------------------------------------\n\nTITLE: BraveSearchTool with Custom Parameters\nDESCRIPTION: Advanced example demonstrating BraveSearchTool usage with custom parameters including country specification, result count, and file saving option.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bravesearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import BraveSearchTool\n\n# Initialize the tool with custom parameters\ntool = BraveSearchTool(\n    country=\"US\",\n    n_results=5,\n    save_file=True\n)\n\n# Execute a search\nresults = tool.run(search_query=\"Latest AI developments\")\nprint(results)\n```\n\n----------------------------------------\n\nTITLE: Designing Collaborative Agents in CrewAI\nDESCRIPTION: Shows how to define a set of complementary agents for a content creation crew, each with distinct roles and goals, using YAML in CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\n# Research Agent\nrole: \"Research Specialist for technical topics\"\ngoal: \"Gather comprehensive, accurate information from authoritative sources\"\nbackstory: \"You are a meticulous researcher with a background in library science...\"\n\n# Writer Agent\nrole: \"Technical Content Writer\"\ngoal: \"Transform research into engaging, clear content that educates and informs\"\nbackstory: \"You are an experienced writer who excels at explaining complex concepts...\"\n\n# Editor Agent\nrole: \"Content Quality Editor\"\ngoal: \"Ensure content is accurate, well-structured, and polished while maintaining consistency\"\nbackstory: \"With years of experience in publishing, you have a keen eye for detail...\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Research and Reporting Agents in YAML\nDESCRIPTION: This YAML configuration defines two agents: a researcher who discovers the latest developments on a topic, and a reporting analyst who creates detailed reports based on research findings. The configuration uses variable interpolation for customization.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# src/latest_ai_development/config/agents.yaml\nresearcher:\n  role: >\n    {topic} Senior Data Researcher\n  goal: >\n    Uncover cutting-edge developments in {topic}\n  backstory: >\n    You're a seasoned researcher with a knack for uncovering the latest\n    developments in {topic}. Known for your ability to find the most relevant\n    information and present it in a clear and concise manner.\n\nreporting_analyst:\n  role: >\n    {topic} Reporting Analyst\n  goal: >\n    Create detailed reports based on {topic} data analysis and research findings\n  backstory: >\n    You're a meticulous analyst with a keen eye for detail. You're known for\n    your ability to turn complex data into clear and concise reports, making\n    it easy for others to understand and act on the information you provide.\n```\n\n----------------------------------------\n\nTITLE: Adding Content to RagTool Knowledge Base\nDESCRIPTION: Shows different methods of adding content to the RagTool knowledge base, including PDF files, web pages, YouTube videos, and directories.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/ragtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Add a PDF file\nrag_tool.add(data_type=\"file\", path=\"path/to/your/document.pdf\")\n\n# Add a web page\nrag_tool.add(data_type=\"web_page\", url=\"https://example.com\")\n\n# Add a YouTube video\nrag_tool.add(data_type=\"youtube_video\", url=\"https://www.youtube.com/watch?v=VIDEO_ID\")\n\n# Add a directory of files\nrag_tool.add(data_type=\"directory\", path=\"path/to/your/directory\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Structured State Management in CrewAI Flow (Python)\nDESCRIPTION: Shows how to use structured state management in a CrewAI Flow using Pydantic BaseModel. This approach ensures type safety and consistency across the workflow, with an automatically generated unique ID for each state instance.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\nfrom pydantic import BaseModel\n\n\nclass ExampleState(BaseModel):\n    # Note: 'id' field is automatically added to all states\n    counter: int = 0\n    message: str = \"\"\n\n\nclass StructuredExampleFlow(Flow[ExampleState]):\n\n    @start()\n    def first_method(self):\n        # Access the auto-generated ID if needed\n        print(f\"State ID: {self.state.id}\")\n        self.state.message = \"Hello from structured flow\"\n\n    @listen(first_method)\n    def second_method(self):\n        self.state.counter += 1\n        self.state.message += \" - updated\"\n\n    @listen(second_method)\n    def third_method(self):\n        self.state.counter += 1\n        self.state.message += \" - updated again\"\n\n        print(f\"State after third_method: {self.state}\")\n\n\nflow = StructuredExampleFlow()\nflow.kickoff()\n```\n\n----------------------------------------\n\nTITLE: JSON Output Validation with Retry Logic\nDESCRIPTION: Implements JSON validation guardrail with retry mechanism for task outputs. Includes error handling for JSON parsing and retry limit configuration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional, Tuple, Union\nfrom crewai import TaskOutput, Task\n\ndef validate_json_output(result: TaskOutput) -> Tuple[bool, Any]:\n    \"\"\"Validate and parse JSON output.\"\"\"\n    try:\n        # Try to parse as JSON\n        data = json.loads(result)\n        return (True, data)\n    except json.JSONDecodeError as e:\n        return (False, \"Invalid JSON format\")\n\ntask = Task(\n    description=\"Generate a JSON report\",\n    expected_output=\"A valid JSON object\",\n    agent=analyst,\n    guardrail=validate_json_output,\n    max_retries=3  # Limit retry attempts\n)\n```\n\n----------------------------------------\n\nTITLE: Creating CrewAI Application with Agents and Tasks\nDESCRIPTION: Implementation of a CrewAI application with a writer agent and task configuration for generating math-related haikus.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/langfuse-observability.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\n\nfrom crewai_tools import (\n    WebsiteSearchTool\n)\n\nweb_rag_tool = WebsiteSearchTool()\n\nwriter = Agent(\n        role=\"Writer\",\n        goal=\"You make math engaging and understandable for young children through poetry\",\n        backstory=\"You're an expert in writing haikus but you know nothing of math.\",\n        tools=[web_rag_tool],  \n    )\n\ntask = Task(description=(\"What is {multiplication}?\"),\n            expected_output=(\"Compose a haiku that includes the answer.\"),\n            agent=writer)\n\ncrew = Crew(\n  agents=[writer],\n  tasks=[task],\n  share_crew=False\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing MDXSearchTool in Python\nDESCRIPTION: Examples of initializing the MDXSearchTool, either for searching any MDX content or for a specific MDX file.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/mdxsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import MDXSearchTool\n\n# Initialize the tool to search any MDX content it learns about during execution\ntool = MDXSearchTool()\n\n# OR\n\n# Initialize the tool with a specific MDX file path for an exclusive search within that document\ntool = MDXSearchTool(mdx='path/to/your/document.mdx')\n```\n\n----------------------------------------\n\nTITLE: ScrapflyScrapeWebsiteTool Implementation\nDESCRIPTION: Core implementation of the ScrapflyScrapeWebsiteTool class showing the main scraping logic and error handling.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapflyscrapetool.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass ScrapflyScrapeWebsiteTool(BaseTool):\n    name: str = \"Scrapfly web scraping API tool\"\n    description: str = (\n        \"Scrape a webpage url using Scrapfly and return its content as markdown or text\"\n    )\n    \n    # Implementation details...\n    \n    def _run(\n        self,\n        url: str,\n        scrape_format: str = \"markdown\",\n        scrape_config: Optional[Dict[str, Any]] = None,\n        ignore_scrape_failures: Optional[bool] = None,\n    ):\n        from scrapfly import ScrapeApiResponse, ScrapeConfig\n\n        scrape_config = scrape_config if scrape_config is not None else {}\n        try:\n            response: ScrapeApiResponse = self.scrapfly.scrape(\n                ScrapeConfig(url, format=scrape_format, **scrape_config)\n            )\n            return response.scrape_result[\"content\"]\n        except Exception as e:\n            if ignore_scrape_failures:\n                logger.error(f\"Error fetching data from {url}, exception: {e}\")\n                return None\n            else:\n                raise e\n```\n\n----------------------------------------\n\nTITLE: Implementing Research Crew Class in Python\nDESCRIPTION: Python class implementation defining the research crew with agents, tasks and crew configuration using CrewAI decorators\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/crews/first-crew.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai.project import CrewBase, agent, crew, task\nfrom crewai_tools import SerperDevTool\nfrom crewai.agents.agent_builder.base_agent import BaseAgent\nfrom typing import List\n\n@CrewBase\nclass ResearchCrew():\n    \"\"\"Research crew for comprehensive topic analysis and reporting\"\"\"\n\n    agents: List[BaseAgent]\n    tasks: List[Task]\n\n    @agent\n    def researcher(self) -> Agent:\n        return Agent(\n            config=self.agents_config['researcher'], # type: ignore[index]\n            verbose=True,\n            tools=[SerperDevTool()]\n        )\n\n    @agent\n    def analyst(self) -> Agent:\n        return Agent(\n            config=self.agents_config['analyst'], # type: ignore[index]\n            verbose=True\n        )\n\n    @task\n    def research_task(self) -> Task:\n        return Task(\n            config=self.tasks_config['research_task'] # type: ignore[index]\n        )\n\n    @task\n    def analysis_task(self) -> Task:\n        return Task(\n            config=self.tasks_config['analysis_task'], # type: ignore[index]\n            output_file='output/report.md'\n        )\n\n    @crew\n    def crew(self) -> Crew:\n        \"\"\"Creates the research crew\"\"\"\n        return Crew(\n            agents=self.agents,\n            tasks=self.tasks,\n            process=Process.sequential,\n            verbose=True,\n        )\n```\n\n----------------------------------------\n\nTITLE: Implementing PDF Knowledge Source in CrewAI\nDESCRIPTION: This snippet shows how to create and use a PDF knowledge source in CrewAI. It demonstrates setting up the source with multiple PDF files and integrating it with an agent or crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource\n\n# Create a PDF knowledge source\npdf_source = PDFKnowledgeSource(\n    file_paths=[\"document.pdf\", \"another.pdf\"]\n)\n\n# Create crew with PDF knowledge source on agents or crew level\nagent = Agent(\n    ...\n    knowledge_sources=[pdf_source]\n)\n\ncrew = Crew(\n    ...\n    knowledge_sources=[pdf_source]\n)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Flow State for Debugging in Python\nDESCRIPTION: This example provides a method to visualize the current state of a flow for debugging purposes. It uses the rich library to create a formatted output of the state as a JSON string.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef visualize_state(self):\n    \"\"\"Create a simple visualization of the current state\"\"\"\n    import json\n    from rich.console import Console\n    from rich.panel import Panel\n\n    console = Console()\n\n    if hasattr(self.state, \"model_dump\"):\n        # Pydantic v2\n        state_dict = self.state.model_dump()\n    elif hasattr(self.state, \"dict\"):\n        # Pydantic v1\n        state_dict = self.state.dict()\n    else:\n        # Unstructured state\n        state_dict = dict(self.state)\n\n    # Remove id for cleaner output\n    if \"id\" in state_dict:\n        state_dict.pop(\"id\")\n\n    state_json = json.dumps(state_dict, indent=2, default=str)\n    console.print(Panel(state_json, title=\"Current Flow State\"))\n```\n\n----------------------------------------\n\nTITLE: Orchestrating CrewAI Workflow for Space News Analysis in Python\nDESCRIPTION: This snippet sets up the CrewAI workflow, combining the agent and task to process the user's question and generate a response based on recent space news articles.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ncrew = Crew(\n    agents=[space_news_analyst],\n    tasks=[task],\n    verbose=2\n)\n\nresult = crew.kickoff()\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Configuring LLMs using Environment Variables in Bash\nDESCRIPTION: Sets up the required API key and optional parameters for using OpenAI models with CrewAI through environment variables. This includes the API key, default model selection, and organization ID if applicable.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Required: Your API key for authentication\nOPENAI_API_KEY=<your-api-key>\n\n# Optional: Default model selection\nOPENAI_MODEL_NAME=gpt-4o-mini  # Default if not set\n\n# Optional: Organization ID (if applicable)\nOPENAI_ORGANIZATION_ID=<your-org-id>\n```\n\n----------------------------------------\n\nTITLE: Implementing HyperbrowserLoadTool with CrewAI Agent\nDESCRIPTION: Example demonstrating how to initialize the HyperbrowserLoadTool with an API key and create a web researcher agent. Shows tool initialization and agent definition using the CrewAI framework.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/hyperbrowserloadtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import HyperbrowserLoadTool\nfrom crewai import Agent\n\n# Initialize the tool with your API key\ntool = HyperbrowserLoadTool(api_key=\"your_api_key\")  # Or use environment variable\n\n# Define an agent that uses the tool\n@agent\ndef web_researcher(self) -> Agent:\n    '''\n    This agent uses the HyperbrowserLoadTool to scrape websites\n    and extract information.\n    '''\n    return Agent(\n        config=self.agents_config[\"web_researcher\"],\n        tools=[tool]\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing Single Asynchronous Crew Execution in Python\nDESCRIPTION: This example demonstrates how to kickoff a single crew asynchronously using asyncio. It creates an agent, a task, and a crew, then executes the crew asynchronously and prints the result.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/kickoff-async.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crewai import Crew, Agent, Task\n\n# Create an agent with code execution enabled\ncoding_agent = Agent(\n    role=\"Python Data Analyst\",\n    goal=\"Analyze data and provide insights using Python\",\n    backstory=\"You are an experienced data analyst with strong Python skills.\",\n    allow_code_execution=True\n)\n\n# Create a task that requires code execution\ndata_analysis_task = Task(\n    description=\"Analyze the given dataset and calculate the average age of participants. Ages: {ages}\",\n    agent=coding_agent,\n    expected_output=\"The average age of the participants.\"\n)\n\n# Create a crew and add the task\nanalysis_crew = Crew(\n    agents=[coding_agent],\n    tasks=[data_analysis_task]\n)\n\n# Async function to kickoff the crew asynchronously\nasync def async_crew_execution():\n    result = await analysis_crew.kickoff_async(inputs={\"ages\": [25, 30, 35, 40, 45]})\n    print(\"Crew Result:\", result)\n\n# Run the async function\nasyncio.run(async_crew_execution())\n```\n\n----------------------------------------\n\nTITLE: Implementing Try-Except Blocks for API Calls in Custom LLM\nDESCRIPTION: Shows how to properly implement try-except blocks for API calls in a custom LLM implementation. This handles different error types and raises appropriate exceptions with descriptive messages.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef call(\n    self,\n    messages: Union[str, List[Dict[str, str]]],\n    tools: Optional[List[dict]] = None,\n    callbacks: Optional[List[Any]] = None,\n    available_functions: Optional[Dict[str, Any]] = None,\n) -> Union[str, Any]:\n    try:\n        # API call implementation\n        response = requests.post(\n            self.endpoint,\n            headers=self.headers,\n            json=self.prepare_payload(messages),\n            timeout=30  # Set a reasonable timeout\n        )\n        response.raise_for_status()  # Raise an exception for HTTP errors\n        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n    except requests.Timeout:\n        raise TimeoutError(\"LLM request timed out\")\n    except requests.RequestException as e:\n        raise RuntimeError(f\"LLM request failed: {str(e)}\")\n    except (KeyError, IndexError, ValueError) as e:\n        raise ValueError(f\"Invalid response format: {str(e)}\")\n```\n\n----------------------------------------\n\nTITLE: Detailed Integration of CodeInterpreterTool with CrewAI Agent\nDESCRIPTION: A more comprehensive example of integrating the CodeInterpreterTool with a CrewAI agent for data analysis tasks, including generating random data, calculating correlation, and creating a scatter plot.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/codeinterpretertool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import CodeInterpreterTool\n\n# Initialize the tool\ncode_interpreter = CodeInterpreterTool()\n\n# Define an agent that uses the tool\ndata_analyst = Agent(\n    role=\"Data Analyst\",\n    goal=\"Analyze data using Python code\",\n    backstory=\"\"\"You are an expert data analyst who specializes in using Python \n    to analyze and visualize data. You can write efficient code to process \n    large datasets and extract meaningful insights.\"\"\",\n    tools=[code_interpreter],\n    verbose=True,\n)\n\n# Create a task for the agent\nanalysis_task = Task(\n    description=\"\"\"\n    Write Python code to:\n    1. Generate a random dataset of 100 points with x and y coordinates\n    2. Calculate the correlation coefficient between x and y\n    3. Create a scatter plot of the data\n    4. Print the correlation coefficient and save the plot as 'scatter.png'\n    \n    Make sure to handle any necessary imports and print the results.\n    \"\"\",\n    expected_output=\"The correlation coefficient and confirmation that the scatter plot has been saved.\",\n    agent=data_analyst,\n)\n\n# Run the task\ncrew = Crew(\n    agents=[data_analyst],\n    tasks=[analysis_task],\n    verbose=True,\n    process=Process.sequential,\n)\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI LLM in CrewAI\nDESCRIPTION: Demonstrates how to initialize an OpenAI LLM in a CrewAI project, specifying the model, temperature, and other parameters like max tokens, top_p, and penalties.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM\n\nllm = LLM(\n    model=\"openai/gpt-4\", # call model by provider/model_name\n    temperature=0.8,\n    max_tokens=150,\n    top_p=0.9,\n    frequency_penalty=0.1,\n    presence_penalty=0.1,\n    stop=[\"END\"],\n    seed=42\n)\n```\n\n----------------------------------------\n\nTITLE: Integrating BraveSearchTool with CrewAI Agent\nDESCRIPTION: Example showing how to integrate the BraveSearchTool into a CrewAI agent configuration for automated research capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bravesearchtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\nfrom crewai.project import agent\nfrom crewai_tools import BraveSearchTool\n\n# Initialize the tool\nbrave_search_tool = BraveSearchTool()\n\n# Define an agent with the BraveSearchTool\n@agent\ndef researcher(self) -> Agent:\n    return Agent(\n        config=self.agents_config[\"researcher\"],\n        allow_delegation=False,\n        tools=[brave_search_tool]\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing Content Production Flow with CrewAI in Python\nDESCRIPTION: This code snippet defines a ContentProductionFlow class that inherits from Flow[ContentState]. It outlines a complete content production pipeline including project initialization, outline creation, content writing, and SEO optimization. The flow uses CrewAI's Agent, Crew, and Task components to orchestrate the content creation process.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/concepts/evaluating-use-cases.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\nfrom crewai import Agent, Crew, Process, Task\nfrom pydantic import BaseModel\nfrom typing import List, Dict\n\nclass ContentState(BaseModel):\n    topic: str = \"\"\n    target_audience: str = \"\"\n    content_type: str = \"\"\n    outline: Dict = {}\n    draft_content: str = \"\"\n    final_content: str = \"\"\n    seo_score: int = 0\n\nclass ContentProductionFlow(Flow[ContentState]):\n    @start()\n    def initialize_project(self):\n        # Set initial parameters\n        self.state.topic = \"Sustainable Investing\"\n        self.state.target_audience = \"Millennial Investors\"\n        self.state.content_type = \"Blog Post\"\n        return \"Project initialized\"\n\n    @listen(initialize_project)\n    def create_outline(self, _):\n        # Use a research crew to create an outline\n        researcher = Agent(\n            role=\"Content Researcher\",\n            goal=f\"Research {self.state.topic} for {self.state.target_audience}\",\n            backstory=\"You are an expert researcher with deep knowledge of content creation.\"\n        )\n\n        outliner = Agent(\n            role=\"Content Strategist\",\n            goal=f\"Create an engaging outline for a {self.state.content_type}\",\n            backstory=\"You excel at structuring content for maximum engagement.\"\n        )\n\n        research_task = Task(\n            description=f\"Research {self.state.topic} focusing on what would interest {self.state.target_audience}\",\n            expected_output=\"Comprehensive research notes with key points and statistics\",\n            agent=researcher\n        )\n\n        outline_task = Task(\n            description=f\"Create an outline for a {self.state.content_type} about {self.state.topic}\",\n            expected_output=\"Detailed content outline with sections and key points\",\n            agent=outliner,\n            context=[research_task]\n        )\n\n        outline_crew = Crew(\n            agents=[researcher, outliner],\n            tasks=[research_task, outline_task],\n            process=Process.sequential,\n            verbose=True\n        )\n\n        # Run the crew and store the result\n        result = outline_crew.kickoff()\n\n        # Parse the outline (in a real app, you might use a more robust parsing approach)\n        import json\n        try:\n            self.state.outline = json.loads(result.raw)\n        except:\n            # Fallback if not valid JSON\n            self.state.outline = {\"sections\": result.raw}\n\n        return \"Outline created\"\n\n    @listen(create_outline)\n    def write_content(self, _):\n        # Use a writing crew to create the content\n        writer = Agent(\n            role=\"Content Writer\",\n            goal=f\"Write engaging content for {self.state.target_audience}\",\n            backstory=\"You are a skilled writer who creates compelling content.\"\n        )\n\n        editor = Agent(\n            role=\"Content Editor\",\n            goal=\"Ensure content is polished, accurate, and engaging\",\n            backstory=\"You have a keen eye for detail and a talent for improving content.\"\n        )\n\n        writing_task = Task(\n            description=f\"Write a {self.state.content_type} about {self.state.topic} following this outline: {self.state.outline}\",\n            expected_output=\"Complete draft content in markdown format\",\n            agent=writer\n        )\n\n        editing_task = Task(\n            description=\"Edit and improve the draft content for clarity, engagement, and accuracy\",\n            expected_output=\"Polished final content in markdown format\",\n            agent=editor,\n            context=[writing_task]\n        )\n\n        writing_crew = Crew(\n            agents=[writer, editor],\n            tasks=[writing_task, editing_task],\n            process=Process.sequential,\n            verbose=True\n        )\n\n        # Run the crew and store the result\n        result = writing_crew.kickoff()\n        self.state.final_content = result.raw\n\n        return \"Content created\"\n\n    @listen(write_content)\n    def optimize_for_seo(self, _):\n        # Use a direct LLM call for SEO optimization\n        from crewai import LLM\n        llm = LLM(model=\"openai/gpt-4o-mini\")\n\n        prompt = f\"\"\"\n        Analyze this content for SEO effectiveness for the keyword \"{self.state.topic}\".\n        Rate it on a scale of 1-100 and provide 3 specific recommendations for improvement.\n\n        Content: {self.state.final_content[:1000]}... (truncated for brevity)\n\n        Format your response as JSON with the following structure:\n        {{\n            \"score\": 85,\n            \"recommendations\": [\n                \"Recommendation 1\",\n                \"Recommendation 2\",\n                \"Recommendation 3\"\n            ]\n        }}\n        \"\"\"\n\n        seo_analysis = llm.call(prompt)\n\n        # Parse the SEO analysis\n        import json\n        try:\n            analysis = json.loads(seo_analysis)\n            self.state.seo_score = analysis.get(\"score\", 0)\n            return analysis\n        except:\n            self.state.seo_score = 50\n            return {\"score\": 50, \"recommendations\": [\"Unable to parse SEO analysis\"]}\n\n# Run the flow\ncontent_flow = ContentProductionFlow()\nresult = content_flow.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Initializing a Multimodal Agent in CrewAI\nDESCRIPTION: This snippet demonstrates how to create a multimodal agent by setting the 'multimodal' parameter to True. This enables the agent to process both text and non-text content like images.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/multimodal-agents.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\n\nagent = Agent(\n    role=\"Image Analyst\",\n    goal=\"Analyze and extract insights from images\",\n    backstory=\"An expert in visual content interpretation with years of experience in image analysis\",\n    multimodal=True  # This enables multimodal capabilities\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Retry Logic for Transient Failures in Custom LLM\nDESCRIPTION: Demonstrates how to implement retry logic with exponential backoff for handling transient failures like network issues in a custom LLM implementation. It attempts the API call multiple times before giving up.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef call(\n    self,\n    messages: Union[str, List[Dict[str, str]]],\n    tools: Optional[List[dict]] = None,\n    callbacks: Optional[List[Any]] = None,\n    available_functions: Optional[Dict[str, Any]] = None,\n) -> Union[str, Any]:\n    import time\n    \n    max_retries = 3\n    retry_delay = 1  # seconds\n    \n    for attempt in range(max_retries):\n        try:\n            response = requests.post(\n                self.endpoint,\n                headers=self.headers,\n                json=self.prepare_payload(messages),\n                timeout=30\n            )\n            response.raise_for_status()\n            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n        except (requests.Timeout, requests.ConnectionError) as e:\n            if attempt < max_retries - 1:\n                time.sleep(retry_delay * (2 ** attempt))  # Exponential backoff\n                continue\n            raise TimeoutError(f\"LLM request failed after {max_retries} attempts: {str(e)}\")\n        except requests.RequestException as e:\n            raise RuntimeError(f\"LLM request failed: {str(e)}\")\n```\n\n----------------------------------------\n\nTITLE: Advanced RagTool Configuration\nDESCRIPTION: Shows how to create a RagTool instance with custom configuration including specific LLM providers and embedding models.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/ragtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import RagTool\n\n# Create a RAG tool with custom configuration\nconfig = {\n    \"app\": {\n        \"name\": \"custom_app\",\n    },\n    \"llm\": {\n        \"provider\": \"openai\",\n        \"config\": {\n            \"model\": \"gpt-4\",\n        }\n    },\n    \"embedding_model\": {\n        \"provider\": \"openai\",\n        \"config\": {\n            \"model\": \"text-embedding-ada-002\"\n        }\n    }\n}\n\nrag_tool = RagTool(config=config, summarize=True)\n```\n\n----------------------------------------\n\nTITLE: Using ApifyActorsTool to Run RAG Web Browser Actor in Python\nDESCRIPTION: This example demonstrates how to initialize and use the ApifyActorsTool to run the RAG Web Browser Actor for web searching. It includes setting up the tool, running it with input parameters, and processing the results.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/apifyactorstool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import ApifyActorsTool\n\n# Initialize the tool with an Apify Actor\ntool = ApifyActorsTool(actor_name=\"apify/rag-web-browser\")\n\n# Run the tool with input parameters\nresults = tool.run(run_input={\"query\": \"What is CrewAI?\", \"maxResults\": 5})\n\n# Process the results\nfor result in results:\n    print(f\"URL: {result['metadata']['url']}\")\n    print(f\"Content: {result.get('markdown', 'N/A')[:100]}...\")\n```\n\n----------------------------------------\n\nTITLE: Initializing FirecrawlSearchTool in Python\nDESCRIPTION: Example showing how to create an instance of FirecrawlSearchTool with a search query parameter. This tool allows agents to load and process website content.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/firecrawlsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import FirecrawlSearchTool\n\ntool = FirecrawlSearchTool(query='what is firecrawl?')\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Tool by Subclassing BaseTool\nDESCRIPTION: Example showing how to create a custom tool by subclassing BaseTool, including input schema definition and implementation of the _run method.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tools.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\n\nclass MyToolInput(BaseModel):\n    \"\"\"Input schema for MyCustomTool.\"\"\"\n    argument: str = Field(..., description=\"Description of the argument.\")\n\nclass MyCustomTool(BaseTool):\n    name: str = \"Name of my tool\"\n    description: str = \"What this tool does. It's vital for effective utilization.\"\n    args_schema: Type[BaseModel] = MyToolInput\n\n    def _run(self, argument: str) -> str:\n        # Your tool's logic here\n        return \"Tool's result\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Models for WebsiteSearchTool\nDESCRIPTION: Example demonstrating how to customize the LLM provider and embeddings model using a configuration dictionary. Shows options for different providers including ollama, google, openai, anthropic, and llama2.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/websitesearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = WebsiteSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Detailed Agent Integration Example with SeleniumScrapingTool\nDESCRIPTION: A comprehensive example demonstrating how to integrate the SeleniumScrapingTool with a CrewAI agent for extracting specific information from a news website.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/seleniumscrapingtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew, Process\nfrom crewai_tools import SeleniumScrapingTool\n\n# Initialize the tool\nselenium_tool = SeleniumScrapingTool()\n\n# Define an agent that uses the tool\nweb_scraper_agent = Agent(\n    role=\"Web Scraper\",\n    goal=\"Extract and analyze information from dynamic websites\",\n    backstory=\"\"\"You are an expert web scraper who specializes in extracting \n    content from dynamic websites that require browser automation. You have \n    extensive knowledge of CSS selectors and can identify the right selectors \n    to target specific content on any website.\"\"\",\n    tools=[selenium_tool],\n    verbose=True,\n)\n\n# Create a task for the agent\nscrape_task = Task(\n    description=\"\"\"\n    Extract the following information from the news website at {website_url}:\n    \n    1. The headlines of all featured articles (CSS selector: '.headline')\n    2. The publication dates of these articles (CSS selector: '.pub-date')\n    3. The author names where available (CSS selector: '.author')\n    \n    Compile this information into a structured format with each article's details grouped together.\n    \"\"\",\n    expected_output=\"A structured list of articles with their headlines, publication dates, and authors.\",\n    agent=web_scraper_agent,\n)\n\n# Run the task\ncrew = Crew(\n    agents=[web_scraper_agent],\n    tasks=[scrape_task],\n    verbose=True,\n    process=Process.sequential,\n)\nresult = crew.kickoff(inputs={\"website_url\": \"https://news-example.com\"})\n```\n\n----------------------------------------\n\nTITLE: Configuring Ollama (Local LLMs) with CrewAI\nDESCRIPTION: Demonstrates how to set up and use Ollama for local LLM inference with CrewAI, including installation and configuration steps.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"ollama/llama3:70b\",\n    base_url=\"http://localhost:11434\"\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Router Flow Control in Python\nDESCRIPTION: Demonstrates the use of @router decorator for conditional flow control based on state. Uses random boolean generation to determine execution path between success and failure handlers.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport random\nfrom crewai.flow.flow import Flow, listen, router, start\nfrom pydantic import BaseModel\n\nclass ExampleState(BaseModel):\n    success_flag: bool = False\n\nclass RouterFlow(Flow[ExampleState]):\n\n    @start()\n    def start_method(self):\n        print(\"Starting the structured flow\")\n        random_boolean = random.choice([True, False])\n        self.state.success_flag = random_boolean\n\n    @router(start_method)\n    def second_method(self):\n        if self.state.success_flag:\n            return \"success\"\n        else:\n            return \"failed\"\n\n    @listen(\"success\")\n    def third_method(self):\n        print(\"Third method running\")\n\n    @listen(\"failed\")\n    def fourth_method(self):\n        print(\"Fourth method running\")\n\n\nflow = RouterFlow()\nflow.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Task Output Access and Guardrails Implementation\nDESCRIPTION: Demonstrates how to access specific task outputs and implement validation guardrails for task outputs using custom functions.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Tuple, Union\nfrom crewai import Task\n\ndef validate_json_output(result: str) -> Tuple[bool, Union[dict, str]]:\n    \"\"\"Validate that the output is valid JSON.\"\"\"\n    try:\n        json_data = json.loads(result)\n        return (True, json_data)\n    except json.JSONDecodeError:\n        return (False, \"Output must be valid JSON\")\n\ntask = Task(\n    description=\"Generate JSON data\",\n    expected_output=\"Valid JSON object\",\n    guardrail=validate_json_output\n)\n```\n\n----------------------------------------\n\nTITLE: Creating LlamaIndexTool from LlamaIndex Query Engine\nDESCRIPTION: Example of creating a LlamaIndexTool from a LlamaIndex Query Engine. Demonstrates document loading, index creation, and query engine setup.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/llamaindextool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import LlamaIndexTool\nfrom llama_index.core import VectorStoreIndex\nfrom llama_index.core.readers import SimpleDirectoryReader\n\n# Load documents\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n# Create an index\nindex = VectorStoreIndex.from_documents(documents)\n\n# Create a query engine\nquery_engine = index.as_query_engine()\n\n# Create a LlamaIndexTool from the query engine\nquery_tool = LlamaIndexTool.from_query_engine(\n    query_engine,\n    name=\"Company Data Query Tool\",\n    description=\"Use this tool to lookup information in company documents\"\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring AI Agents in YAML\nDESCRIPTION: YAML configuration defining specialized AI agents with roles, goals and backstories for research and analysis tasks\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/crews/first-crew.mdx#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nresearcher:\n  role: >\n    Senior Research Specialist for {topic}\n  goal: >\n    Find comprehensive and accurate information about {topic}\n    with a focus on recent developments and key insights\n  backstory: >\n    You are an experienced research specialist with a talent for\n    finding relevant information from various sources. You excel at\n    organizing information in a clear and structured manner, making\n    complex topics accessible to others.\n  llm: openai/gpt-4o-mini\n\nanalyst:\n  role: >\n    Data Analyst and Report Writer for {topic}\n  goal: >\n    Analyze research findings and create a comprehensive, well-structured\n    report that presents insights in a clear and engaging way\n  backstory: >\n    You are a skilled analyst with a background in data interpretation\n    and technical writing. You have a talent for identifying patterns\n    and extracting meaningful insights from research data, then\n    communicating those insights effectively through well-crafted reports.\n  llm: openai/gpt-4o-mini\n```\n\n----------------------------------------\n\nTITLE: Using YAML Configuration in Python with CrewBase\nDESCRIPTION: Demonstrates how to implement a crew class that inherits from CrewBase to use YAML configurations, defining agents and tasks with decorators and creating the crew with the specified process.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# src/latest_ai_development/crew.py\n\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai.project import CrewBase, agent, crew, task\nfrom crewai_tools import SerperDevTool\n\n@CrewBase\nclass LatestAiDevelopmentCrew():\n  \"\"\"LatestAiDevelopment crew\"\"\"\n\n  @agent\n  def researcher(self) -> Agent:\n    return Agent(\n      config=self.agents_config['researcher'], # type: ignore[index]\n      verbose=True,\n      tools=[SerperDevTool()]\n    )\n\n  @agent\n  def reporting_analyst(self) -> Agent:\n    return Agent(\n      config=self.agents_config['reporting_analyst'], # type: ignore[index]\n      verbose=True\n    )\n\n  @task\n  def research_task(self) -> Task:\n    return Task(\n      config=self.tasks_config['research_task'] # type: ignore[index]\n    )\n\n  @task\n  def reporting_task(self) -> Task:\n    return Task(\n      config=self.tasks_config['reporting_task'] # type: ignore[index]\n    )\n\n  @crew\n  def crew(self) -> Crew:\n    return Crew(\n      agents=[\n        self.researcher(),\n        self.reporting_analyst()\n      ],\n      tasks=[\n        self.research_task(),\n        self.reporting_task()\n      ],\n      process=Process.sequential\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Embeddings in CrewAI\nDESCRIPTION: This example shows how to set up a Crew using OpenAI embeddings, which is the default provider. It demonstrates two ways to configure OpenAI embeddings: using a dictionary configuration and directly passing the OpenAIEmbeddingFunction.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"openai\",\n        \"config\": {\n            \"model\": 'text-embedding-3-small'\n        }\n    }\n)\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\nfrom chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"openai\",\n        \"config\": {\n            \"model\": 'text-embedding-3-small'\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Before and After Example: Research Agent Definition in CrewAI\nDESCRIPTION: A transformation example showing how to improve a basic research agent definition into a specialized academic research specialist with clear expertise and methodology.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nrole: \"Researcher\"\ngoal: \"Find information\"\nbackstory: \"You are good at finding information online.\"\n\nrole: \"Academic Research Specialist in Emerging Technologies\"\ngoal: \"Discover and synthesize cutting-edge research, identifying key trends, methodologies, and findings while evaluating the quality and reliability of sources\"\nbackstory: \"With a background in both computer science and library science, you've mastered the art of digital research. You've worked with research teams at prestigious universities and know how to navigate academic databases, evaluate research quality, and synthesize findings across disciplines. You're methodical in your approach, always cross-referencing information and tracing claims to primary sources before drawing conclusions.\"\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using SnowflakeSearchTool in CrewAI\nDESCRIPTION: Example of how to configure and use the SnowflakeSearchTool with a CrewAI Agent and Task. It demonstrates setting up the Snowflake configuration, initializing the tool, and creating an agent and task to query sales data.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/snowflakesearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import SnowflakeSearchTool, SnowflakeConfig\n\n# Create Snowflake configuration\nconfig = SnowflakeConfig(\n    account=\"your_account\",\n    user=\"your_username\",\n    password=\"your_password\",\n    warehouse=\"COMPUTE_WH\",\n    database=\"your_database\",\n    snowflake_schema=\"your_schema\"\n)\n\n# Initialize the tool\nsnowflake_tool = SnowflakeSearchTool(config=config)\n\n# Define an agent that uses the tool\ndata_analyst_agent = Agent(\n    role=\"Data Analyst\",\n    goal=\"Analyze data from Snowflake database\",\n    backstory=\"An expert data analyst who can extract insights from enterprise data.\",\n    tools=[snowflake_tool],\n    verbose=True,\n)\n\n# Example task to query sales data\nquery_task = Task(\n    description=\"Query the sales data for the last quarter and summarize the top 5 products by revenue.\",\n    expected_output=\"A summary of the top 5 products by revenue for the last quarter.\",\n    agent=data_analyst_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[data_analyst_agent], \n            tasks=[query_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Customizing LLM and Embeddings for CodeDocsSearchTool\nDESCRIPTION: Demonstrates how to customize the underlying language model and embeddings used by the CodeDocsSearchTool through a configuration dictionary, allowing integration with different providers like Ollama, Google, OpenAI, or Anthropic.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/codedocssearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = CodeDocsSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: State Design Best Practices\nDESCRIPTION: Example of broad vs. focused state design in CrewAI flows using Pydantic models.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Too broad\nclass BloatedState(BaseModel):\n    user_data: Dict = {}\n    system_settings: Dict = {}\n    temporary_calculations: List = []\n    debug_info: Dict = {}\n    # ...many more fields\n```\n\n----------------------------------------\n\nTITLE: Tailoring Agents to LLM Capabilities in CrewAI\nDESCRIPTION: Demonstrates how to specify different LLMs for agents based on their intended tasks and required capabilities using YAML in CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\n# For complex reasoning tasks\nanalyst:\n  role: \"Data Insights Analyst\"\n  goal: \"...\"\n  backstory: \"...\"\n  llm: openai/gpt-4o\n\n# For creative content\nwriter:\n  role: \"Creative Content Writer\"\n  goal: \"...\"\n  backstory: \"...\"\n  llm: anthropic/claude-3-opus\n```\n\n----------------------------------------\n\nTITLE: Implementing SpiderTool with CrewAI for web scraping\nDESCRIPTION: Python code example demonstrating how to use SpiderTool within a CrewAI setup. It creates an agent with the SpiderTool, defines a task to scrape a specific website, and executes the task using a Crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/spidertool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import SpiderTool\n\ndef main():\n    spider_tool = SpiderTool()\n\n    searcher = Agent(\n        role=\"Web Research Expert\",\n        goal=\"Find related information from specific URL's\",\n        backstory=\"An expert web researcher that uses the web extremely well\",\n        tools=[spider_tool],\n        verbose=True,\n    )\n\n    return_metadata = Task(\n        description=\"Scrape https://spider.cloud with a limit of 1 and enable metadata\",\n        expected_output=\"Metadata and 10 word summary of spider.cloud\",\n        agent=searcher\n    )\n\n    crew = Crew(\n        agents=[searcher],\n        tasks=[\n            return_metadata,\n        ],\n        verbose=2\n    )\n\n    crew.kickoff()\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Implementing Simple and Complex Flows with Unstructured and Structured State in Python\nDESCRIPTION: This example shows the difference between using unstructured state for a simple flow and structured state for a more complex flow. It includes a SimpleGreetingFlow with unstructured state and a RegistrationFlow with structured state using Pydantic.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Simple flow can use unstructured state\nclass SimpleGreetingFlow(Flow):\n    @start()\n    def greet(self):\n        self.state[\"name\"] = \"World\"\n        return f\"Hello, {self.state['name']}!\"\n\n# Complex flow benefits from structured state\nclass UserRegistrationState(BaseModel):\n    username: str\n    email: str\n    verification_status: bool = False\n    registration_date: datetime = Field(default_factory=datetime.now)\n    last_login: Optional[datetime] = None\n\nclass RegistrationFlow(Flow[UserRegistrationState]):\n    # Methods with strongly-typed state access\n```\n\n----------------------------------------\n\nTITLE: Implementing Rate Limiting for Custom LLM\nDESCRIPTION: A custom LLM implementation with rate limiting functionality to control API request frequency. Includes time-based request tracking and enforcement of requests per minute limit.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport time\nfrom typing import Any, Dict, List, Optional, Union\n\nclass RateLimitedLLM(BaseLLM):\n    def __init__(\n        self, \n        api_key: str, \n        endpoint: str, \n        requests_per_minute: int = 60\n    ):\n        super().__init__()\n        self.api_key = api_key\n        self.endpoint = endpoint\n        self.requests_per_minute = requests_per_minute\n        self.request_times: List[float] = []\n        \n    def call(\n        self,\n        messages: Union[str, List[Dict[str, str]]],\n        tools: Optional[List[dict]] = None,\n        callbacks: Optional[List[Any]] = None,\n        available_functions: Optional[Dict[str, Any]] = None,\n    ) -> Union[str, Any]:\n        self._enforce_rate_limit()\n        # Record this request time\n        self.request_times.append(time.time())\n        # Make the actual API call\n        return self._make_api_call(messages, tools)\n        \n    def _enforce_rate_limit(self) -> None:\n        now = time.time()\n        # Remove request times older than 1 minute\n        self.request_times = [t for t in self.request_times if now - t < 60]\n        \n        if len(self.request_times) >= self.requests_per_minute:\n            # Calculate how long to wait\n            oldest_request = min(self.request_times)\n            wait_time = 60 - (now - oldest_request)\n            if wait_time > 0:\n                time.sleep(wait_time)\n```\n\n----------------------------------------\n\nTITLE: Implementing JWT Authentication for Custom LLM\nDESCRIPTION: A custom LLM implementation that uses JWT-based authentication. Includes error handling, request timeout management, and support for function calling and stop words.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import BaseLLM, Agent, Task\nfrom typing import Any, Dict, List, Optional, Union\n\nclass JWTAuthLLM(BaseLLM):\n    def __init__(self, jwt_token: str, endpoint: str):\n        super().__init__()  # Initialize the base class to set default attributes\n        if not jwt_token or not isinstance(jwt_token, str):\n            raise ValueError(\"Invalid JWT token: must be a non-empty string\")\n        if not endpoint or not isinstance(endpoint, str):\n            raise ValueError(\"Invalid endpoint URL: must be a non-empty string\")\n        self.jwt_token = jwt_token\n        self.endpoint = endpoint\n        self.stop = []  # You can customize stop words if needed\n        \n    def call(\n        self,\n        messages: Union[str, List[Dict[str, str]]],\n        tools: Optional[List[dict]] = None,\n        callbacks: Optional[List[Any]] = None,\n        available_functions: Optional[Dict[str, Any]] = None,\n    ) -> Union[str, Any]:\n        import requests\n        \n        try:\n            headers = {\n                \"Authorization\": f\"Bearer {self.jwt_token}\",\n                \"Content-Type\": \"application/json\"\n            }\n            \n            if isinstance(messages, str):\n                messages = [{\"role\": \"user\", \"content\": messages}]\n            \n            data = {\n                \"messages\": messages,\n                \"tools\": tools\n            }\n            \n            response = requests.post(\n                self.endpoint,\n                headers=headers,\n                json=data,\n                timeout=30  # Set a reasonable timeout\n            )\n            \n            if response.status_code == 401:\n                raise ValueError(\"Authentication failed: Invalid JWT token\")\n            elif response.status_code == 403:\n                raise ValueError(\"Authorization failed: Insufficient permissions\")\n                \n            response.raise_for_status()  # Raise an exception for HTTP errors\n            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n        except requests.Timeout:\n            raise TimeoutError(\"LLM request timed out\")\n        except requests.RequestException as e:\n            raise RuntimeError(f\"LLM request failed: {str(e)}\")\n        except (KeyError, IndexError, ValueError) as e:\n            raise ValueError(f\"Invalid response format: {str(e)}\")\n        \n    def supports_function_calling(self) -> bool:\n        return True\n        \n    def supports_stop_words(self) -> bool:\n        return True\n        \n    def get_context_window_size(self) -> int:\n        return 8192\n```\n\n----------------------------------------\n\nTITLE: Creating Specialized Tool Users in CrewAI\nDESCRIPTION: Illustrates how to define an agent with specific tools and capabilities for data analysis tasks using YAML in CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\nrole: \"Data Analysis Specialist\"\ngoal: \"Derive meaningful insights from complex datasets through statistical analysis\"\nbackstory: \"With a background in data science, you excel at working with structured and unstructured data...\"\ntools: [PythonREPLTool, DataVisualizationTool, CSVAnalysisTool]\n```\n\n----------------------------------------\n\nTITLE: Improving Task Instructions in CrewAI\nDESCRIPTION: Shows the transformation of a vague task into a well-defined one with clear instructions and expected output using YAML in CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nresearch_task:\n  description: >\n    Research the top emerging AI trends for 2024 with a focus on:\n    1. Enterprise adoption patterns\n    2. Technical breakthroughs in the past 6 months\n    3. Regulatory developments affecting implementation\n\n    For each trend, identify key companies, technologies, and potential business impacts.\n  expected_output: >\n    A comprehensive markdown report with:\n    - Executive summary (5 bullet points)\n    - 5-7 major trends with supporting evidence\n    - For each trend: definition, examples, and business implications\n    - References to authoritative sources\n```\n\n----------------------------------------\n\nTITLE: Initializing GithubSearchTool for Dynamic Repository Search\nDESCRIPTION: Example of initializing the GithubSearchTool for dynamic repository searches, allowing the agent to search any repository it learns about during execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/githubsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the tool for semantic searches within a specific GitHub repository, so the agent can search any repository if it learns about during its execution\ntool = GithubSearchTool(\n\tgh_token='your_github_personal_access_token',\n\tcontent_types=['code', 'issue'] # Options: code, repo, pr, issue\n)\n```\n\n----------------------------------------\n\nTITLE: Chaining Multiple Validations in CrewAI\nDESCRIPTION: Implementation of a validation chain that combines multiple guardrail validators. Includes example usage with email and sensitive information validation.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndef chain_validations(*validators):\n    \"\"\"Chain multiple validators together.\"\"\"\n    def combined_validator(result):\n        for validator in validators:\n            success, data = validator(result)\n            if not success:\n                return (False, data)\n            result = data\n        return (True, result)\n    return combined_validator\n\n# Usage\ntask = Task(\n    description=\"Get user contact info\",\n    expected_output=\"Email and phone\",\n    guardrail=chain_validations(\n        validate_email_format,\n        filter_sensitive_info\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using SeleniumScrapingTool with CrewAI Agent\nDESCRIPTION: Example of how to initialize the SeleniumScrapingTool and use it with a CrewAI agent to scrape content from a website.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/seleniumscrapingtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew, Process\nfrom crewai_tools import SeleniumScrapingTool\n\n# Initialize the tool\nselenium_tool = SeleniumScrapingTool()\n\n# Define an agent that uses the tool\nweb_scraper_agent = Agent(\n    role=\"Web Scraper\",\n    goal=\"Extract information from websites using Selenium\",\n    backstory=\"An expert web scraper who can extract content from dynamic websites.\",\n    tools=[selenium_tool],\n    verbose=True,\n)\n\n# Example task to scrape content from a website\nscrape_task = Task(\n    description=\"Extract the main content from the homepage of example.com. Use the CSS selector 'main' to target the main content area.\",\n    expected_output=\"The main content from example.com's homepage.\",\n    agent=web_scraper_agent,\n)\n\n# Create and run the crew\ncrew = Crew(\n    agents=[web_scraper_agent],\n    tasks=[scrape_task],\n    verbose=True,\n    process=Process.sequential,\n)\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Class-Level State Persistence in CrewAI\nDESCRIPTION: Shows how to implement class-level state persistence using the @persist decorator to save state after every method execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, persist, start\nfrom pydantic import BaseModel\n\nclass CounterState(BaseModel):\n    value: int = 0\n\n@persist  # Apply to the entire flow class\nclass PersistentCounterFlow(Flow[CounterState]):\n    @start()\n    def increment(self):\n        self.state.value += 1\n        print(f\"Incremented to {self.state.value}\")\n        return self.state.value\n\n    @listen(increment)\n    def double(self, value):\n        self.state.value = value * 2\n        print(f\"Doubled to {self.state.value}\")\n        return self.state.value\n\n# First run\nflow1 = PersistentCounterFlow()\nresult1 = flow1.kickoff()\nprint(f\"First run result: {result1}\")\n\n# Second run - state is automatically loaded\nflow2 = PersistentCounterFlow()\nresult2 = flow2.kickoff()\nprint(f\"Second run result: {result2}\")  # Will be higher due to persisted state\n```\n\n----------------------------------------\n\nTITLE: Creating LlamaIndexTools from LlamaHub Tools\nDESCRIPTION: Example of initializing LlamaIndexTools from LlamaHub Tools, specifically using the WolframAlpha tool specification.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/llamaindextool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import LlamaIndexTool\nfrom llama_index.tools.wolfram_alpha import WolframAlphaToolSpec\n\n# Initialize from LlamaHub Tools\nwolfram_spec = WolframAlphaToolSpec(app_id=\"your_app_id\")\nwolfram_tools = wolfram_spec.to_tool_list()\ntools = [LlamaIndexTool.from_tool(t) for t in wolfram_tools]\n```\n\n----------------------------------------\n\nTITLE: Custom Memory Implementation with FAISS VectorDB\nDESCRIPTION: Shows how to implement custom memory instances using FAISS as the vector database, with specific configurations for long-term, short-term, and entity memory components.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Process\nfrom crewai.memory import LongTermMemory, ShortTermMemory, EntityMemory\nfrom crewai.memory.storage.rag_storage import RAGStorage\nfrom crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\nfrom typing import List, Optional\n\n# Assemble your crew with memory capabilities\nmy_crew: Crew = Crew(\n    agents = [...],\n    tasks = [...],\n    process = Process.sequential,\n    memory = True,\n    # Long-term memory for persistent storage across sessions\n    long_term_memory = LongTermMemory(\n        storage=LTMSQLiteStorage(\n            db_path=\"/my_crew1/long_term_memory_storage.db\"\n        )\n    ),\n    # Short-term memory for current context using RAG\n    short_term_memory = ShortTermMemory(\n        storage = RAGStorage(\n                embedder_config={\n                    \"provider\": \"openai\",\n                    \"config\": {\n                        \"model\": 'text-embedding-3-small'\n                    }\n                },\n                type=\"short_term\",\n                path=\"/my_crew1/\"\n            )\n        ),\n    ),\n    # Entity memory for tracking key information about entities\n    entity_memory = EntityMemory(\n        storage=RAGStorage(\n            embedder_config={\n                \"provider\": \"openai\",\n                \"config\": {\n                    \"model\": 'text-embedding-3-small'\n                }\n            },\n            type=\"short_term\",\n            path=\"/my_crew1/\"\n        )\n    ),\n    verbose=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Using CrewDoclingSource for Multiple File Formats in CrewAI\nDESCRIPTION: This example shows how to use the CrewDoclingSource to handle multiple file formats including MD, PDF, DOCX, and HTML. It sets up a knowledge source from web URLs, creates an agent with this knowledge, and executes a task using the crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM, Agent, Crew, Process, Task\nfrom crewai.knowledge.source.crew_docling_source import CrewDoclingSource\n\n# Create a knowledge source\ncontent_source = CrewDoclingSource(\n    file_paths=[\n        \"https://lilianweng.github.io/posts/2024-11-28-reward-hacking\",\n        \"https://lilianweng.github.io/posts/2024-07-07-hallucination\",\n    ],\n)\n\n# Create an LLM with a temperature of 0 to ensure deterministic outputs\nllm = LLM(model=\"gpt-4o-mini\", temperature=0)\n\n# Create an agent with the knowledge store\nagent = Agent(\n    role=\"About papers\",\n    goal=\"You know everything about the papers.\",\n    backstory=\"\"\"You are a master at understanding papers and their content.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    llm=llm,\n)\ntask = Task(\n    description=\"Answer the following questions about the papers: {question}\",\n    expected_output=\"An answer to the question.\",\n    agent=agent,\n)\n\ncrew = Crew(\n    agents=[agent],\n    tasks=[task],\n    verbose=True,\n    process=Process.sequential,\n    knowledge_sources=[\n        content_source\n    ],  # Enable knowledge by adding the sources here. You can also add more sources to the sources list.\n)\n\nresult = crew.kickoff(\n    inputs={\n        \"question\": \"What is the reward hacking paper about? Be sure to provide sources.\"\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Using ScrapeElementFromWebsiteTool for Specific Element Extraction in Python\nDESCRIPTION: Example demonstrating how to use the ScrapeElementFromWebsiteTool with a CrewAI agent to extract specific product titles from a website using a CSS selector.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapeelementfromwebsitetool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Example of using the tool with an agent\nweb_scraper_agent = Agent(\n    role=\"Web Scraper\",\n    goal=\"Extract specific elements from websites\",\n    backstory=\"An expert in web scraping who can extract targeted content using CSS selectors.\",\n    tools=[scrape_tool],\n    verbose=True,\n)\n\n# Create a task for the agent to extract specific elements\nextract_task = Task(\n    description=\"\"\"\n    Extract all product titles from the featured products section on example.com.\n    Use the CSS selector '.product-title' to target the title elements.\n    \"\"\",\n    expected_output=\"A list of product titles from the website\",\n    agent=web_scraper_agent,\n)\n\n# Run the task through a crew\ncrew = Crew(agents=[web_scraper_agent], tasks=[extract_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Creating a Listener Implementation in a Package Structure\nDESCRIPTION: Example showing how to define a custom listener class in a dedicated file within a listeners package, creating an instance at module level to ensure it's loaded properly.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# my_custom_listener.py\nfrom crewai.utilities.events.base_event_listener import BaseEventListener\n# ... import events ...\n\nclass MyCustomListener(BaseEventListener):\n    # ... implementation ...\n\n# Create an instance of your listener\nmy_custom_listener = MyCustomListener()\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Models and Embeddings for DirectorySearchTool\nDESCRIPTION: Advanced configuration example showing how to customize the tool with different LLM providers and embedding configurations.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/directorysearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = DirectorySearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # Options include ollama, google, anthropic, llama2, and more\n            config=dict(\n                model=\"llama2\",\n                # Additional configurations here\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Knowledge Parameters in CrewAI\nDESCRIPTION: This snippet shows how to configure knowledge parameters such as results limit and score threshold for an agent in CrewAI. These parameters control the number of relevant documents returned and the minimum relevance score for consideration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.knowledge.knowledge_config import KnowledgeConfig\n\nknowledge_config = KnowledgeConfig(results_limit=10, score_threshold=0.5)\n\nagent = Agent(\n    ...\n    knowledge_config=knowledge_config\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Agent with Code Execution Enabled\nDESCRIPTION: Example showing how to create a CrewAI agent with code execution enabled, which automatically adds the CodeInterpreterTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/codeinterpretertool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\n\n# Create an agent with code execution enabled\nprogrammer_agent = Agent(\n    role=\"Python Programmer\",\n    goal=\"Write and execute Python code to solve problems\",\n    backstory=\"An expert Python programmer who can write efficient code to solve complex problems.\",\n    allow_code_execution=True,  # This automatically adds the CodeInterpreterTool\n    verbose=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Advanced Guardrail Error Handling\nDESCRIPTION: Shows structured error handling implementation for task guardrails including specific error categories and validation chains. Includes type hints and comprehensive error handling.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import TaskOutput\n\ndef validate_with_context(result: TaskOutput) -> Tuple[bool, Any]:\n    try:\n        # Main validation logic\n        validated_data = perform_validation(result)\n        return (True, validated_data)\n    except ValidationError as e:\n        return (False, f\"VALIDATION_ERROR: {str(e)}\")\n    except Exception as e:\n        return (False, str(e))\n```\n\n----------------------------------------\n\nTITLE: Using S3ReaderTool with CrewAI Agent and Task\nDESCRIPTION: Example demonstrating how to initialize the S3ReaderTool, create an agent with the tool, define a task for reading from S3, and run the crew with inputs.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/s3readertool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools.aws.s3 import S3ReaderTool\n\n# Initialize the tool\ns3_reader_tool = S3ReaderTool()\n\n# Define an agent that uses the tool\nfile_reader_agent = Agent(\n    role=\"File Reader\",\n    goal=\"Read files from S3 buckets\",\n    backstory=\"An expert in retrieving and processing files from cloud storage.\",\n    tools=[s3_reader_tool],\n    verbose=True,\n)\n\n# Example task to read a configuration file\nread_task = Task(\n    description=\"Read the configuration file from {my_bucket} and summarize its contents.\",\n    expected_output=\"A summary of the configuration file contents.\",\n    agent=file_reader_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[file_reader_agent], tasks=[read_task])\nresult = crew.kickoff(inputs={\"my_bucket\": \"s3://my-bucket/config/app-config.json\"})\n```\n\n----------------------------------------\n\nTITLE: Implementation of ScrapeElementFromWebsiteTool in Python\nDESCRIPTION: The core implementation of the ScrapeElementFromWebsiteTool class, showing how it uses requests to fetch web pages and BeautifulSoup to parse and extract elements based on CSS selectors.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapeelementfromwebsitetool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass ScrapeElementFromWebsiteTool(BaseTool):\n    name: str = \"Read a website content\"\n    description: str = \"A tool that can be used to read a website content.\"\n    \n    # Implementation details...\n    \n    def _run(self, **kwargs: Any) -> Any:\n        website_url = kwargs.get(\"website_url\", self.website_url)\n        css_element = kwargs.get(\"css_element\", self.css_element)\n        page = requests.get(\n            website_url,\n            headers=self.headers,\n            cookies=self.cookies if self.cookies else {},\n        )\n        parsed = BeautifulSoup(page.content, \"html.parser\")\n        elements = parsed.select(css_element)\n        return \"\\n\".join([element.get_text() for element in elements])\n```\n\n----------------------------------------\n\nTITLE: Implementing Class-Level Persistence in CrewAI Flow (Python)\nDESCRIPTION: Demonstrates how to use the @persist decorator at the class level to enable automatic state persistence for all flow methods in a CrewAI Flow. This allows maintaining flow state across restarts or different workflow executions.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@persist  # Using SQLiteFlowPersistence by default\nclass MyFlow(Flow[MyState]):\n    @start()\n    def initialize_flow(self):\n        # This method will automatically have its state persisted\n        self.state.counter = 1\n        print(\"Initialized flow. State ID:\", self.state.id)\n\n    @listen(initialize_flow)\n    def next_step(self):\n        # The state (including self.state.id) is automatically reloaded\n        self.state.counter += 1\n        print(\"Flow state is persisted. Counter:\", self.state.counter)\n```\n\n----------------------------------------\n\nTITLE: Customizing YoutubeVideoSearchTool with Custom Model and Embeddings\nDESCRIPTION: Example demonstrating how to customize the YoutubeVideoSearchTool with specific LLM and embedder configurations using a config dictionary.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubevideosearchtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nyoutube_search_tool = YoutubeVideoSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Pre and Post Execution Hooks to CrewAI\nDESCRIPTION: This Python code adds optional before_kickoff and after_kickoff functions to the crew class, allowing for pre-processing of inputs and post-processing of results.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# src/latest_ai_development/crew.py\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai.project import CrewBase, agent, crew, task, before_kickoff, after_kickoff\nfrom crewai_tools import SerperDevTool\n\n@CrewBase\nclass LatestAiDevelopmentCrew():\n  \"\"\"LatestAiDevelopment crew\"\"\"\n\n  @before_kickoff\n  def before_kickoff_function(self, inputs):\n    print(f\"Before kickoff function with inputs: {inputs}\")\n    return inputs # You can return the inputs or modify them as needed\n\n  @after_kickoff\n  def after_kickoff_function(self, result):\n    print(f\"After kickoff function with result: {result}\")\n    return result # You can return the result or modify it as needed\n\n  # ... remaining code\n```\n\n----------------------------------------\n\nTITLE: Enabling Planning for a CrewAI Crew\nDESCRIPTION: This snippet demonstrates how to enable planning capabilities for a CrewAI Crew by setting planning=True when initializing the Crew object. This allows the crew to automatically plan tasks before execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/planning.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\n# Assemble your crew with planning capabilities\nmy_crew = Crew(\n    agents=self.agents,\n    tasks=self.tasks,\n    process=Process.sequential,\n    planning=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Integrating ApifyActorsTool with CrewAI Agent in Python\nDESCRIPTION: This code snippet shows how to integrate the ApifyActorsTool with a CrewAI Agent. It demonstrates setting up the tool and creating an agent that can use it for research tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/apifyactorstool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\nfrom crewai_tools import ApifyActorsTool\n\nrag_browser = ApifyActorsTool(actor_name=\"apify/rag-web-browser\")\n\nagent = Agent(\n    role=\"Research Analyst\",\n    goal=\"Find and summarize information about specific topics\",\n    backstory=\"You are an experienced researcher with attention to detail\",\n    tools=[rag_browser],\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Logging for State Changes in Python\nDESCRIPTION: This snippet demonstrates how to add logging to track state changes during flow execution. It includes a method to log the state after each step and uses Python's logging module.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\nclass LoggingFlow(Flow):\n    def log_state(self, step_name):\n        logging.info(f\"State after {step_name}: {self.state}\")\n\n    @start()\n    def initialize(self):\n        self.state[\"counter\"] = 0\n        self.log_state(\"initialize\")\n        return \"Initialized\"\n\n    @listen(initialize)\n    def increment(self, _):\n        self.state[\"counter\"] += 1\n        self.log_state(\"increment\")\n        return f\"Incremented to {self.state['counter']}\"\n```\n\n----------------------------------------\n\nTITLE: Customizing the Planning LLM in CrewAI\nDESCRIPTION: This snippet shows how to enable planning and specify a custom language model to use for planning tasks. The example uses gpt-4o as the planning LLM and includes the kickoff() method to start the crew execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/planning.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\n# Assemble your crew with planning capabilities and custom LLM\nmy_crew = Crew(\n    agents=self.agents,\n    tasks=self.tasks,\n    process=Process.sequential,\n    planning=True,\n    planning_llm=\"gpt-4o\"\n)\n\n# Run the crew\nmy_crew.kickoff()\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[2024-07-15 16:49:11][INFO]: Planning the crew execution\n**Step-by-Step Plan for Task Execution**\n\n**Task Number 1: Conduct a thorough research about AI LLMs**\n\n**Agent:** AI LLMs Senior Data Researcher\n\n**Agent Goal:** Uncover cutting-edge developments in AI LLMs\n\n**Task Expected Output:** A list with 10 bullet points of the most relevant information about AI LLMs\n\n**Task Tools:** None specified\n\n**Agent Tools:** None specified\n\n**Step-by-Step Plan:**\n\n1. **Define Research Scope:**\n\n   - Determine the specific areas of AI LLMs to focus on, such as advancements in architecture, use cases, ethical considerations, and performance metrics.\n\n2. **Identify Reliable Sources:**\n\n   - List reputable sources for AI research, including academic journals, industry reports, conferences (e.g., NeurIPS, ACL), AI research labs (e.g., OpenAI, Google AI), and online databases (e.g., IEEE Xplore, arXiv).\n\n3. **Collect Data:**\n\n   - Search for the latest papers, articles, and reports published in 2024 and early 2025.\n   - Use keywords like \"Large Language Models 2025\", \"AI LLM advancements\", \"AI ethics 2025\", etc.\n\n4. **Analyze Findings:**\n\n   - Read and summarize the key points from each source.\n   - Highlight new techniques, models, and applications introduced in the past year.\n\n5. **Organize Information:**\n\n   - Categorize the information into relevant topics (e.g., new architectures, ethical implications, real-world applications).\n   - Ensure each bullet point is concise but informative.\n\n6. **Create the List:**\n\n   - Compile the 10 most relevant pieces of information into a bullet point list.\n   - Review the list to ensure clarity and relevance.\n\n**Expected Output:**\n\nA list with 10 bullet points of the most relevant information about AI LLMs.\n\n---\n\n**Task Number 2: Review the context you got and expand each topic into a full section for a report**\n\n**Agent:** AI LLMs Reporting Analyst\n\n**Agent Goal:** Create detailed reports based on AI LLMs data analysis and research findings\n\n**Task Expected Output:** A fully fledged report with the main topics, each with a full section of information. Formatted as markdown without '```'\n\n**Task Tools:** None specified\n\n**Agent Tools:** None specified\n\n**Step-by-Step Plan:**\n\n1. **Review the Bullet Points:**\n   - Carefully read through the list of 10 bullet points provided by the AI LLMs Senior Data Researcher.\n\n2. **Outline the Report:**\n   - Create an outline with each bullet point as a main section heading.\n   - Plan sub-sections under each main heading to cover different aspects of the topic.\n\n3. **Research Further Details:**\n   - For each bullet point, conduct additional research if necessary to gather more detailed information.\n   - Look for case studies, examples, and statistical data to support each section.\n\n4. **Write Detailed Sections:**\n   - Expand each bullet point into a comprehensive section.\n   - Ensure each section includes an introduction, detailed explanation, examples, and a conclusion.\n   - Use markdown formatting for headings, subheadings, lists, and emphasis.\n\n5. **Review and Edit:**\n   - Proofread the report for clarity, coherence, and correctness.\n   - Make sure the report flows logically from one section to the next.\n   - Format the report according to markdown standards.\n\n6. **Finalize the Report:**\n   - Ensure the report is complete with all sections expanded and detailed.\n   - Double-check formatting and make any necessary adjustments.\n\n**Expected Output:**\nA fully fledged report with the main topics, each with a full section of information. Formatted as markdown without '```'.\n```\n\n----------------------------------------\n\nTITLE: SeleniumScrapingTool Implementation Details\nDESCRIPTION: The core implementation of the SeleniumScrapingTool class, showing how it uses Selenium WebDriver to automate browser interactions and extract content.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/seleniumscrapingtool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass SeleniumScrapingTool(BaseTool):\n    name: str = \"Read a website content\"\n    description: str = \"A tool that can be used to read a website content.\"\n    args_schema: Type[BaseModel] = SeleniumScrapingToolSchema\n    \n    def _run(self, **kwargs: Any) -> Any:\n        website_url = kwargs.get(\"website_url\", self.website_url)\n        css_element = kwargs.get(\"css_element\", self.css_element)\n        return_html = kwargs.get(\"return_html\", self.return_html)\n        driver = self._create_driver(website_url, self.cookie, self.wait_time)\n\n        content = self._get_content(driver, css_element, return_html)\n        driver.close()\n\n        return \"\\n\".join(content)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using TXTSearchTool in Python\nDESCRIPTION: Example of how to initialize the TXTSearchTool, either for searching within any text file's content or with a specific text file path provided.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/txtsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import TXTSearchTool\n\n# Initialize the tool to search within any text file's content \n# the agent learns about during its execution\ntool = TXTSearchTool()\n\n# OR\n\n# Initialize the tool with a specific text file, \n# so the agent can search within the given text file's content\ntool = TXTSearchTool(txt='path/to/text/file.txt')\n```\n\n----------------------------------------\n\nTITLE: Using a Multimodal Agent for Image Analysis in CrewAI\nDESCRIPTION: This example shows how to use a multimodal agent to analyze an image. It creates an agent, defines a task for image analysis, and runs the crew to perform the analysis.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/multimodal-agents.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\n\n# Create a multimodal agent\nimage_analyst = Agent(\n    role=\"Product Analyst\",\n    goal=\"Analyze product images and provide detailed descriptions\",\n    backstory=\"Expert in visual product analysis with deep knowledge of design and features\",\n    multimodal=True\n)\n\n# Create a task for image analysis\ntask = Task(\n    description=\"Analyze the product image at https://example.com/product.jpg and provide a detailed description\",\n    expected_output=\"A detailed description of the product image\",\n    agent=image_analyst\n)\n\n# Create and run the crew\ncrew = Crew(\n    agents=[image_analyst],\n    tasks=[task]\n)\n\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Model and Embeddings for CSVSearchTool\nDESCRIPTION: Example of customizing the CSVSearchTool with specific LLM and embedding providers. This allows for fine-tuning the tool's performance and capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/csvsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = CSVSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Method-Level Persistence in CrewAI Flow (Python)\nDESCRIPTION: Shows how to use the @persist decorator at the method level for granular control over state persistence in a CrewAI Flow. This approach allows persisting state for specific methods only.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass AnotherFlow(Flow[dict]):\n    @persist  # Persists only this method's state\n    @start()\n    def begin(self):\n        if \"runs\" not in self.state:\n            self.state[\"runs\"] = 0\n        self.state[\"runs\"] += 1\n        print(\"Method-level persisted runs:\", self.state[\"runs\"])\n```\n\n----------------------------------------\n\nTITLE: Performing a Custom Search with LinkupSearchTool\nDESCRIPTION: Advanced usage example showing how to perform a search with custom parameters using the LinkupSearchTool. It demonstrates setting specific query, depth, and output type values.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/linkupsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Perform a search with custom parameters\nresults = linkup_tool.run(\n    query=\"Women Nobel Prize Physics\",\n    depth=\"deep\",\n    output_type=\"searchResults\"\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Models and Embeddings for DOCXSearchTool\nDESCRIPTION: Example showing how to customize the language model and embeddings providers using a configuration dictionary\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/docxsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = DOCXSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM Class for OpenAI-Compatible Providers in Python\nDESCRIPTION: Shows how to set specific attributes on the LLM class for connecting to OpenAI-compatible LLMs, including model name, API key, and base URL.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/llm-connections.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"custom-model-name\",\n    api_key=\"your-api-key\",\n    base_url=\"https://api.your-provider.com/v1\"\n)\nagent = Agent(llm=llm, ...)\n```\n\n----------------------------------------\n\nTITLE: Monitoring CrewAI Agent with OpenLIT\nDESCRIPTION: Example of using OpenLIT to monitor a CrewAI Agent, including agent and task definitions, and crew setup.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/openlit-observability.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew, Process\nimport openlit\n\nopenlit.init(disable_metrics=True)\n# Define your agents\nresearcher = Agent(\n    role=\"Researcher\",\n    goal=\"Conduct thorough research and analysis on AI and AI agents\",\n    backstory=\"You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.\",\n    allow_delegation=False,\n    llm='command-r'\n)\n\n\n# Define your task\ntask = Task(\n    description=\"Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.\",\n    expected_output=\"5 bullet points, each with a paragraph and accompanying notes.\",\n)\n\n# Define the manager agent\nmanager = Agent(\n    role=\"Project Manager\",\n    goal=\"Efficiently manage the crew and ensure high-quality task completion\",\n    backstory=\"You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.\",\n    allow_delegation=True,\n    llm='command-r'\n)\n\n# Instantiate your crew with a custom manager\ncrew = Crew(\n    agents=[researcher],\n    tasks=[task],\n    manager_agent=manager,\n    process=Process.hierarchical,\n)\n\n# Start the crew's work\nresult = crew.kickoff()\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Creating Reporter Task in Python\nDESCRIPTION: Defines a task for the reporter agent to compile results from previous tasks. The task specifies its description, expected output, assigned agent, and output structure.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntask3 = Task(\n    description=\"Report the results of the tasks.\",\n    expected_output=\"A report of the results of the tasks. this is the code produced and then the links to the resources that can help with the coding task.\",\n    agent=reporter_agent,\n    output_json=Report,\n)\n```\n\n----------------------------------------\n\nTITLE: Including Purpose and Context in CrewAI Task Definitions\nDESCRIPTION: Illustrates how to provide context and purpose for a task, explaining its importance in the larger workflow using YAML in CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\ncompetitor_analysis_task:\n  description: >\n    Analyze our three main competitors' pricing strategies.\n    This analysis will inform our upcoming pricing model revision.\n    Focus on identifying patterns in how they price premium features\n    and how they structure their tiered offerings.\n```\n\n----------------------------------------\n\nTITLE: Custom Embedding Function Implementation\nDESCRIPTION: Example showing how to implement custom embeddings using a HuggingFace model instead of the default OpenAI embeddings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/qdrantvectorsearchtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\n\n# Load model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\nmodel = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n\ndef custom_embeddings(text: str) -> list[float]:\n    # Tokenize and get model outputs\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n    outputs = model(**inputs)\n    \n    # Use mean pooling to get text embedding\n    embeddings = outputs.last_hidden_state.mean(dim=1)\n    \n    # Convert to list of floats and return\n    return embeddings[0].tolist()\n\n# Use custom embeddings with the tool\ntool = QdrantVectorSearchTool(\n    qdrant_url=\"your_url\",\n    qdrant_api_key=\"your_key\",\n    collection_name=\"your_collection\",\n    custom_embedding_fn=custom_embeddings  # Pass your custom function\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using FileReadTool in Python\nDESCRIPTION: This snippet demonstrates how to import and initialize the FileReadTool. It shows two ways to create the tool: one for reading any file the agent knows about, and another for reading a specific file.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/filereadtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import FileReadTool\n\n# Initialize the tool to read any files the agents knows or lean the path for\nfile_read_tool = FileReadTool()\n\n# OR\n\n# Initialize the tool with a specific file path, so the agent can only read the content of the specified file\nfile_read_tool = FileReadTool(file_path='path/to/your/file.txt')\n```\n\n----------------------------------------\n\nTITLE: Advanced Multi-Agent Workflow with Session Management in Python\nDESCRIPTION: Demonstrates a complex scenario using multiple BedrockInvokeAgentTool instances with session management, creating a multi-stage workflow with different CrewAI agents.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bedrockinvokeagenttool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew, Process\nfrom crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool\n\n# Initialize tools with session management\ninitial_tool = BedrockInvokeAgentTool(\n    agent_id=\"your-agent-id\",\n    agent_alias_id=\"your-agent-alias-id\",\n    session_id=\"custom-session-id\"\n)\n\nfollowup_tool = BedrockInvokeAgentTool(\n    agent_id=\"your-agent-id\",\n    agent_alias_id=\"your-agent-alias-id\",\n    session_id=\"custom-session-id\"\n)\n\nfinal_tool = BedrockInvokeAgentTool(\n    agent_id=\"your-agent-id\",\n    agent_alias_id=\"your-agent-alias-id\",\n    session_id=\"custom-session-id\",\n    end_session=True\n)\n\n# Create agents for different stages\nresearcher = Agent(\n    role='AWS Service Researcher',\n    goal='Gather information about AWS services',\n    backstory='I am specialized in finding detailed AWS service information.',\n    tools=[initial_tool]\n)\n\nanalyst = Agent(\n    role='Service Compatibility Analyst',\n    goal='Analyze service compatibility and requirements',\n    backstory='I analyze AWS services for compatibility and integration possibilities.',\n    tools=[followup_tool]\n)\n\nsummarizer = Agent(\n    role='Technical Documentation Writer',\n    goal='Create clear technical summaries',\n    backstory='I specialize in creating clear, concise technical documentation.',\n    tools=[final_tool]\n)\n\n# Create tasks\nresearch_task = Task(\n    description=\"Find all available AWS services in us-west-2 region.\",\n    agent=researcher\n)\n\nanalysis_task = Task(\n    description=\"Analyze which services support IPv6 and their implementation requirements.\",\n    agent=analyst\n)\n\nsummary_task = Task(\n    description=\"Create a summary of IPv6-compatible services and their key features.\",\n    agent=summarizer\n)\n\n# Create a crew with the agents and tasks\ncrew = Crew(\n    agents=[researcher, analyst, summarizer],\n    tasks=[research_task, analysis_task, summary_task],\n    process=Process.sequential,\n    verbose=2\n)\n\n# Run the crew\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Models and Embeddings for PDFSearchTool\nDESCRIPTION: Example showing how to customize the PDFSearchTool with different LLM providers and embedding configurations.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/pdfsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = PDFSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: State Management in CrewAI Flows\nDESCRIPTION: Shows how state is managed across steps in a CrewAI flow. This snippet defines a Pydantic model for the flow's state, providing a type-safe way to track and transform data throughout the flow execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nclass GuideCreatorState(BaseModel):\n    topic: str = \"\"\n    audience_level: str = \"\"\n    guide_outline: GuideOutline = None\n    sections_content: Dict[str, str] = {}\n```\n\n----------------------------------------\n\nTITLE: State-Based Conditional Logic in CrewAI\nDESCRIPTION: Implements complex conditional logic using state management and routing in CrewAI flows.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, router, start\nfrom pydantic import BaseModel\n\nclass PaymentState(BaseModel):\n    amount: float = 0.0\n    is_approved: bool = False\n    retry_count: int = 0\n\nclass PaymentFlow(Flow[PaymentState]):\n    @start()\n    def process_payment(self):\n        # Simulate payment processing\n        self.state.amount = 100.0\n        self.state.is_approved = self.state.amount < 1000\n        return \"Payment processed\"\n\n    @router(process_payment)\n    def check_approval(self, previous_result):\n        if self.state.is_approved:\n            return \"approved\"\n        elif self.state.retry_count < 3:\n            return \"retry\"\n        else:\n            return \"rejected\"\n\n    @listen(\"approved\")\n    def handle_approval(self):\n        return f\"Payment of ${self.state.amount} approved!\"\n\n    @listen(\"retry\")\n    def handle_retry(self):\n        self.state.retry_count += 1\n        print(f\"Retrying payment (attempt {self.state.retry_count})...\")\n        # Could implement retry logic here\n        return \"Retry initiated\"\n\n    @listen(\"rejected\")\n    def handle_rejection(self):\n        return f\"Payment of ${self.state.amount} rejected after {self.state.retry_count} retries.\"\n```\n\n----------------------------------------\n\nTITLE: Initializing YoutubeVideoSearchTool with Specific URL\nDESCRIPTION: Example showing how to initialize the YoutubeVideoSearchTool with a specific YouTube video URL and create an agent to use it.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubevideosearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the tool with a specific YouTube video URL\nyoutube_search_tool = YoutubeVideoSearchTool(\n    youtube_video_url='https://youtube.com/watch?v=example'\n)\n\n# Define an agent that uses the tool\nvideo_researcher = Agent(\n    role=\"Video Researcher\",\n    goal=\"Extract relevant information from a specific YouTube video\",\n    backstory=\"An expert researcher who specializes in analyzing video content.\",\n    tools=[youtube_search_tool],\n    verbose=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Excel Knowledge Source in CrewAI\nDESCRIPTION: This snippet demonstrates how to create and use an Excel knowledge source in CrewAI. It shows the setup of the source with an Excel file and its integration with an agent or crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.knowledge.source.excel_knowledge_source import ExcelKnowledgeSource\n\n# Create an Excel knowledge source\nexcel_source = ExcelKnowledgeSource(\n    file_paths=[\"spreadsheet.xlsx\"]\n)\n\n# Create crew with Excel knowledge source on agents or crew level\nagent = Agent(\n    ...\n    knowledge_sources=[excel_source]\n)\n\ncrew = Crew(\n    ...\n    knowledge_sources=[excel_source]\n)\n```\n\n----------------------------------------\n\nTITLE: Direct LLM Call in Python using CrewAI\nDESCRIPTION: Illustrates how to make a direct call to a language model within a CrewAI flow. This snippet shows the creation of an LLM instance with a specific model and response format, and how to call it with messages.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(model=\"openai/gpt-4o-mini\", response_format=GuideOutline)\nresponse = llm.call(messages=messages)\n```\n\n----------------------------------------\n\nTITLE: Using SerperDevTool with Localization Parameters\nDESCRIPTION: This example demonstrates how to use SerperDevTool with localization parameters such as country, locale, and location to perform a search query in French.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/serperdevtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import SerperDevTool\n\ntool = SerperDevTool(\n    country=\"fr\",\n    locale=\"fr\",\n    location=\"Paris, Paris, Ile-de-France, France\",\n    n_results=2,\n)\n\nprint(tool.run(search_query=\"Jeux Olympiques\"))\n\n# Using Tool: Search the internet\n\n# Search results: Title: Jeux Olympiques de Paris 2024 - Actualits, calendriers, rsultats\n# Link: https://olympics.com/fr/paris-2024\n# Snippet: Quels sont les sports prsents aux Jeux Olympiques de Paris 2024 ?  Athltisme  Aviron  Badminton  Basketball  Basketball 3x3  Boxe  Breaking  Cano ...\n# ---\n# Title: Billetterie Officielle de Paris 2024 - Jeux Olympiques et Paralympiques\n# Link: https://tickets.paris2024.org/\n# Snippet: Achetez vos billets exclusivement sur le site officiel de la billetterie de Paris 2024 pour participer au plus grand vnement sportif au monde.\n# ---\n```\n\n----------------------------------------\n\nTITLE: Validating Input Parameters in Custom LLM Constructor\nDESCRIPTION: Shows how to validate input parameters in a custom LLM constructor to prevent runtime errors. This example checks that API key and endpoint URL are both valid non-empty strings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef __init__(self, api_key: str, endpoint: str):\n    super().__init__()\n    if not api_key or not isinstance(api_key, str):\n        raise ValueError(\"Invalid API key: must be a non-empty string\")\n    if not endpoint or not isinstance(endpoint, str):\n        raise ValueError(\"Invalid endpoint URL: must be a non-empty string\")\n    self.api_key = api_key\n    self.endpoint = endpoint\n```\n\n----------------------------------------\n\nTITLE: Method-Level State Persistence in CrewAI\nDESCRIPTION: Demonstrates method-level state persistence using the @persist decorator for granular control over state saving.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, persist, start\n\nclass SelectivePersistFlow(Flow):\n    @start()\n    def first_step(self):\n        self.state[\"count\"] = 1\n        return \"First step\"\n\n    @persist  # Only persist after this method\n    @listen(first_step)\n    def important_step(self, prev_result):\n        self.state[\"count\"] += 1\n        self.state[\"important_data\"] = \"This will be persisted\"\n        return \"Important step completed\"\n\n    @listen(important_step)\n    def final_step(self, prev_result):\n        self.state[\"count\"] += 1\n        return f\"Complete with count {self.state['count']}\"\n```\n\n----------------------------------------\n\nTITLE: Documenting State Transitions in Flow Methods using Python\nDESCRIPTION: This snippet demonstrates how to document state transitions within flow methods. It includes a method that initializes an order state and documents the before and after states in the method's docstring.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n@start()\ndef initialize_order(self):\n    \"\"\"\n    Initialize order state with empty values.\n\n    State before: {}\n    State after: {order_id: str, items: [], status: 'new'}\n    \"\"\"\n    self.state.order_id = str(uuid.uuid4())\n    self.state.items = []\n    self.state.status = \"new\"\n    return \"Order initialized\"\n```\n\n----------------------------------------\n\nTITLE: Integrating AIMindTool with CrewAI Agent\nDESCRIPTION: Example demonstrating how to integrate the AIMindTool with a CrewAI agent for data analysis tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/aimindtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\nfrom crewai.project import agent\nfrom crewai_tools import AIMindTool\n\n# Initialize the tool\naimind_tool = AIMindTool(\n    datasources=[\n        {\n            \"description\": \"sales data\",\n            \"engine\": \"postgres\",\n            \"connection_data\": {\n                \"user\": \"your_user\",\n                \"password\": \"your_password\",\n                \"host\": \"your_host\",\n                \"port\": 5432,\n                \"database\": \"your_db\",\n                \"schema\": \"your_schema\"\n            },\n            \"tables\": [\"sales\"]\n        }\n    ]\n)\n\n# Define an agent with the AIMindTool\n@agent\ndef data_analyst(self) -> Agent:\n    return Agent(\n        config=self.agents_config[\"data_analyst\"],\n        allow_delegation=False,\n        tools=[aimind_tool]\n    )\n```\n\n----------------------------------------\n\nTITLE: Integrating Crews in CrewAI Flows\nDESCRIPTION: Demonstrates how to integrate crews for complex collaborative tasks within a CrewAI flow. This snippet shows how to kickoff a crew with specific inputs, allowing for seamless combination of direct LLM calls and crew-based processing.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nresult = ContentCrew().crew().kickoff(inputs={\n    \"section_title\": section.title,\n    # ...\n})\n```\n\n----------------------------------------\n\nTITLE: Customizing GithubSearchTool Models and Embeddings\nDESCRIPTION: Example of how to customize the underlying models and embeddings used by the GithubSearchTool. It demonstrates setting custom providers and configurations for both the language model and embedder.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/githubsearchtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntool = GithubSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Using SnowflakeSearchTool with CrewAI Agent and Task\nDESCRIPTION: Detailed example of creating a CrewAI Agent with the SnowflakeSearchTool, defining a task for data analysis, and executing the task within a Crew. This showcases how to integrate the tool into a CrewAI workflow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/snowflakesearchtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Example of using the tool with an agent\ndata_analyst = Agent(\n    role=\"Data Analyst\",\n    goal=\"Analyze sales data from Snowflake\",\n    backstory=\"An expert data analyst with experience in SQL and data visualization.\",\n    tools=[snowflake_tool],\n    verbose=True\n)\n\n# The agent will use the tool with parameters like:\n# query=\"SELECT product_name, SUM(revenue) as total_revenue FROM sales GROUP BY product_name ORDER BY total_revenue DESC LIMIT 5\"\n# timeout=600\n\n# Create a task for the agent\nanalysis_task = Task(\n    description=\"Query the sales database and identify the top 5 products by revenue for the last quarter.\",\n    expected_output=\"A detailed analysis of the top 5 products by revenue.\",\n    agent=data_analyst\n)\n\n# Run the task\ncrew = Crew(\n    agents=[data_analyst], \n    tasks=[analysis_task]\n)\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Initializing ScrapegraphScrapeTool with Parameters\nDESCRIPTION: Example showing how to initialize the ScrapegraphScrapeTool with predefined parameters.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapegraphscrapetool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the tool with predefined parameters\nscrape_tool = ScrapegraphScrapeTool(\n    website_url=\"https://www.example.com\",\n    user_prompt=\"Extract all product prices and descriptions\",\n    api_key=\"your_api_key\"\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing CSV Knowledge Source in CrewAI\nDESCRIPTION: This example illustrates how to create and use a CSV knowledge source in CrewAI. It shows the setup of the source with a CSV file and its integration with an agent or crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.knowledge.source.csv_knowledge_source import CSVKnowledgeSource\n\n# Create a CSV knowledge source\ncsv_source = CSVKnowledgeSource(\n    file_paths=[\"data.csv\"]\n)\n\n# Create crew with CSV knowledge source or on agent level\nagent = Agent(\n    ...\n    knowledge_sources=[csv_source]\n)\n\ncrew = Crew(\n    ...\n    knowledge_sources=[csv_source]\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing NL2SQLTool and Creating an Agent in Python\nDESCRIPTION: Example of how to initialize the NL2SQLTool with a database URI and create an agent that uses this tool. The code demonstrates setting up a PostgreSQL connection and creating a researcher agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/nl2sqltool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import NL2SQLTool\n\n# psycopg2 was installed to run this example with PostgreSQL\nnl2sql = NL2SQLTool(db_uri=\"postgresql://example@localhost:5432/test_db\")\n\n@agent\ndef researcher(self) -> Agent:\n    return Agent(\n        config=self.agents_config[\"researcher\"],\n        allow_delegation=False,\n        tools=[nl2sql]\n    )\n```\n\n----------------------------------------\n\nTITLE: Using ScrapeElementFromWebsiteTool with CrewAI Agent in Python\nDESCRIPTION: Example demonstrating how to initialize the ScrapeElementFromWebsiteTool, create a CrewAI agent with the tool, and define a task for extracting headlines from a news website.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapeelementfromwebsitetool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import ScrapeElementFromWebsiteTool\n\n# Initialize the tool\nscrape_tool = ScrapeElementFromWebsiteTool()\n\n# Define an agent that uses the tool\nweb_scraper_agent = Agent(\n    role=\"Web Scraper\",\n    goal=\"Extract specific information from websites\",\n    backstory=\"An expert in web scraping who can extract targeted content from web pages.\",\n    tools=[scrape_tool],\n    verbose=True,\n)\n\n# Example task to extract headlines from a news website\nscrape_task = Task(\n    description=\"Extract the main headlines from the CNN homepage. Use the CSS selector '.headline' to target the headline elements.\",\n    expected_output=\"A list of the main headlines from CNN.\",\n    agent=web_scraper_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Initializing LinkupSearchTool and Creating a CrewAI Agent\nDESCRIPTION: Example of how to initialize the LinkupSearchTool with an API key and create a CrewAI agent that uses this tool. It demonstrates setting up the environment and defining an agent function.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/linkupsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import LinkupSearchTool\nfrom crewai import Agent\nimport os\n\n# Initialize the tool with your API key\nlinkup_tool = LinkupSearchTool(api_key=os.getenv(\"LINKUP_API_KEY\"))\n\n# Define an agent that uses the tool\n@agent\ndef researcher(self) -> Agent:\n    '''\n    This agent uses the LinkupSearchTool to retrieve contextual information\n    from the Linkup API.\n    '''\n    return Agent(\n        config=self.agents_config[\"researcher\"],\n        tools=[linkup_tool]\n    )\n```\n\n----------------------------------------\n\nTITLE: Integrating External Tools with CrewAI Tasks\nDESCRIPTION: Shows how to integrate external tools like SerperDevTool with CrewAI tasks for enhanced functionality. Includes environment setup and tool configuration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\n\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import SerperDevTool\n\nresearch_agent = Agent(\n  role='Researcher',\n  goal='Find and summarize the latest AI news',\n  backstory=\"\"\"You're a researcher at a large company.\n  You're responsible for analyzing data and providing insights\n  to the business.\"\"\",\n  verbose=True\n)\n\n# to perform a semantic search for a specified query from a text's content across the internet\nsearch_tool = SerperDevTool()\n\ntask = Task(\n  description='Find and summarize the latest AI news',\n  expected_output='A bullet list summary of the top 5 most important AI news',\n  agent=research_agent,\n  tools=[search_tool]\n)\n\ncrew = Crew(\n    agents=[research_agent],\n    tasks=[task],\n    verbose=True\n)\n\nresult = crew.kickoff()\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Advanced Task Configuration Example\nDESCRIPTION: Example of creating a task with specific scraping requirements including format conversion and proxy settings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapflyscrapetool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nadvanced_scrape_task = Task(\n    description=\"\"\"\n    Extract content from example.com with the following requirements:\n    - Convert the content to plain text format\n    - Enable JavaScript rendering\n    - Use a US-based proxy\n    - Handle any scraping failures gracefully\n    \"\"\",\n    expected_output=\"The extracted content from example.com\",\n    agent=web_scraper_agent,\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenTelemetry with Phoenix\nDESCRIPTION: Code to initialize the OpenInference OpenTelemetry instrumentation SDK for capturing traces and sending them to Phoenix.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/arize-phoenix-observability.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom phoenix.otel import register\n\ntracer_provider = register(\n    project_name=\"crewai-tracing-demo\",\n    auto_instrument=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Chunking for Knowledge Sources in CrewAI\nDESCRIPTION: This snippet demonstrates how to configure chunking behavior for knowledge sources in CrewAI. It shows how to set chunk size and overlap for optimizing content processing and retrieval accuracy.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n\nsource = StringKnowledgeSource(\n    content=\"Your content here\",\n    chunk_size=4000,      # Maximum size of each chunk (default: 4000)\n    chunk_overlap=200     # Overlap between chunks (default: 200)\n)\n```\n\n----------------------------------------\n\nTITLE: CrewAI Agent Integration with WeaviateVectorSearchTool\nDESCRIPTION: Example showing how to integrate the WeaviateVectorSearchTool with a CrewAI agent, including agent configuration and tool assignment.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/weaviatevectorsearchtool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\nfrom crewai_tools import WeaviateVectorSearchTool\n\n# Initialize the tool\nweaviate_tool = WeaviateVectorSearchTool(\n    collection_name='example_collections',\n    limit=3,\n    weaviate_cluster_url=\"https://your-weaviate-cluster-url.com\",\n    weaviate_api_key=\"your-weaviate-api-key\",\n)\n\n# Create an agent with the tool\nrag_agent = Agent(\n    name=\"rag_agent\",\n    role=\"You are a helpful assistant that can answer questions with the help of the WeaviateVectorSearchTool.\",\n    llm=\"gpt-4o-mini\",\n    tools=[weaviate_tool],\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Unstructured State Management in CrewAI Flow\nDESCRIPTION: This example demonstrates how to use unstructured state management in a CrewAI Flow. It shows initialization, modification, and access of state data across multiple flow methods.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\n\nclass UnstructuredStateFlow(Flow):\n    @start()\n    def initialize_data(self):\n        print(\"Initializing flow data\")\n        # Add key-value pairs to state\n        self.state[\"user_name\"] = \"Alex\"\n        self.state[\"preferences\"] = {\n            \"theme\": \"dark\",\n            \"language\": \"English\"\n        }\n        self.state[\"items\"] = []\n\n        # The flow state automatically gets a unique ID\n        print(f\"Flow ID: {self.state['id']}\")\n\n        return \"Initialized\"\n\n    @listen(initialize_data)\n    def process_data(self, previous_result):\n        print(f\"Previous step returned: {previous_result}\")\n\n        # Access and modify state\n        user = self.state[\"user_name\"]\n        print(f\"Processing data for {user}\")\n\n        # Add items to a list in state\n        self.state[\"items\"].append(\"item1\")\n        self.state[\"items\"].append(\"item2\")\n\n        # Add a new key-value pair\n        self.state[\"processed\"] = True\n\n        return \"Processed\"\n\n    @listen(process_data)\n    def generate_summary(self, previous_result):\n        # Access multiple state values\n        user = self.state[\"user_name\"]\n        theme = self.state[\"preferences\"][\"theme\"]\n        items = self.state[\"items\"]\n        processed = self.state.get(\"processed\", False)\n\n        summary = f\"User {user} has {len(items)} items with {theme} theme. \"\n        summary += \"Data is processed.\" if processed else \"Data is not processed.\"\n\n        return summary\n\n# Run the flow\nflow = UnstructuredStateFlow()\nresult = flow.kickoff()\nprint(f\"Final result: {result}\")\nprint(f\"Final state: {flow.state}\")\n```\n\n----------------------------------------\n\nTITLE: Forcing Tool Output as Result with CrewAI Agent\nDESCRIPTION: This code demonstrates how to create an agent with a custom tool where the tool's output is forced to be the task result by setting result_as_answer=True. This ensures the tool output is returned without any modifications by the agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/force-tool-output-as-result.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.agent import Agent\nfrom my_tool import MyCustomTool\n\n# Create a coding agent with the custom tool\ncoding_agent = Agent(\n        role=\"Data Scientist\",\n        goal=\"Produce amazing reports on AI\",\n        backstory=\"You work with data and AI\",\n        tools=[MyCustomTool(result_as_answer=True)],\n    )\n\n# Assuming the tool's execution and result population occurs within the system\ntask_result = coding_agent.execute_task(task)\n```\n\n----------------------------------------\n\nTITLE: Customizing MySQLSearchTool with Custom Model and Embeddings in Python\nDESCRIPTION: Example of how to customize the MySQLSearchTool by specifying custom models for language processing and embeddings, using providers like Ollama and Google.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/mysqltool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = MySQLSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\",\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Using the Custom Tool Adapter in an Agent Adapter in Python\nDESCRIPTION: This snippet demonstrates how to use the custom tool adapter within a custom agent adapter's configure_tools method to process and adapt tools for an external agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Inside MyCustomAgentAdapter.configure_tools\ndef configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:\n    if tools:\n        tool_adapter = MyCustomToolAdapter() # Instantiate your tool adapter\n        tool_adapter.configure_tools(tools)  # Convert the tools\n        adapted_tools = tool_adapter.tools() # Get the converted tools\n\n        # Now configure your external agent with the adapted_tools\n        # Example: self.external_agent.set_tools(adapted_tools)\n        print(f\"Configuring external agent with adapted tools: {adapted_tools}\") # Placeholder\n    else:\n        # Handle no tools case\n        print(\"No tools provided for MyCustomAgentAdapter.\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Local Mem0 Memory in CrewAI\nDESCRIPTION: This snippet demonstrates how to set up a Crew with local Mem0 memory using a custom configuration. It includes settings for vector store, LLM, embedder, graph store, and other memory-related parameters.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew\n\n#local mem0 config\nconfig = {\n    \"vector_store\": {\n        \"provider\": \"qdrant\",\n        \"config\": {\n            \"host\": \"localhost\",\n            \"port\": 6333\n        }\n    },\n    \"llm\": {\n        \"provider\": \"openai\",\n        \"config\": {\n            \"api_key\": \"your-api-key\",\n            \"model\": \"gpt-4\"\n        }\n    },\n    \"embedder\": {\n        \"provider\": \"openai\",\n        \"config\": {\n            \"api_key\": \"your-api-key\",\n            \"model\": \"text-embedding-3-small\"\n        }\n    },\n    \"graph_store\": {\n        \"provider\": \"neo4j\",\n        \"config\": {\n            \"url\": \"neo4j+s://your-instance\",\n            \"username\": \"neo4j\",\n            \"password\": \"password\"\n        }\n    },\n    \"history_db_path\": \"/path/to/history.db\",\n    \"version\": \"v1.1\",\n    \"custom_fact_extraction_prompt\": \"Optional custom prompt for fact extraction for memory\",\n    \"custom_update_memory_prompt\": \"Optional custom prompt for update memory\"\n}\n\ncrew = Crew(\n    agents=[...],\n    tasks=[...],\n    verbose=True,\n    memory=True,\n    memory_config={\n        \"provider\": \"mem0\",\n        \"config\": {\"user_id\": \"john\", 'local_mem0_config': config},\n        \"user_memory\" : {} #Set user_memory explicitly to a dictionary, we are working on this issue.\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Embedding Function in CrewAI\nDESCRIPTION: Demonstrates how to create and integrate a custom embedding function with CrewAI using the ChromaDB embedding interface.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\n\n# Create a custom embedding function\nclass CustomEmbedder(EmbeddingFunction):\n    def __call__(self, input: Documents) -> Embeddings:\n        # generate embeddings\n        return [1, 2, 3] # this is a dummy embedding\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"custom\",\n        \"config\": {\n            \"embedder\": CustomEmbedder()\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Structured Output Configuration in Python\nDESCRIPTION: Implementation of the configure_structured_output method to handle structured output requirements for the external agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef configure_structured_output(self, structured_output: Any) -> None:\n    # Configure your external agent to produce output in the specified format\n    # Example: self.external_agent.set_output_format(structured_output)\n    self.adapted_structured_output = True # Signal that structured output is handled\n    print(f\"Configuring structured output for MyCustomAgentAdapter: {structured_output}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Sensitive Information Filter in CrewAI\nDESCRIPTION: A guardrail function that checks for and filters sensitive information patterns. Returns a tuple with success status and either filtered content or error message.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef filter_sensitive_info(result: str) -> Tuple[bool, Union[str, str]]:\n    \"\"\"Remove or validate sensitive information.\"\"\"\n    sensitive_patterns = ['SSN:', 'password:', 'secret:']\n    for pattern in sensitive_patterns:\n        if pattern.lower() in result.lower():\n            return (False, f\"Output contains sensitive information ({pattern})\")\n    return (True, result)\n```\n\n----------------------------------------\n\nTITLE: Advanced WeaviateVectorSearchTool Configuration\nDESCRIPTION: Example showing advanced configuration of the WeaviateVectorSearchTool with custom vectorizer and generative model settings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/weaviatevectorsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import WeaviateVectorSearchTool\nfrom weaviate.classes.config import Configure\n\n# Setup custom model for vectorizer and generative model\ntool = WeaviateVectorSearchTool(\n    collection_name='example_collections',\n    limit=3,\n    vectorizer=Configure.Vectorizer.text2vec_openai(model=\"nomic-embed-text\"),\n    generative_model=Configure.Generative.openai(model=\"gpt-4o-mini\"),\n    weaviate_cluster_url=\"https://your-weaviate-cluster-url.com\",\n    weaviate_api_key=\"your-weaviate-api-key\",\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Before Kickoff Hook in CrewAI\nDESCRIPTION: This snippet demonstrates how to define a before kickoff function in a CrewAI implementation. The hook preprocesses or modifies inputs before the crew starts its tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/before-and-after-kickoff-hooks.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import CrewBase, before_kickoff\n\n@CrewBase\nclass MyCrew:\n    @before_kickoff\n    def prepare_data(self, inputs):\n        # Preprocess or modify inputs\n        inputs['processed'] = True\n        return inputs\n\n#...\n```\n\n----------------------------------------\n\nTITLE: Defining Research and Reporting Tasks in YAML\nDESCRIPTION: This YAML configuration specifies two tasks: a research task to gather information about a topic and a reporting task to create a comprehensive report based on the research findings. Each task is assigned to a specific agent and has defined outputs.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# src/latest_ai_development/config/tasks.yaml\nresearch_task:\n  description: >\n    Conduct a thorough research about {topic}\n    Make sure you find any interesting and relevant information given\n    the current year is 2025.\n  expected_output: >\n    A list with 10 bullet points of the most relevant information about {topic}\n  agent: researcher\n\nreporting_task:\n  description: >\n    Review the context you got and expand each topic into a full section for a report.\n    Make sure the report is detailed and contains any and all relevant information.\n  expected_output: >\n    A fully fledge reports with the mains topics, each with a full section of information.\n    Formatted as markdown without '```'\n  agent: reporting_analyst\n  output_file: report.md\n```\n\n----------------------------------------\n\nTITLE: Setting Manager LLM in CrewAI with Python\nDESCRIPTION: This code snippet shows how to set a specific language model for the manager in CrewAI when using the hierarchical process. It demonstrates creating an LLM instance and passing it to the Crew constructor as the manager_llm parameter.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-manager-agent.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM\n\nmanager_llm = LLM(model=\"gpt-4o\")\n\ncrew = Crew(\n    agents=[researcher, writer],\n    tasks=[task],\n    process=Process.hierarchical,\n    manager_llm=manager_llm\n)\n```\n\n----------------------------------------\n\nTITLE: Complete CrewAI Travel Planning Application with MLflow Tracing\nDESCRIPTION: Full example of a CrewAI implementation for a travel planning application with agents that select cities and provide local expertise, designed to be traced by MLflow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/mlflow-observability.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Task\nfrom crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\nfrom crewai_tools import SerperDevTool, WebsiteSearchTool\n\nfrom textwrap import dedent\n\ncontent = \"Users name is John. He is 30 years old and lives in San Francisco.\"\nstring_source = StringKnowledgeSource(\n    content=content, metadata={\"preference\": \"personal\"}\n)\n\nsearch_tool = WebsiteSearchTool()\n\n\nclass TripAgents:\n    def city_selection_agent(self):\n        return Agent(\n            role=\"City Selection Expert\",\n            goal=\"Select the best city based on weather, season, and prices\",\n            backstory=\"An expert in analyzing travel data to pick ideal destinations\",\n            tools=[\n                search_tool,\n            ],\n            verbose=True,\n        )\n\n    def local_expert(self):\n        return Agent(\n            role=\"Local Expert at this city\",\n            goal=\"Provide the BEST insights about the selected city\",\n            backstory=\"\"\"A knowledgeable local guide with extensive information\n        about the city, it's attractions and customs\"\"\",\n            tools=[search_tool],\n            verbose=True,\n        )\n\n\nclass TripTasks:\n    def identify_task(self, agent, origin, cities, interests, range):\n        return Task(\n            description=dedent(\n                f\"\"\"\n                Analyze and select the best city for the trip based\n                on specific criteria such as weather patterns, seasonal\n                events, and travel costs. This task involves comparing\n                multiple cities, considering factors like current weather\n                conditions, upcoming cultural or seasonal events, and\n                overall travel expenses.\n                Your final answer must be a detailed\n                report on the chosen city, and everything you found out\n                about it, including the actual flight costs, weather\n                forecast and attractions.\n\n                Traveling from: {origin}\n                City Options: {cities}\n                Trip Date: {range}\n                Traveler Interests: {interests}\n            \"\"\"\n            ),\n            agent=agent,\n            expected_output=\"Detailed report on the chosen city including flight costs, weather forecast, and attractions\",\n        )\n\n    def gather_task(self, agent, origin, interests, range):\n        return Task(\n            description=dedent(\n                f\"\"\"\n                As a local expert on this city you must compile an\n                in-depth guide for someone traveling there and wanting\n                to have THE BEST trip ever!\n                Gather information about key attractions, local customs,\n                special events, and daily activity recommendations.\n                Find the best spots to go to, the kind of place only a\n                local would know.\n                This guide should provide a thorough overview of what\n                the city has to offer, including hidden gems, cultural\n                hotspots, must-visit landmarks, weather forecasts, and\n                high level costs.\n                The final answer must be a comprehensive city guide,\n                rich in cultural insights and practical tips,\n                tailored to enhance the travel experience.\n\n                Trip Date: {range}\n                Traveling from: {origin}\n                Traveler Interests: {interests}\n            \"\"\"\n            ),\n            agent=agent,\n            expected_output=\"Comprehensive city guide including hidden gems, cultural hotspots, and practical travel tips\",\n        )\n\n\nclass TripCrew:\n    def __init__(self, origin, cities, date_range, interests):\n        self.cities = cities\n        self.origin = origin\n        self.interests = interests\n        self.date_range = date_range\n\n    def run(self):\n        agents = TripAgents()\n        tasks = TripTasks()\n\n        city_selector_agent = agents.city_selection_agent()\n        local_expert_agent = agents.local_expert()\n\n        identify_task = tasks.identify_task(\n            city_selector_agent,\n            self.origin,\n            self.cities,\n            self.interests,\n            self.date_range,\n        )\n        gather_task = tasks.gather_task(\n            local_expert_agent, self.origin, self.interests, self.date_range\n        )\n\n        crew = Crew(\n            agents=[city_selector_agent, local_expert_agent],\n            tasks=[identify_task, gather_task],\n            verbose=True,\n            memory=True,\n            knowledge={\n                \"sources\": [string_source],\n                \"metadata\": {\"preference\": \"personal\"},\n            },\n        )\n\n        result = crew.kickoff()\n        return result\n\n\ntrip_crew = TripCrew(\"California\", \"Tokyo\", \"Dec 12 - Dec 20\", \"sports\")\nresult = trip_crew.run()\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: YoutubeChannelSearchTool Class Implementation\nDESCRIPTION: Core implementation of the YoutubeChannelSearchTool class showing its structure and initialization logic\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubechannelsearchtool.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass YoutubeChannelSearchTool(RagTool):\n    name: str = \"Search a Youtube Channels content\"\n    description: str = \"A tool that can be used to semantic search a query from a Youtube Channels content.\"\n    args_schema: Type[BaseModel] = YoutubeChannelSearchToolSchema\n\n    def __init__(self, youtube_channel_handle: Optional[str] = None, **kwargs):\n        super().__init__(**kwargs)\n        if youtube_channel_handle is not None:\n            kwargs[\"data_type\"] = DataType.YOUTUBE_CHANNEL\n            self.add(youtube_channel_handle)\n            self.description = f\"A tool that can be used to semantic search a query the {youtube_channel_handle} Youtube Channels content.\"\n            self.args_schema = FixedYoutubeChannelSearchToolSchema\n            self._generate_description()\n\n    def add(\n        self,\n        youtube_channel_handle: str,\n        **kwargs: Any,\n    ) -> None:\n        if not youtube_channel_handle.startswith(\"@\"):\n            youtube_channel_handle = f\"@{youtube_channel_handle}\"\n        super().add(youtube_channel_handle, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Configuring Local NVIDIA NIM LLM with CrewAI\nDESCRIPTION: Sets up a local NVIDIA NIM LLM for use with CrewAI, demonstrating how to initialize the LLM and use it in a custom Crew class.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.llm import LLM\n\nlocal_nvidia_nim_llm = LLM(\n    model=\"openai/meta/llama-3.1-8b-instruct\", # it's an openai-api compatible model\n    base_url=\"http://localhost:8000/v1\",\n    api_key=\"<your_api_key|any text if you have not configured it>\", # api_key is required, but you can use any text\n)\n\n# Then you can use it in your crew:\n\n@CrewBase\nclass MyCrew():\n    # ...\n\n    @agent\n    def researcher(self) -> Agent:\n        return Agent(\n            config=self.agents_config['researcher'], # type: ignore[index]\n            llm=local_nvidia_nim_llm\n        )\n    \n    # ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Dependencies in CrewAI\nDESCRIPTION: Shows how to create dependent tasks where one task relies on the output of another using the context parameter. Demonstrates research and analysis task chain.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nresearch_task = Task(\n    description=\"Research the latest developments in AI\",\n    expected_output=\"A list of recent AI developments\",\n    agent=researcher\n)\n\nanalysis_task = Task(\n    description=\"Analyze the research findings and identify key trends\",\n    expected_output=\"Analysis report of AI trends\",\n    agent=analyst,\n    context=[research_task]  # This task will wait for research_task to complete\n)\n```\n\n----------------------------------------\n\nTITLE: Preloading Documents to Weaviate Database\nDESCRIPTION: Example demonstrating how to preload documents into a Weaviate database, including connection setup and batch document loading.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/weaviatevectorsearchtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom crewai_tools import WeaviateVectorSearchTool\nimport weaviate\nfrom weaviate.classes.init import Auth\n\n# Connect to Weaviate\nclient = weaviate.connect_to_weaviate_cloud(\n    cluster_url=\"https://your-weaviate-cluster-url.com\",\n    auth_credentials=Auth.api_key(\"your-weaviate-api-key\"),\n    headers={\"X-OpenAI-Api-Key\": \"your-openai-api-key\"}\n)\n\n# Get or create collection\ntest_docs = client.collections.get(\"example_collections\")\nif not test_docs:\n    test_docs = client.collections.create(\n        name=\"example_collections\",\n        vectorizer_config=Configure.Vectorizer.text2vec_openai(model=\"nomic-embed-text\"),\n        generative_config=Configure.Generative.openai(model=\"gpt-4o\"),\n    )\n\n# Load documents\ndocs_to_load = os.listdir(\"knowledge\")\nwith test_docs.batch.dynamic() as batch:\n    for d in docs_to_load:\n        with open(os.path.join(\"knowledge\", d), \"r\") as f:\n            content = f.read()\n        batch.add_object(\n            {\n                \"content\": content,\n                \"year\": d.split(\"_\")[0],\n            }\n        )\n\n# Initialize the tool\ntool = WeaviateVectorSearchTool(\n    collection_name='example_collections', \n    limit=3,\n    weaviate_cluster_url=\"https://your-weaviate-cluster-url.com\",\n    weaviate_api_key=\"your-weaviate-api-key\",\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Mistral LLM in CrewAI\nDESCRIPTION: This code demonstrates how to initialize a Mistral Language Model with specific parameters in a CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"mistral/mistral-large-latest\",\n    temperature=0.7\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing PatronusPredefinedCriteriaEvalTool in CrewAI\nDESCRIPTION: Example demonstrating the implementation of PatronusPredefinedCriteriaEvalTool with predefined evaluator and criteria for code generation tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/patronustools.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import PatronusPredefinedCriteriaEvalTool\n\n# Initialize the tool with predefined criteria\npatronus_eval_tool = PatronusPredefinedCriteriaEvalTool(\n    evaluators=[{\"evaluator\": \"judge\", \"criteria\": \"contains-code\"}]\n)\n\n# Define an agent that uses the tool\ncoding_agent = Agent(\n    role=\"Coding Agent\",\n    goal=\"Generate high quality code\",\n    backstory=\"An experienced coder who can generate high quality python code.\",\n    tools=[patronus_eval_tool],\n    verbose=True,\n)\n\n# Example task to generate code\ngenerate_code_task = Task(\n    description=\"Create a simple program to generate the first N numbers in the Fibonacci sequence.\",\n    expected_output=\"Program that generates the first N numbers in the Fibonacci sequence.\",\n    agent=coding_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[coding_agent], tasks=[generate_code_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Using FileWriterTool in Python\nDESCRIPTION: Example demonstrating how to initialize FileWriterTool and write content to a file in a specified directory. The tool handles directory creation and cross-platform compatibility automatically.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/filewritetool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import FileWriterTool\n\n# Initialize the tool\nfile_writer_tool = FileWriterTool()\n\n# Write content to a file in a specified directory\nresult = file_writer_tool._run('example.txt', 'This is a test content.', 'test_directory')\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Initializing Nvidia NIM LLM in CrewAI\nDESCRIPTION: This code demonstrates how to initialize a Nvidia NIM Language Model with specific parameters in a CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"nvidia_nim/meta/llama3-70b-instruct\",\n    temperature=0.7\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Model and Embeddings for XMLSearchTool\nDESCRIPTION: Example of how to customize the underlying model and embeddings used by XMLSearchTool, including options for different providers and model configurations.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/xmlsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = XMLSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Monitoring Async CrewAI Agent with OpenLIT\nDESCRIPTION: Example of using OpenLIT to monitor an asynchronous CrewAI Agent, including agent and task definitions, and asynchronous crew execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/openlit-observability.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crewai import Crew, Agent, Task\nimport openlit\n\nopenlit.init(otlp_endpoint=\"http://127.0.0.1:4318\")\n\n# Create an agent with code execution enabled\ncoding_agent = Agent(\n  role=\"Python Data Analyst\",\n  goal=\"Analyze data and provide insights using Python\",\n  backstory=\"You are an experienced data analyst with strong Python skills.\",\n  allow_code_execution=True,\n  llm=\"command-r\"\n)\n\n# Create a task that requires code execution\ndata_analysis_task = Task(\n  description=\"Analyze the given dataset and calculate the average age of participants. Ages: {ages}\",\n  agent=coding_agent,\n  expected_output=\"5 bullet points, each with a paragraph and accompanying notes.\",\n)\n\n# Create a crew and add the task\nanalysis_crew = Crew(\n  agents=[coding_agent],\n  tasks=[data_analysis_task]\n)\n\n# Async function to kickoff the crew asynchronously\nasync def async_crew_execution():\n    result = await analysis_crew.kickoff_async(inputs={\"ages\": [25, 30, 35, 40, 45]})\n    print(\"Crew Result:\", result)\n\n# Run the async function\nasyncio.run(async_crew_execution())\n```\n\n----------------------------------------\n\nTITLE: Implementing LangChain SearchTool in CrewAI\nDESCRIPTION: This code snippet demonstrates how to create a custom SearchTool using LangChain's GoogleSerperAPIWrapper and integrate it with a CrewAI Agent. It includes environment setup, tool definition, and agent creation.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/langchaintool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom dotenv import load_dotenv\nfrom crewai import Agent, Task, Crew\nfrom crewai.tools import BaseTool\nfrom pydantic import Field\nfrom langchain_community.utilities import GoogleSerperAPIWrapper\n\n# Set up your SERPER_API_KEY key in an .env file, eg:\n# SERPER_API_KEY=<your api key>\nload_dotenv()\n\nsearch = GoogleSerperAPIWrapper()\n\nclass SearchTool(BaseTool):\n    name: str = \"Search\"\n    description: str = \"Useful for search-based queries. Use this to find current information about markets, companies, and trends.\"\n    search: GoogleSerperAPIWrapper = Field(default_factory=GoogleSerperAPIWrapper)\n\n    def _run(self, query: str) -> str:\n        \"\"\"Execute the search query and return results\"\"\"\n        try:\n            return self.search.run(query)\n        except Exception as e:\n            return f\"Error performing search: {str(e)}\"\n\n# Create Agents\nresearcher = Agent(\n    role='Research Analyst',\n    goal='Gather current market data and trends',\n    backstory=\"\"\"You are an expert research analyst with years of experience in\n    gathering market intelligence. You're known for your ability to find\n    relevant and up-to-date market information and present it in a clear,\n    actionable format.\"\"\",\n    tools=[SearchTool()],\n    verbose=True\n)\n\n# rest of the code ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Agents for Content Writer Crew\nDESCRIPTION: YAML configuration that defines two specialized agents - a content writer and a content reviewer - with specific roles, goals, and backstories to create high-quality educational content.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# src/guide_creator_flow/crews/content_crew/config/agents.yaml\ncontent_writer:\n  role: >\n    Educational Content Writer\n  goal: >\n    Create engaging, informative content that thoroughly explains the assigned topic\n    and provides valuable insights to the reader\n  backstory: >\n    You are a talented educational writer with expertise in creating clear, engaging\n    content. You have a gift for explaining complex concepts in accessible language\n    and organizing information in a way that helps readers build their understanding.\n  llm: openai/gpt-4o-mini\n\ncontent_reviewer:\n  role: >\n    Educational Content Reviewer and Editor\n  goal: >\n    Ensure content is accurate, comprehensive, well-structured, and maintains\n    consistency with previously written sections\n  backstory: >\n    You are a meticulous editor with years of experience reviewing educational\n    content. You have an eye for detail, clarity, and coherence. You excel at\n    improving content while maintaining the original author's voice and ensuring\n    consistent quality across multiple sections.\n  llm: openai/gpt-4o-mini\n```\n\n----------------------------------------\n\nTITLE: Implementing configure_tools Method for Custom Tool Adapter in Python\nDESCRIPTION: This snippet demonstrates the implementation of the configure_tools method, which is responsible for converting CrewAI BaseTool instances into a format compatible with the external agent framework.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef configure_tools(self, tools: List[BaseTool]) -> None:\n    \"\"\"Configure and convert CrewAI tools for the specific implementation.\"\"\"\n    self.converted_tools = [] # Reset in case it's called multiple times\n    for tool in tools:\n        # Sanitize the tool name if required by the target framework\n        sanitized_name = self.sanitize_tool_name(tool.name)\n\n        # --- Your Conversion Logic Goes Here ---\n        # Example: Convert BaseTool to a dictionary format for LangGraph\n        # converted_tool = {\n        #     \"name\": sanitized_name,\n        #     \"description\": tool.description,\n        #     \"parameters\": tool.args_schema.schema() if tool.args_schema else {},\n        #     # Add any other framework-specific fields\n        # }\n\n        # Example: Convert BaseTool to an OpenAI function definition\n        # converted_tool = {\n        #     \"type\": \"function\",\n        #     \"function\": {\n        #         \"name\": sanitized_name,\n        #         \"description\": tool.description,\n        #         \"parameters\": tool.args_schema.schema() if tool.args_schema else {\"type\": \"object\", \"properties\": {}},\n        #     }\n        # }\n\n        # --- Replace above examples with your actual adaptation ---\n        converted_tool = self.adapt_tool_to_my_framework(tool, sanitized_name) # Placeholder\n\n        self.converted_tools.append(converted_tool)\n        print(f\"Adapted tool '{tool.name}' to '{sanitized_name}' for MyCustomToolAdapter\") # Placeholder\n\n    print(f\"MyCustomToolAdapter finished configuring tools: {len(self.converted_tools)} adapted.\") # Placeholder\n```\n\n----------------------------------------\n\nTITLE: Advanced S3WriterTool Configuration Example\nDESCRIPTION: Shows detailed usage of S3WriterTool with specific configuration file writing task and implementation\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/s3writertool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Example of using the tool with an agent\nfile_writer_agent = Agent(\n    role=\"File Writer\",\n    goal=\"Write content to files in S3 buckets\",\n    backstory=\"An expert in storing and managing files in cloud storage.\",\n    tools=[s3_writer_tool],\n    verbose=True,\n)\n\n# Create a task for the agent to write a specific file\nwrite_config_task = Task(\n    description=\"\"\"\n    Create a configuration file with the following database settings:\n    - host: db.example.com\n    - port: 5432\n    - username: app_user\n    - password: secure_password\n    \n    Save this configuration as JSON to {my_bucket}.\n    \"\"\",\n    expected_output=\"Confirmation that the configuration file was successfully saved to S3.\",\n    agent=file_writer_agent,\n)\n\n# Run the task\ncrew = Crew(agents=[file_writer_agent], tasks=[write_config_task])\nresult = crew.kickoff(inputs={\"my_bucket\": \"s3://my-bucket/config/db-config.json\"})\n```\n\n----------------------------------------\n\nTITLE: Basic WeaviateVectorSearchTool Implementation\nDESCRIPTION: Example showing how to initialize the WeaviateVectorSearchTool and create a search agent with it. Demonstrates basic tool configuration with required parameters.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/weaviatevectorsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import WeaviateVectorSearchTool\n\n# Initialize the tool\ntool = WeaviateVectorSearchTool(\n    collection_name='example_collections',\n    limit=3,\n    weaviate_cluster_url=\"https://your-weaviate-cluster-url.com\",\n    weaviate_api_key=\"your-weaviate-api-key\",\n)\n\n@agent\ndef search_agent(self) -> Agent:\n    '''\n    This agent uses the WeaviateVectorSearchTool to search for \n    semantically similar documents in a Weaviate vector database.\n    '''\n    return Agent(\n        config=self.agents_config[\"search_agent\"],\n        tools=[tool]\n    )\n```\n\n----------------------------------------\n\nTITLE: Using S3ReaderTool in a Specific Task\nDESCRIPTION: Example showing how to create an agent with S3ReaderTool and define a task for reading a specific configuration file from S3.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/s3readertool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Example of using the tool with an agent\nfile_reader_agent = Agent(\n    role=\"File Reader\",\n    goal=\"Read files from S3 buckets\",\n    backstory=\"An expert in retrieving and processing files from cloud storage.\",\n    tools=[s3_reader_tool],\n    verbose=True,\n)\n\n# Create a task for the agent to read a specific file\nread_config_task = Task(\n    description=\"Read the application configuration file from {my_bucket} and extract the database connection settings.\",\n    expected_output=\"The database connection settings from the configuration file.\",\n    agent=file_reader_agent,\n)\n\n# Run the task\ncrew = Crew(agents=[file_reader_agent], tasks=[read_config_task])\nresult = crew.kickoff(inputs={\"my_bucket\": \"s3://my-bucket/config/app-config.json\"})\n```\n\n----------------------------------------\n\nTITLE: Filtering Tools by Tags\nDESCRIPTION: Example of filtering GitHub tools based on specific tags\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntag = \"users\"\n\nfiltered_action_enums = toolset.find_actions_by_tags(\n    App.GITHUB,\n    tags=[tag], \n)\n\ntools = toolset.get_tools(actions=filtered_action_enums)\n```\n\n----------------------------------------\n\nTITLE: Defining Focused Tasks in YAML for CrewAI\nDESCRIPTION: Demonstrates how to create focused, single-purpose tasks with clear descriptions and expected outputs using YAML syntax in CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n# Task 1\nresearch_task:\n  description: \"Research the top 5 market trends in the AI industry for 2024.\"\n  expected_output: \"A markdown list of the 5 trends with supporting evidence.\"\n\n# Task 2\nanalysis_task:\n  description: \"Analyze the identified trends to determine potential business impacts.\"\n  expected_output: \"A structured analysis with impact ratings (High/Medium/Low).\"\n\n# Task 3\nvisualization_task:\n  description: \"Create a visual representation of the analyzed trends.\"\n  expected_output: \"A description of a chart showing trends and their impact ratings.\"\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM Client with Portkey\nDESCRIPTION: Setup code for initializing an LLM client using Portkey's gateway and authentication. Requires Portkey API key and Virtual key for secure LLM API key management.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/portkey-observability.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM\nfrom portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n\ngpt_llm = LLM(\n    model=\"gpt-4\",\n    base_url=PORTKEY_GATEWAY_URL,\n    api_key=\"dummy\", # We are using Virtual key\n    extra_headers=createHeaders(\n        api_key=\"YOUR_PORTKEY_API_KEY\",\n        virtual_key=\"YOUR_VIRTUAL_KEY\", # Enter your Virtual key from Portkey\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Loading Google Cloud Credentials for Vertex AI in CrewAI\nDESCRIPTION: Demonstrates how to load Google Cloud credentials from a JSON file for use with Vertex AI in a CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nfile_path = 'path/to/vertex_ai_service_account.json'\n\n# Load the JSON file\nwith open(file_path, 'r') as file:\n    vertex_credentials = json.load(file)\n\n# Convert the credentials to a JSON string\nvertex_credentials_json = json.dumps(vertex_credentials)\n```\n\n----------------------------------------\n\nTITLE: Complex State Transformations in CrewAI\nDESCRIPTION: Shows how to handle complex state transformations with dedicated helper methods and Pydantic models.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\nfrom pydantic import BaseModel\nfrom typing import List, Dict\n\nclass UserData(BaseModel):\n    name: str\n    active: bool = True\n    login_count: int = 0\n\nclass ComplexState(BaseModel):\n    users: Dict[str, UserData] = {}\n    active_user_count: int = 0\n\nclass TransformationFlow(Flow[ComplexState]):\n    @start()\n    def initialize(self):\n        # Add some users\n        self.add_user(\"alice\", \"Alice\")\n        self.add_user(\"bob\", \"Bob\")\n        self.add_user(\"charlie\", \"Charlie\")\n        return \"Initialized\"\n\n    @listen(initialize)\n    def process_users(self, _):\n        # Increment login counts\n        for user_id in self.state.users:\n            self.increment_login(user_id)\n\n        # Deactivate one user\n        self.deactivate_user(\"bob\")\n\n        # Update active count\n        self.update_active_count()\n\n        return f\"Processed {len(self.state.users)} users\"\n\n    # Helper methods for state transformations\n    def add_user(self, user_id: str, name: str):\n        self.state.users[user_id] = UserData(name=name)\n        self.update_active_count()\n\n    def increment_login(self, user_id: str):\n        if user_id in self.state.users:\n            self.state.users[user_id].login_count += 1\n\n    def deactivate_user(self, user_id: str):\n        if user_id in self.state.users:\n            self.state.users[user_id].active = False\n            self.update_active_count()\n\n    def update_active_count(self):\n        self.state.active_user_count = sum(\n            1 for user in self.state.users.values() if user.active\n        )\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Callbacks in CrewAI\nDESCRIPTION: Shows how to implement callback functions for tasks to handle post-completion actions and notifications.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef callback_function(output: TaskOutput):\n    # Do something after the task is completed\n    # Example: Send an email to the manager\n    print(f\"\"\"\n        Task completed!\n        Task: {output.description}\n        Output: {output.raw}\n    \"\"\")\n\nresearch_task = Task(\n    description='Find and summarize the latest AI news',\n    expected_output='A bullet list summary of the top 5 most important AI news',\n    agent=research_agent,\n    tools=[search_tool],\n    callback=callback_function\n)\n```\n\n----------------------------------------\n\nTITLE: Processing Crew Results in Flow State\nDESCRIPTION: Shows how to process and store crew execution results in flow state with error handling.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@listen(execute_crew)\ndef process_crew_results(self, _):\n    # Parse the raw results (assuming JSON output)\n    import json\n    try:\n        results_dict = json.loads(self.state.raw_results)\n        self.state.processed_results = {\n            \"title\": results_dict.get(\"title\", \"\"),\n            \"main_points\": results_dict.get(\"main_points\", []),\n            \"conclusion\": results_dict.get(\"conclusion\", \"\")\n        }\n        return \"Results processed successfully\"\n    except json.JSONDecodeError:\n        self.state.error = \"Failed to parse crew results as JSON\"\n        return \"Error processing results\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Caching for Tools in Python\nDESCRIPTION: Illustrates how to implement a custom caching mechanism for tools in CrewAI. This example shows a multiplication tool with a cache function that only caches results that are multiples of 2, demonstrating fine-grained control over caching behavior.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tools.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.tools import tool\n\n@tool\ndef multiplication_tool(first_number: int, second_number: int) -> str:\n    \"\"\"Useful for when you need to multiply two numbers together.\"\"\"\n    return first_number * second_number\n\ndef cache_func(args, result):\n    # In this case, we only cache the result if it's a multiple of 2\n    cache = result % 2 == 0\n    return cache\n\nmultiplication_tool.cache_function = cache_func\n\nwriter1 = Agent(\n        role=\"Writer\",\n        goal=\"You write lessons of math for kids.\",\n        backstory=\"You're an expert in writing and you love to teach kids but you know nothing of math.\",\n        tools=[multiplication_tool],\n        allow_delegation=False,\n    )\n    #...\n```\n\n----------------------------------------\n\nTITLE: Generating Plot for CrewAI Flow using Python\nDESCRIPTION: Python code to generate an interactive HTML plot of a CrewAI flow. This method is used when working directly with a flow instance.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Assuming you have a flow instance\nflow.plot(\"my_flow_plot\")\n```\n\n----------------------------------------\n\nTITLE: Configuring a Long-Running Analysis Agent with Rate Limiting\nDESCRIPTION: Setting up an agent optimized for extended data analysis operations with API rate limiting and memory features. Uses a more efficient model for function calling to reduce costs.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/agents.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nanalysis_agent = Agent(\n    role=\"Data Analyst\",\n    goal=\"Perform deep analysis of large datasets\",\n    backstory=\"Specialized in big data analysis and pattern recognition\",\n    memory=True,\n    respect_context_window=True,\n    max_rpm=10,  # Limit API calls\n    function_calling_llm=\"gpt-4o-mini\"  # Cheaper model for tool calls\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up and Executing CrewAI Workflow in Python\nDESCRIPTION: Creates a CrewAI crew with the defined agents and tasks, then executes the workflow with a specific input. The result is processed and displayed based on its structure.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Use in CrewAI\ncrew = Crew(\n    agents=[code_helper_agent, link_finder_agent, reporter_agent],\n    tasks=[task, task2, task3],\n    verbose=True,\n)\n\nresult = crew.kickoff(\n    inputs={\"task\": \"How do you implement an abstract class in python?\"}\n)\n\n# Print raw result first\nprint(\"Raw result:\", result)\n\n# Handle result based on its type\nif hasattr(result, \"json_dict\") and result.json_dict:\n    json_result = result.json_dict\n    print(\"\\nStructured JSON result:\")\n    print(f\"{json.dumps(json_result, indent=2)}\")\n\n    # Access fields safely\n    if isinstance(json_result, dict):\n        if \"code\" in json_result:\n            print(\"\\nCode:\")\n            print(\n                json_result[\"code\"][:200] + \"...\"\n                if len(json_result[\"code\"]) > 200\n                else json_result[\"code\"]\n            )\n\n        if \"links\" in json_result:\n            print(\"\\nLinks:\")\n            for link in json_result[\"links\"][:5]:  # Print first 5 links\n                print(f\"- {link}\")\n            if len(json_result[\"links\"]) > 5:\n                print(f\"...and {len(json_result['links']) - 5} more links\")\nelif hasattr(result, \"pydantic\") and result.pydantic:\n    print(\"\\nPydantic model result:\")\n    print(result.pydantic.model_dump_json(indent=2))\nelse:\n    # Fallback to raw output\n    print(\"\\nNo structured result available, using raw output:\")\n    print(result.raw[:500] + \"...\" if len(result.raw) > 500 else result.raw)\n```\n\n----------------------------------------\n\nTITLE: Directory Creation for File Output in CrewAI\nDESCRIPTION: Example of configuring a task to automatically create directories when saving output files, useful for organizing task results in specific folder structures.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nsave_output_task = Task(\n    description='Save the summarized AI news to a file',\n    expected_output='File saved successfully',\n    agent=research_agent,\n    tools=[file_save_tool],\n    output_file='outputs/ai_news_summary.txt',\n    create_directory=True\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Research Tasks in YAML\nDESCRIPTION: YAML configuration specifying the research and analysis tasks with detailed instructions and expected outputs\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/crews/first-crew.mdx#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nresearch_task:\n  description: >\n    Conduct thorough research on {topic}. Focus on:\n    1. Key concepts and definitions\n    2. Historical development and recent trends\n    3. Major challenges and opportunities\n    4. Notable applications or case studies\n    5. Future outlook and potential developments\n\n    Make sure to organize your findings in a structured format with clear sections.\n  expected_output: >\n    A comprehensive research document with well-organized sections covering\n    all the requested aspects of {topic}. Include specific facts, figures,\n    and examples where relevant.\n  agent: researcher\n\nanalysis_task:\n  description: >\n    Analyze the research findings and create a comprehensive report on {topic}.\n    Your report should:\n    1. Begin with an executive summary\n    2. Include all key information from the research\n    3. Provide insightful analysis of trends and patterns\n    4. Offer recommendations or future considerations\n    5. Be formatted in a professional, easy-to-read style with clear headings\n  expected_output: >\n    A polished, professional report on {topic} that presents the research\n    findings with added analysis and insights. The report should be well-structured\n    with an executive summary, main sections, and conclusion.\n  agent: analyst\n  context:\n    - research_task\n  output_file: output/report.md\n```\n\n----------------------------------------\n\nTITLE: Initializing SageMaker LLM in CrewAI\nDESCRIPTION: This snippet demonstrates how to initialize a Language Model using a SageMaker endpoint in a CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"sagemaker/<my-endpoint>\"\n)\n```\n\n----------------------------------------\n\nTITLE: Running Basic CrewAI Test with Default Parameters\nDESCRIPTION: Execute a basic test of your crew using the built-in CLI command with default settings (2 iterations using gpt-4o-mini model).\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/testing.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncrewai test\n```\n\n----------------------------------------\n\nTITLE: Accessing CrewAI Usage Metrics\nDESCRIPTION: This snippet demonstrates how to access the usage metrics of a CrewAI crew after execution. It provides insights into the language model usage for all tasks executed by the crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/crews.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Access the crew's usage metrics\ncrew = Crew(agents=[agent1, agent2], tasks=[task1, task2])\ncrew.kickoff()\nprint(crew.usage_metrics)\n```\n\n----------------------------------------\n\nTITLE: Environment Variable Based Memory Configuration\nDESCRIPTION: Demonstrates secure memory configuration using environment variables for storage paths and database credentials.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom crewai import Crew\nfrom crewai.memory import LongTermMemory\nfrom crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n\n# Configure storage path using environment variable\nstorage_path = os.getenv(\"CREWAI_STORAGE_DIR\", \"./storage\")\ncrew = Crew(\n    memory=True,\n    long_term_memory=LongTermMemory(\n        storage=LTMSQLiteStorage(\n            db_path=\"{storage_path}/memory.db\".format(storage_path=storage_path)\n        )\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing PatronusEvalTool in CrewAI\nDESCRIPTION: Example showing how to initialize and use PatronusEvalTool with a CrewAI agent to generate and evaluate Fibonacci sequence code. This tool allows agents to select appropriate evaluators and criteria.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/patronustools.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import PatronusEvalTool\n\n# Initialize the tool\npatronus_eval_tool = PatronusEvalTool()\n\n# Define an agent that uses the tool\ncoding_agent = Agent(\n    role=\"Coding Agent\",\n    goal=\"Generate high quality code and verify that the output is code\",\n    backstory=\"An experienced coder who can generate high quality python code.\",\n    tools=[patronus_eval_tool],\n    verbose=True,\n)\n\n# Example task to generate and evaluate code\ngenerate_code_task = Task(\n    description=\"Create a simple program to generate the first N numbers in the Fibonacci sequence. Select the most appropriate evaluator and criteria for evaluating your output.\",\n    expected_output=\"Program that generates the first N numbers in the Fibonacci sequence.\",\n    agent=coding_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[coding_agent], tasks=[generate_code_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Replaying a Task Programmatically in Python\nDESCRIPTION: Function to replay a specific task programmatically with error handling. This approach allows specifying both the task ID and optional input parameters for the replay process.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/replay-tasks-from-latest-crew-kickoff.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef replay():\n    \"\"\"\n    Replay the crew execution from a specific task.\n    \"\"\"\n    task_id = '<task_id>'\n    inputs = {\"topic\": \"CrewAI Training\"}  # This is optional; you can pass in the inputs you want to replay; otherwise, it uses the previous kickoff's inputs.\n    try:\n        YourCrewName_Crew().crew().replay(task_id=task_id, inputs=inputs)\n\n    except subprocess.CalledProcessError as e:\n        raise Exception(f\"An error occurred while replaying the crew: {e}\")\n\n    except Exception as e:\n        raise Exception(f\"An unexpected error occurred: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Handling Authentication Errors in Custom LLM\nDESCRIPTION: Demonstrates how to handle authentication and authorization errors gracefully in a custom LLM implementation. This code detects specific HTTP status codes and raises appropriate exceptions with clear error messages.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef call(\n    self,\n    messages: Union[str, List[Dict[str, str]]],\n    tools: Optional[List[dict]] = None,\n    callbacks: Optional[List[Any]] = None,\n    available_functions: Optional[Dict[str, Any]] = None,\n) -> Union[str, Any]:\n    try:\n        response = requests.post(self.endpoint, headers=self.headers, json=data)\n        if response.status_code == 401:\n            raise ValueError(\"Authentication failed: Invalid API key or token\")\n        elif response.status_code == 403:\n            raise ValueError(\"Authorization failed: Insufficient permissions\")\n        response.raise_for_status()\n        # Process response\n    except Exception as e:\n        # Handle error\n        raise\n```\n\n----------------------------------------\n\nTITLE: Configuring SnowflakeSearchTool with Key-Pair Authentication\nDESCRIPTION: Example of setting up the SnowflakeConfig with key-pair authentication instead of password authentication. This demonstrates an alternative, more secure method of connecting to Snowflake.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/snowflakesearchtool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconfig = SnowflakeConfig(\n    account=\"your_account\",\n    user=\"your_username\",\n    private_key_path=\"/path/to/your/private/key.p8\",\n    warehouse=\"COMPUTE_WH\",\n    database=\"your_database\",\n    snowflake_schema=\"your_schema\"\n)\n```\n\n----------------------------------------\n\nTITLE: Handling Flow Output and Results\nDESCRIPTION: Shows how to retrieve and handle the final output from a CrewAI Flow, demonstrating the basic pattern of method chaining and result handling.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\n\nclass OutputExampleFlow(Flow):\n    @start()\n    def first_method(self):\n        return \"Output from first_method\"\n\n    @listen(first_method)\n    def second_method(self, first_output):\n        return f\"Second method received: {first_output}\"\n\n\nflow = OutputExampleFlow()\nfinal_output = flow.kickoff()\n\nprint(\"---- Final Output ----\")\nprint(final_output)\n```\n\n----------------------------------------\n\nTITLE: Basic Tool Usage with CrewAI Agent\nDESCRIPTION: Example showing basic usage of the ScrapflyScrapeWebsiteTool with a CrewAI Agent and Task setup.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapflyscrapetool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nweb_scraper_agent = Agent(\n    role=\"Web Scraper\",\n    goal=\"Extract information from websites\",\n    backstory=\"An expert in web scraping who can extract content from any website.\",\n    tools=[scrape_tool],\n    verbose=True,\n)\n\nscrape_task = Task(\n    description=\"Extract the main content from example.com in markdown format.\",\n    expected_output=\"The main content of example.com in markdown format.\",\n    agent=web_scraper_agent,\n)\n\ncrew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: LlamaIndexTool Class Method: from_query_engine\nDESCRIPTION: Class method signature for creating a LlamaIndexTool from a LlamaIndex query engine. Shows method parameters including optional ones and return type.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/llamaindextool.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@classmethod\ndef from_query_engine(\n    cls,\n    query_engine: Any,\n    name: Optional[str] = None,\n    description: Optional[str] = None,\n    return_direct: bool = False,\n    **kwargs: Any,\n) -> \"LlamaIndexTool\":\n    # Implementation details\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM with Custom Settings in Python\nDESCRIPTION: Shows how to use the LLM class for more detailed configuration of the language model, including setting the model, temperature, base URL, and API key.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/llm-connections.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, LLM\n\nllm = LLM(\n    model=\"gpt-4\",\n    temperature=0.7,\n    base_url=\"https://api.openai.com/v1\",\n    api_key=\"your-api-key-here\"\n)\n\nagent = Agent(\n    role='Customized LLM Expert',\n    goal='Provide tailored responses',\n    backstory=\"An AI assistant with custom LLM settings.\",\n    llm=llm\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Langtrace with CrewAI\nDESCRIPTION: Code snippet showing how to import and initialize Langtrace before using CrewAI modules. Requires a Langtrace API key obtained from the signup process.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/langtrace-observability.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom langtrace_python_sdk import langtrace\nlangtrace.init(api_key='<LANGTRACE_API_KEY>')\n\n# Now import CrewAI modules\nfrom crewai import Agent, Task, Crew\n```\n\n----------------------------------------\n\nTITLE: Advanced Mem0 Configuration with Organization Settings\nDESCRIPTION: Demonstrates advanced Mem0 integration with organization and project-specific settings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew\n\ncrew = Crew(\n    agents=[...],\n    tasks=[...],\n    verbose=True,\n    memory=True,\n    memory_config={\n        \"provider\": \"mem0\",\n        \"config\": {\"user_id\": \"john\", \"org_id\": \"my_org_id\", \"project_id\": \"my_project_id\"},\n        \"user_memory\" : {} #Set user_memory explicitly to a dictionary, we are working on this issue.\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Scoped Event Handlers in Python\nDESCRIPTION: Example of using scoped handlers for temporary event handling in CrewAI, useful for testing or specific operations. The handler only exists within the context manager's scope.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.utilities.events import crewai_event_bus, CrewKickoffStartedEvent\n\nwith crewai_event_bus.scoped_handlers():\n    @crewai_event_bus.on(CrewKickoffStartedEvent)\n    def temp_handler(source, event):\n        print(\"This handler only exists within this context\")\n\n    # Do something that emits events\n\n# Outside the context, the temporary handler is removed\n```\n\n----------------------------------------\n\nTITLE: Custom Storage Path Configuration\nDESCRIPTION: Demonstrates how to configure custom storage paths for memory systems using SQLite storage.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew\nfrom crewai.memory import LongTermMemory\nfrom crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n\n# Configure custom storage paths\ncrew = Crew(\n    memory=True,\n    long_term_memory=LongTermMemory(\n        storage=LTMSQLiteStorage(db_path=\"./memory.db\")\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring DallETool with Custom Parameters in Python\nDESCRIPTION: Advanced example showing how to initialize the DallETool with custom parameters for the DALL-E model, such as model version, image size, quality, and number of images to generate.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/dalletool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import DallETool\n\ndalle_tool = DallETool(model=\"dall-e-3\",\n                       size=\"1024x1024\",\n                       quality=\"standard\",\n                       n=1)\n\nAgent(\n    ...\n    tools=[dalle_tool]\n)\n```\n\n----------------------------------------\n\nTITLE: Agent Usage with Error Handling\nDESCRIPTION: Example demonstrating how to create a task with error handling instructions for the scraping agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapegraphscrapetool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create a task that includes error handling instructions\nrobust_extract_task = Task(\n    description=\"\"\"\n    Extract the main heading from example.com.\n    Be aware that you might encounter errors such as:\n    - Invalid URL format\n    - Missing API key\n    - Rate limit exceeded\n    - Network or API errors\n    \n    If you encounter any errors, provide a clear explanation of what went wrong\n    and suggest possible solutions.\n    \"\"\",\n    expected_output=\"Either the extracted heading or a clear error explanation\",\n    agent=web_scraper_agent,\n)\n```\n\n----------------------------------------\n\nTITLE: Handling Streaming Events from LLM in Python\nDESCRIPTION: This snippet demonstrates how to handle streaming events from an LLM in CrewAI. It defines a custom event handler class and registers it to process chunks of streamed data.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_39\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM\nfrom crewai.utilities.events import EventHandler, LLMStreamChunkEvent\n\nclass MyEventHandler(EventHandler):\n    def on_llm_stream_chunk(self, event: LLMStreamChunkEvent):\n        # Process each chunk as it arrives\n        print(f\"Received chunk: {event.chunk}\")\n\n# Register the event handler\nfrom crewai.utilities.events import crewai_event_bus\ncrewai_event_bus.register_handler(MyEventHandler())\n```\n\n----------------------------------------\n\nTITLE: Implementing Error Handling for State Access in Python\nDESCRIPTION: This example shows how to implement error handling when accessing state values that might not exist. It uses a try-except block to catch AttributeError and KeyError, providing a default value and logging the error.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n@listen(previous_step)\ndef process_data(self, _):\n    try:\n        # Try to access a value that might not exist\n        user_preference = self.state.preferences.get(\"theme\", \"default\")\n    except (AttributeError, KeyError):\n        # Handle the error gracefully\n        self.state.errors = self.state.get(\"errors\", [])\n        self.state.errors.append(\"Failed to access preferences\")\n        user_preference = \"default\"\n\n    return f\"Used preference: {user_preference}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Google AI Embeddings in CrewAI\nDESCRIPTION: This example shows how to set up a Crew using Google AI embeddings. It includes the necessary configuration for the Google AI provider, including API key and model selection. Prerequisites for using Google AI embeddings are also mentioned.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"google\",\n        \"config\": {\n            \"api_key\": \"<YOUR_API_KEY>\",\n            \"model\": \"<model_name>\"\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: LinkupSearchTool Successful Response Format\nDESCRIPTION: JSON structure representing the format of a successful response from the LinkupSearchTool. It includes a success flag and an array of result objects with name, URL, and content.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/linkupsearchtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"success\": true,\n  \"results\": [\n    {\n      \"name\": \"Result Title\",\n      \"url\": \"https://example.com/result\",\n      \"content\": \"Content of the result...\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring CrewAI Crew Logging\nDESCRIPTION: This snippet shows how to configure logging for CrewAI crew execution. It demonstrates different ways to specify the output log file, including using boolean values and custom file names.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/crews.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Save crew logs\ncrew = Crew(output_log_file = True)  # Logs will be saved as logs.txt\ncrew = Crew(output_log_file = file_name)  # Logs will be saved as file_name.txt\ncrew = Crew(output_log_file = file_name.txt)  # Logs will be saved as file_name.txt\ncrew = Crew(output_log_file = file_name.json)  # Logs will be saved as file_name.json\n```\n\n----------------------------------------\n\nTITLE: Basic QdrantVectorSearchTool Implementation\nDESCRIPTION: Minimal example showing how to initialize and use the QdrantVectorSearchTool with a CrewAI agent. Uses OpenAI embeddings by default and returns the 3 most relevant results with scores above 0.35.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/qdrantvectorsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\nfrom crewai_tools import QdrantVectorSearchTool\n\n# Initialize the tool\nqdrant_tool = QdrantVectorSearchTool(\n    qdrant_url=\"your_qdrant_url\",\n    qdrant_api_key=\"your_qdrant_api_key\",\n    collection_name=\"your_collection\"\n)\n\n# Create an agent that uses the tool\nagent = Agent(\n    role=\"Research Assistant\",\n    goal=\"Find relevant information in documents\",\n    tools=[qdrant_tool]\n)\n\n# The tool will automatically use OpenAI embeddings\n# and return the 3 most relevant results with scores > 0.35\n```\n\n----------------------------------------\n\nTITLE: Setting Up Anthropic Environment Variables for CrewAI\nDESCRIPTION: Configures the necessary environment variables for using Anthropic's LLMs with CrewAI, including the API key and optional custom base URL.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n# Required\nANTHROPIC_API_KEY=sk-ant-...\n\n# Optional\nANTHROPIC_API_BASE=<custom-base-url>\n```\n\n----------------------------------------\n\nTITLE: Crew Integration with State Management\nDESCRIPTION: Demonstrates how to integrate crew execution with flow state management for research tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\nfrom crewai import Agent, Crew, Process, Task\nfrom pydantic import BaseModel\n\nclass ResearchState(BaseModel):\n    topic: str = \"\"\n    depth: str = \"medium\"\n    results: str = \"\"\n\nclass ResearchFlow(Flow[ResearchState]):\n    @start()\n    def get_parameters(self):\n        # In a real app, this might come from user input\n        self.state.topic = \"Artificial Intelligence Ethics\"\n        self.state.depth = \"deep\"\n        return \"Parameters set\"\n\n    @listen(get_parameters)\n    def execute_research(self, _):\n        # Create agents\n        researcher = Agent(\n            role=\"Research Specialist\",\n            goal=f\"Research {self.state.topic} in {self.state.depth} detail\",\n            backstory=\"You are an expert researcher with a talent for finding accurate information.\"\n        )\n\n        writer = Agent(\n            role=\"Content Writer\",\n            goal=\"Transform research into clear, engaging content\",\n            backstory=\"You excel at communicating complex ideas clearly and concisely.\"\n        )\n\n        # Create tasks\n        research_task = Task(\n            description=f\"Research {self.state.topic} with {self.state.depth} analysis\",\n            expected_output=\"Comprehensive research notes in markdown format\",\n            agent=researcher\n        )\n\n        writing_task = Task(\n            description=f\"Create a summary on {self.state.topic} based on the research\",\n            expected_output=\"Well-written article in markdown format\",\n            agent=writer,\n            context=[research_task]\n        )\n\n        # Create and run crew\n        research_crew = Crew(\n            agents=[researcher, writer],\n            tasks=[research_task, writing_task],\n            process=Process.sequential,\n            verbose=True\n        )\n\n        # Run crew and store result in state\n        result = research_crew.kickoff()\n        self.state.results = result.raw\n\n        return \"Research completed\"\n\n    @listen(execute_research)\n    def summarize_results(self, _):\n        # Access the stored results\n        result_length = len(self.state.results)\n        return f\"Research on {self.state.topic} completed with {result_length} characters of results.\"\n```\n\n----------------------------------------\n\nTITLE: Basic YouTube Channel Search Implementation\nDESCRIPTION: Example showing how to initialize and use the YoutubeChannelSearchTool with a CrewAI agent and task\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubechannelsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import YoutubeChannelSearchTool\n\n# Initialize the tool for general YouTube channel searches\nyoutube_channel_tool = YoutubeChannelSearchTool()\n\n# Define an agent that uses the tool\nchannel_researcher = Agent(\n    role=\"Channel Researcher\",\n    goal=\"Extract relevant information from YouTube channels\",\n    backstory=\"An expert researcher who specializes in analyzing YouTube channel content.\",\n    tools=[youtube_channel_tool],\n    verbose=True,\n)\n\n# Example task to search for information in a specific channel\nresearch_task = Task(\n    description=\"Search for information about machine learning tutorials in the YouTube channel {youtube_channel_handle}\",\n    expected_output=\"A summary of the key machine learning tutorials available on the channel.\",\n    agent=channel_researcher,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[channel_researcher], tasks=[research_task])\nresult = crew.kickoff(inputs={\"youtube_channel_handle\": \"@exampleChannel\"})\n```\n\n----------------------------------------\n\nTITLE: Creating the Main Entry Point with Custom Inputs\nDESCRIPTION: This Python script serves as the main entry point for running the crew. It demonstrates how to pass custom inputs (such as the research topic) to the crew for dynamic execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n#!/usr/bin/env python\n# src/latest_ai_development/main.py\nimport sys\nfrom latest_ai_development.crew import LatestAiDevelopmentCrew\n\ndef run():\n  \"\"\"\n  Run the crew.\n  \"\"\"\n  inputs = {\n    'topic': 'AI Agents'\n  }\n  LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)\n```\n\n----------------------------------------\n\nTITLE: Initializing GithubSearchTool for Specific Repository Search\nDESCRIPTION: Example of how to initialize the GithubSearchTool for semantic searches within a specific GitHub repository. It demonstrates setting the repository URL, GitHub token, and content types to search.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/githubsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import GithubSearchTool\n\n# Initialize the tool for semantic searches within a specific GitHub repository\ntool = GithubSearchTool(\n\tgithub_repo='https://github.com/example/repo',\n\tgh_token='your_github_personal_access_token',\n\tcontent_types=['code', 'issue'] # Options: code, repo, pr, issue\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Caching for Tools in Python\nDESCRIPTION: Illustrates how to define a custom caching strategy for a tool using the cache_function attribute. This optimization technique can improve tool performance by reducing redundant computations.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/create-custom-tools.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@tool(\"Tool with Caching\")\ndef cached_tool(argument: str) -> str:\n    \"\"\"Tool functionality description.\"\"\"\n    return \"Cacheable result\"\n\ndef my_cache_strategy(arguments: dict, result: str) -> bool:\n    # Define custom caching logic\n    return True if some_condition else False\n\ncached_tool.cache_function = my_cache_strategy\n```\n\n----------------------------------------\n\nTITLE: Initializing Anthropic LLM in CrewAI\nDESCRIPTION: Shows how to initialize an Anthropic LLM in a CrewAI project, specifying the model and temperature.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"anthropic/claude-3-sonnet-20240229-v1:0\",\n    temperature=0.7\n)\n```\n\n----------------------------------------\n\nTITLE: Creating an Agent with Custom Templates for Specialized Interactions\nDESCRIPTION: Configuring an agent with custom system, prompt, and response templates to control interaction format. This approach allows for fine-tuning how the agent processes inputs and formats responses.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/agents.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncustom_agent = Agent(\n    role=\"Customer Service Representative\",\n    goal=\"Assist customers with their inquiries\",\n    backstory=\"Experienced in customer support with a focus on satisfaction\",\n    system_template=\"\"\"<|start_header_id|>system<|end_header_id|>\n                        {{ .System }}<|eot_id|>\"\"\",\n    prompt_template=\"\"\"<|start_header_id|>user<|end_header_id|>\n                        {{ .Prompt }}<|eot_id|>\"\"\",\n    response_template=\"\"\"<|start_header_id|>assistant<|end_header_id|>\n                        {{ .Response }}<|eot_id|>\"\"\",\n)\n```\n\n----------------------------------------\n\nTITLE: Customizing SnowflakeSearchTool Parameters\nDESCRIPTION: Example of initializing the SnowflakeSearchTool with custom parameters for connection pooling, retries, and caching. This demonstrates how to fine-tune the tool's behavior for specific use cases.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/snowflakesearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the tool with custom parameters\nsnowflake_tool = SnowflakeSearchTool(\n    config=config,\n    pool_size=10,\n    max_retries=5,\n    retry_delay=2.0,\n    enable_caching=True\n)\n```\n\n----------------------------------------\n\nTITLE: Running the CrewAI Project\nDESCRIPTION: Command to execute the CrewAI project, initializing the AI crew and starting the defined workflow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/flow/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncrewai run\n```\n\n----------------------------------------\n\nTITLE: Initializing PGSearchTool with Database Connection\nDESCRIPTION: Example showing how to initialize PGSearchTool by providing database URI and table name for semantic search operations.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/pgsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import PGSearchTool\n\n# Initialize the tool with the database URI and the target table name\ntool = PGSearchTool(\n    db_uri='postgresql://user:password@localhost:5432/mydatabase', \n    table_name='employees'\n)\n```\n\n----------------------------------------\n\nTITLE: Using SerperDevTool with Custom Parameters\nDESCRIPTION: This example shows how to initialize SerperDevTool with custom parameters such as search URL and number of results, and then perform a search query.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/serperdevtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import SerperDevTool\n\ntool = SerperDevTool(\n    search_url=\"https://google.serper.dev/scholar\",\n    n_results=2,\n)\n\nprint(tool.run(search_query=\"ChatGPT\"))\n\n# Using Tool: Search the internet\n\n# Search results: Title: Role of chat gpt in public health\n# Link: https://link.springer.com/article/10.1007/s10439-023-03172-7\n# Snippet:  ChatGPT in public health. In this overview, we will examine the potential uses of ChatGPT in\n# ---\n# Title: Potential use of chat gpt in global warming\n# Link: https://link.springer.com/article/10.1007/s10439-023-03171-8\n# Snippet:  as ChatGPT, have the potential to play a critical role in advancing our understanding of climate\n# ---\n```\n\n----------------------------------------\n\nTITLE: Creating Flow Projects with CLI\nDESCRIPTION: Command line instruction for generating a new CrewAI flow project with predefined structure and scaffolding.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncrewai create flow name_of_flow\n```\n\n----------------------------------------\n\nTITLE: Using Cohere Embeddings in CrewAI\nDESCRIPTION: This snippet demonstrates how to configure a Crew to use Cohere embeddings. It specifies the Cohere provider, API key, and model name for embeddings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"cohere\",\n        \"config\": {\n            \"api_key\": \"YOUR_API_KEY\",\n            \"model\": \"<model_name>\"\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing WebsiteSearchTool in Python\nDESCRIPTION: Examples showing how to initialize WebsiteSearchTool for both general website searches and single-website focused searches.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/websitesearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import WebsiteSearchTool\n\n# Example of initiating tool that agents can use \n# to search across any discovered websites\ntool = WebsiteSearchTool()\n\n# Example of limiting the search to the content of a specific website, \n# so now agents can only search within that website\ntool = WebsiteSearchTool(website='https://example.com')\n```\n\n----------------------------------------\n\nTITLE: Using Immutable Operations for State Management in Python\nDESCRIPTION: This example shows how to use immutable operations when working with state, especially for structured state. It demonstrates creating a new list instead of modifying an existing one in-place.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom typing import List\n\nclass ItemState(BaseModel):\n    items: List[str] = []\n\nclass ImmutableFlow(Flow[ItemState]):\n    @start()\n    def add_item(self):\n        # Create new list with the added item\n        self.state.items = [*self.state.items, \"new item\"]\n        return \"Item added\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple LLM Providers\nDESCRIPTION: Example of configuring different LLM providers (Anthropic and Azure) using Portkey's Virtual keys system.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/portkey-observability.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Anthropic Configuration\nanthropic_llm = LLM(\n    model=\"claude-3-5-sonnet-latest\",\n    base_url=PORTKEY_GATEWAY_URL,\n    api_key=\"dummy\",\n    extra_headers=createHeaders(\n        api_key=\"YOUR_PORTKEY_API_KEY\",\n        virtual_key=\"YOUR_ANTHROPIC_VIRTUAL_KEY\", #You don't need provider when using Virtual keys\n        trace_id=\"anthropic_agent\"\n    )\n)\n\n# Azure OpenAI Configuration\nazure_llm = LLM(\n    model=\"gpt-4\",\n    base_url=PORTKEY_GATEWAY_URL,\n    api_key=\"dummy\",\n    extra_headers=createHeaders(\n        api_key=\"YOUR_PORTKEY_API_KEY\",\n        virtual_key=\"YOUR_AZURE_VIRTUAL_KEY\", #You don't need provider when using Virtual keys\n        trace_id=\"azure_agent\"\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Fireworks AI LLM in CrewAI\nDESCRIPTION: Demonstrates how to initialize a Fireworks AI LLM for use in a CrewAI project, specifying the model and temperature.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct\",\n    temperature=0.7\n)\n```\n\n----------------------------------------\n\nTITLE: Integrating Custom Prompts in CrewAI Python Script\nDESCRIPTION: Python code demonstrating how to create agents, tasks, and a crew using a custom prompt file in CrewAI. This example shows the integration of the custom_prompts.json file into the crew configuration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/advanced/customizing-prompts.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Task, Process\n\n# Create agents and tasks as normal\nresearcher = Agent(\n    role=\"Research Specialist\",\n    goal=\"Find information on quantum computing\",\n    backstory=\"You are a quantum physics expert\",\n    verbose=True\n)\n\nresearch_task = Task(\n    description=\"Research quantum computing applications\",\n    expected_output=\"A summary of practical applications\",\n    agent=researcher\n)\n\n# Create a crew with your custom prompt file\ncrew = Crew(\n    agents=[researcher],\n    tasks=[research_task],\n    prompt_file=\"path/to/custom_prompts.json\",\n    verbose=True\n)\n\n# Run the crew\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Changing Base API URL for LLM Provider in Python\nDESCRIPTION: Shows how to change the base API URL for any LLM provider by setting the base_url parameter in the LLM configuration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/llm-connections.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"custom-model-name\",\n    base_url=\"https://api.your-provider.com/v1\",\n    api_key=\"your-api-key\"\n)\nagent = Agent(llm=llm, ...)\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies with CrewAI CLI\nDESCRIPTION: Optional command to lock and install project dependencies using the CrewAI CLI. This ensures consistent package versions across different environments.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/crew/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncrewai install\n```\n\n----------------------------------------\n\nTITLE: Initializing MySQLSearchTool for Semantic Database Queries in Python\nDESCRIPTION: Example of how to initialize the MySQLSearchTool with a database URI and table name to perform semantic searches on a MySQL database table.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/mysqltool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import MySQLSearchTool\n\n# Initialize the tool with the database URI and the target table name\ntool = MySQLSearchTool(\n    db_uri='mysql://user:password@localhost:3306/mydatabase',\n    table_name='employees'\n)\n```\n\n----------------------------------------\n\nTITLE: Basic Scrapfly Tool Usage with CrewAI\nDESCRIPTION: Example showing how to initialize and use the ScrapflyScrapeWebsiteTool with a CrewAI Agent and Task for basic web scraping.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapflyscrapetool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import ScrapflyScrapeWebsiteTool\n\n# Initialize the tool\nscrape_tool = ScrapflyScrapeWebsiteTool(api_key=\"your_scrapfly_api_key\")\n\n# Define an agent that uses the tool\nweb_scraper_agent = Agent(\n    role=\"Web Scraper\",\n    goal=\"Extract information from websites\",\n    backstory=\"An expert in web scraping who can extract content from any website.\",\n    tools=[scrape_tool],\n    verbose=True,\n)\n\n# Example task to extract content from a website\nscrape_task = Task(\n    description=\"Extract the main content from the product page at https://web-scraping.dev/products and summarize the available products.\",\n    expected_output=\"A summary of the products available on the website.\",\n    agent=web_scraper_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Fingerprint Persistence in CrewAI\nDESCRIPTION: Shows how fingerprints remain unchanged even when a component is modified. This example modifies an Agent's goal but demonstrates that the fingerprint's UUID string remains the same, proving the persistence property.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/advanced/fingerprinting.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\noriginal_fingerprint = agent.fingerprint.uuid_str\n\n# Modify the agent\nagent.goal = \"New goal for analysis\"\n\n# The fingerprint remains unchanged\nassert agent.fingerprint.uuid_str == original_fingerprint\n```\n\n----------------------------------------\n\nTITLE: CodeInterpreterTool Implementation Details\nDESCRIPTION: Code snippet showing the implementation details of the CodeInterpreterTool, including its initialization and the _run method for executing code either in unsafe mode or within a Docker container.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/codeinterpretertool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass CodeInterpreterTool(BaseTool):\n    name: str = \"Code Interpreter\"\n    description: str = \"Interprets Python3 code strings with a final print statement.\"\n    args_schema: Type[BaseModel] = CodeInterpreterSchema\n    default_image_tag: str = \"code-interpreter:latest\"\n    \n    def _run(self, **kwargs) -> str:\n        code = kwargs.get(\"code\", self.code)\n        libraries_used = kwargs.get(\"libraries_used\", [])\n\n        if self.unsafe_mode:\n            return self.run_code_unsafe(code, libraries_used)\n        else:\n            return self.run_code_in_docker(code, libraries_used)\n```\n\n----------------------------------------\n\nTITLE: Configuring Agent with Local Ollama Model in Python\nDESCRIPTION: Demonstrates how to configure a CrewAI agent to use a local Ollama model, specifying the model name and local base URL.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/llm-connections.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nagent = Agent(\n    role='Local AI Expert',\n    goal='Process information using a local model',\n    backstory=\"An AI assistant running on local hardware.\",\n    llm=LLM(model=\"ollama/llama3.2\", base_url=\"http://localhost:11434\")\n)\n```\n\n----------------------------------------\n\nTITLE: Advanced Usage Example of MultiOnTool\nDESCRIPTION: Detailed example showing how to create an agent specifically for web browsing tasks and execute specific web search and summarization tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/multiontool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Example of using the tool with an agent\nbrowser_agent = Agent(\n    role=\"Web Browser Agent\",\n    goal=\"Search for and summarize information from the web\",\n    backstory=\"An expert at finding and extracting information from websites.\",\n    tools=[multion_tool],\n    verbose=True,\n)\n\n# Create a task for the agent\nsearch_task = Task(\n    description=\"Search for the latest AI news on TechCrunch and summarize the top 3 headlines\",\n    expected_output=\"A summary of the top 3 AI news headlines from TechCrunch\",\n    agent=browser_agent,\n)\n\n# Run the task\ncrew = Crew(agents=[browser_agent], tasks=[search_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Environment Variables for CrewAI\nDESCRIPTION: Sets up the required and optional environment variables for using OpenAI with CrewAI. This includes the API key, custom base URL, and organization ID.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n# Required\nOPENAI_API_KEY=sk-...\n\n# Optional\nOPENAI_API_BASE=<custom-base-url>\nOPENAI_ORGANIZATION=<your-org-id>\n```\n\n----------------------------------------\n\nTITLE: Adding Metadata to CrewAI Fingerprints\nDESCRIPTION: Shows how to add custom metadata to a component's fingerprint for additional context. The example demonstrates adding version, department, and project information to an Agent's fingerprint and then accessing that metadata.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/advanced/fingerprinting.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Add metadata to the agent's fingerprint\nagent.security_config.fingerprint.metadata = {\n    \"version\": \"1.0\",\n    \"department\": \"Data Science\",\n    \"project\": \"Customer Analysis\"\n}\n\n# Access the metadata\nprint(f\"Agent metadata: {agent.fingerprint.metadata}\")\n```\n\n----------------------------------------\n\nTITLE: Registering Event Listener in Flow-based Applications\nDESCRIPTION: Example showing how to import and instantiate a custom event listener at the top of a Flow implementation file to ensure it's loaded and active during Flow execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# In your main.py or flow.py file\nfrom crewai.flow import Flow, listen, start\nfrom my_listeners import MyCustomListener\n\n# Create an instance of your listener\nmy_listener = MyCustomListener()\n\nclass MyCustomFlow(Flow):\n    # Your flow implementation...\n\n    @start()\n    def first_step(self):\n        # ...\n```\n\n----------------------------------------\n\nTITLE: Implementing PatronusLocalEvaluatorTool with Custom Evaluator\nDESCRIPTION: Example showing how to create and use a custom evaluator with PatronusLocalEvaluatorTool, including registering a random score evaluator function.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/patronustools.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import PatronusLocalEvaluatorTool\nfrom patronus import Client, EvaluationResult\nimport random\n\n# Initialize the Patronus client\nclient = Client()\n\n# Register a custom evaluator\n@client.register_local_evaluator(\"random_evaluator\")\ndef random_evaluator(**kwargs):\n    score = random.random()\n    return EvaluationResult(\n        score_raw=score,\n        pass_=score >= 0.5,\n        explanation=\"example explanation\",\n    )\n\n# Initialize the tool with the custom evaluator\npatronus_eval_tool = PatronusLocalEvaluatorTool(\n    patronus_client=client,\n    evaluator=\"random_evaluator\",\n    evaluated_model_gold_answer=\"example label\",\n)\n\n# Define an agent that uses the tool\ncoding_agent = Agent(\n    role=\"Coding Agent\",\n    goal=\"Generate high quality code\",\n    backstory=\"An experienced coder who can generate high quality python code.\",\n    tools=[patronus_eval_tool],\n    verbose=True,\n)\n\n# Example task to generate code\ngenerate_code_task = Task(\n    description=\"Create a simple program to generate the first N numbers in the Fibonacci sequence.\",\n    expected_output=\"Program that generates the first N numbers in the Fibonacci sequence.\",\n    agent=coding_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[coding_agent], tasks=[generate_code_task])\nresult = crew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Arize Phoenix and CrewAI\nDESCRIPTION: Command to install required Python packages including OpenInference instrumentation, CrewAI, and Arize Phoenix OpenTelemetry integration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/arize-phoenix-observability.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install openinference-instrumentation-crewai crewai crewai-tools arize-phoenix-otel\n```\n\n----------------------------------------\n\nTITLE: Customizing MDXSearchTool with Model and Embeddings in Python\nDESCRIPTION: Example of customizing the MDXSearchTool with specific model and embedding configurations using a dictionary.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/mdxsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = MDXSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # Options include google, openai, anthropic, llama2, etc.\n            config=dict(\n                model=\"llama2\",\n                # Optional parameters can be included here.\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # Optional title for the embeddings can be added here.\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing BrowserbaseLoadTool\nDESCRIPTION: Example showing how to initialize and use the BrowserbaseLoadTool in Python. The tool requires API key and Project ID from Browserbase.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/browserbaseloadtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import BrowserbaseLoadTool\n\n# Initialize the tool with the Browserbase API key and Project ID\ntool = BrowserbaseLoadTool()\n```\n\n----------------------------------------\n\nTITLE: Implementing Logging for Custom LLM\nDESCRIPTION: A custom LLM implementation with logging capabilities for debugging and monitoring purposes. Includes log levels for info, debug, and error messages.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/custom-llm.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom typing import Any, Dict, List, Optional, Union\n\nclass LoggingLLM(BaseLLM):\n    def __init__(self, api_key: str, endpoint: str):\n        super().__init__()\n        self.api_key = api_key\n        self.endpoint = endpoint\n        self.logger = logging.getLogger(\"crewai.llm.custom\")\n        \n    def call(\n        self,\n        messages: Union[str, List[Dict[str, str]]],\n        tools: Optional[List[dict]] = None,\n        callbacks: Optional[List[Any]] = None,\n        available_functions: Optional[Dict[str, Any]] = None,\n    ) -> Union[str, Any]:\n        self.logger.info(f\"Calling LLM with {len(messages) if isinstance(messages, list) else 1} messages\")\n        try:\n            # API call implementation\n            response = self._make_api_call(messages, tools)\n            self.logger.debug(f\"LLM response received: {response[:100]}...\")\n            return response\n        except Exception as e:\n            self.logger.error(f\"LLM call failed: {str(e)}\")\n            raise\n```\n\n----------------------------------------\n\nTITLE: Creating Deterministic Fingerprints in CrewAI\nDESCRIPTION: Demonstrates how to generate deterministic fingerprints using a seed string, which ensures the same fingerprint is created every time with the same seed. Also shows how to add metadata during generation.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/advanced/fingerprinting.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.security import Fingerprint\n\n# Create a deterministic fingerprint using a seed string\ndeterministic_fingerprint = Fingerprint.generate(seed=\"my-agent-id\")\n\n# The same seed always produces the same fingerprint\nsame_fingerprint = Fingerprint.generate(seed=\"my-agent-id\")\nassert deterministic_fingerprint.uuid_str == same_fingerprint.uuid_str\n\n# You can also set metadata\ncustom_fingerprint = Fingerprint.generate(\n    seed=\"my-agent-id\",\n    metadata={\"version\": \"1.0\"}\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing EXA Search Tool in Python\nDESCRIPTION: Example showing how to import and initialize the EXASearchTool for performing internet searches. Requires an EXA_API_KEY environment variable to be set.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/exasearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import EXASearchTool\n\n# Initialize the tool for internet searching capabilities\ntool = EXASearchTool()\n```\n\n----------------------------------------\n\nTITLE: Initializing Weave for CrewAI application monitoring\nDESCRIPTION: Code snippet to initialize Weave in your CrewAI application, setting up a project for monitoring agent interactions and performance metrics.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/weave-integration.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport weave\n\n# Initialize Weave with your project name\nweave.init(project_name=\"crewai_demo\")\n```\n\n----------------------------------------\n\nTITLE: Initializing SambaNova LLM in CrewAI\nDESCRIPTION: Demonstrates how to initialize a SambaNova LLM for use in a CrewAI project, specifying the model and temperature.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"sambanova/Meta-Llama-3.1-8B-Instruct\",\n    temperature=0.7\n)\n```\n\n----------------------------------------\n\nTITLE: Using ScrapeWebsiteTool in Python\nDESCRIPTION: Example demonstrating how to initialize and use the ScrapeWebsiteTool to extract content from a website. It shows two initialization methods: one for scraping any website and another for a specific URL.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapewebsitetool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import ScrapeWebsiteTool\n\n# To enable scrapping any website it finds during it's execution\ntool = ScrapeWebsiteTool()\n\n# Initialize the tool with the website URL, \n# so the agent can only scrap the content of the specified website\ntool = ScrapeWebsiteTool(website_url='https://www.example.com')\n\n# Extract the text from the site\ntext = tool.run()\nprint(text)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Azure OpenAI Embeddings in CrewAI\nDESCRIPTION: This snippet demonstrates how to configure a Crew to use Azure OpenAI embeddings. It includes settings for API key, base path, API version, and model name specific to Azure OpenAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\nfrom crewai import Crew, Agent, Task, Process\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"openai\",\n        \"config\": {\n            \"api_key\": \"YOUR_API_KEY\",\n            \"api_base\": \"YOUR_API_BASE_PATH\",\n            \"api_version\": \"YOUR_API_VERSION\",\n            \"model_name\": 'text-embedding-3-small'\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies with CrewAI CLI\nDESCRIPTION: Optional command to lock and install project dependencies using the CrewAI CLI tool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/flow/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncrewai install\n```\n\n----------------------------------------\n\nTITLE: Initializing Azure OpenAI LLM in CrewAI\nDESCRIPTION: Demonstrates how to initialize an Azure OpenAI LLM in a CrewAI project, specifying the model and API version.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"azure/gpt-4\",\n    api_version=\"2023-05-15\"\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up HuggingFace Embeddings in CrewAI\nDESCRIPTION: This snippet demonstrates how to configure a Crew to use HuggingFace embeddings. It specifies the HuggingFace provider and the API URL for embeddings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"huggingface\",\n        \"config\": {\n            \"api_url\": \"<api_url>\",\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Running a CrewAI Crew or Flow\nDESCRIPTION: Command to execute a crew or flow. From version 0.103.0, this automatically detects whether to run a crew or flow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ncrewai run\n```\n\n----------------------------------------\n\nTITLE: Defining Structured State for Focused User Data in Python\nDESCRIPTION: This snippet demonstrates how to create a structured state using Pydantic BaseModel for storing focused user data. It includes fields for user ID, preferences, and completion status.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/mastering-flow-state.mdx#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclass FocusedState(BaseModel):\n    user_id: str\n    preferences: Dict[str, str]\n    completion_status: Dict[str, bool]\n```\n\n----------------------------------------\n\nTITLE: Defining Report Output Model in Python\nDESCRIPTION: Creates a Pydantic BaseModel class named Report to structure the final output. It includes fields for code and a list of resource links.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nclass Report(BaseModel):\n    code: str\n    links: List[str]\n```\n\n----------------------------------------\n\nTITLE: Defining Tasks in YAML Configuration\nDESCRIPTION: Shows how to configure tasks using YAML, including task descriptions, expected outputs, agent assignments, and output file specifications.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nresearch_task:\n  description: >\n    Conduct a thorough research about {topic}\n    Make sure you find any interesting and relevant information given\n    the current year is 2025.\n  expected_output: >\n    A list with 10 bullet points of the most relevant information about {topic}\n  agent: researcher\n\nreporting_task:\n  description: >\n    Review the context you got and expand each topic into a full section for a report.\n    Make sure the report is detailed and contains any and all relevant information.\n  expected_output: >\n    A fully fledge reports with the mains topics, each with a full section of information.\n    Formatted as markdown without '```'\n  agent: reporting_analyst\n  output_file: report.md\n```\n\n----------------------------------------\n\nTITLE: Implementing S3ReaderTool Class\nDESCRIPTION: The implementation of the S3ReaderTool class, showing how it interacts with AWS S3 using boto3 and handles errors.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/s3readertool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass S3ReaderTool(BaseTool):\n    name: str = \"S3 Reader Tool\"\n    description: str = \"Reads a file from Amazon S3 given an S3 file path\"\n    \n    def _run(self, file_path: str) -> str:\n        try:\n            bucket_name, object_key = self._parse_s3_path(file_path)\n\n            s3 = boto3.client(\n                's3',\n                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),\n                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),\n                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')\n            )\n\n            # Read file content from S3\n            response = s3.get_object(Bucket=bucket_name, Key=object_key)\n            file_content = response['Body'].read().decode('utf-8')\n\n            return file_content\n        except ClientError as e:\n            return f\"Error reading file from S3: {str(e)}\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Perplexity AI LLM in CrewAI\nDESCRIPTION: Demonstrates how to initialize a Perplexity AI LLM for use in a CrewAI project, specifying the model and base URL.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"llama-3.1-sonar-large-128k-online\",\n    base_url=\"https://api.perplexity.ai/\"\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Watson Embeddings in CrewAI\nDESCRIPTION: This example shows how to set up a Crew using Watson embeddings. It includes configuration for the Watson provider, including model name, API URL, API key, and project ID. Note that the ibm_watsonx_ai library is required for Watson embeddings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\n# Note: Ensure you have installed and imported `ibm_watsonx_ai` for Watson embeddings to work.\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"watson\",\n        \"config\": {\n            \"model\": \"<model_name>\",\n            \"api_url\": \"<api_url>\",\n            \"api_key\": \"<YOUR_API_KEY>\",\n            \"project_id\": \"<YOUR_PROJECT_ID>\",\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring TXTSearchTool with Custom Models and Embeddings\nDESCRIPTION: Example of how to customize the TXTSearchTool with specific language models and embedding providers, including options for various providers like Ollama, Google, OpenAI, Anthropic, and Llama2.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/txtsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = TXTSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Model and Embeddings for PGSearchTool\nDESCRIPTION: Example demonstrating how to customize the model and embeddings configuration using different providers like Ollama, Google, or OpenAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/pgsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntool = PGSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI and Portkey Dependencies\nDESCRIPTION: Command to install the required Python packages for CrewAI and Portkey integration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/portkey-observability.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -qU crewai portkey-ai\n```\n\n----------------------------------------\n\nTITLE: Initializing FirecrawlScrapeWebsiteTool in Python\nDESCRIPTION: This snippet demonstrates how to create an instance of the FirecrawlScrapeWebsiteTool with a specified URL. It allows an agent to load and scrape websites using the Firecrawl service.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/firecrawlscrapewebsitetool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import FirecrawlScrapeWebsiteTool\n\ntool = FirecrawlScrapeWebsiteTool(url='firecrawl.dev')\n```\n\n----------------------------------------\n\nTITLE: Enabling Memory in a Data Analyst Agent\nDESCRIPTION: Simple example showing how to enable memory for an agent to maintain context across interactions. This configuration is useful for tasks requiring historical context and continuity.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/agents.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\n\nanalyst = Agent(\n    role=\"Data Analyst\",\n    goal=\"Analyze and remember complex data patterns\",\n    memory=True,  # Enable memory\n    verbose=True\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Adapter Constructor in Python\nDESCRIPTION: Implementation of the __init__ method for the custom agent adapter, handling initialization and configuration of the external agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef __init__(self, agent_config: Optional[Dict[str, Any]] = None, **kwargs: Any):\n    super().__init__(agent_config=agent_config, **kwargs)\n    # Initialize your external agent here, possibly using agent_config\n    # Example: self.external_agent = initialize_my_agent(agent_config)\n    print(f\"Initializing MyCustomAgentAdapter with config: {agent_config}\")\n```\n\n----------------------------------------\n\nTITLE: Importing Listener Package in Crew Implementation\nDESCRIPTION: Simple example showing how to import a listeners package in a Crew implementation file to ensure all listeners are loaded when the Crew is executed.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# In your crew.py or flow.py file\nimport my_project.listeners  # This loads all your listeners\n\nclass MyCustomCrew:\n    # Your crew implementation...\n```\n\n----------------------------------------\n\nTITLE: Configuring Context Window Management for LLM in Python\nDESCRIPTION: This snippet demonstrates how to configure context window management for an LLM in CrewAI. It sets the maximum number of tokens for the response and relies on CrewAI's automatic context handling features.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM\n\n# CrewAI automatically handles:\n# 1. Token counting and tracking\n# 2. Content summarization when needed\n# 3. Task splitting for large contexts\n\nllm = LLM(\n    model=\"gpt-4\",\n    max_tokens=4000,  # Limit response length\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a New CrewAI Flow Project Using CLI\nDESCRIPTION: Commands to create and initialize a new CrewAI Flow project using the CrewAI CLI. This sets up a scaffolded project with all necessary directories and template files.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncrewai create flow guide_creator_flow\ncd guide_creator_flow\n```\n\n----------------------------------------\n\nTITLE: Phone Number Normalization in CrewAI\nDESCRIPTION: A guardrail function that normalizes phone numbers to a consistent format. Validates 10-digit numbers and formats them with appropriate separators.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef normalize_phone_number(result: str) -> Tuple[bool, Union[str, str]]:\n    \"\"\"Ensure phone numbers are in a consistent format.\"\"\"\n    import re\n    digits = re.sub(r'\\D', '', result)\n    if len(digits) == 10:\n        formatted = f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n        return (True, formatted)\n    return (False, \"Output must be a 10-digit phone number\")\n```\n\n----------------------------------------\n\nTITLE: Advanced Scrapfly Configuration Example\nDESCRIPTION: Example demonstrating advanced configuration options for the ScrapflyScrapeWebsiteTool including custom parameters for proxy settings and JavaScript rendering.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapflyscrapetool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nweb_scraper_agent = Agent(\n    role=\"Web Scraper\",\n    goal=\"Extract information from websites with custom parameters\",\n    backstory=\"An expert in web scraping who can extract content from any website.\",\n    tools=[scrape_tool],\n    verbose=True,\n)\n\nscrape_task = Task(\n    description=\"Extract the main content from the product page at https://web-scraping.dev/products using advanced scraping options including JavaScript rendering and proxy settings.\",\n    expected_output=\"A detailed summary of the products with all available information.\",\n    agent=web_scraper_agent,\n)\n```\n\n----------------------------------------\n\nTITLE: Basic Implementation of CodeDocsSearchTool in Python\nDESCRIPTION: Shows how to initialize the CodeDocsSearchTool either without specifying a documentation URL (for general search across available documentation) or with a specific URL to focus the search on a particular documentation site.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/codedocssearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import CodeDocsSearchTool\n\n# To search any code documentation content \n# if the URL is known or discovered during its execution:\ntool = CodeDocsSearchTool()\n\n# OR\n\n# To specifically focus your search on a given documentation site \n# by providing its URL:\ntool = CodeDocsSearchTool(docs_url='https://docs.example.com/reference')\n```\n\n----------------------------------------\n\nTITLE: Installing UV Package Manager for Python\nDESCRIPTION: Command to install UV, a package manager for Python projects, used for dependency management in this CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/flow/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install uv\n```\n\n----------------------------------------\n\nTITLE: Running CrewAI Flow via CLI\nDESCRIPTION: Demonstrates how to kickoff a CrewAI flow using the command line interface. This command initiates the guide creation process, prompting for user input and orchestrating the flow steps.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncrewai flow kickoff\n```\n\n----------------------------------------\n\nTITLE: Initializing SeleniumScrapingTool with Predefined Parameters\nDESCRIPTION: Example of how to initialize the SeleniumScrapingTool with predefined parameters for website URL, CSS selector, and wait time.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/seleniumscrapingtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the tool with predefined parameters\nselenium_tool = SeleniumScrapingTool(\n    website_url='https://example.com',\n    css_element='.main-content',\n    wait_time=5\n)\n\n# Define an agent that uses the tool\nweb_scraper_agent = Agent(\n    role=\"Web Scraper\",\n    goal=\"Extract information from websites using Selenium\",\n    backstory=\"An expert web scraper who can extract content from dynamic websites.\",\n    tools=[selenium_tool],\n    verbose=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Inheriting from BaseToolAdapter in Python\nDESCRIPTION: This snippet shows how to create a custom tool adapter class by inheriting from BaseToolAdapter and importing necessary dependencies.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.agents.agent_adapters.base_tool_adapter import BaseToolAdapter\nfrom crewai.tools import BaseTool\nfrom typing import List, Any\n\nclass MyCustomToolAdapter(BaseToolAdapter):\n    # ... implementation details ...\n```\n\n----------------------------------------\n\nTITLE: Training CrewAI Agents via CLI\nDESCRIPTION: Execute training iterations for CrewAI agents through the command line interface. This command allows you to specify the number of training iterations and optionally provide a filename for model storage.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/training.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncrewai train -n <n_iterations> <filename> (optional)\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenLIT in Python Application\nDESCRIPTION: Code snippet to initialize OpenLIT in a Python application using function arguments.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/openlit-observability.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport openlit\nopenlit.init(otlp_endpoint=\"http://127.0.0.1:4318\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Space News Analyst Agent in Python\nDESCRIPTION: This snippet sets up a CrewAI agent specialized as a Space News Analyst. It uses the custom SpaceNewsKnowledgeSource to access recent space news articles for analysis.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nrecent_news = SpaceNewsKnowledgeSource(\n    api_endpoint=\"https://api.spaceflightnewsapi.net/v4/articles\",\n    limit=10,\n)\n\nspace_news_analyst = Agent(\n    role=\"Space News Analyst\",\n    goal=\"Provide accurate and up-to-date information on space exploration developments\",\n    backstory=\"You are an expert in space exploration with access to the latest news and developments in the field.\",\n    tools=[recent_news],\n    verbose=True\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq LLM in CrewAI\nDESCRIPTION: Shows how to initialize a Groq LLM for use in a CrewAI project, specifying the model and temperature.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"groq/llama-3.2-90b-text-preview\",\n    temperature=0.7\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing JSONSearchTool in Python\nDESCRIPTION: Examples of initializing the JSONSearchTool for general JSON content search and for searching within a specific JSON file. The tool can be configured to search either globally or within a specified JSON file path.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/jsonsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import JSONSearchTool\n\n# General JSON content search\n# This approach is suitable when the JSON path is either known beforehand or can be dynamically identified.\ntool = JSONSearchTool()\n\n# Restricting search to a specific JSON file\n# Use this initialization method when you want to limit the search scope to a specific JSON file.\ntool = JSONSearchTool(json_path='./path/to/your/file.json')\n```\n\n----------------------------------------\n\nTITLE: Creating Tasks for Code Helper and Link Finder Agents in Python\nDESCRIPTION: Defines two tasks: one for answering coding questions and another for finding relevant resources. Each task specifies its description, expected output, and assigned agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntask = Task(\n    description=\"Give an answer to the coding question: {task}\",\n    expected_output=\"A thorough answer to the coding question: {task}\",\n    agent=code_helper_agent,\n    output_json=Code,\n)\ntask2 = Task(\n    description=\"Find links to resources that can help with coding tasks. Use the serper tool to find resources that can help.\",\n    expected_output=\"A list of links to resources that can help with coding tasks\",\n    agent=link_finder_agent,\n)\n```\n\n----------------------------------------\n\nTITLE: Checking Python Version for CrewAI Compatibility\nDESCRIPTION: Command to verify your Python version to ensure it meets CrewAI's requirements of Python >=3.10 and <3.13.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython3 --version\n```\n\n----------------------------------------\n\nTITLE: Basic BraveSearchTool Usage\nDESCRIPTION: Basic example showing how to initialize and use the BraveSearchTool for performing internet searches.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bravesearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import BraveSearchTool\n\n# Initialize the tool for internet searching capabilities\ntool = BraveSearchTool()\n\n# Execute a search\nresults = tool.run(search_query=\"CrewAI agent framework\")\nprint(results)\n```\n\n----------------------------------------\n\nTITLE: Configuring Chat LLM in Crew Definition\nDESCRIPTION: Code snippet showing how to set up the chat_llm property in a crew.py file, which is required for the chat command to work properly.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n@crew\ndef crew(self) -> Crew:\n    return Crew(\n        agents=self.agents,\n        tasks=self.tasks,\n        process=Process.sequential,\n        verbose=True,\n        chat_llm=\"gpt-4o\",  # LLM for chat orchestration\n    )\n```\n\n----------------------------------------\n\nTITLE: Training Command Example\nDESCRIPTION: Example showing how to train a crew for 10 iterations and save the training data to a custom file named 'my_training_data.pkl'.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncrewai train -n 10 -f my_training_data.pkl\n```\n\n----------------------------------------\n\nTITLE: Implementing CrewAI Agents and Tasks\nDESCRIPTION: Example implementation of a CrewAI workflow with two agents and two tasks configured for market analysis.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/opik-observability.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Task, Process\n\n\nclass YourCrewName:\n    def agent_one(self) -> Agent:\n        return Agent(\n            role=\"Data Analyst\",\n            goal=\"Analyze data trends in the market\",\n            backstory=\"An experienced data analyst with a background in economics\",\n            verbose=True,\n        )\n\n    def agent_two(self) -> Agent:\n        return Agent(\n            role=\"Market Researcher\",\n            goal=\"Gather information on market dynamics\",\n            backstory=\"A diligent researcher with a keen eye for detail\",\n            verbose=True,\n        )\n\n    def task_one(self) -> Task:\n        return Task(\n            name=\"Collect Data Task\",\n            description=\"Collect recent market data and identify trends.\",\n            expected_output=\"A report summarizing key trends in the market.\",\n            agent=self.agent_one(),\n        )\n\n    def task_two(self) -> Task:\n        return Task(\n            name=\"Market Research Task\",\n            description=\"Research factors affecting market dynamics.\",\n            expected_output=\"An analysis of factors influencing the market.\",\n            agent=self.agent_two(),\n        )\n\n    def crew(self) -> Crew:\n        return Crew(\n            agents=[self.agent_one(), self.agent_two()],\n            tasks=[self.task_one(), self.task_two()],\n            process=Process.sequential,\n            verbose=True,\n        )\n```\n\n----------------------------------------\n\nTITLE: Implementing Opik Tracking with CrewAI\nDESCRIPTION: Final implementation showing how to track CrewAI execution with Opik and run the crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/opik-observability.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom opik.integrations.crewai import track_crewai\n\ntrack_crewai(project_name=\"crewai-integration-demo\")\n\nmy_crew = YourCrewName().crew()\nresult = my_crew.kickoff()\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Accessing Fingerprint Structure in CrewAI\nDESCRIPTION: Explains the structure of a fingerprint object in CrewAI, showing how to access its three main components: the UUID string (unique identifier), creation timestamp, and metadata dictionary.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/advanced/fingerprinting.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.security import Fingerprint\n\nfingerprint = agent.fingerprint\n\n# UUID string - the unique identifier (auto-generated)\nuuid_str = fingerprint.uuid_str  # e.g., \"123e4567-e89b-12d3-a456-426614174000\"\n\n# Creation timestamp (auto-generated)\ncreated_at = fingerprint.created_at  # A datetime object\n\n# Metadata - for additional information (can be customized)\nmetadata = fingerprint.metadata  # A dictionary, defaults to {}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenRouter LLM in Python\nDESCRIPTION: This snippet demonstrates how to configure an LLM using OpenRouter models in CrewAI. It specifies the model, base URL, and API key for authentication.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nmodel=\"openrouter/deepseek/deepseek-r1\",\nbase_url=\"https://openrouter.ai/api/v1\",\napi_key=OPENROUTER_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Initializing FirecrawlCrawlWebsiteTool in Python\nDESCRIPTION: This snippet demonstrates how to create an instance of the FirecrawlCrawlWebsiteTool, specifying the URL to crawl. It allows an agent to load and process websites using the Firecrawl platform.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/firecrawlcrawlwebsitetool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import FirecrawlCrawlWebsiteTool\n\ntool = FirecrawlCrawlWebsiteTool(url='firecrawl.dev')\n```\n\n----------------------------------------\n\nTITLE: Initializing XMLSearchTool in Python\nDESCRIPTION: Examples of how to initialize the XMLSearchTool, either for searching any XML file or a specific XML file.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/xmlsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import XMLSearchTool\n\n# Allow agents to search within any XML file's content \n#as it learns about their paths during execution\ntool = XMLSearchTool()\n\n# OR\n\n# Initialize the tool with a specific XML file path \n#for exclusive search within that document\ntool = XMLSearchTool(xml='path/to/your/xmlfile.xml')\n```\n\n----------------------------------------\n\nTITLE: Initializing ComposioToolSet\nDESCRIPTION: Basic setup code to initialize the Composio toolset for use with CrewAI agents\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom composio_crewai import ComposioToolSet, App, Action\nfrom crewai import Agent, Task, Crew\n\ntoolset = ComposioToolSet()\n```\n\n----------------------------------------\n\nTITLE: Starting an Interactive Chat Session\nDESCRIPTION: Command to start an interactive chat session with a crew, available from version 0.98.0. The AI assistant will guide the user through the process.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ncrewai chat\n```\n\n----------------------------------------\n\nTITLE: Setting Open Router API Key in Environment Variables\nDESCRIPTION: Shows how to set the Open Router API key in the .env file for use with CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_36\n\nLANGUAGE: toml\nCODE:\n```\nOPENROUTER_API_KEY=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Initializing Cerebras LLM in CrewAI\nDESCRIPTION: Demonstrates how to initialize a Cerebras LLM for use in a CrewAI project, specifying the model, temperature, and max tokens.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"cerebras/llama3.1-70b\",\n    temperature=0.7,\n    max_tokens=8192\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Tool with Specific Channel\nDESCRIPTION: Example demonstrating how to initialize the YoutubeChannelSearchTool with a specific YouTube channel handle\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubechannelsearchtool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the tool with a specific YouTube channel handle\nyoutube_channel_tool = YoutubeChannelSearchTool(\n    youtube_channel_handle='@exampleChannel'\n)\n\n# Define an agent that uses the tool\nchannel_researcher = Agent(\n    role=\"Channel Researcher\",\n    goal=\"Extract relevant information from a specific YouTube channel\",\n    backstory=\"An expert researcher who specializes in analyzing YouTube channel content.\",\n    tools=[youtube_channel_tool],\n    verbose=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using DirectoryReadTool in Python\nDESCRIPTION: Example of how to import, initialize, and use the DirectoryReadTool in Python. It shows two initialization methods: one for reading any directory and another for reading a specific directory.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/directoryreadtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import DirectoryReadTool\n\n# Initialize the tool so the agent can read any directory's content \n# it learns about during execution\ntool = DirectoryReadTool()\n\n# OR\n\n# Initialize the tool with a specific directory, \n# so the agent can only read the content of the specified directory\ntool = DirectoryReadTool(directory='/path/to/your/directory')\n```\n\n----------------------------------------\n\nTITLE: Creating a new CrewAI project using CLI\nDESCRIPTION: Command to create a new CrewAI project folder structure using the command line interface.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncrewai create crew <project_name>\n```\n\n----------------------------------------\n\nTITLE: Defining Code Output Model in Python\nDESCRIPTION: Creates a Pydantic BaseModel class named Code to structure the output of coding tasks. It contains a single field 'code' of type string.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass Code(BaseModel):\n    code: str\n```\n\n----------------------------------------\n\nTITLE: Initializing Custom Agent Adapter Class in Python\nDESCRIPTION: Basic class definition for a custom agent adapter that inherits from BaseAgentAdapter, including import statements and class declaration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.agents.agent_adapters.base_agent_adapter import BaseAgentAdapter\nfrom crewai.tools import BaseTool\nfrom typing import List, Optional, Any, Dict\n\nclass MyCustomAgentAdapter(BaseAgentAdapter):\n    # ... implementation details ...\n```\n\n----------------------------------------\n\nTITLE: Basic S3WriterTool Usage Example\nDESCRIPTION: Demonstrates how to initialize and use the S3WriterTool with CrewAI agents and tasks to write content to S3\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/s3writertool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools.aws.s3 import S3WriterTool\n\n# Initialize the tool\ns3_writer_tool = S3WriterTool()\n\n# Define an agent that uses the tool\nfile_writer_agent = Agent(\n    role=\"File Writer\",\n    goal=\"Write content to files in S3 buckets\",\n    backstory=\"An expert in storing and managing files in cloud storage.\",\n    tools=[s3_writer_tool],\n    verbose=True,\n)\n\n# Example task to write a report\nwrite_task = Task(\n    description=\"Generate a summary report of the quarterly sales data and save it to {my_bucket}.\",\n    expected_output=\"Confirmation that the report was successfully saved to S3.\",\n    agent=file_writer_agent,\n)\n\n# Create and run the crew\ncrew = Crew(agents=[file_writer_agent], tasks=[write_task])\nresult = crew.kickoff(inputs={\"my_bucket\": \"s3://my-bucket/reports/quarterly-summary.txt\"})\n```\n\n----------------------------------------\n\nTITLE: Initializing PDFSearchTool in Python\nDESCRIPTION: Examples showing how to initialize the PDFSearchTool either with or without a specific PDF path.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/pdfsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import PDFSearchTool\n\n# Initialize the tool allowing for any PDF content search if the path is provided during execution\ntool = PDFSearchTool()\n\n# OR\n\n# Initialize the tool with a specific PDF path for exclusive search within that document\ntool = PDFSearchTool(pdf='path/to/your/document.pdf')\n```\n\n----------------------------------------\n\nTITLE: CrewAI Built-in Listener Registration\nDESCRIPTION: Example showing how CrewAI's built-in agentops_listener is registered in the CrewAI codebase through package imports.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# src/crewai/utilities/events/third_party/__init__.py\nfrom .agentops_listener import agentops_listener\n```\n\n----------------------------------------\n\nTITLE: Training a CrewAI Crew\nDESCRIPTION: Command to train a crew for a specified number of iterations, with options for iteration count and training data filename.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncrewai train [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Setting Nvidia API Key in Environment Variables\nDESCRIPTION: This snippet shows how to set the Nvidia API key in the .env file for use with Nvidia NIM in a CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_18\n\nLANGUAGE: toml\nCODE:\n```\nNVIDIA_API_KEY=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Initializing DirectorySearchTool in Python\nDESCRIPTION: Examples showing how to import and initialize the DirectorySearchTool with both dynamic and fixed directory configurations.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/directorysearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import DirectorySearchTool\n\n# For dynamic directory specification at runtime\ntool = DirectorySearchTool()\n\n# For fixed directory searches\ntool = DirectorySearchTool(directory='/path/to/directory')\n```\n\n----------------------------------------\n\nTITLE: Connecting GitHub Account Programmatically\nDESCRIPTION: Python code to programmatically initiate GitHub connection and get authentication URL\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nrequest = toolset.initiate_connection(app=App.GITHUB)\nprint(f\"Open this URL to authenticate: {request.redirectUrl}\")\n```\n\n----------------------------------------\n\nTITLE: Generating CrewAI Project Scaffolding\nDESCRIPTION: Command to create a new CrewAI project with standard directory structure and configuration files using the CrewAI CLI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ncrewai create crew <your_project_name>\n```\n\n----------------------------------------\n\nTITLE: Defining Asynchronous Crew Execution Method in Python\nDESCRIPTION: This snippet shows the method signature for kicking off a crew asynchronously in CrewAI. It takes a dictionary of inputs and returns a CrewOutput object.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/kickoff-async.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef kickoff_async(self, inputs: dict) -> CrewOutput:\n```\n\n----------------------------------------\n\nTITLE: Running CrewAI Test with Custom Parameters (Short Form)\nDESCRIPTION: Test your crew with specified number of iterations and a custom model using shorthand parameter flags. This example runs 5 iterations using the gpt-4o model.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/testing.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncrewai test -n 5 -m gpt-4o\n```\n\n----------------------------------------\n\nTITLE: Initializing SerperDevTool in Python\nDESCRIPTION: This snippet demonstrates how to import and initialize the SerperDevTool for internet searching capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/serperdevtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import SerperDevTool\n\n# Initialize the tool for internet searching capabilities\ntool = SerperDevTool()\n```\n\n----------------------------------------\n\nTITLE: Initializing Hugging Face LLM in CrewAI\nDESCRIPTION: Demonstrates how to initialize a Hugging Face LLM for use in a CrewAI project, specifying the model.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct\"\n)\n```\n\n----------------------------------------\n\nTITLE: Examples of Creating Crews and Flows\nDESCRIPTION: Example commands showing how to create a new crew named 'my_new_crew' and a new flow named 'my_new_flow'.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncrewai create crew my_new_crew\ncrewai create flow my_new_flow\n```\n\n----------------------------------------\n\nTITLE: Adding a Content Writer Crew to the Flow\nDESCRIPTION: Command to add a specialized content writer crew to the flow. This automatically creates the necessary directories and template files for the crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncrewai flow add-crew content-crew\n```\n\n----------------------------------------\n\nTITLE: Setting Mistral API Key in Environment Variables\nDESCRIPTION: This snippet shows how to set the Mistral API key in the .env file for use in a CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_16\n\nLANGUAGE: toml\nCODE:\n```\nMISTRAL_API_KEY=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Initializing CSVSearchTool in Python\nDESCRIPTION: Examples of initializing the CSVSearchTool with and without a specific CSV file path. This setup allows for flexible usage in different scenarios.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/csvsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import CSVSearchTool\n\n# Initialize the tool with a specific CSV file. \n# This setup allows the agent to only search the given CSV file.\ntool = CSVSearchTool(csv='path/to/your/csvfile.csv')\n\n# OR\n\n# Initialize the tool without a specific CSV file. \n# Agent will need to provide the CSV path at runtime.\ntool = CSVSearchTool()\n```\n\n----------------------------------------\n\nTITLE: Disabling Telemetry in CrewAI Python\nDESCRIPTION: Shows how to disable telemetry collection in CrewAI using environment variables. Provides two options: disabling only CrewAI telemetry or disabling all OpenTelemetry instrumentation globally.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/telemetry.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Disable CrewAI telemetry only\nos.environ['CREWAI_DISABLE_TELEMETRY'] = 'true'\n\n# Disable all OpenTelemetry (including CrewAI)\nos.environ['OTEL_SDK_DISABLED'] = 'true'\n```\n\n----------------------------------------\n\nTITLE: Initializing Google Gemini LLM in CrewAI\nDESCRIPTION: Shows how to initialize a Google Gemini LLM in a CrewAI project, specifying the model, temperature, and Vertex AI credentials.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM\n\nllm = LLM(\n    model=\"gemini/gemini-1.5-pro-latest\",\n    temperature=0.7,\n    vertex_credentials=vertex_credentials_json\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a New Crew Project with CrewAI CLI\nDESCRIPTION: This command initializes a new CrewAI project named 'latest-ai-development' with the basic directory structure.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncrewai create crew latest-ai-development\n```\n\n----------------------------------------\n\nTITLE: Retrieving All GitHub Tools\nDESCRIPTION: Code to fetch all available tools for a specific app (GitHub)\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntools = toolset.get_tools(apps=[App.GITHUB])\n```\n\n----------------------------------------\n\nTITLE: Test Command Example\nDESCRIPTION: Example showing how to test a crew for 5 iterations using the gpt-3.5-turbo model.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ncrewai test -n 5 -m gpt-3.5-turbo\n```\n\n----------------------------------------\n\nTITLE: Implementing JSON Knowledge Source in CrewAI\nDESCRIPTION: This example shows how to create and use a JSON knowledge source in CrewAI. It demonstrates the setup of the source with a JSON file and its integration with an agent or crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/knowledge.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.knowledge.source.json_knowledge_source import JSONKnowledgeSource\n\n# Create a JSON knowledge source\njson_source = JSONKnowledgeSource(\n    file_paths=[\"data.json\"]\n)\n\n# Create crew with JSON knowledge source on agents or crew level\nagent = Agent(\n    ...\n    knowledge_sources=[json_source]\n)\n\ncrew = Crew(\n    ...\n    knowledge_sources=[json_source]\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing ScrapeElementFromWebsiteTool with Predefined Parameters in Python\nDESCRIPTION: Example showing how to initialize the ScrapeElementFromWebsiteTool with predefined website URL and CSS selector parameters.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapeelementfromwebsitetool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the tool with predefined parameters\nscrape_tool = ScrapeElementFromWebsiteTool(\n    website_url=\"https://www.example.com\",\n    css_element=\".main-content\"\n)\n```\n\n----------------------------------------\n\nTITLE: Enabling Streaming Responses for LLM in Python\nDESCRIPTION: This code shows how to enable streaming responses when initializing an LLM in CrewAI. It sets the 'stream' parameter to True for real-time output processing.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import LLM\n\n# Create an LLM with streaming enabled\nllm = LLM(\n    model=\"openai/gpt-4o\",\n    stream=True  # Enable streaming\n)\n```\n\n----------------------------------------\n\nTITLE: CrewAI Feature Table Documentation in Markdown\nDESCRIPTION: Markdown table documenting the enhanced attributes and features of the CrewAI Crew class, including language model management, custom manager agents, process flow controls, and various configuration options.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/collaboration.mdx#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Feature                                    | Description                                                                                                                                                                                                                  |\n|:-------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Language Model Management** (`manager_llm`, `function_calling_llm`) | Manages language models for executing tasks and tools. `manager_llm` is required for hierarchical processes, while `function_calling_llm` is optional with a default value for streamlined interactions.                    |\n| **Custom Manager Agent** (`manager_agent`) | Specifies a custom agent as the manager, replacing the default CrewAI manager.                                                                                                                                                |\n| **Process Flow** (`process`)           | Defines execution logic (e.g., sequential, hierarchical) for task distribution.                                                                                                                                                |\n| **Verbose Logging** (`verbose`)        | Provides detailed logging for monitoring and debugging. Accepts integer and boolean values to control verbosity level.                                                                                                       |\n| **Rate Limiting** (`max_rpm`)          | Limits requests per minute to optimize resource usage. Setting guidelines depend on task complexity and load.                                                                                                                 |\n| **Internationalization / Customization** (`prompt_file`) | Supports prompt customization for global usability. [Example of file](https://github.com/joaomdmoura/crewAI/blob/main/src/crewai/translations/en.json)                                                                                      |\n| **Callback and Telemetry** (`step_callback`, `task_callback`) | Enables step-wise and task-level execution monitoring and telemetry for performance analytics.                                                                                                                               |\n| **Crew Sharing** (`share_crew`)        | Allows sharing crew data with CrewAI for model improvement. Privacy implications and benefits should be considered.                                                                                                          |\n| **Usage Metrics** (`usage_metrics`)    | Logs all LLM usage metrics during task execution for performance insights.                                                                                                                           |\n| **Memory Usage** (`memory`)            | Enables memory for storing execution history, aiding in agent learning and task efficiency.                                                                                                                                  |\n| **Embedder Configuration** (`embedder`) | Configures the embedder for language understanding and generation, with support for provider customization.                                                                                                                   |\n| **Cache Management** (`cache`)         | Specifies whether to cache tool execution results, enhancing performance.                                                                                                                                                   |\n| **Output Logging** (`output_log_file`) | Defines the file path for logging crew execution output.                                                                                                                                                                      |\n| **Planning Mode** (`planning`)         | Enables action planning before task execution. Set `planning=True` to activate.                                                                                                                                              |\n| **Replay Feature** (`replay`)         | Provides CLI for listing tasks from the last run and replaying from specific tasks, aiding in task management and troubleshooting.                                                                                           |\n```\n\n----------------------------------------\n\nTITLE: Detailed Agent Integration with YoutubeVideoSearchTool\nDESCRIPTION: A comprehensive example of integrating the YoutubeVideoSearchTool with a CrewAI agent, including task definition and execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubevideosearchtool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import YoutubeVideoSearchTool\n\n# Initialize the tool\nyoutube_search_tool = YoutubeVideoSearchTool()\n\n# Define an agent that uses the tool\nvideo_researcher = Agent(\n    role=\"Video Researcher\",\n    goal=\"Extract and analyze information from YouTube videos\",\n    backstory=\"\"\"You are an expert video researcher who specializes in extracting \n    and analyzing information from YouTube videos. You have a keen eye for detail \n    and can quickly identify key points and insights from video content.\"\"\",\n    tools=[youtube_search_tool],\n    verbose=True,\n)\n\n# Create a task for the agent\nresearch_task = Task(\n    description=\"\"\"\n    Search for information about recent advancements in artificial intelligence \n    in the YouTube video at {youtube_video_url}. \n    \n    Focus on:\n    1. Key AI technologies mentioned\n    2. Real-world applications discussed\n    3. Future predictions made by the speaker\n    \n    Provide a comprehensive summary of these points.\n    \"\"\",\n    expected_output=\"A detailed summary of AI advancements, applications, and future predictions from the video.\",\n    agent=video_researcher,\n)\n\n# Run the task\ncrew = Crew(agents=[video_researcher], tasks=[research_task])\nresult = crew.kickoff(inputs={\"youtube_video_url\": \"https://youtube.com/watch?v=example\"})\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of BedrockInvokeAgentTool in Python\nDESCRIPTION: Demonstrates how to initialize and use the BedrockInvokeAgentTool with a CrewAI agent, including creating a task and running a crew.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bedrockinvokeagenttool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool\n\n# Initialize the tool\nagent_tool = BedrockInvokeAgentTool(\n    agent_id=\"your-agent-id\",\n    agent_alias_id=\"your-agent-alias-id\"\n)\n\n# Create a CrewAI agent that uses the tool\naws_expert = Agent(\n    role='AWS Service Expert',\n    goal='Help users understand AWS services and quotas',\n    backstory='I am an expert in AWS services and can provide detailed information about them.',\n    tools=[agent_tool],\n    verbose=True\n)\n\n# Create a task for the agent\nquota_task = Task(\n    description=\"Find out the current service quotas for EC2 in us-west-2 and explain any recent changes.\",\n    agent=aws_expert\n)\n\n# Create a crew with the agent\ncrew = Crew(\n    agents=[aws_expert],\n    tasks=[quota_task],\n    verbose=2\n)\n\n# Run the crew\nresult = crew.kickoff()\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Version Command Examples\nDESCRIPTION: Examples showing how to check the CrewAI version, either basic version information or with the tools flag for additional details.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncrewai version\ncrewai version --tools\n```\n\n----------------------------------------\n\nTITLE: CrewAI Installation and Execution Commands\nDESCRIPTION: Shell commands for installing dependencies and running the CrewAI project\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncd my_project\ncrewai install\ncrewai run\n\n# or\n\npython src/my_project/main.py\n\n# If error occurs\ncrewai update\n```\n\n----------------------------------------\n\nTITLE: Executing CrewAI Flow\nDESCRIPTION: Commands to run a CrewAI flow. Two alternative methods are provided using either the 'crewai' command or 'uv' command.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ncrewai flow kickoff\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv run kickoff\n```\n\n----------------------------------------\n\nTITLE: Replay Command Example\nDESCRIPTION: Example showing how to replay a crew execution starting from a specific task with ID 'task_123456'.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ncrewai replay -t task_123456\n```\n\n----------------------------------------\n\nTITLE: Defining Specialized Agents in CrewAI\nDESCRIPTION: Demonstrates how to create a detailed and specialized agent definition with a specific role, goal, and backstory using YAML in CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nagent:\n  role: \"SaaS Metrics Specialist focusing on growth-stage startups\"\n  goal: \"Identify actionable insights from business data that can directly impact customer retention and revenue growth\"\n  backstory: \"With 10+ years analyzing SaaS business models, you've developed a keen eye for the metrics that truly matter for sustainable growth. You've helped numerous companies identify the leverage points that turned around their business trajectory. You believe in connecting data to specific, actionable recommendations rather than general observations.\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Configuration in Python\nDESCRIPTION: Implementation of the configure_tools method for adapting CrewAI tools to the external agent's expected format.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:\n    if tools:\n        adapted_tools = []\n        for tool in tools:\n            # Adapt CrewAI BaseTool to the format your agent expects\n            # Example: adapted_tool = adapt_to_my_framework(tool)\n            # adapted_tools.append(adapted_tool)\n            pass # Replace with your actual adaptation logic\n\n        # Configure the external agent with the adapted tools\n        # Example: self.external_agent.set_tools(adapted_tools)\n        print(f\"Configuring tools for MyCustomAgentAdapter: {adapted_tools}\") # Placeholder\n    else:\n        # Handle the case where no tools are provided\n        # Example: self.external_agent.set_tools([])\n        print(\"No tools provided for MyCustomAgentAdapter.\")\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for BedrockInvokeAgentTool\nDESCRIPTION: Example of environment variables used for configuring the BedrockInvokeAgentTool, including AWS credentials and Bedrock agent details.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bedrockinvokeagenttool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nBEDROCK_AGENT_ID=your-agent-id           # Alternative to passing agent_id\nBEDROCK_AGENT_ALIAS_ID=your-agent-alias-id # Alternative to passing agent_alias_id\nAWS_REGION=your-aws-region               # Defaults to us-west-2\nAWS_ACCESS_KEY_ID=your-access-key        # Required for AWS authentication\nAWS_SECRET_ACCESS_KEY=your-secret-key    # Required for AWS authentication\n```\n\n----------------------------------------\n\nTITLE: Accessing Component Fingerprints in CrewAI\nDESCRIPTION: Demonstrates how to create Agent, Crew, and Task components in CrewAI and access their automatically generated fingerprints. Shows how to retrieve and print the UUID strings that uniquely identify each component.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/advanced/fingerprinting.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Crew, Task\n\n# Create components - fingerprints are automatically generated\nagent = Agent(\n    role=\"Data Scientist\",\n    goal=\"Analyze data\",\n    backstory=\"Expert in data analysis\"\n)\n\ncrew = Crew(\n    agents=[agent],\n    tasks=[]\n)\n\ntask = Task(\n    description=\"Analyze customer data\",\n    expected_output=\"Insights from data analysis\",\n    agent=agent\n)\n\n# Access the fingerprints\nagent_fingerprint = agent.fingerprint\ncrew_fingerprint = crew.fingerprint\ntask_fingerprint = task.fingerprint\n\n# Print the UUID strings\nprint(f\"Agent fingerprint: {agent_fingerprint.uuid_str}\")\nprint(f\"Crew fingerprint: {crew_fingerprint.uuid_str}\")\nprint(f\"Task fingerprint: {task_fingerprint.uuid_str}\")\n```\n\n----------------------------------------\n\nTITLE: ScrapegraphScrapeTool Implementation\nDESCRIPTION: Core implementation of the ScrapegraphScrapeTool class showing the main scraping logic and error handling.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapegraphscrapetool.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass ScrapegraphScrapeTool(BaseTool):\n    \"\"\"\n    A tool that uses Scrapegraph AI to intelligently scrape website content.\n    \"\"\"\n    \n    # Implementation details...\n    \n    def _run(self, **kwargs: Any) -> Any:\n        website_url = kwargs.get(\"website_url\", self.website_url)\n        user_prompt = (\n            kwargs.get(\"user_prompt\", self.user_prompt)\n            or \"Extract the main content of the webpage\"\n        )\n\n        if not website_url:\n            raise ValueError(\"website_url is required\")\n\n        # Validate URL format\n        self._validate_url(website_url)\n\n        try:\n            # Make the SmartScraper request\n            response = self._client.smartscraper(\n                website_url=website_url,\n                user_prompt=user_prompt,\n            )\n\n            return response\n        # Error handling...\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS Bedrock Environment Variables for CrewAI\nDESCRIPTION: Sets up the necessary AWS environment variables for using AWS Bedrock with CrewAI, including access key, secret key, and region.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\nAWS_ACCESS_KEY_ID=<your-access-key>\nAWS_SECRET_ACCESS_KEY=<your-secret-key>\nAWS_DEFAULT_REGION=<your-region>\n```\n\n----------------------------------------\n\nTITLE: Checking CrewAI Version\nDESCRIPTION: Command to display the installed version of CrewAI, with an optional flag to show the version of CrewAI tools.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncrewai version [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Setting Up Azure OpenAI Environment Variables for CrewAI\nDESCRIPTION: Configures the required and optional environment variables for using Azure OpenAI with CrewAI, including API key, base URL, and version.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n# Required\nAZURE_API_KEY=<your-api-key>\nAZURE_API_BASE=<your-resource-url>\nAZURE_API_VERSION=<api-version>\n\n# Optional\nAZURE_AD_TOKEN=<your-azure-ad-token>\nAZURE_API_TYPE=<your-azure-api-type>\n```\n\n----------------------------------------\n\nTITLE: Running the CrewAI Project\nDESCRIPTION: This command executes the CrewAI project, starting the research and reporting workflow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ncrewai run\n```\n\n----------------------------------------\n\nTITLE: Running the CrewAI Project\nDESCRIPTION: Command to execute the CrewAI project, initializing the AI agents and starting the task execution process. This should be run from the root folder of the project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/crew/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ crewai run\n```\n\n----------------------------------------\n\nTITLE: Initializing a Listeners Package with Module Imports\nDESCRIPTION: Example demonstrating how to create an __init__.py file in a listeners package that imports listener instances to ensure they're loaded when the package is imported.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# __init__.py\nfrom .my_custom_listener import my_custom_listener\nfrom .another_listener import another_listener\n\n# Optionally export them if you need to access them elsewhere\n__all__ = ['my_custom_listener', 'another_listener']\n```\n\n----------------------------------------\n\nTITLE: Configuring Agent Delegation\nDESCRIPTION: Example demonstrating how to configure an agent's delegation capabilities by setting the allow_delegation parameter during initialization.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/customizing-agents.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nagent = Agent(\n  role='Content Writer',\n  goal='Write engaging content on market trends',\n  backstory='A seasoned writer with expertise in market analysis.',\n  allow_delegation=True # Enabling delegation\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Caching Settings\nDESCRIPTION: Example of configuring caching settings using Portkey's config system, showing how to enable semantic or simple caching.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/portkey-observability.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconfig = {\n    \"cache\": {\n        \"mode\": \"semantic\",  # or \"simple\" for exact matching\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Resetting Memory via CrewAI Crew Object\nDESCRIPTION: Programmatic approach to reset memory components using the Crew object's reset_memories method.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"custom\",\n        \"config\": {\n            \"embedder\": CustomEmbedder()\n        }\n    }\n)\n\nmy_crew.reset_memories(command_type = 'all') # Resets all the memory\n```\n\n----------------------------------------\n\nTITLE: YoutubeVideoSearchTool Class Implementation\nDESCRIPTION: The core implementation of the YoutubeVideoSearchTool class, showing its inheritance from RagTool and initialization logic.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubevideosearchtool.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass YoutubeVideoSearchTool(RagTool):\n    name: str = \"Search a Youtube Video content\"\n    description: str = \"A tool that can be used to semantic search a query from a Youtube Video content.\"\n    args_schema: Type[BaseModel] = YoutubeVideoSearchToolSchema\n\n    def __init__(self, youtube_video_url: Optional[str] = None, **kwargs):\n        super().__init__(**kwargs)\n        if youtube_video_url is not None:\n            kwargs[\"data_type\"] = DataType.YOUTUBE_VIDEO\n            self.add(youtube_video_url)\n            self.description = f\"A tool that can be used to semantic search a query the {youtube_video_url} Youtube Video content.\"\n            self.args_schema = FixedYoutubeVideoSearchToolSchema\n            self._generate_description()\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Gemini Environment Variables for CrewAI\nDESCRIPTION: Sets up the environment variables for using Google's Gemini API or Vertex AI with CrewAI, providing options for API key or IAM credentials.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n# Option 1: Gemini accessed with an API key.\n# https://ai.google.dev/gemini-api/docs/api-key\nGEMINI_API_KEY=<your-api-key>\n\n# Option 2: Vertex AI IAM credentials for Gemini, Anthropic, and Model Garden.\n# https://cloud.google.com/vertex-ai/generative-ai/docs/overview\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for ApifyActorsTool in Python\nDESCRIPTION: This snippet shows how to install the required dependencies for using ApifyActorsTool with CrewAI. It installs crewai with tools support and the langchain-apify package.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/apifyactorstool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install 'crewai[tools]' langchain-apify\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools and Selenium Dependencies\nDESCRIPTION: Commands to install the necessary packages for using the SeleniumScrapingTool, including CrewAI tools and Selenium.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/seleniumscrapingtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\nuv add selenium webdriver-manager\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI CLI using uv\nDESCRIPTION: Command to install the CrewAI CLI tool using the uv package manager. This is the main installation step for CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nuv tool install crewai\n```\n\n----------------------------------------\n\nTITLE: Viewing Latest Kickoff Task IDs using Shell Command\nDESCRIPTION: Command to view all task IDs from the latest crew kickoff, which helps identify which task to replay.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/replay-tasks-from-latest-crew-kickoff.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncrewai log-tasks-outputs\n```\n\n----------------------------------------\n\nTITLE: S3WriterTool Implementation Code\nDESCRIPTION: Core implementation of the S3WriterTool class showing AWS SDK integration and error handling\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/s3writertool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass S3WriterTool(BaseTool):\n    name: str = \"S3 Writer Tool\"\n    description: str = \"Writes content to a file in Amazon S3 given an S3 file path\"\n    \n    def _run(self, file_path: str, content: str) -> str:\n        try:\n            bucket_name, object_key = self._parse_s3_path(file_path)\n\n            s3 = boto3.client(\n                's3',\n                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),\n                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),\n                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')\n            )\n\n            s3.put_object(Bucket=bucket_name, Key=object_key, Body=content.encode('utf-8'))\n            return f\"Successfully wrote content to {file_path}\"\n        except ClientError as e:\n            return f\"Error writing file to S3: {str(e)}\"\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI-Compatible LLM Environment Variables in Python\nDESCRIPTION: Demonstrates how to set environment variables for connecting to OpenAI-compatible LLMs, including API key, base URL, and model name.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/llm-connections.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\nos.environ[\"OPENAI_API_BASE\"] = \"https://api.your-provider.com/v1\"\nos.environ[\"OPENAI_MODEL_NAME\"] = \"your-model-name\"\n```\n\n----------------------------------------\n\nTITLE: Installing EXA Search Tool Dependencies\nDESCRIPTION: Command to install the crewai tools package which includes the EXASearchTool functionality.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/exasearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Initializing Agents with Different LLMs in Python\nDESCRIPTION: Demonstrates how to create CrewAI agents using different LLMs by passing the model name as a string when initializing the agent.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/llm-connections.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent\n\n# Using OpenAI's GPT-4\nopenai_agent = Agent(\n    role='OpenAI Expert',\n    goal='Provide insights using GPT-4',\n    backstory=\"An AI assistant powered by OpenAI's latest model.\",\n    llm='gpt-4'\n)\n\n# Using Anthropic's Claude\nclaude_agent = Agent(\n    role='Anthropic Expert',\n    goal='Analyze data using Claude',\n    backstory=\"An AI assistant leveraging Anthropic's language model.\",\n    llm='claude-2'\n)\n```\n\n----------------------------------------\n\nTITLE: Specifying Detailed Task Instructions in YAML for CrewAI\nDESCRIPTION: Shows how to create a detailed task description with explicit instructions on inputs, analysis focus, and expected output format using YAML in CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nanalysis_task:\n  description: >\n    Analyze the customer feedback data from the CSV file.\n    Focus on identifying recurring themes related to product usability.\n    Consider sentiment and frequency when determining importance.\n  expected_output: >\n    A markdown report with the following sections:\n    1. Executive summary (3-5 bullet points)\n    2. Top 3 usability issues with supporting data\n    3. Recommendations for improvement\n```\n\n----------------------------------------\n\nTITLE: Installing SpiderTool and CrewAI dependencies\nDESCRIPTION: Command to install the Spider SDK and CrewAI tools using pip. This step is necessary before using the SpiderTool in your project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/spidertool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install spider-client 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Initializing CrewAI with Bedrock Embeddings\nDESCRIPTION: Sets up a CrewAI crew with AWS Bedrock embeddings integration. Requires boto3 installation and AWS credentials configuration through environment variables.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport boto3\nfrom crewai import Crew, Agent, Task, Process\n\nboto3_session = boto3.Session(\n    region_name=os.environ.get(\"AWS_REGION_NAME\"),\n    aws_access_key_id=os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n    aws_secret_access_key=os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n)\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    embedder={\n    \"provider\": \"bedrock\",\n        \"config\":{\n            \"session\": boto3_session,\n            \"model\": \"amazon.titan-embed-text-v2:0\",\n            \"vector_dimension\": 1024\n        }\n    }\n    verbose=True\n)\n```\n\n----------------------------------------\n\nTITLE: Installing SerperDevTool via pip\nDESCRIPTION: This command installs the crewai package with the tools extension, which includes the SerperDevTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/serperdevtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Project Directory Structure for CrewAI\nDESCRIPTION: Example directory structure showing the files and folders created when scaffolding a new CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nmy_project/\n .gitignore\n knowledge/\n pyproject.toml\n README.md\n .env\n src/\n     my_project/\n         __init__.py\n         main.py\n         crew.py\n         tools/\n            custom_tool.py\n            __init__.py\n         config/\n             agents.yaml\n             tasks.yaml\n```\n\n----------------------------------------\n\nTITLE: Basic CrewAI CLI Command Structure\nDESCRIPTION: The fundamental structure for all CrewAI CLI commands, consisting of a main command, options, and arguments.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncrewai [COMMAND] [OPTIONS] [ARGUMENTS]\n```\n\n----------------------------------------\n\nTITLE: Writing Detailed Agent Backstories in CrewAI\nDESCRIPTION: Examples of effective backstories that establish agent expertise, experience, working style, and values. A good backstory creates a cohesive persona that aligns with the agent's role and goal.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/agents/crafting-effective-agents.mdx#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nbackstory: \"You have spent 15 years conducting and analyzing user research for top tech companies. You have a talent for reading between the lines and identifying patterns that others miss. You believe that good UX is invisible and that the best insights come from listening to what users don't say as much as what they do say.\"\n\nbackstory: \"With 20+ years of experience building distributed systems at scale, you've developed a pragmatic approach to software architecture. You've seen both successful and failed systems and have learned valuable lessons from each. You balance theoretical best practices with practical constraints and always consider the maintenance and operational aspects of your designs.\"\n\nbackstory: \"As a seasoned communications professional who has guided multiple organizations through high-profile crises, you understand the importance of transparency, speed, and empathy in crisis response. You have a methodical approach to crafting messages that address concerns while maintaining organizational credibility.\"\n```\n\n----------------------------------------\n\nTITLE: Registering Event Listener in Crew-based Applications\nDESCRIPTION: Example demonstrating how to import and instantiate a custom event listener at the top of a Crew implementation file, ensuring the listener is active when the Crew is executed.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# In your crew.py file\nfrom crewai import Agent, Crew, Task\nfrom my_listeners import MyCustomListener\n\n# Create an instance of your listener\nmy_listener = MyCustomListener()\n\nclass MyCustomCrew:\n    # Your crew implementation...\n\n    def crew(self):\n        return Crew(\n            agents=[...],\n            tasks=[...],\n            # ...\n        )\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools Package\nDESCRIPTION: Command to install the CrewAI tools package with additional dependencies.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tools.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Custom Retry Logic Configuration in CrewAI\nDESCRIPTION: Example of configuring custom retry logic for task validation with a specified maximum number of retry attempts.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ntask = Task(\n    description=\"Generate data\",\n    expected_output=\"Valid data\",\n    guardrail=validate_data,\n    max_retries=5  # Override default retry limit\n)\n```\n\n----------------------------------------\n\nTITLE: Installing crewai_tools Package for CSVSearchTool\nDESCRIPTION: Command to install the crewai_tools package, which includes the CSVSearchTool for RAG-based CSV searching.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/csvsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Memory Reset Examples\nDESCRIPTION: Examples showing how to reset specific memory types (long and short term) or all memory types at once.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ncrewai reset-memories --long --short\ncrewai reset-memories --all\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Command to install all required dependencies for a CrewAI project. Should be run before executing your crew for the first time.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncrewai install\n```\n\n----------------------------------------\n\nTITLE: Setting Fireworks AI API Key in Environment Variables\nDESCRIPTION: Shows how to set the Fireworks AI API key in the .env file for use with CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_26\n\nLANGUAGE: toml\nCODE:\n```\nFIREWORKS_API_KEY=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Running CrewAI Test with Custom Parameters (Long Form)\nDESCRIPTION: Test your crew with specified number of iterations and a custom model using long-form parameter names. This example runs 5 iterations using the gpt-4o model.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/testing.mdx#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncrewai test --n_iterations 5 --model gpt-4o\n```\n\n----------------------------------------\n\nTITLE: Resetting Crew Memories\nDESCRIPTION: Command to reset different types of crew memories, with options to specify which memory types to reset.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ncrewai reset-memories [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with CrewAI CLI\nDESCRIPTION: Command line instructions for installing required dependencies using the CrewAI CLI tool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/crews/first-crew.mdx#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncrewai install\n```\n\n----------------------------------------\n\nTITLE: Starting OpenLIT Docker Compose\nDESCRIPTION: Command to start OpenLIT services using Docker Compose from the root directory of the OpenLIT repository.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/openlit-observability.mdx#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Running CrewAI Flow using Python API\nDESCRIPTION: Python code to programmatically run a CrewAI flow by creating an instance of the flow class and calling the kickoff() method.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nflow = ExampleFlow()\nresult = flow.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Installing crewai_tools Package\nDESCRIPTION: Command to install the crewai_tools package, which includes the DallETool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/dalletool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Initializing MLflow for CrewAI Tracing\nDESCRIPTION: Python code to initialize MLflow for CrewAI tracing by enabling autolog and optionally setting tracking URI and experiment name.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/mlflow-observability.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport mlflow\n\nmlflow.crewai.autolog()\n\n# Optional: Set a tracking URI and an experiment name if you have a tracking server\nmlflow.set_tracking_uri(\"http://localhost:5000\")\nmlflow.set_experiment(\"CrewAI\")\n```\n\n----------------------------------------\n\nTITLE: Using CrewAI CLI Memory Reset Commands\nDESCRIPTION: Command line interface options for resetting different types of CrewAI memory components.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\ncrewai reset-memories [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for CrewAI Flow\nDESCRIPTION: Command to install dependencies for a CrewAI flow project. This step is optional and should be run before executing the flow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ncrewai install\n```\n\n----------------------------------------\n\nTITLE: Installing Composio and CrewAI Dependencies\nDESCRIPTION: Commands to install the required Python packages for using Composio with CrewAI\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install composio-crewai\npip install crewai\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for CrewAI\nDESCRIPTION: Environment configuration file containing API keys for OpenAI and Serper services required by the CrewAI framework.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/crews/first-crew.mdx#2025-04-22_snippet_5\n\nLANGUAGE: plaintext\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\nSERPER_API_KEY=your_serper_api_key\n```\n\n----------------------------------------\n\nTITLE: Installing WebsiteSearchTool Dependencies with pip\nDESCRIPTION: Command to install the crewai package with tools extension, which includes necessary dependencies for WebsiteSearchTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/websitesearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Configuring Opik Integration\nDESCRIPTION: Basic configuration setup for Opik integration using remote server.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/opik-observability.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport opik\nopik.configure(use_local=False)\n```\n\n----------------------------------------\n\nTITLE: Executing CrewAI Task\nDESCRIPTION: Example of creating and executing a CrewAI task for starring a GitHub repository\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntask = Task(\n    description=\"Star a repo composiohq/composio on GitHub\",\n    agent=crewai_agent,\n    expected_output=\"Status of the operation\",\n)\n\ncrew = Crew(agents=[crewai_agent], tasks=[task])\n\ncrew.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Installing DirectorySearchTool via pip\nDESCRIPTION: Command to install the crewai_tools package with required dependencies for DirectorySearchTool functionality.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/directorysearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing PDFSearchTool via pip\nDESCRIPTION: Command to install the crewai_tools package with PDF search capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/pdfsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Setting SambaNova API Key in Environment Variables\nDESCRIPTION: Shows how to set the SambaNova API key in the .env file for use with CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_32\n\nLANGUAGE: toml\nCODE:\n```\nSAMBANOVA_API_KEY=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installation of necessary Python packages including langfuse, openlit, crewai, and crewai_tools using pip.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/langfuse-observability.mdx#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install langfuse openlit crewai crewai_tools\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for API Keys\nDESCRIPTION: Python code to configure environment variables for Phoenix Cloud, OpenAI, and Serper API credentials using getpass for secure input.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/arize-phoenix-observability.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\n\n# Get your Phoenix Cloud credentials\nPHOENIX_API_KEY = getpass(\" Enter your Phoenix Cloud API Key: \")\n\n# Get API keys for services\nOPENAI_API_KEY = getpass(\" Enter your OpenAI API key: \")\nSERPER_API_KEY = getpass(\" Enter your Serper API key: \")\n\n# Set environment variables\nos.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\nos.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\"\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\nos.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Navigating to the Crew Project Directory\nDESCRIPTION: This command changes the current directory to the newly created crew project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncd latest-ai-development\n```\n\n----------------------------------------\n\nTITLE: Custom Model Configuration\nDESCRIPTION: Example showing how to configure custom models and embeddings for the YoutubeChannelSearchTool\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubechannelsearchtool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nyoutube_channel_tool = YoutubeChannelSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"ollama\", # or google, openai, anthropic, llama2, ...\n            config=dict(\n                model=\"llama2\",\n                # temperature=0.5,\n                # top_p=1,\n                # stream=true,\n            ),\n        ),\n        embedder=dict(\n            provider=\"google\", # or openai, ollama, ...\n            config=dict(\n                model=\"models/embedding-001\",\n                task_type=\"retrieval_document\",\n                # title=\"Embeddings\",\n            ),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Browserbase and CrewAI Tools\nDESCRIPTION: Command to install the Browserbase SDK and CrewAI tools package using pip.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/browserbaseloadtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install browserbase 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Defining CrewAI Agent\nDESCRIPTION: Configuration of a CrewAI agent with GitHub tools and specific role parameters\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ncrewai_agent = Agent(\n    role=\"GitHub Agent\",\n    goal=\"You take action on GitHub using GitHub APIs\",\n    backstory=\"You are AI agent that is responsible for taking actions on GitHub on behalf of users using GitHub APIs\",\n    verbose=True,\n    tools=tools,\n    llm= # pass an llm\n)\n```\n\n----------------------------------------\n\nTITLE: Installing crewai_tools Package\nDESCRIPTION: Command to install the crewai_tools package, which includes the MDXSearchTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/mdxsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Basic CrewAI Task Execution\nDESCRIPTION: Simple example of starting a crew's task execution using the basic kickoff() method and displaying the result.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/crews.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Start the crew's task execution\nresult = my_crew.kickoff()\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Installing TXTSearchTool via pip\nDESCRIPTION: Command to install the crewai_tools package, which includes the TXTSearchTool, using pip package manager for Python.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/txtsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Setting Perplexity AI API Key in Environment Variables\nDESCRIPTION: Shows how to set the Perplexity AI API key in the .env file for use with CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_28\n\nLANGUAGE: toml\nCODE:\n```\nPERPLEXITY_API_KEY=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Installing OpenLIT SDK\nDESCRIPTION: Command to install the OpenLIT SDK using pip.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/openlit-observability.mdx#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npip install openlit\n```\n\n----------------------------------------\n\nTITLE: Setting IBM watsonx.ai Environment Variables\nDESCRIPTION: Demonstrates how to set required and optional environment variables for IBM watsonx.ai integration with CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_23\n\nLANGUAGE: toml\nCODE:\n```\n# Required\nWATSONX_URL=<your-url>\nWATSONX_APIKEY=<your-apikey>\nWATSONX_PROJECT_ID=<your-project-id>\n\n# Optional\nWATSONX_TOKEN=<your-token>\nWATSONX_DEPLOYMENT_SPACE_ID=<your-space-id>\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for CrewAI Guide Creator\nDESCRIPTION: Command to install required dependencies for the guide creation system using CrewAI's installation tool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncrewai install\n```\n\n----------------------------------------\n\nTITLE: Setting Cerebras API Key in Environment Variables\nDESCRIPTION: Shows how to set the Cerebras API key in the .env file for use with CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_34\n\nLANGUAGE: toml\nCODE:\n```\n# Required\nCEREBRAS_API_KEY=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Installing Hyperbrowser SDK\nDESCRIPTION: Command to install the Hyperbrowser SDK using uv package manager\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/hyperbrowserloadtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add hyperbrowser\n```\n\n----------------------------------------\n\nTITLE: Using Specific GitHub Actions\nDESCRIPTION: Example of selecting a specific GitHub action for repository starring\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntools = toolset.get_tools(\n    actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]\n)\n```\n\n----------------------------------------\n\nTITLE: Installing S3WriterTool Dependencies\nDESCRIPTION: Command to install the required boto3 package using uv package manager\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/s3writertool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add boto3\n```\n\n----------------------------------------\n\nTITLE: Installing crewai_tools Package for MySQL RAG Search\nDESCRIPTION: Command to install the crewai_tools package, which includes the MySQLSearchTool for performing semantic searches on MySQL databases.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/mysqltool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Creating CrewAI Project Directory\nDESCRIPTION: CLI commands to create and navigate to a new CrewAI project directory\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/crews/first-crew.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncrewai create crew research_crew\ncd research_crew\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Opik and CrewAI\nDESCRIPTION: Command to install the necessary Python packages including crewai, crewai-tools, and opik.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/opik-observability.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install crewai crewai-tools opik --upgrade\n```\n\n----------------------------------------\n\nTITLE: Testing a CrewAI Crew\nDESCRIPTION: Command to test a crew and evaluate results, with options for iteration count and LLM model selection.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ncrewai test [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Setting Groq API Key in Environment Variables\nDESCRIPTION: Demonstrates how to set the Groq API key in the .env file for use with CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_21\n\nLANGUAGE: toml\nCODE:\n```\nGROQ_API_KEY=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Sample AI Agents Report Output\nDESCRIPTION: This is an example of the markdown report output generated by the reporting analyst agent, showing how the final report is structured with sections on AI agents.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n# Comprehensive Report on the Rise and Impact of AI Agents in 2025\n\n## 1. Introduction to AI Agents\nIn 2025, Artificial Intelligence (AI) agents are at the forefront of innovation across various industries. As intelligent systems that can perform tasks typically requiring human cognition, AI agents are paving the way for significant advancements in operational efficiency, decision-making, and overall productivity within sectors like Human Resources (HR) and Finance. This report aims to detail the rise of AI agents, their frameworks, applications, and potential implications on the workforce.\n\n## 2. Benefits of AI Agents\nAI agents bring numerous advantages that are transforming traditional work environments. Key benefits include:\n\n- **Task Automation**: AI agents can carry out repetitive tasks such as data entry, scheduling, and payroll processing without human intervention, greatly reducing the time and resources spent on these activities.\n- **Improved Efficiency**: By quickly processing large datasets and performing analyses that would take humans significantly longer, AI agents enhance operational efficiency. This allows teams to focus on strategic tasks that require higher-level thinking.\n- **Enhanced Decision-Making**: AI agents can analyze trends and patterns in data, provide insights, and even suggest actions, helping stakeholders make informed decisions based on factual data rather than intuition alone.\n\n## 3. Popular AI Agent Frameworks\nSeveral frameworks have emerged to facilitate the development of AI agents, each with its own unique features and capabilities. Some of the most popular frameworks include:\n\n- **Autogen**: A framework designed to streamline the development of AI agents through automation of code generation.\n```\n\n----------------------------------------\n\nTITLE: Installing MultiOn Package via UV Package Manager\nDESCRIPTION: Command to install the required MultiOn package using the UV package manager\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/multiontool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add multion\n```\n\n----------------------------------------\n\nTITLE: Setting Hugging Face Token in Environment Variables\nDESCRIPTION: Shows how to set the Hugging Face token in the .env file for use with CrewAI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_30\n\nLANGUAGE: toml\nCODE:\n```\nHF_TOKEN=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Installing Weaviate Client\nDESCRIPTION: Command to install the Weaviate client package using uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/weaviatevectorsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add weaviate-client\n```\n\n----------------------------------------\n\nTITLE: Initializing DOCXSearchTool in Python\nDESCRIPTION: Examples showing how to initialize the DOCXSearchTool either for general use or with a specific DOCX file path\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/docxsearchtool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import DOCXSearchTool\n\n# Initialize the tool to search within any DOCX file's content\ntool = DOCXSearchTool()\n\n# OR\n\n# Initialize the tool with a specific DOCX file, \n# so the agent can only search the content of the specified DOCX file\ntool = DOCXSearchTool(docx='path/to/your/document.docx')\n```\n\n----------------------------------------\n\nTITLE: Publishing a CrewAI Tool\nDESCRIPTION: Command to publish a CrewAI tool, allowing collaboration within an organization or public contribution to the community. Replace {{tool_name}} with the actual name of the tool being published.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/tool/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncrewai tool publish {{tool_name}}\n```\n\n----------------------------------------\n\nTITLE: Installing Firecrawl Dependencies with pip\nDESCRIPTION: Command to install the Firecrawl SDK and crewai tools package using pip package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/firecrawlsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install firecrawl-py 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Implementing Helper Method for Tool Adaptation in Python\nDESCRIPTION: This snippet shows an example helper method for adapting a CrewAI BaseTool to a specific external agent framework, including handling of both synchronous and asynchronous tool implementations.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/bring-your-own-agent.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef adapt_tool_to_my_framework(self, tool: BaseTool, sanitized_name: str) -> Any:\n    # Replace this with the actual logic to convert a CrewAI BaseTool\n    # to the format needed by your specific external agent framework.\n    # This will vary greatly depending on the target framework.\n    adapted_representation = {\n        \"framework_specific_name\": sanitized_name,\n        \"framework_specific_description\": tool.description,\n        \"inputs\": tool.args_schema.schema() if tool.args_schema else None,\n        \"implementation_reference\": tool.run # Or however the framework needs to call it\n    }\n    # Also ensure the tool works both sync and async\n    async def async_tool_wrapper(*args, **kwargs):\n        output = tool.run(*args, **kwargs)\n        if inspect.isawaitable(output):\n            return await output\n        else:\n            return output\n\n    adapted_tool = MyFrameworkTool(\n        name=sanitized_name,\n        description=tool.description,\n        inputs=tool.args_schema.schema() if tool.args_schema else None,\n        implementation_reference=async_tool_wrapper\n    )\n    \n    return adapted_representation\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for S3ReaderTool\nDESCRIPTION: Command to install the required boto3 package using uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/s3readertool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add boto3\n```\n\n----------------------------------------\n\nTITLE: Generating Plot for CrewAI Flow using CLI\nDESCRIPTION: Command line instruction to generate an interactive HTML plot of a CrewAI flow. This method is useful for larger projects or when working within a structured CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ncrewai flow plot\n```\n\n----------------------------------------\n\nTITLE: Installing a Published CrewAI Tool\nDESCRIPTION: Command for other users to install a published CrewAI tool in their crews. Replace {{tool_name}} with the name of the tool to be installed.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/tool/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncrewai tool install {{tool_name}}\n```\n\n----------------------------------------\n\nTITLE: AWS Environment Variables Configuration\nDESCRIPTION: Required environment variables for AWS authentication and Bedrock Knowledge Base configuration\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bedrockkbretriever.mdx#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nBEDROCK_KB_ID=your-knowledge-base-id  # Alternative to passing knowledge_base_id\nAWS_REGION=your-aws-region            # Defaults to us-east-1\nAWS_ACCESS_KEY_ID=your-access-key     # Required for AWS authentication\nAWS_SECRET_ACCESS_KEY=your-secret-key # Required for AWS authentication\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools Package\nDESCRIPTION: Command to install the CrewAI tools package using pip\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/customizing-agents.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing FileWriterTool Package\nDESCRIPTION: Command to install the crewai_tools package with all required dependencies for using FileWriterTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/filewritetool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Using Ollama Embeddings in CrewAI\nDESCRIPTION: This snippet demonstrates how to configure a Crew to use Ollama embeddings. It specifies the Ollama provider and the model to be used for embeddings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"ollama\",\n        \"config\": {\n            \"model\": \"mxbai-embed-large\"\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Replaying CrewAI Execution\nDESCRIPTION: Command to replay a crew execution from a specific task ID, including all subsequent tasks that were executed.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ncrewai replay [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for ScrapeElementFromWebsiteTool in Python\nDESCRIPTION: Command to install the required dependencies (requests and beautifulsoup4) for the ScrapeElementFromWebsiteTool using the uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapeelementfromwebsitetool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add requests beautifulsoup4\n```\n\n----------------------------------------\n\nTITLE: Installing Scrapfly SDK with UV Package Manager\nDESCRIPTION: Command to install the required Scrapfly SDK dependency using the UV package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapflyscrapetool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add scrapfly-sdk\n```\n\n----------------------------------------\n\nTITLE: Installing XMLSearchTool via pip\nDESCRIPTION: Command to install the crewai_tools package, which includes the XMLSearchTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/xmlsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Activating Virtual Environment for CrewAI\nDESCRIPTION: Command to activate the virtual environment for a CrewAI project. This step is necessary before running the flow.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nsource .venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Project Dependencies\nDESCRIPTION: Command to install project dependencies for a CrewAI tool using the UV package manager. This should be run in the project directory after UV is installed.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/tool/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncrewai install\n```\n\n----------------------------------------\n\nTITLE: Initializing IBM watsonx.ai LLM in CrewAI\nDESCRIPTION: Shows how to initialize an IBM watsonx.ai LLM for use in a CrewAI project, specifying the model and base URL.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"watsonx/meta-llama/llama-3-1-70b-instruct\",\n    base_url=\"https://api.watsonx.ai/v1\"\n)\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI and Weave packages with pip\nDESCRIPTION: Command to install the required packages for integrating CrewAI with Weave for tracing and monitoring.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/weave-integration.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install crewai weave\n```\n\n----------------------------------------\n\nTITLE: Installing JSONSearchTool via pip\nDESCRIPTION: Command to install the JSONSearchTool using pip. This installs the tool along with its dependencies.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/jsonsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing Langtrace SDK for CrewAI\nDESCRIPTION: Command to install the Langtrace Python SDK via pip package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/langtrace-observability.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install langtrace-python-sdk\n```\n\n----------------------------------------\n\nTITLE: Running a CrewAI Project\nDESCRIPTION: Command to execute your CrewAI project from the root directory after installation and configuration are complete.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ncrewai run\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools Package with pip\nDESCRIPTION: Command to install the crewai_tools package, which includes the YoutubeVideoSearchTool, using pip.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubevideosearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenLIT with Environment Variables\nDESCRIPTION: Code snippet to initialize OpenLIT using environment variables in a Python application.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/openlit-observability.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport openlit\n\nopenlit.init()\n```\n\n----------------------------------------\n\nTITLE: Installing UV Package Manager for CrewAI\nDESCRIPTION: Command to install UV, a dependency management and package handling tool used for CrewAI projects. UV offers a seamless setup and execution experience.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/tool/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install uv\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Langfuse and OpenAI\nDESCRIPTION: Setting up environment variables for Langfuse authentication and OpenTelemetry export configuration, including API keys and endpoints.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/langfuse-observability.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport base64\n\nLANGFUSE_PUBLIC_KEY=\"pk-lf-...\"\nLANGFUSE_SECRET_KEY=\"sk-lf-...\"\nLANGFUSE_AUTH=base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n\nos.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://cloud.langfuse.com/api/public/otel\" # EU data region\n# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://us.cloud.langfuse.com/api/public/otel\" # US data region\nos.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n\n# your openai key\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n```\n\n----------------------------------------\n\nTITLE: Using Amazon Bedrock Embeddings in CrewAI\nDESCRIPTION: This snippet is intended to demonstrate how to configure Amazon Bedrock embeddings in CrewAI. However, the code for this configuration is missing in the provided text.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_19\n\n\n\n----------------------------------------\n\nTITLE: Passing Variables to YAML Templates in Python\nDESCRIPTION: Example showing how to pass variables to YAML templates when running a crew, allowing dynamic content in task descriptions and expected outputs.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncrew.kickoff(inputs={'topic': 'AI Agents'})\n```\n\n----------------------------------------\n\nTITLE: Setting Scrapegraph API Key\nDESCRIPTION: Shell command to set the Scrapegraph API key as an environment variable.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapegraphscrapetool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport SCRAPEGRAPH_API_KEY=\"your_api_key\"\n```\n\n----------------------------------------\n\nTITLE: Installing uv on macOS/Linux using curl\nDESCRIPTION: Command to download and install uv dependency management tool on macOS or Linux systems using curl. uv is required for managing CrewAI packages.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI with pip\nDESCRIPTION: Commands to install the CrewAI package using pip, including optional features for additional tools.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install crewai\n```\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing MLflow Package for CrewAI Integration\nDESCRIPTION: Command to install MLflow package with version 2.19.0 or higher which includes support for CrewAI integration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/mlflow-observability.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# The crewAI integration is available in mlflow>=2.19.0\npip install mlflow\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI with Tools Support\nDESCRIPTION: Command to install CrewAI with additional tools support using the uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bedrockinvokeagenttool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing UV Package Manager\nDESCRIPTION: Command to install UV, a dependency management tool for Python projects. UV is used for efficient package handling in this project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/src/crewai/cli/templates/crew/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install uv\n```\n\n----------------------------------------\n\nTITLE: Initializing AWS Bedrock LLM in CrewAI\nDESCRIPTION: Shows how to initialize an AWS Bedrock LLM (specifically Claude 3 Sonnet) in a CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(\n    model=\"bedrock/anthropic.claude-3-sonnet-20240229-v1:0\"\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenLit SDK\nDESCRIPTION: Initialization of the OpenLit OpenTelemetry instrumentation SDK for trace capture.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/langfuse-observability.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport openlit\n\nopenlit.init()\n```\n\n----------------------------------------\n\nTITLE: Installing Qdrant Client Package\nDESCRIPTION: Command to install the required Qdrant client package using uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/qdrantvectorsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv add qdrant-client\n```\n\n----------------------------------------\n\nTITLE: Installing crewai_tools Package for GithubSearchTool\nDESCRIPTION: Command to install the crewai_tools package, which includes the GithubSearchTool and other related tools.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/githubsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing crewai_tools package with pip\nDESCRIPTION: Command to install the crewai_tools package, which includes the DirectoryReadTool, using pip. This step is necessary to use the tool in your project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/directoryreadtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing uv on macOS/Linux using wget\nDESCRIPTION: Alternative command to download and install uv dependency management tool on macOS or Linux systems using wget instead of curl.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nwget -qO- https://astral.sh/uv/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Setting OTEL Export Endpoint\nDESCRIPTION: Shell command to set the OTEL export endpoint environment variable for OpenLIT.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/openlit-observability.mdx#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nexport OTEL_EXPORTER_OTLP_ENDPOINT = \"http://127.0.0.1:4318\"\n```\n\n----------------------------------------\n\nTITLE: Configuring VoyageAI Embeddings in CrewAI\nDESCRIPTION: This example shows how to set up a Crew using VoyageAI embeddings. It includes the configuration for the VoyageAI provider, including API key and model selection.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Agent, Task, Process\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"voyageai\",\n        \"config\": {\n            \"api_key\": \"YOUR_API_KEY\",\n            \"model\": \"<model_name>\"\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Connecting GitHub Account via CLI\nDESCRIPTION: Command to add GitHub integration through Composio CLI\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncomposio add github\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools Package\nDESCRIPTION: Command to install the CrewAI tools package, which includes the CodeInterpreterTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/codeinterpretertool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools Package\nDESCRIPTION: Command to install the crewai_tools package with tools dependencies using pip\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/docxsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Cloning OpenLIT Repository\nDESCRIPTION: Command to clone the OpenLIT repository from GitHub.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/openlit-observability.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone git@github.com:openlit/openlit.git\n```\n\n----------------------------------------\n\nTITLE: Setting Up Amazon SageMaker Environment Variables for CrewAI\nDESCRIPTION: Configures the AWS environment variables necessary for using Amazon SageMaker with CrewAI, including access key, secret key, and region.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/llms.mdx#2025-04-22_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\nAWS_ACCESS_KEY_ID=<your-access-key>\nAWS_SECRET_ACCESS_KEY=<your-secret-key>\nAWS_DEFAULT_REGION=<your-region>\n```\n\n----------------------------------------\n\nTITLE: Installing crewai_tools Package with Tools Support\nDESCRIPTION: Command to install the crewai_tools package with tools support via pip, which is required to use the CodeDocsSearchTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/codedocssearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Error Handling Task Example\nDESCRIPTION: Example showing how to create a task that handles scraping failures gracefully using the ignore_scrape_failures parameter.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapflyscrapetool.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nerror_handling_task = Task(\n    description=\"\"\"\n    Extract content from a potentially problematic website and make sure to handle any \n    scraping failures gracefully by setting ignore_scrape_failures to True.\n    \"\"\",\n    expected_output=\"Either the extracted content or a graceful error message\",\n    agent=web_scraper_agent,\n)\n```\n\n----------------------------------------\n\nTITLE: Installing crewai_tools Package\nDESCRIPTION: Command to install the crewai_tools package with the 'tools' extra, which includes the ScrapeWebsiteTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapewebsitetool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: MultiOnTool Class Implementation\nDESCRIPTION: Core implementation of the MultiOnTool class showing the base structure and run method signature. This class extends BaseTool from CrewAI to provide web browsing capabilities.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/multiontool.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MultiOnTool(BaseTool):\n    \"\"\"Tool to wrap MultiOn Browse Capabilities.\"\"\"\n\n    name: str = \"Multion Browse Tool\"\n    description: str = \"\"\"Multion gives the ability for LLMs to control web browsers using natural language instructions.\n            If the status is 'CONTINUE', reissue the same instruction to continue execution\n        \"\"\"\n    \n    # Implementation details...\n    \n    def _run(self, cmd: str, *args: Any, **kwargs: Any) -> str:\n        \"\"\"\n        Run the Multion client with the given command.\n        \n        Args:\n            cmd (str): The detailed and specific natural language instruction for web browsing\n            *args (Any): Additional arguments to pass to the Multion client\n            **kwargs (Any): Additional keyword arguments to pass to the Multion client\n        \"\"\"\n        # Implementation details...\n```\n\n----------------------------------------\n\nTITLE: Installing NL2SQLTool via pip\nDESCRIPTION: Command to install the crewai_tools package, which includes the NL2SQLTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/nl2sqltool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of DallETool in Python\nDESCRIPTION: Example of how to use the DallETool with an Agent. The tool is initialized without custom parameters and added to the Agent's tool list.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/dalletool.mdx#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai_tools import DallETool\n\nAgent(\n    ...\n    tools=[DallETool()],\n)\n```\n\n----------------------------------------\n\nTITLE: Environment Configuration for CrewAI Guide Creator\nDESCRIPTION: Environment variable configuration for the guide creation system, specifying the required OpenAI API key.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/flows/first-flow.mdx#2025-04-22_snippet_6\n\nLANGUAGE: plaintext\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools Package\nDESCRIPTION: Command to install the crewai_tools package which contains the YoutubeChannelSearchTool\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/youtubechannelsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Implementing Email Format Validation in CrewAI\nDESCRIPTION: A guardrail function that validates email address format using regex pattern matching. Returns a tuple containing success status and either validated email or error message.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/tasks.mdx#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef validate_email_format(result: str) -> Tuple[bool, Union[str, str]]:\n    \"\"\"Ensure the output contains a valid email address.\"\"\"\n    import re\n    email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n    if re.match(email_pattern, result.strip()):\n        return (True, result.strip())\n    return (False, \"Output must be a valid email address\")\n```\n\n----------------------------------------\n\nTITLE: Registering AgentOps Listener in CrewAI\nDESCRIPTION: Code snippet showing how to register the AgentOps listener in CrewAI's event system through the utilities package initialization.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/event-listener.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom .agentops_listener import agentops_listener\n```\n\n----------------------------------------\n\nTITLE: Starting MLflow Tracking Server\nDESCRIPTION: Command to start the MLflow tracking server which provides visualization and broader features for monitoring CrewAI agents.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/mlflow-observability.mdx#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n# This process is optional, but it is recommended to use MLflow tracking server for better visualization and broader features.\nmlflow server\n```\n\n----------------------------------------\n\nTITLE: Running CrewAI Project Commands\nDESCRIPTION: Collection of common CrewAI CLI commands for managing and executing the project, including running the crew, testing, resetting memories, and replaying tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/crews/first-crew.mdx#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# View all available commands\ncrewai --help\n\n# Run the crew\ncrewai run\n\n# Test the crew\ncrewai test\n\n# Reset crew memories\ncrewai reset-memories\n\n# Replay from a specific task\ncrewai replay -t <task_id>\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Package via pip\nDESCRIPTION: Command to install the CrewAI package using pip, which is required before implementing human input functionality in agent execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/human-input-on-execution.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install crewai\n```\n\n----------------------------------------\n\nTITLE: Running CrewAI Flow using CLI\nDESCRIPTION: Command line instructions to run a CrewAI flow. The 'crewai run' command is the recommended method, while 'crewai flow kickoff' is provided for backward compatibility.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\ncrewai run\n```\n\nLANGUAGE: bash\nCODE:\n```\ncrewai flow kickoff\n```\n\n----------------------------------------\n\nTITLE: Using External Memory with Mem0 in CrewAI\nDESCRIPTION: This example shows how to set up a Crew with external memory using Mem0 as the provider. It includes setting up an agent, task, and crew with external memory configuration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai.memory.external.external_memory import ExternalMemory\n\nos.environ[\"MEM0_API_KEY\"] = \"YOUR-API-KEY\"\n\nagent = Agent(\n    role=\"You are a helpful assistant\",\n    goal=\"Plan a vacation for the user\",\n    backstory=\"You are a helpful assistant that can plan a vacation for the user\",\n    verbose=True,\n)\ntask = Task(\n    description=\"Give things related to the user's vacation\",\n    expected_output=\"A plan for the vacation\",\n    agent=agent,\n)\n\ncrew = Crew(\n    agents=[agent],\n    tasks=[task],\n    verbose=True,\n    process=Process.sequential,\n    external_memory=ExternalMemory(\n        embedder_config={\"provider\": \"mem0\", \"config\": {\"user_id\": \"U-123\"}} # you can provide an entire Mem0 configuration\n    ),\n)\n\ncrew.kickoff(\n    inputs={\"question\": \"which destination is better for a beach vacation?\"}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Agents using YAML in CrewAI\nDESCRIPTION: YAML configuration for defining agent roles, goals, and backstories in CrewAI. This approach provides a clean, maintainable way to define agents with support for variable interpolation.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/agents.mdx#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# src/latest_ai_development/config/agents.yaml\nresearcher:\n  role: >\n    {topic} Senior Data Researcher\n  goal: >\n    Uncover cutting-edge developments in {topic}\n  backstory: >\n    You're a seasoned researcher with a knack for uncovering the latest\n    developments in {topic}. Known for your ability to find the most relevant\n    information and present it in a clear and concise manner.\n\nreporting_analyst:\n  role: >\n    {topic} Reporting Analyst\n  goal: >\n    Create detailed reports based on {topic} data analysis and research findings\n  backstory: >\n    You're a meticulous analyst with a keen eye for detail. You're known for\n    your ability to turn complex data into clear and concise reports, making\n    it easy for others to understand and act on the information you provide.\n```\n\n----------------------------------------\n\nTITLE: Advanced BedrockKBRetrieverTool Configuration\nDESCRIPTION: Example showing advanced usage with custom retrieval configuration and specialized agent setup\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bedrockkbretriever.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nkb_tool = BedrockKBRetrieverTool(\n    knowledge_base_id=\"your-kb-id\",\n    retrieval_configuration={\n        \"vectorSearchConfiguration\": {\n            \"numberOfResults\": 10,\n            \"overrideSearchType\": \"HYBRID\"\n        }\n    }\n)\n\npolicy_expert = Agent(\n    role='Policy Expert',\n    goal='Analyze company policies in detail',\n    backstory='I am an expert in corporate policy analysis with deep knowledge of regulatory requirements.',\n    tools=[kb_tool]\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Unstructured State Management in CrewAI Flow (Python)\nDESCRIPTION: Demonstrates how to use unstructured state management in a CrewAI Flow. This approach allows flexible state manipulation without a predefined schema, automatically including a unique ID for each state instance.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/flows.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start\n\nclass UnstructuredExampleFlow(Flow):\n\n    @start()\n    def first_method(self):\n        # The state automatically includes an 'id' field\n        print(f\"State ID: {self.state['id']}\")\n        self.state['counter'] = 0\n        self.state['message'] = \"Hello from structured flow\"\n\n    @listen(first_method)\n    def second_method(self):\n        self.state['counter'] += 1\n        self.state['message'] += \" - updated\"\n\n    @listen(second_method)\n    def third_method(self):\n        self.state['counter'] += 1\n        self.state['message'] += \" - updated again\"\n\n        print(f\"State after third_method: {self.state}\")\n\n\nflow = UnstructuredExampleFlow()\nflow.kickoff()\n```\n\n----------------------------------------\n\nTITLE: Implementing Vertex AI Embeddings in CrewAI\nDESCRIPTION: This example shows how to set up a Crew using Vertex AI embeddings. It includes configuration for project ID, region, API key, and model name specific to Google Cloud's Vertex AI service.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom chromadb.utils.embedding_functions import GoogleVertexEmbeddingFunction\nfrom crewai import Crew, Agent, Task, Process\n\nmy_crew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"vertexai\",\n        \"config\": {\n            \"project_id\"=\"YOUR_PROJECT_ID\",\n            \"region\"=\"YOUR_REGION\",\n            \"api_key\"=\"YOUR_API_KEY\",\n            \"model_name\"=\"textembedding-gecko\"\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Environment Variables Configuration\nDESCRIPTION: Required environment variables for setting up the Qdrant Vector Search Tool with default OpenAI embeddings.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/qdrantvectorsearchtool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport QDRANT_URL=\"your_qdrant_url\"  # If not provided in constructor\nexport QDRANT_API_KEY=\"your_api_key\"  # If not provided in constructor\nexport OPENAI_API_KEY=\"your_openai_key\"  # If using default embeddings\n```\n\n----------------------------------------\n\nTITLE: LlamaIndexTool Class Method: from_tool\nDESCRIPTION: Class method signature for creating a LlamaIndexTool from a LlamaIndex tool. Shows method parameters and return type.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/llamaindextool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@classmethod\ndef from_tool(cls, tool: Any, **kwargs: Any) -> \"LlamaIndexTool\":\n    # Implementation details\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for SnowflakeSearchTool\nDESCRIPTION: Commands to install the required dependencies for using the SnowflakeSearchTool with CrewAI. Two options are provided using the 'uv' package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/snowflakesearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add cryptography snowflake-connector-python snowflake-sqlalchemy\n```\n\nLANGUAGE: shell\nCODE:\n```\nuv sync --extra snowflake\n```\n\n----------------------------------------\n\nTITLE: Retrieving Latest Task Outputs\nDESCRIPTION: Command to retrieve and display the outputs from the most recent crew.kickoff() task execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ncrewai log-tasks-outputs\n```\n\n----------------------------------------\n\nTITLE: Installing Firecrawl SDK and crewai[tools] package\nDESCRIPTION: This command installs the Firecrawl SDK and the crewai[tools] package, which are necessary for using the FirecrawlScrapeWebsiteTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/firecrawlscrapewebsitetool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install firecrawl-py 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Configuring Tasks in YAML\nDESCRIPTION: YAML configuration file defining research and reporting tasks with their descriptions, expected outputs and assigned agents\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nresearch_task:\n  description: >\n    Conduct a thorough research about {topic}\n    Make sure you find any interesting and relevant information given\n    the current year is 2025.\n  expected_output: >\n    A list with 10 bullet points of the most relevant information about {topic}\n  agent: researcher\n\nreporting_task:\n  description: >\n    Review the context you got and expand each topic into a full section for a report.\n    Make sure the report is detailed and contains any and all relevant information.\n  expected_output: >\n    A fully fledge reports with the mains topics, each with a full section of information.\n    Formatted as markdown without '```'\n  agent: reporting_analyst\n  output_file: report.md\n```\n\n----------------------------------------\n\nTITLE: Filtering Tools by Use Case\nDESCRIPTION: Demonstration of finding specific GitHub tools based on use case description\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/composiotool.mdx#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nuse_case = \"Star a repository on GitHub\"\n\nfiltered_action_enums = toolset.find_actions_by_use_case(\n    App.GITHUB, use_case=use_case, advanced=False\n)\n\ntools = toolset.get_tools(actions=filtered_action_enums)\n```\n\n----------------------------------------\n\nTITLE: Defining Agents in YAML Configuration\nDESCRIPTION: Example YAML configuration for defining AI agents with roles, goals, and backstories in a CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# src/my_project/config/agents.yaml\nresearcher:\n  role: >\n    {topic} Senior Data Researcher\n  goal: >\n    Uncover cutting-edge developments in {topic}\n  backstory: >\n    You're a seasoned researcher with a knack for uncovering the latest\n    developments in {topic}. Known for your ability to find the most relevant\n    information and present it in a clear and concise manner.\n\nreporting_analyst:\n  role: >\n    {topic} Reporting Analyst\n  goal: >\n    Create detailed reports based on {topic} data analysis and research findings\n  backstory: >\n    You're a meticulous analyst with a keen eye for detail. You're known for\n    your ability to turn complex data into clear and concise reports, making\n    it easy for others to understand and act on the information you provide.\n```\n\n----------------------------------------\n\nTITLE: AddImageToolSchema for Multimodal Agents in CrewAI\nDESCRIPTION: This code snippet defines the schema for the AddImageTool, which is automatically configured for multimodal agents. It specifies the required image_url and optional action parameters.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/multimodal-agents.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass AddImageToolSchema:\n    image_url: str  # Required: The URL or path of the image to process\n    action: Optional[str] = None  # Optional: Additional context or specific questions about the image\n```\n\n----------------------------------------\n\nTITLE: Mem0 Integration Configuration\nDESCRIPTION: Shows how to integrate Mem0 for enhanced user memory capabilities with API configuration.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom crewai import Crew, Process\nfrom mem0 import MemoryClient\n\n# Set environment variables for Mem0\nos.environ[\"MEM0_API_KEY\"] = \"m0-xx\"\n\n# Step 1: Create a Crew with User Memory\n\ncrew = Crew(\n    agents=[...],\n    tasks=[...],\n    verbose=True,\n    process=Process.sequential,\n    memory=True,\n    memory_config={\n        \"provider\": \"mem0\",\n        \"config\": {\"user_id\": \"john\"},\n        \"user_memory\" : {} #Set user_memory explicitly to a dictionary, we are working on this issue.\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Additional Packages for CrewAI\nDESCRIPTION: This command shows how to install additional packages for your CrewAI project using uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nuv add <package-name>\n```\n\n----------------------------------------\n\nTITLE: Replaying a Specific Task using Shell Command\nDESCRIPTION: Command to replay a specific task from the latest kickoff by providing the task ID.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/replay-tasks-from-latest-crew-kickoff.mdx#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncrewai replay -t <task_id>\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools Package\nDESCRIPTION: Command to install CrewAI with tools support using uv package manager\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bedrockkbretriever.mdx#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools Package\nDESCRIPTION: Command to install the crewai_tools package with the tools extension using pip package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/visiontool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Tools Package\nDESCRIPTION: Command to install the crewai tools package which includes the BraveSearchTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bravesearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Bedrock Knowledge Base Response Format\nDESCRIPTION: Example JSON structure returned by the BedrockKBRetrieverTool showing the format of retrieved results\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/bedrockkbretriever.mdx#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"results\": [\n    {\n      \"content\": \"Retrieved text content\",\n      \"content_type\": \"text\",\n      \"source_type\": \"S3\",\n      \"source_uri\": \"s3://bucket/document.pdf\",\n      \"score\": 0.95,\n      \"metadata\": {\n        \"additional\": \"metadata\"\n      }\n    }\n  ],\n  \"nextToken\": \"pagination-token\",\n  \"guardrailAction\": \"NONE\"\n}\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI using pip\nDESCRIPTION: Commands to install CrewAI and its additional tools using pip package manager. The first command installs the core CrewAI package, while the second installs CrewAI with additional tools.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\npip install crewai\n```\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Basic Prompt Customization in JSON for CrewAI\nDESCRIPTION: Example of a custom JSON file (custom_prompts.json) containing modified prompt slices for CrewAI. This snippet demonstrates how to override the 'format' slice to customize the response structure.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/guides/advanced/customizing-prompts.mdx#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"slices\": {\n    \"format\": \"When responding, follow this structure:\\n\\nTHOUGHTS: Your step-by-step thinking\\nACTION: Any tool you're using\\nRESULT: Your final answer or conclusion\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing AI Mind Tool Dependencies\nDESCRIPTION: Shell command to install the required Minds SDK package using the uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/aimindtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add minds-sdk\n```\n\n----------------------------------------\n\nTITLE: Installing Firecrawl SDK and crewai[tools] Package\nDESCRIPTION: This command installs the Firecrawl SDK and the crewai package with tools extension, which are required to use the FirecrawlCrawlWebsiteTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/firecrawlcrawlwebsitetool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install firecrawl-py 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Dependencies\nDESCRIPTION: This command installs all dependencies required for the CrewAI project.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/quickstart.mdx#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncrewai install\n```\n\n----------------------------------------\n\nTITLE: LinkupSearchTool Error Response Format\nDESCRIPTION: JSON structure representing the format of an error response from the LinkupSearchTool. It includes a success flag set to false and an error message.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/linkupsearchtool.mdx#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"success\": false,\n  \"error\": \"Error message\"\n}\n```\n\n----------------------------------------\n\nTITLE: CrewAI Flow Configuration\nDESCRIPTION: Python code demonstrating how to combine Crews with Flows using logical operators for complex automation pipelines\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.flow.flow import Flow, listen, start, router, or_\nfrom crewai import Crew, Agent, Task, Process\nfrom pydantic import BaseModel\n```\n\n----------------------------------------\n\nTITLE: Main Execution Script\nDESCRIPTION: Python main script to run the AI development crew with topic input parameter\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n#!/usr/bin/env python\nfrom latest_ai_development.crew import LatestAiDevelopmentCrew\n\ndef run():\n    \"\"\"\n    Run the crew.\n    \"\"\"\n    inputs = {\n        'topic': 'AI Agents'\n    }\n    LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)\n```\n\n----------------------------------------\n\nTITLE: Creating a New Crew or Flow in CrewAI\nDESCRIPTION: Command for creating a new crew or flow with a specified name. Requires the type (crew or flow) and name parameters.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncrewai create [OPTIONS] TYPE NAME\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI via pip\nDESCRIPTION: Command to install CrewAI using pip package manager, which is required before using the CLI.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/cli.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install crewai\n```\n\n----------------------------------------\n\nTITLE: Installing CrewAI Dependencies and Development Setup\nDESCRIPTION: Commands for setting up a development environment for CrewAI, including dependency management, virtual environment creation, and test execution.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/README.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nuv lock\nuv sync\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv venv\n```\n\nLANGUAGE: bash\nCODE:\n```\npre-commit install\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv run pytest .\n```\n\nLANGUAGE: bash\nCODE:\n```\nuvx mypy src\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv build\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install dist/*.tar.gz\n```\n\n----------------------------------------\n\nTITLE: CrewAI Task Replay Commands\nDESCRIPTION: CLI commands for viewing and replaying tasks from previous executions, including viewing task IDs and initiating replay from specific tasks.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/crews.mdx#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncrewai log-tasks-outputs\n```\n\nLANGUAGE: shell\nCODE:\n```\ncrewai replay -t <task_id>\n```\n\n----------------------------------------\n\nTITLE: Listing Installed uv Tools\nDESCRIPTION: Command to verify the installation of CrewAI by listing all tools installed with uv. Should show the CrewAI version installed.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nuv tool list\n```\n\n----------------------------------------\n\nTITLE: Basic Memory Configuration Example\nDESCRIPTION: Shows a simple memory configuration setup using default storage locations.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/concepts/memory.mdx#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew\nfrom crewai.memory import LongTermMemory\n\n# Simple memory configuration\ncrew = Crew(memory=True)  # Uses default storage locations\n```\n\n----------------------------------------\n\nTITLE: Installing Additional Packages for CrewAI\nDESCRIPTION: Command to add extra packages to your CrewAI project using uv as the package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nuv add <package-name>\n```\n\n----------------------------------------\n\nTITLE: Installing crewai_tools package with FileReadTool functionality\nDESCRIPTION: This command installs the crewai_tools package, which includes the FileReadTool functionality. It uses pip to install the package with the 'tools' extra.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/filereadtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Installing uv on Windows\nDESCRIPTION: PowerShell command to download and install uv dependency management tool on Windows systems using irm and iex.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n----------------------------------------\n\nTITLE: Updating Shell Path for uv Tools\nDESCRIPTION: Command to update your shell's PATH to include the uv tools directory if you encounter a PATH warning during installation.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nuv tool update-shell\n```\n\n----------------------------------------\n\nTITLE: Installing LlamaIndex for CrewAI\nDESCRIPTION: Command to install the LlamaIndex package using the uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/llamaindextool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add llama-index\n```\n\n----------------------------------------\n\nTITLE: Upgrading CrewAI with uv\nDESCRIPTION: Command to upgrade an existing CrewAI installation to the latest version using the uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nuv tool install crewai --upgrade\n```\n\n----------------------------------------\n\nTITLE: Installing Patronus Package and Setting API Key\nDESCRIPTION: Commands for installing the Patronus package using uv package manager and setting up the Patronus API key as an environment variable.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/patronustools.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add patronus\nexport PATRONUS_API_KEY=\"your_patronus_api_key\"\n```\n\n----------------------------------------\n\nTITLE: Example Output from uv tool list\nDESCRIPTION: Example output showing a successful CrewAI installation when running the uv tool list command, displaying the installed version.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/installation.mdx#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncrewai v0.102.0\n- crewai\n```\n\n----------------------------------------\n\nTITLE: Installing Scrapegraph Python Client\nDESCRIPTION: Command to install the Scrapegraph Python client using uv package manager.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/scrapegraphscrapetool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add scrapegraph-py\n```\n\n----------------------------------------\n\nTITLE: Installing Linkup SDK using uv package manager\nDESCRIPTION: Command to install the Linkup SDK, which is a prerequisite for using the LinkupSearchTool.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/linkupsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv add linkup-sdk\n```\n\n----------------------------------------\n\nTITLE: Installing PGSearchTool via pip\nDESCRIPTION: Command to install the crewai_tools package that will include PGSearchTool functionality.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/tools/pgsearchtool.mdx#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install 'crewai[tools]'\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI API Environment\nDESCRIPTION: Environment setup for OpenAI API key using getpass for secure input.\nSOURCE: https://github.com/crewaiinc/crewai/blob/main/docs/how-to/opik-observability.mdx#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport getpass\n\nif \"OPENAI_API_KEY\" not in os.environ:\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n```"
  }
]