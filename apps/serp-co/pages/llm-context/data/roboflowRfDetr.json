[
  {
    "owner": "roboflow",
    "repo": "rf-detr",
    "content": "TITLE: Basic Image Inference with RF-DETR\nDESCRIPTION: Example of performing object detection on a single image using RF-DETR. Demonstrates loading the model, making predictions, and visualizing results with annotations.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport io\nimport requests\nimport supervision as sv\nfrom PIL import Image\nfrom rfdetr import RFDETRBase\nfrom rfdetr.util.coco_classes import COCO_CLASSES\n\nmodel = RFDETRBase()\n\nurl = \"https://media.roboflow.com/notebooks/examples/dog-2.jpeg\"\n\nimage = Image.open(io.BytesIO(requests.get(url).content))\ndetections = model.predict(image, threshold=0.5)\n\nlabels = [\n    f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n    for class_id, confidence\n    in zip(detections.class_id, detections.confidence)\n]\n\nannotated_image = image.copy()\nannotated_image = sv.BoxAnnotator().annotate(annotated_image, detections)\nannotated_image = sv.LabelAnnotator().annotate(annotated_image, detections, labels)\n\nsv.plot_image(annotated_image)\n```\n\n----------------------------------------\n\nTITLE: Fine-tuning RF-DETR Model\nDESCRIPTION: Demonstrates how to fine-tune the RF-DETR model on a custom dataset. Includes basic training configuration with parameters for epochs, batch size, gradient accumulation, and learning rate.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom rfdetr import RFDETRBase\n\nmodel = RFDETRBase()\n\nmodel.train(dataset_dir=<DATASET_PATH>, epochs=10, batch_size=4, grad_accum_steps=4, lr=1e-4, output_dir=<OUTPUT_PATH>)\n```\n\n----------------------------------------\n\nTITLE: Loading and Running a Fine-tuned RF-DETR Model\nDESCRIPTION: Demonstrates how to load a trained RF-DETR model from a checkpoint and use it for inference on new images. This allows you to apply your fine-tuned model to detect objects in images.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom rfdetr import RFDETRBase\n\nmodel = RFDETRBase(pretrain_weights=<CHECKPOINT_PATH>)\n\ndetections = model.predict(<IMAGE_PATH>)\n```\n\n----------------------------------------\n\nTITLE: Batch Inference with RF-DETR Model\nDESCRIPTION: Demonstrates how to perform batch inference on multiple images using the RF-DETR model. The code loads images from URLs, processes them in a single forward pass, and visualizes the detection results with bounding boxes and labels.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport io\nimport requests\nimport supervision as sv\nfrom PIL import Image\nfrom rfdetr import RFDETRBase\nfrom rfdetr.util.coco_classes import COCO_CLASSES\n\nmodel = RFDETRBase()\n\nurls = [\n    \"https://media.roboflow.com/notebooks/examples/dog-2.jpeg\",\n    \"https://media.roboflow.com/notebooks/examples/dog-3.jpeg\"\n]\n\nimages = [Image.open(io.BytesIO(requests.get(url).content)) for url in urls]\n\ndetections_list = model.predict(images, threshold=0.5)\n\nfor image, detections in zip(images, detections_list):\n    labels = [\n        f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n        for class_id, confidence\n        in zip(detections.class_id, detections.confidence)\n    ]\n\n    annotated_image = image.copy()\n    annotated_image = sv.BoxAnnotator().annotate(annotated_image, detections)\n    annotated_image = sv.LabelAnnotator().annotate(annotated_image, detections, labels)\n\n    sv.plot_image(annotated_image)\n```\n\n----------------------------------------\n\nTITLE: Webcam Inference with RF-DETR\nDESCRIPTION: Real-time object detection implementation using webcam feed. Continuously processes frames and displays results with annotations.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport cv2\nimport supervision as sv\nfrom rfdetr import RFDETRBase\nfrom rfdetr.util.coco_classes import COCO_CLASSES\n\nmodel = RFDETRBase()\n\ncap = cv2.VideoCapture(0)\nwhile True:\n    success, frame = cap.read()\n    if not success:\n        break\n\n    detections = model.predict(frame[:, :, ::-1], threshold=0.5)\n    \n    labels = [\n        f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n        for class_id, confidence\n        in zip(detections.class_id, detections.confidence)\n    ]\n\n    annotated_frame = frame.copy()\n    annotated_frame = sv.BoxAnnotator().annotate(annotated_frame, detections)\n    annotated_frame = sv.LabelAnnotator().annotate(annotated_frame, detections, labels)\n\n    cv2.imshow(\"Webcam\", annotated_frame)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```\n\n----------------------------------------\n\nTITLE: Video Inference with RF-DETR\nDESCRIPTION: Implementation of object detection on video files using RF-DETR. Processes video frames and adds detection annotations.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport supervision as sv\nfrom rfdetr import RFDETRBase\nfrom rfdetr.util.coco_classes import COCO_CLASSES\n\nmodel = RFDETRBase()\n\ndef callback(frame, index):\n    detections = model.predict(frame[:, :, ::-1], threshold=0.5)\n        \n    labels = [\n        f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n        for class_id, confidence\n        in zip(detections.class_id, detections.confidence)\n    ]\n\n    annotated_frame = frame.copy()\n    annotated_frame = sv.BoxAnnotator().annotate(annotated_frame, detections)\n    annotated_frame = sv.LabelAnnotator().annotate(annotated_frame, detections, labels)\n    return annotated_frame\n\nsv.process_video(\n    source_path=<SOURCE_VIDEO_PATH>,\n    target_path=<TARGET_VIDEO_PATH>,\n    callback=callback\n)\n```\n\n----------------------------------------\n\nTITLE: RTSP Stream Inference with RF-DETR\nDESCRIPTION: Implementation for performing object detection on RTSP video streams. Processes stream frames in real-time and displays annotated results.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport cv2\nimport supervision as sv\nfrom rfdetr import RFDETRBase\nfrom rfdetr.util.coco_classes import COCO_CLASSES\n\nmodel = RFDETRBase()\n\ncap = cv2.VideoCapture(<RTSP_STREAM_URL>)\nwhile True:\n    success, frame = cap.read()\n    if not success:\n        break\n\n    detections = model.predict(frame[:, :, ::-1], threshold=0.5)\n    \n    labels = [\n        f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n        for class_id, confidence\n        in zip(detections.class_id, detections.confidence)\n    ]\n\n    annotated_frame = frame.copy()\n    annotated_frame = sv.BoxAnnotator().annotate(annotated_frame, detections)\n    annotated_frame = sv.LabelAnnotator().annotate(annotated_frame, detections, labels)\n\n    cv2.imshow(\"RTSP Stream\", annotated_frame)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```\n\n----------------------------------------\n\nTITLE: Configuring RF-DETR Input Resolution\nDESCRIPTION: Shows how to initialize the RF-DETR model with a custom input resolution. The resolution value must be divisible by 56 and affects the model's prediction quality and inference speed.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel = RFDETRBase(resolution=560)\n```\n\n----------------------------------------\n\nTITLE: Exporting RF-DETR Model to ONNX Format\nDESCRIPTION: Shows how to export an RF-DETR model to ONNX format for deployment. This enables interoperability with various inference frameworks and can improve deployment efficiency.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom rfdetr import RFDETRBase\n\nmodel = RFDETRBase(pretrain_weights=<CHECKPOINT_PATH>)\n\nmodel.export()\n```\n\n----------------------------------------\n\nTITLE: Installing RF-DETR Package\nDESCRIPTION: Instructions for installing the RF-DETR package using pip. Requires Python 3.9 or higher.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install rfdetr\n```\n\n----------------------------------------\n\nTITLE: Installing RF-DETR from Source\nDESCRIPTION: Alternative installation method directly from the GitHub repository for accessing the latest development features.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install git+https://github.com/roboflow/rf-detr.git\n```\n\n----------------------------------------\n\nTITLE: Training RF-DETR with Early Stopping\nDESCRIPTION: Demonstrates how to initialize the RF-DETR model and train it with early stopping enabled. This helps prevent overfitting by monitoring validation performance and stopping training when improvements plateau.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom rfdetr import RFDETRBase\n\nmodel = RFDETRBase()\n\nmodel.train(dataset_dir=<DATASET_PATH>, epochs=10, batch_size=4, grad_accum_steps=4, lr=1e-4, output_dir=<OUTPUT_PATH>, early_stopping=True)\n```\n\n----------------------------------------\n\nTITLE: Resuming RF-DETR Training\nDESCRIPTION: Shows how to resume training from a previously saved checkpoint by providing the checkpoint file path. Useful for continuing interrupted training sessions or further fine-tuning.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom rfdetr import RFDETRBase\n\nmodel = RFDETRBase()\n\nmodel.train(dataset_dir=<DATASET_PATH>, epochs=10, batch_size=4, grad_accum_steps=4, lr=1e-4, output_dir=<OUTPUT_PATH>, resume=<CHECKPOINT_PATH>)\n```\n\n----------------------------------------\n\nTITLE: Dataset Directory Structure Example\nDESCRIPTION: Illustrates the required directory structure for training data in COCO format. Shows how train, valid, and test splits should be organized with their respective annotation files.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_8\n\nLANGUAGE: plaintext\nCODE:\n```\ndataset/\n├── train/\n│   ├── _annotations.coco.json\n│   ├── image1.jpg\n│   ├── image2.jpg\n│   └── ... (other image files)\n├── valid/\n│   ├── _annotations.coco.json\n│   ├── image1.jpg\n│   ├── image2.jpg\n│   └── ... (other image files)\n└── test/\n    ├── _annotations.coco.json\n    ├── image1.jpg\n    ├── image2.jpg\n    └── ... (other image files)\n```\n\n----------------------------------------\n\nTITLE: Running Multi-GPU Training with PyTorch DDP\nDESCRIPTION: Shows how to use PyTorch's Distributed Data Parallel (DDP) to train RF-DETR across multiple GPUs. This command launches training processes on each GPU, automatically dividing the workload for faster training.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\npython -m torch.distributed.launch --nproc_per_node=8 --use_env main.py\n```\n\n----------------------------------------\n\nTITLE: Required Python Packages for RF-DETR Project\nDESCRIPTION: List of dependencies for RF-DETR including CUDA support (pycuda), ONNX ecosystem packages (conversion, optimization, runtime), TensorRT for acceleration, and Polygraphy for debugging and visualization.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/rfdetr/deploy/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npycuda\nonnx\nonnxsim\nonnxruntime\nonnxruntime-gpu\nonnx_graphsurgeon\ntensorrt>=8.6.1\npolygraphy\n```\n\n----------------------------------------\n\nTITLE: Training RF-DETR with Weights and Biases Logging\nDESCRIPTION: Shows how to enable Weights and Biases logging when training the RF-DETR model. This allows tracking of experiments with project and run organization on the W&B platform.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom rfdetr import RFDETRBase\n\nmodel = RFDETRBase()\n\nmodel.train(\n    dataset_dir=<DATASET_PATH>,\n    epochs=10,\n    batch_size=4,\n    grad_accum_steps=4,\n    lr=1e-4,\n    output_dir=<OUTPUT_PATH>,\n    wandb=True,\n    project=<PROJECT_NAME>,\n    run=<RUN_NAME>\n)\n```\n\n----------------------------------------\n\nTITLE: Training RF-DETR with TensorBoard Logging\nDESCRIPTION: Shows how to enable TensorBoard logging when training the RF-DETR model. This allows real-time visualization of metrics such as loss values and evaluation metrics during training.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom rfdetr import RFDETRBase\n\nmodel = RFDETRBase()\n\nmodel.train(\n    dataset_dir=<DATASET_PATH>,\n    epochs=10,\n    batch_size=4,\n    grad_accum_steps=4,\n    lr=1e-4,\n    output_dir=<OUTPUT_PATH>,\n    tensorboard=True\n)\n```\n\n----------------------------------------\n\nTITLE: Google-Style Docstring Example with Type Hints in Python\nDESCRIPTION: Example function with Google-style docstrings and type hints as required for all new functions in RF-DETR. Demonstrates proper documentation of parameters, return types, and usage examples.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/CONTRIBUTING.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef sample_function(param1: int, param2: int = 10) -> bool:\n    \"\"\"\n    Provides a brief description of function behavior.\n\n    Args:\n        param1 (int): Explanation of the first parameter.\n        param2 (int): Explanation of the second parameter, defaulting to 10.\n\n    Returns:\n        bool: True if the operation succeeds, otherwise False.\n\n    Examples:\n        >>> sample_function(5, 10)\n        True\n    \"\"\"\n    return param1 == param2\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard for Local Monitoring\nDESCRIPTION: Command to start a TensorBoard server for monitoring training metrics. This opens a local web interface where you can view visualizations of your model's performance.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ntensorboard --logdir <OUTPUT_DIR>\n```\n\n----------------------------------------\n\nTITLE: Starting TensorBoard in Google Colab\nDESCRIPTION: Commands to initialize and run TensorBoard in a Google Colab environment. This enables visualization of training metrics directly within the Colab notebook interface.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n%load_ext tensorboard\n%tensorboard --logdir <OUTPUT_DIR>\n```\n\n----------------------------------------\n\nTITLE: Installing TensorBoard Support for RF-DETR\nDESCRIPTION: Command to install the required packages for TensorBoard logging with RF-DETR. This enables visualization of training metrics and model performance.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\npip install \"rfdetr[metrics]\"\n```\n\n----------------------------------------\n\nTITLE: Installing Weights and Biases Support for RF-DETR\nDESCRIPTION: Command to install the required packages for Weights and Biases (W&B) logging with RF-DETR. This enables cloud-based tracking and visualization of model training progress.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\npip install \"rfdetr[metrics]\"\n```\n\n----------------------------------------\n\nTITLE: Logging into Weights and Biases\nDESCRIPTION: Command to authenticate with the Weights and Biases service. This is required before using W&B for experiment tracking during model training.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nwandb login\n```\n\n----------------------------------------\n\nTITLE: Committing and Pushing Changes to RF-DETR\nDESCRIPTION: Git commands for staging, committing, and pushing changes to a remote repository. These commands are used after making modifications to the codebase.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/CONTRIBUTING.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit add .\ngit commit -m \"A brief description of your changes\"\ngit push -u origin your-descriptive-name\n```\n\n----------------------------------------\n\nTITLE: Creating a Branch for Contributing to RF-DETR\nDESCRIPTION: Command for creating a new feature branch with a descriptive name in Git. This is part of the contribution workflow for making changes to the RF-DETR project.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b feature/your-descriptive-name\n```\n\n----------------------------------------\n\nTITLE: CLA Signing Comment for RF-DETR Pull Requests\nDESCRIPTION: Required comment text to add to pull requests to sign the Contributor License Agreement. This confirms that contributions are properly licensed under the Apache 2.0 License.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/CONTRIBUTING.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nI have read the CLA Document and I sign the CLA.\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for RF-DETR\nDESCRIPTION: BibTeX entry for citing the RF-DETR object detection model in academic research. Includes author information, license details, title, URL, and publication year.\nSOURCE: https://github.com/roboflow/rf-detr/blob/develop/README.md#2025-04-22_snippet_22\n\nLANGUAGE: bibtex\nCODE:\n```\n@software{rf-detr,\n  author = {Robinson, Isaac and Robicheaux, Peter and Popov, Matvei},\n  license = {Apache-2.0},\n  title = {RF-DETR},\n  howpublished = {\\url{https://github.com/roboflow/rf-detr}},\n  year = {2025},\n  note = {SOTA Real-Time Object Detection Model}\n}\n```"
  }
]