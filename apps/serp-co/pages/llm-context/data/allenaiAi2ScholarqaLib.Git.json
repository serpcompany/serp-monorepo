[
  {
    "owner": "allenai",
    "repo": "ai2-scholarqa-lib.git",
    "content": "TITLE: Detailed Pipeline Steps for Ai2 Scholar QA in Python\nDESCRIPTION: Demonstrates the detailed steps of the Ai2 Scholar QA pipeline, including query decomposition, paper retrieval, reranking, quote extraction, clustering, and summary generation. Shows how to use the ScholarQA class for modular pipeline execution.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom scholarqa.rag.multi_step_qa_pipeline import MultiStepQAPipeline\nfrom scholarqa.preprocess.query_preprocessor import decompose_query\nfrom scholarqa.llms.constants import CLAUDE_37_SONNET\nfrom scholarqa.llms.prompts import SYSTEM_PROMPT_QUOTE_PER_PAPER, SYSTEM_PROMPT_QUOTE_CLUSTER, PROMPT_ASSEMBLE_SUMMARY\n\n#Custom MultiStepQAPipeline class/steps with llm_model asa any litellm supported model\nmqa_pipeline = MultiStepQAPipeline(llm_model=CLAUDE_37_SONNET)\n\nquery = \"Which is the 9th planet in our solar system?\"\n\nscholar_qa = ScholarQA(paper_finder=paper_finder, multi_step_pipeline=llm_model=mqa_pipeline, CLAUDE_37_SONNET)\n\ncost_args = None #This is used for house keeping, can be None\n\n# Decompose the query to get filters like year, venue, fos, citations, etc along with\n#a re-written version of the query and a query suitable for keyword search.\nllm_processed_query = scholar_qa.query(query, cost_args)\n\n# Paper finder step - retrieve relevant paper passages from semantic scholar index and api\nfull_text_src, keyword_srch_res = scholar_qa.find_relevant_papers(llm_processed_query.result)\nretrieved_candidates = snippet_srch_res + s2_srch_res\n\n# Rerank the retrieved candidates based on the query with a cross encoder\n#keyword search results are returned with associated metadata, metadata is retrieved separately for full text serach results\nkeyword_srch_metadata = [{k: v for k, v in paper.items() if k == \"corpus_id\" or k in NUMERIC_META_FIELDS or k in CATEGORICAL_META_FIELDS}\n                        for paper in s2_srch_res]\nreranked_df, paper_metadata = scholar_qa.rerank_and_aggregate(query, retrieved_candidates, filter_paper_metadata={str(paper[\"corpus_id\"]): paper for paper in\n                                                                 keyword_srch_metadata})\n# Step 1 - quote extraction\nper_paper_quotes = scholar_qa.step_select_quotes(query, reranked_df, cost_args, sys_prompt=SYSTEM_PROMPT_QUOTE_PER_PAPER)\n\n# step 2: outline planning and clustering\ncluster_json = scholar_qa.step_clustering(query, per_paper_quotes.result, cost_args, sys_prompt=SYSTEM_PROMPT_QUOTE_CLUSTER)\n\n# Changing to expected format in the summary generation prompt\nplan_json = {f'{dim[\"name\"]} ({dim[\"format\"]})': dim[\"quotes\"] for dim in cluster_json.result[\"dimensions\"]}\n\n# step 2.1: extend the clustered snippets in plan json with their inline citations\nper_paper_summaries_extd = scholar_qa.multi_step_pipeline.extend_quote_citations(reranked_df,\n                                                                           per_paper_quotes.result,\n                                                                           plan_json, paper_metadata)\n```\n\n----------------------------------------\n\nTITLE: Generating Iterative Summaries using ScholarQA\nDESCRIPTION: This code snippet shows how to use the ScholarQA library to generate a summary from query results and paper summaries based on a plan. It uses the step_gen_iterative_summary method to create a structured answer from the provided inputs.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nanswer = list(scholar_qa.step_gen_iterative_summary(query, per_paper_summaries_extd, plan_json, cost_args, sys_prompt=PROMPT_ASSEMBLE_SUMMARY))\n```\n\n----------------------------------------\n\nTITLE: Installing and Using Ai2 Scholar QA Python Package\nDESCRIPTION: Instructions for creating a conda environment, installing the Ai2 Scholar QA Python package, and a code example demonstrating how to use the ScholarQA class with custom retriever and reranker components.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nconda create -n scholarqa python=3.11.3\nconda activate scholarqa\npip install ai2-scholar-qa\n\n#to use sentence transformer models as re-ranker\npip install 'ai2-scholar-qa[all]'\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom scholarqa.rag.reranker.reranker_base import CrossEncoderScores\nfrom scholarqa.rag.reranker.modal_engine import ModalReranker\nfrom scholarqa.rag.retrieval import PaperFinderWithReranker\nfrom scholarqa.rag.retriever_base import FullTextRetriever\nfrom scholarqa import ScholarQA\nfrom scholarqa.llms.constants import CLAUDE_37_SONNET\n\n#Retrieval class/steps\nretriever = FullTextRetriever(n_retrieval=256, n_keyword_srch=20) #full text and keyword search\nreranker = CrossEncoderScores(model_name_or_path=\"mixedbread-ai/mxbai-rerank-large-v1\") #sentence transformer\n\n\n#Reranker if deployed on Modal, modal_app_name and modal_api_name are modal specific arguments.\n#Please refer https://github.com/allenai/ai2-scholarqa-lib/blob/aps/readme_fixes/docs/MODAL.md for more info \nreranker = ModalReranker(app_name=<modal_app_name>, api_name=<modal_api_name>, batch_size=256, gen_options=dict())\n\n#wraps around the retriever with `retrieve_passages()` and `retrieve_additional_papers()`, and reranker with rerank()\n#any modifications to the retrieval output can be made here\npaper_finder =  PaperFinderWithReranker(retriever, reranker, n_rerank=50, context_threshold=0.5)\n\n#For wrapper class with MultiStepQAPipeline integrated\nscholar_qa = ScholarQA(paper_finder=paper_finder, llm_model=CLAUDE_37_SONNET) #llm_model can be any litellm model\nprint(scholar_qa.answer_query(\"Which is the 9th planet in our solar system?\"))\n```\n\n----------------------------------------\n\nTITLE: Creating Custom API Endpoints with ScholarQA\nDESCRIPTION: This code demonstrates how to extend ScholarQA's functionality by creating custom API endpoints using FastAPI. It shows implementation of a retrieval endpoint that processes queries and finds relevant papers using the ScholarQA pipeline.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import APIRouter, FastAPI\nfrom scholarqa.app import create_app as create_app_base\nfrom scholarqa.app import app_config\nfrom scholarqa.models import ToolRequest\n\ndef create_app() -> FastAPI:\n  app = create_app_base()\n  custom_router = APIRouter()\n\n  @custom_router.post(\"/retrieval\")\n  def retrieval(tool_request: ToolRequest, task_id: str):\n    scholar_qa = app_config.load_scholarqa(task_id)\n    #a re-written version of the query and a query suitable for keyword search.\n    llm_processed_query = scholar_qa.query(query, cost_args=None)\n    full_text_src, keyword_srch_res = scholar_qa.find_relevant_papers(llm_processed_query.result)\n    retrieved_candidates = snippet_srch_res + s2_srch_res\n    return retrieved_candidates\n\n  app.include_router(custom_router)\n  return app.py\n```\n\n----------------------------------------\n\nTITLE: Defining Configuration Fields for Ai2 Scholar QA in Python\nDESCRIPTION: Defines configuration fields for the Ai2 Scholar QA pipeline, including retriever and reranker services and arguments. These fields allow customization of the pipeline components.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nretriever_args: dict = Field(default=None, description=\"Arguments for the retrieval service\")\nretriever_service: str = Field(default=\"public_api\", description=\"Service to use for paper retrieval\")\nreranker_service: str = Field(default=\"modal\", description=\"Service to use for paper reranking\")\nreranker_args: dict = Field(default=None, description=\"Arguments for the reranker service\")\npaper_finder_args: dict = Field(default=None, description=\"Arguments for the paper finder service\")\npipeline_args: dict = Field(default=None, description=\"Arguments for the Scholar QA pipeline service\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for ScholarQA\nDESCRIPTION: Essential environment variables needed for the ScholarQA system, including API keys for Semantic Scholar, Anthropic, and OpenAI services.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport S2_API_KEY=  \nexport ANTHROPIC_API_KEY=\nexport OPENAI_API_KEY=\n```\n\n----------------------------------------\n\nTITLE: Default JSON Configuration for ScholarQA Web App\nDESCRIPTION: Default configuration file specifying logging and pipeline settings for the web application, including retrieval, reranking, and pipeline arguments.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"logs\": {\n    \"log_dir\": \"logs\",\n    \"llm_cache_dir\": \"llm_cache\",\n    \"event_trace_loc\": \"scholarqa_traces\",\n    \"tracing_mode\": \"local\"\n  },\n  \"run_config\": {\n    \"retrieval_service\": \"public_api\",\n    \"retriever_args\": {\n      \"n_retrieval\": 256,\n      \"n_keyword_srch\": 20\n    },\n    \"reranker_service\": \"modal\",\n    \"reranker_args\": {\n      \"app_name\": \"ai2-scholar-qa\",\n      \"api_name\": \"inference_api\",\n      \"batch_size\": 256,\n      \"gen_options\": {}\n    },\n    \"paper_finder_args\": {\n      \"n_rerank\": 50,\n      \"context_threshold\": 0.5\n    },\n    \"pipeline_args\": {\n      \"validate\": true,\n      \"llm\": \"anthropic/claude-3-5-sonnet-20241022\",\n      \"decomposer_llm\": \"anthropic/claude-3-5-sonnet-20241022\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Pipeline Configuration Class Definition\nDESCRIPTION: Python class defining the base pipeline configuration using Pydantic BaseModel, specifying the retrieval service settings.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass RunConfig(BaseModel):  \n    retrieval_service: str = Field(default=\"public_api\", description=\"Service to use for paper retrieval\")\n```\n\n----------------------------------------\n\nTITLE: Running Ai2 Scholar QA Web App with Docker Compose in Bash\nDESCRIPTION: Commands for cloning the Ai2 Scholar QA repository and running the web application using Docker Compose. Includes options for verbose output during the build process.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:allenai/ai2-scholarqa-lib.git\ncd ai2-scholarqa-lib\ndocker compose up --build\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose build --progress plain\n```\n\n----------------------------------------\n\nTITLE: Logging Configuration Class Definition\nDESCRIPTION: Python class defining the logging configuration structure using Pydantic BaseModel, including fields for log directories and tracing settings.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass LogsConfig(BaseModel):\n    log_dir: str = Field(default=\"logs\", description=\"Directory to store logs, event traces and litellm cache\")\n    llm_cache_dir: str = Field(default=\"llm_cache\", description=\"Sub directory to cache llm calls\")\n    event_trace_loc: str = Field(default=\"scholarqa_traces\", description=\"Sub directory to store event traces\"\n                                                                         \"OR the GCS bucket name\")\n    tracing_mode: Literal[\"local\", \"gcs\"] = Field(default=\"local\",\n                                                  description=\"Mode to store event traces (local or gcs)\")\n```\n\n----------------------------------------\n\nTITLE: Starting Local Development Environment with Docker Compose\nDESCRIPTION: This command builds and starts the local development environment using Docker Compose. It launches several processes and makes the application accessible at http://localhost:8080.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/docs/DOCKER.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up --build\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Containers for Ai2 Scholar QA Web App in YAML\nDESCRIPTION: Defines the Docker configuration for the Ai2 Scholar QA web application, including containers for API, GUI, nginx proxy, and sonar. Specifies environment variables and volume mappings for the API container.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\napi:  \nbuild: ./api  \nvolumes:  \n- ./api:/api  \n- ./secret:/secret  \nenvironment:  \n# This ensures that errors are printed as they occur, which  \n# makes debugging easier.  \n- PYTHONUNBUFFERED=1  \n- LOG_LEVEL=INFO\n- CONFIG_PATH=run_configs/default.json  \nports:  \n- 8000:8000  \nenv_file:  \n- .env\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for AI2 ScholarQA\nDESCRIPTION: This snippet lists the required Python packages and their versions for the AI2 ScholarQA library. It includes transformers, sentencepiece, hf-transfer, huggingface_hub, and sentence-transformers with specific version constraints where applicable.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/api/reranker_requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntransformers==4.44.1\nsentencepiece\nhf-transfer==0.1.6\nhuggingface_hub==0.23.4\nsentence-transformers==3.0.1\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies\nDESCRIPTION: This series of commands demonstrates how to install a new Python dependency and update the requirements.txt file within the API container.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/docs/DOCKER.md#2025-04-23_snippet_2\n\nLANGUAGE: shellscript\nCODE:\n```\npython -m pip install <dependency>\npython -m pip freeze -l > requirements.txt\nexit\n```\n\n----------------------------------------\n\nTITLE: Configuring Modal Authentication with TOML\nDESCRIPTION: Example of the .modal.toml configuration file that contains authentication tokens required for deploying Modal applications. The file should be placed in the user's home directory with appropriate token values.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/docs/MODAL.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[user]\ntoken_id = \"ak-*[...]*\"\ntoken_secret = \"as-*[...]*\"\n\nactive = true\n```\n\n----------------------------------------\n\nTITLE: Accessing Python API Container Shell\nDESCRIPTION: This command opens a bash shell in the API container, allowing developers to execute commands within the Python environment.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/docs/DOCKER.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose exec api /bin/bash\n```\n\n----------------------------------------\n\nTITLE: Installing UI Dependencies with Yarn\nDESCRIPTION: This series of commands demonstrates how to install a new UI dependency using Yarn within the UI container.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/docs/DOCKER.md#2025-04-23_snippet_4\n\nLANGUAGE: shellscript\nCODE:\n```\nyarn add <dependency>\nexit\n```\n\n----------------------------------------\n\nTITLE: Formatting Markdown Badges for Ai2 Scholar QA Resources\nDESCRIPTION: This snippet contains a series of markdown-formatted badges that link to various resources related to the Ai2 Scholar QA project. It includes links to the live app, research paper on Semantic Scholar, PyPI package, HuggingFace dataset, and a YouTube demo walkthrough.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n  <a href=\"https://qa.allen.ai/chat\">\n    <img alt=\"Live App\" src=\"https://img.shields.io/badge/Ai2-qa.allen.ai-white?labelColor=teal&color=black\">\n  </a>  \n  <a href=\"https://www.semanticscholar.org/paper/Ai2-Scholar-QA%3A-Organized-Literature-Synthesis-with-Singh-Chang/c815591e854afb83dc985fa3ff07506d6b25a1b4?utm_source=direct_link\">\n    <img alt=\"Paper URL\" src=\"https://img.shields.io/badge/Semantic%20Scholar-white?logo=semanticscholar&labelColor=%231857B6&color=black\">\n  </a>\n  <a href=\"https://pypi.org/project/ai2-scholar-qa/\">\n    <img alt=\"PyPI\" src=\"https://img.shields.io/badge/PyPI-white?logo=PyPI&logoColor=white&labelColor=%233775A9&color=black\">\n  </a>\n    <a href=\"https://huggingface.co/datasets/allenai/sqa_reranking_eval\">\n    <img alt=\"HuggingFace Dataset\" src=\"https://img.shields.io/badge/Dataset-white?logo=Hugging%20Face&logoColor=white&labelColor=%23FFD21E&color=black\">\n  </a>\n    </a>\n    <a href=\"https://www.youtube.com/watch?v=augQU982aGQ&ab_channel=Ai2\">\n    <img alt=\"Demo walkthrough\" src=\"https://img.shields.io/badge/Youtube-white?logo=YouTube&logoColor=white&labelColor=%23FF0000&color=black\">\n  </a>\n</p>\n```\n\n----------------------------------------\n\nTITLE: Accessing UI Container Shell\nDESCRIPTION: This command opens a shell in the UI container, allowing developers to execute commands within the frontend environment.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/docs/DOCKER.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose exec ui /bin/sh\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies with Version Constraints\nDESCRIPTION: This snippet defines the external package dependencies required for the AI2 ScholarQA library. It specifies the requests package at version 2.31.0, which is used for making HTTP requests to APIs.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/sonar/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nrequests==2.31.0\n```\n\n----------------------------------------\n\nTITLE: Configuring Web Crawler Access Controls for AI2 ScholarQA API\nDESCRIPTION: Standard robots.txt configuration that blocks all web crawlers from accessing the /api endpoint. Includes references to privacy policy and terms of use, with a note about contacting Allen AI for data access.\nSOURCE: https://github.com/allenai/ai2-scholarqa-lib.git/blob/main/ui/public/robots.txt#2025-04-23_snippet_0\n\nLANGUAGE: robotstxt\nCODE:\n```\nUser-agent: *\nDisallow: /api\n```"
  }
]