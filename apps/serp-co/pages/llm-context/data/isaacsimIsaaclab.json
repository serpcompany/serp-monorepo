[
  {
    "owner": "isaac-sim",
    "repo": "isaaclab",
    "content": "TITLE: Complete Random Agent Script\nDESCRIPTION: The full implementation of the random_agent.py script that demonstrates environment registration and usage with highlighted key lines for environment creation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/register_rl_env_gym.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#!/usr/bin/env python3\n# Copyright (c) 2023-2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# NVIDIA CORPORATION, its affiliates and licensors retain all intellectual\n# property and proprietary rights in and to this material, related\n# documentation and any modifications thereto. Any use, reproduction,\n# disclosure or distribution of this material and related documentation\n# without an express license agreement from NVIDIA CORPORATION or\n# its affiliates is strictly prohibited.\n\n\"\"\"Script demonstrating the use of environment registrations using gymnasium.\"\"\"\n\nimport argparse\nimport glob\nimport os\n\nimport gymnasium as gym\nimport numpy as np\n\nfrom omni.isaac.core.utils.extensions import enable_extension\n\nfrom isaaclab.utils.parse_cfg import load_default_env_cfg\n\n# enable the IsaacLab extension\nenable_extension(\"omni.isaac.lab_tasks\")\n\n# import isaaclab_tasks to register the environments\n# this import is unused (hence the noqa comment) but necessary to register the environments\nimport isaaclab_tasks  # noqa: F401\n\n\ndef main():\n    \"\"\"Main function to run the example.\"\"\"\n\n    # Set parameters to modify the configuration\n    parser = argparse.ArgumentParser(description=\"Random policy for environments.\")\n    parser.add_argument(\"--task\", type=str, default=\"Isaac-Cartpole-v0\", help=\"Name of the environment.\")\n    parser.add_argument(\"--num_envs\", type=int, default=32, help=\"Number of environments to simulate.\")\n    parser.add_argument(\"--disable_render\", action=\"store_true\", default=False, help=\"Disable rendering.\")\n    parser.add_argument(\"--device\", type=str, default=None, help=\"Device to run simulator on.\")\n    args_cli = parser.parse_args()\n\n    # create environment configuration\n    env_cfg = load_default_env_cfg(args_cli.task)\n    # update configuration\n    env_cfg.sim.num_envs = args_cli.num_envs\n    env_cfg.sim.add_ground_plane = True\n    env_cfg.render_camera = not args_cli.disable_render\n    if args_cli.device is not None:\n        env_cfg.sim.device = args_cli.device\n    # create environment\n    env = gym.make(args_cli.task, cfg=env_cfg)\n\n    # reset environment\n    obs, info = env.reset()\n    done = False\n    # simulate the environment\n    while not done:\n        # take a random action\n        action = env.action_space.sample()\n        # apply the action and step simulation\n        obs, reward, terminated, truncated, _ = env.step(action)\n        done = terminated.all() or truncated.all()\n\n    # close the environment\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Main Simulation Loop for Cartpole RL Environment in Python\nDESCRIPTION: Implements the main simulation loop using ManagerBasedRLEnv to run the cartpole environment. Handles environment stepping, reward calculation, and termination checking.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_rl_env.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef main():\n    \"\"\"Main function.\"\"\"\n    # parse arguments\n    parser = ArgumentParser(description=\"Cartpole environment -- RL\")\n    parser.add_argument(\"--num_envs\", type=int, default=1, help=\"Number of environments to simulate.\")\n    args_cli = parser.parse_args()\n\n    # create environment\n    env = envs.ManagerBasedRLEnv(CartpoleEnvCfg(num_envs=args_cli.num_envs))\n\n    # create a viewer\n    env.reset()\n    # simulate\n    while simulation_app.is_running():\n        # simulate one step\n        actions = torch.zeros(env.env_cfg.num_envs, *env.action_spec.shape)\n        obs, rew, terminated, info = env.step(actions)\n        # check connection\n        if not env.is_playing():\n            break\n\n    # close the viewer\n    simulation_app.close()\n```\n\n----------------------------------------\n\nTITLE: Defining DirectRLEnv Configuration Class for Cartpole\nDESCRIPTION: Configuration class for a direct workflow cartpole environment, inheriting from DirectRLEnvCfg. It defines action and observation spaces, reset conditions, and reward scale parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass CartpoleEnvCfg(DirectRLEnvCfg):\n   ...\n   action_space = 1\n   observation_space = 4\n   state_space = 0\n```\n\n----------------------------------------\n\nTITLE: Acquiring and Accessing Joint State Data - IsaacGymEnvs vs. Isaac Lab - Python\nDESCRIPTION: These paired snippets compare state acquisition in IsaacGymEnvs and Isaac Lab. The IsaacGymEnvs side uses gym.acquire_dof_state_tensor(), manual tensor wrapping/unwrapping, and explicit refresh calls, while the Isaac Lab side directly accesses joint position and velocity fields from the robot articulationâ€™s .data object. Required dependencies are torch and gym APIs or their Isaac Lab equivalents. Input is the simulation data/state; output is direct access to joint state tensors. Limitations in IsaacGymEnvs include manual refresh and explicit tensor handling, while Isaac Lab streamlines this workflow.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndof_state_tensor = self.gym.acquire_dof_state_tensor(self.sim)\nself.dof_state = gymtorch.wrap_tensor(dof_state_tensor)\nself.gym.refresh_dof_state_tensor(self.sim)\n```\n\nLANGUAGE: python\nCODE:\n```\nself.joint_pos = self._robot.data.joint_pos\nself.joint_vel = self._robot.data.joint_vel\n```\n\n----------------------------------------\n\nTITLE: Spawning Articulated Robot in Isaac Sim\nDESCRIPTION: Code that creates an articulation (cart-pole) from a USD file using the ArticulationCfg class. Demonstrates how to set up groups and spawn the articulation in the simulation environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_articulation.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Create separate groups called \"Origin1\", \"Origin2\"\ngroup1 = Group(\"Origin1\")\ngroup2 = Group(\"Origin2\")\n\n# Add a ground plane and light to the scene\nenvironment = Environment()\nlight = Light(prim_path=\"/light\")\n\n# Get the cart-pole configuration\ncartpole_cfg = asset_info.CARTPOLE_FROM_USD\n\n# Add the robots to the scenes\ncartpole = Articulation(cfg=cartpole_cfg)\n```\n\n----------------------------------------\n\nTITLE: Creating Environment with Gymnasium Registry\nDESCRIPTION: Code snippet demonstrating the improved approach of creating an environment using gym.make() after registering it with the Gymnasium registry.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/register_rl_env_gym.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Set parameters to modify the configuration\nparser = argparse.ArgumentParser(description=\"Random policy for environments.\")\nparser.add_argument(\"--task\", type=str, default=\"Isaac-Cartpole-v0\", help=\"Name of the environment.\")\nparser.add_argument(\"--num_envs\", type=int, default=32, help=\"Number of environments to simulate.\")\nparser.add_argument(\"--disable_render\", action=\"store_true\", default=False, help=\"Disable rendering.\")\nparser.add_argument(\"--device\", type=str, default=None, help=\"Device to run simulator on.\")\nargs_cli = parser.parse_args()\n\n# create environment configuration\nenv_cfg = load_default_env_cfg(args_cli.task)\n# update configuration\nenv_cfg.sim.num_envs = args_cli.num_envs\nenv_cfg.sim.add_ground_plane = True\nenv_cfg.render_camera = not args_cli.disable_render\nif args_cli.device is not None:\n    env_cfg.sim.device = args_cli.device\n# create environment\nenv = gym.make(args_cli.task, cfg=env_cfg)\n```\n\n----------------------------------------\n\nTITLE: Registering a Custom Environment with Gymnasium in Isaac Lab (Python)\nDESCRIPTION: Provides a canonical example of registering a new RL environment module within Gymnasium using Isaac Lab conventions. Required dependencies: gymnasium, environment-specific agent/config files, and implementation of environment class/object. Parameters include the environment ID, entry point, and keyword arguments for configuration file pointers. This snippet should be included in the environment package's __init__.py. The registration step is necessary for integration with Gym training scripts.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport gymnasium as gym\n\nfrom . import agents\nfrom .cartpole_env import CartpoleEnv, CartpoleEnvCfg\n\n##\n# Register Gym environments.\n##\n\ngym.register(\n    id=\"Isaac-Cartpole-Direct-v0\",\n    entry_point=\"isaaclab_tasks.direct_workflow.cartpole:CartpoleEnv\",\n    disable_env_checker=True,\n    kwargs={\n        \"env_cfg_entry_point\": CartpoleEnvCfg,\n        \"rl_games_cfg_entry_point\": f\"{agents.__name__}:rl_games_ppo_cfg.yaml\"\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Implementation of Stable-Baselines3 Training Script\nDESCRIPTION: Python script for training a reinforcement learning agent using Stable-Baselines3. It creates the environment, applies wrappers, and sets up the PPO algorithm for training.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/run_rl_training.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n.. literalinclude:: ../../../../scripts/reinforcement_learning/sb3/train.py\n  :language: python\n  :emphasize-lines: 57, 66, 68-70, 81, 90-98, 100, 105-113, 115-116, 121-126, 133-136\n  :linenos:\n```\n\n----------------------------------------\n\nTITLE: Creating and Spawning a Ground Plane in Isaac Lab with Python\nDESCRIPTION: Demonstrates how to create a grid-like ground plane by configuring appearance and size properties using the GroundPlaneCfg class and then spawn it into the scene using its built-in function.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/spawn_prims.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Ground-plane\ncfg_ground = sim.spawners.GroundPlaneCfg()\ncfg_ground.size = 500.0\ncfg_ground.color = torch.tensor([0.8, 0.8, 0.8])\ncfg_ground.pattern_frequency = 0.1\ncfg_ground.pattern_rotation = 0.0\ncfg_ground.pattern_color = torch.tensor([0.8, 0.8, 0.8])\ncfg_ground.func(\"/World/defaultGroundPlane\", cfg_ground)\n```\n\n----------------------------------------\n\nTITLE: Configuring Tiled Camera in Isaac Lab Python\nDESCRIPTION: Example configuration for TiledCamera in Isaac Lab, specifying camera paths, offset transformations, data types, and parameters for pinhole cameras. This configuration is used when creating a TiledCamera instance.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/camera.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ntiled_camera: TiledCameraCfg = TiledCameraCfg(\n    prim_path=\"/World/envs/env_.*/Camera\",\n    offset=TiledCameraCfg.OffsetCfg(pos=(-7.0, 0.0, 3.0), rot=(0.9945, 0.0, 0.1045, 0.0), convention=\"world\"),\n    data_types=[\"rgb\"],\n    spawn=sim_utils.PinholeCameraCfg(\n        focal_length=24.0, focus_distance=400.0, horizontal_aperture=20.955, clipping_range=(0.1, 20.0)\n    ),\n    width=80,\n    height=80,\n)\n```\n\n----------------------------------------\n\nTITLE: Training and Playing with RL-Games on Isaac-Ant-v0 in Windows\nDESCRIPTION: Commands for installing RL-Games, training an agent on the Isaac-Ant-v0 environment, playing trained models, and recording videos in Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_1\n\nLANGUAGE: batch\nCODE:\n```\n:: install python module (for rl-games)\nisaaclab.bat -i rl_games\n:: run script for training\nisaaclab.bat -p scripts\\reinforcement_learning\\rl_games\\train.py --task Isaac-Ant-v0 --headless\n:: run script for playing with 32 environments\nisaaclab.bat -p scripts\\reinforcement_learning\\rl_games\\play.py --task Isaac-Ant-v0 --num_envs 32 --checkpoint /PATH/TO/model.pth\n:: run script for playing a pre-trained checkpoint with 32 environments\nisaaclab.bat -p scripts\\reinforcement_learning\\rl_games\\play.py --task Isaac-Ant-v0 --num_envs 32 --use_pretrained_checkpoint\n:: run script for recording video of a trained agent (requires installing `ffmpeg`)\nisaaclab.bat -p scripts\\reinforcement_learning\\rl_games\\play.py --task Isaac-Ant-v0 --headless --video --video_length 200\n```\n\n----------------------------------------\n\nTITLE: Creating an Operational Space Controller in Python\nDESCRIPTION: This code snippet demonstrates how to create and configure an Operational Space Controller (OSC) for a robot. It sets up the controller with specific parameters for motion control, force control, impedance modes, and null-space behavior.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_osc.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Create the OSC\nosc_cfg = OperationalSpaceControllerCfg(\n    target_types=[\"pose_abs\", \"wrench_abs\"],\n    motion_control_axes_task=[1, 1, 0, 1, 1, 1],\n    force_control_axes_task=[0, 0, 1, 0, 0, 0],\n    motion_control_stiffness=stiffness_val,\n    motion_damping_ratio_task=1.0,\n    impedance_mode=\"variable_kp\",\n    motion_stiffness_limits_task=[0.0, 500.0],\n    inertial_dynamics_decoupling=True,\n    partial_inertial_dynamics_decoupling=False,\n    gravity_compensation=False,\n    nullspace_control=\"position\",\n    nullspace_stiffness=20.0,\n    nullspace_damping_ratio=1.0,\n)\nosc = OperationalSpaceController(osc_cfg, num_envs=scene.num_envs, device=sim.device)\n```\n\n----------------------------------------\n\nTITLE: Registering a Custom Environment with Gymnasium in Isaac Lab - Python\nDESCRIPTION: This snippet registers a custom task environment named 'Isaac-Cartpole-Direct-v0' using Gymnasium's register API in Python. It specifies the module entrypoint, disables the environment checker, and passes in both the environment configuration entry point and the RL games config entry point. Required dependencies are gymnasium and proper module/file structure; key parameters are id, entry_point, disable_env_checker, and kwargs. Successful execution registers the custom environment for use in training and inference scripts.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport gymnasium as gym\n\nfrom . import agents\nfrom .cartpole_env import CartpoleEnv, CartpoleEnvCfg\n\n##\n# Register Gym environments.\n##\n\ngym.register(\n    id=\"Isaac-Cartpole-Direct-v0\",\n    entry_point=\"isaaclab_tasks.direct_workflow.cartpole:CartpoleEnv\",\n    disable_env_checker=True,\n    kwargs={\n        \"env_cfg_entry_point\": CartpoleEnvCfg,\n        \"rl_games_cfg_entry_point\": f\"{agents.__name__}:rl_games_ppo_cfg.yaml\"\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Direct Workflow RL Environment Class\nDESCRIPTION: The environment class for the cartpole task that inherits from DirectRLEnv, including the class initialization which receives the configuration object.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass CartpoleEnv(DirectRLEnv):\n   cfg: CartpoleEnvCfg\n\n   def __init__(self, cfg: CartpoleEnvCfg, render_mode: str | None = None, **kwargs):\n     super().__init__(cfg, render_mode, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Creating a Complete Cartpole Environment Configuration in Python\nDESCRIPTION: This code defines the CartpoleEnvCfg class that brings together all the components (scene, actions, observations, events) to create a complete environment configuration. It also modifies default simulation parameters in the post-initialization method.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_base_env.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass CartpoleEnvCfg(ManagerBasedEnvCfg):\n    \"\"\"Configuration for the cartpole environment.\"\"\"\n\n    def __post_init__(self):\n        \"\"\"Post initialization of the cartpole environment configuration.\"\"\"\n        # Initialize the scene with the cartpole scene\n        self.scene = SceneCfg()\n\n        # Set action, observation and event configurations\n        self.actions = ActionsCfg()\n        self.observations = ObservationsCfg()\n        self.events = EventCfg()\n\n        # Modify default simulation parameters\n        self.sim.dt = 1.0 / 60.0\n        self.sim.substeps = 2\n```\n\n----------------------------------------\n\nTITLE: Training and Playing with RL-Games on Isaac-Ant-v0 in Linux\nDESCRIPTION: Commands for installing RL-Games, training an agent on the Isaac-Ant-v0 environment, playing trained models, and recording videos in Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# install python module (for rl-games)\n./isaaclab.sh -i rl_games\n# run script for training\n./isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py --task Isaac-Ant-v0 --headless\n# run script for playing with 32 environments\n./isaaclab.sh -p scripts/reinforcement_learning/rl_games/play.py --task Isaac-Ant-v0 --num_envs 32 --checkpoint /PATH/TO/model.pth\n# run script for playing a pre-trained checkpoint with 32 environments\n./isaaclab.sh -p scripts/reinforcement_learning/rl_games/play.py --task Isaac-Ant-v0 --num_envs 32 --use_pretrained_checkpoint\n# run script for recording video of a trained agent (requires installing `ffmpeg`)\n./isaaclab.sh -p scripts/reinforcement_learning/rl_games/play.py --task Isaac-Ant-v0 --headless --video --video_length 200\n```\n\n----------------------------------------\n\nTITLE: Resetting Articulation State in Isaac Sim\nDESCRIPTION: Shows how to reset an articulation by setting root pose, velocity, and joint states. The code demonstrates the full reset process including calling the articulation's reset method to clear internal buffers.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_articulation.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# reset the scene entities\nterrain.set_world_poses(torch.zeros(1, 7, device=self.sim.device))\n\n# Set robot state\npos_x = -0.5 if start_group_name == \"Origin1\" else 0.5\n\nrobot_position = torch.tensor([pos_x, 0.0, 0.3], device=self.sim.device)\nrobot_orientation = torch.tensor([1.0, 0.0, 0.0, 0.0], device=self.sim.device)\nrobot_lin_vel = torch.zeros(3, device=self.sim.device)\nrobot_ang_vel = torch.zeros(3, device=self.sim.device)\nrobot_joint_pos = torch.zeros(robot.num_dof, device=self.sim.device)\nrobot_joint_vel = torch.zeros(robot.num_dof, device=self.sim.device)\n\n# Write pose to sim\nrobot.write_root_pose_to_sim(robot_position, robot_orientation)\nrobot.write_root_velocity_to_sim(robot_lin_vel, robot_ang_vel)\nrobot.write_joint_state_to_sim(robot_joint_pos, robot_joint_vel)\nrobot.reset()\n```\n\n----------------------------------------\n\nTITLE: Differential Inverse Kinematics Control\nDESCRIPTION: Task-space to joint-space conversion using various pseudo-inverse formulations of the Jacobian matrix.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/motion_generators.rst#2025-04-23_snippet_3\n\nLANGUAGE: math\nCODE:\n```\nq_{des} = q + \\eta J_{eO}^{-} \\Delta \\chi_e\n```\n\n----------------------------------------\n\nTITLE: Domain Randomization Configuration for Direct Workflow\nDESCRIPTION: Example configuration for domain randomization in direct workflow, using EventTerm to specify materials, joint properties, and physics parameters to randomize during training.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass EventCfg:\n  robot_physics_material = EventTerm(\n      func=mdp.randomize_rigid_body_material,\n      mode=\"reset\",\n      params={\n          \"asset_cfg\": SceneEntityCfg(\"robot\", body_names=\".*\"),\n          \"static_friction_range\": (0.7, 1.3),\n          \"dynamic_friction_range\": (1.0, 1.0),\n          \"restitution_range\": (1.0, 1.0),\n          \"num_buckets\": 250,\n      },\n  )\n  robot_joint_stiffness_and_damping = EventTerm(\n      func=mdp.randomize_actuator_gains,\n      mode=\"reset\",\n      params={\n          \"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=\".*\"),\n          \"stiffness_distribution_params\": (0.75, 1.5),\n          \"damping_distribution_params\": (0.3, 3.0),\n          \"operation\": \"scale\",\n          \"distribution\": \"log_uniform\",\n      },\n  )\n  reset_gravity = EventTerm(\n```\n\n----------------------------------------\n\nTITLE: Applying Kinematic Targets to Deformable Object Nodes in IsaacLab (Python)\nDESCRIPTION: This code shows how to set kinematic position targets for specific nodes of a deformable object during the simulation. By incrementally adjusting target positions, users can control the movement of certain mesh nodes while others remain passive. This method is integral for partial kinematic interactions and requires the DeformableObject class and simulation buffers be correctly in place.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_deformable_object.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# update the kinematic target for cubes at index 0 and 3\ncube_object.write_nodal_kinematic_target_to_sim(nodal_kinematic_target)\n```\n\n----------------------------------------\n\nTITLE: Resetting Rigid Object Simulation State\nDESCRIPTION: Demonstrates how to reset the simulation state of rigid objects by setting their pose and velocity in the world frame. Includes randomization of translation coordinates.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_rigid_object.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# reset root state\nroot_state = cone_object.data.default_root_state.clone()\nroot_state[..., :3] = torch.tensor([0.0, 0.0, 2.0]).expand_as(root_state[..., :3])\nroot_state[..., :3] += 0.1 * torch.randn_like(root_state[..., :3])\n# write to simulation\ncone_object.write_root_pose_to_sim(root_state[..., :7])\ncone_object.write_root_velocity_to_sim(root_state[..., 7:])\ncone_object.reset()\n```\n\n----------------------------------------\n\nTITLE: Creating a Differential IK Controller in Python\nDESCRIPTION: Initializes a differential inverse kinematics controller using damped least-squares method for computing desired joint positions to reach target end-effector poses. The controller is configured to track absolute end-effector poses.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_diff_ik.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Create controller\ndiff_ik_cfg = DifferentialIKControllerCfg(\n    command_type=\"pose_abs\",\n    ik_method=\"dls\",\n    gain=1.0,\n    damping=0.05,\n)\ndiff_ik_controller = DifferentialIKController(diff_ik_cfg, num_envs=scene.num_envs, device=sim.device)\n```\n\n----------------------------------------\n\nTITLE: Constructing and Cloning Scenes Using Isaac Sim Cloner APIs - Python\nDESCRIPTION: This snippet demonstrates how to construct a single simulation environment using a Cartpole robot, replicate this environment for multiple environments via the clone_environments() method, and filter out collisions between environments by providing global primitive paths to filter_collisions(). Dependencies include proper configuration access (self.cfg) and the Isaac Sim/Isaac Lab API for Articulation and scene management. Inputs are the robot configuration and terrain path, and the code outputs a cloned, collision-filtered scene for multi-environment simulations.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# construct a single environment with the Cartpole robot\nself.cartpole = Articulation(self.cfg.robot_cfg)\n# clone the environment\nself.scene.clone_environments(copy_from_source=False)\n# filter collisions\nself.scene.filter_collisions(global_prim_paths=[self.cfg.terrain.prim_path])\n```\n\n----------------------------------------\n\nTITLE: Scene Creation for Direct Workflow Environment\nDESCRIPTION: The _setup_scene method implements scene creation for the environment, including adding actors to the stage, cloning environments, and configuring the scene with ground plane and lights.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef _setup_scene(self):\n    stage = get_current_stage()\n    add_stage_up_axis(stage, cfg.WorldCfg.up_axis)\n\n    # create physics scene\n    self.physics_sim_view = PhysicsSceneView(\n        self.physics_sim,\n        self.device,\n        scene_cfg=self.cfg.scene,\n    )\n\n    # add ground\n    self.ground = add_ground_plane(\n        stage=stage,\n        name=\"ground_plane\",\n        size=100.0,\n        position=(0.0, 0.0, 0.0),\n        color=(0.2, 0.2, 0.2),\n    )\n\n    # create env\n    grid_x = int(math.sqrt(self.num_envs) + 0.5)\n    grid_y = int(self.num_envs / grid_x + 0.5)\n\n    # create cartpole\n    self.cart_usd = ISAAC_LAB_TASKS_ASSETS.joinpath(\"cartpole\").joinpath(\"cartpole.usd\")\n    # load basic cart physics properties\n    cartpole_path = load_asset_from_disk(stage, self.cart_usd, \"cartpole\")\n    self.cartpole = RigidPrimView(cartpole_path, self.physics_sim, name=\"cartpole\")\n    # create cart clone in each environment\n    self.cloner = EnvCloner(stage=stage, num_envs=self.num_envs)\n    self.envs_positions = torch.zeros((self.num_envs, 3), device=self.device)\n    self.envs_positions[:, 0] = torch.arange(0, grid_x, device=self.device).repeat_interleave(grid_y) * 4.0\n    self.envs_positions[:, 1] = torch.arange(0, grid_y, device=self.device).repeat(grid_x) * 4.0\n    self.cloner.clone_prim(cartpole_path, self.envs_positions)\n\n    # filter out self-collisions\n    filter_collisions(self.physics_sim, \"cartpole.*\")\n    # filter out collisions between environments\n    filter_collisions_by_env_id(self.physics_sim, \"cartpole.*\", \"cartpole.*\", self.cloner.env_id_array)\n\n    # add articulation\n    self.articulation = ArticulationView(cartpole_path, self.physics_sim, name=\"cartpole\")\n\n    # track indices for cart and pole dofs\n    self._cart_dof_idx = []\n    self._pole_dof_idx = []\n    for i, j in enumerate(self.articulation.dof_names):\n        if j == \"slider_to_cart\":\n            self._cart_dof_idx.append(i)\n        elif j == \"cart_to_pole\":\n            self._pole_dof_idx.append(i)\n\n    # add lights\n    add_distant_light(stage, name=\"distant_light\", intensity=1000.0, exposure=1.0)\n    add_dome_light(stage, name=\"dome_light\", color=(0.8, 0.8, 0.8), intensity=2000.0, exposure=0.5)\n\n    # reset env\n    self.reset_terminated = None\n    self.reset_goal_reached = None\n    self.reset_time_out = None\n    self.reset_buf = None\n    self.progress_buf = None\n    self.states_buf = None\n    self.actions = None\n    reset_buffers(self, self.num_envs)\n```\n\n----------------------------------------\n\nTITLE: Defining Job Configuration for Ray Tuning (Python)\nDESCRIPTION: Python code snippet showing the definition of the `JobCfg` class within `tuner.py`. This class serves as a configuration structure for specifying parameters and settings for hyperparameter tuning jobs submitted via Ray Tune, specifically tailored for the rl_games workflow.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n... literalinclude:: ../../../scripts/reinforcement_learning/ray/tuner.py\n  :language: python\n  :start-at: class JobCfg\n  :end-at: self.cfg = cfg\n```\n\n----------------------------------------\n\nTITLE: Training a Robot Dog with Reinforcement Learning (Windows)\nDESCRIPTION: This command runs a predefined workflow to train a robot dog (Anymal C) to navigate rough terrain using reinforcement learning in Isaac Lab on Windows. The --headless flag is recommended for faster training.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_26\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Velocity-Rough-Anymal-C-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Spawning Deformable Objects with IsaacLab in Python\nDESCRIPTION: This snippet demonstrates how to set up and spawn deformable (soft body) objects in a simulation scene using IsaacLab's assets API. The DeformableObjectCfg class holds the spawning and initial state configuration, which is used by DeformableObject to initialize and manage the object within the simulation. Required dependencies include IsaacLab's assets module, and the cube_object will manage the soft body instance. No external or third-party libraries (other than the underlying simulation environment) are needed.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_deformable_object.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Create separate groups called \"Origin1\", \"Origin2\", \"Origin3\"\nfrom isaaclab.assets import DeformableObject, DeformableObjectCfg\n\ncfg = DeformableObjectCfg(\n    prim_path=\"/World/Cube\",\n    ... # configuration details omitted for brevity\n)\ncube_object = DeformableObject(cfg=cfg)\n```\n\n----------------------------------------\n\nTITLE: Defining and Configuring an Articulation Actor Using ArticulationCfg (Python)\nDESCRIPTION: Defines a robot (cartpole) using ArticulationCfg, specifying the robot's USD file, rigid body properties, articulation root settings, initial state, and multiple actuators. Makes use of sim_utils for configuration, and includes settings for joint effort, velocity, stiffness, and damping. Meant to serve as an input to actor creation and later registration into the simulation scene. Dependencies: isaaclab, sim_utils, valid USD asset path constants. Inputs: spawn parameters and actuator configs; Outputs: ArticulationCfg instance.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.actuators import ImplicitActuatorCfg\nfrom isaaclab.assets import ArticulationCfg\n\nCARTPOLE_CFG = ArticulationCfg(\n    spawn=sim_utils.UsdFileCfg(\n        usd_path=f\"{ISAACLAB_NUCLEUS_DIR}/Robots/Classic/Cartpole/cartpole.usd\",\n        rigid_props=sim_utils.RigidBodyPropertiesCfg(\n            rigid_body_enabled=True,\n            max_linear_velocity=1000.0,\n            max_angular_velocity=1000.0,\n            max_depenetration_velocity=100.0,\n            enable_gyroscopic_forces=True,\n        ),\n        articulation_props=sim_utils.ArticulationRootPropertiesCfg(\n            enabled_self_collisions=False,\n            solver_position_iteration_count=4,\n            solver_velocity_iteration_count=0,\n            sleep_threshold=0.005,\n            stabilization_threshold=0.001,\n        ),\n    ),\n    init_state=ArticulationCfg.InitialStateCfg(\n        pos=(0.0, 0.0, 2.0), joint_pos={\"slider_to_cart\": 0.0, \"cart_to_pole\": 0.0}\n    ),\n    actuators={\n        \"cart_actuator\": ImplicitActuatorCfg(\n            joint_names_expr=[\"slider_to_cart\"],\n            effort_limit=400.0,\n            velocity_limit=100.0,\n            stiffness=0.0,\n            damping=10.0,\n        ),\n        \"pole_actuator\": ImplicitActuatorCfg(\n            joint_names_expr=[\"cart_to_pole\"], effort_limit=400.0, velocity_limit=100.0, stiffness=0.0, damping=0.0\n        ),\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Registering Isaac Lab Environments with OpenAI Gym - Python\nDESCRIPTION: This Python snippet demonstrates how two variants of the 'Isaac-Velocity-Anymal-C' environments (Rough and Flat) are registered with the OpenAI Gym registry using gym.register. Each call to gym.register specifies a unique environment ID, entry point, disables the default env checker, and passes a dictionary of configuration entry points for different RL libraries. All dependencies such as the gym library and references to agent/config modules are required; input parameters include the environment IDs and config paths, and the snippet assumes that the configuration classes and YAMLs exist and are accessible via the specified dotted paths.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab_tasks/docs/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngym.register(\\n    id=\\\"Isaac-Velocity-Rough-Anymal-C-v0\\\",\\n    entry_point=\\\"isaaclab.envs:ManagerBasedRLEnv\\\",\\n    disable_env_checker=True,\\n    kwargs={\\n        \\\"env_cfg_entry_point\\\": f\\\"{__name__}.rough_env_cfg:AnymalCRoughEnvCfg\\\",\\n        \\\"rl_games_cfg_entry_point\\\": f\\\"{agents.__name__}:rl_games_rough_ppo_cfg.yaml\\\",\\n        \\\"rsl_rl_cfg_entry_point\\\": f\\\"{agents.__name__}.rsl_rl_ppo_cfg:AnymalCRoughPPORunnerCfg\\\",\\n        \\\"skrl_cfg_entry_point\\\": f\\\"{agents.__name__}:skrl_rough_ppo_cfg.yaml\\\",\\n    },\\n)\\n\\ngym.register(\\n    id=\\\"Isaac-Velocity-Flat-Anymal-C-v0\\\",\\n    entry_point=\\\"isaaclab.envs:ManagerBasedRLEnv\\\",\\n    disable_env_checker=True,\\n    kwargs={\\n        \\\"env_cfg_entry_point\\\": f\\\"{__name__}.flat_env_cfg:AnymalCFlatEnvCfg\\\",\\n        \\\"rsl_rl_cfg_entry_point\\\": f\\\"{agents.__name__}.rsl_rl_ppo_cfg:AnymalCFlatPPORunnerCfg\\\",\\n        \\\"rl_games_cfg_entry_point\\\": f\\\"{agents.__name__}:rl_games_flat_ppo_cfg.yaml\\\",\\n        \\\"skrl_cfg_entry_point\\\": f\\\"{agents.__name__}:skrl_flat_ppo_cfg.yaml\\\",\\n    },\\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Rigid Objects in Isaac Sim\nDESCRIPTION: Creates multiple cone objects at different spawn locations using RigidObject class. Demonstrates how to set up spawn configurations and initialize physics handles for rigid objects.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_rigid_object.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Create separate groups called \"Origin1\", \"Origin2\", \"Origin3\"\nfor i in range(3):\n    origin_prim = stage.DefinePrim(f\"/World/Origin{i+1}\", \"Xform\")\n    origins.append(origin_prim)\n    # Set random poses for the origins\n    pos = np.random.uniform([0, 0, 0.5], [0, 0, 2.0])\n    rot = R.random().as_quat()\n    UsdGeom.XformCommonAPI(origin_prim).SetTranslate(pos)\n    UsdGeom.XformCommonAPI(origin_prim).SetRotate(convert.quat_to_euler_angles(rot))\n\n# Create the rigid object\ncone_cfg = RigidObjectCfg(\n    prim_path=\"/World/Origin.*/Cone\",\n    spawn=SpawnCfg(\n        func=create_primitive,\n        args=(\n            \"Cone\",\n            dict(\n                size=(0.05, 0.05, 0.1),\n                semantic_label=\"cone\",\n                visual_material=create_uniform_green_material(),\n            ),\n        ),\n    ),\n)\ncone_object = RigidObject(cfg=cone_cfg)\n```\n\n----------------------------------------\n\nTITLE: Spawning a Static ANYmal Robot in Isaac Sim\nDESCRIPTION: This code demonstrates how to spawn an ANYmal robot as a static articulation in the simulation. It uses the UsdFileCfg class to load the robot model and sets various properties, including fixing the root link to make it static.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/make_fixed_prim.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport isaaclab.sim as sim_utils\nfrom isaaclab.utils.assets import ISAACLAB_NUCLEUS_DIR\n\nanymal_spawn_cfg = sim_utils.UsdFileCfg(\n    usd_path=f\"{ISAACLAB_NUCLEUS_DIR}/Robots/ANYbotics/ANYmal-C/anymal_c.usd\",\n    activate_contact_sensors=True,\n    rigid_props=sim_utils.RigidBodyPropertiesCfg(\n        disable_gravity=False,\n        retain_accelerations=False,\n        linear_damping=0.0,\n        angular_damping=0.0,\n        max_linear_velocity=1000.0,\n        max_angular_velocity=1000.0,\n        max_depenetration_velocity=1.0,\n    ),\n    articulation_props=sim_utils.ArticulationRootPropertiesCfg(\n        enabled_self_collisions=True,\n        solver_position_iteration_count=4,\n        solver_velocity_iteration_count=0,\n        fix_root_link=True,\n    ),\n)\nanymal_spawn_cfg.func(\n    \"/World/ANYmal\", anymal_spawn_cfg, translation=(0.0, 0.0, 0.8), orientation=(1.0, 0.0, 0.0, 0.0)\n)\n```\n\n----------------------------------------\n\nTITLE: Computing CartPole Rewards in Isaac Lab\nDESCRIPTION: Implementation of reward calculation for CartPole environment in Isaac Lab. Uses scaled rewards based on alive status, termination, pole position, cart and pole velocities.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_33\n\nLANGUAGE: python\nCODE:\n```\ndef _get_rewards(self) -> torch.Tensor:\n    total_reward = compute_rewards(\n        self.cfg.rew_scale_alive,\n        self.cfg.rew_scale_terminated,\n        self.cfg.rew_scale_pole_pos,\n        self.cfg.rew_scale_cart_vel,\n        self.cfg.rew_scale_pole_vel,\n        self.joint_pos[:, self._pole_dof_idx[0]],\n        self.joint_vel[:, self._pole_dof_idx[0]],\n        self.joint_pos[:, self._cart_dof_idx[0]],\n        self.joint_vel[:, self._cart_dof_idx[0]],\n        self.reset_terminated,\n    )\n    return total_reward\n\n@torch.jit.script\ndef compute_rewards(\n    rew_scale_alive: float,\n    rew_scale_terminated: float,\n    rew_scale_pole_pos: float,\n    rew_scale_cart_vel: float,\n    rew_scale_pole_vel: float,\n    pole_pos: torch.Tensor,\n    pole_vel: torch.Tensor,\n    cart_pos: torch.Tensor,\n    cart_vel: torch.Tensor,\n    reset_terminated: torch.Tensor,\n):\n    rew_alive = rew_scale_alive * (1.0 - reset_terminated.float())\n    rew_termination = rew_scale_terminated * reset_terminated.float()\n    rew_pole_pos = rew_scale_pole_pos * torch.sum(\n        torch.square(pole_pos), dim=-1)\n    rew_cart_vel = rew_scale_cart_vel * torch.sum(\n        torch.abs(cart_vel), dim=-1)\n    rew_pole_vel = rew_scale_pole_vel * torch.sum(\n        torch.abs(pole_vel), dim=-1)\n    total_reward = (rew_alive + rew_termination\n                     + rew_pole_pos + rew_cart_vel + rew_pole_vel)\n    return total_reward\n```\n\n----------------------------------------\n\nTITLE: Defining Task Config Class with configclass in Isaac Lab\nDESCRIPTION: A skeleton example showing how to define a task configuration class using the configclass decorator in Isaac Lab. The class inherits from DirectRLEnvCfg and includes simulation, robot, scene, and task-specific parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.envs import DirectRLEnvCfg\nfrom isaaclab.scene import InteractiveSceneCfg\nfrom isaaclab.sim import SimulationCfg\n\n@configclass\nclass MyEnvCfg(DirectRLEnvCfg):\n   # simulation\n   sim: SimulationCfg = SimulationCfg()\n   # robot\n   robot_cfg: ArticulationCfg = ArticulationCfg()\n   # scene\n   scene: InteractiveSceneCfg = InteractiveSceneCfg()\n   # env\n   decimation = 2\n   episode_length_s = 5.0\n   action_space = 1\n   observation_space = 4\n   state_space = 0\n   # task-specific parameters\n   ...\n```\n\n----------------------------------------\n\nTITLE: Training and Playing Multi-Agent SKRL on Isaac-Shadow-Hand-Over-Direct-v0 in Windows\nDESCRIPTION: Commands for installing SKRL and training multi-agent systems on the Isaac-Shadow-Hand-Over-Direct-v0 environment in Windows using MAPPO or IPPO algorithms.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_8\n\nLANGUAGE: batch\nCODE:\n```\n:: install python module (for skrl)\nisaaclab.bat -i skrl\n:: run script for training with the MAPPO algorithm (IPPO is also supported)\nisaaclab.bat -p scripts\\reinforcement_learning\\skrl\\train.py --task Isaac-Shadow-Hand-Over-Direct-v0 --headless --algorithm MAPPO\n:: run script for playing with 32 environments with the MAPPO algorithm (IPPO is also supported)\n```\n\n----------------------------------------\n\nTITLE: Configuring IMU Sensors for Anymal Quadruped in Isaac Lab\nDESCRIPTION: This code snippet demonstrates how to add IMU sensors to the front feet of an Anymal Quadruped robot, with different gravity bias configurations for comparison. The left foot IMU retains the default gravity bias while the right foot IMU has the bias explicitly removed.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/imu.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef create_scenario(scene: InteractiveScene, render_product: RenderProduct):\n    # Set some parameters\n    if not precomputed_data_dir.exists():\n        precomputed_data_dir.mkdir(parents=True)\n\n    # Recommended camera settings\n    scene.height = 480\n    scene.width = 640\n\n    # Create Ground Plane\n    scene.ground_plane = GroundPlane(\n        surface_type=SurfaceType.GRID, size=100.0, color=torch.tensor([0.8, 0.3, 0.1]), metalness=0.3\n    )\n\n    ## Create an ANYmal Robot\n    scene[\"robot\"] = Anymal()\n\n    # Add an IMU to the left front foot\n    scene[\"imu_LF\"] = Imu(prim_path=scene[\"robot\"].lr_lower_joints[0].lr_lower_links[0].prim_path,\n                           name=\"imu_LF\", position=torch.zeros(3), orientation=torch.zeros(4),\n                           gravity_dir=torch.tensor([0.0, 0.0, -1.0]),\n                           gravity_bias=torch.tensor([0.0, 0.0, 9.81]))\n\n    # Add another IMU to the right front foot (and explicitly zero out the bias term)\n    scene[\"imu_RF\"] = Imu(prim_path=scene[\"robot\"].ll_lower_joints[0].ll_lower_links[0].prim_path,\n                          name=\"imu_RF\", position=torch.zeros(3), orientation=torch.zeros(4),\n                          gravity_dir=torch.tensor([0.0, 0.0, -1.0]),\n                          gravity_bias=torch.tensor([0.0, 0.0, 0.0]))\n```\n\n----------------------------------------\n\nTITLE: Training an Ant Robot with Reinforcement Learning (Linux)\nDESCRIPTION: This command runs a predefined workflow to train an ant robot to walk using reinforcement learning in Isaac Lab on Linux. The --headless flag is recommended for faster training.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Ant-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Computing Robot Command for Operational Space Control\nDESCRIPTION: This code transforms target commands to the task frame and sets the OSC command. It handles the conversion of desired pose and wrench values to the appropriate reference frame before sending them to the controller.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_osc.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Convert the target commands to the task frame\nee_pose_b_mat = isaac_tensor.pose_to_matrix(ee_pose_b)\nee_pos_b = ee_pose_b[:, 0:3]\nee_quat_b = ee_pose_b[:, 3:7]\n\ntask_frame_pos_b = target_pose_b[:, 0:3]\ntask_frame_quat_b = target_pose_b[:, 3:7]\ntask_frame_pose_b = torch.cat([task_frame_pos_b, task_frame_quat_b], dim=-1)\ntask_frame_rot_b = isaac_tensor.quat_to_rot(task_frame_quat_b)\n\n# Transform the pose targets to the task frame\ntarget_pos_task = torch.bmm(task_frame_rot_b.transpose(1, 2), (target_pos_b - task_frame_pos_b).unsqueeze(-1)).squeeze(-1)\ntarget_quat_task = isaac_tensor.quat_multiply(isaac_tensor.quat_conjugate(task_frame_quat_b), target_quat_b)\ntarget_pose_task = torch.cat([target_pos_task, target_quat_task], dim=-1)\n\n# Concatenate target pose and target wrench\ncommand = torch.cat([target_pose_task, desired_wrench_task, motion_kp], dim=-1)\n\nreturn command, task_frame_pose_b\n```\n\n----------------------------------------\n\nTITLE: Spawning a Rigid Body Cone in Isaac Lab with Python\nDESCRIPTION: Creates a cone with rigid body physics properties, including collision detection, mass, and material properties like friction and restitution. This enables physical simulation of the cone interacting with other objects.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/spawn_prims.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# spawn a green cone with colliders and rigid body\ncfg_cone = sim.spawners.ConeCfg()\ncfg_cone.radius = 0.5\ncfg_cone.height = 1.0\ncfg_cone.visual_material = sim.materials.PreviewSurfaceCfg()\ncfg_cone.visual_material.diffuse_color = torch.tensor([0.0, 1.0, 0.0])\n\n# add collision and physics properties\ncfg_cone.physics_material = sim.materials.RigidBodyMaterialCfg()\ncfg_cone.physics_material.friction_combine_mode = \"multiply\"\ncfg_cone.physics_material.restitution_combine_mode = \"multiply\"\ncfg_cone.physics_material.static_friction = 0.5\ncfg_cone.physics_material.dynamic_friction = 0.5\ncfg_cone.physics_material.restitution = 0.7\n\n# add rigid body physics properties\ncfg_cone.rigid_body_properties = sim.physics.RigidBodyPropertiesCfg()\ncfg_cone.rigid_body_properties.disable_gravity = False\ncfg_cone.rigid_body_properties.mass = 1.0\n\n# add collision properties\ncfg_cone.collision_properties = sim.physics.CollisionPropertiesCfg()\ncfg_cone.collision_properties.contact_offset = 0.02\ncfg_cone.collision_properties.rest_offset = 0.0\n\ncfg_cone.func(\"/World/Objects/ConeRigid\", cfg_cone, translation=(0.0, 0.0, 5.0))\n```\n\n----------------------------------------\n\nTITLE: Setting Up Contact Sensors for an Anymal Quadruped Robot in Python\nDESCRIPTION: This snippet shows how to define contact sensors on the feet of an Anymal Quadruped robot. It demonstrates two approaches: creating independent sensors for front feet with filtering for a specific object (Cube), and defining a single sensor with multiple bodies for hind feet.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/contact_sensor.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef run_simulator(sim: sim_utils.SimulationContext, scene: InteractiveScene):\n  .\n  .\n  .\n  # Simulate physics\n  while simulation_app.is_running():\n    .\n    .\n    .\n    # print information from the sensors\n    print(\"-------------------------------\")\n    print(scene[\"contact_forces_LF\"])\n    print(\"Received force matrix of: \", scene[\"contact_forces_LF\"].data.force_matrix_w)\n    print(\"Received contact force of: \", scene[\"contact_forces_LF\"].data.net_forces_w)\n    print(\"-------------------------------\")\n    print(scene[\"contact_forces_RF\"])\n    print(\"Received force matrix of: \", scene[\"contact_forces_RF\"].data.force_matrix_w)\n    print(\"Received contact force of: \", scene[\"contact_forces_RF\"].data.net_forces_w)\n    print(\"-------------------------------\")\n    print(scene[\"contact_forces_H\"])\n    print(\"Received force matrix of: \", scene[\"contact_forces_H\"].data.force_matrix_w)\n    print(\"Received contact force of: \", scene[\"contact_forces_H\"].data.net_forces_w)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Cartpole Scene in Isaac Lab\nDESCRIPTION: Demonstrates the updated scene setup process in Isaac Lab, including ground plane creation, environment cloning, collision filtering, and adding articulations and lights.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef _setup_scene(self):\n    self.cartpole = Articulation(self.cfg.robot_cfg)\n    # add ground plane\n    spawn_ground_plane(prim_path=\"/World/ground\", cfg=GroundPlaneCfg())\n    # clone, filter, and replicate\n    self.scene.clone_environments(copy_from_source=False)\n    self.scene.filter_collisions(global_prim_paths=[])\n    # add articulation to scene\n    self.scene.articulations[\"cartpole\"] = self.cartpole\n\n    # add lights\n    light_cfg = sim_utils.DomeLightCfg(intensity=2000.0, color=(0.75, 0.75, 0.75))\n    light_cfg.func(\"/World/Light\", light_cfg)\n```\n\n----------------------------------------\n\nTITLE: Contact Sensor Configuration in Python\nDESCRIPTION: The core implementation of configuring contact sensors for an Anymal Quadruped robot. This snippet shows how to set up the environment, create the robot, define contact sensors on various feet, and run the simulation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/contact_sensor.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef run_simulator(sim: sim_utils.SimulationContext, scene: InteractiveScene):\n    .\n    .\n    .\n    # Simulate physics\n    while simulation_app.is_running():\n      .\n      .\n      .\n      # print information from the sensors\n      print(\"-------------------------------\")\n      print(scene[\"contact_forces_LF\"])\n      print(\"Received force matrix of: \", scene[\"contact_forces_LF\"].data.force_matrix_w)\n      print(\"Received contact force of: \", scene[\"contact_forces_LF\"].data.net_forces_w)\n      print(\"-------------------------------\")\n      print(scene[\"contact_forces_RF\"])\n      print(\"Received force matrix of: \", scene[\"contact_forces_RF\"].data.force_matrix_w)\n      print(\"Received contact force of: \", scene[\"contact_forces_RF\"].data.net_forces_w)\n      print(\"-------------------------------\")\n      print(scene[\"contact_forces_H\"])\n      print(\"Received force matrix of: \", scene[\"contact_forces_H\"].data.force_matrix_w)\n      print(\"Received contact force of: \", scene[\"contact_forces_H\"].data.net_forces_w)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Event Configuration for Cartpole Simulation in Python\nDESCRIPTION: This code defines an EventCfg class that configures simulation events like randomizing pole mass at startup and resetting joint positions on environment reset. It demonstrates both 'startup' and 'reset' event modes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_base_env.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass EventCfg(ManagerBasedEnvCfg.EventCfg):\n    \"\"\"Configuration for events.\"\"\"\n\n    def __post_init__(self):\n        \"\"\"Initialize event terms.\"\"\"\n        # Create event to randomize the pole mass at startup\n        # Note: This operation is costly so we don't want to do it on every reset\n        self.domain_randomization = EventTermCfg(\n            func=lambda env: setattr(\n                env.scene.get_by_name(\"cartpole\").links[\"pole\"], \"mass\", torch.rand_like(env.scene.physics_sim_view.dt) * 0.1 + 0.1\n            ),\n            mode=\"startup\",\n        )\n\n        # Create an event to randomize the joint state at reset\n        self.randomize_joint_state = EventTermCfg(\n            func=lambda env: env.scene.get_by_name(\"cartpole\").set_joint_positions(\n                torch.zeros(\n                    env.scene.num_envs,\n                    env.scene.get_by_name(\"cartpole\").num_dof,\n                    device=env.device,\n                    dtype=torch.float,\n                ).uniform_(-0.05, 0.05)\n            ),\n            mode=\"reset\",\n        )\n```\n\n----------------------------------------\n\nTITLE: Executing the Sensor Script via IsaacLab Shell (Bash)\nDESCRIPTION: This Bash command runs the add_sensors_on_robot.py script using the IsaacLab shell, enabling camera support and spawning two environments for parallel simulation. The '--num_envs 2' flag sets the number of environments, and '--enable_cameras' activates camera sensor streams. Requires IsaacLab to be installed and available at the specified shell path.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/04_sensors/add_sensors_on_robot.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/tutorials/04_sensors/add_sensors_on_robot.py --num_envs 2 --enable_cameras\n```\n\n----------------------------------------\n\nTITLE: Configuring Contact Sensors on Robot's Feet in IsaacLab (Python)\nDESCRIPTION: This snippet creates a ContactSensorCfg instance to detect and report contact forces on the robot's feet using the PhysX API. The sensors are attached to all prims whose names match the regex \".*_FOOT\" (i.e., all feet), with an update period of 0 (synchronized with the simulation). History length determines the number of simulation steps for which contact data is stored (here, 6). Activating these sensors requires the robot asset configuration to enable contact sensors, and the PhysX backend.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/04_sensors/add_sensors_on_robot.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncontact_forces = ContactSensorCfg(\n    prim_regexs=[r\".*_FOOT\"],\n    update_period=0,\n    history_length=6,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Rewards for Cartpole RL Environment in Python\nDESCRIPTION: Defines reward terms for the cartpole balancing task including alive reward, termination penalty, pole angle reward, and velocity-based rewards. Uses RewardTermCfg to specify reward functions and their weights.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_rl_env.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass RewardsCfg:\n    \"\"\"Reward terms for the cartpole environment.\"\"\"\n\n    # list all reward terms and their weights\n    reward_terms = dict(\n        alive=RewardTermCfg(\n            term_fn=GymReward,\n            params=dict(value=1.0),\n            weight=0.1,\n        ),\n        terminating=RewardTermCfg(\n            term_fn=GymReward,\n            params=dict(value=-1.0),\n            weight=1.0,\n        ),\n        pole_angle=RewardTermCfg(\n            term_fn=GaussianReward,\n            params=dict(value=None, scale=0.5),\n            weight=3.0,\n        ),\n        cart_vel=RewardTermCfg(\n            term_fn=GaussianReward,\n            params=dict(value=None, scale=1.0),\n            weight=1.0,\n        ),\n        pole_vel=RewardTermCfg(\n            term_fn=GaussianReward,\n            params=dict(value=None, scale=2.0),\n            weight=1.0,\n        ),\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring Domain Randomization EventTerm in Python\nDESCRIPTION: This snippet shows how to set up an EventTerm for randomizing physics scene gravity in an Isaac Sim environment. It specifies the randomization function, mode, interval, and distribution parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfunc=mdp.randomize_physics_scene_gravity,\nmode=\"interval\",\nis_global_time=True,\ninterval_range_s=(36.0, 36.0),  # time_s = num_steps * (decimation * dt)\nparams={\n    \"gravity_distribution_params\": ([0.0, 0.0, 0.0], [0.0, 0.0, 0.4]),\n    \"operation\": \"add\",\n    \"distribution\": \"gaussian\",\n},\n```\n\n----------------------------------------\n\nTITLE: Training a Robot Dog with Isaac Lab (Windows)\nDESCRIPTION: Command to train a robot dog using Isaac Lab's reinforcement learning capabilities on Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_28\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Velocity-Rough-Anymal-C-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Configuring and Initializing SimulationContext\nDESCRIPTION: Demonstrates how to configure the simulation with physics and rendering time steps, and initialize the simulation context. Also shows camera positioning.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/create_empty.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the simulation context\nsim_cfg = SimulationCfg(\n    dt=0.01,  # Physics timestep size in seconds\n    render_dt=0.01,  # Rendering timestep size in seconds\n)\nsim = SimulationContext(sim_cfg)\n\n# Set the camera for viewing the scene\nsim.set_camera_view([2.5, 2.5, 2.5], [0.0, 0.0, 0.0])\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Configuration and Instance\nDESCRIPTION: Code snippet demonstrating how to create an environment configuration from default settings, update it with command line arguments, and instantiate the environment using gym.make().\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/register_rl_env_gym.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# create environment configuration\nenv_cfg = load_default_env_cfg(args_cli.task)\n# update configuration\nenv_cfg.sim.num_envs = args_cli.num_envs\nenv_cfg.sim.add_ground_plane = True\nenv_cfg.render_camera = not args_cli.disable_render\nif args_cli.device is not None:\n    env_cfg.sim.device = args_cli.device\n# create environment\nenv = gym.make(args_cli.task, cfg=env_cfg)\n```\n\n----------------------------------------\n\nTITLE: Running the Simulation Loop\nDESCRIPTION: Shows how to reset the simulation to initialize physics handles, then run a basic simulation loop that steps the simulator while the app is running.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/create_empty.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Play the simulator\nsim.reset()\n\n# Run a simple simulation loop\nwhile simulation_app.is_running():\n    # Step the simulator\n    sim.step()\n```\n\n----------------------------------------\n\nTITLE: Generating Observations for RL Policy\nDESCRIPTION: The _get_observations method constructs the observation buffer for the environment by gathering cart and pole state information and normalizing the values.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef _get_observations(self) -> dict[str, torch.Tensor]:\n    # store joint information in the buffer\n    self.joint_pos = self.articulation.get_joint_positions(clone=False)\n    self.joint_vel = self.articulation.get_joint_velocities(clone=False)\n\n    # compute observation\n    cart_pos = self.joint_pos[:, self._cart_dof_idx[0]].unsqueeze(-1)\n    cart_pos = cart_pos / self.cfg.max_cart_pos\n    cart_vel = self.joint_vel[:, self._cart_dof_idx[0]].unsqueeze(-1) / 10.0\n    pole_pos = self.joint_pos[:, self._pole_dof_idx[0]].unsqueeze(-1)\n    pole_vel = self.joint_vel[:, self._pole_dof_idx[0]].unsqueeze(-1) / 10.0\n\n    self.obs_buf = torch.cat([cart_pos, cart_vel, pole_pos, pole_vel], dim=-1)\n\n    return {\"policy\": self.obs_buf}\n```\n\n----------------------------------------\n\nTITLE: Accessing Scene Entities via InteractiveScene Dictionary Interface (Python)\nDESCRIPTION: Demonstrates how to access scene entities, such as the cartpole, using dictionary-like access on an InteractiveScene instance. This simplifies entity retrieval compared to manual management. Dependencies: an existing InteractiveScene instance with configured entities. The key parameter is the string key (for example, 'cartpole') which corresponds to configuration variable names. Returns the scene entity object for further manipulation. Limitation: Key names must match those defined in the configuration class.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/02_scene/create_scene.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Extract scene entities\nrobot = scene[\"cartpole\"]\n```\n\n----------------------------------------\n\nTITLE: Implementing Rewards Function with PyTorch JIT\nDESCRIPTION: The _get_rewards method calculates rewards for the cartpole environment using both class functions and a PyTorch JIT-compiled function for performance optimization.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef _get_rewards(self) -> torch.Tensor:\n    total_reward = compute_rewards(\n        self.cfg.rew_scale_alive,\n        self.cfg.rew_scale_terminated,\n        self.cfg.rew_scale_pole_pos,\n        self.cfg.rew_scale_cart_vel,\n        self.cfg.rew_scale_pole_vel,\n        self.joint_pos[:, self._pole_dof_idx[0]],\n        self.joint_vel[:, self._pole_dof_idx[0]],\n        self.joint_pos[:, self._cart_dof_idx[0]],\n        self.joint_vel[:, self._cart_dof_idx[0]],\n        self.reset_terminated,\n    )\n    return total_reward\n\n@torch.jit.script\ndef compute_rewards(\n   rew_scale_alive: float,\n   rew_scale_terminated: float,\n   rew_scale_pole_pos: float,\n   rew_scale_cart_vel: float,\n   rew_scale_pole_vel: float,\n   pole_pos: torch.Tensor,\n   pole_vel: torch.Tensor,\n   cart_pos: torch.Tensor,\n   cart_vel: torch.Tensor,\n   reset_terminated: torch.Tensor,\n):\n   rew_alive = rew_scale_alive * (1.0 - reset_terminated.float())\n   rew_termination = rew_scale_terminated * reset_terminated.float()\n   rew_pole_pos = rew_scale_pole_pos * torch.sum(torch.square(pole_pos), dim=-1)\n   rew_cart_vel = rew_scale_cart_vel * torch.sum(torch.abs(cart_vel), dim=-1)\n   rew_pole_vel = rew_scale_pole_vel * torch.sum(torch.abs(pole_vel), dim=-1)\n   total_reward = rew_alive + rew_termination + rew_pole_pos + rew_cart_vel + rew_pole_vel\n   return total_reward\n```\n\n----------------------------------------\n\nTITLE: Parsing and Merging CLI Arguments with AppLauncher - Python\nDESCRIPTION: This snippet demonstrates how to set up an argparse.ArgumentParser with both custom script-specific arguments (such as --size) and AppLauncher-provided arguments. The AppLauncher.add_app_launcher_args method is used to extend the parser with its own options, and then the parser processes command line input before being passed to the AppLauncher for simulation configuration. This modular argument handling pattern allows user, simulation, and AppLauncher options to coexist seamlessly.\n\nDependencies: Python (3.x), argparse, and the isaaclab.app module. The parser is expected to receive values for --size (custom float), as well as for --width and --height (forwarded to SimulationApp). Inputs are processed from sys.argv, and a Namespace object is passed to AppLauncher.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/launch_app.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\n\nparser = argparse.ArgumentParser(description=\"Tutorial on running IsaacSim via the AppLauncher.\")\nparser.add_argument(\"--size\", type=float, help=\"Side-length of cuboid\")\nparser.add_argument(\"--width\", type=int, default=1280, help=\"Width of the viewport and generated images. Defaults to 1280\")\nparser.add_argument(\"--height\", type=int, default=720, help=\"Height of the viewport and generated images. Defaults to 720\")\n\nimport isaaclab.app as app\nparser = app.AppLauncher.add_app_launcher_args(parser)\nargs = parser.parse_args()\napp_launcher = app.AppLauncher(args)\nsimulation_app = app_launcher.app\n```\n\n----------------------------------------\n\nTITLE: Running Multi-GPU Training with rl_games in Isaac Lab\nDESCRIPTION: Command to launch distributed RL training using rl_games across multiple GPUs on a single machine. The nproc_per_node parameter sets the number of GPUs to use for training the Isaac-Cartpole-v0 environment in headless mode.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython -m torch.distributed.run --nnodes=1 --nproc_per_node=2 scripts/reinforcement_learning/rl_games/train.py --task=Isaac-Cartpole-v0 --headless --distributed\n```\n\n----------------------------------------\n\nTITLE: Resetting Environments to Initial State\nDESCRIPTION: The _reset_idx method resets specified environments by setting random initial states for the cart and pole, including positions and velocities.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef _reset_idx(self, env_ids: torch.Tensor) -> None:\n    num_resets = len(env_ids)\n    if num_resets == 0:\n        return\n\n    # reset agent states\n    reset_joint_pos = torch.zeros(\n        (num_resets, self.articulation.num_dof), device=self.device, dtype=torch.float32\n    )\n    reset_joint_pos[:, self._pole_dof_idx[0]] = torch_random_float(\n        -self.cfg.initial_pole_angle_range[0],\n        self.cfg.initial_pole_angle_range[1],\n        (num_resets, 1),\n        device=self.device,\n    ).squeeze()\n\n    # set random states for the agents\n    indices = env_ids.to(dtype=torch.int32)\n    self.articulation.set_joint_positions(reset_joint_pos, indices=indices)\n    self.articulation.set_joint_velocities(\n        torch.zeros_like(reset_joint_pos, device=self.device), indices=indices\n    )\n    # bookkeeping\n    self.reset_terminated[env_ids] = 0\n    self.reset_time_out[env_ids] = 0\n    self.progress_buf[env_ids] = 0\n\n    # update buffers\n    self.joint_pos[env_ids] = reset_joint_pos\n    self.joint_vel[env_ids] = 0\n```\n\n----------------------------------------\n\nTITLE: Training and Playing with SKRL (PyTorch) on Isaac-Reach-Franka-v0 in Windows\nDESCRIPTION: Commands for installing SKRL with PyTorch, training an agent on the Isaac-Reach-Franka-v0 environment, playing trained models, and recording videos in Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_5\n\nLANGUAGE: batch\nCODE:\n```\n:: install python module (for skrl)\nisaaclab.bat -i skrl\n:: run script for training\nisaaclab.bat -p scripts\\reinforcement_learning\\skrl\\train.py --task Isaac-Reach-Franka-v0 --headless\n:: run script for playing with 32 environments\nisaaclab.bat -p scripts\\reinforcement_learning\\skrl\\play.py --task Isaac-Reach-Franka-v0 --num_envs 32 --checkpoint /PATH/TO/model.pt\n:: run script for playing a pre-trained checkpoint with 32 environments\nisaaclab.bat -p scripts\\reinforcement_learning\\skrl\\play.py --task Isaac-Reach-Franka-v0 --num_envs 32 --use_pretrained_checkpoint\n:: run script for recording video of a trained agent (requires installing `ffmpeg`)\nisaaclab.bat -p scripts\\reinforcement_learning\\skrl\\play.py --task Isaac-Reach-Franka-v0 --headless --video --video_length 200\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-Asset Rigid Objects in IsaacLab (Python)\nDESCRIPTION: This code snippet demonstrates how to configure a rigid object that can be a randomly selected shape (cone, cube, or sphere) in each environment instance, enabling diverse asset configuration across environments.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/multi_asset_spawning.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef make_asset_func(shape: str):\n    \"\"\"Creates a function that returns a primitive asset.\"\"\"\n\n    def _asset_func() -> PrimitiveAsset:\n        if shape == \"cone\":\n            return PrimitiveAsset(prim_type=\"Cone\", size=(0.1, 0.1, 0.1), color=(0.4, 0.4, 0.9))\n        elif shape == \"cube\":\n            return PrimitiveAsset(prim_type=\"Cube\", size=(0.1, 0.1, 0.1), color=(0.9, 0.4, 0.4))\n        elif shape == \"sphere\":\n            return PrimitiveAsset(prim_type=\"Sphere\", size=(0.05, 0.05, 0.05), color=(0.4, 0.9, 0.4))\n        else:\n            raise ValueError(f\"Unsupported shape: {shape}\")\n\n    return _asset_func\n\n\ndef make_random_pose_func(shape: str, rot_z_range: tuple):\n    \"\"\"Creates a function that returns a random pose.\"\"\"\n\n    def _pose_func(env_ids):\n        num_envs = len(env_ids)\n        pose = torch.zeros((num_envs, 7), dtype=torch.float32)\n        pose[:, 0] = get_x_position(shape)  # x\n        pose[:, 1] = get_y_position(shape)  # y\n        pose[:, 2] = 0.5  # z\n        # Set orientation: identity quaternion (w=1, xyz=0) with a random rotation around z\n        angle_z = torch.zeros(num_envs, dtype=torch.float32).uniform_(*rot_z_range)\n        quat_z = [torch.cos(angle_z / 2), torch.zeros_like(angle_z), torch.zeros_like(angle_z), torch.sin(angle_z / 2)]\n        pose[:, 3:7] = torch.stack(quat_z, dim=1)  # x, y, z, w (quaternion)\n        return pose\n\n    return _pose_func\n\n\n# Create a single rigid object whose asset is selected randomly from cone, cube, or sphere\nrigid_object_cfg = RigidObjectCfg(\n    prim_path=\"/World/envs/env_.*/RandomObject\",\n    spawn=MultiAssetSpawnerCfg(\n        configs=[\n            RigidObjectSpawnerCfg(\n                asset_func=make_asset_func(\"cone\"),\n                pose_func=make_random_pose_func(\"cone\", rot_z_range=(-np.pi, np.pi)),\n            ),\n            RigidObjectSpawnerCfg(\n                asset_func=make_asset_func(\"cube\"),\n                pose_func=make_random_pose_func(\"cube\", rot_z_range=(-np.pi, np.pi)),\n            ),\n            RigidObjectSpawnerCfg(\n                asset_func=make_asset_func(\"sphere\"),\n                pose_func=make_random_pose_func(\"sphere\", rot_z_range=(-np.pi, np.pi)),\n            ),\n        ],\n        random_choice=True,\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Updating Articulation State in Isaac Sim\nDESCRIPTION: Shows how to update the articulation's internal state buffer with the latest data from the simulation. This is necessary to read the current state of the articulation after the simulation step.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_articulation.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Update buffers\nrobot.update(sim_dt)\n```\n\n----------------------------------------\n\nTITLE: Configuring a Height Scanner Sensor in IsaacLab (Python)\nDESCRIPTION: This Python snippet shows a RayCasterCfg configuration for a virtual height scanner sensor using NVIDIA Warp ray-casting. The sensor is attached to the robot's base frame and set to project a grid pattern of rays, returning terrain heights under the robot. It attaches only by yaw (ignores roll/pitch) and is configured for debug visualization. The sensor's update frequency, raycasting targets, and hit pattern/spacing can be adjusted as needed; IsaacLab's sensors and patterns modules must be available.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/04_sensors/add_sensors_on_robot.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nheight_scanner = RayCasterCfg(\n    prim_path=\"{ENV_REGEX_NS}/Robot/base/height_scanner\",\n    update_period=0.05,   # 20 Hz\n    attach_yaw_only=True,\n    pattern=patterns.GridPatternCfg(\n        size=(0.5, 0.5),\n        resolution=(5, 5),\n        offset=(0.0, 0.0),\n    ),\n    debug_vis=True,  # Enable visualization of ray hits\n    mesh_regexs=[\"/World.*GroundPlane\"],  # Target meshes for raycasting\n)\n```\n\n----------------------------------------\n\nTITLE: Updating Rigid Object Simulation Data\nDESCRIPTION: Shows how to update simulation buffers and internal state of rigid objects during the simulation loop. Includes writing simulation data and updating object state.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_rigid_object.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# apply sim data\ncone_object.write_data_to_sim()\n\n# update buffers\ncone_object.update(sim_dt)\n```\n\n----------------------------------------\n\nTITLE: Configuring Domain Randomization in Isaac Lab\nDESCRIPTION: Demonstrates how to set up domain randomization using the configclass module and EventTerm variables. This includes randomizing physics materials, joint properties, and gravity.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass EventCfg:\n  robot_physics_material = EventTerm(\n      func=mdp.randomize_rigid_body_material,\n      mode=\"reset\",\n      params={\n          \"asset_cfg\": SceneEntityCfg(\"robot\", body_names=\".*\"),\n          \"static_friction_range\": (0.7, 1.3),\n          \"dynamic_friction_range\": (1.0, 1.0),\n          \"restitution_range\": (1.0, 1.0),\n          \"num_buckets\": 250,\n      },\n  )\n  robot_joint_stiffness_and_damping = EventTerm(\n      func=mdp.randomize_actuator_gains,\n      mode=\"reset\",\n      params={\n          \"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=\".*\"),\n          \"stiffness_distribution_params\": (0.75, 1.5),\n          \"damping_distribution_params\": (0.3, 3.0),\n          \"operation\": \"scale\",\n          \"distribution\": \"log_uniform\",\n      },\n  )\n  reset_gravity = EventTerm(\n      func=mdp.randomize_physics_scene_gravity,\n      mode=\"interval\",\n      is_global_time=True,\n      interval_range_s=(36.0, 36.0),  # time_s = num_steps * (decimation * dt)\n      params={\n          \"gravity_distribution_params\": ([0.0, 0.0, 0.0], [0.0, 0.0, 0.4]),\n          \"operation\": \"add\",\n          \"distribution\": \"gaussian\",\n      },\n  )\n```\n\n----------------------------------------\n\nTITLE: Converting MJCF to USD Format for Unitree H1 Humanoid Robot\nDESCRIPTION: This snippet shows how to clone the mujoco_menagerie repository and convert the Unitree H1 humanoid robot MJCF model to USD format. It uses the convert_mjcf.py utility with options to import sites and make the assets instanceable for better performance.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/import_new_asset.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# create a directory to clone\nmkdir ~/git && cd ~/git\n# clone a repository with URDF files\ngit clone git@github.com:google-deepmind/mujoco_menagerie.git\n\n# go to top of the Isaac Lab repository\ncd IsaacLab\n# run the converter\n./isaaclab.sh -p scripts/tools/convert_mjcf.py \\\n  ~/git/mujoco_menagerie/unitree_h1/h1.xml \\\n  source/isaaclab_assets/data/Robots/Unitree/h1.usd \\\n  --import-sites \\\n  --make-instanceable\n```\n\n----------------------------------------\n\nTITLE: Basic Python Pattern for Spawning Prims in Isaac Lab\nDESCRIPTION: Demonstrates the general pattern for creating configuration instances and spawning primitives in Isaac Lab, showing how to set up configurations and use spawner functions with transformation parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/spawn_prims.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Create a configuration class instance\ncfg = MyPrimCfg()\nprim_path = \"/path/to/prim\"\n\n# Spawn the prim into the scene using the corresponding spawner function\nspawn_my_prim(prim_path, cfg, translation=[0, 0, 0], orientation=[1, 0, 0, 0], scale=[1, 1, 1])\n# OR\n# Use the spawner function directly from the configuration class\ncfg.func(prim_path, cfg, translation=[0, 0, 0], orientation=[1, 0, 0, 0], scale=[1, 1, 1])\n```\n\n----------------------------------------\n\nTITLE: Configuring Frame Transformer Sensor in Python\nDESCRIPTION: Shows how to create and configure a Frame Transformer sensor by defining source frames and target frames using prim paths. This enables tracking of relative positions and orientations between rigid bodies in a physics simulation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/frame_transformer.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# specific frames\nscene.add(\n    FrameTransformer(\n        name=\"specific_transforms\",\n        frame_source=\"/World/envs/env_.*/Robot/base\",\n        frame_targets=[\"LF_FOOT\", \"RF_FOOT\"],\n        visualizer=FrameTransformerVisualizer(visible=True, arrow_scale=0.1),\n    )\n)\n\n# We can also use regex to select multiple object frames\nscene.add(\n    FrameTransformer(\n        name=\"robot_transforms\",\n        frame_source=\"/World/envs/env_.*/Robot/base\",\n        frame_targets=[\".*\"],  # all rigid bodies (including the source)\n        visualizer=FrameTransformerVisualizer(visible=False, arrow_scale=0.1),\n    )\n)\n\n# or we can reference a different object entirely. This is especially\n# useful for tracking cameras or end effectors\nscene.add(\n    FrameTransformer(\n        name=\"cube_transform\",\n        frame_source=\"/World/envs/env_.*/Robot/base\",\n        frame_targets=[\"/World/envs/env_.*/cube\"],\n        visualizer=FrameTransformerVisualizer(visible=True, arrow_scale=0.1),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Calculating Rewards for Cartpole in OmniIsaacGymEnvs and Isaac Lab\nDESCRIPTION: Shows the reward calculation for the cartpole environment. OmniIsaacGymEnvs uses a single method, while Isaac Lab separates the calculation into a main method and a JIT-compiled helper function for better performance.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef calculate_metrics(self) -> None:\n    reward = (1.0 - self.pole_pos * self.pole_pos\n        - 0.01 * torch.abs(self.cart_vel) - 0.005\n        * torch.abs(self.pole_vel))\n    reward = torch.where(\n        torch.abs(self.cart_pos) > self._reset_dist,\n        torch.ones_like(reward) * -2.0, reward)\n    reward = torch.where(\n        torch.abs(self.pole_pos) > np.pi / 2,\n        torch.ones_like(reward) * -2.0, reward)\n\n    self.rew_buf[:] = reward\n```\n\nLANGUAGE: python\nCODE:\n```\ndef _get_rewards(self) -> torch.Tensor:\n    total_reward = compute_rewards(\n        self.cfg.rew_scale_alive,\n        self.cfg.rew_scale_terminated,\n        self.cfg.rew_scale_pole_pos,\n        self.cfg.rew_scale_cart_vel,\n        self.cfg.rew_scale_pole_vel,\n        self.joint_pos[:, self._pole_dof_idx[0]],\n        self.joint_vel[:, self._pole_dof_idx[0]],\n        self.joint_pos[:, self._cart_dof_idx[0]],\n        self.joint_vel[:, self._cart_dof_idx[0]],\n        self.reset_terminated,\n    )\n    return total_reward\n\n@torch.jit.script\ndef compute_rewards(\n    rew_scale_alive: float,\n    rew_scale_terminated: float,\n    rew_scale_pole_pos: float,\n    rew_scale_cart_vel: float,\n    rew_scale_pole_vel: float,\n    pole_pos: torch.Tensor,\n    pole_vel: torch.Tensor,\n    cart_pos: torch.Tensor,\n    cart_vel: torch.Tensor,\n    reset_terminated: torch.Tensor,\n):\n    rew_alive = rew_scale_alive * (1.0 - reset_terminated.float())\n    rew_termination = rew_scale_terminated * reset_terminated.float()\n    rew_pole_pos = rew_scale_pole_pos * torch.sum(\n        torch.square(pole_pos), dim=-1)\n    rew_cart_vel = rew_scale_cart_vel * torch.sum(\n        torch.abs(cart_vel), dim=-1)\n    rew_pole_vel = rew_scale_pole_vel * torch.sum(\n        torch.abs(pole_vel), dim=-1)\n    total_reward = (rew_alive + rew_termination\n        + rew_pole_pos + rew_cart_vel + rew_pole_vel)\n    return total_reward\n```\n\n----------------------------------------\n\nTITLE: Running Multi-GPU Training with skrl and PyTorch in Isaac Lab\nDESCRIPTION: Command to launch distributed RL training using skrl library with PyTorch backend across multiple GPUs on a single machine. The nproc_per_node parameter sets the number of GPUs to use for training the Isaac-Cartpole-v0 environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npython -m torch.distributed.run --nnodes=1 --nproc_per_node=2 scripts/reinforcement_learning/skrl/train.py --task=Isaac-Cartpole-v0 --headless --distributed\n```\n\n----------------------------------------\n\nTITLE: Handling Isaac Sim Events with Weak References in Python\nDESCRIPTION: This Python snippet demonstrates how to correctly subscribe to an Isaac Sim post-update event stream within a class. It uses `weakref.proxy` in the lambda function to pass a weak reference of the class instance (`self`) to the callback, preventing reference cycles and allowing the object to be garbage collected. The `__del__` method ensures the subscription is explicitly unsubscribed when the object is destroyed, preventing potential issues.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n            self._handle = app_interface.get_post_update_event_stream().create_subscription_to_pop(\n                lambda event, obj=weakref.proxy(self): obj.on_event_callback(event)\n            )\n\n        def __del__(self):\n            self._handle.unsubscribe()\n            self._handle = None\n\n        def on_event_callback(self, event):\n            # do something with the message\n```\n\n----------------------------------------\n\nTITLE: Scene Setup in Isaac Lab CartPole Implementation\nDESCRIPTION: Implements scene setup using the Cloner API in Isaac Lab, which simplifies environment replication. Articulation configuration is defined declaratively using configuration objects rather than procedural code, reducing boilerplate.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ndef _setup_scene(self):\n    self.cartpole = Articulation(self.cfg.robot_cfg)\n    # add ground plane\n    spawn_ground_plane(prim_path=\"/World/ground\",\n        cfg=GroundPlaneCfg())\n    # clone, filter, and replicate\n    self.scene.clone_environments(\n        copy_from_source=False)\n    self.scene.filter_collisions(\n        global_prim_paths=[])\n    # add articulation to scene\n    self.scene.articulations[\"cartpole\"] = self.cartpole\n    # add lights\n    light_cfg = sim_utils.DomeLightCfg(\n        intensity=2000.0, color=(0.75, 0.75, 0.75))\n    light_cfg.func(\"/World/Light\", light_cfg)\n\nCARTPOLE_CFG = ArticulationCfg(\n    spawn=sim_utils.UsdFileCfg(\n        usd_path=f\"{ISAACLAB_NUCLEUS_DIR}/.../cartpole.usd\",\n        rigid_props=sim_utils.RigidBodyPropertiesCfg(\n            rigid_body_enabled=True,\n            max_linear_velocity=1000.0,\n            max_angular_velocity=1000.0,\n            max_depenetration_velocity=100.0,\n            enable_gyroscopic_forces=True,\n        ),\n        articulation_props=sim_utils.ArticulationRootPropertiesCfg(\n            enabled_self_collisions=False,\n            solver_position_iteration_count=4,\n            solver_velocity_iteration_count=0,\n            sleep_threshold=0.005,\n            stabilization_threshold=0.001,\n        ),\n    ),\n    init_state=ArticulationCfg.InitialStateCfg(\n        pos=(0.0, 0.0, 2.0),\n        joint_pos={\"slider_to_cart\": 0.0, \"cart_to_pole\": 0.0}\n    ),\n    actuators={\n        \"cart_actuator\": ImplicitActuatorCfg(\n            joint_names_expr=[\"slider_to_cart\"],\n            effort_limit=400.0,\n            velocity_limit=100.0,\n            stiffness=0.0,\n            damping=10.0,\n```\n\n----------------------------------------\n\nTITLE: Training and Playing with RSL-RL on Isaac-Reach-Franka-v0 in Windows\nDESCRIPTION: Commands for installing RSL-RL, training an agent on the Isaac-Reach-Franka-v0 environment, playing trained models, and recording videos in Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_3\n\nLANGUAGE: batch\nCODE:\n```\n:: install python module (for rsl-rl)\nisaaclab.bat -i rsl_rl\n:: run script for training\nisaaclab.bat -p scripts\\reinforcement_learning\\rsl_rl\\train.py --task Isaac-Reach-Franka-v0 --headless\n:: run script for playing with 32 environments\nisaaclab.bat -p scripts\\reinforcement_learning\\rsl_rl\\play.py --task Isaac-Reach-Franka-v0 --num_envs 32 --load_run run_folder_name --checkpoint model.pt\n:: run script for playing a pre-trained checkpoint with 32 environments\nisaaclab.bat -p scripts\\reinforcement_learning\\rsl_rl\\play.py --task Isaac-Reach-Franka-v0 --num_envs 32 --use_pretrained_checkpoint\n:: run script for recording video of a trained agent (requires installing `ffmpeg`)\nisaaclab.bat -p scripts\\reinforcement_learning\\rsl_rl\\play.py --task Isaac-Reach-Franka-v0 --headless --video --video_length 200\n```\n\n----------------------------------------\n\nTITLE: Computing Termination Conditions for RL Episodes\nDESCRIPTION: The _get_dones method determines when episodes should terminate based on cart position, pole angle, and episode length, setting flags for different termination reasons.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef _get_dones(self) -> tuple[torch.Tensor, torch.Tensor]:\n    # fall when pole is almost upside down\n    self.reset_terminated = torch.where(\n        torch.abs(self.joint_pos[:, self._pole_dof_idx[0]]) > math.pi / 2,\n        torch.ones_like(self.reset_buf),\n        torch.zeros_like(self.reset_buf),\n    )\n    # fall if the cart is beyong a certain threshold\n    self.reset_terminated = torch.where(\n        torch.abs(self.joint_pos[:, self._cart_dof_idx[0]]) > self.cfg.max_cart_pos,\n        torch.ones_like(self.reset_buf),\n        self.reset_terminated,\n    )\n    # reached max episode length\n    self.reset_time_out = torch.where(\n        self.progress_buf >= self.cfg.episode_length - 1,\n        torch.ones_like(self.reset_buf),\n        torch.zeros_like(self.reset_buf),\n    )\n    # create overall reset signal\n    self.reset_buf = torch.logical_or(self.reset_terminated, self.reset_time_out).to(torch.int8)\n    return self.reset_buf, self.reset_time_out\n```\n\n----------------------------------------\n\nTITLE: Defining Scene Configuration with InteractiveSceneCfg in isaaclab (Python)\nDESCRIPTION: Defines a custom CartpoleSceneCfg class inheriting from InteractiveSceneCfg to systematically configure interactive and non-interactive prims for the simulation. Dependencies include isaaclab's scene and assets modules, requiring InteractiveSceneCfg, AssetBaseCfg, and ArticulationCfg classes. Configuration variables, serving as keys, specify the prim paths and configuration of ground plane, light source, and cartpole entities, facilitating scalable scene composition. Key parameters specify prim paths with ENV_REGEX_NS for duplicating assets per environment. Inputs are configuration details; the output is an organized scene setup. Limitations depend on correct key/path specification and compatibility of config classes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/02_scene/create_scene.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass CartpoleSceneCfg(InteractiveSceneCfg):\n    # Configuration for the ground plane\n    ground_plane = AssetBaseCfg(\n        prim_path=\"/World/defaultGroundPlane\"\n    )\n    # Configuration for the light source\n    light = AssetBaseCfg(\n        prim_path=\"/World/Light\"\n    )\n    # Configuration for the cartpole articulation\n    cartpole = ArticulationCfg(\n        prim_path=\"{ENV_REGEX_NS}/Robot\",\n        # additional cartpole parameters...\n    )\n```\n\n----------------------------------------\n\nTITLE: Setting Desired End-Effector Pose for IK Control\nDESCRIPTION: Sets the target end-effector pose command for the differential IK controller. The poses are specified in the robot's base frame, and the controller is reset before setting new commands.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_diff_ik.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# reset controller\ndiff_ik_controller.reset()\n# set desired ee pose\nee_pos_des_b = poses_b[pose_index, :, :3]\nee_quat_des_b = poses_b[pose_index, :, 3:7]\n# set command to the controller\nik_commands = torch.cat([ee_pos_des_b, ee_quat_des_b], dim=-1)\ndiff_ik_controller.set_command(ik_commands)\n```\n\n----------------------------------------\n\nTITLE: Configuring an Articulated Robot in Python\nDESCRIPTION: Demonstrates how to configure an articulated robot using ArticulationCfg in Isaac Lab, including USD file path, rigid body properties, articulation properties, initial states, and actuator configurations.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.actuators import ImplicitActuatorCfg\nfrom isaaclab.assets import ArticulationCfg\n\nCARTPOLE_CFG = ArticulationCfg(\n    spawn=sim_utils.UsdFileCfg(\n        usd_path=f\"{ISAACLAB_NUCLEUS_DIR}/Robots/Classic/Cartpole/cartpole.usd\",\n        rigid_props=sim_utils.RigidBodyPropertiesCfg(\n            rigid_body_enabled=True,\n            max_linear_velocity=1000.0,\n            max_angular_velocity=1000.0,\n            max_depenetration_velocity=100.0,\n            enable_gyroscopic_forces=True,\n        ),\n        articulation_props=sim_utils.ArticulationRootPropertiesCfg(\n            enabled_self_collisions=False,\n            solver_position_iteration_count=4,\n            solver_velocity_iteration_count=0,\n            sleep_threshold=0.005,\n            stabilization_threshold=0.001,\n        ),\n    ),\n    init_state=ArticulationCfg.InitialStateCfg(\n        pos=(0.0, 0.0, 2.0), joint_pos={\"slider_to_cart\": 0.0, \"cart_to_pole\": 0.0}\n    ),\n    actuators={\n        \"cart_actuator\": ImplicitActuatorCfg(\n            joint_names_expr=[\"slider_to_cart\"],\n            effort_limit=400.0,\n            velocity_limit=100.0,\n            stiffness=0.0,\n            damping=10.0,\n        ),\n        \"pole_actuator\": ImplicitActuatorCfg(\n            joint_names_expr=[\"cart_to_pole\"], effort_limit=400.0, velocity_limit=100.0, stiffness=0.0, damping=0.0\n        ),\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Converting OBJ Mesh to Instanceable USD Asset with Physics Properties using convert_mesh.py\nDESCRIPTION: This bash script demonstrates how to clone a repository with mesh files and use the convert_mesh.py tool to transform an OBJ file into an instanceable USD asset. The example includes setting collision properties and mass for the asset, which enables physics simulation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/import_new_asset.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# create a directory to clone\nmkdir ~/git && cd ~/git\n# clone a repository with URDF files\ngit clone git@github.com:NVIDIA-Omniverse/IsaacGymEnvs.git\n\n# go to top of the Isaac Lab repository\ncd IsaacLab\n# run the converter\n./isaaclab.sh -p scripts/tools/convert_mesh.py \\\n  ~/git/IsaacGymEnvs/assets/trifinger/objects/meshes/cube_multicolor.obj \\\n  source/isaaclab_assets/data/Props/CubeMultiColor/cube_multicolor.usd \\\n  --make-instanceable \\\n  --collision-approximation convexDecomposition \\\n  --mass 1.0\n```\n\n----------------------------------------\n\nTITLE: Getting Done States in Isaac Lab\nDESCRIPTION: Function that determines whether environments are done in Isaac Lab. It checks if episodes have timed out or if the cart or pole positions have exceeded their bounds, returning both conditions as tensors.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_28\n\nLANGUAGE: python\nCODE:\n```\ndef _get_dones(self) -> tuple[torch.Tensor, torch.Tensor]:\n    self.joint_pos = self.cartpole.data.joint_pos\n    self.joint_vel = self.cartpole.data.joint_vel\n\n    time_out = self.episode_length_buf >= self.max_episode_length - 1\n    out_of_bounds = torch.any(torch.abs(\n        self.joint_pos[:, self._cart_dof_idx]) > self.cfg.max_cart_pos,\n        dim=1)\n    out_of_bounds = out_of_bounds | torch.any(\n        torch.abs(self.joint_pos[:, self._pole_dof_idx]) > math.pi / 2,\n        dim=1)\n    return out_of_bounds, time_out\n```\n\n----------------------------------------\n\nTITLE: Dones and Reset Logic Implementation\nDESCRIPTION: Demonstrates the different approaches to handling done conditions and resets between frameworks. IsaacLab separates done conditions into resets and timeouts, with automatic episode length handling.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ndef is_done(self) -> None:\n  resets = torch.where(\n    torch.abs(self.cart_pos) > self._reset_dist, 1, 0)\n  resets = torch.where(\n    torch.abs(self.pole_pos) > math.pi / 2, 1, resets)\n  resets = torch.where(\n    self.progress_buf >= self._max_episode_length, 1, resets)\n  self.reset_buf[:] = resets\n\ndef reset_idx(self, env_ids):\n  num_resets = len(env_ids)\n\n  # randomize DOF positions\n  dof_pos = torch.zeros((num_resets, self._cartpoles.num_dof),\n      device=self._device)\n  dof_pos[:, self._cart_dof_idx] = 1.0 * (\n      1.0 - 2.0 * torch.rand(num_resets, device=self._device))\n  dof_pos[:, self._pole_dof_idx] = 0.125 * math.pi * (\n      1.0 - 2.0 * torch.rand(num_resets, device=self._device))\n```\n\nLANGUAGE: python\nCODE:\n```\ndef _get_dones(self) -> tuple[torch.Tensor, torch.Tensor]:\n    self.joint_pos = self.cartpole.data.joint_pos\n    self.joint_vel = self.cartpole.data.joint_vel\n\n    time_out = self.episode_length_buf >= self.max_episode_length - 1\n    out_of_bounds = torch.any(torch.abs(\n        self.joint_pos[:, self._cart_dof_idx]) > self.cfg.max_cart_pos,\n        dim=1)\n    out_of_bounds = out_of_bounds | torch.any(\n        torch.abs(self.joint_pos[:, self._pole_dof_idx]) > math.pi / 2,\n        dim=1)\n    return out_of_bounds, time_out\n\ndef _reset_idx(self, env_ids: Sequence[int] | None):\n    if env_ids is None:\n        env_ids = self.cartpole._ALL_INDICES\n    super()._reset_idx(env_ids)\n\n    joint_pos = self.cartpole.data.default_joint_pos[env_ids]\n    joint_pos[:, self._pole_dof_idx] += sample_uniform(\n        self.cfg.initial_pole_angle_range[0] * math.pi,\n        self.cfg.initial_pole_angle_range[1] * math.pi,\n        joint_pos[:, self._pole_dof_idx].shape,\n        joint_pos.device,\n    )\n    joint_vel = self.cartpole.data.default_joint_vel[env_ids]\n\n    default_root_state = self.cartpole.data.default_root_state[env_ids]\n```\n\n----------------------------------------\n\nTITLE: Accessing and Printing Sensor Data in IsaacLab (Python)\nDESCRIPTION: This snippet demonstrates how to retrieve data from the configured sensors via their data attributes and print out summaries to the console. It accesses RGB camera images, height scanner height arrays, and the maximum contact force (using PyTorch operations). This requires that the simulation has run and sensor observations are up-to-date. The scene object must index sensors by their configuration names (e.g., 'camera', 'height_scanner', 'contact_forces').\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/04_sensors/add_sensors_on_robot.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# print information from the sensors\nprint(\"Received RGB camera image shape: \", scene[\"camera\"].data.rgb.shape)\nprint(\"Received height array: \", scene[\"height_scanner\"].data.heights)\nprint(\"Received max contact force of: \", torch.max(scene[\"contact_forces\"].data.net_forces_w).item())\n```\n\n----------------------------------------\n\nTITLE: Defining Reward Configuration for Cartpole Task (Manager-Based)\nDESCRIPTION: This class defines the reward configuration for the Cartpole environment using the manager-based approach. It specifies individual reward terms, their functions, weights, and parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/task_workflows.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass RewardsCfg(RewardsConfig):\n    # Define reward terms\n    position: RewardTerm = RewardTerm(\n        func=\"compute_position_reward\",\n        weight=1.0,\n        params=dict(clip=[-1.0, 1.0], offset=0.0, scale=1.0),\n    )\n    orientation: RewardTerm = RewardTerm(\n        func=\"compute_orientation_reward\",\n        weight=1.0,\n        params=dict(clip=[-1.0, 1.0], offset=0.0, scale=1.0),\n    )\n    effort: RewardTerm = RewardTerm(\n        func=\"compute_effort_reward\",\n        weight=-0.01,\n        params=dict(clip=[-1.0, 0.0], offset=0.0, scale=1.0),\n    )\n```\n\n----------------------------------------\n\nTITLE: Synchronizing Deformable Object Data to Simulation in IsaacLab (Python)\nDESCRIPTION: This snippet writes internal data maintained by the deformable object instance into the simulation engine. While it does not apply external forces, this action ensures all in-memory state changes are fully synchronized with the simulated object. Method requires the DeformableObject instance to be set up and its state initialized.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_deformable_object.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# write internal data to simulation\ncube_object.write_data_to_sim()\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating Stable-Baselines3 Agents in Isaac Lab (Linux)\nDESCRIPTION: Provides a sequence of bash commands using `isaaclab.sh` for Linux users. It covers installing the `sb3` module, training an agent on the CPU for the `Isaac-Cartpole-v0` task, playing back a trained agent from a specific checkpoint or using a default pre-trained one, and recording agent gameplay as a video (requires `ffmpeg`). Training is explicitly set to CPU as SB3 may not offer significant GPU optimization for this case.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# install python module (for stable-baselines3)\n./isaaclab.sh -i sb3\n# run script for training\n# note: we set the device to cpu since SB3 doesn't optimize for GPU anyway\n./isaaclab.sh -p scripts/reinforcement_learning/sb3/train.py --task Isaac-Cartpole-v0 --headless --device cpu\n# run script for playing with 32 environments\n./isaaclab.sh -p scripts/reinforcement_learning/sb3/play.py --task Isaac-Cartpole-v0 --num_envs 32 --checkpoint /PATH/TO/model.zip\n# run script for playing a pre-trained checkpoint with 32 environments\n./isaaclab.sh -p scripts/reinforcement_learning/sb3/play.py --task Isaac-Cartpole-v0 --num_envs 32 --use_pretrained_checkpoint\n# run script for recording video of a trained agent (requires installing `ffmpeg`)\n./isaaclab.sh -p scripts/reinforcement_learning/sb3/play.py --task Isaac-Cartpole-v0 --headless --video --video_length 200\n```\n\n----------------------------------------\n\nTITLE: Initializing Environment Scene in IsaacGymEnvs vs Isaac Lab (Python)\nDESCRIPTION: Compares the legacy and new approaches for environment scene creation in Isaac frameworks. In IsaacGymEnvs, 'create_sim' manually sets up the simulation and adds plane and actors before environment creation via looping. In Isaac Lab, manual sim object creation is replaced by '_setup_scene', which leverages internal context management to manage physics simulation, ground plane, actor instantiation, environmental cloning, filtering, and lighting in a structured way. Major dependencies: numpy, Articulation, GroundPlaneCfg, sim_utils. Inputs: class instances, config objects; Outputs: initialized environment ready for simulation and RL tasks.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef create_sim(self):\n  # set the up axis to be z-up\n  self.up_axis = self.cfg[\"sim\"][\"up_axis\"]\n  self.sim = super().create_sim(self.device_id, self.graphics_device_id,\n                                 self.physics_engine, self.sim_params)\n  self._create_ground_plane()\n  self._create_envs(self.num_envs, self.cfg[\"env\"]['envSpacing'],\n                    int(np.sqrt(self.num_envs)))\n```\n\nLANGUAGE: python\nCODE:\n```\ndef _setup_scene(self):\n  self.cartpole = Articulation(self.cfg.robot_cfg)\n  # add ground plane\n  spawn_ground_plane(prim_path=\"/World/ground\", cfg=GroundPlaneCfg())\n  # clone, filter, and replicate\n  self.scene.clone_environments(copy_from_source=False)\n  self.scene.filter_collisions(global_prim_paths=[])\n  # add articulation to scene\n  self.scene.articulations[\"cartpole\"] = self.cartpole\n  # add lights\n  light_cfg = sim_utils.DomeLightCfg(intensity=2000.0)\n  light_cfg.func(\"/World/Light\", light_cfg)\n```\n\n----------------------------------------\n\nTITLE: Creating a Terrain Using TerrainImporterCfg in Python\nDESCRIPTION: Demonstrates how to create a more sophisticated ground plane using the TerrainImporterCfg class in Isaac Lab, including physics material configuration.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.terrains import TerrainImporterCfg\n\nterrain = TerrainImporterCfg(\n     prim_path=\"/World/ground\",\n     terrain_type=\"plane\",\n     collision_group=-1,\n     physics_material=sim_utils.RigidBodyMaterialCfg(\n         friction_combine_mode=\"multiply\",\n         restitution_combine_mode=\"multiply\",\n         static_friction=1.0,\n         dynamic_friction=1.0,\n         restitution=0.0,\n     ),\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Multi-USD Articulation in IsaacLab (Python)\nDESCRIPTION: This code demonstrates how to set up an articulation that randomly selects between different USD robot models (ANYmal-C or ANYmal-D) for each environment, enabling diverse robot configurations in the simulation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/multi_asset_spawning.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create an articulation whose USD file is selected randomly from anymal_c or anymal_d robots\narticulation_cfg = ArticulationCfg(\n    prim_path=\"/World/envs/env_.*/Robot\",\n    spawn=MultiUsdFileCfg(\n        configs=[\n            UsdFileCfg(\n                usd_path=\"omniverse://localhost/NVIDIA/Assets/Isaac/2023.1.1/Isaac/Robots/ANYbotics/anymal_c.usd\",\n                rigid_props=RigidBodyProperties(\n                    disable_gravity=False,\n                    retain_acceleration=False,\n                    linear_damping=0.0,\n                    angular_damping=0.0,\n                    max_linear_velocity=1000.0,\n                    max_angular_velocity=1000.0,\n                    max_depenetration_velocity=1.0,\n                    disable_spatial_accelerations=True,\n                ),\n            ),\n            UsdFileCfg(\n                usd_path=\"omniverse://localhost/NVIDIA/Assets/Isaac/2023.1.1/Isaac/Robots/ANYbotics/anymal_d.usd\",\n                rigid_props=RigidBodyProperties(\n                    disable_gravity=False,\n                    retain_acceleration=False,\n                    linear_damping=0.0,\n                    angular_damping=0.0,\n                    max_linear_velocity=1000.0,\n                    max_angular_velocity=1000.0,\n                    max_depenetration_velocity=1.0,\n                    disable_spatial_accelerations=True,\n                ),\n            ),\n        ],\n        random_choice=True,\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Termination Criteria for Cartpole RL Environment in Python\nDESCRIPTION: Specifies conditions for episode termination including maximum episode length and cart position bounds. Uses TerminationsCfg to define termination terms and their parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_rl_env.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass TerminationsCfg:\n    \"\"\"Termination terms for the cartpole environment.\"\"\"\n\n    # list all termination terms\n    termination_terms = dict(\n        time=TerminationTermCfg(\n            time_out=True,\n        ),\n        cart_pos=TerminationTermCfg(\n            term_fn=AbsValueFiniteCriterion,\n            params=dict(vals=None, threshold=3.0),\n            time_out=False,\n        ),\n    )\n```\n\n----------------------------------------\n\nTITLE: Importing a USD Asset into Isaac Lab with Python\nDESCRIPTION: Demonstrates how to import a pre-built USD asset (a table) into the scene using the UsdFileCfg class. This allows for referencing external USD files rather than building objects from primitive shapes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/spawn_prims.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# spawn a usd file of a table into the scene\nusd_path = os.path.join(\"/isaac-sim/exts/omni.isaac.assets\", \"isaac\", \"props\", \"table\", \"table.usd\")\ncfg = sim.spawners.UsdFileCfg()\ncfg.usd_path = usd_path\ncfg.func(\"/World/Objects/Table\", cfg, translation=(0.0, 0.0, 1.05))\n```\n\n----------------------------------------\n\nTITLE: Configuring Visualization Markers in Python\nDESCRIPTION: Demonstrates the configuration of different marker prototypes including cones, spheres, frames, and arrows. Shows how to set up marker properties and paths using VisualizationMarkersCfg.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/draw_markers.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nmarker_cfg = VisualizationMarkersCfg(\n    prim_path=\"/scene/markers\",\n    markers={\n        \"cone\": SpawnCfg(\n            scale=(0.1, 0.1, 0.2),\n            color=(1.0, 0.0, 0.0),\n            shape=SpawnShape.CONE,\n        ),\n        \"sphere\": SpawnCfg(\n            scale=(0.1, 0.1, 0.1),\n            color=(0.0, 1.0, 0.0),\n            shape=SpawnShape.SPHERE,\n        ),\n        \"frame\": SpawnCfg(\n            scale=(0.2, 0.2, 0.2),\n            usd_path=lab_path(\"assets/isaac_assets/isaac_assets/Props/UIElements/frame.usd\"),\n        ),\n        \"arrow_x\": SpawnCfg(\n            scale=(0.2, 0.2, 0.2),\n            usd_path=lab_path(\"assets/isaac_assets/isaac_assets/Props/UIElements/arrow.usd\"),\n            color=(1.0, 0.0, 0.0),\n        ),\n        \"arrow_y\": SpawnCfg(\n            scale=(0.2, 0.2, 0.2),\n            usd_path=lab_path(\"assets/isaac_assets/isaac_assets/Props/UIElements/arrow.usd\"),\n            color=(0.0, 1.0, 0.0),\n            orientation=(0.0, 0.0, 0.7071068, 0.7071068),\n        ),\n        \"arrow_z\": SpawnCfg(\n            scale=(0.2, 0.2, 0.2),\n            usd_path=lab_path(\"assets/isaac_assets/isaac_assets/Props/UIElements/arrow.usd\"),\n            color=(0.0, 0.0, 1.0),\n            orientation=(0.0, -0.7071068, 0.0, 0.7071068),\n        ),\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Contact Sensors for Anymal Quadruped Feet\nDESCRIPTION: This snippet shows the initialization of contact sensors for an Anymal Quadruped robot's feet in two different ways: independent sensors for front feet with specific filtering, and a single sensor with multiple bodies for hind feet.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/contact_sensor.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef run_simulator(sim: sim_utils.SimulationContext, scene: InteractiveScene):\n    .\n    .\n    .\n```\n\n----------------------------------------\n\nTITLE: Training a Robot Dog with Reinforcement Learning (Linux)\nDESCRIPTION: This command runs a predefined workflow to train a robot dog (Anymal C) to navigate rough terrain using reinforcement learning in Isaac Lab on Linux. The --headless flag is recommended for faster training.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Velocity-Rough-Anymal-C-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Master Node Command for Multi-Node Training with rsl_rl\nDESCRIPTION: Command for the master node when running RL training with RSL-RL across multiple machines. Specifies rendezvous settings including ID, backend, and endpoint to coordinate training across nodes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\npython -m torch.distributed.run --nproc_per_node=2 --nnodes=2 --node_rank=0 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=localhost:5555 scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --headless --distributed\n```\n\n----------------------------------------\n\nTITLE: AppLauncher Initialization Methods in Python\nDESCRIPTION: Demonstrates different ways to initialize the AppLauncher class using argparse, keyword arguments, dictionaries, or default settings.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/api/lab/isaaclab.app.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport argparser\n\nfrom isaaclab.app import AppLauncher\n\n# add argparse arguments\nparser = argparse.ArgumentParser()\n# add your own arguments\n# ....\n# add app launcher arguments for cli\nAppLauncher.add_app_launcher_args(parser)\n# parse arguments\nargs = parser.parse_args()\n\n# launch omniverse isaac-sim app\n# -- Option 1: Pass the settings as a Namespace object\napp_launcher = AppLauncher(args).app\n# -- Option 2: Pass the settings as keywords arguments\napp_launcher = AppLauncher(headless=args.headless, livestream=args.livestream)\n# -- Option 3: Pass the settings as a dictionary\napp_launcher = AppLauncher(vars(args))\n# -- Option 4: Pass no settings\napp_launcher = AppLauncher()\n\n# obtain the launched app\nsimulation_app = app_launcher.app\n```\n\n----------------------------------------\n\nTITLE: Writing Deformable Object Nodal State and Resetting Buffers in IsaacLab (Python)\nDESCRIPTION: This snippet writes the current nodal state of a deformable object into the simulation and resets all kinematic targets and internal buffers. It leverages the write_nodal_state_to_sim and reset methods to ensure the simulation accurately reflects the object's new initial state. These methods are dependent on the correct configuration of the DeformableObject instance.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_deformable_object.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# write nodal state to simulation\ncube_object.write_nodal_state_to_sim(nodal_state)\ncube_object.write_nodal_kinematic_target_to_sim(None)\ncube_object.reset()\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating Stable-Baselines3 Agents in Isaac Lab (Windows)\nDESCRIPTION: Provides a sequence of batch commands using `isaaclab.bat` for Windows users. It covers installing the `sb3` module, training an agent on the CPU for the `Isaac-Cartpole-v0` task, playing back a trained agent from a specific checkpoint (`.zip` file) or using a default pre-trained one, and recording agent gameplay as a video (requires `ffmpeg`). Training is explicitly set to CPU as SB3 may not offer significant GPU optimization for this case.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_11\n\nLANGUAGE: batch\nCODE:\n```\n:: install python module (for stable-baselines3)\nisaaclab.bat -i sb3\n:: run script for training\n:: note: we set the device to cpu since SB3 doesn't optimize for GPU anyway\nisaaclab.bat -p scripts\\reinforcement_learning\\sb3\\train.py --task Isaac-Cartpole-v0 --headless --device cpu\n:: run script for playing with 32 environments\nisaaclab.bat -p scripts\\reinforcement_learning\\sb3\\play.py --task Isaac-Cartpole-v0 --num_envs 32 --checkpoint /PATH/TO/model.zip\n:: run script for playing a pre-trained checkpoint with 32 environments\nisaaclab.bat -p scripts\\reinforcement_learning\\sb3\\play.py --task Isaac-Cartpole-v0 --num_envs 32 --use_pretrained_checkpoint\n:: run script for recording video of a trained agent (requires installing `ffmpeg`)\nisaaclab.bat -p scripts\\reinforcement_learning\\sb3\\play.py --task Isaac-Cartpole-v0 --headless --video --video_length 200\n```\n\n----------------------------------------\n\nTITLE: Querying Ray Caster Sensor Data in Python\nDESCRIPTION: This code snippet shows how to query and print data from the Ray Caster sensor during simulation runtime. It demonstrates accessing the sensor's data attribute to retrieve hit results.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/ray_caster.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef run_simulator(sim: sim_utils.SimulationContext, scene: InteractiveScene):\n    .\n    .\n    .\n    # Simulate physics\n    while simulation_app.is_running():\n      .\n      .\n      .\n      # print information from the sensors\n        print(\"-------------------------------\")\n        print(scene[\"ray_caster\"])\n        print(\"Ray cast hit results: \", scene[\"ray_caster\"].data.ray_hits_w)\n```\n\n----------------------------------------\n\nTITLE: Defining Resource-Wrapped Jobs in Python\nDESCRIPTION: This script defines the core functionality for resource-wrapped aggregate jobs in Isaac Lab. It allows manual definition of sub-jobs and their resource requirements, enabling resource isolation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef wrap_resources(cfg):\n    \"\"\"Wrap resources for a job.\n\n    Args:\n        cfg (DictConfig): The configuration object.\n\n    Returns:\n        dict: A dictionary containing the wrapped resources.\n    \"\"\"\n    num_gpus = cfg.get(\"num_gpus\", 1)\n    num_cpus = cfg.get(\"num_cpus\", 1)\n    memory = cfg.get(\"memory\", None)\n\n    @ray.remote(num_gpus=num_gpus, num_cpus=num_cpus, memory=memory)\n    def wrapped_job(cfg, job_id):\n        \"\"\"The wrapped job function.\n\n        Args:\n            cfg (DictConfig): The configuration object.\n            job_id (int): The job ID.\n\n        Returns:\n            Any: The result of the job execution.\n        \"\"\"\n        return execute_job(cfg, job_id)\n\n    return wrapped_job\n```\n\n----------------------------------------\n\nTITLE: Defining Spawn Configuration for Cartpole in Isaac Lab\nDESCRIPTION: This snippet shows how to configure a Cartpole articulation asset using UsdFileCfg. It specifies the USD file path, rigid properties for the articulation's root, and articulation properties for all links.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/write_articulation_cfg.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nspawn_config=UsdFileCfg(\n    usd_path=\"${ISAACLAB_ASSETS_PATH}/isaaclab_assets/robots/usd/cartpole.usd\",\n    rigid_props=RigidBodyProperties(\n        solver_position_iteration_count=4,\n        solver_velocity_iteration_count=0,\n        max_angular_velocity=1000.0,\n        max_linear_velocity=1000.0,\n        max_depenetration_velocity=5.0,\n        disable_gravity=False,\n    ),\n    articulation_props=ArticulationRootProperties(\n        solver_position_iteration_count=4,\n        solver_velocity_iteration_count=1,\n        sleep_threshold=0.005,\n        stabilization_threshold=0.001,\n        enable_self_collisions=True,\n        self_collision_filter_mode=FilterMode.BLOCK_NULL_FILTER,\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Retrieving IMU Sensor Data in Isaac Lab Simulation\nDESCRIPTION: This code snippet shows how to retrieve and print IMU sensor data within a simulation loop. It extracts linear velocity, angular velocity, linear acceleration, and angular acceleration from two different IMU sensors attached to robot feet.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/imu.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef run_simulator(sim: sim_utils.SimulationContext, scene: InteractiveScene):\n    .\n    .\n    .\n    # Simulate physics\n    while simulation_app.is_running():\n      .\n      .\n      .\n      # print information from the sensors\n      print(\"-------------------------------\")\n      print(scene[\"imu_LF\"])\n      print(\"Received linear velocity: \", scene[\"imu_LF\"].data.lin_vel_b)\n      print(\"Received angular velocity: \", scene[\"imu_LF\"].data.ang_vel_b)\n      print(\"Received linear acceleration: \", scene[\"imu_LF\"].data.lin_acc_b)\n      print(\"Received angular acceleration: \", scene[\"imu_LF\"].data.ang_acc_b)\n      print(\"-------------------------------\")\n      print(scene[\"imu_RF\"])\n      print(\"Received linear velocity: \", scene[\"imu_RF\"].data.lin_vel_b)\n      print(\"Received angular velocity: \", scene[\"imu_RF\"].data.ang_vel_b)\n      print(\"Received linear acceleration: \", scene[\"imu_RF\"].data.lin_acc_b)\n      print(\"Received angular acceleration: \", scene[\"imu_RF\"].data.ang_acc_b)\n```\n\n----------------------------------------\n\nTITLE: Running the Cartpole Environment Simulation in Python\nDESCRIPTION: This main function illustrates how to instantiate the environment from the configuration, reset it, and run a simulation loop that applies random actions. It captures the simplified workflow of using the ManagerBasedEnv class.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_base_env.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef main():\n    # Create the environment configuration\n    env_cfg = CartpoleEnvCfg()\n\n    # Create an environment with the specified number of environments\n    with torch.inference_mode():\n        env = ManagerBasedEnv(env_cfg)\n\n        # Reset the environment -- Get observations and info\n        obs, info = env.reset()\n        print(f\"Observation space: {obs.shape}\")\n\n        # Simulate for a fixed number of steps\n        max_steps = 1000\n        steps = 0\n        while steps < max_steps:\n            # Get random actions from the action space\n            actions = torch.rand(env.scene.num_envs, 1, device=env.device) * 2.0 - 1.0\n\n            # Step the environment -- Get observations and info\n            obs, info = env.step(actions)\n\n            # Render the environment (default cameras)\n            env.render()\n\n            # Increase step count\n            steps += 1\n\n            # Reset every 100 steps\n            if steps % 100 == 0:\n                obs, info = env.reset()\n```\n\n----------------------------------------\n\nTITLE: Initializing Cartpole Environment in Isaac Sim\nDESCRIPTION: This snippet sets up the cartpole environment, creates actors, and configures their properties. It includes environment creation, actor placement, and DOF property setup.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nself.num_dof = self.gym.get_asset_dof_count(cartpole_asset)\n\npose = gymapi.Transform()\nif self.up_axis == 'z':\n    pose.p.z = 2.0\n    pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)\nelse:\n    pose.p.y = 2.0\n    pose.r = gymapi.Quat(-np.sqrt(2)/2, 0.0, 0.0, np.sqrt(2)/2)\n\nself.cartpole_handles = []\nself.envs = []\nfor i in range(self.num_envs):\n    # create env instance\n    env_ptr = self.gym.create_env(self.sim, lower, upper, num_per_row)\n    cartpole_handle = self.gym.create_actor(env_ptr, cartpole_asset, pose, \"cartpole\", i, 1, 0)\n\n    dof_props = self.gym.get_actor_dof_properties(env_ptr, cartpole_handle)\n    dof_props['driveMode'][0] = gymapi.DOF_MODE_EFFORT\n    dof_props['driveMode'][1] = gymapi.DOF_MODE_NONE\n    dof_props['stiffness'][:] = 0.0\n    dof_props['damping'][:] = 0.0\n    self.gym.set_actor_dof_properties(env_ptr, cartpole_handle, dof_props)\n\n    self.envs.append(env_ptr)\n    self.cartpole_handles.append(cartpole_handle)\n```\n\n----------------------------------------\n\nTITLE: Resetting Deformable Object State in IsaacLab using Python\nDESCRIPTION: This snippet resets the nodal state of a deformable object by transforming its node positions using position and orientation values. The reset is performed by updating the simulation buffer with new nodal state information, ensuring the deformable object begins at randomized initial positions. Dependencies include the assets.DeformableObject class, and the primary inputs are position (pos_w) and quaternion (quat_w) for transformation purposes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_deformable_object.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# reset the nodal state of the object\nnodal_state[..., :3] = cube_object.transform_nodal_pos(nodal_state[..., :3], pos_w, quat_w)\n```\n\n----------------------------------------\n\nTITLE: Configuring Action and Observation Noise Models in Python\nDESCRIPTION: This snippet shows how to add action and observation noise models to a task configuration. It uses NoiseModelWithAdditiveBiasCfg to add Gaussian noise and bias to both actions and observations.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass MyTaskConfig:\n\n    # at every time-step add gaussian noise + bias. The bias is a gaussian sampled at reset\n    action_noise_model: NoiseModelWithAdditiveBiasCfg = NoiseModelWithAdditiveBiasCfg(\n      noise_cfg=GaussianNoiseCfg(mean=0.0, std=0.05, operation=\"add\"),\n      bias_noise_cfg=GaussianNoiseCfg(mean=0.0, std=0.015, operation=\"abs\"),\n    )\n\n    # at every time-step add gaussian noise + bias. The bias is a gaussian sampled at reset\n    observation_noise_model: NoiseModelWithAdditiveBiasCfg = NoiseModelWithAdditiveBiasCfg(\n      noise_cfg=GaussianNoiseCfg(mean=0.0, std=0.002, operation=\"add\"),\n      bias_noise_cfg=GaussianNoiseCfg(mean=0.0, std=0.0001, operation=\"abs\"),\n    )\n```\n\n----------------------------------------\n\nTITLE: Joint Torque Control Implementation\nDESCRIPTION: Direct torque control implementation where input actions are set as feed-forward joint torque commands.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/motion_generators.rst#2025-04-23_snippet_0\n\nLANGUAGE: math\nCODE:\n```\n\\tau = \\tau_{des}\n```\n\n----------------------------------------\n\nTITLE: Packaging and Writing Camera Data with Replicator\nDESCRIPTION: Packages converted camera data into a format suitable for the Replicator BasicWriter and writes it to disk. This organizes the data into a dictionary structure that matches Replicator's expected format.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/save_camera_output.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Pack data back into replicator format to save them using its writer\nrep_output = {\n    \"rgb\": {\"data\": single_cam_rgb},\n    \"semantic_segmentation\": {\"data\": single_cam_semantic},\n    \"instance_segmentation\": {\"data\": single_cam_instance},\n    \"distance\": {\"data\": single_cam_distance},\n    \"normals\": {\"data\": single_cam_normals},\n}\nrep_writer.write(rep_output)\n```\n\n----------------------------------------\n\nTITLE: Running Isaac Lab Tasks Remotely - Bash\nDESCRIPTION: This snippet launches Isaac Lab with a specific training script and task argument on a cloud-hosted Linux desktop. It assumes the user is already connected to the cloud instance and has access to the 'isaaclab.sh' launcher script and necessary Python environments.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py --task=Isaac-Cartpole-v0\n```\n\n----------------------------------------\n\nTITLE: Initializing and Playing Simulation in IsaacLab (Python)\nDESCRIPTION: This snippet initiates the physics simulator and resets it to ensure that all buffers and sensor handles are properly allocated before the simulation loop. This is critical in IsaacLab: sensors and physics setups only allocate their internal structures after sim.reset() is called. Invoking sim.reset() after scene creation is necessary for correct initialization; prerequisite is a properly constructed sim object and scene.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/04_sensors/add_sensors_on_robot.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Play the simulator\nsim.play()\nsim.reset()\n```\n\n----------------------------------------\n\nTITLE: Getting Observations in Isaac Lab\nDESCRIPTION: Function to get observations for CartPole environments in Isaac Lab. It concatenates the pole and cart positions and velocities into a single tensor and returns a dictionary with the 'policy' key for consumption by the RL policy.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_31\n\nLANGUAGE: python\nCODE:\n```\ndef _get_observations(self) -> dict:\n    obs = torch.cat(\n        (\n            self.joint_pos[:, self._pole_dof_idx[0]],\n            self.joint_vel[:, self._pole_dof_idx[0]],\n            self.joint_pos[:, self._cart_dof_idx[0]],\n            self.joint_vel[:, self._cart_dof_idx[0]],\n        ),\n        dim=-1,\n    )\n    observations = {\"policy\": obs}\n    return observations\n```\n\n----------------------------------------\n\nTITLE: Pre-Physics Step Implementation Comparison\nDESCRIPTION: Shows the difference between OmniIsaacGymEnvs and IsaacLab pre-physics step handling. IsaacLab separates action processing and application into two methods for better flexibility.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndef pre_physics_step(self, actions) -> None:\n    if not self.world.is_playing():\n        return\n\n    reset_env_ids = self.reset_buf.nonzero(\n        as_tuple=False).squeeze(-1)\n    if len(reset_env_ids) > 0:\n        self.reset_idx(reset_env_ids)\n\n    actions = actions.to(self._device)\n\n    forces = torch.zeros((self._cartpoles.count,\n        self._cartpoles.num_dof),\n        dtype=torch.float32, device=self._device)\n    forces[:, self._cart_dof_idx] =\n        self._max_push_effort * actions[:, 0]\n\n    indices = torch.arange(self._cartpoles.count,\n        dtype=torch.int32, device=self._device)\n    self._cartpoles.set_joint_efforts(\n        forces, indices=indices)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef _pre_physics_step(self,\n        actions: torch.Tensor) -> None:\n    self.actions = self.action_scale * actions\n\ndef _apply_action(self) -> None:\n    self.cartpole.set_joint_effort_target(\n        self.actions, joint_ids=self._cart_dof_idx)\n```\n\n----------------------------------------\n\nTITLE: Configuring Actuators for Cartpole with Separate Actuator Models\nDESCRIPTION: This snippet shows how to configure actuators for a Cartpole, using separate actuator models for each joint. It demonstrates using ImplicitActuatorCfg with different settings for the cart_to_pole and slider_to_cart joints.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/write_articulation_cfg.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nactuators={\n    \"slider_actuator\": ImplicitActuatorCfg(\n        joint_names_expr=[\"slider_to_cart\"],\n        effort_limit=400.0,\n        velocity_limit=100.0,\n        stiffness=0.0,\n        damping=10.0,\n    ),\n    \"hinge_actuator\": ImplicitActuatorCfg(\n        joint_names_expr=[\"cart_to_pole\"],\n        effort_limit=400.0,\n        velocity_limit=100.0,\n    ),\n},\n```\n\n----------------------------------------\n\nTITLE: Writing Joint State Data with Indexed Assignment - IsaacGymEnvs vs. Isaac Lab - Python\nDESCRIPTION: These paired snippets showcase how indexed assignment of joint state is performed in IsaacGymEnvs and Isaac Lab. The IsaacGymEnvs side casts env_ids to int32 and uses set_dof_state_tensor_indexed after careful unwrapping, whereas Isaac Lab provides a direct method write_joint_state_to_sim that takes joint position, joint velocity, joint IDs, and environment IDs as inputs. This pattern reduces error-prone manual buffer manipulations and leverages direct tensor operations enabled by the Isaac Lab API.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nenv_ids_int32 = env_ids.to(dtype=torch.int32)\nself.gym.set_dof_state_tensor_indexed(self.sim,\n    gymtorch.unwrap_tensor(self.dof_state),\n    gymtorch.unwrap_tensor(env_ids_int32), len(env_ids_int32))\n```\n\nLANGUAGE: python\nCODE:\n```\nself._robot.write_joint_state_to_sim(joint_pos, joint_vel, \n                                   joint_ids, env_ids)\n```\n\n----------------------------------------\n\nTITLE: Defining Action Configuration for Cartpole Control in Python\nDESCRIPTION: This code defines an ActionsCfg class that configures how actions are processed in the cartpole environment. It sets up a single action term that controls the force applied to the cart using the JointEffort controller.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_base_env.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass ActionsCfg(ManagerBasedEnvCfg.ActionsCfg):\n    \"\"\"Configuration for actions.\"\"\"\n\n    def __post_init__(self):\n        \"\"\"Initialize action terms.\"\"\"\n        # Add a joint effort controller that controls the force applied to the cart\n        self.joint_effort = JointEffortActionCfg(\n            # Reference: Used to get a reference to the asset path\n            asset_name=\"cartpole\",\n            # Parameters: Control all joints (this is configurable) using the range [-1, 1]\n            joint_names=[\"slider_to_cart\"],\n            scale=10.0,\n        )\n```\n\n----------------------------------------\n\nTITLE: Submitting Aggregate Jobs to Ray Clusters in Python\nDESCRIPTION: This script provides functionality to submit aggregate jobs to one or more Ray clusters. It can be used for running jobs on remote clusters or simultaneous jobs with heterogeneous resource requirements.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef submit_job(job_cfg, cluster_cfg):\n    \"\"\"Submit a job to a Ray cluster.\n\n    Args:\n        job_cfg (dict): The job configuration.\n        cluster_cfg (dict): The cluster configuration.\n\n    Returns:\n        ObjectRef: A reference to the submitted job.\n    \"\"\"\n    # Set up Ray client connection\n    ray.init(address=cluster_cfg['address'])\n\n    # Create a remote function for the job\n    @ray.remote\n    def remote_job(cfg):\n        return execute_job(cfg)\n\n    # Submit the job\n    job_ref = remote_job.remote(job_cfg)\n\n    return job_ref\n```\n\n----------------------------------------\n\nTITLE: Worker Node Command for Multi-Node Training with skrl and JAX\nDESCRIPTION: Command for non-master (worker) nodes when running RL training with skrl using JAX backend across multiple machines. Connects to the coordinator on the master node using the specified address.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\npython -m skrl.utils.distributed.jax --nproc_per_node=2 --nnodes=2 --node_rank=1 --coordinator_address=ip_of_master_machine:5555 scripts/reinforcement_learning/skrl/train.py --task=Isaac-Cartpole-v0 --headless --distributed --ml_framework jax\n```\n\n----------------------------------------\n\nTITLE: Adding Events Configuration to Task Class in Python\nDESCRIPTION: This code demonstrates how to add the EventCfg to a task configuration class using the configclass decorator. It sets up the events attribute for domain randomization.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass MyTaskConfig:\n  events: EventCfg = EventCfg()\n```\n\n----------------------------------------\n\nTITLE: Converting and Saving Camera Images with BasicWriter\nDESCRIPTION: Processes camera data by converting PyTorch tensors to NumPy arrays, then saves the images using Replicator's BasicWriter. This handles RGB images, segmentation maps, depth data, and normals.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/save_camera_output.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Save images from camera at camera_index\nsingle_cam_rgb = camera.data.output[\"rgb\"][camera_index].cpu().numpy()\nsingle_cam_distance = camera.data.output[\"distance_to_image_plane\"][camera_index].cpu().numpy()\nsingle_cam_normals = camera.data.output[\"normals\"][camera_index].cpu().numpy()\nsingle_cam_semantic = camera.data.output[\"semantic_segmentation\"][camera_index].cpu().numpy()\nsingle_cam_instance = camera.data.output[\"instance_segmentation\"][camera_index].cpu().numpy()\nsingle_cam_info = camera.data.info[camera_index]\n```\n\n----------------------------------------\n\nTITLE: Running RL Training with Video Recording in Isaac Lab\nDESCRIPTION: This command demonstrates how to launch a reinforcement learning training session with video recording enabled. It specifies a Cartpole task, runs in headless mode, and configures video recording with a length of 100 steps and an interval of 500 steps between recordings.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/record_video.rst#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython scripts/reinforcement_learning/rl_games/train.py --task=Isaac-Cartpole-v0 --headless --video --video_length 100 --video_interval 500\n```\n\n----------------------------------------\n\nTITLE: Adjusting Observation and Action Spaces for H1 Robot\nDESCRIPTION: Code snippet demonstrating how to modify the observation and action space dimensions to match the H1 robot's joint configuration.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/modify_direct_rl_env.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# observation and action spaces\nobs_dim = 102 + 102 + 24 * 2  # history * num_bodies * 6 + history * prev_obs + action\naction_dim = 24  # num_dof\n```\n\n----------------------------------------\n\nTITLE: Launching IsaacSim with AppLauncher & Environment Variables - Console\nDESCRIPTION: This console command illustrates launching an IsaacSim simulation with the AppLauncher wrapper while using an environment variable (LIVESTREAM) and custom CLI arguments. The environmental variable LIVESTREAM is set to 2 to force livestreaming, and the script is executed with a specific cuboid size. This demonstrates the precedence and interaction between environment variables and CLI arguments.\n\nPrerequisites: IsaacLab must be correctly installed with the isaaclab.sh script available. The environment variable sets the livestream policy; CLI flags control the cuboid size. The simulation proceeds in headless mode determined by the LIVESTREAM envar.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/launch_app.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nLIVESTREAM=2 ./isaaclab.sh -p scripts/tutorials/00_sim/launch_app.py --size 0.5\n```\n\n----------------------------------------\n\nTITLE: Running Multi-GPU Training with rsl_rl in Isaac Lab\nDESCRIPTION: Command to launch distributed RL training using RSL-RL across multiple GPUs on a single machine. The nproc_per_node parameter sets the number of GPUs to use for training the Isaac-Cartpole-v0 environment in headless mode.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npython -m torch.distributed.run --nnodes=1 --nproc_per_node=2 scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --headless --distributed\n```\n\n----------------------------------------\n\nTITLE: Configuring a Camera Sensor in IsaacLab (Python)\nDESCRIPTION: This Python snippet creates a CameraCfg instance for an RGB-D camera sensor attached to the robot's head in the simulation. The configuration specifies the USD camera spawn type, sensor offset, and the data types (e.g., RGB, depth) to capture. The update period is set to 0.1s (10 Hz), and the prim path determines its attachment point within the robot's scene graph. To use this, the IsaacLab Python API and its sensors submodule must be installed.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/04_sensors/add_sensors_on_robot.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ncamera = CameraCfg(\n    prim_path=\"{ENV_REGEX_NS}/Robot/base/front_cam\",\n    update_period=0.1,  # 10 Hz\n    offset=CameraCfg.OffsetCfg(\n        translation=(0.35, 0.0, 0.25),\n        rotation=(0, 0, 0, 1),  # Quaternion xyzw\n        convention=\"ros\"\n    ),\n    data_types=[\"rgb\", \"distance_to_image_plane\", \"normals\"],\n    spawn=sim.spawners.sensors.PinholeCameraCfg(\n        width=640,\n        height=480,\n        fov=90.0,\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Training and Playing with RSL-RL on Isaac-Reach-Franka-v0 in Linux\nDESCRIPTION: Commands for installing RSL-RL, training an agent on the Isaac-Reach-Franka-v0 environment, playing trained models, and recording videos in Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# install python module (for rsl-rl)\n./isaaclab.sh -i rsl_rl\n# run script for training\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task Isaac-Reach-Franka-v0 --headless\n# run script for playing with 32 environments\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Reach-Franka-v0 --num_envs 32 --load_run run_folder_name --checkpoint model.pt\n# run script for playing a pre-trained checkpoint with 32 environments\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Reach-Franka-v0 --num_envs 32 --use_pretrained_checkpoint\n# run script for recording video of a trained agent (requires installing `ffmpeg`)\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Reach-Franka-v0 --headless --video --video_length 200\n```\n\n----------------------------------------\n\nTITLE: Computing Joint Positions with Differential IK\nDESCRIPTION: Computes desired joint positions using differential inverse kinematics. The method requires the current end-effector pose, Jacobian matrix, and joint positions as inputs. These values are obtained from the robot's data and converted to the appropriate reference frames.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_diff_ik.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# obtain quantities from simulation\n# -- read data from simulation\nscene.update()\n# -- read current joint positions\njoint_pos = franka_data.joint_pos[:, arm_joint_ids]\n# -- read current ee pose (in world frame)\nee_pos_w = franka_data.body_state_w[:, ee_body_id, 0:3]\nee_quat_w = franka_data.body_state_w[:, ee_body_id, 3:7]\n# -- convert to base frame\nrobot_pos_w = franka_data.root_state_w[:, 0:3]\nrobot_quat_w = franka_data.root_state_w[:, 3:7]\n# -- end-effector pose in base frame\nee_pos_b = transform_utils.transform_points(ee_pos_w, robot_pos_w, robot_quat_w, direction=\"to-local\")\nee_quat_b = transform_utils.transform_quats(ee_quat_w, robot_quat_w, direction=\"to-local\")\n# -- read jacobian\njacobian = franka_data.jacobians[:, arm_joint_ids, ee_body_id, :]\n# -- compute desired joint positions\njoint_pos_des = diff_ik_controller.compute(ee_pos_b, ee_quat_b, jacobian, joint_pos)\n```\n\n----------------------------------------\n\nTITLE: Configuring Action and Observation Noise in Isaac Lab\nDESCRIPTION: Demonstrates how to set up action and observation noise models using NoiseModelWithAdditiveBiasCfg in the task configuration.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_27\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass MyTaskConfig:\n    # at every time-step add gaussian noise + bias. The bias is a gaussian sampled at reset\n    action_noise_model: NoiseModelWithAdditiveBiasCfg = NoiseModelWithAdditiveBiasCfg(\n      noise_cfg=GaussianNoiseCfg(mean=0.0, std=0.05, operation=\"add\"),\n      bias_noise_cfg=GaussianNoiseCfg(mean=0.0, std=0.015, operation=\"abs\"),\n    )\n    # at every time-step add gaussian noise + bias. The bias is a gaussian sampled at reset\n    observation_noise_model: NoiseModelWithAdditiveBiasCfg = NoiseModelWithAdditiveBiasCfg(\n      noise_cfg=GaussianNoiseCfg(mean=0.0, std=0.002, operation=\"add\"),\n      bias_noise_cfg=GaussianNoiseCfg(mean=0.0, std=0.0001, operation=\"abs\"),\n    )\n```\n\n----------------------------------------\n\nTITLE: Unprojecting Depth Images to 3D Space in PyTorch\nDESCRIPTION: Demonstrates how to convert depth images into 3D point clouds in camera coordinates, then transform them to world coordinates. This uses PyTorch operations for efficient computation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/save_camera_output.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.utils.math import transform_points, unproject_depth\n\n# Pointcloud in world frame\npoints_3d_cam = unproject_depth(\n   camera.data.output[\"distance_to_image_plane\"], camera.data.intrinsic_matrices\n)\n\npoints_3d_world = transform_points(points_3d_cam, camera.data.pos_w, camera.data.quat_w_ros)\n```\n\n----------------------------------------\n\nTITLE: Running Procedural Terrain Demo in Isaac Lab\nDESCRIPTION: Commands to create and spawn procedurally generated terrains with different configurations. This demo showcases terrain generation capabilities in Isaac Lab.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/showroom.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/procedural_terrain.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\demos\\procedural_terrain.py\n```\n\n----------------------------------------\n\nTITLE: Defining Basic Omniverse Extension Class in Python\nDESCRIPTION: Demonstrates the implementation of an Omniverse extension class that inherits from omni.ext.IExt. This class defines the fundamental lifecycle methods that are called when an extension is loaded or unloaded.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/developer-guide/development.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport omni.ext\n\nclass MyExt(omni.ext.IExt):\n   \"\"\"My extension application.\"\"\"\n\n   def on_startup(self, ext_id):\n      \"\"\"Called when the extension is loaded.\"\"\"\n      pass\n\n   def on_shutdown(self):\n      \"\"\"Called when the extension is unloaded.\n\n      It releases all references to the extension and cleans up any resources.\n      \"\"\"\n      pass\n```\n\n----------------------------------------\n\nTITLE: Running skrl MAPPO Agent in Isaac Lab (Windows)\nDESCRIPTION: Executes the `play.py` script using `isaaclab.bat` to run a pre-trained MAPPO agent from the skrl library on the `Isaac-Shadow-Hand-Over-Direct-v0` task. It specifies the number of environments (32) and requires the path to the model checkpoint (`.pt` file). This command is intended for Windows systems.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_9\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\reinforcement_learning\\skrl\\play.py --task Isaac-Shadow-Hand-Over-Direct-v0 --num_envs 32 --algorithm MAPPO --checkpoint /PATH/TO/model.pt\n```\n\n----------------------------------------\n\nTITLE: Initializing Cartpole Environment in Isaac Lab\nDESCRIPTION: Shows the updated class structure and initialization for a Cartpole environment in Isaac Lab, with simplified setup and direct access to joint data.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nclass CartpoleEnv(DirectRLEnv):\n    cfg: CartpoleEnvCfg\n    def __init__(self, cfg: CartpoleEnvCfg, render_mode: str | None = None, **kwargs):\n        super().__init__(cfg, render_mode, **kwargs)\n\n        self._cart_dof_idx, _ = self.cartpole.find_joints(self.cfg.cart_dof_name)\n        self._pole_dof_idx, _ = self.cartpole.find_joints(self.cfg.pole_dof_name)\n        self.action_scale=self.cfg.action_scale\n\n        self.joint_pos = self.cartpole.data.joint_pos\n        self.joint_vel = self.cartpole.data.joint_vel\n```\n\n----------------------------------------\n\nTITLE: Defining Cartpole Depth Camera Environment Configuration\nDESCRIPTION: Python code snippet showing the CartpoleDepthCameraEnvCfg class definition, including camera and observation space parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/hydra.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass CartpoleDepthCameraEnvCfg(CartpoleEnvCfg):\n    tiled_camera: TiledCameraCfg = TiledCameraCfg()\n    observation_space: Union[List[int], Tuple[int, ...]] = (80, 80, 1)\n\n    def __post_init__(self):\n        super().__post_init__()\n        self.tiled_camera.height = self.observation_space[0]\n        self.tiled_camera.width = self.observation_space[1]\n```\n\n----------------------------------------\n\nTITLE: Post-Physics Step in IsaacGymEnvs\nDESCRIPTION: This function handles post-physics step operations in IsaacGymEnvs, including progress tracking, environment resets, and computation of observations and rewards.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndef post_physics_step(self):\n    self.progress_buf += 1\n\n    env_ids = self.reset_buf.nonzero(as_tuple=False).squeeze(-1)\n    if len(env_ids) > 0:\n        self.reset_idx(env_ids)\n\n    self.compute_observations()\n    self.compute_reward()\n```\n\n----------------------------------------\n\nTITLE: Setting OSC Command for Robot Control\nDESCRIPTION: This code snippet shows how to set the operational space controller command with the properly formatted command vector, end-effector pose, and task frame pose. It demonstrates the final step in the command pipeline.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_osc.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# set the osc command\nosc.set_command(\n    command=command,\n    current_ee_pose_b=ee_pose_b,\n    current_task_frame_pose_b=task_frame_pose_b,\n)\n\n# compute the joint efforts\njoint_efforts = osc.compute_joint_efforts()\n```\n\n----------------------------------------\n\nTITLE: Training and Playing with SKRL (PyTorch) on Isaac-Reach-Franka-v0 in Linux\nDESCRIPTION: Commands for installing SKRL with PyTorch, training an agent on the Isaac-Reach-Franka-v0 environment, playing trained models, and recording videos in Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# install python module (for skrl)\n./isaaclab.sh -i skrl\n# run script for training\n./isaaclab.sh -p scripts/reinforcement_learning/skrl/train.py --task Isaac-Reach-Franka-v0 --headless\n# run script for playing with 32 environments\n./isaaclab.sh -p scripts/reinforcement_learning/skrl/play.py --task Isaac-Reach-Franka-v0 --num_envs 32 --checkpoint /PATH/TO/model.pt\n# run script for playing a pre-trained checkpoint with 32 environments\n./isaaclab.sh -p scripts/reinforcement_learning/skrl/play.py --task Isaac-Reach-Franka-v0 --num_envs 32 --use_pretrained_checkpoint\n# run script for recording video of a trained agent (requires installing `ffmpeg`)\n./isaaclab.sh -p scripts/reinforcement_learning/skrl/play.py --task Isaac-Reach-Franka-v0 --headless --video --video_length 200\n```\n\n----------------------------------------\n\nTITLE: Isaac Lab CartPole Joint State Access\nDESCRIPTION: Shows how joint position and velocity data is accessed in the Isaac Lab implementation of CartPole. This simplifies state tracking compared to the tensor manipulation in IsaacGymEnvs.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nself.action_scale = self.cfg.action_scale\n\nself.joint_pos = self.cartpole.data.joint_pos\nself.joint_vel = self.cartpole.data.joint_vel\n```\n\n----------------------------------------\n\nTITLE: Applying IK-Computed Joint Actions to Robot\nDESCRIPTION: Applies the computed desired joint positions to the robot using a joint position controller. The computed joint commands are written to the robot's joint position targets and the scene data is synchronized with the simulation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_diff_ik.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# apply actions\nfranka_data.joint_pos_target[:, arm_joint_ids] = joint_pos_des\n# -- write data to simulation\nscene.write_data_to_sim()\n```\n\n----------------------------------------\n\nTITLE: Applying Commands to Articulation Joints in Isaac Sim\nDESCRIPTION: Code that demonstrates how to control an articulation with joint effort commands. Shows the process of setting joint targets and writing the data to the simulation buffer. Uses random commands to move the cart-pole randomly.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_articulation.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Apply random action\njoint_efforts = 2.0 * torch.rand(robot.num_dof, device=self.sim.device) - 1.0\n# Scale the efforts to reasonable values\njoint_efforts *= torch.tensor([20.0, 1.0], device=self.sim.device)\n# set the target to current\nrobot.set_joint_effort_target(joint_efforts)\n# Apply the target to simulation\nrobot.write_data_to_sim()\n```\n\n----------------------------------------\n\nTITLE: Initializing Articulation and RigidObject Assets for State Access - Python\nDESCRIPTION: This snippet illustrates the initialization of articulate and rigid object assets (robot, cabinet, and generic object) by instantiating Articulation or RigidObject with their respective configuration. It is a prerequisite for accessing or writing simulation states in Isaac Lab, eliminating the need for raw body handle management. The dependencies are the asset configuration objects available from self.cfg, and the expected outcome is the instantiation of asset instances ready for state operations.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nself._robot = Articulation(self.cfg.robot)\nself._cabinet = Articulation(self.cfg.cabinet)\nself._object = RigidObject(self.cfg.object_cfg)\n```\n\n----------------------------------------\n\nTITLE: Extracting KubeRay Cluster Information in Python\nDESCRIPTION: This script extracts KubeRay cluster information for aggregate job submission using the kubectl command-line tool.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef get_cluster_info():\n    \"\"\"Get KubeRay cluster information.\n\n    Returns:\n        dict: A dictionary containing cluster information.\n    \"\"\"\n    # Run kubectl command to get cluster info\n    result = subprocess.run(['kubectl', 'get', 'rayclusters', '-o', 'json'], capture_output=True, text=True)\n    cluster_info = json.loads(result.stdout)\n\n    # Extract relevant information\n    clusters = []\n    for item in cluster_info['items']:\n        cluster = {\n            'name': item['metadata']['name'],\n            'namespace': item['metadata']['namespace'],\n            'status': item['status']['phase']\n        }\n        clusters.append(cluster)\n\n    return clusters\n```\n\n----------------------------------------\n\nTITLE: Testing Ray Cluster Operation and GPU Visibility (Bash)\nDESCRIPTION: Executes the `submit_job.py` script with specific arguments (`--aggregate_jobs wrap_resources.py --test`) to verify that the Ray cluster is operational and that NVIDIA GPUs are correctly detected and accessible by Ray workers.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n# Test that NVIDIA GPUs are visible and that Ray is operation with the following command:\npython3 scripts/reinforcement_learning/ray/submit_job.py --aggregate_jobs wrap_resources.py --test\n```\n\n----------------------------------------\n\nTITLE: Comparing Simulation Configuration between OmniIsaacGymEnvs and Isaac Lab\nDESCRIPTION: Side-by-side comparison of simulation configuration syntax between OmniIsaacGymEnvs (YAML format) and Isaac Lab (Python configclass format). Shows the mapping of physics parameters and GPU buffer settings between the two frameworks.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# OmniIsaacGymEnvs\nsim:\n\ndt: 0.0083 # 1/120 s\nuse_gpu_pipeline: ${eq:${...pipeline},\"gpu\"}\nuse_fabric: True\nenable_scene_query_support: False\ndisable_contact_processing: False\ngravity: [0.0, 0.0, -9.81]\n\ndefault_physics_material:\nstatic_friction: 1.0\ndynamic_friction: 1.0\nrestitution: 0.0\n\nphysx:\nworker_thread_count: ${....num_threads}\nsolver_type: ${....solver_type}\nuse_gpu: ${contains:\"cuda\",${....sim_device}}\nsolver_position_iteration_count: 4\nsolver_velocity_iteration_count: 0\ncontact_offset: 0.02\nrest_offset: 0.001\nbounce_threshold_velocity: 0.2\nfriction_offset_threshold: 0.04\nfriction_correlation_distance: 0.025\nenable_sleeping: True\nenable_stabilization: True\nmax_depenetration_velocity: 100.0\n\ngpu_max_rigid_contact_count: 524288\ngpu_max_rigid_patch_count: 81920\ngpu_found_lost_pairs_capacity: 1024\ngpu_found_lost_aggregate_pairs_capacity: 262144\ngpu_total_aggregate_pairs_capacity: 1024\ngpu_heap_capacity: 67108864\ngpu_temp_buffer_capacity: 16777216\ngpu_max_num_partitions: 8\ngpu_max_soft_body_contacts: 1048576\ngpu_max_particle_contacts: 1048576\n```\n\nLANGUAGE: python\nCODE:\n```\n# IsaacLab\nsim: SimulationCfg = SimulationCfg(\ndevice = \"cuda:0\" # can be \"cpu\", \"cuda\", \"cuda:<device_id>\"\ndt=1 / 120,\n# use_gpu_pipeline is deduced from the device\nuse_fabric=True,\nenable_scene_query_support=False,\n\ngravity=(0.0, 0.0, -9.81),\n\nphysics_material=RigidBodyMaterialCfg(\nstatic_friction=1.0,\ndynamic_friction=1.0,\nrestitution=0.0\n)\nphysx: PhysxCfg = PhysxCfg(\n# worker_thread_count is no longer needed\nsolver_type=1,\n# use_gpu is deduced from the device\nmax_position_iteration_count=4,\nmax_velocity_iteration_count=0,\n# moved to actor config\n# moved to actor config\nbounce_threshold_velocity=0.2,\nfriction_offset_threshold=0.04,\nfriction_correlation_distance=0.025,\n# enable_sleeping is no longer needed\nenable_stabilization=True,\n# moved to RigidBodyPropertiesCfg\n\ngpu_max_rigid_contact_count=2**23,\ngpu_max_rigid_patch_count=5 * 2**15,\ngpu_found_lost_pairs_capacity=2**21,\ngpu_found_lost_aggregate_pairs_capacity=2**25,\ngpu_total_aggregate_pairs_capacity=2**21,\ngpu_heap_capacity=2**26,\ngpu_temp_buffer_capacity=2**24,\ngpu_max_num_partitions=8,\ngpu_max_soft_body_contacts=2**20,\ngpu_max_particle_contacts=2**20,\n)\n)\n```\n\n----------------------------------------\n\nTITLE: Required Task Configuration Parameters in Isaac Lab\nDESCRIPTION: A code snippet showing the required parameters that must be set for each environment configuration in Isaac Lab, including decimation, episode length, and dimensionality of action, observation, and state spaces.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndecimation = 2\nepisode_length_s = 5.0\naction_space = 1\nobservation_space = 4\nstate_space = 0\n```\n\n----------------------------------------\n\nTITLE: Computing Observations in IsaacGymEnvs\nDESCRIPTION: Function to compute observations for CartPole environments in IsaacGymEnvs. It refreshes the DOF state tensor and fills the observation buffer with the current state of the cart and pole positions and velocities.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_30\n\nLANGUAGE: python\nCODE:\n```\ndef compute_observations(self, env_ids=None):\n    if env_ids is None:\n        env_ids = np.arange(self.num_envs)\n\n    self.gym.refresh_dof_state_tensor(self.sim)\n\n    self.obs_buf[env_ids, 0] = self.dof_pos[env_ids, 0]\n    self.obs_buf[env_ids, 1] = self.dof_vel[env_ids, 0]\n    self.obs_buf[env_ids, 2] = self.dof_pos[env_ids, 1]\n    self.obs_buf[env_ids, 3] = self.dof_vel[env_ids, 1]\n\n    return self.obs_buf\n```\n\n----------------------------------------\n\nTITLE: Implementing Reward Function for Cartpole Task (Direct)\nDESCRIPTION: This function computes rewards for the Cartpole environment using the direct approach. It calls a Torch JIT compiled function for performance optimization.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/task_workflows.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef _get_rewards(self) -> torch.Tensor:\n    # extract values from buffers\n    pole_angle = self._pole_angle_buf\n    pole_vel = self._pole_vel_buf\n    cart_vel = self._cart_vel_buf\n    cart_pos = self._cart_pos_buf\n    actions = self._actions_buf\n\n    # compute rewards\n    self._rewards_buf[:] = compute_rewards(\n        pole_angle,\n        pole_vel,\n        cart_vel,\n        cart_pos,\n        actions,\n        self._reward_scales,\n        self._max_episode_length,\n    )\n    return self._rewards_buf\n```\n\nLANGUAGE: python\nCODE:\n```\n@torch.jit.script\ndef compute_rewards(\n    pole_angle: torch.Tensor,\n    pole_vel: torch.Tensor,\n    cart_vel: torch.Tensor,\n    cart_pos: torch.Tensor,\n    actions: torch.Tensor,\n    reward_scales: Dict[str, float],\n    max_episode_length: int,\n) -> torch.Tensor:\n    # prepare tensors\n    # pole angle deviated from upright\n    angle_reward = 1.0 - torch.abs(pole_angle / math.pi)\n    # cart velocity\n    cart_velocity_reward = 1.0 - torch.abs(cart_vel / 1.0)\n    # cart position from center\n    cart_pos_reward = 1.0 - torch.abs(cart_pos / 0.6)\n    # sum rewards\n    rewards = (\n        reward_scales[\"angle\"] * angle_reward\n        + reward_scales[\"cart_velocity\"] * cart_velocity_reward\n        + reward_scales[\"cart_position\"] * cart_pos_reward\n    )\n    return rewards\n```\n\n----------------------------------------\n\nTITLE: Running RL Training with Hydra Arguments (rsl_rl)\nDESCRIPTION: Example of running a training script for the Isaac-Cartpole-v0 task using rsl_rl, with Hydra arguments to modify environment and agent parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/hydra.rst#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --headless env.actions.joint_effort.scale=10.0 agent.seed=2024\n```\n\n----------------------------------------\n\nTITLE: Running RL Training with Hydra Arguments (sb3)\nDESCRIPTION: Example of running a training script for the Isaac-Cartpole-v0 task using sb3, with Hydra arguments to modify environment and agent parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/hydra.rst#2025-04-23_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npython scripts/reinforcement_learning/sb3/train.py --task=Isaac-Cartpole-v0 --headless env.actions.joint_effort.scale=10.0 agent.seed=2024\n```\n\n----------------------------------------\n\nTITLE: Pre-Physics Step in IsaacLab\nDESCRIPTION: This function prepares actions for the physics simulation step in IsaacLab. It scales the actions and stores them for later use.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndef _pre_physics_step(self, actions: torch.Tensor) -> None:\n    self.actions = self.action_scale * actions\n```\n\n----------------------------------------\n\nTITLE: Setting Task-Specific Configuration Parameters\nDESCRIPTION: Additional task-specific attributes in the configuration class, including thresholds for reset conditions and scaling factors for different reward components.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass CartpoleEnvCfg(DirectRLEnvCfg):\n   ...\n   # reset\n   max_cart_pos = 3.0\n   initial_pole_angle_range = [-0.25, 0.25]\n\n   # reward scales\n   rew_scale_alive = 1.0\n   rew_scale_terminated = -2.0\n   rew_scale_pole_pos = -1.0\n   rew_scale_cart_vel = -0.01\n   rew_scale_pole_vel = -0.005\n```\n\n----------------------------------------\n\nTITLE: Worker Node Command for Multi-Node Training with skrl and PyTorch\nDESCRIPTION: Command for non-master (worker) nodes when running RL training with skrl using PyTorch backend across multiple machines. Connects to the master node for distributed training.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\npython -m torch.distributed.run --nproc_per_node=2 --nnodes=2 --node_rank=1 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=ip_of_master_machine:5555 scripts/reinforcement_learning/skrl/train.py --task=Isaac-Cartpole-v0 --headless --distributed\n```\n\n----------------------------------------\n\nTITLE: Submitting Jobs to Ray Cluster (Python)\nDESCRIPTION: Reference to the `submit_job.py` script, highlighting the section (lines 12-53) likely responsible for parsing arguments and submitting either hyperparameter tuning jobs or resource-wrapped execution jobs to the configured Ray cluster.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n... literalinclude:: ../../../scripts/reinforcement_learning/ray/submit_job.py\n  :language: python\n  :emphasize-lines: 12-53\n```\n\n----------------------------------------\n\nTITLE: Simulation Time Tracking in Python\nDESCRIPTION: Code snippet showing how to increment and log simulation time at each simulation step, writing to a log file in a mounted volume.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Prepare to count sim_time\nsim_time = 0.0\n\n# Append to the log\nlog_path = os.path.join(log_dir_path, \"log.txt\")\nwith open(log_path, \"w\") as f:\n    while sim_time < max_time:\n        # Step the simulation\n        sim.step()\n        # Log the simulation time\n        f.write(f\"{sim_time}\\n\")\n        f.flush()\n        # Increment the simulation time\n        sim_time += sim_dt\n```\n\n----------------------------------------\n\nTITLE: Running Deformable Teddy Bear Lifting State Machine\nDESCRIPTION: Commands to execute a Warp-based state machine for picking up a deformable teddy bear and placing it at a desired pose with a robotic arm.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/simple_agents.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/environments/state_machine/lift_teddy_bear.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\environments\\state_machine\\lift_teddy_bear.py\n```\n\n----------------------------------------\n\nTITLE: Instantiating InteractiveScene with Custom Configuration (Python)\nDESCRIPTION: Creates an instance of the InteractiveScene class using the custom CartpoleSceneCfg configuration, specifying the number of environment copies. This is central to initializing and cloning scene entities for parallel environments in the simulation. Dependencies are scene.InteractiveScene and a valid configuration class. The key input parameter is num_envs, controlling the number of scene duplicates, and the output is a fully instantiated InteractiveScene object. Limitations: relies on proper config structure and the existence of InteractiveScene in the environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/02_scene/create_scene.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Design scene\nscene_cfg = CartpoleSceneCfg(num_envs=32)\nscene = InteractiveScene(scene_cfg)\n```\n\n----------------------------------------\n\nTITLE: Defining Locomotion Velocity Rough Environment Configuration\nDESCRIPTION: Python code snippet showing the LocomotionVelocityRoughEnvCfg class definition, including post-initialization updates for simulation and scene parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/hydra.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass LocomotionVelocityRoughEnvCfg(LocomotionVelocityEnvCfg):\n    def __post_init__(self):\n        super().__post_init__()\n        self.sim.render_interval = self.decimation\n        self.scene.height_scanner.update_period = self.sim.dt * self.decimation\n        self.scene.contact_forces.update_period = self.sim.dt * self.decimation\n```\n\n----------------------------------------\n\nTITLE: Logging Time Script in Python\nDESCRIPTION: Python script that logs simulation time at each step. The script demonstrates how to write logs to a persistent volume in the Docker container that can later be accessed from the host machine.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Specify that the logs must be in logs/docker_tutorial\nlog_dir_path = os.path.abspath(os.path.join(\"logs\", \"docker_tutorial\"))\nos.makedirs(log_dir_path, exist_ok=True)\nprint(f\"[INFO] Logging experiment to directory: {log_dir_path}\")\n```\n\n----------------------------------------\n\nTITLE: Computing OSC Joint Commands in Python\nDESCRIPTION: This Python snippet demonstrates computing joint effort/torque values using the `osc.compute` method. It requires the current robot state (`robot_state`), the desired command (`command`), the current end-effector pose (`ee_pose_b`), and the current task frame pose (`task_frame_pose_b`) as inputs. The method returns the computed joint efforts.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_osc.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# compute the joint commands\njoint_efforts = osc.compute(\n    robot_state=robot_state,\n    command=command,\n    current_ee_pose_b=ee_pose_b,\n    current_task_frame_pose_b=task_frame_pose_b,\n)\n```\n\n----------------------------------------\n\nTITLE: Pre-Physics Step in IsaacGymEnvs\nDESCRIPTION: This function prepares actions for the physics simulation step in IsaacGymEnvs. It converts actions to forces and applies them to the simulation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef pre_physics_step(self, actions):\n    actions_tensor = torch.zeros(self.num_envs * self.num_dof, device=self.device, dtype=torch.float)\n    actions_tensor[::self.num_dof] = actions.to(self.device).squeeze() * self.max_push_effort\n    forces = gymtorch.unwrap_tensor(actions_tensor)\n    self.gym.set_dof_actuation_force_tensor(self.sim, forces)\n```\n\n----------------------------------------\n\nTITLE: Configuring Cartpole Environment in Python (Isaac Lab)\nDESCRIPTION: Python configuration class for the Cartpole environment in Isaac Lab, defining simulation, robot, scene, and environment parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass CartpoleEnvCfg(DirectRLEnvCfg):\n    # simulation\n    sim: SimulationCfg = SimulationCfg(dt=1 / 120)\n    # robot\n    robot_cfg: ArticulationCfg = CARTPOLE_CFG.replace(\n        prim_path=\"/World/envs/env_.*/Robot\")\n    cart_dof_name = \"slider_to_cart\"\n    pole_dof_name = \"cart_to_pole\"\n    # scene\n    scene: InteractiveSceneCfg = InteractiveSceneCfg(\n        num_envs=4096, env_spacing=4.0, replicate_physics=True)\n    # env\n    decimation = 2\n    episode_length_s = 5.0\n    action_scale = 100.0  # [N]\n    action_space = 1\n    observation_space = 4\n    state_space = 0\n    # reset\n    max_cart_pos = 3.0\n    initial_pole_angle_range = [-0.25, 0.25]\n    # reward scales\n    rew_scale_alive = 1.0\n    rew_scale_terminated = -2.0\n    rew_scale_pole_pos = -1.0\n    rew_scale_cart_vel = -0.01\n    rew_scale_pole_vel = -0.005\n```\n\n----------------------------------------\n\nTITLE: Running Random-Action Agent on Cart-pole Environment\nDESCRIPTION: Commands to run a random-action agent on the Cart-pole environment with 32 parallel environments. Random agents provide a basic performance baseline.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/simple_agents.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/environments/random_agent.py --task Isaac-Cartpole-v0 --num_envs 32\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\environments\\random_agent.py --task Isaac-Cartpole-v0 --num_envs 32\n```\n\n----------------------------------------\n\nTITLE: Verifying Kubernetes Cluster Access and Operators (Bash)\nDESCRIPTION: Uses kubectl commands to verify access to the Kubernetes cluster, check for existing node pools (if not using managed services like Autopilot), and confirm the installation of required Custom Resource Definitions (CRDs) for Ray and NVIDIA operators.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# Verify cluster access\nkubectl cluster-info\n# If using a manually managed cluster (not Autopilot or the like)\n# verify that there are node pools\nkubectl get nodes\n# Check that the ray operator is installed on the cluster\n# should list rayclusters.ray.io , rayjobs.ray.io , and rayservices.ray.io\nkubectl get crds | grep ray\n# Check that the NVIDIA Driver Operator is installed on the cluster\n# should list clusterpolicies.nvidia.com\nkubectl get crds | grep nvidia\n```\n\n----------------------------------------\n\nTITLE: Launching Isaac Environment with Camera Support\nDESCRIPTION: Shell command example for launching a reinforcement learning training script with camera support enabled. The --enable_cameras flag is required when working with camera rendering.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/camera.rst#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npython scripts/reinforcement_learning/rl_games/train.py --task=Isaac-Cartpole-RGB-Camera-Direct-v0 --headless --enable_cameras\n```\n\n----------------------------------------\n\nTITLE: Running Cube Lifting State Machine with Robotic Arm\nDESCRIPTION: Commands to execute a Warp-based state machine for picking up a cube and placing it at a desired pose with a robotic arm, running 32 parallel environments.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/simple_agents.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/environments/state_machine/lift_cube_sm.py --num_envs 32\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\environments\\state_machine\\lift_cube_sm.py --num_envs 32\n```\n\n----------------------------------------\n\nTITLE: Implementing Animation Recording Toggle in BaseEnvWindow Class\nDESCRIPTION: This Python method toggles the recording of animations in the BaseEnvWindow class. It captures the current state of the stage, manages recording settings, and saves both the original stage and time-sampled animation to the recordings directory.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/record_animation.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef _toggle_recording_animation_fn(self):\n    \"\"\"Function to toggle recording of the simulation animation\n\n    This function uses the Stage Recorder extension to record the animation of the\n    simulation. The recording is saved to the \"recordings\" folder in the current\n    working directory. The recorded animation includes the time-sampled USD file\n    and the original stage file.\n\n    Note:\n        This function assumes that Fabric is disabled to allow reading and writing\n        all the changes (such as motion and USD properties) to the USD stage.\n    \"\"\"\n    # Cannot record animation when Fabric is enabled\n    if omni.usd.get_context().get_stage_uploader().is_fabric_enabled():\n        carb.log_warn(\"Cannot record animation when Fabric is enabled. Please restart with --disable_fabric flag.\")\n        return\n\n    # Get stage recorder interface\n    ext_manager = omni.kit.app.get_app().get_extension_manager()\n    if not ext_manager.is_extension_enabled(\"omni.anim.stage_recorder\"):\n        # Enable the extension if not enabled\n        ext_manager.set_extension_enabled_immediate(\"omni.anim.stage_recorder\", True)\n    stage_recorder = omni.kit.stage_recorder.get_instance()\n    recording_state = stage_recorder.get_recording_state()\n\n    # Toggle recording state\n    if recording_state != omni.kit.stage_recorder.RecordingState.RECORDING:\n        # Create the recordings directory if it doesn't exist\n        if not os.path.exists(\"recordings\"):\n            os.makedirs(\"recordings\")\n        # Set recording settings\n        settings = omni.kit.stage_recorder.RecordingSettings(\n            \"recordings/Stage.usd\",\n            \"recordings/TimeSample_tk\",\n            refresh_rate=60.0,\n            record_scene_data=True,\n            record_visibility=False,\n            record_materials=False,\n            record_cameras=False,\n            record_lights=False,\n            record_animation=True,\n        )\n        # Start recording\n        stage_recorder.start_recording(settings)\n        # Update button text\n        self._record_button.text = \"Stop Recording\"\n    else:\n        # Stop recording\n        stage_recorder.stop_recording()\n        # Update button text\n        self._record_button.text = \"Record Animation\"\n        # Log recording location\n        print(\"Recording saved to:\\n  recordings/Stage.usd\\n  recordings/TimeSample_tk001.usd\")\n```\n\n----------------------------------------\n\nTITLE: Updating Robot States for Operational Space Control\nDESCRIPTION: This code updates the robot's state information that's required by the Operational Space Controller. It includes Jacobian matrix, mass/inertia matrix, end-effector pose, velocity, contact force, and joint positions and velocities.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_osc.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Update robot states\n# Update the OSC with the robot's states\njacobian_ee_b = robot_view.jacobian\ninertia_matrix = robot_view.mass_matrix\n\nee_pose_b = robot_view.ee_pose_w\nee_vel_b = robot_view.ee_body_velocity_b\nee_contact_force_b = contact_sensor.get_net_contact_forces()\n\njoint_pos = robot_view.joint_positions\njoint_vel = robot_view.joint_velocities\n\nnull_joint_targets = (franka_joint_pos_limits[:, 0] + franka_joint_pos_limits[:, 1]) / 2.0\n\nosc.update_state(\n    jacobian_ee_b, inertia_matrix, ee_pose_b, ee_vel_b, ee_contact_force_b, joint_pos, joint_vel,\n    gravity_vec=None, null_joint_targets=null_joint_targets\n)\n```\n\n----------------------------------------\n\nTITLE: Integrating with Stable-Baselines3 Framework\nDESCRIPTION: Example of wrapping an Isaac Sim environment to make it compatible with the Stable-Baselines3 RL framework.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/wrap_rl_env.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab_rl.sb3 import Sb3VecEnvWrapper\n\n# create isaac-env instance\nenv = gym.make(task_name, cfg=env_cfg)\n# wrap around environment for stable baselines\nenv = Sb3VecEnvWrapper(env)\n```\n\n----------------------------------------\n\nTITLE: Adding Terrain to Scene in Python\nDESCRIPTION: Shows how to add a configured terrain to the scene in the _setup_scene method.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef _setup_scene(self):\n   ...\n   self.cfg.terrain.num_envs = self.scene.cfg.num_envs\n   self.cfg.terrain.env_spacing = self.scene.cfg.env_spacing\n   self._terrain = self.cfg.terrain.class_type(self.cfg.terrain)\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Actions from RL Policy\nDESCRIPTION: The _pre_physics_step method processes actions from the RL policy before they are applied to the environment, scaling and clamping the actions as necessary.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef _pre_physics_step(self, actions: torch.Tensor) -> None:\n    # action is the force applied to the cart\n    self.actions = torch.clamp(actions, -1.0, 1.0)\n    # default is 1000 N\n    self.actions *= 1000.0\n```\n\n----------------------------------------\n\nTITLE: Converting URDF to USD Format for ANYmal-D Robot\nDESCRIPTION: This snippet demonstrates how to clone a repository containing URDF files for the ANYmal-D robot and convert them to USD format using the convert_urdf.py utility tool. It sets specific joint parameters and merge settings for optimal simulation performance.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/import_new_asset.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# create a directory to clone\nmkdir ~/git && cd ~/git\n# clone a repository with URDF files\ngit clone git@github.com:isaac-orbit/anymal_d_simple_description.git\n\n# go to top of the Isaac Lab repository\ncd IsaacLab\n# run the converter\n./isaaclab.sh -p scripts/tools/convert_urdf.py \\\n  ~/git/anymal_d_simple_description/urdf/anymal.urdf \\\n  source/isaaclab_assets/data/Robots/ANYbotics/anymal_d.usd \\\n  --merge-joints \\\n  --joint-stiffness 0.0 \\\n  --joint-damping 0.0 \\\n  --joint-target-type none\n```\n\n----------------------------------------\n\nTITLE: Initializing Cartpole Environment in OmniIsaacGymEnvs\nDESCRIPTION: Demonstrates the class structure and initialization of a Cartpole task in OmniIsaacGymEnvs, including configuration updates and post-reset setup.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nclass CartpoleTask(RLTask):\n\n    def __init__(self, name, sim_config, env, offset=None) -> None:\n        self.update_config(sim_config)\n        self._max_episode_length = 500\n\n        self._num_observations = 4\n        self._num_actions = 1\n\n        RLTask.__init__(self, name, env)\n\n        def update_config(self, sim_config):\n            self._sim_config = sim_config\n            self._cfg = sim_config.config\n            self._task_cfg = sim_config.task_config\n\n            self._num_envs = self._task_cfg[\"env\"][\"numEnvs\"]\n            self._env_spacing = self._task_cfg[\"env\"][\"envSpacing\"]\n            self._cartpole_positions = torch.tensor([0.0, 0.0, 2.0])\n\n            self._reset_dist = self._task_cfg[\"env\"][\"resetDist\"]\n            self._max_push_effort = self._task_cfg[\"env\"][\"maxEffort\"]\n\n\n        def post_reset(self):\n            self._cart_dof_idx = self._cartpoles.get_dof_index(\"cartJoint\")\n            self._pole_dof_idx = self._cartpoles.get_dof_index(\"poleJoint\")\n            # randomize all envs\n            indices = torch.arange(self._cartpoles.count, dtype=torch.int64, device=self._device)\n            self.reset_idx(indices)\n```\n\n----------------------------------------\n\nTITLE: Registering Direct Environment\nDESCRIPTION: Code snippet showing how to register a direct-based environment (cartpole) with the Gymnasium registry, highlighting the differences in environment ID and entry point compared to manager-based environments.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/register_rl_env_gym.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Copyright (c) 2023-2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# NVIDIA CORPORATION, its affiliates and licensors retain all intellectual\n# property and proprietary rights in and to this material, related\n# documentation and any modifications thereto. Any use, reproduction,\n# disclosure or distribution of this material and related documentation\n# without an express license agreement from NVIDIA CORPORATION or\n# its affiliates is strictly prohibited.\n\n# register the environments\nimport gymnasium as gym\n\ngym.register(\n    id=\"Isaac-Cartpole-Direct-v0\",\n    entry_point=\"isaaclab_tasks.direct.cartpole.cartpole_env:CartpoleEnv\",\n    env_cfg_entry_point=\"isaaclab_tasks.direct.cartpole:CartpoleCfg\",\n)\n\ngym.register(\n    id=\"Isaac-Dactyl-Reorientation-Direct-v0\",\n    entry_point=\"isaaclab_tasks.direct.dactyl.dactyl_reorientation_env:DactylReorientationEnv\",\n    env_cfg_entry_point=(\n        \"isaaclab_tasks.direct.dactyl.dactyl_reorientation:DactylReorientationCfg\"\n    ),\n)\n\ngym.register(\n    id=\"Isaac-Half-Cheetah-Direct-v0\",\n    entry_point=\"isaaclab_tasks.direct.mujoco.half_cheetah_env:HalfCheetahEnv\",\n    env_cfg_entry_point=\"isaaclab_tasks.direct.mujoco.half_cheetah:HalfCheetahCfg\",\n)\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch Nightly Build for 50 Series GPUs (Bash)\nDESCRIPTION: Installs the latest nightly pre-release build of PyTorch and torchvision from the specified index URL (cu128). This is specifically recommended for users with NVIDIA 50 series GPUs as a replacement for the standard PyTorch 2.5.1 included with Isaac Sim, ensuring compatibility with newer hardware.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128\n```\n\n----------------------------------------\n\nTITLE: Setting Up Cartpole Scene in OmniIsaacGymEnvs\nDESCRIPTION: Illustrates the scene setup process in OmniIsaacGymEnvs, including creating and adding cartpoles to the scene.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef set_up_scene(self, scene) -> None:\n    self.get_cartpole()\n    super().set_up_scene(scene)\n    self._cartpoles = ArticulationView(\n        prim_paths_expr=\"/World/envs/.*/Cartpole\",\n        name=\"cartpole_view\",\n        reset_xform_properties=False\n    )\n    scene.add(self._cartpoles)\n    return\n\ndef get_cartpole(self):\n    cartpole = Cartpole(\n        prim_path=self.default_zero_env_path+\"/Cartpole\",\n        name=\"Cartpole\",\n        translation=self._cartpole_positions\n    )\n```\n\n----------------------------------------\n\nTITLE: Policy Inference Implementation in Python\nDESCRIPTION: Python code showing configuration modifications for running policy inference in a prebuilt USD environment, with CPU device settings and Fabric disabled for better performance with small environment counts.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/policy_inference_in_usd.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Note: This is a snippet from the emphasized lines\ncfg[\"env\"][\"numEnvs\"] = 1\ncfg[\"device\"] = \"cpu\"\ncfg[\"enableFabric\"] = False\ncfg[\"env\"][\"env\"] = None\ncfg[\"env\"][\"terrainProps\"][\"type\"] = \"plane\"\ncfg[\"env\"][\"terrainProps\"][\"staticFriction\"] = 1.0\ncfg[\"env\"][\"terrainProps\"][\"dynamicFriction\"] = 1.0\ncfg[\"env\"][\"terrainProps\"][\"restitution\"] = 0.0\ncfg[\"env\"][\"loadTerrainUsd\"] = True\n```\n\n----------------------------------------\n\nTITLE: Resetting Environment Indices in Isaac Lab\nDESCRIPTION: Function to reset specific environments by their indices in Isaac Lab. It initializes the pole at a random angle within a configured range and sets joint positions, velocities, and root states for the specified environments.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_29\n\nLANGUAGE: python\nCODE:\n```\ndef _reset_idx(self, env_ids: Sequence[int] | None):\n    if env_ids is None:\n        env_ids = self.cartpole._ALL_INDICES\n    super()._reset_idx(env_ids)\n\n    joint_pos = self.cartpole.data.default_joint_pos[env_ids]\n    joint_pos[:, self._pole_dof_idx] += sample_uniform(\n        self.cfg.initial_pole_angle_range[0] * math.pi,\n        self.cfg.initial_pole_angle_range[1] * math.pi,\n        joint_pos[:, self._pole_dof_idx].shape,\n        joint_pos.device,\n    )\n    joint_vel = self.cartpole.data.default_joint_vel[env_ids]\n\n    default_root_state = self.cartpole.data.default_root_state[env_ids]\n    default_root_state[:, :3] += self.scene.env_origins[env_ids]\n\n    self.joint_pos[env_ids] = joint_pos\n\n    self.cartpole.write_root_pose_to_sim(\n        default_root_state[:, :7], env_ids)\n    self.cartpole.write_root_velocity_to_sim(\n        default_root_state[:, 7:], env_ids)\n    self.cartpole.write_joint_state_to_sim(\n        joint_pos, joint_vel, None, env_ids)\n```\n\n----------------------------------------\n\nTITLE: Velocity Control Implementation\nDESCRIPTION: Proportional control law for velocity control using joint torque commands based on velocity error.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/motion_generators.rst#2025-04-23_snippet_1\n\nLANGUAGE: math\nCODE:\n```\n\\tau = k_d (\\dot{q}_{des} - \\dot{q})\n```\n\n----------------------------------------\n\nTITLE: Accessing Tiled Camera Data in Isaac Lab\nDESCRIPTION: Code snippet showing how to create a TiledCamera object from configuration and access image data. The returned data is automatically formatted in the shape (num_cameras, height, width, num_channels) suitable for reinforcement learning.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/camera.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntiled_camera = TiledCamera(cfg.tiled_camera)\ndata_type = \"rgb\"\ndata = tiled_camera.data.output[data_type]\n```\n\n----------------------------------------\n\nTITLE: Training an Ant Robot with Isaac Lab (Linux)\nDESCRIPTION: Command to train an ant robot to walk using Isaac Lab's reinforcement learning capabilities on Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Ant-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Applying Articulation Settings in IsaacLab\nDESCRIPTION: Applies articulation settings to a cartpole from task configuration YAML file using the simulation config.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nself._sim_config.apply_articulation_settings(\n    \"Cartpole\", get_prim_at_path(cartpole.prim_path),\n    self._sim_config.parse_actor_config(\"Cartpole\")\n)\n```\n\n----------------------------------------\n\nTITLE: Master Node Command for Multi-Node Training with skrl and PyTorch\nDESCRIPTION: Command for the master node when running RL training with skrl using PyTorch backend across multiple machines. Specifies rendezvous settings for coordinating distributed training between nodes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\npython -m torch.distributed.run --nproc_per_node=2 --nnodes=2 --node_rank=0 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=localhost:5555 scripts/reinforcement_learning/skrl/train.py --task=Isaac-Cartpole-v0 --headless --distributed\n```\n\n----------------------------------------\n\nTITLE: Registering Manager-Based Environment\nDESCRIPTION: Code snippet demonstrating how to register a manager-based environment (cartpole) with the Gymnasium registry, showing the environment ID, entry point, and configuration entry point.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/register_rl_env_gym.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Copyright (c) 2023-2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# NVIDIA CORPORATION, its affiliates and licensors retain all intellectual\n# property and proprietary rights in and to this material, related\n# documentation and any modifications thereto. Any use, reproduction,\n# disclosure or distribution of this material and related documentation\n# without an express license agreement from NVIDIA CORPORATION or\n# its affiliates is strictly prohibited.\n\n# register the environments\nimport gymnasium as gym\n\ngym.register(\n    id=\"Isaac-Cartpole-v0\",\n    entry_point=\"isaaclab.envs:ManagerBasedRLEnv\",\n    env_cfg_entry_point=\"isaaclab_tasks.manager_based.classic.cartpole:CartpoleCfg\",\n)\n```\n\n----------------------------------------\n\nTITLE: Launching Isaac Sim via Command Line - Bash\nDESCRIPTION: Runs the Isaac Sim executable from the command line. Passing --help displays available command-line options. Prerequisites include successful Isaac Sim installation and a properly set up Python environment. Result is the launch of the Isaac Sim GUI or headless process.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# note: you can pass the argument \"--help\" to see all arguments possible.\nisaacsim\n```\n\n----------------------------------------\n\nTITLE: Initializing Cartpole Environment in Python (IsaacGymEnvs)\nDESCRIPTION: Python class initialization for the Cartpole environment in IsaacGymEnvs, setting up environment parameters and inheriting from VecTask.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nclass Cartpole(VecTask):\n    def __init__(self, cfg, rl_device, sim_device, graphics_device_id, headless, virtual_screen_capture, force_render):\n        self.cfg = cfg\n\n        self.reset_dist = self.cfg[\"env\"][\"resetDist\"]\n\n        self.max_push_effort = self.cfg[\"env\"][\"maxEffort\"]\n        self.max_episode_length = 500\n```\n\n----------------------------------------\n\nTITLE: Initializing Cartpole Environment in Python (Isaac Lab)\nDESCRIPTION: Python class initialization for the Cartpole environment in Isaac Lab, using a configuration class and inheriting from DirectRLEnv.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nclass CartpoleEnv(DirectRLEnv):\n    cfg: CartpoleEnvCfg\n    def __init__(self, cfg: CartpoleEnvCfg,\n            render_mode: str | None = None, **kwargs):\n\n        super().__init__(cfg, render_mode, **kwargs)\n\n        self._cart_dof_idx, _ = self.cartpole.find_joints(\n            self.cfg.cart_dof_name)\n        self._pole_dof_idx, _ = self.cartpole.find_joints(\n            self.cfg.pole_dof_name)\n```\n\n----------------------------------------\n\nTITLE: Importing isaaclab_tasks to Register Environments\nDESCRIPTION: Code snippet showing the import statement needed to register all environments from the isaaclab_tasks extension with the Gymnasium registry.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/register_rl_env_gym.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport isaaclab_tasks  # noqa: F401\n```\n\n----------------------------------------\n\nTITLE: Gathering Observations for Cartpole in OmniIsaacGymEnvs and Isaac Lab\nDESCRIPTION: Demonstrates how observations are collected in both implementations. Isaac Lab requires returning a dictionary with a 'policy' key containing the observation buffer, and optionally a 'critic' key for asymmetric actor-critic states.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndef get_observations(self) -> dict:\n    dof_pos = self._cartpoles.get_joint_positions(clone=False)\n    dof_vel = self._cartpoles.get_joint_velocities(clone=False)\n\n    self.cart_pos = dof_pos[:, self._cart_dof_idx]\n```\n\nLANGUAGE: python\nCODE:\n```\ndef _get_observations(self) -> dict:\n    obs = torch.cat(\n             (\n        self.joint_pos[:, self._pole_dof_idx[0]],\n        self.joint_vel[:, self._pole_dof_idx[0]],\n```\n\n----------------------------------------\n\nTITLE: Position Control with Fixed Impedance\nDESCRIPTION: PD control law for position tracking with simple and complete formulations including dynamics compensation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/motion_generators.rst#2025-04-23_snippet_2\n\nLANGUAGE: math\nCODE:\n```\n\\tau = k_p (q_{des} - q)  - k_d \\dot{q}\n```\n\nLANGUAGE: math\nCODE:\n```\n\\tau = M \\left( k_p (q_{des} - q)  - k_d \\dot{q} \\right) + g\n```\n\nLANGUAGE: math\nCODE:\n```\nk_d = 2 \\sqrt{k_p} \\times D\n```\n\n----------------------------------------\n\nTITLE: Running H1 Locomotion Demo in Isaac Lab\nDESCRIPTION: Commands for interactive inference of trained H1 rough terrain locomotion policy. This demo demonstrates a practical application of trained locomotion policies in challenging environments.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/showroom.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/h1_locomotion.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\demos\\h1_locomotion.py\n```\n\n----------------------------------------\n\nTITLE: Applying Actions to Simulation Environment\nDESCRIPTION: The _apply_action method applies the processed actions to the physics simulation, setting the joint efforts for the cart in each environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef _apply_action(self) -> None:\n    # feed actions into controller\n    joint_efforts = torch.zeros((self.num_envs, self.articulation.num_dof), device=self.device)\n    joint_efforts[:, self._cart_dof_idx[0]] = self.actions[:, 0]\n    self.articulation.set_joint_efforts(joint_efforts)\n```\n\n----------------------------------------\n\nTITLE: Adding Terrain to the Scene in Isaac Lab (Python)\nDESCRIPTION: Illustrates how to instantiate and add the defined terrain configuration into the simulation scene. Updates the terrain configuration with scene-wide values for 'num_envs' and 'env_spacing' before constructing the terrain object via its class_type initializer. The resulting terrain is available for attachment or management in the simulation. Inputs: references to config and scene objects; Outputs: instantiated terrain object.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef _setup_scene(self):\n   ...\n   self.cfg.terrain.num_envs = self.scene.cfg.num_envs\n   self.cfg.terrain.env_spacing = self.scene.cfg.env_spacing\n   self._terrain = self.cfg.terrain.class_type(self.cfg.terrain)\n```\n\n----------------------------------------\n\nTITLE: Configuring Cartpole Environment in YAML\nDESCRIPTION: YAML configuration for the Cartpole environment, including physics engine settings, environment parameters, and simulation details. It specifies GPU-related configurations and Cartpole-specific physics properties.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\n# used to create the object\n\nname: Cartpole\n\nphysics_engine: ${..physics_engine}\n\n# if given, will override the device setting in gym.\nenv:\n  numEnvs: ${resolve_default:512,${...num_envs}}\n  envSpacing: 4.0\n  resetDist: 3.0\n  maxEffort: 400.0\n\n  clipObservations: 5.0\n  clipActions: 1.0\n  controlFrequencyInv: 2 # 60 Hz\n\nsim:\n  dt: 0.0083 # 1/120 s\n  use_gpu_pipeline: ${eq:${...pipeline},\"gpu\"}\n  gravity: [0.0, 0.0, -9.81]\n  add_ground_plane: True\n  add_distant_light: False\n  use_fabric: True\n  enable_scene_query_support: False\n  disable_contact_processing: False\n\n  enable_cameras: False\n\n  default_physics_material:\n    static_friction: 1.0\n    dynamic_friction: 1.0\n    restitution: 0.0\n\n  physx:\n    worker_thread_count: ${....num_threads}\n    solver_type: ${....solver_type}\n    use_gpu: ${eq:${....sim_device},\"gpu\"} # set to False to...\n    solver_position_iteration_count: 4\n    solver_velocity_iteration_count: 0\n    contact_offset: 0.02\n    rest_offset: 0.001\n    bounce_threshold_velocity: 0.2\n    friction_offset_threshold: 0.04\n    friction_correlation_distance: 0.025\n    enable_sleeping: True\n    enable_stabilization: True\n    max_depenetration_velocity: 100.0\n\n    # GPU buffers\n    gpu_max_rigid_contact_count: 524288\n    gpu_max_rigid_patch_count: 81920\n    gpu_found_lost_pairs_capacity: 1024\n    gpu_found_lost_aggregate_pairs_capacity: 262144\n    gpu_total_aggregate_pairs_capacity: 1024\n    gpu_max_soft_body_contacts: 1048576\n    gpu_max_particle_contacts: 1048576\n    gpu_heap_capacity: 67108864\n    gpu_temp_buffer_capacity: 16777216\n    gpu_max_num_partitions: 8\n\n    Cartpole:\n      override_usd_defaults: False\n      enable_self_collisions: False\n      enable_gyroscopic_forces: True\n      solver_position_iteration_count: 4\n      solver_velocity_iteration_count: 0\n      sleep_threshold: 0.005\n      stabilization_threshold: 0.001\n      density: -1\n```\n\n----------------------------------------\n\nTITLE: Applying Actions in IsaacLab\nDESCRIPTION: This function applies the prepared actions to the cartpole in IsaacLab by setting joint effort targets.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ndef _apply_action(self) -> None:\n    self.cartpole.set_joint_effort_target(self.actions, joint_ids=self._cart_dof_idx)\n```\n\n----------------------------------------\n\nTITLE: Configuring Actuators for Cartpole with a Single Actuator Model\nDESCRIPTION: This alternative snippet shows how to configure all joints of the Cartpole using a single actuator model. It uses a wildcard expression to match all joints and provides custom stiffness and damping settings for each joint.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/write_articulation_cfg.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nactuators={\n   \"all_joints\": ImplicitActuatorCfg(\n      joint_names_expr=[\".*\"],\n      effort_limit=400.0,\n      velocity_limit=100.0,\n      stiffness={\"slider_to_cart\": 0.0, \"cart_to_pole\": 0.0},\n      damping={\"slider_to_cart\": 10.0, \"cart_to_pole\": 0.0},\n   ),\n},\n```\n\n----------------------------------------\n\nTITLE: Initializing Basic Environment Wrapper in Isaac Sim\nDESCRIPTION: Demonstrates how to launch Isaac Sim in headless mode and wrap an environment with OrderEnforcing wrapper to ensure reset is called before step.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/wrap_rl_env.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Launch Isaac Sim Simulator first.\"\"\"\n\nfrom isaaclab.app import AppLauncher\n\n# launch omniverse app in headless mode\napp_launcher = AppLauncher(headless=True)\nsimulation_app = app_launcher.app\n\n\"\"\"Rest everything follows.\"\"\"\n\nimport gymnasium as gym\n\nimport isaaclab_tasks  # noqa: F401\nfrom isaaclab_tasks.utils import load_cfg_from_registry\n\n# create base environment\ncfg = load_cfg_from_registry(\"Isaac-Reach-Franka-v0\", \"env_cfg_entry_point\")\nenv = gym.make(\"Isaac-Reach-Franka-v0\", cfg=cfg)\n# wrap environment to enforce that reset is called before step\nenv = gym.wrappers.OrderEnforcing(env)\n```\n\n----------------------------------------\n\nTITLE: Running Quadrupeds Demo in Isaac Lab\nDESCRIPTION: Commands to spawn different quadrupeds and make robots stand using position commands. The script demonstrates how to use the quadruped interfaces in Isaac Lab.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/showroom.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/quadrupeds.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\demos\\quadrupeds.py\n```\n\n----------------------------------------\n\nTITLE: Training Launch Command for Isaac Lab\nDESCRIPTION: Command to launch training for CartPole environment in Isaac Lab using RL Games framework.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_34\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/reinforcement_learning/rl_games/train.py --task=Isaac-Cartpole-Direct-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Comparing Observation/Action Clipping Configuration in YAML\nDESCRIPTION: Shows how to migrate observation and action clipping parameters from IsaacGymEnvs task config to Isaac Lab RL config file.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n# OmniIsaacGymEnvs\nenv:\n  clipObservations: 5.0\n  clipActions: 1.0\n```\n\nLANGUAGE: yaml\nCODE:\n```\n# IsaacLab\nparams:\n  env:\n    clip_observations: 5.0\n    clip_actions: 1.0\n```\n\n----------------------------------------\n\nTITLE: Applying Computed Joint Efforts in Isaac Sim (Python)\nDESCRIPTION: This Python code snippet shows how to apply the computed joint effort targets to the robot within the Isaac Sim environment. It first sets the joint effort targets using `robot.set_joint_effort_target()` and then calls `robot.write_data_to_sim()` to update the simulation state.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_osc.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# apply actions\n# -- set joint efforts\nrobot.set_joint_effort_target(joint_efforts)\n# -- write data to sim\nrobot.write_data_to_sim()\n```\n\n----------------------------------------\n\nTITLE: Resetting Cartpole Environment in OmniIsaacGymEnvs and Isaac Lab\nDESCRIPTION: Compares the reset implementation for the cartpole environment between OmniIsaacGymEnvs and Isaac Lab. Both versions randomize initial positions and velocities, but Isaac Lab uses a more modular approach with separate methods for writing state to simulation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndof_pos[:, self._cart_dof_idx] = 1.0 * (1.0 - 2.0 * torch.rand(num_resets, device=self._device))\ndof_pos[:, self._pole_dof_idx] = 0.125 * math.pi * (1.0 - 2.0 * torch.rand(num_resets, device=self._device))\ndof_vel[:, self._cart_dof_idx] = 0.5 * (1.0 - 2.0 * torch.rand(num_resets, device=self._device))\ndof_vel[:, self._pole_dof_idx] = 0.25 * math.pi * (1.0 - 2.0 * torch.rand(num_resets, device=self._device))\n\n# apply resets\nindices = env_ids.to(dtype=torch.int32)\nself._cartpoles.set_joint_positions(dof_pos, indices=indices)\nself._cartpoles.set_joint_velocities(dof_vel, indices=indices)\n\n# bookkeeping\nself.reset_buf[env_ids] = 0\nself.progress_buf[env_ids] = 0\n```\n\nLANGUAGE: python\nCODE:\n```\ndefault_root_state[:, :3] += self.scene.env_origins[env_ids]\n\nself.joint_pos[env_ids] = joint_pos\nself.joint_vel[env_ids] = joint_vel\n\nself.cartpole.write_root_pose_to_sim(\n    default_root_state[:, :7], env_ids)\nself.cartpole.write_root_velocity_to_sim(\n    default_root_state[:, 7:], env_ids)\nself.cartpole.write_joint_state_to_sim(\n    joint_pos, joint_vel, None, env_ids)\n```\n\n----------------------------------------\n\nTITLE: Interpreting RSL RL Training Output\nDESCRIPTION: Output format from RSL RL showing detailed metrics including computation speed, loss values, rewards, and timing information for training iterations.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/training_guide.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n                          Learning iteration 0/150\n\n                       Computation: 50355 steps/s (collection: 1.106s, learning 0.195s)\n               Value function loss: 22.0539\n                    Surrogate loss: -0.0086\n             Mean action noise std: 1.00\n                       Mean reward: -5.49\n               Mean episode length: 15.79\n  --------------------------------------------------------------------------------\n                   Total timesteps: 65536\n                    Iteration time: 1.30s\n                        Total time: 1.30s\n                               ETA: 195.2s\n```\n\n----------------------------------------\n\nTITLE: Referencing Isaac Lab Assets in Python\nDESCRIPTION: This snippet demonstrates how to properly reference robot assets from the Isaac Lab assets directory. It imports the ISAACLAB_ASSETS_DATA_DIR constant and uses it to construct paths to robot USD files for ANYmal-C and ANYmal-D robots.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab_assets/docs/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab_assets import ISAACLAB_ASSETS_DATA_DIR\n\n\n# ANYmal-C\nANYMAL_C_USD_PATH = f\"{ISAACLAB_ASSETS_DATA_DIR}/Robots/ANYbotics/ANYmal-C/anymal_c.usd\"\n# ANYmal-D\nANYMAL_D_USD_PATH = f\"{ISAACLAB_ASSETS_DATA_DIR}/Robots/ANYbotics/ANYmal-D/anymal_d.usd\"\n```\n\n----------------------------------------\n\nTITLE: Executing RL Training Headless\nDESCRIPTION: Command for running the RL training script in headless mode, which executes physics simulation without rendering to speed up training.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/run_rl_training.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/sb3/train.py --task Isaac-Cartpole-v0 --num_envs 64 --headless\n```\n\n----------------------------------------\n\nTITLE: Launching Isaac Sim Simulator with AppLauncher\nDESCRIPTION: Shows how to launch the Isaac Sim application using the AppLauncher class, which handles command-line arguments and environment variables for simulation configuration.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/create_empty.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport argparse\nfrom isaaclab.app import AppLauncher\n\n# Parse command line arguments\nparser = argparse.ArgumentParser(description=\"Create an empty stage in Isaac Lab\")\n# Add app launcher command line arguments to parser\napp_launcher = AppLauncher()\napp_launcher.add_app_launcher_args(parser)\nargs, unknown = parser.parse_known_args()\n\n# Launch the simulator\napp_launcher.setup(args)\nsimulation_app = app_launcher.app\n```\n\n----------------------------------------\n\nTITLE: Running Isaac Lab Benchmark Scripts\nDESCRIPTION: Commands for running different benchmark scripts to test environment performance with RSL RL, RL Games, or without RL libraries. Scripts generate KPI files containing startup times, runtime statistics, and environment FPS metrics.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/performance_benchmarks.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# benchmark with RSL RL\npython scripts/benchmarks/benchmark_rsl_rl.py --task=Isaac-Cartpole-v0 --headless\n\n# benchmark with RL Games\npython scripts/benchmarks/benchmark_rlgames.py --task=Isaac-Cartpole-v0 --headless\n\n# benchmark without RL libraries\npython scripts/benchmarks/benchmark_non_rl.py --task=Isaac-Cartpole-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Running Camera Simulation Scripts with Command-line Arguments\nDESCRIPTION: Shows how to execute the camera simulation script with different command-line options for saving images, drawing point clouds, enabling cameras, and running in headless mode.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/save_camera_output.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Usage with saving and drawing\n./isaaclab.sh -p scripts/tutorials/04_sensors/run_usd_camera.py --save --draw --enable_cameras\n\n# Usage with saving only in headless mode\n./isaaclab.sh -p scripts/tutorials/04_sensors/run_usd_camera.py --save --headless --enable_cameras\n```\n\n----------------------------------------\n\nTITLE: Configuring Hyperparameter Tuning in Python\nDESCRIPTION: This script defines the core functionality for tuning aggregate jobs in Isaac Lab. It sets up hyperparameter sweeps and manages the execution of individual jobs based on the sweep configuration.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass JobCfg:\n    \"\"\"Base class for job configuration.\"\"\"\n\n    def __init__(self):\n        self.cfg = None\n\n    def get_sweep(self):\n        \"\"\"Get the hyperparameter sweep configuration.\n\n        Returns:\n            dict: The hyperparameter sweep configuration.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement get_sweep()\")\n\n    def get_base_cfg(self):\n        \"\"\"Get the base configuration.\n\n        Returns:\n            DictConfig: The base configuration.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement get_base_cfg()\")\n\n    def get_run_name(self, trial):\n        \"\"\"Get the run name for a trial.\n\n        Args:\n            trial (Trial): The trial object.\n\n        Returns:\n            str: The run name.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement get_run_name()\")\n```\n\n----------------------------------------\n\nTITLE: Scene Setup in IsaacGymEnvs CartPole Implementation\nDESCRIPTION: Creates simulation environment in IsaacGymEnvs by manually setting up ground plane and creating individual environments with specific spacing. Requires explicit asset loading and parameter configuration.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndef create_sim(self):\n    # set the up axis to be z-up given that assets are y-up by default\n    self.up_axis = self.cfg[\"sim\"][\"up_axis\"]\n                                                                    \n    self.sim = super().create_sim(self.device_id,\n        self.graphics_device_id, self.physics_engine,\n        self.sim_params)\n    self._create_ground_plane()\n    self._create_envs(self.num_envs,\n        self.cfg[\"env\"]['envSpacing'],\n        int(np.sqrt(self.num_envs)))\n                                                                   \ndef _create_ground_plane(self):\n    plane_params = gymapi.PlaneParams()\n    # set the normal force to be z dimension\n    plane_params.normal = (gymapi.Vec3(0.0, 0.0, 1.0)\n        if self.up_axis == 'z'\n        else gymapi.Vec3(0.0, 1.0, 0.0))\n    self.gym.add_ground(self.sim, plane_params)\n                                                                   \ndef _create_envs(self, num_envs, spacing, num_per_row):\n    # define plane on which environments are initialized\n    lower = (gymapi.Vec3(0.5 * -spacing, -spacing, 0.0)\n        if self.up_axis == 'z'\n        else gymapi.Vec3(0.5 * -spacing, 0.0, -spacing))\n    upper = gymapi.Vec3(0.5 * spacing, spacing, spacing)\n                                                                   \n    asset_root = os.path.join(os.path.dirname(\n        os.path.abspath(__file__)), \"../../assets\")\n    asset_file = \"urdf/cartpole.urdf\"\n                                                                   \n    if \"asset\" in self.cfg[\"env\"]:\n        asset_root = os.path.join(os.path.dirname(\n            os.path.abspath(__file__)),\n            self.cfg[\"env\"][\"asset\"].get(\"assetRoot\", asset_root))\n        asset_file = self.cfg[\"env\"][\"asset\"].get(\n            \"assetFileName\", asset_file)\n                                                                   \n    asset_path = os.path.join(asset_root, asset_file)\n    asset_root = os.path.dirname(asset_path)\n    asset_file = os.path.basename(asset_path)\n                                                                   \n    asset_options = gymapi.AssetOptions()\n    asset_options.fix_base_link = True\n    cartpole_asset = self.gym.load_asset(self.sim,\n        asset_root, asset_file, asset_options)\n```\n\n----------------------------------------\n\nTITLE: Finding Robot Joint and Body Indices in IsaacLab\nDESCRIPTION: Uses SceneEntityCfg to resolve joint and body indices for the robot's arm and end-effector. This allows for extracting specific joint positions and body states from the robot's data, ignoring irrelevant parts like the gripper.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_diff_ik.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Specify robot-specific parameters\n# -- robot arm joint and body names\nfranka_arm_joint_names = [\n    \"panda_joint1\",\n    \"panda_joint2\",\n    \"panda_joint3\",\n    \"panda_joint4\",\n    \"panda_joint5\",\n    \"panda_joint6\",\n    \"panda_joint7\",\n]\nfranka_ee_body_name = [\"panda_hand\"]\n\n# -- robot arm joint and body indices\nrobot_arms_cfg = SceneEntityCfg(articulation_name=robot_cfg.name, joint_names=franka_arm_joint_names)\nrobot_ee_cfg = SceneEntityCfg(articulation_name=robot_cfg.name, body_names=franka_ee_body_name)\n\n# -- resolve joint and body indices\narm_joint_ids = robot_arms_cfg.joint_ids.get_resolved_values(scene)[0]\nee_body_id = robot_ee_cfg.body_ids.get_resolved_values(scene)[0]\n```\n\n----------------------------------------\n\nTITLE: Defining Observations Configuration in Cartpole Environment\nDESCRIPTION: Python code snippet showing the ObservationsCfg class definition for the Cartpole environment, including the joint_pos_rel observation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/hydra.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass ObservationsCfg:\n    policy: PolicyCfg = PolicyCfg()\n```\n\n----------------------------------------\n\nTITLE: Executing RL Training Interactively\nDESCRIPTION: Command for running RL training with the Isaac Sim window open for interactive visualization of the training process.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/run_rl_training.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/sb3/train.py --task Isaac-Cartpole-v0 --num_envs 64\n```\n\n----------------------------------------\n\nTITLE: Monitoring Training Progress with TensorBoard\nDESCRIPTION: Command for launching TensorBoard to monitor the training progress and visualize metrics.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/run_rl_training.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p -m tensorboard.main --logdir logs/sb3/Isaac-Cartpole-v0\n```\n\n----------------------------------------\n\nTITLE: Configuring Rigid Object Collections in IsaacLab (Python)\nDESCRIPTION: This code demonstrates how to create a collection of multiple rigid objects (cone, cube, sphere) that can be accessed and modified with a unified API for better performance in IsaacLab simulations.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/multi_asset_spawning.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Create a collection of rigid objects with cone, cube, and sphere\ncollection_cfg = RigidObjectCollectionCfg(\n    prim_path=\"/World/envs/env_.*/ObjectCollection\",\n    rigid_objects={\n        \"cone\": RigidObjectCfg(\n            prim_path=\"\",  # Empty as it's built by the collection\n            spawn=RigidObjectSpawnerCfg(\n                asset_func=make_asset_func(\"cone\"),\n                pose_func=make_random_pose_func(\"cone\", rot_z_range=(-np.pi, np.pi)),\n                collision_group=-1,\n            ),\n        ),\n        \"cube\": RigidObjectCfg(\n            prim_path=\"\",  # Empty as it's built by the collection\n            spawn=RigidObjectSpawnerCfg(\n                asset_func=make_asset_func(\"cube\"),\n                pose_func=make_random_pose_func(\"cube\", rot_z_range=(-np.pi, np.pi)),\n                collision_group=-1,\n            ),\n        ),\n        \"sphere\": RigidObjectCfg(\n            prim_path=\"\",  # Empty as it's built by the collection\n            spawn=RigidObjectSpawnerCfg(\n                asset_func=make_asset_func(\"sphere\"),\n                pose_func=make_random_pose_func(\"sphere\", rot_z_range=(-np.pi, np.pi)),\n                collision_group=-1,\n            ),\n        ),\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Commands for Training and Visualizing the Modified Environment\nDESCRIPTION: Terminal commands for training the modified H1 environment using RL Games and visualizing the trained policy.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/modify_direct_rl_env.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py --task Isaac-H1-Direct-v0 --headless\n```\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/rl_games/play.py --task Isaac-H1-Direct-v0 --num_envs 64\n```\n\n----------------------------------------\n\nTITLE: Ray Caster Sensor Output in Bash\nDESCRIPTION: This snippet shows the typical output of a Ray Caster sensor query. It displays sensor information including the number of meshes, sensors, and rays, as well as the actual hit results data.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/ray_caster.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n-------------------------------\nRay-caster @ '/World/envs/env_.*/Robot/base/lidar_cage':\n        view type            : <class 'isaacsim.core.prims.xform_prim.XFormPrim'>\n        update period (s)    : 0.016666666666666666\n        number of meshes     : 1\n        number of sensors    : 1\n        number of rays/sensor: 18000\n        total number of rays : 18000\nRay cast hit results:  tensor([[[-0.3698,  0.0357,  0.0000],\n        [-0.3698,  0.0357,  0.0000],\n        [-0.3698,  0.0357,  0.0000],\n        ...,\n        [    inf,     inf,     inf],\n        [    inf,     inf,     inf],\n        [    inf,     inf,     inf]]], device='cuda:0')\n-------------------------------\n```\n\n----------------------------------------\n\nTITLE: Disabling Physics Replication for Multi-Asset Environments (Python)\nDESCRIPTION: When using different assets across environments, physics replication must be disabled to ensure proper physics parsing for each unique environment configuration.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/multi_asset_spawning.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create scene with physics replication disabled\nscene_cfg = InteractiveSceneCfg(\n    replicate_physics=False,  # This must be False when using different assets in each env\n)\n```\n\n----------------------------------------\n\nTITLE: Computing CartPole Rewards in IsaacGymEnvs\nDESCRIPTION: Implementation of reward calculation for CartPole environment in IsaacGymEnvs. Uses pole angle, velocity, cart position and velocity to compute rewards and reset conditions.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_32\n\nLANGUAGE: python\nCODE:\n```\ndef compute_reward(self):\n    # retrieve environment observations from buffer\n    pole_angle = self.obs_buf[:, 2]\n    pole_vel = self.obs_buf[:, 3]\n    cart_vel = self.obs_buf[:, 1]\n    cart_pos = self.obs_buf[:, 0]\n\n    self.rew_buf[:], self.reset_buf[:] = compute_cartpole_reward(\n        pole_angle, pole_vel, cart_vel, cart_pos,\n        self.reset_dist, self.reset_buf,\n        self.progress_buf, self.max_episode_length\n    )\n\n@torch.jit.script\ndef compute_cartpole_reward(pole_angle, pole_vel,\n                            cart_vel, cart_pos,\n                            reset_dist, reset_buf,\n                            progress_buf, max_episode_length):\n\n    reward = (1.0 - pole_angle * pole_angle -\n        0.01 * torch.abs(cart_vel) -\n        0.005 * torch.abs(pole_vel))\n\n    # adjust reward for reset agents\n    reward = torch.where(torch.abs(cart_pos) > reset_dist,\n        torch.ones_like(reward) * -2.0, reward)\n    reward = torch.where(torch.abs(pole_angle) > np.pi / 2,\n        torch.ones_like(reward) * -2.0, reward)\n\n    reset = torch.where(torch.abs(cart_pos) > reset_dist,\n        torch.ones_like(reset_buf), reset_buf)\n    reset = torch.where(torch.abs(pole_angle) > np.pi / 2,\n        torch.ones_like(reset_buf), reset_buf)\n    reset = torch.where(progress_buf >= max_episode_length - 1,\n        torch.ones_like(reset_buf), reset)\n```\n\n----------------------------------------\n\nTITLE: Playing the Trained RL Agent\nDESCRIPTION: Command for visualizing the trained agent by loading the latest checkpoint from the logs directory.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/run_rl_training.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/sb3/play.py --task Isaac-Cartpole-v0 --num_envs 32 --use_last_checkpoint\n```\n\n----------------------------------------\n\nTITLE: Running RL Training with Hydra Arguments (skrl)\nDESCRIPTION: Example of running a training script for the Isaac-Cartpole-v0 task using skrl, with Hydra arguments to modify environment and agent parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/hydra.rst#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npython scripts/reinforcement_learning/skrl/train.py --task=Isaac-Cartpole-v0 --headless env.actions.joint_effort.scale=10.0 agent.seed=2024\n```\n\n----------------------------------------\n\nTITLE: Configuring PhysX GPU Buffer Capacity\nDESCRIPTION: Python code snippet showing how to increase the GPU buffer capacity for PhysX simulation to prevent \"PhysX error\" messages when running complex simulations with many collision pairs.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport isaaclab.sim as sim_utils\n\nsim_cfg = sim_utils.SimulationConfig()\nsim_cfg.physx.gpu_found_lost_pairs_capacity = 4096\nsim = SimulationContext(sim_params=sim_cfg)\n```\n\n----------------------------------------\n\nTITLE: Resetting Environment Indices in IsaacGymEnvs\nDESCRIPTION: Function to reset specific environments by their indices in IsaacGymEnvs. It generates random positions and velocities for DOFs, applies them to the specified environments, and resets their progress buffers.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ndef reset_idx(self, env_ids):\n    positions = 0.2 * (torch.rand((len(env_ids), self.num_dof),\n        device=self.device) - 0.5)\n    velocities = 0.5 * (torch.rand((len(env_ids), self.num_dof),\n        device=self.device) - 0.5)\n\n    self.dof_pos[env_ids, :] = positions[:]\n    self.dof_vel[env_ids, :] = velocities[:]\n\n    env_ids_int32 = env_ids.to(dtype=torch.int32)\n    self.gym.set_dof_state_tensor_indexed(self.sim,\n        gymtorch.unwrap_tensor(self.dof_state),\n        gymtorch.unwrap_tensor(env_ids_int32), len(env_ids_int32))\n    self.reset_buf[env_ids] = 0\n    self.progress_buf[env_ids] = 0\n```\n\n----------------------------------------\n\nTITLE: Creating a Standalone Application with Isaac Sim Simulator\nDESCRIPTION: Example of a standalone application that launches the Isaac Sim simulator and directly controls the simulation. This pattern is necessary for applications that need precise control over the simulation lifecycle, such as reinforcement learning.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/developer-guide/development.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Launch Isaac Sim Simulator first.\"\"\"\n\nfrom isaaclab.app import AppLauncher\n\n# launch omniverse app\napp_launcher = AppLauncher(headless=False)\nsimulation_app = app_launcher.app\n\n\n\"\"\"Rest everything follows.\"\"\"\n\nfrom isaaclab.sim import SimulationContext\n\nif __name__ == \"__main__\":\n   # get simulation context\n   simulation_context = SimulationContext()\n   # reset and play simulation\n   simulation_context.reset()\n   # step simulation\n   simulation_context.step()\n   # stop simulation\n   simulation_context.stop()\n\n   # close the simulation\n   simulation_app.close()\n```\n\n----------------------------------------\n\nTITLE: Launching KubeRay Cluster and MLFlow Server (Python)\nDESCRIPTION: Python script snippet demonstrating how to launch a KubeRay cluster and an MLFlow server, specifically highlighting the configuration section (lines 15-37) likely responsible for defining cluster resources and settings, particularly for Google GKE as mentioned in the surrounding text.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n... literalinclude:: ../../../scripts/reinforcement_learning/ray/launch.py\n  :language: python\n  :emphasize-lines: 15-37\n```\n\n----------------------------------------\n\nTITLE: Defining KubeRay Cluster Configuration (Jinja/YAML)\nDESCRIPTION: Reference to a Jinja template file (`kuberay.yaml.ninja`) used for configuring KubeRay cluster resources on Google Cloud. This file defines parameters like node types, scaling, and potentially MLFlow integration, rendered into a YAML configuration for Kubernetes. Note: Although the file is a Jinja template for YAML, the include directive specifies the language as Python.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n... literalinclude:: ../../../scripts/reinforcement_learning/ray/cluster_configs/google_cloud/kuberay.yaml.jinja\n    :language: python\n```\n\n----------------------------------------\n\nTITLE: Spawning a Static Cone Collider in Isaac Sim\nDESCRIPTION: This code snippet demonstrates how to create a static cone collider in the simulation world. It uses the ConeCfg class to define the cone's properties and spawns it at a specific location and orientation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/make_fixed_prim.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport isaaclab.sim as sim_utils\n\ncone_spawn_cfg = sim_utils.ConeCfg(\n    radius=0.15,\n    height=0.5,\n    collision_props=sim_utils.CollisionPropertiesCfg(),\n    visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.0, 1.0, 0.0)),\n)\ncone_spawn_cfg.func(\n    \"/World/Cone\", cone_spawn_cfg, translation=(0.0, 0.0, 2.0), orientation=(0.5, 0.0, 0.5, 0.0)\n)\n```\n\n----------------------------------------\n\nTITLE: Running RL Training with Hydra Arguments (rl_games)\nDESCRIPTION: Example of running a training script for the Isaac-Cartpole-v0 task using rl_games, with Hydra arguments to modify environment and agent parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/hydra.rst#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npython scripts/reinforcement_learning/rl_games/train.py --task=Isaac-Cartpole-v0 --headless env.actions.joint_effort.scale=10.0 agent.params.seed=2024\n```\n\n----------------------------------------\n\nTITLE: Master Node Command for Multi-Node Training with rl_games\nDESCRIPTION: Command for the master node when running RL training with rl_games across multiple machines. Specifies rendezvous settings including ID, backend, and endpoint to coordinate training across nodes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\npython -m torch.distributed.run --nproc_per_node=2 --nnodes=2 --node_rank=0 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=localhost:5555 scripts/reinforcement_learning/rl_games/train.py --task=Isaac-Cartpole-v0 --headless --distributed\n```\n\n----------------------------------------\n\nTITLE: Spawning a Deformable Cuboid in Isaac Lab with Python\nDESCRIPTION: Creates a cuboid with deformable body physics properties, which allows for simulation of soft bodies. This example includes configurations for stiffness, damping, and other physical properties of the deformable object.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/spawn_prims.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# spawn a blue cuboid with deformable body\ncfg_cuboid = sim.spawners.CuboidCfg()\ncfg_cuboid.size = torch.tensor([1.0, 1.0, 1.0])\ncfg_cuboid.visual_material = sim.materials.PreviewSurfaceCfg()\ncfg_cuboid.visual_material.diffuse_color = torch.tensor([0.0, 0.0, 1.0])\n\n# add softbody properties\ncfg_cuboid.deformable_body_properties = sim.physics.DeformableBodyPropertiesCfg()\ncfg_cuboid.deformable_body_properties.particle_spacing = 0.2\ncfg_cuboid.deformable_body_properties.solver_position_iteration_count = 4\ncfg_cuboid.deformable_body_properties.solver_velocity_iteration_count = 1\ncfg_cuboid.deformable_body_properties.stiffness = 0.1\ncfg_cuboid.deformable_body_properties.position_smoothing = 0.3\ncfg_cuboid.deformable_body_properties.damping_scale = 0.0\ncfg_cuboid.deformable_body_properties.particle_mass = 2.0\ncfg_cuboid.deformable_body_properties.volume_sampling = \"hexahedral\"\n\n# softbody can only be simulated on GPU\ncfg_cuboid.func(\"/World/Objects/CuboidDeformable\", cfg_cuboid, translation=(3.0, 3.0, 2.0))\n```\n\n----------------------------------------\n\nTITLE: Example Hyperparameter Tuning Configuration (Python)\nDESCRIPTION: Reference to an example Python script (`vision_cartpole_cfg.py`) demonstrating how to use the `JobCfg` class to configure a specific hyperparameter tuning task for a vision-based Cartpole environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n... literalinclude:: ../../../scripts/reinforcement_learning/ray/hyperparameter_tuning/vision_cartpole_cfg.py\n  :language: python\n```\n\n----------------------------------------\n\nTITLE: Implementing PD Controller with Feed-Forward in Mathematical Form\nDESCRIPTION: Mathematical representation of an ideal explicit actuator model using PD control with feed-forward effort and torque clipping. The formula shows how joint torques are computed based on position and velocity errors, and then clipped to respect maximum effort constraints.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/actuators.rst#2025-04-23_snippet_0\n\nLANGUAGE: math\nCODE:\n```\n\\tau_{j, computed} & = k_p * (q_{des} - q) + k_d * (\\dot{q}_{des} - \\dot{q}) + \\tau_{ff} \\\\\n\\tau_{j, applied} & = clip(\\tau_{computed}, -\\tau_{j, max}, \\tau_{j, max})\n```\n\n----------------------------------------\n\nTITLE: Creating Ray Clusters on Google GKE in Python\nDESCRIPTION: This script provides functionality to easily create Ray clusters on Google Kubernetes Engine (GKE) for use with Isaac Lab.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef create_gke_cluster(cluster_name, node_count, machine_type):\n    \"\"\"Create a GKE cluster for Ray.\n\n    Args:\n        cluster_name (str): The name of the cluster.\n        node_count (int): The number of nodes in the cluster.\n        machine_type (str): The machine type for the nodes.\n\n    Returns:\n        str: The cluster creation status.\n    \"\"\"\n    # Set up gcloud command\n    cmd = [\n        'gcloud', 'container', 'clusters', 'create', cluster_name,\n        f'--num-nodes={node_count}',\n        f'--machine-type={machine_type}',\n        '--zone=us-central1-a',\n        '--project=your-project-id'\n    ]\n\n    # Run the command\n    result = subprocess.run(cmd, capture_output=True, text=True)\n\n    if result.returncode == 0:\n        return \"Cluster created successfully\"\n    else:\n        return f\"Error creating cluster: {result.stderr}\"\n```\n\n----------------------------------------\n\nTITLE: Running Quadruped Locomotion Environment Script in Isaac Lab (Bash)\nDESCRIPTION: This bash command uses the Isaac Lab wrapper script (`isaaclab.sh`) to execute a Python tutorial script (`scripts/tutorials/03_envs/create_quadruped_base_env.py`). The `-p` flag indicates the target script, which sets up a quadrupedal locomotion environment where a policy interacts with it. The `--num_envs 32` argument specifies that 32 instances of the environment should be simulated in parallel.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_base_env.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Quadrupedal locomotion environment with a policy that interacts with the environment\n./isaaclab.sh -p scripts/tutorials/03_envs/create_quadruped_base_env.py --num_envs 32\n```\n\n----------------------------------------\n\nTITLE: Verifying Isaac Lab Installation (Linux)\nDESCRIPTION: These commands verify the successful installation of Isaac Lab on Linux by running a simple script to create an empty simulation. Two options are provided: using the isaaclab.sh executable or using python in a virtual environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n# Option 1: Using the isaaclab.sh executable\n# note: this works for both the bundled python and the virtual environment\n./isaaclab.sh -p scripts/tutorials/00_sim/create_empty.py\n\n# Option 2: Using python in your virtual environment\npython scripts/tutorials/00_sim/create_empty.py\n```\n\n----------------------------------------\n\nTITLE: Training and Playing Multi-Agent SKRL on Isaac-Shadow-Hand-Over-Direct-v0 in Linux\nDESCRIPTION: Commands for installing SKRL and training multi-agent systems on the Isaac-Shadow-Hand-Over-Direct-v0 environment in Linux using MAPPO or IPPO algorithms.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# install python module (for skrl)\n./isaaclab.sh -i skrl\n# run script for training with the MAPPO algorithm (IPPO is also supported)\n./isaaclab.sh -p scripts/reinforcement_learning/skrl/train.py --task Isaac-Shadow-Hand-Over-Direct-v0 --headless --algorithm MAPPO\n# run script for playing with 32 environments with the MAPPO algorithm (IPPO is also supported)\n./isaaclab.sh -p scripts/reinforcement_learning/skrl/play.py --task Isaac-Shadow-Hand-Over-Direct-v0 --num_envs 32 --algorithm MAPPO --checkpoint /PATH/TO/model.pt\n```\n\n----------------------------------------\n\nTITLE: Configuring Ray Caster Sensor in Python\nDESCRIPTION: This snippet demonstrates how to configure a Ray Caster sensor with a LIDAR pattern. It sets up the sensor's properties including field of view, resolution, and visualization options.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/ray_caster.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Create ray caster sensor\npattern_config = {\n    \"pattern_name\": \"lidar\",\n    \"horizontal_fov\": 180.0,\n    \"vertical_fov\": 90.0,\n    \"horizontal_resolution\": 1.0,\n    \"vertical_resolution\": 1.0,\n    \"min_range\": 0.01,\n    \"max_range\": 100,\n    \"draw_points\": True,\n    \"draw_lines\": True,\n    \"num_prims\": 1,\n    \"prim_names\": [\"plane\"],\n}\n\nscene.add(\n    RayCasterSensor(\n        prim_path=\"/World/envs/env_0/Robot/base/lidar_cage\",\n        name=\"ray_caster\",\n        position=carb.Float3(0.0, 0.0, 1.05),\n        orientation=carb.Float4(0.0, 0.0, 0.0, 1.0),\n        pattern_config=pattern_config,\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Executing Sensor Tutorial Python Scripts with Isaac Lab Shell - Shell\nDESCRIPTION: These shell command snippets show how to execute individual sensor tutorial Python scripts using the 'isaaclab.sh' shell wrapper. Each command launches a different script under 'scripts/tutorials/04_sensors/', responsible for various sensor simulations in Isaac Lab. Some commands include comments indicating the script's focus (e.g., Ray Caster or USD Camera), and additional arguments (like '--enable_cameras') may be provided to enable specific simulation features. Inputs include the relative path to each tutorial script and optional flags; the output is the simulation environment running the chosen sensor functionality. The shell script assumes proper setup of the Isaac Lab environment and Python dependencies.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/04_sensors/add_sensors_on_robot.rst#2025-04-23_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n./isaaclab.sh -p scripts/tutorials/04_sensors/run_frame_transformer.py\n```\n\nLANGUAGE: shell\nCODE:\n```\n# Ray Caster\n./isaaclab.sh -p scripts/tutorials/04_sensors/run_ray_caster.py\n```\n\nLANGUAGE: shell\nCODE:\n```\n# Ray Caster Camera\n./isaaclab.sh -p scripts/tutorials/04_sensors/run_ray_caster_camera.py\n```\n\nLANGUAGE: shell\nCODE:\n```\n# USD Camera\n./isaaclab.sh -p scripts/tutorials/04_sensors/run_usd_camera.py --enable_cameras\n```\n\n----------------------------------------\n\nTITLE: Verifying Isaac Lab Installation (Linux)\nDESCRIPTION: Commands to verify the successful installation of Isaac Lab on Linux by running a sample script.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\n# Option 1: Using the isaaclab.sh executable\n# note: this works for both the bundled python and the virtual environment\n./isaaclab.sh -p scripts/tutorials/00_sim/create_empty.py\n\n# Option 2: Using python in your virtual environment\npython scripts/tutorials/00_sim/create_empty.py\n```\n\n----------------------------------------\n\nTITLE: Updating and Printing Deformable Object State in IsaacLab (Python)\nDESCRIPTION: This snippet updates the in-memory buffers of the deformable object by calling its update method, and prints the computed root position (average node position) in the world frame. Used typically after stepping the simulation, it helps monitor object positions, although the concept of 'root' is not native for deformables. Requires the DeformableObject.data API and the object to be advanced at least once in the simulation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_deformable_object.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# update buffers\ncube_object.update()\nprint(f\"Root position (in world): {cube_object.data.root_pos_w[:, :3]}\")\n```\n\n----------------------------------------\n\nTITLE: Spawning Visual Cone Primitives in Isaac Lab with Python\nDESCRIPTION: Demonstrates how to spawn purely visual cone primitives with different colors and positions using the ConeCfg class, without physics properties enabled.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/spawn_prims.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# spawn a red cone\ncfg_cone = sim.spawners.ConeCfg()\ncfg_cone.radius = 0.5\ncfg_cone.height = 1.0\ncfg_cone.visual_material = sim.materials.PreviewSurfaceCfg()\ncfg_cone.visual_material.diffuse_color = torch.tensor([1.0, 0.0, 0.0])\ncfg_cone.func(\"/World/Objects/Cone1\", cfg_cone, translation=(1.0, 1.0, 1.0))\n\n# spawn another cone with different color\ncfg_cone.visual_material.diffuse_color = torch.tensor([1.0, 1.0, 0.0])\ncfg_cone.func(\"/World/Objects/Cone2\", cfg_cone, translation=(-1.0, -1.0, 1.0))\n```\n\n----------------------------------------\n\nTITLE: Creating an Xform Transform Container in Isaac Lab with Python\nDESCRIPTION: Creates a transform primitive (Xform) that serves as a container to group multiple objects together, allowing them to be transformed as a unit.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/spawn_prims.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# create a new xform prim for all objects to be spawned under\nprim_utils.create_prim(\"/World/Objects\", \"Xform\")\n```\n\n----------------------------------------\n\nTITLE: Running an Example in Isaac Lab Container\nDESCRIPTION: Command to run a simple example script within the Isaac Lab container in headless mode. Uses the isaaclab.sh script to execute a time logging example.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/docker.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/tutorials/00_sim/log_time.py --headless\n```\n\n----------------------------------------\n\nTITLE: Configuring the H1 Robot in Environment Configuration\nDESCRIPTION: Code snippet showing how to replace the original humanoid robot with the Unitree H1 robot in the environment configuration, including joint gear settings.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/modify_direct_rl_env.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# robot definition and configuration\nrobot = UnitreeH1()\nrobot.default_state.joint_positions = torch.zeros(24)\nrobot.default_state.joint_positions = robot.default_state.default_joint_pos\n\n# torque = gear * motor_torque\n# motor_torque proportional to action command\n# See simulator.articulation_class._compute_torque for details\njoint_gears = [60.0] * 24\n```\n\n----------------------------------------\n\nTITLE: Verifying Isaac Sim Python Environment on Windows\nDESCRIPTION: Performs two checks on Windows using the Isaac Sim Python executable defined by ISAACSIM_PYTHON_EXE. The first command verifies the Python path configuration by printing a success message. The second command checks if Isaac Sim can be launched from a standalone Python script by running an example.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_5\n\nLANGUAGE: batch\nCODE:\n```\n:: checks that python path is set correctly\n%ISAACSIM_PYTHON_EXE% -c \"print('Isaac Sim configuration is now complete.')\"\n:: checks that Isaac Sim can be launched from python\n%ISAACSIM_PYTHON_EXE% %ISAACSIM_PATH%\\standalone_examples\\api\\isaacsim.core.api\\add_cubes.py\n```\n\n----------------------------------------\n\nTITLE: Running Floating Cube Environment Script in Isaac Lab (Bash)\nDESCRIPTION: This bash command executes the Isaac Lab wrapper script (`isaaclab.sh`) to run a specific Python tutorial script (`scripts/tutorials/03_envs/create_cube_base_env.py`). The `-p` flag specifies the path to the Python script, which defines a floating cube environment with a custom action term for PD control. The `--num_envs 32` argument configures the simulation to run 32 parallel environments.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_base_env.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# Floating cube environment with custom action term for PD control\n./isaaclab.sh -p scripts/tutorials/03_envs/create_cube_base_env.py --num_envs 32\n```\n\n----------------------------------------\n\nTITLE: Launching Isaac Sim with Specific Experience File - Bash\nDESCRIPTION: Launches the Isaac Sim application with an explicitly provided experience file. The experience file argument can be an absolute or relative path; when relative, Isaac Sim searches predefined directories. Isaac Sim and dependencies must already be installed. Output is the simulator running a selected experience configuration.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# experience files can be absolute path, or relative path searched in isaacsim/apps or omni/apps\nisaacsim isaacsim.exp.full.kit\n```\n\n----------------------------------------\n\nTITLE: Installing CUDA 12-Compatible PyTorch via Pip - Bash\nDESCRIPTION: This command installs CUDA 12.1 compatible wheels for PyTorch 2.5.1 and torchvision 0.20.1 from the specified PyTorch index URL. Use this for CUDA 12-enabled systems prior to running Isaac Sim or Isaac Lab. Dependencies include a pre-installed compatible CUDA 12 driver.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu121\n```\n\n----------------------------------------\n\nTITLE: Retrieving Instance Segmentation Information in ISAAC Sim with Python\nDESCRIPTION: Shows how to access the info dictionary from the instance segmentation data. This retrieves mappings from IDs to labels and semantic information from a tiled camera.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/camera.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntiled_camera.data.info['instance_segmentation_fast']\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard for Log Visualization in Isaac Lab (Linux)\nDESCRIPTION: Executes TensorBoard using `isaaclab.sh` to visualize training logs stored in the default `logs` directory. This command should be run from the root directory of the Isaac Lab repository on a Linux system. It utilizes the `-p` flag to pass arguments to the python interpreter and `-m` to run the tensorboard module.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# execute from the root directory of the repository\n./isaaclab.sh -p -m tensorboard.main --logdir=logs\n```\n\n----------------------------------------\n\nTITLE: Contact Sensor Console Output for Front Feet\nDESCRIPTION: Console output showing the contact sensor data for the front feet of the Anymal Quadruped. It displays the net contact forces and force matrices, demonstrating how filtering works with the left foot detecting contact with the Cube while the right foot doesn't.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/contact_sensor.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n-------------------------------\nContact sensor @ '/World/envs/env_.*/Robot/LF_FOOT':\n        view type         : <class 'omni.physics.tensors.impl.api.RigidBodyView'>\n        update period (s) : 0.0\n        number of bodies  : 1\n        body names        : ['LF_FOOT']\n\nReceived force matrix of:  tensor([[[[-1.3923e-05,  1.5727e-04,  1.1032e+02]]]], device='cuda:0')\nReceived contact force of:  tensor([[[-1.3923e-05,  1.5727e-04,  1.1032e+02]]], device='cuda:0')\n-------------------------------\nContact sensor @ '/World/envs/env_.*/Robot/RF_FOOT':\n        view type         : <class 'omni.physics.tensors.impl.api.RigidBodyView'>\n        update period (s) : 0.0\n        number of bodies  : 1\n        body names        : ['RF_FOOT']\n\nReceived force matrix of:  tensor([[[[0., 0., 0.]]]], device='cuda:0')\nReceived contact force of:  tensor([[[1.3529e-05, 0.0000e+00, 1.0069e+02]]], device='cuda:0')\n```\n\n----------------------------------------\n\nTITLE: Worker Node Command for Multi-Node Training with rsl_rl\nDESCRIPTION: Command for non-master (worker) nodes when running RL training with RSL-RL across multiple machines. Connects to the master node using its IP address and the specified port.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\npython -m torch.distributed.run --nproc_per_node=2 --nnodes=2 --node_rank=1 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=ip_of_master_machine:5555 scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --headless --distributed\n```\n\n----------------------------------------\n\nTITLE: Running Isaac Sim Simulator on Linux\nDESCRIPTION: Executes the Isaac Sim simulator startup script on Linux using the ISAACSIM_PATH environment variable. This command verifies that the simulator can be launched. The optional '--help' argument can be passed to see available command-line options.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# note: you can pass the argument \"--help\" to see all arguments possible.\n${ISAACSIM_PATH}/isaac-sim.sh\n```\n\n----------------------------------------\n\nTITLE: Configuring a Ground Plane Using TerrainImporterCfg (Python)\nDESCRIPTION: Shows the definition and instantiation of a ground plane in Isaac Lab using TerrainImporterCfg. The class allows specification of properties such as friction, restitution, collision groups, and physics material via nested config classes. Requires isaaclab.terrains, sim_utils, and a valid simulation context. The created terrain object must be attached to the correct prim_path in the scene tree. Inputs: parameterized config instances; Outputs: terrain instance ready for scene attachment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.terrains import TerrainImporterCfg\n\nterrain = TerrainImporterCfg(\n     prim_path=\"/World/ground\",\n     terrain_type=\"plane\",\n     collision_group=-1,\n     physics_material=sim_utils.RigidBodyMaterialCfg(\n         friction_combine_mode=\"multiply\",\n         restitution_combine_mode=\"multiply\",\n         static_friction=1.0,\n         dynamic_friction=1.0,\n         restitution=0.0,\n     ),\n )\n```\n\n----------------------------------------\n\nTITLE: Configuring Cartpole Environment in YAML (IsaacGymEnvs)\nDESCRIPTION: YAML configuration for the Cartpole environment in IsaacGymEnvs, specifying simulation parameters, asset details, and physics settings.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\n# used to create the object\nname: Cartpole\n\nphysics_engine: ${..physics_engine}\n\n# if given, will override the device setting in gym.\nenv:\n  numEnvs: ${resolve_default:512,${...num_envs}}\n  envSpacing: 4.0\n  resetDist: 3.0\n  maxEffort: 400.0\n\n  clipObservations: 5.0\n  clipActions: 1.0\n\n  asset:\n    assetRoot: \"../../assets\"\n    assetFileName: \"urdf/cartpole.urdf\"\n\n  enableCameraSensors: False\n\nsim:\n  dt: 0.0166 # 1/60 s\n  substeps: 2\n  up_axis: \"z\"\n  use_gpu_pipeline: ${eq:${...pipeline},\"gpu\"}\n  gravity: [0.0, 0.0, -9.81]\n  physx:\n    num_threads: ${....num_threads}\n    solver_type: ${....solver_type}\n    use_gpu: ${contains:\"cuda\",${....sim_device}}\n    num_position_iterations: 4\n    num_velocity_iterations: 0\n    contact_offset: 0.02\n    rest_offset: 0.001\n    bounce_threshold_velocity: 0.2\n    max_depenetration_velocity: 100.0\n    default_buffer_size_multiplier: 2.0\n    max_gpu_contact_pairs: 1048576 # 1024*1024\n    num_subscenes: ${....num_subscenes}\n    contact_collection: 0\n```\n\n----------------------------------------\n\nTITLE: Training a Robot Dog with Isaac Lab (Linux)\nDESCRIPTION: Command to train a robot dog using Isaac Lab's reinforcement learning capabilities on Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Velocity-Rough-Anymal-C-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Installing Isaac Sim via Pip - none\nDESCRIPTION: Installs the Isaac Sim Python package version 4.5.0 with all extension and extension cache extras using pip. The '--extra-index-url' option specifies an additional package repository for NVIDIA-hosted wheels. This command can be run on both Windows and Linux. Successful execution results in Isaac Sim being available to the current Python environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_7\n\nLANGUAGE: none\nCODE:\n```\npip install 'isaacsim[all,extscache]==4.5.0' --extra-index-url https://pypi.nvidia.com\n```\n\n----------------------------------------\n\nTITLE: Creating and Processing 3D Point Clouds from Depth Camera\nDESCRIPTION: Shows how to create a point cloud from depth camera data and prepare it for visualization. This code handles cropping the point cloud to the visible region and filtering out invalid points.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/save_camera_output.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Derive pointcloud from camera at camera_index\npointcloud = create_pointcloud_from_depth(\n    camera_index,\n    camera.data.output[\"distance_to_image_plane\"],\n    camera.data.intrinsic_matrices,\n    camera.data.pos_w,\n    camera.data.quat_w_ros,\n)\n\n# Crop to visible region\nbounds = [(-30, 30), (-1, 20), (-30, 30)]\nvalid_indices = torch.ones(pointcloud.shape[0], dtype=torch.bool, device=pointcloud.device)\nfor i, (lower, upper) in enumerate(bounds):\n    valid_indices = valid_indices & (pointcloud[:, i] > lower) & (pointcloud[:, i] < upper)\npointcloud = pointcloud[valid_indices]\n```\n\n----------------------------------------\n\nTITLE: Benchmarking Tiled Cameras in Cartpole Environment\nDESCRIPTION: Command to test performance with 100 tiled cameras in the Cartpole environment, using 2 cameras per environment (50 environments total) in RGB mode only.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/estimate_how_many_cameras_can_run.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/benchmarks/benchmark_cameras.py \\\n--task Isaac-Cartpole-v0 --num_tiled_cameras 100 \\\n--task_num_cameras_per_env 2 \\\n--tiled_camera_data_types rgb\n```\n\n----------------------------------------\n\nTITLE: Accessing PhysX Views in Python\nDESCRIPTION: Shows how to access PhysX views instead of deprecated Isaac Sim view classes. This change removes dependencies on Isaac Sim view classes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# Instead of:\n# root_view\n# body_view\n\n# Use:\nroot_physx_view\nbody_physx_view\n```\n\n----------------------------------------\n\nTITLE: Conflicting Environment Variable and CLI Arg Resolution - Console\nDESCRIPTION: This snippet executes the simulation while setting a LIVESTREAM environment variable to 0 but overrides it with a CLI argument (\"--livestream 2\"). AppLauncher ensures CLI arguments take priority over environment variables, demonstrating conflict resolution. The cuboid size is specified and the launch occurs in the same way as previous runs.\n\nRequires the isaaclab.sh launcher and a properly configured IsaacLab environment. CLI values will override any conflicting environment settings for AppLauncher.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/launch_app.rst#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nLIVESTREAM=0 ./isaaclab.sh -p scripts/tutorials/00_sim/launch_app.py --size 0.5 --livestream 2\n```\n\n----------------------------------------\n\nTITLE: Resetting Isaac Sim User Data on Windows\nDESCRIPTION: Runs the Isaac Sim simulator startup batch script on Windows with the '--reset-user' flag. This command should be run the first time after installing a new version of Isaac Sim (if a previous version existed) to clear old user data and cached variables. Requires the ISAACSIM_PATH environment variable to be set.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_7\n\nLANGUAGE: batch\nCODE:\n```\n%ISAACSIM_PATH%\\isaac-sim.bat --reset-user\n```\n\n----------------------------------------\n\nTITLE: Configuring Simple Gaussian Noise Model in Python\nDESCRIPTION: This code shows how to configure a simple Gaussian noise model for actions using GaussianNoiseCfg. It adds per-step noise to the action buffer without a separate bias term.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_direct_rl_env.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass MyTaskConfig:\n  action_noise_model: GaussianNoiseCfg = GaussianNoiseCfg(mean=0.0, std=0.05, operation=\"add\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Observations for Cartpole Environment in Python\nDESCRIPTION: This code defines an ObservationsCfg class that configures what state information is observable by the agent. It creates a 'policy' observation group with two terms: joint positions and joint velocities of the cartpole.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/create_manager_base_env.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass ObservationsCfg(ManagerBasedEnvCfg.ObservationsCfg):\n    \"\"\"Configuration for observations.\"\"\"\n\n    def __post_init__(self):\n        \"\"\"Initialize observation terms.\"\"\"\n        # Create the \"policy\" observation group\n        # The name policy is used by default in various wrappers provided by Isaac Lab\n        self.policy = ObservationGroupCfg(\n            # Whether to concatenate all terms or not: True -> returns one tensor, False -> returns a dict\n            enable_corruption=False,\n            concatenate_terms=True\n        )\n\n        # Create the observation terms\n        # Joint positions\n        self.policy.joint_pos = ObservationTermCfg(\n            # Reference: Used to get a reference to the asset path\n            func=asset_state_obs_func(\"cartpole\", joint_pos=True, joint_vel=False, dtype=\"float\"),\n        )\n\n        # Joint velocities\n        self.policy.joint_vel = ObservationTermCfg(\n            # Reference: Used to get a reference to the asset path\n            func=asset_state_obs_func(\"cartpole\", joint_pos=False, joint_vel=True, dtype=\"float\"),\n        )\n```\n\n----------------------------------------\n\nTITLE: Importing Required Modules for Environment Registration\nDESCRIPTION: Code snippet showing the necessary imports for registering a new environment in the __init__.py file of the humanoid module.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/modify_direct_rl_env.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.environments.registration import make, register\n\n# Import task modules\nfrom isaaclab_tasks.direct.humanoid.humanoid_env import HumanoidEnv, HumanoidEnvCfg\nfrom isaaclab_tasks.direct.humanoid.h1_env import H1Env, H1EnvCfg\n```\n\n----------------------------------------\n\nTITLE: Running the Isaac Automator Docker Container - Windows Batch\nDESCRIPTION: This batch command launches the Isaac Automator Docker container interactively on Windows, mapping the current directory into '/app' within the container. The '--rm' flag ensures the container is removed upon exit, and it uses the 'isa' image created earlier.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_6\n\nLANGUAGE: batch\nCODE:\n```\ndocker run --platform linux/x86_64 -it --rm -v .:/app isa bash\n```\n\n----------------------------------------\n\nTITLE: Running Isaac Lab Container with Interactive Bash\nDESCRIPTION: Command to run the pre-built Isaac Lab container with an interactive bash session. Maps various cache and data directories as volumes and enables GPU access with proper environment variables for EULA and privacy consent.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/docker.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --name isaac-lab --entrypoint bash -it --gpus all -e \"ACCEPT_EULA=Y\" --rm --network=host \\\n   -e \"PRIVACY_CONSENT=Y\" \\\n   -v ~/docker/isaac-sim/cache/kit:/isaac-sim/kit/cache:rw \\\n   -v ~/docker/isaac-sim/cache/ov:/root/.cache/ov:rw \\\n   -v ~/docker/isaac-sim/cache/pip:/root/.cache/pip:rw \\\n   -v ~/docker/isaac-sim/cache/glcache:/root/.cache/nvidia/GLCache:rw \\\n   -v ~/docker/isaac-sim/cache/computecache:/root/.nv/ComputeCache:rw \\\n   -v ~/docker/isaac-sim/logs:/root/.nvidia-omniverse/logs:rw \\\n   -v ~/docker/isaac-sim/data:/root/.local/share/ov/data:rw \\\n   -v ~/docker/isaac-sim/documents:/root/Documents:rw \\\n   nvcr.io/nvidia/isaac-lab:2.0.2\n```\n\n----------------------------------------\n\nTITLE: Visualizing Point Clouds with Debug Markers\nDESCRIPTION: Demonstrates how to visualize the 3D point clouds in the Isaac Sim viewport using debug markers. This creates markers for each point in the cloud with a specified size and color.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/save_camera_output.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# In the first few steps, things are still being instanced and Camera.data\n# may not have been initialized yet\nif len(pointcloud) > 0:\n    # Visualize point cloud with debug markers\n    if pc_markers is None:\n        pc_markers = DebugPointCloudMarkers(\n            translations=pointcloud,\n            colors=colors,\n            scale=0.05,\n            name=\"pointcloud\",\n        )\n    pc_markers.visualize(translations=pointcloud)\n```\n\n----------------------------------------\n\nTITLE: Testing Camera Performance with Random Objects Without Task Environment\nDESCRIPTION: Command to assess performance of 2 standard cameras viewing 100 random objects, capturing instance segmentation and normals data types with 100x100 resolution images.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/estimate_how_many_cameras_can_run.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/benchmarks/benchmark_cameras.py \\\n--height 100 --width 100 --num_standard_cameras 2 \\\n--standard_camera_data_types instance_segmentation_fast normals --num_objects 100 \\\n--experiment_length 100\n```\n\n----------------------------------------\n\nTITLE: Comparison of Simulation Configuration between IsaacGymEnvs and Isaac Lab\nDESCRIPTION: A side-by-side comparison of simulation configuration syntax between IsaacGymEnvs (YAML) and Isaac Lab (Python). Shows changes in parameter naming and structure, particularly in PhysX configuration.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# IsaacGymEnvs\nsim:\n  dt: 0.0166 # 1/60 s\n  substeps: 2\n  up_axis: \"z\"\n  use_gpu_pipeline: ${eq:${...pipeline},\"gpu\"}\n  gravity: [0.0, 0.0, -9.81]\n  physx:\n    num_threads: ${....num_threads}\n    solver_type: ${....solver_type}\n    use_gpu: ${contains:\"cuda\",${....sim_device}}\n    num_position_iterations: 4\n    num_velocity_iterations: 0\n    contact_offset: 0.02\n    rest_offset: 0.001\n    bounce_threshold_velocity: 0.2\n    max_depenetration_velocity: 100.0\n    default_buffer_size_multiplier: 2.0\n    max_gpu_contact_pairs: 1048576 # 1024*1024\n    num_subscenes: ${....num_subscenes}\n    contact_collection: 0\n```\n\nLANGUAGE: python\nCODE:\n```\n# IsaacLab\nsim: SimulationCfg = SimulationCfg(\n  device = \"cuda:0\" # can be \"cpu\", \"cuda\", \"cuda:<device_id>\"\n  dt=1 / 120,\n  # decimation will be set in the task config\n  # up axis will always be Z in isaac sim\n  # use_gpu_pipeline is deduced from the device\n  gravity=(0.0, 0.0, -9.81),\n  physx: PhysxCfg = PhysxCfg(\n      # num_threads is no longer needed\n      solver_type=1,\n      # use_gpu is deduced from the device\n      max_position_iteration_count=4,\n      max_velocity_iteration_count=0,\n      # moved to actor config\n      # moved to actor config\n      bounce_threshold_velocity=0.2,\n      # moved to actor config\n      # default_buffer_size_multiplier is no longer needed\n      gpu_max_rigid_contact_count=2**23\n      # num_subscenes is no longer needed\n      # contact_collection is no longer needed\n  )\n)\n```\n\n----------------------------------------\n\nTITLE: Customizing Simulation Viewport Resolution - Console\nDESCRIPTION: This command shows launching the simulation with the LIVESTREAM environment variable enabled, while also specifying custom viewport width and height via CLI arguments. These are forwarded by AppLauncher to the underlying SimulationApp, resulting in high-resolution simulation output. The cuboid size is defined for the scenario.\n\nDependencies: IsaacLab setup with scripts available. Key parameters include LIVESTREAM, --size, --width, --height. This allows collection of high-res simulation video or testing performance at different resolutions.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/launch_app.rst#2025-04-23_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nLIVESTREAM=2 ./isaaclab.sh -p scripts/tutorials/00_sim/launch_app.py --size 0.5 --width 1920 --height 1080\n```\n\n----------------------------------------\n\nTITLE: Installing Apptainer on Ubuntu\nDESCRIPTION: Commands to install Apptainer package manager on Ubuntu for converting Docker images to Singularity format\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/cluster.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt update\nsudo apt install -y software-properties-common\nsudo add-apt-repository -y ppa:apptainer/ppa\nsudo apt update\nsudo apt install -y apptainer\n```\n\n----------------------------------------\n\nTITLE: Running Multi-GPU Training with skrl and JAX in Isaac Lab\nDESCRIPTION: Command to launch distributed RL training using skrl library with JAX backend across multiple GPUs on a single machine. Uses skrl's distributed utility for JAX instead of torch.distributed.run to initialize the training across GPUs.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npython -m skrl.utils.distributed.jax --nnodes=1 --nproc_per_node=2 scripts/reinforcement_learning/skrl/train.py --task=Isaac-Cartpole-v0 --headless --distributed --ml_framework jax\n```\n\n----------------------------------------\n\nTITLE: Converting MLFlow Logs to Local TensorBoard (Bash)\nDESCRIPTION: Command to run a script (`mlflow_to_local_tensorboard.py`) using the `isaaclab.sh` wrapper. This script connects to the specified MLFlow server URI (e.g., the port-forwarded address), downloads logs for a given experiment name, and converts them into TensorBoard format in a local directory.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/ray/mlflow_to_local_tensorboard.py \\\n--uri http://localhost:5000 --experiment-name IsaacRay-<CLASS_JOB_CFG>-tune --download-dir test\n```\n\n----------------------------------------\n\nTITLE: Defining Reset Event Configuration in Cartpole Environment\nDESCRIPTION: Python code snippet showing the configuration for the reset_cart_position event in the Cartpole environment, including the position_range parameter.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/hydra.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nreset_cart_position: EventCfg = EventCfg(\n    name=\"reset_cart_position\",\n    func=reset_cart_position,\n    trigger=EventTrigger.RESET,\n    params={\n        \"position_range\": (-2.0, 2.0),\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Copying Artifacts from Docker Container to Host\nDESCRIPTION: Command to copy logs and other artifacts from the Docker container to the host machine, allowing access to results after container execution.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n./container.py copy\n```\n\n----------------------------------------\n\nTITLE: Sample Docker Container List Output\nDESCRIPTION: Example output from the docker container ls command showing a running Isaac Lab container.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nCONTAINER ID   IMAGE               COMMAND   CREATED           STATUS         PORTS     NAMES\n483d1d5e2def   isaac-lab-base      \"bash\"    30 seconds ago   Up 30 seconds             isaac-lab-base\n```\n\n----------------------------------------\n\nTITLE: Querying Frame Transformer Sensor Data in Python\nDESCRIPTION: Demonstrates how to query the Frame Transformer sensor during simulation to retrieve relative transform and orientation data. The code shows how to access the target positions and quaternions relative to the source frame.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/frame_transformer.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef run_simulator(sim: sim_utils.SimulationContext, scene: InteractiveScene):\n  .\n  .\n  .\n  # Simulate physics\n  while simulation_app.is_running():\n    .\n    .\n    .\n\n    # print information from the sensors\n    print(\"-------------------------------\")\n    print(scene[\"specific_transforms\"])\n    print(\"relative transforms:\", scene[\"specific_transforms\"].data.target_pos_source)\n    print(\"relative orientations:\", scene[\"specific_transforms\"].data.target_quat_source)\n    print(\"-------------------------------\")\n    print(scene[\"cube_transform\"])\n    print(\"relative transform:\", scene[\"cube_transform\"].data.target_pos_source)\n    print(\"-------------------------------\")\n    print(scene[\"robot_transforms\"])\n    print(\"relative transforms:\", scene[\"robot_transforms\"].data.target_pos_source)\n```\n\n----------------------------------------\n\nTITLE: Running an Isaac Lab Task with an RL Library (Bash)\nDESCRIPTION: Runs a training script associated with a specific Reinforcement Learning (RL) library, targeting a particular task (`<TASK_NAME>`). The `<RL_LIBRARY>` placeholder should be replaced with the actual library name (e.g., `rsl_rl`). Requires the project and Isaac Lab to be installed. Use the Isaac Lab script (`isaaclab.sh|bat -p`) if Isaac Lab isn't in the Python environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/templates/external/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# use 'FULL_PATH_TO_isaaclab.sh|bat -p' instead of 'python' if Isaac Lab is not installed in Python venv or conda\npython scripts/<RL_LIBRARY>/train.py --task=<TASK_NAME>\n```\n\n----------------------------------------\n\nTITLE: Comparison of Scene Configuration between IsaacGymEnvs and Isaac Lab\nDESCRIPTION: A comparison showing how scene configuration parameters (number of environments and spacing) are specified in IsaacGymEnvs (YAML) versus Isaac Lab (Python).\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# IsaacGymEnvs\nenv:\n  numEnvs: ${resolve_default:512,${...num_envs}}\n  envSpacing: 4.0\n```\n\nLANGUAGE: python\nCODE:\n```\n# IsaacLab\nscene: InteractiveSceneCfg = InteractiveSceneCfg(\n  num_envs=512,\n  env_spacing=4.0)\n```\n\n----------------------------------------\n\nTITLE: Running the Isaac Automator Container - Bash\nDESCRIPTION: This script executes the run command to start the Isaac Automator container on Linux. It must be executed from within the Isaac Automator project directory and assumes Docker has already built the relevant image via the './build' script.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./run\n```\n\n----------------------------------------\n\nTITLE: Installing Build Dependencies for Isaac Lab Extensions - Bash\nDESCRIPTION: Installs core compilation tools (cmake and build-essential) using apt on Ubuntu, which are needed to build certain extensions or dependencies for Isaac Lab. The command must be run with sudo privileges. Input is the package list; output is an updated system with required packages.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install cmake build-essential\n```\n\n----------------------------------------\n\nTITLE: Proper Implementation with Weak References\nDESCRIPTION: Improved implementation of a Python class that registers a callback with the simulator using weak references to prevent memory leaks by allowing proper garbage collection.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport omni.kit\nimport weakref\n\nclass MyClass:\n    def __init__(self):\n        app_interface = omni.kit.app.get_app_interface()\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch Nightly for 50 Series GPUs (Windows)\nDESCRIPTION: Command to install the latest PyTorch nightly build for 50 series GPUs on Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_22\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p -m pip install --upgrade --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128\n```\n\n----------------------------------------\n\nTITLE: Running Multi-Asset Simulation in IsaacLab (Bash)\nDESCRIPTION: Command-line instruction to execute the multi-asset simulation script with 2048 environments, each containing randomly selected assets from the configured options.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/multi_asset_spawning.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/multi_asset.py --num_envs 2048\n```\n\n----------------------------------------\n\nTITLE: Running IsaacLab Training Script on a Specific Device (New CLI) using Bash\nDESCRIPTION: Illustrates the current command-line method in IsaacLab v1.2.0+ using `./isaaclab.sh` to run a training script (`sb3/train.py`), specifying the execution device with the `--device` argument (e.g., `--device cpu`). This replaces the older `--cpu` and `--device_id` flags and accepts values like `cpu`, `cuda`, or `cuda:N`.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n.. code:: bash\n\n    ./isaaclab.sh -p source/standalone/workflows/sb3/train.py --task Isaac-Cartpole-v0 --headless --device cpu\n```\n\n----------------------------------------\n\nTITLE: Building the Isaac Automator Docker Image - Windows Batch\nDESCRIPTION: This batch script builds the Isaac Automator Docker image explicitly targeting the linux/x86_64 platform. It assigns the resulting image the tag 'isa' and mounts the current working directory. Requires Docker to be installed on Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_4\n\nLANGUAGE: batch\nCODE:\n```\ndocker build --platform linux/x86_64 -t isa .\n```\n\n----------------------------------------\n\nTITLE: Viewing Frame Transformer Sensor Output for Specific Frames\nDESCRIPTION: Example output from the Frame Transformer sensor when tracking specific objects (robot feet). Shows the tensor format of relative positions and orientations from the source frame to the target frames.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/frame_transformer.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n-------------------------------\nFrameTransformer @ '/World/envs/env_.*/Robot/base':\n        tracked body frames: ['base', 'LF_FOOT', 'RF_FOOT']\n        number of envs: 1\n        source body frame: base\n        target frames (count: ['LF_FOOT', 'RF_FOOT']): 2\n\nrelative transforms: tensor([[[ 0.4658,  0.3085, -0.4840],\n        [ 0.4487, -0.2959, -0.4828]]], device='cuda:0')\nrelative orientations: tensor([[[ 0.9623,  0.0072, -0.2717, -0.0020],\n        [ 0.9639,  0.0052, -0.2663, -0.0014]]], device='cuda:0')\n```\n\n----------------------------------------\n\nTITLE: Listing Available Isaac Lab Tasks (Bash)\nDESCRIPTION: Executes a Python script (`scripts/list_envs.py`) to list the simulation environments (tasks) available within the project. Requires the project and Isaac Lab to be installed. If the task name changes, the script's search pattern might need updating. Use the Isaac Lab script (`isaaclab.sh|bat -p`) if Isaac Lab isn't in the Python environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/templates/external/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# use 'FULL_PATH_TO_isaaclab.sh|bat -p' instead of 'python' if Isaac Lab is not installed in Python venv or conda\npython scripts/list_envs.py\n```\n\n----------------------------------------\n\nTITLE: Migrating Clipping Parameters in RL Configs (YAML)\nDESCRIPTION: Demonstrates how to migrate observation and action clipping parameters from IsaacGymEnvs to Isaac Lab RL config files. In IsaacGymEnvs, these settings are set under the 'env' section as 'clipObservations' and 'clipActions'. In Isaac Lab, the parameters are nested within 'params.env' and use snake_case keys. This change ensures compatibility with the new configuration structure. Inputs: YAML config files for each framework. Outputs: Updated Isaac Lab YAML config.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n# IsaacGymEnvs\nenv:\n  clipObservations: 5.0\n  clipActions: 1.0\n```\n\nLANGUAGE: yaml\nCODE:\n```\n# IsaacLab\nparams:\n  env:\n    clip_observations: 5.0\n    clip_actions: 1.0\n```\n\n----------------------------------------\n\nTITLE: Deploying Isaac Automator to Cloud Providers - Bash\nDESCRIPTION: This snippet illustrates how to deploy Isaac Automator control environments onto AWS, Azure, GCP, or Alibaba Cloud from within the automator container. Depending on the desired cloud provider, the user selects and invokes the corresponding deployment script. Requires pre-setup credentials and Docker container context.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# AWS\n./deploy-aws\n# Azure\n./deploy-azure\n# GCP\n./deploy-gcp\n# Alibaba Cloud\n./deploy-alicloud\n```\n\n----------------------------------------\n\nTITLE: Upgrading pip to Latest Version - Batch (Windows)\nDESCRIPTION: Runs pip upgrade via 'python -m pip' to ensure the latest version of pip is installed on Windows, which is recommended before installing Isaac Sim and other pip-based packages. The command should be executed from an active virtual environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_6\n\nLANGUAGE: batch\nCODE:\n```\npython -m pip install --upgrade pip\n```\n\n----------------------------------------\n\nTITLE: Registering the New H1 Environment in the Gym Registry\nDESCRIPTION: Code snippet demonstrating how to register the new H1 environment in the Gym registry with appropriate configuration parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/modify_direct_rl_env.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Register envs\nregister(\n    id=\"Isaac-Humanoid-Direct-v0\",\n    entry_point=\"isaaclab_tasks.direct.humanoid:HumanoidEnv\",\n    kwargs={\n        \"cfg\": HumanoidEnvCfg,\n        \"rl_games_cfg\": \"training/rl_games/rl_games_ppo_humanoid.yaml\",\n    },\n)\n\nregister(\n    id=\"Isaac-H1-Direct-v0\",\n    entry_point=\"isaaclab_tasks.direct.humanoid:H1Env\",\n    kwargs={\n        \"cfg\": H1EnvCfg,\n        \"rl_games_cfg\": \"training/rl_games/rl_games_ppo_humanoid.yaml\",\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Running the Deformable Object Tutorial Script (Bash)\nDESCRIPTION: This bash command runs the deformable object tutorial script using IsaacLab's launcher. It initializes the simulation stage and executes all setup, spawning, and control logic as described in the Python code. Requires the IsaacLab simulator to be installed and the script path to be correct.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/01_assets/run_deformable_object.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/tutorials/01_assets/run_deformable_object.py\n```\n\n----------------------------------------\n\nTITLE: Drawing Visualization Markers in Python\nDESCRIPTION: Shows how to use the visualize method to draw markers with specific poses and prototypes. Demonstrates marker positioning and transformation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/draw_markers.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmarkers.visualize(\n    poses=[\n        [pos + np.array([0.0, 0.0, 0.1]), quat],\n        [pos + np.array([0.0, 0.0, 0.2]), quat],\n        [pos + np.array([0.0, 0.0, 0.3]), quat],\n    ],\n    marker_names=[\"cone\", \"sphere\", \"frame\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Resetting Isaac Sim User Data on Linux\nDESCRIPTION: Runs the Isaac Sim simulator startup script on Linux with the '--reset-user' flag. This command should be run the first time after installing a new version of Isaac Sim (if a previous version existed) to clear old user data and cached variables. Requires the ISAACSIM_PATH environment variable to be set.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n${ISAACSIM_PATH}/isaac-sim.sh --reset-user\n```\n\n----------------------------------------\n\nTITLE: Viewing Training Logs with TensorBoard in Bash\nDESCRIPTION: This script provides commands for viewing training logs using TensorBoard within the Docker container. It includes steps to enter the container and start TensorBoard.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# In a new terminal (don't close the above) , enter the image with a new shell.\ndocker container ps\ndocker exec -it <ISAAC_RAY_IMAGE_ID_FROM_CONTAINER_PS> /bin/bash\n# Start a tuning run, with one parallel worker per GPU\ntensorboard --logdir=.\n```\n\n----------------------------------------\n\nTITLE: Viewing Frame Transformer Sensor Output for Regex-Matched Frames\nDESCRIPTION: Example output from the Frame Transformer sensor when using regex to track multiple robot components. This shows how inclusive matching works, including the source frame itself in the tracked targets list.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/frame_transformer.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n-------------------------------\nFrameTransformer @ '/World/envs/env_.*/Robot/base':\n        tracked body frames: ['base', 'LF_FOOT', 'LF_HIP', 'LF_SHANK', 'LF_THIGH', 'LH_FOOT', 'LH_HIP', 'LH_SHANK', 'LH_THIGH', 'RF_FOOT', 'RF_HIP', 'RF_SHANK', 'RF_THIGH', 'RH_FOOT', 'RH_HIP', 'RH_SHANK', 'RH_THIGH', 'base']\n        number of envs: 1\n        source body frame: base\n        target frames (count: ['LF_FOOT', 'LF_HIP', 'LF_SHANK', 'LF_THIGH', 'LH_FOOT', 'LH_HIP', 'LH_SHANK', 'LH_THIGH', 'RF_FOOT', 'RF_HIP', 'RF_SHANK', 'RF_THIGH', 'RH_FOOT', 'RH_HIP', 'RH_SHANK', 'RH_THIGH', 'base']): 17\n\nrelative transforms: tensor([[[ 4.6581e-01,  3.0846e-01, -4.8398e-01],\n        [ 2.9990e-01,  1.0400e-01, -1.7062e-09],\n        [ 2.1409e-01,  2.9177e-01, -2.4214e-01],\n        [ 3.5980e-01,  1.8780e-01,  1.2608e-03],\n        [-4.8813e-01,  3.0973e-01, -4.5927e-01],\n        [-2.9990e-01,  1.0400e-01,  2.7044e-09],\n        [-2.1495e-01,  2.9264e-01, -2.4198e-01],\n        [-3.5980e-01,  1.8780e-01,  1.5582e-03],\n        [ 4.4871e-01, -2.9593e-01, -4.8277e-01],\n        [ 2.9990e-01, -1.0400e-01, -2.7057e-09],\n        [ 1.9971e-01, -2.8554e-01, -2.3778e-01],\n        [ 3.5980e-01, -1.8781e-01, -9.1049e-04],\n        [-5.0090e-01, -2.9095e-01, -4.5746e-01],\n        [-2.9990e-01, -1.0400e-01,  6.3592e-09],\n        [-2.1860e-01, -2.8251e-01, -2.5163e-01],\n        [-3.5980e-01, -1.8779e-01, -1.8792e-03],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n```\n\n----------------------------------------\n\nTITLE: Running Deformables Demo in Isaac Lab\nDESCRIPTION: Commands to spawn different deformable (soft) bodies and let them fall from a height. This demo showcases the soft body physics simulation capabilities in Isaac Lab.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/showroom.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/deformables.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\demos\\deformables.py\n```\n\n----------------------------------------\n\nTITLE: Creating venv Environment for Isaac Lab (Linux Bash)\nDESCRIPTION: Creates a Python virtual environment named 'env_isaaclab' using the 'venv' module with Python 3.10 on a Linux system, and then activates it using the 'source' command. This provides an alternative to Conda for environment management.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# create a virtual environment named env_isaaclab with python3.10\npython3.10 -m venv env_isaaclab\n# activate the virtual environment\nsource env_isaaclab/bin/activate\n```\n\n----------------------------------------\n\nTITLE: IMU Sensor Output Example in Isaac Lab\nDESCRIPTION: This snippet shows the actual output from two differently configured IMU sensors. The left foot IMU (with default gravity bias) reports a significant linear acceleration along the Z-axis, while the right foot IMU (with zero bias) reports values close to zero when at rest.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/imu.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nImu sensor @ '/World/envs/env_.*/Robot/LF_FOOT':\n        view type         : <class 'omni.physics.tensors.impl.api.RigidBodyView'>\n        update period (s) : 0.0\n        number of sensors : 1\n\nReceived linear velocity:  tensor([[ 0.0203, -0.0054,  0.0380]], device='cuda:0')\nReceived angular velocity:  tensor([[-0.0104, -0.1189,  0.0080]], device='cuda:0')\nReceived linear acceleration:  tensor([[ 4.8344, -0.0205,  8.5305]], device='cuda:0')\nReceived angular acceleration:  tensor([[-0.0389, -0.0262, -0.0045]], device='cuda:0')\n-------------------------------\nImu sensor @ '/World/envs/env_.*/Robot/RF_FOOT':\n        view type         : <class 'omni.physics.tensors.impl.api.RigidBodyView'>\n        update period (s) : 0.0\n        number of sensors : 1\n\nReceived linear velocity:  tensor([[0.0244, 0.0077, 0.0431]], device='cuda:0')\nReceived angular velocity:  tensor([[ 0.0122, -0.1360, -0.0042]], device='cuda:0')\nReceived linear acceleration:  tensor([[-0.0018,  0.0010, -0.0032]], device='cuda:0')\nReceived angular acceleration:  tensor([[-0.0373, -0.0050, -0.0053]], device='cuda:0')\n-------------------------------\n```\n\n----------------------------------------\n\nTITLE: Running Arms Demo in Isaac Lab\nDESCRIPTION: Commands to spawn different robotic arms and apply random joint position commands. This demo showcases the arm manipulation interfaces in Isaac Lab.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/showroom.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/arms.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\demos\\arms.py\n```\n\n----------------------------------------\n\nTITLE: Installing Specific Learning Framework in Isaac Lab (Windows)\nDESCRIPTION: This command installs a specific learning framework (rl_games in this example) in Isaac Lab on Windows systems. Other valid options include rsl_rl, sb3, skrl, robomimic, and none.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_19\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat --install rl_games :: or \"isaaclab.bat -i rl_games\"\n```\n\n----------------------------------------\n\nTITLE: Training and Playing with SKRL (JAX) on Isaac-Reach-Franka-v0 in Linux\nDESCRIPTION: Commands for installing SKRL with JAX, training an agent on the Isaac-Reach-Franka-v0 environment, playing trained models, and recording videos in Linux. Note that JAX GPU support is only available on Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# install python module (for skrl)\n./isaaclab.sh -i skrl\n# install skrl dependencies for JAX\n./isaaclab.sh -p -m pip install skrl[\"jax\"]\n# run script for training\n./isaaclab.sh -p scripts/reinforcement_learning/skrl/train.py --task Isaac-Reach-Franka-v0 --headless --ml_framework jax\n# run script for playing with 32 environments\n./isaaclab.sh -p scripts/reinforcement_learning/skrl/play.py --task Isaac-Reach-Franka-v0 --num_envs 32  --ml_framework jax --checkpoint /PATH/TO/model.pt\n# run script for recording video of a trained agent (requires installing `ffmpeg`)\n./isaaclab.sh -p scripts/reinforcement_learning/skrl/play.py --task Isaac-Reach-Franka-v0 --headless --ml_framework jax --video --video_length 200\n```\n\n----------------------------------------\n\nTITLE: Displaying Isaac Lab Helper Script Help (Linux)\nDESCRIPTION: Shows the help message and usage instructions for the Isaac Lab helper script `isaaclab.sh` on Linux. This script provides utilities for managing Isaac Lab extensions, formatting code, running Python/simulator, testing, managing Docker, VSCode settings, documentation, and conda environments.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_10\n\nLANGUAGE: text\nCODE:\n```\n./isaaclab.sh --help\n\nusage: isaaclab.sh [-h] [-i] [-f] [-p] [-s] [-t] [-o] [-v] [-d] [-n] [-c] -- Utility to manage Isaac Lab.\n\noptional arguments:\n   -h, --help           Display the help content.\n   -i, --install [LIB]  Install the extensions inside Isaac Lab and learning frameworks (rl-games, rsl-rl, sb3, skrl) as extra dependencies. Default is 'all'.\n   -f, --format         Run pre-commit to format the code and check lints.\n   -p, --python         Run the python executable provided by Isaac Sim or virtual environment (if active).\n   -s, --sim            Run the simulator executable (isaac-sim.sh) provided by Isaac Sim.\n   -t, --test           Run all python unittest tests.\n   -o, --docker         Run the docker container helper script (docker/container.sh).\n   -v, --vscode         Generate the VSCode settings file from template.\n   -d, --docs           Build the documentation from source using sphinx.\n   -n, --new            Create a new external project or internal task from template.\n   -c, --conda [NAME]   Create the conda environment for Isaac Lab. Default name is 'env_isaaclab'.\n```\n\n----------------------------------------\n\nTITLE: Spawning a Static Rigid Cone in Isaac Sim\nDESCRIPTION: This snippet shows how to spawn a static cone with rigid body properties. It uses the ConeCfg class with additional parameters to make the object kinematic, allowing it to participate in collisions without being affected by physics.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/make_fixed_prim.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport isaaclab.sim as sim_utils\n\ncone_spawn_cfg = sim_utils.ConeCfg(\n    radius=0.15,\n    height=0.5,\n    rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True),\n    mass_props=sim_utils.MassPropertiesCfg(mass=1.0),\n    collision_props=sim_utils.CollisionPropertiesCfg(),\n    visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.0, 1.0, 0.0)),\n)\ncone_spawn_cfg.func(\n    \"/World/Cone\", cone_spawn_cfg, translation=(0.0, 0.0, 2.0), orientation=(0.5, 0.0, 0.5, 0.0)\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Isaac Sim Symbolic Link on Linux\nDESCRIPTION: Creates a symbolic link named `_isaac_sim` within the cloned IsaacLab directory, pointing to the actual Isaac Sim installation directory (`path_to_isaac_sim`). This is done on Linux using the `ln -s` command after changing into the `IsaacLab` directory. An example using the `${HOME}/isaacsim` path is provided.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# enter the cloned repository\ncd IsaacLab\n# create a symbolic link\nln -s path_to_isaac_sim _isaac_sim\n# For example: ln -s ${HOME}/isaacsim _isaac_sim\n```\n\n----------------------------------------\n\nTITLE: Managing Isaac Lab Docker Image Extensions\nDESCRIPTION: Commands to start and stop different Isaac Lab Docker image extensions, such as base and ROS2.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/docker.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# start base by default\n./docker/container.py start\n# stop base explicitly\n./docker/container.py stop base\n# start ros2 container\n./docker/container.py start ros2\n# stop ros2 container\n./docker/container.py stop ros2\n```\n\n----------------------------------------\n\nTITLE: Defining Initial State for Articulation in Isaac Lab\nDESCRIPTION: This snippet configures the initial state of the Cartpole articulation. It positions the cartpole at the origin of the XY plane at a height of 2.0 meters, with all joint positions and velocities initialized to 0.0.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/write_articulation_cfg.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ninit_state=InitialStateCfg(\n    pos=(0.0, 0.0, 2.0),\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Conda Environment for Isaac Sim Installation - Bash\nDESCRIPTION: This code snippet demonstrates how to create and activate a new conda environment called 'env_isaaclab' configured with Python 3.10, which is required for Isaac Sim and Isaac Lab. Prerequisites include having Anaconda or Miniconda installed. The \"conda create\" command initializes the environment and \"conda activate\" switches to it; no external inputs are required. Output is a usable Python 3.10 environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda create -n env_isaaclab python=3.10\nconda activate env_isaaclab\n```\n\n----------------------------------------\n\nTITLE: Contact Sensor Console Output for Hind Feet\nDESCRIPTION: Console output showing the contact sensor data for the hind feet of the Anymal Quadruped. It demonstrates how a single sensor with multiple bodies returns contact forces as a tensor with multiple entries, one for each monitored body.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/contact_sensor.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n-------------------------------\nContact sensor @ '/World/envs/env_.*/Robot/.*H_FOOT':\n        view type         : <class 'omni.physics.tensors.impl.api.RigidBodyView'>\n        update period (s) : 0.0\n        number of bodies  : 2\n        body names        : ['LH_FOOT', 'RH_FOOT']\n\nReceived force matrix of:  None\nReceived contact force of:  tensor([[[9.7227e-06, 0.0000e+00, 7.2364e+01],\n        [2.4322e-05, 0.0000e+00, 1.8102e+02]]], device='cuda:0')\n```\n\n----------------------------------------\n\nTITLE: Running Code Formatters/Linters using isaaclab.sh Script in Bash\nDESCRIPTION: Provides the Bash command to execute the `isaaclab.sh` script located in the current directory. Using the `--format` flag (or its shorthand `-f`) triggers the execution of configured code formatters and linters (like black, flake8 via pre-commit) across the entire repository.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh --format  # or \"./isaaclab.sh -f\"\n```\n\n----------------------------------------\n\nTITLE: Master Node Command for Multi-Node Training with skrl and JAX\nDESCRIPTION: Command for the master node when running RL training with skrl using JAX backend across multiple machines. Uses skrl's distributed utility with coordinator address to orchestrate multi-node training.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\npython -m skrl.utils.distributed.jax --nproc_per_node=2 --nnodes=2 --node_rank=0 --coordinator_address=ip_of_master_machine:5555 scripts/reinforcement_learning/skrl/train.py --task=Isaac-Cartpole-v0 --headless --distributed --ml_framework jax\n```\n\n----------------------------------------\n\nTITLE: Destroying a Cloud Deployment - Bash\nDESCRIPTION: This command deletes a specified cloud deployment to save costs. It must be executed from within the Automator container, and <deployment-name> should be replaced with the actual identifier of the running deployment. Requires appropriate permissions on the cloud account.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n./destroy <deployment-name>\n```\n\n----------------------------------------\n\nTITLE: Spawning a Distant Light Source in Isaac Lab with Python\nDESCRIPTION: Shows how to create a distant light (a light that is infinitely far away from the scene and shines in a single direction) using DistantLightCfg and position it within the scene.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/spawn_prims.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# spawn distant light\ncfg_light_distant = sim.spawners.DistantLightCfg()\ncfg_light_distant.color = torch.tensor([1.0, 1.0, 1.0])\ncfg_light_distant.intensity = 3000.0\ncfg_light_distant.func(\"/World/lightDistant\", cfg_light_distant, translation=(1, 0, 10))\n```\n\n----------------------------------------\n\nTITLE: Launching Isaac Sim for Animation Playback\nDESCRIPTION: This bash command shows how to launch the Omniverse Isaac Sim application from the terminal, which can be used to play back recorded animations by loading the saved USD files as sublayers.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/record_animation.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -s  # Opens Isaac Sim application through _isaac_sim/isaac-sim.sh\n```\n\n----------------------------------------\n\nTITLE: Listing Running Docker Containers\nDESCRIPTION: Command to list all running Docker containers. This helps verify that the Isaac Lab container is running correctly.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\ndocker container ls\n```\n\n----------------------------------------\n\nTITLE: Rendering Multiple Frames to Initialize Camera in IsaacLab\nDESCRIPTION: A workaround to address blank initial frames from camera sensors in standalone scripts. This code renders multiple simulation frames to properly load material textures and fill render targets before actual use.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/issues.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.sim import SimulationContext\n\nsim = SimulationContext.instance()\n\n# note: the number of steps might vary depending on how complicated the scene is.\nfor _ in range(12):\n    sim.render()\n```\n\n----------------------------------------\n\nTITLE: Importing Isaac Lab Simulation Module\nDESCRIPTION: Shows how to import the necessary simulation modules from Isaac Lab after the simulation app is running.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/create_empty.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.sim import SimulationCfg, SimulationContext\n```\n\n----------------------------------------\n\nTITLE: Executing Marker Demo Script in Bash\nDESCRIPTION: Command to run the demonstration script for visualization markers in Isaac Sim.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/draw_markers.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/markers.py\n```\n\n----------------------------------------\n\nTITLE: Specifying Teleoperation Device (Old CLI) using Bash\nDESCRIPTION: Shows the previous command-line method using `./isaaclab.sh` to specify the teleoperation input device (e.g., `keyboard`) for a standalone script. It used the `--device` argument, which caused conflicts with the new simulation device argument in v1.2.0.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n.. code:: bash\n\n    ./isaaclab.sh -p source/standalone/environments/teleoperation/teleop_se3_agent.py --task Isaac-Lift-Cube-Franka-IK-Rel-v0 --num_envs 1 --device keyboard\n```\n\n----------------------------------------\n\nTITLE: Fetching KubeRay Cluster IPs with kubectl (Python)\nDESCRIPTION: Python script snippet that uses `kubectl` commands to retrieve the IP addresses of the created KubeRay cluster components and the MLFlow server. The script saves the cluster IPs to a file and prints the MLFlow server IP. Lines 14-26 contain the core logic for this fetching process.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n... literalinclude:: ../../../scripts/reinforcement_learning/ray/grok_cluster_with_kubectl.py\n  :language: python\n  :emphasize-lines: 14-26\n```\n\n----------------------------------------\n\nTITLE: Installing Custom RSL-RL Version in Isaac Lab Environment\nDESCRIPTION: Command to install a custom version of the RSL-RL library in development mode (-e flag) in the Python environment used by Isaac Lab. This allows for modifications to the library to take effect without reinstallation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/add_own_library.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Assuming you are in the root directory of the Isaac Lab repository\ncd IsaacLab\n\n# Note: If you are using a virtual environment, make sure to activate it before running the following command\n./isaaclab.sh -p -m pip install -e /path/to/rsl_rl\n```\n\n----------------------------------------\n\nTITLE: Configuring Joint Drives with PDGainsCfg in URDF Converter\nDESCRIPTION: Example showing how to configure joint drives in the URDF Converter using PDGainsCfg class. This demonstrates setting up joint drives with stiffness and damping parameters, which is a breaking change from previous versions.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/migration.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\njoint_drive=sim_utils.UrdfConverterCfg.JointDriveCfg(\n    gains=sim_utils.UrdfConverterCfg.JointDriveCfg.PDGainsCfg(stiffness=None, damping=None)\n)\n```\n\n----------------------------------------\n\nTITLE: Using isaaclab.sh Helper Script on Linux - Text\nDESCRIPTION: Invokes the isaaclab.sh utility script to display usage help and command-line options for managing Isaac Lab extensions and dependencies on Linux. The script offers commands for installation, formatting, Python execution, simulator launch, testing, Docker features, VSCode settings, documentation, and conda environment management. Dependencies include bash, and the script must have execute permissions.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_13\n\nLANGUAGE: text\nCODE:\n```\n./isaaclab.sh --help\n\nusage: isaaclab.sh [-h] [-i] [-f] [-p] [-s] [-t] [-o] [-v] [-d] [-n] [-c] -- Utility to manage Isaac Lab.\n\noptional arguments:\n   -h, --help           Display the help content.\n   -i, --install [LIB]  Install the extensions inside Isaac Lab and learning frameworks (rl_games, rsl_rl, sb3, skrl) as extra dependencies. Default is 'all'.\n   -f, --format         Run pre-commit to format the code and check lints.\n   -p, --python         Run the python executable provided by Isaac Sim or virtual environment (if active).\n   -s, --sim            Run the simulator executable (isaac-sim.sh) provided by Isaac Sim.\n   -t, --test           Run all python unittest tests.\n   -o, --docker         Run the docker container helper script (docker/container.sh).\n   -v, --vscode         Generate the VSCode settings file from template.\n   -d, --docs           Build the documentation from source using sphinx.\n   -n, --new            Create a new external project or internal task from template.\n   -c, --conda [NAME]   Create the conda environment for Isaac Lab. Default name is 'env_isaaclab'.\n```\n\n----------------------------------------\n\nTITLE: Verifying Isaac Lab Installation (Windows)\nDESCRIPTION: These commands verify the successful installation of Isaac Lab on Windows by running a simple script to create an empty simulation. Two options are provided: using the isaaclab.bat executable or using python in a virtual environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_22\n\nLANGUAGE: batch\nCODE:\n```\n:: Option 1: Using the isaaclab.bat executable\n:: note: this works for both the bundled python and the virtual environment\nisaaclab.bat -p scripts\\tutorials\\00_sim\\create_empty.py\n\n:: Option 2: Using python in your virtual environment\npython scripts\\tutorials\\00_sim\\create_empty.py\n```\n\n----------------------------------------\n\nTITLE: Installing Specific Learning Framework (Linux)\nDESCRIPTION: Command to install a specific learning framework (e.g., rl_games) for Isaac Lab on Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh --install rl_games  # or \"./isaaclab.sh -i rl_games\"\n```\n\n----------------------------------------\n\nTITLE: Running an Isaac Lab Task with a Random-Action Agent (Bash)\nDESCRIPTION: Executes a script (`scripts/random_agent.py`) that runs a specified task (`<TASK_NAME>`) using a dummy agent which outputs random actions. This helps ensure the environment responds correctly to varied inputs and is properly configured. Requires the project and Isaac Lab to be installed. Use the Isaac Lab script (`isaaclab.sh|bat -p`) if Isaac Lab isn't in the Python environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/templates/external/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# use 'FULL_PATH_TO_isaaclab.sh|bat -p' instead of 'python' if Isaac Lab is not installed in Python venv or conda\npython scripts/random_agent.py --task=<TASK_NAME>\n```\n\n----------------------------------------\n\nTITLE: Training an Ant Robot with Reinforcement Learning (Windows)\nDESCRIPTION: This command runs a predefined workflow to train an ant robot to walk using reinforcement learning in Isaac Lab on Windows. The --headless flag is recommended for faster training.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_24\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Ant-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up KubeRay Cluster Resources (Bash)\nDESCRIPTION: A sequence of `kubectl` commands combined with `egrep`, `awk`, and `xargs` to find and delete Kubernetes resources associated with the Isaac Lab Ray cluster. This includes RayCluster custom resources, MLFlow deployments, and related services, ensuring resource cleanup after use.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get raycluster | egrep 'isaacray' | awk '{print $1}' | xargs kubectl delete raycluster &&\nkubectl get deployments | egrep 'mlflow' | awk '{print $1}' | xargs kubectl delete deployment &&\nkubectl get services | egrep 'mlflow' | awk '{print $1}' | xargs kubectl delete service &&\nkubectl get services | egrep 'isaacray' | awk '{print $1}' | xargs kubectl delete service\n```\n\n----------------------------------------\n\nTITLE: Comparing Scene Configuration between OmniIsaacGymEnvs and Isaac Lab\nDESCRIPTION: Side-by-side comparison of scene configuration syntax between OmniIsaacGymEnvs (YAML format) and Isaac Lab (Python configclass format), focusing on environment count settings.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# OmniIsaacGymEnvs\nenv:\n  numEnvs: ${resolve_default:512,${...num_envs}}\n```\n\nLANGUAGE: python\nCODE:\n```\n# IsaacLab\nscene: InteractiveSceneCfg = InteractiveSceneCfg(\n   num_envs=512,\n```\n\n----------------------------------------\n\nTITLE: Verifying RSL-RL Library Installation with Pip\nDESCRIPTION: Command to check the installation details of the RSL-RL library, including its version and installation location, to confirm that the custom version is being used.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/add_own_library.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p -m pip show rsl-rl\n```\n\n----------------------------------------\n\nTITLE: Configuring IsaacLab SimulationCfg for CPU (New Method) in Python\nDESCRIPTION: Illustrates the current, simplified way introduced in IsaacLab v1.2.0 to configure `sim_utils.SimulationCfg` for CPU simulation. Only setting `device=\"cpu\"` is needed, as internal checks now handle the necessary adjustments for GPU pipeline and PhysX settings.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n.. code:: python\n\n    sim_utils.SimulationCfg(device=\"cpu\", dt=0.01, physx=sim_utils.PhysxCfg())\n```\n\n----------------------------------------\n\nTITLE: Setting CPU Scaling Governor to Performance Mode\nDESCRIPTION: Command to set the CPU frequency scaling governor to performance mode for all CPUs. This maximizes CPU performance by running at the highest frequency.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\necho performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\n```\n\n----------------------------------------\n\nTITLE: Executing the Isaac Lab OSC Tutorial Script (Bash)\nDESCRIPTION: This Bash command executes the `run_osc.py` tutorial script using the `isaaclab.sh` wrapper script. The `-p` flag specifies the path to the Python script, and the `--num_envs` flag sets the number of parallel simulation environments to 128.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/05_controllers/run_osc.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/tutorials/05_controllers/run_osc.py --num_envs 128\n```\n\n----------------------------------------\n\nTITLE: Interpreting RL-Games Training Output\nDESCRIPTION: Example output from RL-Games showing FPS metrics for environment steps, policy inference, and total training performance, along with checkpoint saving information.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/training_guide.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nfps step: 112918 fps step and policy inference: 104337 fps total: 78179 epoch: 1/150 frames: 0\n\n=> saving checkpoint 'IsaacLab/logs/rl_games/cartpole_direct/2024-12-28_20-23-06/nn/last_cartpole_direct_ep_150_rew_294.18793.pth'\nsaving next best rewards:  [294.18793]\n```\n\n----------------------------------------\n\nTITLE: Cloning Isaac Lab Repository using SSH\nDESCRIPTION: Clones the Isaac Lab Git repository from GitHub using the SSH protocol. This command downloads the source code into a new directory named 'IsaacLab'.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:isaac-sim/IsaacLab.git\n```\n\n----------------------------------------\n\nTITLE: Executing a Script in the Isaac Lab Container\nDESCRIPTION: Command to run a Python script inside the Isaac Lab Docker container using the isaaclab alias, with the headless flag to prevent GUI display.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nisaaclab -p scripts/tutorials/00_sim/log_time.py --headless\n```\n\n----------------------------------------\n\nTITLE: PBS Job Configuration Parameters\nDESCRIPTION: Default PBS job configuration settings defining resource requirements and constraints\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/cluster.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n#PBS -N isaac-training\n#PBS -q gpu\n#PBS -l select=1:ncpus=8:mem=32gb:ngpus=1\n#PBS -l walltime=24:00:00\n#PBS -o /home/username/isaaclab/logs/pbs.out\n#PBS -e /home/username/isaaclab/logs/pbs.err\n#PBS -j oe\n```\n\n----------------------------------------\n\nTITLE: SensorBase Class References in Isaac Lab\nDESCRIPTION: References to the SensorBase abstract class which provides core functionality for all sensors in Isaac Lab. It manages measurement buffers that are periodically updated based on an update_period specified in simulated seconds.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/core-concepts/sensors/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nSensorBase\n```\n\n----------------------------------------\n\nTITLE: Worker Node Command for Multi-Node Training with rl_games\nDESCRIPTION: Command for non-master (worker) nodes when running RL training with rl_games across multiple machines. Connects to the master node using its IP address and the specified port.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/multi_gpu.rst#2025-04-23_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\npython -m torch.distributed.run --nproc_per_node=2 --nnodes=2 --node_rank=1 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=ip_of_master_machine:5555 scripts/reinforcement_learning/rl_games/train.py --task=Isaac-Cartpole-v0 --headless --distributed\n```\n\n----------------------------------------\n\nTITLE: Event Term Configuration - Updated Isaac Lab Format\nDESCRIPTION: Example of event term configuration in Isaac Lab using mass_distribution_params parameter\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_orbit.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nadd_base_mass = EventTerm(\n    func=mdp.randomize_rigid_body_mass,\n    mode=\"startup\",\n    params={\n        \"asset_cfg\": SceneEntityCfg(\"robot\", body_names=\"base\"),\n        \"mass_distribution_params\": (-5.0, 5.0),\n        \"operation\": \"add\",\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Building Current-Version Documentation on Windows\nDESCRIPTION: This snippet demonstrates how to navigate to the docs directory, install dependencies, build the current documentation, and open it in a browser on Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/README.md#2025-04-23_snippet_1\n\nLANGUAGE: batch\nCODE:\n```\n:: 1. Navigate to the docs directory and install dependencies\ncd docs\npip install -r requirements.txt\n\n:: 2. Build the current documentation\nmake current-docs\n\n:: 3. Open the current docs\nstart _build\\current\\index.html\n```\n\n----------------------------------------\n\nTITLE: Auto-tuning Maximum Camera Count for Cartpole Environment\nDESCRIPTION: Command to automatically determine the maximum number of tiled cameras that can run in the Cartpole environment within specified system resource utilization thresholds (CPU, RAM, GPU compute, GPU memory).\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/estimate_how_many_cameras_can_run.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/benchmarks/benchmark_cameras.py \\\n--task Isaac-Cartpole-v0 --num_tiled_cameras 100 \\\n--task_num_cameras_per_env 2 \\\n--tiled_camera_data_types rgb --autotune \\\n--autotune_max_percentage_util 100 80 50 50\n```\n\n----------------------------------------\n\nTITLE: Interpreting SKRL Training Output\nDESCRIPTION: Simple progress output from SKRL showing completion percentage and timing estimates.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/training_guide.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n    0%|                                          | 2/4800 [00:00<10:02,  7.96it/s]\n```\n\n----------------------------------------\n\nTITLE: Activating Isaac Lab Conda Environment\nDESCRIPTION: Command to activate the Isaac Lab Conda environment after creation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nconda activate env_isaaclab  # or \"conda activate my_env\"\n```\n\n----------------------------------------\n\nTITLE: Setting up Sphinx Autodoc for isaaclab_tasks.utils Module\nDESCRIPTION: Configures Sphinx documentation to automatically document all members and imported members of the isaaclab_tasks.utils module. It includes a submodules rubric to organize documentation structure.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/api/lab_tasks/isaaclab_tasks.utils.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: isaaclab_tasks.utils\n   :members:\n   :imported-members:\n\n   .. rubric:: Submodules\n```\n\n----------------------------------------\n\nTITLE: Executing RL Training Headless with Video Recording\nDESCRIPTION: Command for running RL training in headless mode but with off-screen rendering enabled for video recording.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/run_rl_training.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/sb3/train.py --task Isaac-Cartpole-v0 --num_envs 64 --headless --video\n```\n\n----------------------------------------\n\nTITLE: Training an Ant Robot with Isaac Lab (Windows)\nDESCRIPTION: Command to train an ant robot to walk using Isaac Lab's reinforcement learning capabilities on Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_26\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Ant-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Event Term Configuration - Original Orbit Format\nDESCRIPTION: Example of event term configuration in Orbit using mass_range parameter\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_orbit.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nadd_base_mass = EventTerm(\n    func=mdp.randomize_rigid_body_mass,\n    mode=\"startup\",\n    params={\n        \"asset_cfg\": SceneEntityCfg(\"robot\", body_names=\"base\"),\n        \"mass_range\": (-5.0, 5.0),\n        \"operation\": \"add\",\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Removing the Isaac Lab Docker Image\nDESCRIPTION: Command to remove the isaac-lab-base Docker image to free up disk space, requiring rebuilding the image for future use.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_9\n\nLANGUAGE: console\nCODE:\n```\ndocker image rm isaac-lab-base\n```\n\n----------------------------------------\n\nTITLE: Launching Isaac Sim on Linux\nDESCRIPTION: Command to launch Isaac Sim application with asset caching support on Linux systems using the -s flag.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/asset_caching.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -s\n```\n\n----------------------------------------\n\nTITLE: Viewing Help Documentation for Camera Benchmark Script\nDESCRIPTION: Command to display all available parameters for the benchmark_cameras.py utility.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/estimate_how_many_cameras_can_run.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/benchmarks/benchmark_cameras.py -h\n```\n\n----------------------------------------\n\nTITLE: Running Isaac Sim with a Specific Experience File (Bash)\nDESCRIPTION: Launches the Isaac Sim simulator using a specific Omniverse Kit experience file ('isaacsim.exp.full.kit'). The path to the experience file can be absolute or relative; relative paths are searched within standard Isaac Sim application directories. This allows testing or running predefined simulation setups.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# experience files can be absolute path, or relative path searched in isaacsim/apps or omni/apps\nisaacsim isaacsim.exp.full.kit\n```\n\n----------------------------------------\n\nTITLE: Running NGC Pre-built Isaac Lab Container\nDESCRIPTION: Command to pull the minimal pre-built Isaac Lab container from NGC. This container includes Isaac Sim dependencies and Isaac Lab 2.0 pre-installed, designed for headless operation only.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/docker.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull nvcr.io/nvidia/isaac-lab:2.0.2\n```\n\n----------------------------------------\n\nTITLE: Copying Files from Isaac Lab Docker Container\nDESCRIPTION: Commands to copy files from the Isaac Lab Docker container to the host machine, including a wrapper script for copying logs, data, and documentation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/docker.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Copy the file /workspace/isaaclab/logs to the current directory\ndocker cp isaac-lab-base:/workspace/isaaclab/logs .\n\n# stop the container\n./docker/container.py stop\n```\n\n----------------------------------------\n\nTITLE: Bad Example: Python Function with Redundant Type Hints\nDESCRIPTION: Shows a Python function `my_function` definition where type hints are redundantly specified both in the function signature (`a: int, b: int -> int`) and within the docstring. This duplication is considered bad practice.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef my_function(a: int, b: int) -> int:\n   \"\"\"Adds two numbers.\n\n   This function is a bad example. Reason: Type hints in the docstring and in the function\n   signature. Redundancy.\n\n   Args:\n      a (int): The first argument.\n      b (int): The second argument.\n\n   Returns:\n      int: The sum of the two arguments.\n   \"\"\"\n   return a + b\n```\n\n----------------------------------------\n\nTITLE: Inference Launch Command for Isaac Lab\nDESCRIPTION: Command to launch inference for CartPole environment in Isaac Lab with specified number of environments and checkpoint path.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_35\n\nLANGUAGE: bash\nCODE:\n```\npython scripts/reinforcement_learning/rl_games/play.py --task=Isaac-Cartpole-Direct-v0 --num_envs=25 --checkpoint=<path/to/checkpoint>\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Parameters in CartPole Implementation\nDESCRIPTION: Initializes environment parameters for CartPole including observations, actions, and tensor wrappers for joint positions and velocities. This snippet shows partial constructor code from both implementations.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_isaacgymenvs.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nself.cfg[\"env\"][\"numObservations\"] = 4\nself.cfg[\"env\"][\"numActions\"] = 1\n\nsuper().__init__(config=self.cfg,\n   rl_device=rl_device, sim_device=sim_device,\n   graphics_device_id=graphics_device_id, headless=headless,\n   virtual_screen_capture=virtual_screen_capture,\n   force_render=force_render)\n\ndof_state_tensor = self.gym.acquire_dof_state_tensor(self.sim)\nself.dof_state = gymtorch.wrap_tensor(dof_state_tensor)\nself.dof_pos = self.dof_state.view(\n    self.num_envs, self.num_dof, 2)[..., 0]\nself.dof_vel = self.dof_state.view(\n    self.num_envs, self.num_dof, 2)[..., 1]\n```\n\n----------------------------------------\n\nTITLE: Running Markers Demo in Isaac Lab\nDESCRIPTION: Commands to define multiple markers that are useful for visualizations in Isaac Lab. This demo shows how to use the visualization tools for debugging and display purposes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/showroom.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/markers.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\demos\\markers.py\n```\n\n----------------------------------------\n\nTITLE: Displaying Isaac Lab Repository Structure in Bash\nDESCRIPTION: Tree view representation of the Isaac Lab project directory structure showing main folders like source, scripts, docs, and their subfolders. Illustrates the organization of extensions and standalone applications.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/developer-guide/repo_structure.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nIsaacLab\nâ”œâ”€â”€ .vscode\nâ”œâ”€â”€ .flake8\nâ”œâ”€â”€ CONTRIBUTING.md\nâ”œâ”€â”€ CONTRIBUTORS.md\nâ”œâ”€â”€ LICENSE\nâ”œâ”€â”€ isaaclab.bat\nâ”œâ”€â”€ isaaclab.sh\nâ”œâ”€â”€ pyproject.toml\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ docs\nâ”œâ”€â”€ docker\nâ”œâ”€â”€ source\nâ”‚   â”œâ”€â”€ isaaclab\nâ”‚   â”œâ”€â”€ isaaclab_assets\nâ”‚   â”œâ”€â”€ isaaclab_mimic\nâ”‚   â”œâ”€â”€ isaaclab_rl\nâ”‚   â””â”€â”€ isaaclab_tasks\nâ”œâ”€â”€ scripts\nâ”‚   â”œâ”€â”€ benchmarks\nâ”‚   â”œâ”€â”€ demos\nâ”‚   â”œâ”€â”€ environments\nâ”‚   â”œâ”€â”€ imitation_learning\nâ”‚   â”œâ”€â”€ reinforcement_learning\nâ”‚   â”œâ”€â”€ tools\nâ”‚   â”œâ”€â”€ tutorials\nâ”œâ”€â”€ tools\nâ””â”€â”€ VERSION\n```\n\n----------------------------------------\n\nTITLE: Running Hands Demo in Isaac Lab\nDESCRIPTION: Commands to spawn different dexterous hands and command them to open and close. This demo demonstrates the hand manipulation interfaces in Isaac Lab.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/showroom.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/hands.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\demos\\hands.py\n```\n\n----------------------------------------\n\nTITLE: Running Isaac Lab with Verbose Logging\nDESCRIPTION: Command to launch Isaac Lab with increased logging verbosity level. The --info flag enables INFO level logging and above, which provides more detailed diagnostic information.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Run the standalone script with info logging\n./isaaclab.sh -p scripts/tutorials/00_sim/create_empty.py --headless --info\n```\n\n----------------------------------------\n\nTITLE: Upgrading Pip Package Manager (Linux Bash)\nDESCRIPTION: Updates the pip package installer to its latest version on a Linux system. Running this command before installing other packages ensures compatibility and access to the latest features.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade pip\n```\n\n----------------------------------------\n\nTITLE: Running Python Interpreter in Isaac Lab Docker Container\nDESCRIPTION: Command to run the Python interpreter provided by Isaac Sim within the Docker container.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/docker.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Run the Python interpreter -> points to /isaac-sim/python.sh\npython\n```\n\n----------------------------------------\n\nTITLE: Inspecting Docker Volumes for Isaac Lab\nDESCRIPTION: Commands to list all Docker volumes and inspect a specific volume used by Isaac Lab.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/docker.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# list all volumes\ndocker volume ls\n# inspect a specific volume, e.g. isaac-cache-kit\ndocker volume inspect isaac-cache-kit\n```\n\n----------------------------------------\n\nTITLE: Bad Example: Explicitly Type Hinting None Return in Python\nDESCRIPTION: This Python snippet shows a function `my_function` that takes an optional integer (`int | None`) and explicitly declares its return type as `None` using `-> None`. This explicit annotation for `None` return types is discouraged.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef my_function(x: int | None) -> None:\n   pass\n```\n\n----------------------------------------\n\nTITLE: Running Docker-based Local Quickstart in Bash\nDESCRIPTION: This script provides commands for setting up and running a local Ray-enabled Isaac Lab environment using Docker. It includes steps for building the image, starting the Ray server, and initiating a tuning run.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# Build the base image, but we don't need to run it\npython3 docker/container.py start && python3 docker/container.py stop\n# Build the tuning image with extra deps\ndocker build -t isaacray -f scripts/reinforcement_learning/ray/cluster_configs/Dockerfile .\n# Start the tuning image - symlink so that changes in the source folder show up in the container\ndocker run -v $(pwd)/source:/workspace/isaaclab/source -it --gpus all --net=host --entrypoint /bin/bash isaacray\n# Start the Ray server within the tuning image\necho \"import ray; ray.init(); import time; [time.sleep(10) for _ in iter(int, 1)]\" | ./isaaclab.sh -p\n```\n\n----------------------------------------\n\nTITLE: Running Zero-Action Agent on Cart-pole Environment\nDESCRIPTION: Commands to run a zero-action agent on the Cart-pole environment with 32 parallel environments. Zero-action agents are useful for verifying environment configurations.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/simple_agents.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/environments/zero_agent.py --task Isaac-Cartpole-v0 --num_envs 32\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\environments\\zero_agent.py --task Isaac-Cartpole-v0 --num_envs 32\n```\n\n----------------------------------------\n\nTITLE: Running Isaac Sim Simulator on Windows\nDESCRIPTION: Executes the Isaac Sim simulator startup batch script on Windows using the ISAACSIM_PATH environment variable. This command verifies that the simulator can be launched. The optional '--help' argument can be passed to see available command-line options.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_3\n\nLANGUAGE: batch\nCODE:\n```\n:: note: you can pass the argument \"--help\" to see all arguments possible.\n%ISAACSIM_PATH%\\isaac-sim.bat\n```\n\n----------------------------------------\n\nTITLE: Opening Documentation in Default Browser\nDESCRIPTION: Command to open the generated HTML documentation in the default browser using xdg-open. This is used after building the documentation to view the result.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nxdg-open docs/_build/current/index.html\n```\n\n----------------------------------------\n\nTITLE: Running Container Management Script Using Bash\nDESCRIPTION: This snippet demonstrates starting the old bash-based Docker container manager for IsaacLab. The 'container.sh' script, located in the 'docker' directory, was responsible for various tasks including image building, ROS2 startup, and cluster deployment. No external dependencies are required beyond standard bash and docker installation. Input is the 'start' argument, which triggers the respective startup routine; output is the launch of the appropriate container.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n./docker/container.sh start\n```\n\n----------------------------------------\n\nTITLE: Installing Isaac Lab Extensions via Helper Script (Windows) - Bash\nDESCRIPTION: Executes the isaaclab.bat batch file with --install or -i to install Isaac Lab extensions in editable mode via pip on Windows. Ensures development dependencies are set up for the project. The script output is a ready-to-use local installation for continued development or usage.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nisaaclab.bat --install :: or \"isaaclab.bat -i\"\n```\n\n----------------------------------------\n\nTITLE: Transferring Files from Docker Container in Bash\nDESCRIPTION: This script demonstrates how to transfer files from a running Docker container to the host machine using the docker cp command.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker container ps\ndocker cp <ISAAC_RAY_IMAGE_ID_FROM_CONTAINER_PS>:</path/in/container/file>  </path/on/host/>\n```\n\n----------------------------------------\n\nTITLE: Starting the Isaac Lab Docker Container\nDESCRIPTION: Command to build and start the Isaac Lab Docker container from the repository root. This pulls the base IsaacSim image and builds additional layers on top of it.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\npython docker/container.py start\n```\n\n----------------------------------------\n\nTITLE: Installing Isaac Lab Template Project in Editable Mode (Bash)\nDESCRIPTION: Installs the template project as an editable Python package using pip. This allows changes in the source code to be immediately reflected without reinstallation. It assumes a Python environment with Isaac Lab already installed. If Isaac Lab is not in a standard Python environment (venv/conda), the `isaaclab.sh` or `isaaclab.bat` script with the `-p` flag should be used instead of `python`.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/templates/external/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# use 'PATH_TO_isaaclab.sh|bat -p' instead of 'python' if Isaac Lab is not installed in Python venv or conda\npython -m pip install -e source/{{ name }}\n```\n\n----------------------------------------\n\nTITLE: Configuring VSCode Pylance Extra Paths for Extension Indexing (JSON)\nDESCRIPTION: Adds the path to the custom Isaac Lab extension source directory to the `python.analysis.extraPaths` setting in VSCode's `settings.json`. This helps the Pylance language server correctly index the extension's Python modules for features like autocompletion and error checking. Replace `<path-to-ext-repo>` with the actual path.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/templates/external/README.md#2025-04-23_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"python.analysis.extraPaths\": [\n        \"<path-to-ext-repo>/source/{{ name }}\"\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Isaac Lab Extensions via Helper Script (Linux) - Bash\nDESCRIPTION: Executes ./isaaclab.sh with the --install option to detect and install all Isaac Lab extensions and extra learning frameworks as pip editable packages on Linux. Requires bash and python-pip. This automates multi-project installation and dependency handling for local development.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh --install # or \"./isaaclab.sh -i\"\n```\n\n----------------------------------------\n\nTITLE: Listing Available Environments in Isaac Lab\nDESCRIPTION: Commands to list all available environments registered with OpenAI Gym in Isaac Lab. These environments are part of the isaaclab_tasks extension.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/simple_agents.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/environments/list_envs.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\environments\\list_envs.py\n```\n\n----------------------------------------\n\nTITLE: Verifying Isaac Sim Python Environment on Linux\nDESCRIPTION: Performs two checks on Linux using the Isaac Sim Python executable defined by ISAACSIM_PYTHON_EXE. The first command verifies the Python path configuration by printing a success message. The second command checks if Isaac Sim can be launched from a standalone Python script by running an example.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# checks that python path is set correctly\n${ISAACSIM_PYTHON_EXE} -c \"print('Isaac Sim configuration is now complete.')\"\n# checks that Isaac Sim can be launched from python\n${ISAACSIM_PYTHON_EXE} ${ISAACSIM_PATH}/standalone_examples/api/isaacsim.core.api/add_cubes.py\n```\n\n----------------------------------------\n\nTITLE: Interpreting Stable-Baselines3 Training Output\nDESCRIPTION: Detailed training metrics from Stable-Baselines3 including rollout statistics, timing information, and policy training data.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/training_guide.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 30.8         |\n|    ep_rew_mean          | 2.87         |\n| time/                   |              |\n|    fps                  | 8824         |\n|    iterations           | 2            |\n|    time_elapsed         | 14           |\n|    total_timesteps      | 131072       |\n| train/                  |              |\n|    approx_kl            | 0.0079056695 |\n|    clip_fraction        | 0.0842       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.42        |\n|    explained_variance   | 0.0344       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 10.4         |\n|    n_updates            | 20           |\n|    policy_gradient_loss | -0.0119      |\n|    std                  | 1            |\n|    value_loss           | 17           |\n------------------------------------------\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Isaac Lab (Linux)\nDESCRIPTION: Commands to install necessary dependencies for Isaac Lab on Linux using apt and the isaaclab.sh script.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n# these dependency are needed by robomimic which is not available on Windows\nsudo apt install cmake build-essential\n\n./isaaclab.sh --install # or \"./isaaclab.sh -i\"\n```\n\n----------------------------------------\n\nTITLE: Installing KubeRay Dependencies in Bash\nDESCRIPTION: This script shows the command to install additional Python dependencies required for using KubeRay clusters on Google GKE with the cluster launch file.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npython3 -p -m pip install kubernetes Jinja2\n```\n\n----------------------------------------\n\nTITLE: Stopping the Isaac Lab Docker Container\nDESCRIPTION: Command to stop the running Isaac Lab Docker container when it's no longer needed. The container image persists for future use.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_8\n\nLANGUAGE: console\nCODE:\n```\n./container.py stop\n```\n\n----------------------------------------\n\nTITLE: Updated Import Path for Isaac Lab Assets\nDESCRIPTION: Shows the new import pattern after restructuring, where robot configurations are now accessed through the isaaclab_assets.robots namespace instead of directly from lab_assets.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab_assets.robots.anymal import ANYMAL_C_CFG\n```\n\n----------------------------------------\n\nTITLE: Simulation Context Creation from Config\nDESCRIPTION: The SimulationContext class in the sim module now allows creation of a simulation context from a configuration object.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# This code is implied from the changelog, not explicitly shown\nfrom isaaclab.sim import SimulationContext, SimulationContextConfig\n\ncontext_cfg = SimulationContextConfig()\ncontext = SimulationContext(context_cfg)\n```\n\n----------------------------------------\n\nTITLE: Installing Ray Locally (Bash)\nDESCRIPTION: Installs a specific version (2.31.0) of the Ray library along with its default dependencies using pip. This is a prerequisite step performed on the local machine before interacting with or setting up Ray clusters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npython3 -p -m pip install ray[default]==2.31.0\n```\n\n----------------------------------------\n\nTITLE: Importing the Unitree H1 Robot Asset\nDESCRIPTION: Code showing how to import the Unitree H1 robot model from the isaaclab_assets extension to use in the modified environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/modify_direct_rl_env.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Original imports\nimport torch\n\nfrom isaaclab.assets import ArticulationCfg, AssetBaseCfg, RigidObjectCfg, TerrainImporter\nfrom isaaclab.assets.unitree import UnitreeH1\nfrom isaaclab.environments.direct import DirectEnv, DirectEnvCfg\nfrom isaaclab.observations import HistoryWrapper, ObservationCombiner\nfrom isaaclab.observations.direct import ArticulationObserver, RootStateObserver, SoftDofObserver\nfrom isaaclab.rewards import (\n    ExponentialPositiveRV,\n    ExponentialXRV,\n    GaussianRV,\n    GaussianXRV,\n    MultiplicativeCombiner,\n    RewardCombiner,\n    RewardFns,\n    RewardTerm,\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Isaac Lab (Windows)\nDESCRIPTION: Command to install necessary dependencies for Isaac Lab on Windows using the isaaclab.bat script.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_18\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat --install :: or \"isaaclab.bat -i\"\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for IsaacLab RL\nDESCRIPTION: ReStructuredText documentation layout defining the module structure and automodule directives for the IsaacLab RL framework wrappers.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/api/lab_rl/isaaclab_rl.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\nisaaclab_rl\n===========\n\n.. automodule:: isaaclab_rl\n\nRL-Games Wrapper\n----------------\n\n.. automodule:: isaaclab_rl.rl_games\n   :members:\n   :show-inheritance:\n\nRSL-RL Wrapper\n--------------\n\n.. automodule:: isaaclab_rl.rsl_rl\n   :members:\n   :imported-members:\n   :show-inheritance:\n\nSKRL Wrapper\n------------\n\n.. automodule:: isaaclab_rl.skrl\n   :members:\n   :show-inheritance:\n\nStable-Baselines3 Wrapper\n-------------------------\n\n.. automodule:: isaaclab_rl.sb3\n   :members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Displaying Isaac Lab VSCode Directory Structure in Bash\nDESCRIPTION: This snippet shows the directory structure of the .vscode folder in the Isaac Lab project, including configuration files and setup scripts.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/developer-guide/vs_code.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n.vscode\nâ”œâ”€â”€ tools\nâ”‚   â”œâ”€â”€ launch.template.json\nâ”‚   â”œâ”€â”€ settings.template.json\nâ”‚   â””â”€â”€ setup_vscode.py\nâ”œâ”€â”€ extensions.json\nâ”œâ”€â”€ launch.json  # <- this is generated by setup_vscode.py\nâ”œâ”€â”€ settings.json  # <- this is generated by setup_vscode.py\nâ””â”€â”€ tasks.json\n```\n\n----------------------------------------\n\nTITLE: Upgrading pip to Latest Version - Bash (Linux)\nDESCRIPTION: Updates the pip installer to the most recent version within the current Python environment on Linux. It may be necessary to avoid compatibility issues when installing Isaac Sim and dependencies. Prerequisite: a Python environment activated. No special inputs required.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade pip\n```\n\n----------------------------------------\n\nTITLE: Installing Extension Dependencies via Command Line\nDESCRIPTION: Command line example for installing all dependencies for extensions using the provided install_deps.py script. The script handles apt and ROS dependencies specified in extension.toml files.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/developer-guide/development.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# execute from the root of the repository\n# the script expects the type of dependencies to install and the path to the extensions directory\n# available types are: 'apt', 'rosdep' and 'all'\npython tools/install_deps.py all ${ISAACLAB_PATH}/source\n```\n\n----------------------------------------\n\nTITLE: Verifying Isaac Lab Installation (Windows)\nDESCRIPTION: Commands to verify the successful installation of Isaac Lab on Windows by running a sample script.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_24\n\nLANGUAGE: batch\nCODE:\n```\n:: Option 1: Using the isaaclab.bat executable\n:: note: this works for both the bundled python and the virtual environment\nisaaclab.bat -p scripts\\tutorials\\00_sim\\create_empty.py\n\n:: Option 2: Using python in your virtual environment\npython scripts\\tutorials\\00_sim\\create_empty.py\n```\n\n----------------------------------------\n\nTITLE: Creating and Activating Python venv Environment for Isaac Sim - Bash (Linux)\nDESCRIPTION: This snippet sets up a Python 3.10 virtual environment named 'env_isaaclab' using venv on Linux, then activates it. It requires Python 3.10 pre-installed. The environment isolates dependencies for Isaac Sim and Isaac Lab, preventing system-wide conflicts. Outputs are a new directory and an activated shell session within the environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# create a virtual environment named env_isaaclab with python3.10\npython3.10 -m venv env_isaaclab\n# activate the virtual environment\nsource env_isaaclab/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Defining Required Environment Parameters in Python\nDESCRIPTION: Configuration parameters that must be set for each environment in Isaac Lab, including decimation, episode length, action space, observation space, and state space.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndecimation = 2\nepisode_length_s = 5.0\naction_space = 1\nobservation_space = 4\nstate_space = 0\n```\n\n----------------------------------------\n\nTITLE: Executing a Custom Isaac Lab Python Script (Bash)\nDESCRIPTION: Demonstrates the command to run a custom Python script (`my_awesome_script.py`) that utilizes the Isaac Lab extensions. This assumes the script is located in the current directory and that the Python environment containing the Isaac Lab installation is currently active.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\npython my_awesome_script.py\n```\n\n----------------------------------------\n\nTITLE: Excluding Paths in VSCode Pylance to Prevent Crashes (JSON)\nDESCRIPTION: Illustrates how to exclude certain Omniverse package paths from Pylance analysis by commenting them out or removing them from the `python.analysis.extraPaths` setting in VSCode's `settings.json`. This can resolve memory issues and crashes caused by indexing too many files, especially unused Omniverse UI or service packages. Replace `<path-to-isaac-sim>` with the actual path.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/templates/external/README.md#2025-04-23_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n\"<path-to-isaac-sim>/extscache/omni.anim.*\"         // Animation packages\n\"<path-to-isaac-sim>/extscache/omni.kit.*\"          // Kit UI tools\n\"<path-to-isaac-sim>/extscache/omni.graph.*\"        // Graph UI tools\n\"<path-to-isaac-sim>/extscache/omni.services.*\"     // Services tools\n...\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch 2.5.1 for CUDA 11 (Bash)\nDESCRIPTION: Installs PyTorch version 2.5.1 and torchvision 0.20.1 specifically built for CUDA 11.8 using pip. It specifies the PyTorch download index URL to ensure the correct CUDA compatibility. This step is required on Windows and recommended on Linux before installing Isaac Lab.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu118\n```\n\n----------------------------------------\n\nTITLE: Using isaaclab.bat Helper Script on Windows - Text\nDESCRIPTION: Demonstrates running isaaclab.bat with the --help argument to list available project management options on Windows. The batch script handles extension installation, formatting, Python execution, simulator launch, VSCode setup, documentation, and environment creation. The script should be executed in a command prompt where the project is located. Outputs help information to the console.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_14\n\nLANGUAGE: text\nCODE:\n```\nisaaclab.bat --help\n\nusage: isaaclab.bat [-h] [-i] [-f] [-p] [-s] [-v] [-d] [-n] [-c] -- Utility to manage Isaac Lab.\n\noptional arguments:\n   -h, --help           Display the help content.\n   -i, --install [LIB]  Install the extensions inside Isaac Lab and learning frameworks (rl_games, rsl_rl, sb3, skrl) as extra dependencies. Default is 'all'.\n   -f, --format         Run pre-commit to format the code and check lints.\n   -p, --python         Run the python executable provided by Isaac Sim or virtual environment (if active).\n   -s, --sim            Run the simulator executable (isaac-sim.bat) provided by Isaac Sim.\n   -t, --test           Run all python unittest tests.\n   -v, --vscode         Generate the VSCode settings file from template.\n   -d, --docs           Build the documentation from source using sphinx.\n   -n, --new            Create a new external project or internal task from template.\n   -c, --conda [NAME]   Create the conda environment for Isaac Lab. Default name is 'env_isaaclab'.\n```\n\n----------------------------------------\n\nTITLE: Creating Conda Environment for Isaac Lab (Bash)\nDESCRIPTION: Creates a Conda virtual environment named 'env_isaaclab' using Python 3.10 and then activates it. This is a recommended first step for isolating the Isaac Lab installation dependencies.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda create -n env_isaaclab python=3.10\nconda activate env_isaaclab\n```\n\n----------------------------------------\n\nTITLE: Installing Specific Learning Framework in Isaac Lab (Linux)\nDESCRIPTION: This command installs a specific learning framework (rl_games in this example) in Isaac Lab on Linux systems. Other valid options include rsl_rl, sb3, skrl, robomimic, and none.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh --install rl_games  # or \"./isaaclab.sh -i rl_games\"\n```\n\n----------------------------------------\n\nTITLE: Visualizing Trained Policy Results\nDESCRIPTION: Command to visualize the trained policy results with 64 environments. The simulation can be stopped by closing the window or using Ctrl+C.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/policy_inference_in_usd.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Velocity-Rough-H1-v0 --num_envs 64 --checkpoint logs/rsl_rl/h1_rough/EXPERIMENT_NAME/POLICY_FILE.pt\n```\n\n----------------------------------------\n\nTITLE: Initializing Replicator BasicWriter in Python\nDESCRIPTION: Sets up the Replicator BasicWriter to save camera output images in numpy format. This creates a writer object that can be used to save various sensor data streams.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/save_camera_output.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nrep_writer = rep.BasicWriter(\n    output_dir=str(scripts_dir / \"tutorials/04_sensors/outputs\"),\n    rgb=True,\n    semantic_segmentation=True,\n    instance_segmentation=True,\n    distance=True,\n    normals=True,\n    nest_data=False,\n)\n```\n\n----------------------------------------\n\nTITLE: Launching and Entering Isaac Lab Docker Container\nDESCRIPTION: Commands to start the Isaac Lab Docker container in detached mode and enter it. This snippet also shows how to customize the compose configuration with additional files.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/docker.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Launch the container in detached mode\n# We don't pass an image extension arg, so it defaults to 'base'\n./docker/container.py start\n\n# If we want to add .env or .yaml files to customize our compose config,\n# we can simply specify them in the same manner as the compose cli\n# ./docker/container.py start --file my-compose.yaml --env-file .env.my-vars\n\n# Enter the container\n# We pass 'base' explicitly, but if we hadn't it would default to 'base'\n./docker/container.py enter base\n```\n\n----------------------------------------\n\nTITLE: Listing Python Libraries for CLI Management and Templating\nDESCRIPTION: This text lists Python libraries categorized by their purpose. 'InquirerPy' and 'rich' are listed under '# CLI management', indicating their use for creating command-line interfaces. 'Jinja2' is listed under '# templating', suggesting its use for generating text-based formats (like code, HTML, etc.) from templates. This serves as a dependency list.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# CLI management\nInquirerPy\nrich\n# templating\nJinja2\n```\n\n----------------------------------------\n\nTITLE: Importing Isaac Lab Velocity Environment - Python\nDESCRIPTION: Example showing how to update the import statement for velocity environment from Orbit to Isaac Lab format\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_orbit.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab_tasks.manager_based.locomotion.velocity.velocity_env_cfg ...\n```\n\n----------------------------------------\n\nTITLE: Launching TensorBoard for Log Visualization in Isaac Lab (Windows)\nDESCRIPTION: Executes TensorBoard using `isaaclab.bat` to visualize training logs stored in the default `logs` directory. This command should be run from the root directory of the Isaac Lab repository on a Windows system. It utilizes the `-p` flag to pass arguments to the python interpreter and `-m` to run the tensorboard module.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/reinforcement-learning/rl_existing_scripts.rst#2025-04-23_snippet_13\n\nLANGUAGE: batch\nCODE:\n```\n:: execute from the root directory of the repository\nisaaclab.bat -p -m tensorboard.main --logdir=logs\n```\n\n----------------------------------------\n\nTITLE: Bad Example: Python Function with Type Hints Only in Docstring\nDESCRIPTION: Illustrates an incorrect Python function definition where type hints for parameters (`a`, `b`) and the return value are specified within the docstring (`Args` and `Returns` sections) but are missing from the function signature itself. This is not the standard way to use type hints.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef my_function(a, b):\n   \"\"\"Adds two numbers.\n\n   This function is a bad example. Reason: Type hints in the docstring and not in the\n   function signature.\n\n   Args:\n      a (int): The first argument.\n      b (int): The second argument.\n\n   Returns:\n      int: The sum of the two arguments.\n   \"\"\"\n   return a + b\n```\n\n----------------------------------------\n\nTITLE: Setting Linux Environment Variables for Isaac Sim\nDESCRIPTION: Exports environment variables ISAACSIM_PATH (pointing to the Isaac Sim root directory, assumed to be ${HOME}/isaacsim) and ISAACSIM_PYTHON_EXE (pointing to the Isaac Sim python executable) in a Linux bash shell. These variables are used for convenience in subsequent commands.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Isaac Sim root directory\nexport ISAACSIM_PATH=\"${HOME}/isaacsim\"\n# Isaac Sim python executable\nexport ISAACSIM_PYTHON_EXE=\"${ISAACSIM_PATH}/python.sh\"\n```\n\n----------------------------------------\n\nTITLE: Cloning Isaac Lab Source Repository via SSH - Bash\nDESCRIPTION: Clones the Isaac Lab source code repository from GitHub using SSH. This provides the full codebase for local development. Requires git installed and SSH keys set up for authentication. Output is a new directory named 'IsaacLab'.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:isaac-sim/IsaacLab.git\n```\n\n----------------------------------------\n\nTITLE: Running Policy Inference in USD Environment\nDESCRIPTION: Command to run inference using the exported policy in a warehouse environment with the H1 robot.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/policy_inference_in_usd.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/tutorials/03_envs/policy_inference_in_usd.py --checkpoint logs/rsl_rl/h1_rough/EXPERIMENT_NAME/exported/policy.pt\n```\n\n----------------------------------------\n\nTITLE: Creating Bibliography with Sphinx Directive in reStructuredText\nDESCRIPTION: This is a reStructuredText directive that tells Sphinx to generate a bibliography from citation references throughout the documentation. The bibliography directive with no parameters will include all citations referenced in the document.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/bibliography.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. bibliography::\n```\n\n----------------------------------------\n\nTITLE: Entering the Isaac Lab Docker Container\nDESCRIPTION: Command to enter the running Isaac Lab Docker container, which provides access to the Isaac Lab repository and Isaac Sim libraries.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/run_docker_example.rst#2025-04-23_snippet_3\n\nLANGUAGE: console\nCODE:\n```\npython docker/container.py enter\n```\n\n----------------------------------------\n\nTITLE: Camera Rotation Conventions in Camera Class\nDESCRIPTION: The Camera class now supports three different rotation conventions: OpenGL, ROS, and World. These can be used to declare camera offsets and set world poses.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# This code is implied from the changelog, not explicitly shown\nfrom isaaclab.sensors import Camera, CameraCfg\n\ncamera_cfg = CameraCfg(offset=CameraCfg.OffsetCfg(convention=\"opengl\"))\ncamera = Camera(camera_cfg)\ncamera.set_world_pose(convention=\"ros\")\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Container Management with Python Script\nDESCRIPTION: This snippet shows how to start the newer Python-based Docker container manager for IsaacLab. The recommended workflow uses 'container.py' to directly manage containers and related overlays, replacing the complex legacy bash script. It requires Python as well as access to Docker from the command line. Input is the 'start' argument; execution starts the necessary container(s) or process defined in the Python script.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n./docker/container.py start\n```\n\n----------------------------------------\n\nTITLE: Defining Cartpole Environment Configuration in Python\nDESCRIPTION: Python class definition for CartpoleEnvCfg, which inherits from DirectRLEnvCfg. It includes simulation settings, robot configuration, scene setup, and environment parameters for the Cartpole task.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass CartpoleEnvCfg(DirectRLEnvCfg):\n\n    # simulation\n    sim: SimulationCfg = SimulationCfg(dt=1 / 120)\n    # robot\n    robot_cfg: ArticulationCfg = CARTPOLE_CFG.replace(\n        prim_path=\"/World/envs/env_.*/Robot\")\n    cart_dof_name = \"slider_to_cart\"\n    pole_dof_name = \"cart_to_pole\"\n    # scene\n    scene: InteractiveSceneCfg = InteractiveSceneCfg(\n      num_envs=4096, env_spacing=4.0, replicate_physics=True)\n    # env\n    decimation = 2\n    episode_length_s = 5.0\n    action_scale = 100.0  # [N]\n    action_space = 1\n    observation_space = 4\n    state_space = 0\n    # reset\n    max_cart_pos = 3.0\n    initial_pole_angle_range = [-0.25, 0.25]\n    # reward scales\n    rew_scale_alive = 1.0\n    rew_scale_terminated = -2.0\n    rew_scale_pole_pos = -1.0\n    rew_scale_cart_vel = -0.01\n    rew_scale_pole_vel = -0.005\n\n\nCARTPOLE_CFG = ArticulationCfg(\n  spawn=sim_utils.UsdFileCfg(\n    usd_path=f\"{ISAACLAB_NUCLEUS_DIR}/.../cartpole.usd\",\n    rigid_props=sim_utils.RigidBodyPropertiesCfg(\n      rigid_body_enabled=True,\n      max_linear_velocity=1000.0,\n      max_angular_velocity=1000.0,\n      max_depenetration_velocity=100.0,\n      enable_gyroscopic_forces=True,\n    ),\n    articulation_props=sim_utils.ArticulationRootPropertiesCfg(\n      enabled_self_collisions=False,\n      solver_position_iteration_count=4,\n      solver_velocity_iteration_count=0,\n      sleep_threshold=0.005,\n      stabilization_threshold=0.001,\n    ),\n  ),\n  init_state=ArticulationCfg.InitialStateCfg(\n    pos=(0.0, 0.0, 2.0),\n    joint_pos={\"slider_to_cart\": 0.0, \"cart_to_pole\": 0.0}\n  ),\n  actuators={\n    \"cart_actuator\": ImplicitActuatorCfg(\n       joint_names_expr=[\"slider_to_cart\"],\n       effort_limit=400.0,\n       velocity_limit=100.0,\n       stiffness=0.0,\n       damping=10.0,\n    ),\n    \"pole_actuator\": ImplicitActuatorCfg(\n       joint_names_expr=[\"cart_to_pole\"], effort_limit=400.0,\n       velocity_limit=100.0, stiffness=0.0, damping=0.0\n    ),\n  },\n)\n```\n\n----------------------------------------\n\nTITLE: Identifying Root Cause Error in Isaac Sim Crash Log (Bash)\nDESCRIPTION: This Bash snippet isolates the actual error from a more extensive Isaac Sim crash log. It shows the specific `TypeError` occurring within the `pre_process_actions` function in the `collect_demonstrations.py` script. This demonstrates the importance of scrolling up past the `__del__` related exceptions in a crash log to find the originating issue.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nTraceback (most recent call last):\nFile \"scripts/imitation_learning/robomimic/tools/collect_demonstrations.py\", line 166, in <module>\n    main()\nFile \"scripts/imitation_learning/robomimic/tools/collect_demonstrations.py\", line 126, in main\n    actions = pre_process_actions(delta_pose, gripper_command)\nFile \"scripts/imitation_learning/robomimic/tools/collect_demonstrations.py\", line 57, in pre_process_actions\n    return torch.concat([delta_pose, gripper_vel], dim=1)\nTypeError: expected Tensor as element 1 in argument 0, but got int\n```\n\n----------------------------------------\n\nTITLE: Cloning Isaac Lab Source Repository via HTTPS - Bash\nDESCRIPTION: Uses git to clone the Isaac Lab repository via HTTPS from GitHub. This alternative does not require SSH keys and is suitable for users with only username/password credentials. Produces a local 'IsaacLab' directory containing the project code.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/isaac-sim/IsaacLab.git\n```\n\n----------------------------------------\n\nTITLE: Installing CUDA 11-Compatible PyTorch via Pip - Bash\nDESCRIPTION: Installs PyTorch 2.5.1 and torchvision 0.20.1 with CUDA 11.8 support using a specified PyTorch wheel index URL. This step is relevant when ensuring CUDA compatibility on both Linux and Windows for Isaac Sim. Prerequisite: a compatible CUDA 11 installation. The command ensures you obtain the correct CUDA-enabled build.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu118\n```\n\n----------------------------------------\n\nTITLE: Creating Isaac Lab Conda Environment (Windows)\nDESCRIPTION: Commands to create a Conda environment for Isaac Lab on Windows. Includes options for default and custom environment names.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_15\n\nLANGUAGE: batch\nCODE:\n```\n:: Option 1: Default name for conda environment is 'env_isaaclab'\nisaaclab.bat --conda  :: or \"isaaclab.bat -c\"\n:: Option 2: Custom name for conda environment\nisaaclab.bat --conda my_env  :: or \"isaaclab.bat -c my_env\"\n```\n\n----------------------------------------\n\nTITLE: Running Environment with Animation Recording in Isaac Lab\nDESCRIPTION: This bash command demonstrates how to run a state-machine example in Isaac Lab with Fabric disabled, which allows for animation recording. The --disable_fabric flag is essential for the Stage Recorder to capture all motion and property changes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/record_animation.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/environments/state_machine/lift_cube_sm.py --num_envs 8 --device cpu --disable_fabric\n```\n\n----------------------------------------\n\nTITLE: Building the Isaac Automator Container - Bash\nDESCRIPTION: This snippet runs the build script for Isaac Automator, creating the Docker container environment required for subsequent deployment and automation. Must be executed from the root of the cloned Isaac Automator repository on a Linux system with Docker installed.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./build\n```\n\n----------------------------------------\n\nTITLE: Example Output of Pip Show Command for RSL-RL\nDESCRIPTION: Sample output from the 'pip show' command, displaying details about the RSL-RL library installation, including its version, location, and dependencies.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/add_own_library.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nName: rsl_rl\nVersion: 2.0.2\nSummary: Fast and simple RL algorithms implemented in pytorch\nHome-page: https://github.com/leggedrobotics/rsl_rl\nAuthor: ETH Zurich, NVIDIA CORPORATION\nAuthor-email:\nLicense: BSD-3\nLocation: /home/user/git/rsl_rl\nRequires: torch, torchvision, numpy, GitPython, onnx\nRequired-by:\n```\n\n----------------------------------------\n\nTITLE: Cloning Isaac Lab Repository using HTTPS\nDESCRIPTION: Clones the Isaac Lab Git repository from GitHub using the HTTPS protocol. This command downloads the source code into a new directory named 'IsaacLab'.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/isaac-sim/IsaacLab.git\n```\n\n----------------------------------------\n\nTITLE: Configuring IsaacLab SimulationCfg for CPU (Old Method) in Python\nDESCRIPTION: Shows the previous way to configure `sim_utils.SimulationCfg` for CPU simulation in IsaacLab prior to v1.2.0. This required explicitly setting `use_gpu_pipeline=False` and `physx.use_gpu=False` alongside `device=\"cpu\". This method is now deprecated.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n.. code:: python\n\n    sim_utils.SimulationCfg(device=\"cpu\", use_gpu_pipeline=False, dt=0.01, physx=sim_utils.PhysxCfg(use_gpu=False))\n```\n\n----------------------------------------\n\nTITLE: Creating and Activating Python venv Environment for Isaac Sim - Batch (Windows)\nDESCRIPTION: This snippet illustrates how to create and activate a Python 3.10 venv-based virtual environment on Windows named 'env_isaaclab'. Python 3.10 should be installed and available on the PATH. The resulting environment supports dependency isolation for Isaac Sim development. Outputs include the environment directory and an activated shell.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_2\n\nLANGUAGE: batch\nCODE:\n```\n# create a virtual environment named env_isaaclab with python3.10\npython3.10 -m venv env_isaaclab\n# activate the virtual environment\nenv_isaaclab\\Scripts\\activate\n```\n\n----------------------------------------\n\nTITLE: Verifying Isaac Sim Installation via Command Line (Bash)\nDESCRIPTION: Executes the 'isaacsim' command-line tool to launch the Isaac Sim simulator and verify that the installation was successful. This command should be run within the activated virtual environment where Isaac Lab was installed. The '--help' argument can be passed to see available options.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# note: you can pass the argument \"--help\" to see all arguments possible.\nisaacsim\n```\n\n----------------------------------------\n\nTITLE: Creating Isaac Lab Conda Environment (Linux)\nDESCRIPTION: Commands to create a Conda environment for Isaac Lab on Linux. Includes options for default and custom environment names.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# Option 1: Default name for conda environment is 'env_isaaclab'\n./isaaclab.sh --conda  # or \"./isaaclab.sh -c\"\n# Option 2: Custom name for conda environment\n./isaaclab.sh --conda my_env  # or \"./isaaclab.sh -c my_env\"\n```\n\n----------------------------------------\n\nTITLE: Specifying Teleoperation Device (New CLI) using Bash\nDESCRIPTION: Illustrates the current command-line method in IsaacLab v1.2.0+ using `./isaaclab.sh` to specify the teleoperation input device (e.g., `keyboard`) for a standalone script. It uses the dedicated `--teleop_device` argument to avoid conflicts with the simulation `--device` argument.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n.. code:: bash\n\n    ./isaaclab.sh -p source/standalone/environments/teleoperation/teleop_se3_agent.py --task Isaac-Lift-Cube-Franka-IK-Rel-v0 --num_envs 1 --teleop_device keyboard\n```\n\n----------------------------------------\n\nTITLE: Running Isaac Lab Tasks Remotely - Windows Batch\nDESCRIPTION: This snippet is the Windows equivalent of launching Isaac Lab in the cloud, using the 'isaaclab.bat' script. It passes the training script and task as arguments. Requires that the cloud environment has a Windows interface and relevant batch files.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_9\n\nLANGUAGE: batch\nCODE:\n```\n./isaaclab.bat -p scripts/reinforcement_learning/rl_games/train.py --task=Isaac-Cartpole-v0\n```\n\n----------------------------------------\n\nTITLE: Creating Environment in Previous Tutorial\nDESCRIPTION: Code snippet showing the manual approach to creating an environment by directly instantiating environment and configuration classes.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/register_rl_env_gym.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# create environment configuration\nenv_cfg = CartpoleCfg()\n# update configuration\nenv_cfg.sim.num_envs = 32\n# create environment\nenv = ManagerBasedRLEnv(cfg=env_cfg)\n```\n\n----------------------------------------\n\nTITLE: Authenticating with NVIDIA GPU Cloud (NGC) - Docker - Bash\nDESCRIPTION: This snippet shows how to log in to the NVIDIA GPU Cloud (NGC) container registry using Docker. The username should be set to $oauthtoken and the password should be the user's API key. Docker must be installed and the user needs an NGC API key before running this command.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker login nvcr.io\n```\n\n----------------------------------------\n\nTITLE: Building Multi-Version Documentation on Linux\nDESCRIPTION: This snippet illustrates how to navigate to the docs directory, install dependencies, build the multi-version documentation, and open it in a browser on Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# 1. Navigate to the docs directory and install dependencies\ncd docs\npip install -r requirements.txt\n\n# 2. Build the multi-version documentation\nmake multi-docs\n\n# 3. Open the multi-version docs\nxdg-open _build/index.html\n```\n\n----------------------------------------\n\nTITLE: Upgrading PyTorch for 50 Series GPUs\nDESCRIPTION: This command upgrades PyTorch to the latest nightly build for compatibility with 50 series GPUs, as the default PyTorch 2.5.1 in Isaac Sim may not be suitable.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch 2.5.1 for CUDA 12 (Bash)\nDESCRIPTION: Installs PyTorch version 2.5.1 and torchvision 0.20.1 specifically built for CUDA 12.1 using pip. It specifies the PyTorch download index URL for CUDA 12.1 compatibility. This step is necessary on Windows and advised on Linux prior to the Isaac Lab installation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu121\n```\n\n----------------------------------------\n\nTITLE: Installing Specific Learning Framework (Windows)\nDESCRIPTION: Command to install a specific learning framework (e.g., rl_games) for Isaac Lab on Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_20\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat --install rl_games :: or \"isaaclab.bat -i rl_games\"\n```\n\n----------------------------------------\n\nTITLE: Example Isaac Sim Crash Log with Destructor Errors in Bash\nDESCRIPTION: This Bash snippet shows a typical traceback from an Isaac Sim crash. It includes the primary error (`TypeError` in `collect_demonstrations.py`) followed by multiple `Exception ignored in: ... __del__` messages. These subsequent exceptions often occur during the Python interpreter's cleanup phase and can obscure the original error. The log ends with a segmentation fault, indicating a severe crash.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n... \n\n[INFO]: Completed setting up the environment...\n\nTraceback (most recent call last):\nFile \"scripts/imitation_learning/robomimic/collect_demonstrations.py\", line 166, in <module>\n    main()\nFile \"scripts/imitation_learning/robomimic/collect_demonstrations.py\", line 126, in main\n    actions = pre_process_actions(delta_pose, gripper_command)\nFile \"scripts/imitation_learning/robomimic/collect_demonstrations.py\", line 57, in pre_process_actions\n    return torch.concat([delta_pose, gripper_vel], dim=1)\nTypeError: expected Tensor as element 1 in argument 0, but got int\nException ignored in: <function _make_registry.<locals>._Registry.__del__ at 0x7f94ac097f80>\nTraceback (most recent call last):\nFile \"../IsaacLab/_isaac_sim/kit/extscore/omni.kit.viewport.registry/omni/kit/viewport/registry/registry.py\", line 103, in __del__\nFile \"../IsaacLab/_isaac_sim/kit/extscore/omni.kit.viewport.registry/omni/kit/viewport/registry/registry.py\", line 98, in destroy\nTypeError: 'NoneType' object is not callable\nException ignored in: <function _make_registry.<locals>._Registry.__del__ at 0x7f94ac097f80>\nTraceback (most recent call last):\nFile \"../IsaacLab/_isaac_sim/kit/extscore/omni.kit.viewport.registry/omni/kit/viewport/registry/registry.py\", line 103, in __del__\nFile \"../IsaacLab/_isaac_sim/kit/extscore/omni.kit.viewport.registry/omni/kit/viewport/registry/registry.py\", line 98, in destroy\nTypeError: 'NoneType' object is not callable\nException ignored in: <function SettingChangeSubscription.__del__ at 0x7fa2ea173e60>\nTraceback (most recent call last):\nFile \"../IsaacLab/_isaac_sim/kit/kernel/py/omni/kit/app/_impl/__init__.py\", line 114, in __del__\nAttributeError: 'NoneType' object has no attribute 'get_settings'\nException ignored in: <function RegisteredActions.__del__ at 0x7f935f5cae60>\nTraceback (most recent call last):\nFile \"../IsaacLab/_isaac_sim/extscache/omni.kit.viewport.menubar.lighting-104.0.7/omni/kit/viewport/menubar/lighting/actions.py\", line 345, in __del__\nFile \"../IsaacLab/_isaac_sim/extscache/omni.kit.viewport.menubar.lighting-104.0.7/omni/kit/viewport/menubar/lighting/actions.py\", line 350, in destroy\nTypeError: 'NoneType' object is not callable\n2022-12-02 15:41:54 [18,514ms] [Warning] [carb.audio.context] 1 contexts were leaked\n../IsaacLab/_isaac_sim/python.sh: line 41: 414372 Segmentation fault      (core dumped) $python_exe \"$@\" $args\nThere was an error running python\n```\n\n----------------------------------------\n\nTITLE: Running an Isaac Lab Task with a Zero-Action Agent (Bash)\nDESCRIPTION: Executes a script (`scripts/zero_agent.py`) that runs a specified task (`<TASK_NAME>`) using a dummy agent which outputs zero actions. This is useful for verifying environment configuration and basic simulation functionality. Requires the project and Isaac Lab to be installed. Use the Isaac Lab script (`isaaclab.sh|bat -p`) if Isaac Lab isn't in the Python environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/templates/external/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# use 'FULL_PATH_TO_isaaclab.sh|bat -p' instead of 'python' if Isaac Lab is not installed in Python venv or conda\npython scripts/zero_agent.py --task=<TASK_NAME>\n```\n\n----------------------------------------\n\nTITLE: Migrating Import Statements for Isaac Lab Assets\nDESCRIPTION: This example demonstrates how to update import statements to reflect the reorganization of the isaaclab_assets extension, where robot configurations have been moved to a subdirectory structure.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom omni.isaac.lab_assets.anymal import ANYMAL_C_CFG\n```\n\n----------------------------------------\n\nTITLE: Providing Credentials for NGC Docker Login - Text Prompt\nDESCRIPTION: This snippet displays the prompts for entering credentials when authenticating with NGC via Docker. The user inputs the special username $oauthtoken and their NGC API Key as the password. Used during secure authentication steps.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nUsername: $oauthtoken\nPassword: <Your NGC API Key>\n```\n\n----------------------------------------\n\nTITLE: Enabling Faulthandler in AppLauncher\nDESCRIPTION: The AppLauncher class now enables the faulthandler module by default to catch segfaults and print stack traces.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# This code is implied from the changelog, not explicitly shown\nfrom isaaclab.app import AppLauncher\n\napp = AppLauncher()\n# faulthandler is enabled by default\n```\n\n----------------------------------------\n\nTITLE: Upgrading Pip Package Manager (Windows Batch)\nDESCRIPTION: Updates the pip package installer to its latest version on a Windows system using the 'python -m pip' invocation. This ensures the package manager is up-to-date before proceeding with the Isaac Lab installation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_6\n\nLANGUAGE: batch\nCODE:\n```\npython -m pip install --upgrade pip\n```\n\n----------------------------------------\n\nTITLE: Creating venv Environment for Isaac Lab (Windows Batch)\nDESCRIPTION: Creates a Python virtual environment named 'env_isaaclab' using the 'venv' module with Python 3.10 on a Windows system, and then activates it by running the activate script located within the environment's 'Scripts' directory. This is the Windows equivalent of the Linux venv setup.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_2\n\nLANGUAGE: batch\nCODE:\n```\n# create a virtual environment named env_isaaclab with python3.10\npython3.10 -m venv env_isaaclab\n# activate the virtual environment\nenv_isaaclab\\Scripts\\activate\n```\n\n----------------------------------------\n\nTITLE: Running Multi-Asset Demo in Isaac Lab\nDESCRIPTION: Commands to use the interactive scene and spawn varying assets in individual environments. This demo shows how to manage multiple assets through the same simulation handles.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/showroom.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/multi_asset.py\n```\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -p scripts\\demos\\multi_asset.py\n```\n\n----------------------------------------\n\nTITLE: Enabling OmniPVD Capture in Isaac Lab\nDESCRIPTION: Command line syntax for launching Isaac Lab with PhysX Visual Debugger capture enabled. This helps with debugging physics simulation issues by recording PhysX simulation data to a specified directory.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/demos/bipeds.py --kit_args \"--/persistent/physics/omniPvdOvdRecordingDirectory=/tmp/ --/physics/omniPvdOutputEnabled=true\" --headless\n```\n\n----------------------------------------\n\nTITLE: Running the Motion Viewer Script in Bash\nDESCRIPTION: This command executes the `motion_viewer.py` Python script from the `motions` folder to visualize skeleton motion data stored in a NumPy file. It requires the Python interpreter and the script itself to be present. The `--file` argument specifies the path to the `.npz` motion file containing the recorded motion data to be visualized.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab_tasks/isaaclab_tasks/direct/humanoid_amp/motions/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython motion_viewer.py --file MOTION_FILE_NAME.npz\n```\n\n----------------------------------------\n\nTITLE: Citing Isaac Lab (Orbit) in Academic Publications\nDESCRIPTION: BibTeX citation format for referencing the Isaac Lab framework (which was initiated from the Orbit framework) in academic publications.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@article{mittal2023orbit,\n   author={Mittal, Mayank and Yu, Calvin and Yu, Qinxi and Liu, Jingzhou and Rudin, Nikita and Hoeller, David and Yuan, Jia Lin and Singh, Ritvik and Guo, Yunrong and Mazhar, Hammad and Mandlekar, Ajay and Babich, Buck and State, Gavriel and Hutter, Marco and Garg, Animesh},\n   journal={IEEE Robotics and Automation Letters},\n   title={Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments},\n   year={2023},\n   volume={8},\n   number={6},\n   pages={3740-3747},\n   doi={10.1109/LRA.2023.3270034}\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Windows Environment Variables for Isaac Sim\nDESCRIPTION: Sets environment variables ISAACSIM_PATH (pointing to the Isaac Sim root directory, assumed to be C:/isaacsim) and ISAACSIM_PYTHON_EXE (pointing to the Isaac Sim python executable) in a Windows command prompt (batch). These variables are used for convenience in subsequent commands.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_1\n\nLANGUAGE: batch\nCODE:\n```\n:: Isaac Sim root directory\nset ISAACSIM_PATH=\"C:/isaacsim\"\n:: Isaac Sim python executable\nset ISAACSIM_PYTHON_EXE=\"%ISAACSIM_PATH:\\\"=%\\\\python.bat\"\n```\n\n----------------------------------------\n\nTITLE: Coloring Meshes in TerrainGenerator\nDESCRIPTION: The TerrainGenerator class now supports coloring meshes randomly, based on terrain height, or no coloring.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# This code is implied from the changelog, not explicitly shown\nfrom isaaclab.terrain import TerrainGenerator\n\nterrain_generator = TerrainGenerator()\nterrain_generator.color_mesh(\"random\")  # or \"height\" or \"none\"\n```\n\n----------------------------------------\n\nTITLE: Cloning the Isaac Automator Repository - Git - Bash\nDESCRIPTION: This snippet clones the Isaac Automator GitHub repository using the git command-line tool. It is a prerequisite step for setting up Isaac Automator for cloud deployments. Requires git to be installed on the local machine.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/cloud_installation.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/isaac-sim/IsaacAutomator.git\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch Nightly for 50 Series GPUs (Linux)\nDESCRIPTION: Command to install the latest PyTorch nightly build for 50 series GPUs on Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p -m pip install --upgrade --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128\n```\n\n----------------------------------------\n\nTITLE: Creating Isaac Sim Symbolic Link on Windows\nDESCRIPTION: Creates a directory symbolic link named `_isaac_sim` within the cloned IsaacLab directory, pointing to the actual Isaac Sim installation directory (`path_to_isaac_sim`). This is done on Windows using the `mklink /D` command after changing into the `IsaacLab` directory. Requires Administrator privileges. An example using the `C:/isaacsim` path is provided.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_13\n\nLANGUAGE: batch\nCODE:\n```\n:: enter the cloned repository\ncd IsaacLab\n:: create a symbolic link - requires launching Command Prompt with Administrator access\nmklink /D _isaac_sim path_to_isaac_sim\n:: For example: mklink /D _isaac_sim C:/isaacsim\n```\n\n----------------------------------------\n\nTITLE: Cloning RSL-RL Repository from GitHub with Bash\nDESCRIPTION: Command to clone the RSL-RL library from the GitHub repository, which is the first step in using a custom version of the library with Isaac Lab.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/add_own_library.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:leggedrobotics/rsl_rl.git\n```\n\n----------------------------------------\n\nTITLE: Installing Pre-commit Tool (Bash)\nDESCRIPTION: Installs the `pre-commit` Python package using pip. Pre-commit is used to run automated checks and code formatting before commits are made to version control.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/templates/external/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install pre-commit\n```\n\n----------------------------------------\n\nTITLE: BSD-3-Clause License Text for Isaac Lab Project\nDESCRIPTION: The complete BSD-3-Clause license text that governs the Isaac Lab framework. Includes copyright notice, conditions for redistribution, disclaimer of warranties, and limitation of liability.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/license.rst#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright (c) 2022-2025, The Isaac Lab Project Developers.\nAll rights reserved.\n\nSPDX-License-Identifier: BSD-3-Clause\n\nRedistribution and use in source and binary forms, with or without modification,\nare permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice,\n   this list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its contributors\n   may be used to endorse or promote products derived from this software without\n   specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n```\n\n----------------------------------------\n\nTITLE: Configuring Python Interpreter in VSCode settings.json\nDESCRIPTION: This JSON snippet from the .vscode/settings.json file sets the default Python interpreter path to use the Python executable provided by Omniverse for Isaac Lab development.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/developer-guide/vs_code.rst#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"python.defaultInterpreterPath\": \"${workspaceFolder}/_isaac_sim/python.sh\",\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Physics-based Schemas\nDESCRIPTION: The sim.schemas module now includes methods for defining different physics-based schemas, allowing creation and modification of schema properties based on configuration objects.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# This code is implied from the changelog, not explicitly shown\nfrom isaaclab.sim import schemas\n\nschema_cfg = schemas.PhysicsSchemaConfig()\nschemas.create_physics_schema(\"/prim/path\", schema_cfg)\n```\n\n----------------------------------------\n\nTITLE: Starting a Tuning Run in Bash\nDESCRIPTION: This script provides commands for starting a tuning run within the Docker container. It demonstrates how to enter the container and initiate a tuning run with specific parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# In a new terminal (don't close the above) , enter the image with a new shell.\ndocker container ps\ndocker exec -it <ISAAC_RAY_IMAGE_ID_FROM_CONTAINER_PS> /bin/bash\n# Start a tuning run, with one parallel worker per GPU\n./isaaclab.sh -p scripts/reinforcement_learning/ray/tuner.py \\\n  --cfg_file scripts/reinforcement_learning/ray/hyperparameter_tuning/vision_cartpole_cfg.py \\\n  --cfg_class CartpoleTheiaJobCfg \\\n  --run_mode local \\\n  --workflow scripts/reinforcement_learning/rl_games/train.py \\\n  --num_workers_per_node <NUMBER_OF_GPUS_IN_COMPUTER>\n```\n\n----------------------------------------\n\nTITLE: Checking Simulator Log Output Location\nDESCRIPTION: Example terminal output showing where to find the Isaac Sim log file. The log file location is printed at the start of the terminal output when running a standalone script.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n[INFO] Using python from: /home/${USER}/git/IsaacLab/_isaac_sim/python.sh\n...\nPassing the following args to the base kit application:  []\nLoading user config located at: '.../data/Kit/Isaac-Sim/2023.1/user.config.json'\n[Info] [carb] Logging to file: '.../logs/Kit/Isaac-Sim/2023.1/kit_20240328_183346.log'\n```\n\n----------------------------------------\n\nTITLE: Launching Isaac Sim on Windows\nDESCRIPTION: Command to launch Isaac Sim application with asset caching support on Windows systems using the -s flag.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/asset_caching.rst#2025-04-23_snippet_1\n\nLANGUAGE: batch\nCODE:\n```\nisaaclab.bat -s\n```\n\n----------------------------------------\n\nTITLE: Exiting the Simulation\nDESCRIPTION: Shows how to properly close the simulation application when finished.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/00_sim/create_empty.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# close sim app\nsimulation_app.close()\n```\n\n----------------------------------------\n\nTITLE: Accessing MLFlow Dashboard via Port Forwarding (Bash)\nDESCRIPTION: Command using `kubectl port-forward` to make the MLFlow service running within the Kubernetes cluster accessible on the local machine at `localhost:5000`. This allows viewing experiment results tracked by MLFlow through a web browser.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nkubectl port-forward service/isaacray-mlflow 5000:5000\n```\n\n----------------------------------------\n\nTITLE: Security Documentation in Markdown\nDESCRIPTION: Markdown formatted security documentation that outlines vulnerability reporting procedures, contact methods, and NVIDIA's security policies.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/SECURITY.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Security\n\nNVIDIA is dedicated to the security and trust of our software products and services, including all source code\nrepositories managed through our organization.\n\nIf you need to report a security issue, please use the appropriate contact points outlined below. **Please do\nnot report security vulnerabilities through GitHub.**\n\n## Reporting Potential Security Vulnerability in an NVIDIA Product\n\nTo report a potential security vulnerability in any NVIDIA product:\n\n- Web: [Security Vulnerability Submission Form](https://www.nvidia.com/object/submit-security-vulnerability.html)\n\n- E-Mail: psirt@nvidia.com\n\n    - We encourage you to use the following PGP key for secure email communication: [NVIDIA public PGP Key for communication](https://www.nvidia.com/en-us/security/pgp-key)\n\n    - Please include the following information:\n\n    - Product/Driver name and version/branch that contains the vulnerability\n\n    - Type of vulnerability (code execution, denial of service, buffer overflow, etc.)\n\n    - Instructions to reproduce the vulnerability\n\n    - Proof-of-concept or exploit code\n\n    - Potential impact of the vulnerability, including how an attacker could exploit the vulnerability\n\nWhile NVIDIA currently does not have a bug bounty program, we do offer acknowledgement when an\nexternally reported security issue is addressed under our coordinated vulnerability disclosure policy. Please\nvisit our [Product Security Incident Response Team (PSIRT)](https://www.nvidia.com/en-us/security/psirt-policies/)\npolicies page for more information.\n\n## NVIDIA Product Security\n\nFor all security-related concerns, please visit NVIDIA's Product Security portal at: https://www.nvidia.com/en-us/security\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Extension Directory Structure in Bash\nDESCRIPTION: Shows the typical directory structure of an Isaac Lab extension, which follows a Python package organization with Omniverse-specific configuration files and documentation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/developer-guide/development.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n<extension-name>\nâ”œâ”€â”€ config\nâ”‚   â””â”€â”€ extension.toml\nâ”œâ”€â”€ docs\nâ”‚   â”œâ”€â”€ CHANGELOG.md\nâ”‚   â””â”€â”€ README.md\nâ”œâ”€â”€ <extension-name>\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ ....\nâ”‚   â””â”€â”€ scripts\nâ”œâ”€â”€ setup.py\nâ””â”€â”€ tests\n```\n\n----------------------------------------\n\nTITLE: Building and Pushing Isaac Lab Ray Docker Image (Bash)\nDESCRIPTION: Commands to build a specialized Docker image for Isaac Lab Ray using a provided Dockerfile and push it to a specified container registry. Requires prior login to the target registry (e.g., NGC) and Docker setup. The `<REGISTRY/IMAGE_NAME>` should be replaced with the actual registry path and image name.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/ray.rst#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# Login with NGC (nvcr.io) registry first, see docker steps in repo.\npython3 docker/container.py start\n# Build the special Isaac Lab Ray Image\ndocker build -t <REGISTRY/IMAGE_NAME> -f scripts/reinforcement_learning/ray/cluster_configs/Dockerfile .\n# Push the image to your registry of choice.\ndocker push <REGISTRY/IMAGE_NAME>\n```\n\n----------------------------------------\n\nTITLE: Loading ETH Proxy Module for SLURM\nDESCRIPTION: Commands to load the eth_proxy module for internet access on ETH Zurich Euler cluster\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/cluster.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Load eth_proxy module for internet access\nmodule load eth_proxy\n\n```\n\n----------------------------------------\n\nTITLE: Accepting Isaac Sim EULA License Prompt - Bash\nDESCRIPTION: Demonstrates the initial EULA license prompt when running Isaac Sim for the first time. Users must confirm acceptance by replying \"Yes\" to the prompt. Without acceptance, the simulator will not proceed. This is an interactive CLI sequence rather than a script.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/pip_installation.rst#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nBy installing or using Isaac Sim, I agree to the terms of NVIDIA SOFTWARE LICENSE AGREEMENT (EULA)\nin https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement\n\nDo you accept the EULA? (Yes/No): Yes\n```\n\n----------------------------------------\n\nTITLE: Displaying Isaac Lab Helper Script Help (Windows)\nDESCRIPTION: Shows the help message and usage instructions for the Isaac Lab helper script `isaaclab.bat` on Windows. This script provides utilities for managing Isaac Lab extensions, formatting code, running Python/simulator, testing, VSCode settings, documentation, and conda environments.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/binaries_installation.rst#2025-04-23_snippet_11\n\nLANGUAGE: text\nCODE:\n```\nisaaclab.bat --help\n\nusage: isaaclab.bat [-h] [-i] [-f] [-p] [-s] [-v] [-d] [-n] [-c] -- Utility to manage Isaac Lab.\n\noptional arguments:\n   -h, --help           Display the help content.\n   -i, --install [LIB]  Install the extensions inside Isaac Lab and learning frameworks (rl-games, rsl-rl, sb3, skrl) as extra dependencies. Default is 'all'.\n   -f, --format         Run pre-commit to format the code and check lints.\n   -p, --python         Run the python executable provided by Isaac Sim or virtual environment (if active).\n   -s, --sim            Run the simulator executable (isaac-sim.bat) provided by Isaac Sim.\n   -t, --test           Run all python unittest tests.\n   -v, --vscode         Generate the VSCode settings file from template.\n   -d, --docs           Build the documentation from source using sphinx.\n   -n, --new            Create a new external project or internal task from template.\n   -c, --conda [NAME]   Create the conda environment for Isaac Lab. Default name is 'env_isaaclab'.\n```\n\n----------------------------------------\n\nTITLE: Viewing CPU Scaling Governor Settings\nDESCRIPTION: Command to check the current CPU frequency scaling governor setting. This helps determine if the system is configured for optimal performance.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\n```\n\n----------------------------------------\n\nTITLE: Building Current-Version Documentation on Linux\nDESCRIPTION: This snippet shows how to navigate to the docs directory, install dependencies, build the current documentation, and open it in a browser on Linux.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# 1. Navigate to the docs directory and install dependencies\ncd docs\npip install -r requirements.txt\n\n# 2. Build the current documentation\nmake current-docs\n\n# 3. Open the current docs\nxdg-open _build/current/index.html\n```\n\n----------------------------------------\n\nTITLE: Configuring Extension Dependencies with TOML\nDESCRIPTION: Shows how to specify non-Python dependencies in the extension.toml file. This example demonstrates configuring apt packages and ROS workspace dependencies for an extension.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/overview/developer-guide/development.rst#2025-04-23_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[isaac_lab_settings]\n# apt dependencies\napt_deps = [\"libboost-all-dev\"]\n\n# ROS workspace\n# note: if this path is relative, it is relative to the extension directory's root\nros_ws = \"/home/user/catkin_ws\"\n```\n\n----------------------------------------\n\nTITLE: Importing Isaac Lab Environment in Python\nDESCRIPTION: Code snippet showing how to import an Isaac Lab environment, specifically the 'Isaac-Velocity-Flat-Anymal-C-Direct-v0' environment.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab_tasks/docs/CHANGELOG.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gymnasium as gym\nimport isaaclab\n\nenv = gym.make(\"Isaac-Velocity-Flat-Anymal-C-Direct-v0\")\n```\n\n----------------------------------------\n\nTITLE: Running Simulation Script with Custom Argument (Bash)\nDESCRIPTION: Executes the create_scene.py script using isaaclab's shell interface, specifying the number of environments via the --num_envs argument. Required dependency is a working isaaclab.sh command and the presence of the target script. Inputs are the script path and argument value; output is a simulation run with multiple cartpole environments. Limitations: assumes correct shell setup and script location.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/02_scene/create_scene.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/tutorials/02_scene/create_scene.py --num_envs 32\n```\n\n----------------------------------------\n\nTITLE: Bad Example: Python Function without Type Hints\nDESCRIPTION: Demonstrates an discouraged Python function definition for `my_function` that adds two numbers but lacks type hints entirely, both in the function signature and the docstring. This makes the function's expected inputs and output less clear.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef my_function(a, b):\n   \"\"\"Adds two numbers.\n\n   This function is a bad example. Reason: No type hints anywhere.\n\n   Args:\n      a: The first argument.\n      b: The second argument.\n\n   Returns:\n      The sum of the two arguments.\n   \"\"\"\n   return a + b\n```\n\n----------------------------------------\n\nTITLE: SLURM Job Configuration Parameters\nDESCRIPTION: Default SLURM job configuration settings defining resource requirements and constraints\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/deployment/cluster.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem-per-cpu=4G\n#SBATCH --time=24:00:00\n#SBATCH --gpus=1\n#SBATCH --partition=gpu.24h\n#SBATCH --output=/cluster/home/username/isaaclab/logs/slurm-%j.out\n```\n\n----------------------------------------\n\nTITLE: Installing Isaac Lab and Isaac Sim via Pip\nDESCRIPTION: Installs Isaac Lab version 2.0.2 along with its optional dependencies for Isaac Sim support ('isaacsim') and all other extras ('all') using pip. It requires specifying an extra index URL pointing to Nvidia's PyPI repository. Assumes a compatible Python environment (3.10) and appropriate PyTorch version are already installed.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_7\n\nLANGUAGE: none\nCODE:\n```\npip install isaaclab[isaacsim,all]==2.0.2 --extra-index-url https://pypi.nvidia.com\n```\n\n----------------------------------------\n\nTITLE: Clean Documentation Build\nDESCRIPTION: Command to perform a clean documentation build by first removing the existing build directory and then rebuilding the documentation from scratch.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nrm -rf docs/_build && ./isaaclab.sh --docs\n```\n\n----------------------------------------\n\nTITLE: Training H1 Robot Policy with RSL RL\nDESCRIPTION: Command to train the Isaac-Velocity-Rough-H1-v0 task using RSL RL library in headless mode.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/tutorials/03_envs/policy_inference_in_usd.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task Isaac-Velocity-Rough-H1-v0 --headless\n```\n\n----------------------------------------\n\nTITLE: Building Documentation in IsaacLab\nDESCRIPTION: Command to build the project documentation by installing required dependencies and using the docs/Makefile. This creates documentation in the docs/_build directory.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./isaaclab.sh --docs  # or \"./isaaclab.sh -d\"\n```\n\n----------------------------------------\n\nTITLE: Running IsaacLab Training Script on CPU (Old CLI) using Bash\nDESCRIPTION: Demonstrates the previous command-line method using `./isaaclab.sh` to run a training script (`sb3/train.py`) specifically on the CPU. It used the `--cpu` flag, which is deprecated in IsaacLab v1.2.0+.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/release_notes.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n.. code:: bash\n\n    ./isaaclab.sh -p source/standalone/workflows/sb3/train.py --task Isaac-Cartpole-v0 --headless --cpu\n```\n\n----------------------------------------\n\nTITLE: Building Multi-Version Documentation on Windows\nDESCRIPTION: This snippet shows how to navigate to the docs directory, install dependencies, build the multi-version documentation, and open it in a browser on Windows.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/README.md#2025-04-23_snippet_3\n\nLANGUAGE: batch\nCODE:\n```\n:: 1. Navigate to the docs directory and install dependencies\ncd docs\npip install -r requirements.txt\n\n:: 2. Build the multi-version documentation\nmake multi-docs\n\n:: 3. Open the multi-version docs\nstart _build\\index.html\n```\n\n----------------------------------------\n\nTITLE: Example Isaac Sim EULA Acceptance Prompt (Bash)\nDESCRIPTION: Shows the text prompt displayed when Isaac Sim is run for the first time. Users must type 'Yes' (case-insensitive) and press Enter to accept the NVIDIA Omniverse License Agreement (EULA) before the simulator can proceed. This is a one-time requirement per installation.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/isaaclab_pip_installation.rst#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nBy installing or using Isaac Sim, I agree to the terms of NVIDIA OMNIVERSE LICENSE AGREEMENT (EULA)\nin https://docs.isaacsim.omniverse.nvidia.com/latest/common/NVIDIA_Omniverse_License_Agreement.html\n\nDo you accept the EULA? (Yes/No): Yes\n```\n\n----------------------------------------\n\nTITLE: Good Example: Python Function with Type Hints in Signature Only\nDESCRIPTION: Presents the recommended way to define a Python function `my_function` using type hints. Type hints (`int` for parameters `a`, `b`, and the return value) are placed exclusively in the function signature. The docstring describes the parameters and return value without repeating the type information.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef my_function(a: int, b: int) -> int:\n   \"\"\"Adds two numbers.\n\n   This function is a good example. Reason: Type hints in the function signature and not in the\n   docstring.\n\n   Args:\n      a: The first argument.\n      b: The second argument.\n\n   Returns:\n      The sum of the two arguments.\n   \"\"\"\n   return a + b\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Dependencies for Isaac Sim Project\nDESCRIPTION: This code snippet lists the required Python packages for the Isaac Sim project. It includes packages for documentation building, basic Python functionality, and machine learning. Each package is listed with its specific version (if required) or just the package name for the latest version.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# for building the docs\nsphinx-book-theme==1.0.1\nmyst-parser\nsphinxcontrib-bibtex==2.5.0\nautodocsumm\nsphinx-copybutton\nsphinx-icon\nsphinx_design\nsphinxemoji\nsphinx-tabs # backwards compatibility for building docs on v1.0.0\nsphinx-multiversion==0.2.4\n\n# basic python\nnumpy\nmatplotlib\nwarp-lang\n# learning\ngymnasium\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Documentation Structure\nDESCRIPTION: Main documentation structure written in ReStructuredText (RST) format, organizing various how-to guides into sections with proper hierarchy and cross-references.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. _how-to:\\n\\nHow-to Guides\\n=============\\n\\n.. note::\\n\\n    This section is a work in progress. If you have a question that is not answered here,\\n    please open an issue on our `GitHub page <https://github.com/isaac-sim/IsaacLab>`_.\n```\n\n----------------------------------------\n\nTITLE: Good Example: Omitting Explicit None Return Type Hint in Python\nDESCRIPTION: This Python code demonstrates the recommended practice for functions returning `None`. The function `my_function` accepts an optional integer (`int | None`) but omits the `-> None` return type annotation in the signature, as it's considered unnecessary.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/contributing.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef my_function(x: int | None):\n   pass\n```\n\n----------------------------------------\n\nTITLE: Running Pre-commit Hooks (Bash)\nDESCRIPTION: Executes the pre-commit hooks configured for the repository against all tracked files. This typically includes code formatting and linting checks.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/tools/template/templates/external/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npre-commit run --all-files\n```\n\n----------------------------------------\n\nTITLE: Accessing and Writing Joint States in Isaac Lab and OmniIsaacGymEnvs (Python)\nDESCRIPTION: Demonstrates how to access joint position and velocity states for robots or articulated objects in both OmniIsaacGymEnvs and Isaac Lab, highlighting API differences. No dependencies beyond the Isaac Lab or OmniIsaacGymEnvs frameworks are needed. The expected inputs are robot or articulation object references with valid data buffers; the outputs are state arrays (e.g., joint positions/velocities). Limitations: must be called within the relevant simulation class context.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndof_pos = self._cartpoles.get_joint_positions(clone=False)\ndof_vel = self._cartpoles.get_joint_velocities(clone=False)\n```\n\nLANGUAGE: python\nCODE:\n```\nself.joint_pos = self._robot.data.joint_pos\nself.joint_vel = self._robot.data.joint_vel\n```\n\n----------------------------------------\n\nTITLE: Defining Isaac Lab Locomotion Environment Directory Structure - tree\nDESCRIPTION: This snippet shows the directory and file organization for task and environment configuration in Isaac Lab locomotion environments. It is intended as a structural template, providing context on where configuration Python files and YAMLs reside, such as for velocity-based tasks with different agent and environment settings. No dependencies are required; it serves as a reference for developers.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab_tasks/docs/README.md#2025-04-23_snippet_0\n\nLANGUAGE: tree\nCODE:\n```\nisaaclab_tasks/locomotion/\\nâ”œâ”€â”€ __init__.py\\nâ””â”€â”€ velocity\\n    â”œâ”€â”€ config\\n    â”‚   â””â”€â”€ anymal_c\\n    â”‚       â”œâ”€â”€ agent  # <- this is where we store the learning agent configurations\\n    â”‚       â”œâ”€â”€ __init__.py  # <- this is where we register the environment and configurations to gym registry\\n    â”‚       â”œâ”€â”€ flat_env_cfg.py\\n    â”‚       â””â”€â”€ rough_env_cfg.py\\n    â”œâ”€â”€ __init__.py\\n    â””â”€â”€ velocity_env_cfg.py  # <- this is the base task configuration\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables in Bash\nDESCRIPTION: Demonstrates how to set environment variables for Isaac Sim application using bash commands before running a Python script.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/api/lab/isaaclab.app.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport REMOTE_DEPLOYMENT=3\nexport ENABLE_CAMERAS=1\n# run the python script\n./isaaclab.sh -p scripts/demo/play_quadrupeds.py\n```\n\n----------------------------------------\n\nTITLE: Displaying MuJoCo License Information in Markdown\nDESCRIPTION: License information for MuJoCo models developed by Roboti LLC, which are used as derivative work in this project. The license specifies copyright information, source, version, release date, and contact details.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/licenses/dependencies/gym-license.txt#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nThis file is part of MuJoCo.\nCopyright 2009-2015 Roboti LLC.\nMujoco\t\t:: Advanced physics simulation engine\nSource\t\t: www.roboti.us\nVersion\t\t: 1.31\nReleased \t: 23Apr16\nAuthor\t\t:: Vikash Kumar\nContacts \t: kumar@roboti.us\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Isaac Sim MDP\nDESCRIPTION: ReStructuredText documentation layout defining the structure and components of the isaaclab.envs.mdp module, including automodule directives for various submodules.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/api/lab/isaaclab.envs.mdp.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\nisaaclab.envs.mdp\n=================\n\n.. automodule:: isaaclab.envs.mdp\n\nObservations\n------------\n\n.. automodule:: isaaclab.envs.mdp.observations\n    :members:\n\nActions\n-------\n\n.. automodule:: isaaclab.envs.mdp.actions\n\n.. automodule:: isaaclab.envs.mdp.actions.actions_cfg\n    :members:\n    :show-inheritance:\n    :exclude-members: __init__, class_type\n\nEvents\n------\n\n.. automodule:: isaaclab.envs.mdp.events\n    :members:\n\nCommands\n--------\n\n.. automodule:: isaaclab.envs.mdp.commands\n\n.. automodule:: isaaclab.envs.mdp.commands.commands_cfg\n    :members:\n    :show-inheritance:\n    :exclude-members: __init__, class_type\n\nRewards\n-------\n\n.. automodule:: isaaclab.envs.mdp.rewards\n    :members:\n\nTerminations\n------------\n\n.. automodule:: isaaclab.envs.mdp.terminations\n    :members:\n\nCurriculum\n----------\n\n.. automodule:: isaaclab.envs.mdp.curriculums\n    :members:\n```\n\n----------------------------------------\n\nTITLE: Setting Joint State Buffers in Isaac Lab and OmniIsaacGymEnvs (Python)\nDESCRIPTION: Compares methods for setting joint position and velocity states for robot actors or articulated bodies between OmniIsaacGymEnvs and Isaac Lab. Necessary parameters include arrays of joint positions, joint velocities, joint indices, and environment IDs. These methods write updated state values into simulation buffers; ensure types and shapes match simulation expectations. Requires proper setup of simulation actor objects.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nindices = env_ids.to(dtype=torch.int32)\nself._cartpoles.set_joint_positions(dof_pos, indices=indices)\nself._cartpoles.set_joint_velocities(dof_vel, indices=indices)\n```\n\nLANGUAGE: python\nCODE:\n```\nself._robot.write_joint_state_to_sim(joint_pos, joint_vel, joint_ids, env_ids)\n```\n\n----------------------------------------\n\nTITLE: Resolving Regex Expressions in String Utils\nDESCRIPTION: New utility methods in the string module resolve regex expressions based on a passed list of target keys.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# This code is implied from the changelog, not explicitly shown\nfrom isaaclab.utils import string\n\ntarget_keys = [\"key1\", \"key2\"]\nresolved_expression = string.resolve_regex(\"regex_pattern\", target_keys)\n```\n\n----------------------------------------\n\nTITLE: Writing Root State Buffers in Isaac Lab (Python)\nDESCRIPTION: Shows how to write root position/orientation and velocity state information for an actor (e.g., cartpole) using Isaac Lab APIs. Requires pre-computed root state arrays (split into pose and velocity; arrays must have columns for each state element) and relevant actor/environment references. Inputs are root pose and velocity arrays, and environment IDs. Outputs are written directly to simulation buffers.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nself.cartpole.write_root_pose_to_sim(default_root_state[:, :7], env_ids)\nself.cartpole.write_root_velocity_to_sim(default_root_state[:, 7:], env_ids)\n```\n\n----------------------------------------\n\nTITLE: Incorrect Implementation with Memory Leak\nDESCRIPTION: Example of a Python class that registers a callback with the simulator using a strong reference, which can lead to memory leaks as the object cannot be garbage collected properly.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/refs/troubleshooting.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport omni.kit\n\nclass MyClass:\n    def __init__(self):\n        app_interface = omni.kit.app.get_app_interface()\n        self._handle = app_interface.get_post_update_event_stream().create_subscription_to_pop(\n            self.on_event_callback\n        )\n\n    def __del__(self):\n        self._handle.unsubscribe()\n        self._handle = None\n\n    def on_event_callback(self, event):\n        # do something with the message\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure\nDESCRIPTION: ReStructuredText markup for documentation structure including badges, warnings, notes, and table of contents\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/setup/installation/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. image:: https://img.shields.io/badge/IsaacSim-4.5.0-silver.svg\n   :target: https://developer.nvidia.com/isaac-sim\n   :alt: IsaacSim 4.5.0\n\n.. image:: https://img.shields.io/badge/python-3.10-blue.svg\n   :target: https://www.python.org/downloads/release/python-31013/\n   :alt: Python 3.10\n\n.. image:: https://img.shields.io/badge/platform-linux--64-orange.svg\n   :target: https://releases.ubuntu.com/20.04/\n   :alt: Ubuntu 20.04\n\n.. image:: https://img.shields.io/badge/platform-windows--64-orange.svg\n   :target: https://www.microsoft.com/en-ca/windows/windows-11\n   :alt: Windows 11\n\n.. caution::\n\n   We have dropped support for Isaac Sim versions 4.2.0 and below. We recommend using the latest\n   Isaac Sim 4.5.0 release to benefit from the latest features and improvements.\n\n.. note::\n\n    We recommend system requirements with at least 32GB RAM and 16GB VRAM for Isaac Lab.\n\n.. toctree::\n    :maxdepth: 2\n\n    Pip installation (recommended for Ubuntu 22.04 and Windows) <pip_installation>\n    Binary installation (recommended for Ubuntu 20.04) <binaries_installation>\n    Advanced installation (Isaac Lab pip) <isaaclab_pip_installation>\n    Asset caching <asset_caching>\n```\n\n----------------------------------------\n\nTITLE: Markdown Contributors List Structure\nDESCRIPTION: Structured markdown document listing developers, contributors, and acknowledgements for the Isaac Lab Project, including formatting guidelines and organizational affiliations.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/CONTRIBUTORS.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Isaac Lab Developers and Contributors\n\nThis is the official list of Isaac Lab Project developers and contributors.\n\nTo see the full list of contributors, please check the revision history in the source control.\n\nGuidelines for modifications:\n\n* Please keep the **lists sorted alphabetically**.\n* Names should be added to this file as: *individual names* or *organizations*.\n* E-mail addresses are tracked elsewhere to avoid spam.\n\n## Developers\n\n* Boston Dynamics AI Institute, Inc.\n* ETH Zurich\n* NVIDIA Corporation & Affiliates\n* University of Toronto\n\n---\n\n* Antonio Serrano-MuÃ±oz\n* David Hoeller\n* Farbod Farshidian\n* Hunter Hansen\n* James Smith\n* James Tigue\n* Kelly (Yunrong) Guo\n* Matthew Trepte\n* Mayank Mittal\n* Nikita Rudin\n* Pascal Roth\n* Sheikh Dawood\n* Ossama Ahmed\n```\n\n----------------------------------------\n\nTITLE: Implementing Environment Configuration with configclass in Isaac Lab\nDESCRIPTION: Example skeleton of a task configuration class using the configclass decorator in Isaac Lab. This demonstrates how to define simulation parameters, robot configuration, scene setup, and environment-specific parameters in a structured Python class.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom isaaclab.envs import DirectRLEnvCfg\nfrom isaaclab.scene import InteractiveSceneCfg\nfrom isaaclab.sim import SimulationCfg\n\n@configclass\nclass MyEnvCfg(DirectRLEnvCfg):\n   # simulation\n   sim: SimulationCfg = SimulationCfg()\n   # robot\n   robot_cfg: ArticulationCfg = ArticulationCfg()\n   # scene\n   scene: InteractiveSceneCfg = InteractiveSceneCfg()\n   # env\n   decimation = 2\n   episode_length_s = 5.0\n   action_space = 1\n   observation_space = 4\n   state_space = 0\n   # task-specific parameters\n   ...\n```\n\n----------------------------------------\n\nTITLE: BSD License Declaration for Isaac Sim Lab\nDESCRIPTION: Standard BSD-style license text specifying copyright ownership, redistribution terms, warranty disclaimers, and liability limitations. Includes list of contributors and conditions for both source and binary distributions.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/licenses/dependencies/prettytable-license.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# Copyright (c) 2009-2014 Luke Maurits <luke@maurits.id.au>\n# All rights reserved.\n# With contributions from:\n#  * Chris Clark\n#  * Klein Stephane\n#  * John Filleau\n#  * Vladimir VrziÄ‡\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# * Redistributions of source code must retain the above copyright notice,\n#   this list of conditions and the following disclaimer.\n# * Redistributions in binary form must reproduce the above copyright notice,\n#   this list of conditions and the following disclaimer in the documentation\n#   and/or other materials provided with the distribution.\n# * The name of the author may not be used to endorse or promote products\n#   derived from this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n```\n\n----------------------------------------\n\nTITLE: Implementing Video Recording Wrapper in Isaac Sim\nDESCRIPTION: Shows how to configure and implement video recording wrapper with custom camera settings and recording parameters.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/wrap_rl_env.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"Launch Isaac Sim Simulator first.\"\"\"\n\nfrom isaaclab.app import AppLauncher\n\n# launch omniverse app in headless mode with off-screen rendering\napp_launcher = AppLauncher(headless=True, enable_cameras=True)\nsimulation_app = app_launcher.app\n\n\"\"\"Rest everything follows.\"\"\"\n\nimport gymnasium as gym\n\n# adjust camera resolution and pose\nenv_cfg.viewer.resolution = (640, 480)\nenv_cfg.viewer.eye = (1.0, 1.0, 1.0)\nenv_cfg.viewer.lookat = (0.0, 0.0, 0.0)\n# create isaac-env instance\n# set render mode to rgb_array to obtain images on render calls\nenv = gym.make(task_name, cfg=env_cfg, render_mode=\"rgb_array\")\n# wrap for video recording\nvideo_kwargs = {\n    \"video_folder\": \"videos/train\",\n    \"step_trigger\": lambda step: step % 1500 == 0,\n    \"video_length\": 200,\n}\nenv = gym.wrappers.RecordVideo(env, **video_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Comparing Environment Setup Between OmniIsaacGymEnvs and Isaac Lab\nDESCRIPTION: Shows how to migrate the scene setup code from OmniIsaacGymEnvs to Isaac Lab, highlighting differences in environment creation, actor handling, and view management.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef set_up_scene(self, scene) -> None:\n  self.get_cartpole()\n  super().set_up_scene(scene)\n\n  self._cartpoles = ArticulationView(\n               prim_paths_expr=\"/World/envs/.*/Cartpole\",\n               name=\"cartpole_view\", reset_xform_properties=False\n  )\n  scene.add(self._cartpoles)\n```\n\nLANGUAGE: python\nCODE:\n```\ndef _setup_scene(self):\n  self.cartpole = Articulation(self.cfg.robot_cfg)\n  # add ground plane\n  spawn_ground_plane(prim_path=\"/World/ground\", cfg=GroundPlaneCfg()\n  # clone, filter, and replicate\n  self.scene.clone_environments(copy_from_source=False)\n  self.scene.filter_collisions(global_prim_paths=[])\n  # add articulation to scene\n  self.scene.articulations[\"cartpole\"] = self.cartpole\n  # add lights\n  light_cfg = sim_utils.DomeLightCfg(intensity=2000.0)\n  light_cfg.func(\"/World/Light\", light_cfg)\n```\n\n----------------------------------------\n\nTITLE: Setting Random Seeds in Isaac Lab for Deterministic Simulation\nDESCRIPTION: References to methods and attributes used to set random seeds for ensuring deterministic simulations in Isaac Lab. The method set_seed is used to initialize random seeds globally across libraries including PyTorch and NumPy.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/reproducibility.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nisaacsim.core.utils.torch.set_seed\n```\n\n----------------------------------------\n\nTITLE: Environment Configuration Parameters for Random Seed in Isaac Lab\nDESCRIPTION: Configuration attributes used to set random seeds in different Isaac Lab environment implementations. These parameters ensure reproducible simulation results across runs.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/features/reproducibility.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nisaaclab.envs.ManagerBasedEnvCfg.seed\n```\n\nLANGUAGE: python\nCODE:\n```\nisaaclab.envs.DirectRLEnvCfg.seed\n```\n\n----------------------------------------\n\nTITLE: Adding Events Configuration to Task Config\nDESCRIPTION: Shows how to incorporate the EventCfg class into the main task configuration class.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/migration/migrating_from_omniisaacgymenvs.rst#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n@configclass\nclass MyTaskConfig:\n  events: EventCfg = EventCfg()\n```\n\n----------------------------------------\n\nTITLE: Accessing Body View in RigidObject Class in Python\nDESCRIPTION: Demonstrates the correct way to access the body view in the RigidObject class using the public property instead of the private variable.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Correct usage\nself.body_view  # instead of self._body_view\n```\n\n----------------------------------------\n\nTITLE: Inline Environment Variables in Bash\nDESCRIPTION: Shows how to set environment variables inline with the Python script execution command.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/api/lab/isaaclab.app.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nREMOTE_DEPLOYMENT=3 ENABLE_CAMERAS=1 ./isaaclab.sh -p scripts/demo/play_quadrupeds.py\n```\n\n----------------------------------------\n\nTITLE: Retrieving File Path from Nucleus Server in Python\nDESCRIPTION: Demonstrates the usage of a new method to obtain the absolute path of a file on the Nucleus server or locally.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nfrom isaaclab.utils.assets import retrieve_file_path\n\nfile_path = retrieve_file_path(file_name)\n```\n\n----------------------------------------\n\nTITLE: Initializing Isaac Sim ArticulationView in Python\nDESCRIPTION: Shows the simplified manual initialization of Isaac Sim ArticulationView class by calling their initialize method directly.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/source/isaaclab/docs/CHANGELOG.rst#2025-04-23_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n# Simplified initialization\narticulation_view.initialize()\n```\n\n----------------------------------------\n\nTITLE: Installing FFMPEG Dependencies\nDESCRIPTION: Command to install FFMPEG on Ubuntu systems for video recording functionality.\nSOURCE: https://github.com/isaac-sim/isaaclab/blob/main/docs/source/how-to/wrap_rl_env.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get install ffmpeg\n```"
  }
]