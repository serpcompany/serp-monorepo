[
  {
    "owner": "jxlil",
    "repo": "scrapy-impersonate",
    "content": "TITLE: Implementing a Scrapy Spider with Browser Impersonation\nDESCRIPTION: Complete example of a Scrapy spider that uses browser impersonation to make requests with different browser fingerprints and extract JA3 hash information.\nSOURCE: https://github.com/jxlil/scrapy-impersonate/blob/master/README.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport scrapy\n\n\nclass ImpersonateSpider(scrapy.Spider):\n    name = \"impersonate_spider\"\n    custom_settings = {\n        \"USER_AGENT\": None,\n        \"DOWNLOAD_HANDLERS\": {\n            \"http\": \"scrapy_impersonate.ImpersonateDownloadHandler\",\n            \"https\": \"scrapy_impersonate.ImpersonateDownloadHandler\",\n        },\n        \"TWISTED_REACTOR\": \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\",\n    }\n\n    def start_requests(self):\n        for browser in [\"chrome110\", \"edge99\", \"safari15_5\"]:\n            yield scrapy.Request(\n                \"https://tls.browserleaks.com/json\",\n                dont_filter=True,\n                meta={\"impersonate\": browser},\n            )\n\n    def parse(self, response):\n        # ja3_hash: 773906b0efdefa24a7f2b8eb6985bf37\n        # ja3_hash: cd08e31494f9531f560d64c695473da9\n        # ja3_hash: 2fe1311860bc318fc7f9196556a2a6b9\n        yield {\"ja3_hash\": response.json()[\"ja3_hash\"]}\n```\n\n----------------------------------------\n\nTITLE: Configuring Scrapy Download Handlers for Browser Impersonation\nDESCRIPTION: Python configuration to replace the default HTTP and HTTPS download handlers with ImpersonateDownloadHandler in Scrapy's settings.\nSOURCE: https://github.com/jxlil/scrapy-impersonate/blob/master/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nDOWNLOAD_HANDLERS = {\n    \"http\": \"scrapy_impersonate.ImpersonateDownloadHandler\",\n    \"https\": \"scrapy_impersonate.ImpersonateDownloadHandler\",\n}\n```\n\n----------------------------------------\n\nTITLE: Passing Custom Arguments to curl_cffi Through Scrapy Request\nDESCRIPTION: Example of passing additional arguments like timeout and SSL verification settings to curl_cffi through the impersonate_args parameter in a Scrapy request.\nSOURCE: https://github.com/jxlil/scrapy-impersonate/blob/master/README.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nyield scrapy.Request(\n    \"https://tls.browserleaks.com/json\",\n    dont_filter=True,\n    meta={\n        \"impersonate\": browser,\n        \"impersonate_args\": {\n            \"verify\": False,\n            \"timeout\": 10,\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Automatic User-Agent Selection Based on Impersonated Browser\nDESCRIPTION: Python configuration to let curl_cffi automatically choose the appropriate User-Agent based on the impersonated browser.\nSOURCE: https://github.com/jxlil/scrapy-impersonate/blob/master/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nUSER_AGENT = None\n```\n\n----------------------------------------\n\nTITLE: Installing AsyncIO-based Twisted Reactor for Scrapy\nDESCRIPTION: Python configuration to install the asyncio-based Twisted reactor for proper asynchronous execution in Scrapy.\nSOURCE: https://github.com/jxlil/scrapy-impersonate/blob/master/README.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\n```\n\n----------------------------------------\n\nTITLE: Defining Dependencies for Scrapy-Impersonate in Requirements File\nDESCRIPTION: This snippet specifies the minimum package versions required for the scrapy-impersonate project to function correctly. It requires curl-cffi version 0.10.0 or higher and scrapy version 2.12.0 or higher.\nSOURCE: https://github.com/jxlil/scrapy-impersonate/blob/master/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ncurl-cffi>=0.10.0\nscrapy>=2.12.0\n```\n\n----------------------------------------\n\nTITLE: Installing Scrapy-Impersonate with pip\nDESCRIPTION: Command to install the scrapy-impersonate package via pip package manager.\nSOURCE: https://github.com/jxlil/scrapy-impersonate/blob/master/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install scrapy-impersonate\n```"
  }
]