[
  {
    "owner": "openai",
    "repo": "codex",
    "content": "TITLE: Running Codex in CI/Non-interactive Mode Using GitHub Actions - YAML Shell\nDESCRIPTION: A GitHub Actions workflow step showing how to install Codex CLI, set the API key from a GitHub secret, and run Codex non-interactively to update a changelog. Each shell command is executed in sequence using the run block. This example facilitates automation in CI pipelines with the quiet option to suppress UI output.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\n- name: Update changelog via Codex\\n  run: |\\n    npm install -g @openai/codex\\n    export OPENAI_API_KEY=\"${{ secrets.OPENAI_KEY }}\"\\n    codex -a auto-edit --quiet \"update CHANGELOG for next release\"\n```\n\n----------------------------------------\n\nTITLE: Analyzing Cluster Themes with GPT-4\nDESCRIPTION: Uses OpenAI's GPT-4 to identify and name themes for each cluster based on a sample of reviews. The code randomly selects reviews from each cluster, formats them for analysis, sends them to the GPT-4 API, and then displays the cluster theme along with sample reviews and their scores. This automated interpretation helps understand the semantic meaning of each cluster.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompt-analyzer/template/Clustering.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\nimport os\n\nclient = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n\n# Reading a review which belong to each group.\nrev_per_cluster = 5\n\nfor i in range(n_clusters):\n    print(f\"Cluster {i} Theme:\", end=\" \")\n\n    reviews = \"\\n\".join(\n        df[df.Cluster == i]\n        .combined.str.replace(\"Title: \", \"\")\n        .str.replace(\"\\n\\nContent: \", \":  \")\n        .sample(rev_per_cluster, random_state=42)\n        .values\n    )\n\n    messages = [\n        {\"role\": \"user\", \"content\": f'What do the following customer reviews have in common?\\n\\nCustomer reviews:\\n\"\"\"\\n{reviews}\\n\"\"\"\\n\\nTheme:'}\n    ]\n\n    response = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages,\n        temperature=0,\n        max_tokens=64,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0)\n    print(response.choices[0].message.content.replace(\"\\n\", \"\"))\n\n    sample_cluster_rows = df[df.Cluster == i].sample(rev_per_cluster, random_state=42)\n    for j in range(rev_per_cluster):\n        print(sample_cluster_rows.Score.values[j], end=\", \")\n        print(sample_cluster_rows.Summary.values[j], end=\":   \")\n        print(sample_cluster_rows.Text.str[:70].values[j])\n\n    print(\"-\" * 100)\n```\n\n----------------------------------------\n\nTITLE: Running Codex Interactively - Shell\nDESCRIPTION: Launches the Codex CLI in interactive REPL mode, allowing you to converse and iterate code directly in the terminal. No parameters are required.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncodex\n```\n\n----------------------------------------\n\nTITLE: Implementing K-means Clustering on Text Embeddings\nDESCRIPTION: Applies K-means clustering to the embedding matrix, assigning each review to one of four clusters. The implementation uses the scikit-learn KMeans algorithm with the k-means++ initialization method for better convergence. The code also calculates the mean score for each cluster to identify potential patterns.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompt-analyzer/template/Clustering.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.cluster import KMeans\n\nn_clusters = 4\n\nkmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=42)\nkmeans.fit(matrix)\nlabels = kmeans.labels_\ndf[\"Cluster\"] = labels\n\ndf.groupby(\"Cluster\").Score.mean().sort_values()\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Codex CLI Globally - Shell\nDESCRIPTION: This shell command installs the OpenAI Codex CLI globally on your system using npm. It requires Node.js to be installed and configured with appropriate permissions (avoid running as sudo). This allows the 'codex' command to be available systemwide for terminal usage.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install -g @openai/codex\n```\n\n----------------------------------------\n\nTITLE: Prompting Codex with an Initial Command - Shell\nDESCRIPTION: Runs the Codex CLI with a prompt as an argument to initiate an interactive session preloaded with that instruction. Useful for one-shot tasks or when initiating work with a defined prompt.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncodex \"explain this codebase to me\"\n```\n\n----------------------------------------\n\nTITLE: Setting the OpenAI API Key Using a .env File - Env\nDESCRIPTION: Declares the OPENAI_API_KEY in a .env file at the project root, allowing Codex CLI to automatically read the API key using 'dotenv/config'. This is a convenient option for persisting credentials in development environments. The .env file should not be committed publicly for security.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=your-api-key-here\n```\n\n----------------------------------------\n\nTITLE: Creating an HTML Webpage with Codex\nDESCRIPTION: A sequence of commands to initialize a Git repository and instruct Codex to create an HTML file containing a poem with styling. Shows how to use Codex for creative content generation with specific formatting requirements.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompting_guide.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir first-task && cd first-task\ngit init\ncodex \"Create a file poem.html that renders a poem about the nature of intelligence and programming by you, Codex. Add some nice CSS and make it look like it's framed on a wall\"\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Codex CLI via Package Managers (Bash)\nDESCRIPTION: Demonstrates global installation of the `@openai/codex` CLI tool using various Node.js package managers: npm, yarn, bun, or pnpm. Requires Node.js and the corresponding package manager to be installed.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nnpm install -g @openai/codex\n# or\nyarn global add @openai/codex\n# or\nbun install -g @openai/codex\n# or\npnpm add -g @openai/codex\n```\n\n----------------------------------------\n\nTITLE: Visualizing Clusters with t-SNE Dimensionality Reduction\nDESCRIPTION: Creates a 2D visualization of the high-dimensional embedding clusters using t-SNE dimensionality reduction. The code plots each cluster with a different color, highlights cluster centers, and adds transparency to points for better visualization of densely populated areas. This helps in understanding the spatial distribution of the reviews.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompt-analyzer/template/Clustering.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.manifold import TSNE\nimport matplotlib\nimport matplotlib.pyplot as plt\n\ntsne = TSNE(n_components=2, perplexity=15, random_state=42, init=\"random\", learning_rate=200)\nvis_dims2 = tsne.fit_transform(matrix)\n\nx = [x for x, y in vis_dims2]\ny = [y for x, y in vis_dims2]\n\nfor category, color in enumerate([\"purple\", \"green\", \"red\", \"blue\"]):\n    xs = np.array(x)[df.Cluster == category]\n    ys = np.array(y)[df.Cluster == category]\n    plt.scatter(xs, ys, color=color, alpha=0.3)\n\n    avg_x = xs.mean()\n    avg_y = ys.mean()\n\n    plt.scatter(avg_x, avg_y, marker=\"x\", color=color, s=100)\nplt.title(\"Clusters identified visualized in language 2d using t-SNE\")\n```\n\n----------------------------------------\n\nTITLE: Example Task Description for Code Refactoring\nDESCRIPTION: An example of a medium-complexity task description that can be stored in a file and used with Codex. The task involves refactoring model naming conventions across documentation files with specific file references.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompting_guide.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\nRefactor: simplify model names across static documentation\n\nCan you update docs_site to use a better model naming convention on the site.\n\nRead files like:\n- docs_site/content/models.md\n- docs_site/components/ModelCard.tsx\n- docs_site/utils/modelList.ts\n- docs_site/config/sidebar.ts\n\nReplace confusing model identifiers with a simplified version wherever they're user-facing.\n\nWrite what you changed or tried to do to final_output.md\n```\n\n----------------------------------------\n\nTITLE: Setting the OpenAI API Key via Environment Variable - Shell\nDESCRIPTION: Exports your OpenAI API key for the current terminal session, which is required for the Codex CLI to authenticate with the OpenAI API. The variable is session-local unless added to a shell profile file (such as ~/.zshrc). Make sure to use your actual API key.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport OPENAI_API_KEY=\"your-api-key-here\"\n```\n\n----------------------------------------\n\nTITLE: Using External Task Descriptions with Codex\nDESCRIPTION: Shows how to use the contents of an external file as input for Codex, which is useful when dealing with longer, more complex task descriptions that would be unwieldy as command-line arguments.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompting_guide.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncodex \"$(cat task_description.md)\"\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key for Prompt-Clustering Utility\nDESCRIPTION: Exports the OpenAI API key as an environment variable, which is required to access OpenAI's embedding and chat completion APIs.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompt-analyzer/template/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\"sk‑...\"\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Instructions for OpenAI Codex CLI (Markdown)\nDESCRIPTION: Illustrates how to define custom instructions in `~/.codex/instructions.md`. These instructions guide the AI's behavior, such as always using emojis or restricting git command usage unless explicitly requested. The format is a list of directives parsed by the CLI.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_13\n\nLANGUAGE: markdown\nCODE:\n```\n# ~/.codex/instructions.md\n- Always respond with emojis\n- Only use git commands if I explicitly mention you should\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Codex CLI using YAML\nDESCRIPTION: Shows an example configuration file (`~/.codex/config.yaml`) using YAML format. It defines settings like the default AI model (`o4-mini`), the approval mode for generated changes (`suggest`), the behavior in full-auto mode when errors occur (`ask-user`), and whether to enable desktop notifications (`true`).\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n# ~/.codex/config.yaml\nmodel: o4-mini # Default model\napprovalMode: suggest # or auto-edit, full-auto\nfullAutoErrorMode: ask-user # or ignore-and-continue\nnotify: true # Enable desktop notifications for responses\n```\n\n----------------------------------------\n\nTITLE: Specifying an Alternative Provider API Key - Shell\nDESCRIPTION: Exports an API key for a non-OpenAI provider when using the '--provider' CLI flag or updating the config file. Replace <provider> with the desired provider name (e.g., openrouter, gemini). Ensure to set this as required for any supported external provider and use your actual API key.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nexport <provider>_API_KEY=\"your-api-key-here\"\n```\n\n----------------------------------------\n\nTITLE: Advanced Usage of Prompt-Clustering Utility with Custom Parameters\nDESCRIPTION: Demonstrates how to run the prompt-clustering utility with customized options including input file, embedding cache, clustering method, model selection, and output locations.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompt-analyzer/template/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython cluster_prompts.py \\\n  --csv my_prompts.csv \\\n  --cache .cache/embeddings.json \\\n  --cluster-method dbscan \\\n  --embedding-model text-embedding-3-large \\\n  --chat-model gpt-4o \\\n  --output-md my_analysis.md \\\n  --plots-dir my_plots\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Codex CLI using JSON\nDESCRIPTION: Provides an example configuration file (`~/.codex/config.json`) using JSON format, mirroring the YAML example. It sets parameters such as the default AI model (`o4-mini`), approval mode (`suggest`), full-auto error mode (`ask-user`), and notification preference (`true`).\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n// ~/.codex/config.json\n{\n  \"model\": \"o4-mini\",\n  \"approvalMode\": \"suggest\",\n  \"fullAutoErrorMode\": \"ask-user\",\n  \"notify\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Embedded Text Data in Python\nDESCRIPTION: Loads a CSV file containing food reviews with embeddings, converts the embedding strings to numpy arrays, and stacks them into a matrix for clustering analysis. This preprocessing step transforms the textual data into a numerical format suitable for machine learning algorithms.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompt-analyzer/template/Clustering.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# imports\nimport numpy as np\nimport pandas as pd\nfrom ast import literal_eval\n\n# load data\ndatafile_path = \"./data/fine_food_reviews_with_embeddings_1k.csv\"\n\ndf = pd.read_csv(datafile_path)\ndf[\"embedding\"] = df.embedding.apply(literal_eval).apply(np.array)  # convert string to numpy array\nmatrix = np.vstack(df.embedding.values)\nmatrix.shape\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of Prompt-Clustering Utility\nDESCRIPTION: Runs the prompt-clustering utility with default settings, processing prompts.csv and generating analysis.md plus visualization plots.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompt-analyzer/template/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Minimal command – runs on prompts.csv and writes analysis.md + plots/\npython cluster_prompts.py\n```\n\n----------------------------------------\n\nTITLE: Running Codex in Full Auto-Approval Mode - Shell\nDESCRIPTION: Invokes Codex with the '--approval-mode full-auto' flag, which allows Codex to read, write, and execute shell commands (sandboxed), using the provided prompt. Use with caution as file and shell changes are auto-approved within the current working directory.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncodex --approval-mode full-auto \"create the fanciest todo-list app\"\n```\n\n----------------------------------------\n\nTITLE: Building and Running OpenAI Codex CLI from Source (Bash)\nDESCRIPTION: Provides commands to clone the Codex repository, navigate to the CLI directory, enable corepack, install dependencies using pnpm, build the project, view help options, run the locally built CLI, and optionally link it globally for easier access. Requires Git, Node.js, corepack, and pnpm.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# Clone the repository and navigate to the CLI package\ngit clone https://github.com/openai/codex.git\ncd codex/codex-cli\n\n# Enable corepack\ncorepack enable\n\n# Install dependencies and build\npnpm install\npnpm build\n\n# Get the usage and the options\nnode ./dist/cli.js --help\n\n# Run the locally-built CLI directly\nnode ./dist/cli.js\n\n# Or link the command globally for convenience\npnpm link\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for Prompt-Clustering Utility\nDESCRIPTION: Installs the required Python packages (pandas, numpy, scikit-learn, matplotlib, and openai) needed to run the prompt-clustering utility.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompt-analyzer/template/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install pandas numpy scikit-learn matplotlib openai\n```\n\n----------------------------------------\n\nTITLE: Running Full Check Suite for Development (Bash)\nDESCRIPTION: Shows the command `pnpm test && pnpm run lint && pnpm run typecheck` used in the development workflow. This command executes the unit tests (Vitest), linting checks (ESLint + Prettier), and TypeScript type-checking sequentially. It's crucial for ensuring code quality and correctness before pushing changes. Requires pnpm and configured test/lint/typecheck scripts in `package.json`.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\npnpm test && pnpm run lint && pnpm run typecheck\n```\n\n----------------------------------------\n\nTITLE: Common Development Workflow Commands (Bash)\nDESCRIPTION: Lists several helpful pnpm commands for developers contributing to the Codex CLI project. `pnpm test:watch` runs tests in watch mode for immediate feedback during development. `pnpm typecheck` performs static type analysis using TypeScript. `pnpm lint:fix` and `pnpm format:fix` automatically correct linting and code formatting issues based on ESLint and Prettier rules.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n# Watch mode (tests rerun on change)\npnpm test:watch\n\n# Type-check without emitting files\npnpm typecheck\n\n# Automatically fix lint + prettier issues\npnpm lint:fix\npnpm format:fix\n```\n\n----------------------------------------\n\nTITLE: Displaying Codex CLI Help Information\nDESCRIPTION: Shows how to access the help documentation for the Codex CLI tool, which provides information about available commands and options.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompting_guide.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncodex --help\n```\n\n----------------------------------------\n\nTITLE: Asking Codex a Simple Question\nDESCRIPTION: Demonstrates how to directly interact with Codex by asking it to describe its capabilities in a conversational manner.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/prompting_guide.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncodex \"write 2-3 sentences on what you can do\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Verbose Debug Logging for Codex CLI - Shell\nDESCRIPTION: Sets the DEBUG environment variable to true for a single invocation of the Codex CLI, instructing it to output full API request and response logs. This is useful for troubleshooting and inspecting Codex's backend interactions during development.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nDEBUG=true codex\n```\n\n----------------------------------------\n\nTITLE: Installing pnpm package manager\nDESCRIPTION: Instructions for installing pnpm globally using npm or corepack. This shows two methods: direct npm installation or using corepack which is available with Node.js 22+.\nSOURCE: https://github.com/openai/codex/blob/main/PNPM.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Global installation of pnpm\nnpm install -g pnpm@10.8.1\n\n# Or with corepack (available with Node.js 22+)\ncorepack enable\ncorepack prepare pnpm@10.8.1 --activate\n```\n\n----------------------------------------\n\nTITLE: Running a Codex CLI Example with Helper Script\nDESCRIPTION: Commands to navigate to an example directory and execute the run.sh helper script that creates a new Codex session for the task.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd camerascii\n./run.sh\n```\n\n----------------------------------------\n\nTITLE: Installing a Specific Codex Version using NPM\nDESCRIPTION: Installs a specific version of the 'codex' package globally using the Node Package Manager (NPM). Replace 'version' with the desired version number listed in the changelog. Requires NPM to be installed on the system.\nSOURCE: https://github.com/openai/codex/blob/main/CHANGELOG.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install -g codex@version\n```\n\n----------------------------------------\n\nTITLE: Entering a Nix Development Shell\nDESCRIPTION: This command enters a development environment managed by Nix, based on the project's `flake.nix` file. This shell provides all necessary dependencies like Node.js, installs project dependencies, builds the CLI, and sets up a `codex` command alias for development use. Requires Nix >= 2.4 with flakes enabled.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nnix develop\n```\n\n----------------------------------------\n\nTITLE: Running Codex CLI via Nix Flake App\nDESCRIPTION: This command directly runs the `codex` application defined within the project's Nix flake using `nix run`. It handles building (if necessary) and execution in one step. Requires Nix >= 2.4 with flakes enabled.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\nnix run .#codex\n```\n\n----------------------------------------\n\nTITLE: Building and Running Codex CLI with Nix Directly\nDESCRIPTION: These commands first build the project using `nix build`, creating a `./result` symlink containing the build artifacts. Then, the compiled `codex` executable located within `./result/bin/` is executed with the `--help` flag. This demonstrates building and running without entering the Nix development shell. Requires Nix >= 2.4 with flakes enabled.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\nnix build\n./result/bin/codex --help\n```\n\n----------------------------------------\n\nTITLE: Skipping Git Hooks in Bash\nDESCRIPTION: Commands to bypass Husky git hooks when necessary. The first command skips pre-commit hooks with the --no-verify flag, while the second command skips pre-push hooks using the same flag.\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/HUSKY.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Skip pre-commit hooks\ngit commit -m \"Your message\" --no-verify\n\n# Skip pre-push hooks\ngit push --no-verify\n```\n\n----------------------------------------\n\nTITLE: Example Directory Structure for Codex CLI Projects\nDESCRIPTION: Directory structure showing the organization of a typical Codex CLI example, including run.sh (helper script), task.yaml (prompt specification), template folder (starter files), and runs folder (work directories).\nSOURCE: https://github.com/openai/codex/blob/main/codex-cli/examples/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexample‑name/\n├── run.sh           # helper script that launches a new Codex session for the task\n├── task.yaml        # task spec containing a prompt passed to Codex\n├── template/        # (optional) starter files copied into each run\n└── runs/            # work directories created by run.sh\n```\n\n----------------------------------------\n\nTITLE: Amending and Force Pushing the Last Git Commit\nDESCRIPTION: This command amends the last Git commit, adding a sign-off (`-s`) without opening an editor (`--no-edit`), and then force pushes (`-f`) the amended commit to the remote repository. It's typically used for quick fixes like adding a missing DCO sign-off.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\ngit commit --amend -s --no-edit && git push -f\n```\n\n----------------------------------------\n\nTITLE: Committing Version Bump for Codex CLI Release\nDESCRIPTION: These commands stage the modified `session.ts` and `package.json` files after a version bump, and then create a signed commit (`-s`) with a standardized message indicating a release. The version number is dynamically inserted into the commit message using Node.js to read it from `package.json`. This is part of the release process.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\ngit add codex-cli/src/utils/session.ts codex-cli/package.json\ngit commit -s -m \"chore(release): codex-cli v$(node -p \\\"require('./codex-cli/package.json').version\\\")\"\n```\n\n----------------------------------------\n\nTITLE: Example Error for Zero Data Retention Limitation (Text)\nDESCRIPTION: Displays a typical error message returned by the OpenAI API when attempting to use the Codex CLI with an organization that has Zero Data Retention (ZDR) enabled. This occurs because the CLI relies on the Responses API with `store:true`, which conflicts with ZDR policy preventing data storage.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_14\n\nLANGUAGE: text\nCODE:\n```\nOpenAI rejected the request. Error details: Status: 400, Code: unsupported_parameter, Type: invalid_request_error, Message: 400 Previous response cannot be used for this organization due to Zero Data Retention.\n```\n\n----------------------------------------\n\nTITLE: Monorepo structure for pnpm workspace\nDESCRIPTION: Displays the directory structure of the Codex monorepo after migrating to pnpm. Shows the workspace configuration files and package organization including the main codex-cli package and documentation folder.\nSOURCE: https://github.com/openai/codex/blob/main/PNPM.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncodex/\n├── pnpm-workspace.yaml    # Workspace configuration\n├── .npmrc                 # pnpm configuration\n├── package.json           # Root dependencies and scripts\n├── codex-cli/             # Main package\n│   └── package.json       # codex-cli specific dependencies\n└── docs/                  # Documentation (future package)\n```\n\n----------------------------------------\n\nTITLE: CLA Acceptance Statement in Markdown\nDESCRIPTION: The specific statement that contributors must post as a comment on Pull Requests to agree to the CLA terms. This is the key mechanism for establishing agreement to the license terms.\nSOURCE: https://github.com/openai/codex/blob/main/docs/CLA.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**\"I have read the CLA Document and I hereby sign the CLA\"**\n```\n\n----------------------------------------\n\nTITLE: Signing the Contributor License Agreement (CLA)\nDESCRIPTION: This comment must be pasted into a pull request to signify acceptance of the Contributor License Agreement (CLA). The CLA-Assistant bot monitors comments and marks the corresponding status check as passed upon detecting this specific text.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_18\n\nLANGUAGE: text\nCODE:\n```\nI have read the CLA Document and I hereby sign the CLA\n```\n\n----------------------------------------\n\nTITLE: Contributor License Agreement (CLA) Signature Comment (Text)\nDESCRIPTION: Specifies the exact text required in a pull request comment for contributors to sign the Contributor License Agreement (CLA). Adding a comment with precisely 'I have read the CLA Document and I hereby sign the CLA' allows the CLA-Assistant bot to verify the signature and update the PR status.\nSOURCE: https://github.com/openai/codex/blob/main/README.md#_snippet_16\n\nLANGUAGE: text\nCODE:\n```\nI have read the CLA Document and I hereby sign the CLA\n```"
  }
]