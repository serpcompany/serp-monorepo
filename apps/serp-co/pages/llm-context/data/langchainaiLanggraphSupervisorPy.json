[
  {
    "owner": "langchain-ai",
    "repo": "langgraph-supervisor-py",
    "content": "TITLE: Creating a Supervisor-Managed Multi-Agent System in Python\nDESCRIPTION: Demonstrates how to create specialized agents, a supervisor workflow, and run the system to process a user query about FAANG company headcounts.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_openai import ChatOpenAI\n\nfrom langgraph_supervisor import create_supervisor\nfrom langgraph.prebuilt import create_react_agent\n\nmodel = ChatOpenAI(model=\"gpt-4o\")\n\n# Create specialized agents\n\ndef add(a: float, b: float) -> float:\n    \"\"\"Add two numbers.\"\"\"\n    return a + b\n\ndef multiply(a: float, b: float) -> float:\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\ndef web_search(query: str) -> str:\n    \"\"\"Search the web for information.\"\"\"\n    return (\n        \"Here are the headcounts for each of the FAANG companies in 2024:\\n\"\n        \"1. **Facebook (Meta)**: 67,317 employees.\\n\"\n        \"2. **Apple**: 164,000 employees.\\n\"\n        \"3. **Amazon**: 1,551,000 employees.\\n\"\n        \"4. **Netflix**: 14,000 employees.\\n\"\n        \"5. **Google (Alphabet)**: 181,269 employees.\"\n    )\n\nmath_agent = create_react_agent(\n    model=model,\n    tools=[add, multiply],\n    name=\"math_expert\",\n    prompt=\"You are a math expert. Always use one tool at a time.\"\n)\n\nresearch_agent = create_react_agent(\n    model=model,\n    tools=[web_search],\n    name=\"research_expert\",\n    prompt=\"You are a world class researcher with access to web search. Do not do any math.\"\n)\n\n# Create supervisor workflow\nworkflow = create_supervisor(\n    [research_agent, math_agent],\n    model=model,\n    prompt=(\n        \"You are a team supervisor managing a research expert and a math expert. \"\n        \"For current events, use research_agent. \"\n        \"For math problems, use math_agent.\"\n    )\n)\n\n# Compile and run\napp = workflow.compile()\nresult = app.invoke({\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"what's the combined headcount of the FAANG companies in 2024?\"\n        }\n    ]\n})\n```\n\n----------------------------------------\n\nTITLE: Setting up Supervisor Workflow\nDESCRIPTION: Creates a supervisor workflow that manages both research and joke agents. The supervisor is configured with a specific model and instructions for delegating tasks between agents based on the request type.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nworkflow = create_supervisor(\n    [research_agent, joke_agent],\n    model=model,\n    prompt=(\n        \"You are a team supervisor managing a research expert and a joke expert. \"\n        \"For current events, use research_agent. \"\n        \"For any jokes, use joke_agent.\"\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Using Functional API for Supervisor-Managed Agents in Python\nDESCRIPTION: Demonstrates how to create a supervisor-managed multi-agent system using the Functional API, including a joke generator agent.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.prebuilt import create_react_agent\nfrom langgraph_supervisor import create_supervisor\n\nfrom langchain_openai import ChatOpenAI\n\nfrom langgraph.func import entrypoint, task\nfrom langgraph.graph import add_messages\n\nmodel = ChatOpenAI(model=\"gpt-4o\")\n\n# Create specialized agents\n\n# Functional API - Agent 1 (Joke Generator)\n@task\ndef generate_joke(messages):\n    \"\"\"First LLM call to generate initial joke\"\"\"\n    system_message = {\n        \"role\": \"system\", \n        \"content\": \"Write a short joke\"\n    }\n    msg = model.invoke(\n        [system_message] + messages\n    )\n    return msg\n\n@entrypoint()\ndef joke_agent(state):\n    joke = generate_joke(state['messages']).result()\n    messages = add_messages(state[\"messages\"], [joke])\n    return {\"messages\": messages}\n\njoke_agent.name = \"joke_agent\"\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-level Hierarchies in Python\nDESCRIPTION: Demonstrates how to create a multi-level hierarchical system by nesting supervisors that manage multiple agents or other supervisors.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nresearch_team = create_supervisor(\n    [research_agent, math_agent],\n    model=model,\n    supervisor_name=\"research_supervisor\"\n).compile(name=\"research_team\")\n\nwriting_team = create_supervisor(\n    [writing_agent, publishing_agent],\n    model=model,\n    supervisor_name=\"writing_supervisor\"\n).compile(name=\"writing_team\")\n\ntop_level_supervisor = create_supervisor(\n    [research_team, writing_team],\n    model=model,\n    supervisor_name=\"top_level_supervisor\"\n).compile(name=\"top_level_supervisor\")\n```\n\n----------------------------------------\n\nTITLE: Adding Memory to Supervisor Multi-Agent System in Python\nDESCRIPTION: Shows how to add short-term and long-term memory to a supervisor multi-agent system using checkpointers and stores.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.store.memory import InMemoryStore\n\ncheckpointer = InMemorySaver()\nstore = InMemoryStore()\n\nmodel = ...\nresearch_agent = ...\nmath_agent = ...\n\nworkflow = create_supervisor(\n    [research_agent, math_agent],\n    model=model,\n    prompt=\"You are a team supervisor managing a research expert and a math expert.\",\n)\n\n# Compile with checkpointer/store\napp = workflow.compile(\n    checkpointer=checkpointer,\n    store=store\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Research Agent with React Framework\nDESCRIPTION: Initializes a research agent using React framework with web search capability. The agent is configured with a specific model and instructed to perform research without mathematical operations.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nresearch_agent = create_react_agent(\n    model=model,\n    tools=[web_search],\n    name=\"research_expert\",\n    prompt=\"You are a world class researcher with access to web search. Do not do any math.\"\n)\n```\n\n----------------------------------------\n\nTITLE: Executing Supervisor Workflow\nDESCRIPTION: Compiles and executes the supervisor workflow with a sample user request for a joke. The code includes result processing and message display functionality.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\napp = workflow.compile()\nresult = app.invoke({\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Share a joke to relax and start vibe coding for my next project idea.\"\n        }\n    ]\n})\n\nfor m in result[\"messages\"]:\n    m.pretty_print()\n```\n\n----------------------------------------\n\nTITLE: Customizing Handoff Tools in Python\nDESCRIPTION: Demonstrates how to create and use custom handoff tools for agent communication in a supervisor multi-agent system.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph_supervisor import create_handoff_tool\nworkflow = create_supervisor(\n    [research_agent, math_agent],\n    tools=[\n        create_handoff_tool(agent_name=\"math_expert\", name=\"assign_to_math_expert\", description=\"Assign task to math expert\"),\n        create_handoff_tool(agent_name=\"research_expert\", name=\"assign_to_research_expert\", description=\"Assign task to research expert\")\n    ],\n    model=model,\n)\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\n\nfrom langchain_core.tools import tool, BaseTool, InjectedToolCallId\nfrom langchain_core.messages import ToolMessage\nfrom langgraph.types import Command\nfrom langgraph.prebuilt import InjectedState\n\ndef create_custom_handoff_tool(*, agent_name: str, name: str | None, description: str | None) -> BaseTool:\n\n    @tool(name, description=description)\n    def handoff_to_agent(\n        # you can add additional tool call arguments for the LLM to populate\n        # for example, you can ask the LLM to populate a task description for the next agent\n        task_description: Annotated[str, \"Detailed description of what the next agent should do, including all of the relevant context.\"],\n        # you can inject the state of the agent that is calling the tool\n        state: Annotated[dict, InjectedState],\n        tool_call_id: Annotated[str, InjectedToolCallId],\n    ):\n        tool_message = ToolMessage(\n            content=f\"Successfully transferred to {agent_name}\",\n            name=name,\n            tool_call_id=tool_call_id,\n        )\n        messages = state[\"messages\"]\n        return Command(\n            goto=agent_name,\n            graph=Command.PARENT,\n            # NOTE: this is a state update that will be applied to the swarm multi-agent graph (i.e., the PARENT graph)\n            update={\n                \"messages\": messages + [tool_message],\n                \"active_agent\": agent_name,\n                # optionally pass the task description to the next agent\n                # NOTE: individual agents would need to have `task_description` in their state schema\n                # and would need to implement logic for how to consume it\n                \"task_description\": task_description,\n            },\n        )\n\n    return handoff_to_agent\n```\n\n----------------------------------------\n\nTITLE: Configuring Message History Management in Python\nDESCRIPTION: Shows how to control the inclusion of agent messages in the overall conversation history using different output modes.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nworkflow = create_supervisor(\n    agents=[agent1, agent2],\n    output_mode=\"full_history\"\n)\n```\n\nLANGUAGE: python\nCODE:\n```\nworkflow = create_supervisor(\n    agents=[agent1, agent2],\n    output_mode=\"last_message\"\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Web Search Function for Research Agent\nDESCRIPTION: Defines a mock web search function that returns hardcoded FAANG company employee counts for 2024. This function serves as a tool for the research agent to access web information.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef web_search(query: str) -> str:\n    \"\"\"Search the web for information.\"\"\"\n    return (\n        \"Here are the headcounts for each of the FAANG companies in 2024:\\n\"\n        \"1. **Facebook (Meta)**: 67,317 employees.\\n\"\n        \"2. **Apple**: 164,000 employees.\\n\"\n        \"3. **Amazon**: 1,551,000 employees.\\n\"\n        \"4. **Netflix**: 14,000 employees.\\n\"\n        \"5. **Google (Alphabet)**: 181,269 employees.\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph Supervisor and Dependencies\nDESCRIPTION: Commands to install the LangGraph Supervisor library and its dependencies, including setting the OpenAI API key.\nSOURCE: https://github.com/langchain-ai/langgraph-supervisor-py/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install langgraph-supervisor\n\nexport OPENAI_API_KEY=<your_api_key>\n```"
  }
]