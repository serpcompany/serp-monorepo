[
  {
    "owner": "mintplex-labs",
    "repo": "anything-llm",
    "content": "TITLE: Configure Docker Compose for AnythingLLM\nDESCRIPTION: Provides a Docker Compose configuration to deploy AnythingLLM with environment variables, port mappings, volume mounts, and restart policies for persistent and manageable deployment.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/docker/HOW_TO_USE_DOCKER.md#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nversion: '3.8'\nservices:\n  anythingllm:\n    image: mintplexlabs/anythingllm\n    container_name: anythingllm\n    ports:\n    - \"3001:3001\"\n    cap_add:\n      - SYS_ADMIN\n    environment:\n      - STORAGE_DIR=/app/server/storage\n      - JWT_SECRET=\"make this a large list of random numbers and letters 20+\"\n      - LLM_PROVIDER=ollama\n      - OLLAMA_BASE_PATH=http://127.0.0.1:11434\n      - OLLAMA_MODEL_PREF=llama2\n      - OLLAMA_MODEL_TOKEN_LIMIT=4096\n      - EMBEDDING_ENGINE=ollama\n      - EMBEDDING_BASE_PATH=http://127.0.0.1:11434\n      - EMBEDDING_MODEL_PREF=nomic-embed-text:latest\n      - EMBEDDING_MODEL_MAX_CHUNK_LENGTH=8192\n      - VECTOR_DB=lancedb\n      - WHISPER_PROVIDER=local\n      - TTS_PROVIDER=native\n      - PASSWORDMINCHAR=8\n    volumes:\n      - anythingllm_storage:/app/server/storage\n    restart: always\nvolumes:\n  anythingllm_storage:\n    driver: local\n    driver_opts:\n      type: none\n      o: bind\n      device: /path/on/local/disk\n```\n\n----------------------------------------\n\nTITLE: Pull the latest Docker image for AnythingLLM\nDESCRIPTION: Pulls the latest Docker image for the AnythingLLM container, supporting amd64 and arm64 architectures, to ensure up-to-date deployment.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/docker/HOW_TO_USE_DOCKER.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndocker pull mintplexlabs/anythingllm\n```\n\n----------------------------------------\n\nTITLE: Run Docker container for Linux/MacOs with mounted storage\nDESCRIPTION: Sets up and runs the AnythingLLM Docker container on Linux or MacOS, mounting local storage directory to persist data and configuring environment variables.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/docker/HOW_TO_USE_DOCKER.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport STORAGE_LOCATION=$HOME/anythingllm && \\ \nmkdir -p $STORAGE_LOCATION && \\ \ntouch \"$STORAGE_LOCATION/.env\" && \\ \ndocker run -d -p 3001:3001 \\ \n--cap-add SYS_ADMIN \\ \n-v ${STORAGE_LOCATION}:/app/server/storage \\ \n-v ${STORAGE_LOCATION}/.env:/app/server/.env \\ \n-e STORAGE_DIR=\"/app/server/storage\" \\ \nmintplexlabs/anythingllm\n```\n\n----------------------------------------\n\nTITLE: Run Docker container for Windows with mounted storage\nDESCRIPTION: Configures and starts the AnythingLLM Docker container on Windows using PowerShell, setting environment variables and mounting local storage for persistence.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/docker/HOW_TO_USE_DOCKER.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n# Run this in powershell terminal\n$env:STORAGE_LOCATION=\"$HOME\\Documents\\anythingllm\"; `\nIf(!(Test-Path $env:STORAGE_LOCATION)) {New-Item $env:STORAGE_LOCATION -ItemType Directory}; `\nIf(!(Test-Path \"$env:STORAGE_LOCATION\\.env\")) {New-Item \"$env:STORAGE_LOCATION\\.env\" -ItemType File}; `\ndocker run -d -p 3001:3001 `\n--cap-add SYS_ADMIN `\n-v \"$env:STORAGE_LOCATION`:/app/server/storage\" `\n-v \"$env:STORAGE_LOCATION\\.env`:/app/server/.env\" `\n-e STORAGE_DIR=\"/app/server/storage\" `\nmintplexlabs/anythingllm;\n```\n\n----------------------------------------\n\nTITLE: Configuring Chroma Environment Variables\nDESCRIPTION: This snippet demonstrates configuring environment variables to connect to the Chroma vector database. `VECTOR_DB` specifies to use chroma, `CHROMA_ENDPOINT` sets the address to where the chroma server is running. `CHROMA_API_HEADER` and `CHROMA_API_KEY` are optional and required when an authentication middleware is present on the Chroma server.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/vectorDbProviders/chroma/CHROMA_SETUP.md#_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nVECTOR_DB=\"chroma\"\nCHROMA_ENDPOINT='http://localhost:8000'\n# CHROMA_API_HEADER=\"X-Api-Key\" // If you have an Auth middleware on your instance.\n# CHROMA_API_KEY=\"sk-123abc\" // If you have an Auth middleware on your instance.\n```\n\n----------------------------------------\n\nTITLE: Configuring Pinecone Connection Environment Variables - Dotenv\nDESCRIPTION: This snippet illustrates the environment variables needed to configure AnythingLLM to connect to a Pinecone vector database. It specifies the database type, the API key, and the name of the Pinecone index to be used.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/vectorDbProviders/pinecone/PINECONE_SETUP.md#_snippet_0\n\nLANGUAGE: dotenv\nCODE:\n```\nVECTOR_DB=\"pinecone\"\nPINECONE_API_KEY=sklive-123xyz\nPINECONE_INDEX=my-primary-index # the value from the first instruction!\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Milvus Connection in anything-llm\nDESCRIPTION: This snippet shows how to configure the environment variables in the server/.env.development file to connect to a Milvus vector database. It includes settings for the database type, address, username, and password.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/vectorDbProviders/milvus/MILVUS_SETUP.md#_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nVECTOR_DB=\"milvus\"\nMILVUS_ADDRESS=\"http://localhost:19530\"\nMILVUS_USERNAME=minioadmin # Whatever your username and password are\nMILVUS_PASSWORD=minioadmin\n```\n\n----------------------------------------\n\nTITLE: Configuring Astra DB Environment Variables\nDESCRIPTION: Defines the necessary environment variables for connecting AnythingLLM to an Astra Vector Database. Set `VECTOR_DB` to 'astra', and replace the placeholder values for `ASTRA_DB_ENDPOINT` and `ASTRA_DB_APPLICATION_TOKEN` with your actual Astra DB API endpoint and application token obtained from the Astra dashboard.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/vectorDbProviders/astra/ASTRA_SETUP.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nVECTOR_DB=\"astra\"\nASTRA_DB_ENDPOINT=Astra DB API endpoint\nASTRA_DB_APPLICATION_TOKEN=AstraCS:..\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Weaviate Vector Database in Bash\nDESCRIPTION: This snippet shows the required environment variables to configure Anything-LLM to use a Weaviate vector database instance in development mode. Dependencies include an operational Weaviate server (cloud or Docker) and proper endpoint/API key values. Edit the relevant .env.development file or set these variables in the runtime shell/CI; WEAVIATE_API_KEY is optional unless authentication is required. Expected usage is to specify the database provider and endpoint URI, optionally securing access with an API key.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/vectorDbProviders/weaviate/WEAVIATE_SETUP.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nVECTOR_DB=\"weaviate\"\nWEAVIATE_ENDPOINT='http://localhost:8080'\nWEAVIATE_API_KEY= # Optional\n\n```\n\n----------------------------------------\n\nTITLE: Configuring QDrant Database Variables (Development Mode)\nDESCRIPTION: This snippet demonstrates how to configure environment variables for connecting to a QDrant vector database in development mode. It specifies variables like `VECTOR_DB`, `QDRANT_ENDPOINT`, and `QDRANT_API_KEY`.  The `QDRANT_ENDPOINT` holds the URL of the QDrant instance, and `QDRANT_API_KEY` is used for authentication.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/vectorDbProviders/qdrant/QDRANT_SETUP.md#_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# VECTOR_DB=\"qdrant\"\n# QDRANT_ENDPOINT=\"https://<YOUR_CLOUD_INSTANCE_URL>.qdrant.io:6333\"\n# QDRANT_API_KEY=\"abc...123xyz\"\n```\n\n----------------------------------------\n\nTITLE: Initializing .env Files\nDESCRIPTION: This command sets up the required `.env` files within the project, which are necessary for configuring the application. It should be run from the root of the repository. Ensure the `server/.env.development` file is filled out for the server to function correctly.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/README.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\nyarn setup\n```\n\n----------------------------------------\n\nTITLE: Booting the Server Locally\nDESCRIPTION: This command launches the server locally.  It should be executed from the root of the repository.  The server is a core component of AnythingLLM and must be running for other components to function.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/README.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\nyarn dev:server\n```\n\n----------------------------------------\n\nTITLE: Booting the Frontend Locally\nDESCRIPTION: This command starts the frontend locally.  It should be run from the root of the repository. This command is used to develop the user interface of AnythingLLM.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/README.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\nyarn dev:frontend\n```\n\n----------------------------------------\n\nTITLE: Running the Document Collector\nDESCRIPTION: This command initiates the document collector.  It should be run from the root of the repository. The document collector is a crucial component for processing and indexing documents within AnythingLLM.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/README.md#_snippet_3\n\nLANGUAGE: Shell\nCODE:\n```\nyarn dev:collector\n```\n\n----------------------------------------\n\nTITLE: Setting Up Development Environment - Shell\nDESCRIPTION: Executes the initial setup for the AnythingLLM development environment. This command populates the necessary `.env` files in each application section from the repository root. It is a prerequisite before starting development servers.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/locales/README.ja-JP.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\nyarn setup\n```\n\n----------------------------------------\n\nTITLE: Starting AnythingLLM Server - Shell\nDESCRIPTION: Starts the NodeJS express server component of AnythingLLM in development mode from the repository root. This server handles interactions with LLMs, vector databases, and overall application logic. Requires the `server/.env.development` file to be properly configured.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/locales/README.ja-JP.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\nyarn dev:server\n```\n\n----------------------------------------\n\nTITLE: Starting AnythingLLM Frontend - Shell\nDESCRIPTION: Starts the viteJS + React frontend component of AnythingLLM in development mode from the repository root. This provides the user interface for interacting with the application.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/locales/README.ja-JP.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\nyarn dev:frontend\n```\n\n----------------------------------------\n\nTITLE: Running AnythingLLM Document Collector - Shell\nDESCRIPTION: Executes the NodeJS express server responsible for processing and parsing documents in development mode from the repository root. This component handles the ingestion of user-provided documents.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/locales/README.ja-JP.md#_snippet_3\n\nLANGUAGE: Shell\nCODE:\n```\nyarn dev:collector\n```\n\n----------------------------------------\n\nTITLE: Creating .env files for components\nDESCRIPTION: The command `yarn setup` generates the necessary `.env` files for each component of the AnythingLLM application. This command must be run from the root directory of the repository before proceeding with development.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/locales/README.tr-TR.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn setup\n```\n\n----------------------------------------\n\nTITLE: Starting the local server\nDESCRIPTION: The command `yarn dev:server` starts the AnythingLLM server locally. This command should be executed from the root directory of the repository after completing the `.env` file setup.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/locales/README.tr-TR.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyarn dev:server\n```\n\n----------------------------------------\n\nTITLE: Running the local frontend\nDESCRIPTION: The command `yarn dev:frontend` starts the AnythingLLM frontend locally. Ensure that the server is running before starting the frontend. This command is executed from the repository's root directory.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/locales/README.tr-TR.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn dev:frontend\n```\n\n----------------------------------------\n\nTITLE: Running the document collector\nDESCRIPTION: The command `yarn dev:collector` runs the document collector for AnythingLLM. This component is responsible for collecting and processing documents. Run this command from the root of the repository.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/locales/README.tr-TR.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nyarn dev:collector\n```\n\n----------------------------------------\n\nTITLE: Monitoring AWS EC2 Instance Deployment Progress via SSH\nDESCRIPTION: Connects to the newly created EC2 instance via SSH and uses the `tail` command with `sudo` privileges to continuously monitor the `/var/log/cloud-init-output.log` file. This allows users to track the setup process managed by cloud-init, specifically waiting for the Docker container deployment to complete, indicated by output showing the 'anything-llm' container started.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/aws/cloudformation/DEPLOY.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo tail -f /var/log/cloud-init-output.log\n```\n\n----------------------------------------\n\nTITLE: Configuring NGINX as a reverse proxy for Anything LLM\nDESCRIPTION: This NGINX configuration creates a reverse proxy for Anything LLM, handling both standard HTTP requests and WebSocket connections needed for agent protocol. It includes settings to prevent timeouts on long-running requests and enables HTTP streaming for LLM responses.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/aws/cloudformation/aws_https_instructions.md#_snippet_1\n\nLANGUAGE: nginx\nCODE:\n```\nserver {\n   # Enable websocket connections for agent protocol.\n   location ~* ^/api/agent-invocation/(.*) {\n      proxy_pass http://0.0.0.0:3001;\n      proxy_http_version 1.1;\n      proxy_set_header Upgrade $http_upgrade;\n      proxy_set_header Connection \"Upgrade\";\n   }\n\n   listen 80;\n   server_name [insert FQDN here];\n   location / {\n      # Prevent timeouts on long-running requests.\n      proxy_connect_timeout       605;\n      proxy_send_timeout          605;\n      proxy_read_timeout          605;\n      send_timeout                605;\n      keepalive_timeout           605;\n\n      # Enable readable HTTP Streaming for LLM streamed responses\n      proxy_buffering off; \n      proxy_cache off;\n\n      # Proxy your locally running service\n      proxy_pass  http://0.0.0.0:3001;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Commenting out default NGINX server block configuration\nDESCRIPTION: This shows how to comment out the default server block in the NGINX configuration file to prepare for custom configuration. This prevents conflicts with the new Anything LLM proxy configuration.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/aws/cloudformation/aws_https_instructions.md#_snippet_0\n\nLANGUAGE: nginx\nCODE:\n```\n#    server {\n#        listen       80;\n#        listen       [::]:80;\n#        server_name  _;\n#        root         /usr/share/nginx/html;\n#\n#        # Load configuration files for the default server block.\n#        include /etc/nginx/default.d/*.conf;\n#\n#        error_page 404 /404.html;\n#        location = /404.html {\n#        }\n#\n#        error_page 500 502 503 504 /50x.html;\n#        location = /50x.html {\n#        }\n#    }\n```\n\n----------------------------------------\n\nTITLE: Authenticating with GCP Using gcloud CLI - Shell\nDESCRIPTION: Logs in to Google Cloud Platform using the gcloud CLI, enabling subsequent command-line access to GCP resources. Requires the gcloud tool to be installed and a Google account with billing enabled. The command prompts a web-based authorization process.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/gcp/deployment/DEPLOY.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngcloud auth login\n```\n\n----------------------------------------\n\nTITLE: Creating AnythingLLM Deployment with Deployment Manager - Shell\nDESCRIPTION: Creates a new AnythingLLM deployment on GCP using the Deployment Manager CLI and a provided YAML configuration file. Assumes previous authentication and an available configuration file at 'gcp/deployment/gcp_deploy_anything_llm.yaml'. Outputs resources such as a VM instance, security group, and storage volume. Deployment requires active billing in your GCP account.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/gcp/deployment/DEPLOY.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngcloud deployment-manager deployments create anything-llm-deployment --config gcp/deployment/gcp_deploy_anything_llm.yaml\n```\n\n----------------------------------------\n\nTITLE: Fetching Serial Port Output from AnythingLLM VM Instance - Shell\nDESCRIPTION: Retrieves real-time serial port output logs from the deployed AnythingLLM GCP VM instance using the gcloud CLI. Useful for troubleshooting and monitoring the instance boot process. Ensure that the instance name 'anything-llm-instance' matches your deployment.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/gcp/deployment/DEPLOY.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ngcloud compute instances get-serial-port-output anything-llm-instance\n```\n\n----------------------------------------\n\nTITLE: Accessing AnythingLLM Instance via SSH - Shell\nDESCRIPTION: Initiates an SSH connection to the AnythingLLM GCP VM instance using gcloud CLI. This allows direct command-line access for management and debugging. The instance must be running and accessible on the specified ports.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/gcp/deployment/DEPLOY.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ngcloud compute ssh anything-llm-instance\n```\n\n----------------------------------------\n\nTITLE: Deleting AnythingLLM Deployment on GCP - Shell\nDESCRIPTION: Deletes the deployed AnythingLLM resources on GCP using the Deployment Manager CLI. Removes the VM, security group, and associated storage, which stops any billing for these resources. Ensure you have necessary permissions before deletion.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/gcp/deployment/DEPLOY.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ngcloud deployment-manager deployments delete anything-llm-deployment\n```\n\n----------------------------------------\n\nTITLE: Initializing Terraform, Planning and Applying Changes\nDESCRIPTION: These commands initialize Terraform, review the infrastructure changes that will be applied, and then apply those changes to create the DigitalOcean resources. The 'terraform init' command initializes the Terraform working directory. 'terraform plan' generates an execution plan showing the changes to be made, and 'terraform apply' executes the plan to provision the resources.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/digitalocean/terraform/DEPLOY.md#_snippet_0\n\nLANGUAGE: Terraform\nCODE:\n```\nterraform init  \nterraform plan  \nterraform apply\n```\n\n----------------------------------------\n\nTITLE: Destroying Terraform Managed Resources\nDESCRIPTION: This command destroys all the resources created by Terraform in the current working directory. It prompts for confirmation before destroying the resources and removes the deployed DigitalOcean Droplet.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/cloud-deployments/digitalocean/terraform/DEPLOY.md#_snippet_1\n\nLANGUAGE: Terraform\nCODE:\n```\nterraform destroy\n```\n\n----------------------------------------\n\nTITLE: Setting Ollama Host Environment Variable on macOS (launchctl) - bash\nDESCRIPTION: Sets the `OLLAMA_HOST` environment variable to \"0.0.0.0\" for the current user session using `launchctl`. This command requires the `launchctl` utility, typically available on macOS. It configures Ollama to bind to all network interfaces, making it accessible from external IPs, including those within the Docker network.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/AiProviders/ollama/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nlaunchctl setenv OLLAMA_HOST \"0.0.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Ollama Host Environment Variable in Linux systemd Service - ini\nDESCRIPTION: Adds or modifies the `Environment` line within the `[Service]` section of the Ollama systemd unit file. This configures the `OLLAMA_HOST` environment variable to \"0.0.0.0\" for the Ollama service when it starts, allowing it to bind to all network interfaces. This requires editing the service file, typically via `systemctl edit ollama.service`.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/AiProviders/ollama/README.md#_snippet_1\n\nLANGUAGE: ini\nCODE:\n```\n[Service]\nEnvironment=\"OLLAMA_HOST=0.0.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Reloading systemd Configuration on Linux - bash\nDESCRIPTION: Instructs the systemd manager to reload its configuration files, including unit files that may have been changed. This command is essential after modifying a service file (like `ollama.service`) before restarting the service for the changes to take effect.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/AiProviders/ollama/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsystemctl daemon-reload\n```\n\n----------------------------------------\n\nTITLE: Restarting Ollama systemd Service on Linux - bash\nDESCRIPTION: Restarts the Ollama service managed by systemd. This command applies any configuration changes made to the service's unit file, such as newly set environment variables like `OLLAMA_HOST`. This step is required after reloading the systemd daemon.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/AiProviders/ollama/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsystemctl restart ollama\n```\n\n----------------------------------------\n\nTITLE: Running Prisma Setup Script - Bash\nDESCRIPTION: This script, `yarn setup`, installs necessary node modules, sets up environment files, generates the Prisma client, runs migrations, and seeds the database. It is essential for initializing Prisma in the project. Running this script will ensure the necessary dependencies are installed, and the database is initialized correctly.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/prisma/PRISMA.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nyarn setup\n```\n\n----------------------------------------\n\nTITLE: Running Prisma Script - Bash\nDESCRIPTION: This snippet demonstrates how to execute a Prisma script defined in the project's `package.json` file. It uses `yarn` followed by the script name, such as `prisma:setup`, from the project root directory. This approach is used for managing the Prisma setup, generating the client, running migrations, and seeding the database.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/prisma/PRISMA.md#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nyarn prisma:setup\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for AnythingLLM Server\nDESCRIPTION: Essential environment variable configuration needed in the server/.env file to specify storage directory for the AnythingLLM server.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/BARE_METAL.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nSTORAGE_DIR=\"/your/absolute/path/to/server/storage\"\n```\n\n----------------------------------------\n\nTITLE: Frontend API Configuration in .env File\nDESCRIPTION: Configuration options for the frontend/.env file to set the correct API base URL depending on the deployment environment.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/BARE_METAL.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n# VITE_API_BASE='http://localhost:3001/api' # Use this URL when developing locally\n# VITE_API_BASE=\"https://$CODESPACE_NAME-3001.$GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN/api\" # for GitHub Codespaces\nVITE_API_BASE='/api' # Use this URL deploying on non-localhost address OR in docker.\n```\n\n----------------------------------------\n\nTITLE: Database Migration Commands for Prisma\nDESCRIPTION: Commands for generating Prisma client and deploying database migrations before starting the server in a production environment.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/BARE_METAL.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncd server && npx prisma generate --schema=./prisma/schema.prisma\ncd server && npx prisma migrate deploy --schema=./prisma/schema.prisma\n```\n\n----------------------------------------\n\nTITLE: Comprehensive Update Script for AnythingLLM\nDESCRIPTION: Bash script to automate the update process for an AnythingLLM deployment, including pulling latest code, rebuilding the frontend, installing dependencies, running migrations, and restarting services.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/BARE_METAL.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\n\ncd $HOME/anything-llm &&\\\ngit checkout . &&\\\ngit pull origin master &&\\\necho \"HEAD pulled to commit $(git log -1 --pretty=format:\"%h\" | tail -n 1)\"\n\necho \"Freezing current ENVs\"\ncurl -I \"http://localhost:3001/api/env-dump\" | head -n 1|cut -d$' ' -f2\n\necho \"Rebuilding Frontend\"\ncd $HOME/anything-llm/frontend && yarn && yarn build && cd $HOME/anything-llm\n\necho \"Copying to Sever Public\"\nrm -rf server/public\ncp -r frontend/dist server/public\n\necho \"Killing node processes\"\npkill node\n\necho \"Installing collector dependencies\"\ncd $HOME/anything-llm/collector && yarn\n\necho \"Installing server dependencies & running migrations\"\ncd $HOME/anything-llm/server && yarn\ncd $HOME/anything-llm/server && npx prisma migrate deploy --schema=./prisma/schema.prisma\ncd $HOME/anything-llm/server && npx prisma generate\n\necho \"Booting up services.\"\ntruncate -s 0 /logs/server.log # Or any other log file location.\ntruncate -s 0 /logs/collector.log\n\ncd $HOME/anything-llm/server\n(NODE_ENV=production node index.js) &> /logs/server.log &\n\ncd $HOME/anything-llm/collector\n(NODE_ENV=production node index.js) &> /logs/collector.log &\n```\n\n----------------------------------------\n\nTITLE: Cloning Chroma Repository with Git\nDESCRIPTION: This command clones the Chroma repository from GitHub to a local directory. It requires Git to be installed and configured on the system. The cloned repository contains the necessary files for setting up and running the Chroma vector database.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/vectorDbProviders/chroma/CHROMA_SETUP.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:chroma-core/chroma.git\n```\n\n----------------------------------------\n\nTITLE: Starting Chroma with Docker Compose\nDESCRIPTION: This command uses Docker Compose to build and start the Chroma vector database. It assumes a `docker-compose.yml` file exists in the current directory. The `-d` flag runs the containers in detached mode, allowing the user to continue using the terminal.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/vectorDbProviders/chroma/CHROMA_SETUP.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d --build\n```\n\n----------------------------------------\n\nTITLE: Downloading and Running Milvus with Docker Compose\nDESCRIPTION: This snippet demonstrates how to download the Milvus standalone Docker Compose configuration file and start the Milvus containers. It also shows how to verify that the containers are running properly.\nSOURCE: https://github.com/mintplex-labs/anything-llm/blob/master/server/utils/vectorDbProviders/milvus/MILVUS_SETUP.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nwget https://github.com/milvus-io/milvus/releases/download/v2.3.4/milvus-standalone-docker-compose.yml -O docker-compose.yml\nsudo docker compose up -d\nsudo docker compose ps\n```"
  }
]