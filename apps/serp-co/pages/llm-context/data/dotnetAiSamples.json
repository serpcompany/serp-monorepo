[
  {
    "owner": "dotnet",
    "repo": "ai-samples",
    "content": "TITLE: Generating Question-Answer Pairs from a Topic\nDESCRIPTION: Demonstrates generating a single QA pair from a specified topic using an LLM, with serialization and console output of the generated content\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/README.md#2025-04-21_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nvar topic = SpectreConsoleOutput.AskForString(\"Type the topic to generate the QA?\");\n\nvar qa = await QALLMGenerator.GenerateQA(kernelGenData, topic);\nvar json = JsonSerializer.Serialize(qa, new JsonSerializerOptions\n{\n    WriteIndented = true\n});\nSpectreConsoleOutput.DisplayJson(json, \"Generated QA using LLM\", true);\n```\n\n----------------------------------------\n\nTITLE: Creating Kernels for Azure OpenAI Services with .NET\nDESCRIPTION: Demonstrates how to create Semantic Kernel instances using Azure OpenAI configuration from user secrets, enabling flexible LLM integration for evaluation and data generation\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/README.md#2025-04-21_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\npublic static Kernel CreateKernelEval()\n{\n    var config = new ConfigurationBuilder().AddUserSecrets<Program>().Build();\n\n    var builder = Kernel.CreateBuilder();\n\n    builder.AddAzureOpenAIChatCompletion(\n        config[\"AZURE_OPENAI_MODEL\"],\n        config[\"AZURE_OPENAI_ENDPOINT\"],\n        config[\"AZURE_OPENAI_KEY\"]);\n\n    return builder.Build();\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Semantic Kernel with OpenAI Service\nDESCRIPTION: Initializes the Semantic Kernel by adding OpenAI chat completion service using environment variable for API key\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/01 Hello Semantic Kernel.md#2025-04-21_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nvar kernel = Kernel.CreateBuilder()\n    .AddOpenAIChatCompletion(openAIChatCompletionModelName, Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\"))\n    .Build();\n```\n\n----------------------------------------\n\nTITLE: Creating Kernels for Local Open Source LLMs\nDESCRIPTION: Shows how to create a Semantic Kernel instance for accessing local LLM models like Phi-3 or Llama 3 through Ollama, enabling flexible model evaluation\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/README.md#2025-04-21_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\npublic static Kernel CreateKernelEval()\n{\n    var config = new ConfigurationBuilder().AddUserSecrets<Program>().Build();\n\n    var builder = Kernel.CreateBuilder();\n\n        builder.AddOpenAIChatCompletion(\n            modelId: \"phi3\",\n            endpoint: new Uri(\"http://localhost:11434\"),\n            apiKey: \"api\");\n\n    return builder.Build();\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Loop with History in C#\nDESCRIPTION: This code shows the main chat loop that takes user input, adds it to the `chatHistory`, gets a response from the AI using `chatService.GetChatMessageContentAsync`, prints the response, and adds the AI's response to the `chatHistory`.  This creates a stateful conversation.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/02 Add Chat History.md#2025-04-21_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\n// Basic chat\n    while (true)\n    {\n        Console.Write(\"Q: \");\n        chatHistory.AddUserMessage(Console.ReadLine()); // Add user message to chat history.\n        var response = await chatService.GetChatMessageContentAsync(chatHistory); // Get chat response based on chat history.\n        Console.WriteLine(response); // Print response.\n        chatHistory.Add(response); // Add chat response to chat history\n    }\n```\n\n----------------------------------------\n\nTITLE: Initializing Semantic Kernel with Phi-3 Model for Chat Completion\nDESCRIPTION: C# code snippet demonstrating how to initialize Semantic Kernel with the Phi-3 model for chat completion tasks. It sets up the kernel with a custom HTTP address and invokes a prompt.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/local-models/phi3-llama3/README.md#2025-04-21_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.SemanticKernel;\n\n// Create kernel with a custom http address\nvar builder = Kernel.CreateBuilder();\nbuilder.AddOpenAIChatCompletion(\n    modelId: \"phi3\",\n    endpoint: new Uri(\"http://localhost:11434\"),\n    apiKey: \"apikey\");\nvar kernel = builder.Build();\n\nvar prompt = \"Write a joke about kittens.\";\nvar response = await kernel.InvokePromptAsync(prompt);\nConsole.WriteLine(response.GetValue<string>());\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Response Logic\nDESCRIPTION: Retrieves chat response based on chat history using the configured settings and kernel.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/03 Add Plugin (Function Call).md#2025-04-21_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nvar response = await chatService.GetChatMessageContentAsync(chatHistory, settings, kernel);\n```\n\n----------------------------------------\n\nTITLE: Implementing DemographicInfo Plugin Class\nDESCRIPTION: Defines a class with a kernel function that returns age information for specific names. The GetAge function is decorated with KernelFunction attribute to mark it as a kernel function.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/03 Add Plugin (Function Call).md#2025-04-21_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nclass DemographicInfo\n{\n    [KernelFunction]\n    public int GetAge(string name)\n    {\n        return name switch\n        {\n            \"Alice\" => 25,\n            \"Bob\" => 30,\n            _ => 0\n        };\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Weather Forecast Endpoint\nDESCRIPTION: Creating an endpoint that returns weather forecast data with AI-generated weather descriptions\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_7\n\nLANGUAGE: csharp\nCODE:\n```\napp.MapGet(\"/WeatherForecast\", async (Kernel kernel) =>\n{\n    int temp = Random.Shared.Next(-20, 55);\n    return new WeatherForecast\n    (\n        DateOnly.FromDateTime(DateTime.Now),\n        temp,\n        await kerel.InvokePromptAsync<string>($\"Short description of weather at {temp} degrees Celsius\") // This description will be generated by the AI model for the given temperature.\n    );\n});\napp.Run();\n\ninternal record WeatherForecast(DateOnly Date, int TempratureC, string Summary);\n```\n\n----------------------------------------\n\nTITLE: Configuring Logging Services in Dependency Injection Container\nDESCRIPTION: C# code to add and configure logging services to the dependency injection service collection with console logging enabled at Trace level.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/04 Add Logging.md#2025-04-21_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\n// Add logging services to the builder\nbuilder.Services.AddLogging(b => b.AddConsole().SetMinimumLevel(LogLevel.Trace));\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Evaluation Metrics\nDESCRIPTION: Shows how to configure custom evaluation metrics for LLM output assessment, including coherence, groundedness, relevance, and length evaluators\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/README.md#2025-04-21_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nvar kernelEvalFunctions = kernelEval.CreatePluginFromPromptDirectory(\"Prompts\");\nvar batchEval = new Core.LLMEval();\n\nbatchEval\n    .AddEvaluator(new PromptScoreEval(\"coherence\", kernelEval, kernelEvalFunctions[\"coherence\"]))\n    .AddEvaluator(new PromptScoreEval(\"groundedness\", kernelEval, kernelEvalFunctions[\"groundedness\"]))\n    .AddEvaluator(new PromptScoreEval(\"relevance\", kernelEval, kernelEvalFunctions[\"relevance\"]))\n    .AddEvaluator(new LenghtEval());\nbatchEval.SetMeterId(\"phi3\");\n```\n\n----------------------------------------\n\nTITLE: Importing Bing Search Plugin in Semantic Kernel\nDESCRIPTION: This code snippet imports the Bing Search plugin into the Semantic Kernel, creating a Bing connector using an API key stored in an environment variable. It also suppresses a specific warning.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/05 Add Plugin (Bing Search).md#2025-04-21_snippet_2\n\nLANGUAGE: Csharp\nCODE:\n```\n#pragma warning disable SKEXP0050\nkernel.ImportPluginFromObject(new WebSearchEnginePlugin(\n    new BingConnector(Environment.GetEnvironmentVariable(\"BING_API_KEY\"))));\n#pragma warning restore SKEXP0050\n```\n\n----------------------------------------\n\nTITLE: Implementing Permission Filter Class in C#\nDESCRIPTION: Implementation of the IFunctionInvocationFilter interface that prompts the user for permission before executing a function, throwing an exception if permission is denied.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/06 Modifying Kernel Behavior with Dependency Injection.md#2025-04-21_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nclass PermissionFilter : IFunctionInvocationFilter\n{\npublic async Task OnFunctionInvocationAsync(FunctionInvocationContext context, Func<FunctionInvocationContext, Task> next)\n{\n      Console.WriteLine($\"Allow {context.Function.Name}?\");\n      if (Console.ReadLine() == \"y\")\n      {\n            await next(context);\n      }\n      else\n      {\n            throw new Exception(\"Permission denied\");\n      }\n}\n}\n```\n\n----------------------------------------\n\nTITLE: Example Console Output of Semantic Kernel Execution\nDESCRIPTION: Console output showing the execution flow of a Semantic Kernel application with HTTP tracing, redacted authorization headers, and permission prompting for function invocation.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/06 Modifying Kernel Behavior with Dependency Injection.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\ntrce: Microsoft.SemanticKernel.Plugins.Web.WebSearchEnginePlugin[0]\n      Created KernelFunction 'Search' for 'SearchAsync'\ntrce: Microsoft.SemanticKernel.Plugins.Web.WebSearchEnginePlugin[0]\n      Created KernelFunction 'GetSearchResults' for 'GetSearchResultsAsync'\ntrce: Microsoft.SemanticKernel.Plugins.Web.WebSearchEnginePlugin[0]\n      Created plugin WebSearchEnginePlugin with 2 [KernelFunction] methods out of 8 methods found.\nQ: What are the major Microsoft announcements in Build 2024?\ntrce: Microsoft.SemanticKernel.Connectors.OpenAI.OpenAIChatCompletionService[0]\n      ChatHistory: [{\"Role\":{\"Label\":\"user\"},\"Items\":[{\"$type\":\"TextContent\",\"Text\":\"What are the major Microsoft announcements in Build 2024?\"}]}], Settings: {\"temperature\":1,\"top_p\":1,\"presence_penalty\":0,\"frequency_penalty\":0,\"max_tokens\":null,\"stop_sequences\":null,\"results_per_prompt\":1,\"seed\":null,\"response_format\":null,\"chat_system_prompt\":null,\"token_selection_biases\":null,\"ToolCallBehavior\":{\"ToolCallResultSerializerOptions\":null},\"User\":null,\"logprobs\":null,\"top_logprobs\":null,\"model_id\":null}\ninfo: System.Net.Http.HttpClient.Default.LogicalHandler[100]\n      Start processing HTTP request POST https://api.openai.com/v1/chat/completions\ntrce: System.Net.Http.HttpClient.Default.LogicalHandler[102]\n      Request Headers:\n      Accept: application/json\n      Semantic-Kernel-Version: 1.13.0.0\n      x-ms-client-request-id: b83ec540-7938-41c8-ad48-08cd2bc944c2\n      x-ms-return-client-request-id: true\n      User-Agent: Semantic-Kernel, azsdk-net-AI.OpenAI/1.0.0-beta.15, (.NET 8.0.5; Microsoft Windows 10.0.22631)\n      Authorization: *\n      Content-Type: application/json\n\ndbug: Polly[1]\n      Resilience pipeline executing. Source: '-standard/', Operation Key: '(null)'\ninfo: System.Net.Http.HttpClient.Default.ClientHandler[100]\n      Sending HTTP request POST https://api.openai.com/v1/chat/completions\ntrce: System.Net.Http.HttpClient.Default.ClientHandler[102]\n      Request Headers:\n      Accept: application/json\n      Semantic-Kernel-Version: 1.13.0.0\n      x-ms-client-request-id: b83ec540-7938-41c8-ad48-08cd2bc944c2\n      x-ms-return-client-request-id: true\n      User-Agent: Semantic-Kernel, azsdk-net-AI.OpenAI/1.0.0-beta.15, (.NET 8.0.5; Microsoft Windows 10.0.22631)\n      Authorization: *\n      Content-Type: application/json\n\ninfo: System.Net.Http.HttpClient.Default.ClientHandler[101]\n      Received HTTP response headers after 2160.4263ms - 200\ntrce: System.Net.Http.HttpClient.Default.ClientHandler[103]\n      Response Headers:\n      Date: Mon, 17 Jun 2024 19:29:50 GMT\n      Transfer-Encoding: chunked\n      Connection: keep-alive\n      openai-organization: jakerad\n      openai-processing-ms: 1644\n      openai-version: 2020-10-01\n      Strict-Transport-Security: max-age=15724800; includeSubDomains\n      x-ratelimit-limit-requests: 500\n      x-ratelimit-limit-tokens: 30000\n      x-ratelimit-remaining-requests: 499\n      x-ratelimit-remaining-tokens: 29968\n      x-ratelimit-reset-requests: 120ms\n      x-ratelimit-reset-tokens: 64ms\n      X-Request-ID: req_ca74fa8e36b14b8b8abf2c5d7a771662\n      CF-Cache-Status: DYNAMIC\n      Set-Cookie: __cf_bm=Qc7Bmv2jFNAACsyHMNVilFyRcdP0otO5Vh6fIenIF58-1718652590-1.0.1.1-opt4QPCpcTC988a5M76D_bjPDSgxOFsqPyTjaDqnDqYilp2KwcfCrXaHbveJRD6yD2SoH4D_SDi3opanlUFjqQ; path=/; expires=Mon, 17-Jun-24 19:59:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=CaQj2xRIYdEe8aYXxPZFNTdgDyiUy2NFNejDyk3VS_s-1718652590385-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None\n      Server: cloudflare\n      CF-RAY: 89557356e808766a-SEA\n      Alt-Svc: h3=\":443\"\n      Content-Type: application/json\n\ninfo: Polly[3]\n      Execution attempt. Source: '-standard//Standard-Retry', Operation Key: '', Result: '200', Handled: 'False', Attempt: '0', Execution Time: '2176.1582'\ndbug: Polly[2]\n      Resilience pipeline executed. Source: '-standard/', Operation Key: '', Result: '200', Execution Time: 2191.4154ms\ninfo: System.Net.Http.HttpClient.Default.LogicalHandler[101]\n      End processing HTTP request after 2224.9318ms - 200\ntrce: System.Net.Http.HttpClient.Default.LogicalHandler[103]\n      Response Headers:\n      Date: Mon, 17 Jun 2024 19:29:50 GMT\n      Transfer-Encoding: chunked\n      Connection: keep-alive\n      openai-organization: jakerad\n      openai-processing-ms: 1644\n      openai-version: 2020-10-01\n      Strict-Transport-Security: max-age=15724800; includeSubDomains\n      x-ratelimit-limit-requests: 500\n      x-ratelimit-limit-tokens: 30000\n      x-ratelimit-remaining-requests: 499\n      x-ratelimit-remaining-tokens: 29968\n      x-ratelimit-reset-requests: 120ms\n      x-ratelimit-reset-tokens: 64ms\n      X-Request-ID: req_ca74fa8e36b14b8b8abf2c5d7a771662\n      CF-Cache-Status: DYNAMIC\n      Set-Cookie: __cf_bm=Qc7Bmv2jFNAACsyHMNVilFyRcdP0otO5Vh6fIenIF58-1718652590-1.0.1.1-opt4QPCpcTC988a5M76D_bjPDSgxOFsqPyTjaDqnDqYilp2KwcfCrXaHbveJRD6yD2SoH4D_SDi3opanlUFjqQ; path=/; expires=Mon, 17-Jun-24 19:59:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=CaQj2xRIYdEe8aYXxPZFNTdgDyiUy2NFNejDyk3VS_s-1718652590385-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None\n      Server: cloudflare\n      CF-RAY: 89557356e808766a-SEA\n      Alt-Svc: h3=\":443\"\n      Content-Type: application/json\n\ninfo: Microsoft.SemanticKernel.Connectors.OpenAI.OpenAIChatCompletionService[0]\n      Prompt tokens: 165. Completion tokens: 24. Total tokens: 189.\ndbug: Microsoft.SemanticKernel.Connectors.OpenAI.OpenAIChatCompletionService[0]\n      Tool requests: 1\ntrce: Microsoft.SemanticKernel.Connectors.OpenAI.OpenAIChatCompletionService[0]\n      Function call requests: WebSearchEnginePlugin-Search({\"query\":\"major Microsoft announcements Build 2024\"})\ninfo: Search[0]\n      Function Search invoking.\ntrce: Search[0]\n      Function arguments: {\"query\":\"major Microsoft announcements Build 2024\"}\nAllow Search?\ny\ninfo: Search[0]\n      Function Search succeeded.\ntrce: Search[0]\n```\n\n----------------------------------------\n\nTITLE: Invoking QA Format Prompt with Semantic Kernel\nDESCRIPTION: C# code snippet showing how to use Semantic Kernel to invoke a QA format prompt for solving a physics problem using a local language model.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/local-models/phi3-llama3/README.md#2025-04-21_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nvar prompt = @\"Instruction: A skier slides down a frictionless slope of height 40m and length 80m, what's the skier's speed at the bottom?\nOutput:\";\nvar response = await kernel.InvokePromptAsync(prompt);\nConsole.WriteLine(response.GetValue<string>());\n```\n\n----------------------------------------\n\nTITLE: Generating Python Code using Semantic Kernel\nDESCRIPTION: C# code snippet demonstrating how to use Semantic Kernel to generate Python code for printing prime numbers based on a given prompt.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/local-models/phi3-llama3/README.md#2025-04-21_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nvar codePrompt = @\"Complete the following code\n```python\ndef print_prime(n):\n    # print all prime numbers less than n\";\nvar response = await kernel.InvokePromptAsync(prompt);\nConsole.WriteLine(response.GetValue<string>());\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Service\nDESCRIPTION: Adding OpenAI chat completion service and building the application\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_6\n\nLANGUAGE: csharp\nCODE:\n```\n// This should work for any other service you can decided to use E.g Mistral.\nvar kernel = builder.Services.AddOpenAIChatCompletion(openAIChatCompletionModelName, Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\"));\nvar app = builder.Build();\n```\n\n----------------------------------------\n\nTITLE: Adding Kernel Service\nDESCRIPTION: Adding the Semantic Kernel service to the dependency injection container\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nbuilder.Services.AddKernel();\n```\n\n----------------------------------------\n\nTITLE: Processing User Story Batch Evaluation in C#\nDESCRIPTION: Demonstrates how to evaluate a batch of user stories from a JSON file using custom metrics. The code loads sample data, processes it through a user story creator, and performs evaluation with results display.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/README.md#2025-04-21_snippet_7\n\nLANGUAGE: csharp\nCODE:\n```\n// ========================================\n// evaluate a batch of inputs for User Stories from a file\n// ========================================\nSpectreConsoleOutput.DisplayTitleH2(\"Processing batch of User Stories\");\nvar fileName = \"assets/data-15.json\";\nConsole.WriteLine($\"Processing {fileName} ...\");\nConsole.WriteLine(\"\");\n\n// load the sample data\nvar userStoryCreator = new UserStoryCreator.UserStoryCreator(kernelTest);\nvar userInputCollection = await UserStoryGenerator.FileProcessor.ProcessUserInputFile(fileName);\n\nvar modelOutputCollection = await userStoryCreator.ProcessCollection(userInputCollection);\nvar results = await batchEval.ProcessCollection(modelOutputCollection);\nresults.EvalRunName = \"User Story collection from file\";\nSpectreConsoleOutput.DisplayResults(results);\n```\n\n----------------------------------------\n\nTITLE: Configuring Function Call Behavior\nDESCRIPTION: Sets up the OpenAI prompt execution settings to automatically invoke kernel functions when appropriate.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/03 Add Plugin (Function Call).md#2025-04-21_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nvar settings = new OpenAIPromptExecutionSettings() { ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions };\n```\n\n----------------------------------------\n\nTITLE: Displaying Microsoft.Extensions.AI Sample Implementations Table in Markdown\nDESCRIPTION: This markdown table lists various sample implementations of Microsoft.Extensions.AI, including links to GitHub repositories and brief descriptions for each topic.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n|Topic | GitHub Link | Description | \n| --- | --- | --- |\n Abstraction implementations | [GitHub Link](./abstraction-implementations/README.md) | Samples containing reference implementations of Microsoft.Extensions.AI.Abstractions |\n| OpenAI | [GitHub Link](./openai/README.md) | Samples showcasing Microsoft.Extensions.AI.OpenAI reference implementation |\n| Azure AI Inference | [GitHub Link](./azure-ai-inference/README.md) | Samples showcasing Microsoft.Extensions.AI.AzureAIInference reference implementation |\n| Ollama | [GitHub Link](./ollama/README.md) | Samples showcasing Microsoft.Extensions.AI.Ollama reference implementation |\n```\n\n----------------------------------------\n\nTITLE: Exporting Evaluation Results to JSON in C#\nDESCRIPTION: Shows how to export evaluation results to JSON format, save them to a file, and display them in the console using the LLMEval.Outputs library.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/README.md#2025-04-21_snippet_8\n\nLANGUAGE: csharp\nCODE:\n```\n// convert results to json, save the results and display them in the console\nvar json = LLMEval.Outputs.ExportToJson.CreateJson(results);\nLLMEval.Outputs.ExportToJson.SaveJson(results, \"results.json\");\nSpectreConsoleOutput.DisplayJson(json, \"User Story collection from file\", true);\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI User Secrets\nDESCRIPTION: Demonstrates how to set up and configure user secrets for storing Azure OpenAI service credentials securely using .NET CLI commands\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/README.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndotnet user-secrets init\ndotnet user-secrets set \"AZURE_OPENAI_MODEL\" \"Azure OpenAI Deployment Name\"\ndotnet user-secrets set \"AZURE_OPENAI_ENDPOINT\" \"Azure OpenAI Deployment Endpoint\"\ndotnet user-secrets set \"AZURE_OPENAI_KEY\" \"Azure OpenAI Deployment Key\"\n```\n\n----------------------------------------\n\nTITLE: Creating appsettings.local.json for Configuration - JSON\nDESCRIPTION: This JSON snippet sets up logging levels, allowed hosts, and Azure AI Inference configuration including API key and endpoint details. It is necessary to configure the application for proper operation.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-ai-inference/AzureAIWebAPI/README.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"Logging\":{\"LogLevel\":{\"Default\":\"Information\",\"Microsoft.AspNetCore\":\"Warning\"}},\"AllowedHosts\":\"*\",\"AI\":{\"AzureAIInference\":{\"Key\":\"YOUR-GH-PAT-TOKEN\",\"Chat\":{\"Endpoint\":\"https://models.inference.ai.azure.com\",\"ModelId\":\"gpt-4o-mini\"}}}}\n```\n\n----------------------------------------\n\nTITLE: Initializing ChatHistory in C#\nDESCRIPTION: This snippet initializes a `ChatHistory` object in C#. This object will store the conversation history, allowing the AI to maintain context across multiple turns.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/02 Add Chat History.md#2025-04-21_snippet_2\n\nLANGUAGE: Csharp\nCODE:\n```\nChatHistory chatHistory = [];\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Client and Adding Permission Filter in C#\nDESCRIPTION: Code that configures HTTP client defaults with resilience handling and header redaction, and registers a custom permission filter for function invocation. Includes warning suppression for experimental features.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/06 Modifying Kernel Behavior with Dependency Injection.md#2025-04-21_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nbuilder.Services.ConfigureHttpClientDefaults(b =>\n{\nb.AddStandardResilienceHandler();\nb.RedactLoggedHeaders([\"Authorization\"]);\n});\nbuilder.Services.AddRedaction();\n\n// injecting the permission filter to the kernel.\n#pragma warning disable SKEXP0001,SKEXP0050\nbuilder.Services.AddSingleton<IFunctionInvocationFilter, PermissionFilter>();\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key using .NET User Secrets\nDESCRIPTION: Commands to initialize user secrets and set the OpenAI API key for the application. This allows secure storage of the API key outside of the source code.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/extensions-ai/01-HikeBenefitsSummary/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet user-secrets init\ndotnet user-secrets set OpenAIKey <your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Adding ChatCompletion Service using C#\nDESCRIPTION: This code snippet shows how to retrieve the IChatCompletionService from the Kernel instance in C#. The chat service is essential for interacting with the AI model for generating chat responses.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/02 Add Chat History.md#2025-04-21_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nvar kernel = Kernel.CreateBuilder()\n          .AddOpenAIChatCompletion(openAIChatCompletionModelName, Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\"))\n          .Build();\n\n    var chatService = kernel.GetRequiredService<IChatCompletionService>();\n```\n\n----------------------------------------\n\nTITLE: Generating Multiple QA Pairs\nDESCRIPTION: Shows how to generate a collection of multiple QA pairs using an LLM and serialize the results to JSON for further processing\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/README.md#2025-04-21_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nvar llmGenQAs = await QALLMGenerator.GenerateQACollection(kernelGenData, 3);\n\nvar json = JsonSerializer.Serialize(llmGenQAs, new JsonSerializerOptions\n{\n    WriteIndented = true\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key Using .NET User Secrets\nDESCRIPTION: Commands to initialize user secrets and set the OpenAI API key for the application. These commands store the API key securely in the user secrets configuration.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/01-HikeBenefitsSummary/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet user-secrets init\ndotnet user-secrets set OpenAIKey <your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Installing Semantic Kernel NuGet Package\nDESCRIPTION: Command to add Microsoft.SemanticKernel package to the project dependencies\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/01 Hello Semantic Kernel.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.SemanticKernel\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key for .NET User Secrets\nDESCRIPTION: These commands initialize user secrets for the project and set the OpenAI API key. This step is crucial for authenticating requests to the OpenAI service.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/04-HikerAIPro/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet user-secrets init\ndotnet user-secrets set OpenAIKey <your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI settings in appsettings.local.json\nDESCRIPTION: This JSON snippet shows how to configure the Azure OpenAI endpoint and model IDs for chat and embedding within the appsettings.local.json file. It is required to set the Endpoint to your Azure OpenAI API endpoint and ModelIds to appropriate model names.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-openai/AzureOpenAIWebAPI/README.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Logging\": {\n        \"LogLevel\": {\n            \"Default\": \"Information\",\n            \"Microsoft.AspNetCore\": \"Warning\"\n        }\n    },\n    \"AllowedHosts\": \"*\",\n    \"AI\": {\n        \"AzureOpenAI\": {\n            \"Endpoint\": \"YOUR-AZURE-OPENAI-ENDPOINT\",\n            \"Chat\": {\n                \"ModelId\": \"gpt-4o-mini\"\n            },\n            \"Embedding\": {\n                \"ModelId\": \"text-embedding-3-small\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing SemanticKernel.Plugins.Web Package in .NET\nDESCRIPTION: This command installs the Microsoft.SemanticKernel.Plugins.Web package, which is required for using the Bing Search plugin in a Semantic Kernel project.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/05 Add Plugin (Bing Search).md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.SemanticKernel.Plugins.Web --prerelease\n```\n\n----------------------------------------\n\nTITLE: Adding ChatCompletion using statement in C#\nDESCRIPTION: This snippet adds the `Microsoft.SemanticKernel.ChatCompletion` namespace to the `Program.cs` file. This is necessary to use chat completion functionalities provided by Semantic Kernel.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/02 Add Chat History.md#2025-04-21_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.SemanticKernel.ChatCompletion;\n```\n\n----------------------------------------\n\nTITLE: Installing Phi-3 Model using Ollama\nDESCRIPTION: Command to install and run the Phi-3 model using Ollama on a local machine.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/local-models/phi3-llama3/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nollama run phi3\n```\n\n----------------------------------------\n\nTITLE: Adding Required Namespaces for Logging in C#\nDESCRIPTION: C# using statements to import the Microsoft.Extensions.DependencyInjection and Microsoft.Extensions.Logging namespaces required for setting up logging functionality.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/04 Add Logging.md#2025-04-21_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Logging;\n```\n\n----------------------------------------\n\nTITLE: Generating Question and Answer Data in JavaScript\nDESCRIPTION: This snippet creates a set of question and answer data based on a provided topic or selects a random topic from a list. The output is structured as a JSON object containing fields for the question, answer, and topic. If no topic is provided, the topic field is left empty.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/QAGenerator/_prompts/qagen/skprompt.txt#2025-04-21_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nCreate a question and answer set of data.\nIf a topic is provided, use the topic. \n\n[Topic]\n{{$topic}}\n[End Topic]\n\nOtherwise, choose a random topic from the following list:\n[Topic List]\n- Math\n- Science\n- History\n- Geography\n- Literature\n- Art\n- Music\n- Sports\n[End Topic List]\n\nReturn the results in json format with the fields question, answer and topic. \nAll these fields in the json object are of type string. \nIf there is no value for the topic, the topic field should be an empty string.\nDo not return anything besides the json, no comments, no format, no markdown, just the json object. \nThe JSON must be a valid JSON format.\nFor example: { question: \"2 + 2\", answer: \"4\", topic: \"Math\" }\n```\n\n----------------------------------------\n\nTITLE: PowerShell command for Chat API call\nDESCRIPTION: This PowerShell command calls the Web API's /chat endpoint to get a chat completion response. It sends a JSON payload containing the user's query \"What is AI?\" and extracts the text content from the response.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-openai/AzureOpenAIWebAPI/README.md#2025-04-21_snippet_2\n\nLANGUAGE: powershell\nCODE:\n```\n$response = Invoke-RestMethod -Uri 'http://localhost:5208/chat' -Method Post -Headers @{'Content-Type'='application/json'} -Body '\"What is AI?\"'; $response.message.contents.text\n```\n\n----------------------------------------\n\nTITLE: Adding HTTP Extensions Namespace in C#\nDESCRIPTION: Adding the Microsoft.Extensions.Http namespace to the Program.cs file to enable HTTP client configuration.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/06 Modifying Kernel Behavior with Dependency Injection.md#2025-04-21_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.Extensions.Http;\n```\n\n----------------------------------------\n\nTITLE: Importing OpenAI Connector Namespace in C#\nDESCRIPTION: Adds the required namespace for OpenAI connector functionality in the Semantic Kernel.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/03 Add Plugin (Function Call).md#2025-04-21_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.SemanticKernel.Connectors.OpenAI;\n```\n\n----------------------------------------\n\nTITLE: User Story JSON Structure Example\nDESCRIPTION: An example of the expected JSON format for returning a user story, containing title, description, and acceptance criteria fields.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/UserStoryGenerator/_prompts/userstoryclassic/skprompt.txt#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{ title: \"My summarized title\", description: \"As a <persona>, I want to ...\", acceptanceCriteria: \"1. ...\" }\n```\n\n----------------------------------------\n\nTITLE: Initializing Application Builder\nDESCRIPTION: Setting up the OpenAI model name and creating the web application builder\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nvar openAIChatCompletionModelName = \"gpt-4-turbo\"; // this could be other models like \"gpt-4o\".\nvar builder = WebApplication.CreateBuilder(args);\n```\n\n----------------------------------------\n\nTITLE: Deploying Azure Resources with Azure Developer CLI\nDESCRIPTION: Command to create Azure resources (Azure OpenAI service, gpt-35-turbo and dall-e-3 models) using the Azure Developer CLI.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nazd up\n```\n\n----------------------------------------\n\nTITLE: Installing Ollama Language Model\nDESCRIPTION: Command to download and install the llama3.2 language model using Ollama CLI\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/chat/CustomerSupport/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nollama pull llama3.2\n```\n\n----------------------------------------\n\nTITLE: Importing Plugin to Kernel\nDESCRIPTION: Imports the DemographicInfo class as a plugin into the Semantic Kernel for use in chat completion service.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/03 Add Plugin (Function Call).md#2025-04-21_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nkernel.ImportPluginFromType<DemographicInfo>();\n```\n\n----------------------------------------\n\nTITLE: Restoring aieval Dotnet Tool (Batch)\nDESCRIPTION: Restores the aieval dotnet tool for use in generating and viewing reports. This command should be run from the src/microsoft-extensions-ai-evaluation/api directory.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai-evaluation/api/INSTRUCTIONS.md#2025-04-21_snippet_5\n\nLANGUAGE: batch\nCODE:\n```\ndotnet tool restore\n```\n\n----------------------------------------\n\nTITLE: Running the Chatting About My Previous Hikes Console Application\nDESCRIPTION: Command to execute the .NET console application that uses Azure OpenAI to analyze hiking data. This command should be run from the '03-ChattingAboutMyHikes' directory.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/semantic-kernel/03-ChattingAboutMyHikes/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key using .NET User Secrets\nDESCRIPTION: Commands to initialize user secrets and set the OpenAI API key for the application. These secrets are stored securely and used for authentication with the OpenAI service.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/02-HikerAI/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet user-secrets init\ndotnet user-secrets set OpenAIKey <your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Running .NET Console Application for OpenAI Hike Analysis\nDESCRIPTION: This command runs the .NET console application, which will process the hike data and interact with the OpenAI API to provide analysis and information about previous hikes.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/03-ChattingAboutMyHikes/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Ollama Web API Configuration - JSON\nDESCRIPTION: This JSON snippet demonstrates the configuration settings required for the Ollama Web API. This includes logging levels and the settings for AI models. Save this configuration in *appsettings.local.json*.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/ollama/OllamaWebAPI/README.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Logging\": {\n        \"LogLevel\": {\n            \"Default\": \"Information\",\n            \"Microsoft.AspNetCore\": \"Warning\"\n        }\n    },\n    \"AllowedHosts\": \"*\",\n    \"AI\": {\n        \"Ollama\": {\n            \"Chat\": {\n                \"Endpoint\": \"http://localhost:11434/\",\n                \"ModelId\": \"llama3.1\"\n            },\n            \"Embedding\": {\n                \"Endpoint\": \"http://localhost:11434/\",\n                \"ModelId\": \"all-minilm\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Ollama Models using Bash\nDESCRIPTION: Commands to download the llama3.1 model for chat and all-minilm model for embeddings using Ollama CLI.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/ollama/OllamaExamples/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nollama pull llama3.1 // chat\nollama pull all-minilm // embeddings\n```\n\n----------------------------------------\n\nTITLE: Running the Hiking Benefits Summary Console Application\nDESCRIPTION: This command runs the .NET console application that summarizes the content of 'benefits.md' using Azure OpenAI Service.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/semantic-kernel/01-HikeBenefitsSummary/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Creating New WebApp Project\nDESCRIPTION: Command to create a new .NET web application project named HelloBuildMinimalWebAp\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndotnet new webapp -n HelloBuildMinimalWebAp\n```\n\n----------------------------------------\n\nTITLE: Running the .NET Console Application\nDESCRIPTION: Command to execute the console application that will process the benefits.md file and generate a summary using OpenAI.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/extensions-ai/01-HikeBenefitsSummary/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Stateless Chat Loop with Semantic Kernel\nDESCRIPTION: Implements a continuous chat loop that reads user input, sends prompts to the OpenAI model, and displays responses without maintaining conversation history\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/01 Hello Semantic Kernel.md#2025-04-21_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nwhile (true)\n{\n    Console.Write(\"Q: \");\n    Console.WriteLine(await kernel.InvokePromptAsync(Console.ReadLine()!));\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Web API application using dotnet run\nDESCRIPTION: This command runs the ASP.NET Core Web API application from the command line using the .NET CLI. It compiles and starts the application, making it accessible at the configured port, typically http://localhost:5208.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-openai/AzureOpenAIWebAPI/README.md#2025-04-21_snippet_1\n\nLANGUAGE: dotnetcli\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running .NET Project with dotnet CLI\nDESCRIPTION: This command runs the OpenAIExamples application using the dotnet CLI from the terminal, allowing users to test the OpenAI integration examples.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/openai/OpenAIExamples/README.md#2025-04-21_snippet_0\n\nLANGUAGE: dotnetcli\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Example Task Input/Output for Answer Evaluation\nDESCRIPTION: JSON-formatted examples demonstrating the evaluation of answers against context passages using a 1-5 scoring system where 5 indicates logical entailment, 1 indicates logical contradiction, and values between indicate uncertainty.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/LLMEval.Test/prompts/groundedness/skprompt.txt#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"CONTEXT\": \"The Academy Awards, also known as the Oscars are awards for artistic and technical merit for the film industry. They are presented annually by the Academy of Motion Picture Arts and Sciences, in recognition of excellence in cinematic achievements as assessed by the Academy's voting membership. The Academy Awards are regarded by many as the most prestigious, significant awards in the entertainment industry in the United States and worldwide.\", \"ANSWER\": \"Oscar is presented every other two years\"}\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"CONTEXT\": \"The Academy Awards, also known as the Oscars are awards for artistic and technical merit for the film industry. They are presented annually by the Academy of Motion Picture Arts and Sciences, in recognition of excellence in cinematic achievements as assessed by the Academy's voting membership. The Academy Awards are regarded by many as the most prestigious, significant awards in the entertainment industry in the United States and worldwide.\", \"ANSWER\": \"Oscar is very important awards in the entertainment industry in the United States. And it's also significant worldwide\"}\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"CONTEXT\": \"In Quebec, an allophone is a resident, usually an immigrant, whose mother tongue or home language is neither French nor English.\", \"ANSWER\": \"In Quebec, an allophone is a resident, usually an immigrant, whose mother tongue or home language is not French.\"}\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"CONTEXT\": \"Some are reported as not having been wanted at all.\", \"ANSWER\": \"All are reported as being completely and fully wanted.\"}\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"CONTEXT\": {{$Context}}, \"ANSWER\": {{$Answer}}}\n```\n\n----------------------------------------\n\nTITLE: Running Sample Application - .NET CLI\nDESCRIPTION: This snippet demonstrates how to run the Azure AI Inference sample application using the .NET command line. It provides instructions for navigating to the project directory and executing the application with the 'dotnet run' command.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-ai-inference/AzureAIInferenceExamples/README.md#2025-04-21_snippet_0\n\nLANGUAGE: dotnetcli\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running QA Evaluation\nDESCRIPTION: Demonstrates how to process and evaluate a single QA pair using custom evaluation metrics, including creating a QA object and running the evaluation\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/README.md#2025-04-21_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nvar qaProcessor = new QACreator.QACreator(kernelTest);\nvar qa = new QA\n{\n    Question = \"two plus two\",\n    Answer = \"'4' or 'four'\",\n    Topic = \"Math\"\n};\n\nvar processResult = await qaProcessor.Process(qa);\nvar results = await batchEval.ProcessSingle(processResult);\nresults.EvalRunName = \"Harcoded QA 1\";\nSpectreConsoleOutput.DisplayResults(results);\n```\n\n----------------------------------------\n\nTITLE: Downloading Models for Ollama Web API - Bash\nDESCRIPTION: This snippet outlines the commands to download the required models using the Ollama tool. Ensure that the Ollama tool is installed and configured properly to execute these commands.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/ollama/OllamaWebAPI/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nollama pull llama3.1 // chat\nollama pull all-minilm // embeddings\n```\n\n----------------------------------------\n\nTITLE: Running a .NET application using dotnet CLI\nDESCRIPTION: Command to run the AbstractionImplementationExamples application using the dotnet CLI from the project directory.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/abstraction-implementations/AbstractionImplementationExamples/README.md#2025-04-21_snippet_0\n\nLANGUAGE: dotnetcli\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Relevance Scoring Rule Definition\nDESCRIPTION: Defines a 5-point rating scale for evaluating how relevant an answer is to a specific question and context\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/LLMEval.Test/prompts/relevance/skprompt.txt#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Relevance Rating Scale\n1 star: Completely irrelevant\n2 stars: Mostly irrelevant\n3 stars: Partially relevant\n4 stars: Mostly relevant\n5 stars: Perfectly relevant\n```\n\n----------------------------------------\n\nTITLE: Logging HTTP Client Factory Cleanup Cycle\nDESCRIPTION: This code snippet shows debug logging for HttpMessageHandler cleanup cycles in the Microsoft.Extensions.Http.DefaultHttpClientFactory. It demonstrates the process of cleaning up expired HttpMessageHandlers and provides timing information for each cycle.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/06 Modifying Kernel Behavior with Dependency Injection.md#2025-04-21_snippet_7\n\nLANGUAGE: log\nCODE:\n```\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[103]\n      HttpMessageHandler expired after 120000ms for client ''\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[100]\n      Starting HttpMessageHandler cleanup cycle with 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[101]\n      Ending HttpMessageHandler cleanup cycle after 0.0639ms - processed: 0 items - remaining: 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[100]\n      Starting HttpMessageHandler cleanup cycle with 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[101]\n      Ending HttpMessageHandler cleanup cycle after 0.0038ms - processed: 0 items - remaining: 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[100]\n      Starting HttpMessageHandler cleanup cycle with 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[101]\n      Ending HttpMessageHandler cleanup cycle after 0.012ms - processed: 0 items - remaining: 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[100]\n      Starting HttpMessageHandler cleanup cycle with 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[101]\n      Ending HttpMessageHandler cleanup cycle after 0.0132ms - processed: 0 items - remaining: 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[100]\n      Starting HttpMessageHandler cleanup cycle with 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[101]\n      Ending HttpMessageHandler cleanup cycle after 0.0051ms - processed: 0 items - remaining: 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[100]\n```\n\n----------------------------------------\n\nTITLE: Running .NET Application in Visual Studio Code\nDESCRIPTION: Command-line instruction for running a .NET application using dotnet run in the project directory\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-openai/AzureOpenAIExamples/README.md#2025-04-21_snippet_0\n\nLANGUAGE: dotnetcli\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Displaying PowerShell Version Check Command\nDESCRIPTION: This code snippet shows the command to check the PowerShell version on Windows, which is a prerequisite for running the samples.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```\npwsh\n```\n```\n\n----------------------------------------\n\nTITLE: Installing aieval Dotnet Tool in Repository (Batch)\nDESCRIPTION: Installs the aieval dotnet tool in a repository for production use. Requires specifying the version of the Microsoft.Extensions.AI.Evaluation NuGet package being used.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai-evaluation/api/INSTRUCTIONS.md#2025-04-21_snippet_7\n\nLANGUAGE: batch\nCODE:\n```\ndotnet tool install Microsoft.Extensions.AI.Evaluation.Console --version <VERSION> --create-manifest-if-needed\n```\n\n----------------------------------------\n\nTITLE: Evaluation Metric Implementation\nDESCRIPTION: Pseudocode demonstrating the logic for computing relevance based on context, question, and answer alignment\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/LLMEval.Test/prompts/relevance/skprompt.txt#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef evaluate_relevance(context, question, answer):\n    # Compare answer against context and question\n    # Return integer score between 1-5\n    relevance_score = compute_relevance_score()\n    return min(max(relevance_score, 1), 5)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key in .NET Console Application\nDESCRIPTION: These commands initialize user secrets for the project and set the OpenAI API key. This allows secure storage of the API key for use in the application.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/03-ChattingAboutMyHikes/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet user-secrets init\ndotnet user-secrets set OpenAIKey <your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Viewing Ollama Service Journal\nDESCRIPTION: Command to view the Ollama service journal in real-time for monitoring and debugging purposes.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/local-models/phi3-llama3/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\njournalctl -u ollama -f\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests and Generating Reports - C#\nDESCRIPTION: This snippet explains how to run unit tests from the command line as well as within Visual Studio or Visual Studio Code, and highlights the importance of running all tests in a single execution to properly generate and display evaluation reports.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai-evaluation/api/INSTRUCTIONS.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndotnet test from under src\\microsoft-extensions-ai-evaluation\\api\n```\n\n----------------------------------------\n\nTITLE: Creating .NET Console Application\nDESCRIPTION: Command to generate a new .NET console application project using dotnet CLI\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/01 Hello Semantic Kernel.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndotnet new console -n HelloBuild\n```\n\n----------------------------------------\n\nTITLE: Chat using Azure AI Inference - PowerShell\nDESCRIPTION: This PowerShell snippet sends a POST request to the local API endpoint to initiate a chat query with the question 'What is AI?'. The response is captured and the text content of the message is extracted.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-ai-inference/AzureAIWebAPI/README.md#2025-04-21_snippet_2\n\nLANGUAGE: powershell\nCODE:\n```\n$response = Invoke-RestMethod -Uri 'http://localhost:5093/chat' -Method Post -Headers @{'Content-Type'='application/json'} -Body '\"What is AI?\"'; $response.message.contents.text\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Chat Completion Model Name\nDESCRIPTION: Defines the OpenAI language model to be used for chat completions, with support for different models like GPT-3.5-turbo and GPT-4o\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/01 Hello Semantic Kernel.md#2025-04-21_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nstring openAIChatCompletionModelName = \"gpt-3.5-turbo\";\n```\n\n----------------------------------------\n\nTITLE: Installing Redaction Package with .NET CLI\nDESCRIPTION: Command to add the Microsoft.Extensions.Compliance.Redaction NuGet package to the project for handling sensitive data redaction.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/06 Modifying Kernel Behavior with Dependency Injection.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.Extensions.Compliance.Redaction\n```\n\n----------------------------------------\n\nTITLE: Installing Extensions.Http Package with .NET CLI\nDESCRIPTION: Command to add the Microsoft.Extensions.Http NuGet package to the project for HTTP client configuration.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/06 Modifying Kernel Behavior with Dependency Injection.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.Extensions.Http\n```\n\n----------------------------------------\n\nTITLE: PowerShell command for Embeddings API call\nDESCRIPTION: This PowerShell command calls the Web API's /embedding endpoint to get the embedding vector for the text \"What is AI?\". It sends the text as a JSON payload and extracts the vector from the response.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-openai/AzureOpenAIWebAPI/README.md#2025-04-21_snippet_3\n\nLANGUAGE: powershell\nCODE:\n```\n$response = Invoke-RestMethod -Uri 'http://localhost:5208/embedding' -Method Post -Headers @{'Content-Type'='application/json'} -Body '\"What is AI?\"'; $response.vector\n```\n\n----------------------------------------\n\nTITLE: Sample Logging Output from Semantic Kernel Application\nDESCRIPTION: Console output showing the trace and information level logs produced by the Semantic Kernel when processing a prompt, including details about chat history, model settings, and token usage.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/04 Add Logging.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nQ: Hello\ntrce: Microsoft.SemanticKernel.Connectors.OpenAI.OpenAIChatCompletionService[0]\n      ChatHistory: [{\"Role\":{\"Label\":\"user\"},\"Items\":[{\"$type\":\"TextContent\",\"Text\":\"Hello\"}]}], Settings: {\"temperature\":1,\"top_p\":1,\"presence_penalty\":0,\"frequency_penalty\":0,\"max_tokens\":null,\"stop_sequences\":null,\"results_per_prompt\":1,\"seed\":null,\"response_format\":null,\"chat_system_prompt\":null,\"token_selection_biases\":null,\"ToolCallBehavior\":null,\"User\":null,\"logprobs\":null,\"top_logprobs\":null,\"model_id\":null}\ninfo: Microsoft.SemanticKernel.Connectors.OpenAI.OpenAIChatCompletionService[0]\n      Prompt tokens: 8. Completion tokens: 9. Total tokens: 17.\nHello! How can I help you today?\nQ:\n```\n\n----------------------------------------\n\nTITLE: Installing Swashbuckle Package\nDESCRIPTION: Command to add the Swashbuckle.AspNetCore NuGet package for Swagger support\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Swashbuckle.AspNetCore\n```\n\n----------------------------------------\n\nTITLE: Testing Chat Endpoint - PowerShell\nDESCRIPTION: This PowerShell snippet tests the chat endpoint of the Ollama Web API by sending a POST request with a sample query. Ensure the server is running to get a valid response.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/ollama/OllamaWebAPI/README.md#2025-04-21_snippet_3\n\nLANGUAGE: powershell\nCODE:\n```\n$response = Invoke-RestMethod -Uri 'http://localhost:5078/chat' -Method Post -Headers @{'Content-Type'='application/json'} -Body '\"What is AI?\"'; $response.message.contents.text\n```\n\n----------------------------------------\n\nTITLE: Running the HikerAI Pro Console Application\nDESCRIPTION: This command executes the .NET console application. It starts the HikerAI Pro program, which will interact with the OpenAI API to generate hiking recommendations.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/04-HikerAIPro/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running the .NET console application\nDESCRIPTION: This command executes the .NET console application responsible for reading the `benefits.md` file, sending it to the Azure OpenAI service for summarization, and displaying the summary.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/azure-openai-sdk/01-HikeBenefitsSummary/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n```bash\ndotnet run\n```\n```\n\n----------------------------------------\n\nTITLE: Testing Embedding Endpoint - PowerShell\nDESCRIPTION: This PowerShell snippet tests the embedding endpoint of the Ollama Web API by sending a POST request. Ensure the server is active and set up correctly to receive and process the request.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/ollama/OllamaWebAPI/README.md#2025-04-21_snippet_4\n\nLANGUAGE: powershell\nCODE:\n```\n$response = Invoke-RestMethod -Uri 'http://localhost:5078/embedding' -Method Post -Headers @{'Content-Type'='application/json'} -Body '\"What is AI?\"'; $response.vector\n```\n\n----------------------------------------\n\nTITLE: Running .NET Console Application\nDESCRIPTION: Command to execute the .NET console application that processes the benefits.md file and generates a summary using Azure OpenAI\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/extensions-ai/01-HikeBenefitsSummary/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Executing .NET Console Application\nDESCRIPTION: This bash command runs the .NET 8.0 console application for HikerAI Pro, which sends requests to Azure OpenAI Service. The user must wait a few minutes if the OpenAI model is not yet available. Prerequisites include having .NET 8.0 installed and Azure OpenAI Service deployed.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/azure-openai-sdk/04-HikerAIPro/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Adding Required Using Statements in C#\nDESCRIPTION: These using statements import the necessary namespaces for working with OpenAI connectors, web plugins, and the Bing search engine in a Semantic Kernel project.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/05 Add Plugin (Bing Search).md#2025-04-21_snippet_1\n\nLANGUAGE: Csharp\nCODE:\n```\nusing Microsoft.SemanticKernel.Connectors.OpenAI;\nusing Microsoft.SemanticKernel.Plugins.Web;\nusing Microsoft.SemanticKernel.Plugins.Web.Bing;\n```\n\n----------------------------------------\n\nTITLE: Running the .NET Console Application\nDESCRIPTION: This snippet demonstrates how to run the .NET console application from the terminal. It is used to invoke the Azure OpenAI service to generate images based on a prompt. Ensure your Azure resources are properly deployed before executing this command.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/azure-openai-sdk/05-HikeImages/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Formatting JSON Responses\nDESCRIPTION: This snippet demonstrates how to structure a JSON response based on a given template. The output must have specified fields like 'question', 'answer', and 'topic', all of which are strings. The key challenge is ensuring the JSON format is strictly adhered to without additional text.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/llm-eval/QAGenerator/_prompts/qa/skprompt.txt#2025-04-21_snippet_0\n\nLANGUAGE: String Processing\nCODE:\n```\n{ question: \\\"\\\", answer: \\\"4\\\", topic: \\\"Math\\\"}\n```\n\n----------------------------------------\n\nTITLE: Prerequisites Table in Markdown\nDESCRIPTION: A markdown table listing the available example projects and their descriptions, including console application examples and a Web API implementation.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-ai-inference/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Example | Description |\n| --- | --- |\n| [AzureAIInferenceExamples](./AzureAIInferenceExamples/README.md) | A console application containing a set of samples that shows how to use the Azure AI Inference reference implementation in the Microsoft.Extensions.AI.AzureAIInference NuGet package. |\n| [AzureAIInferenceWebAPI](./AzureAIWebAPI/README.md) | A minimal Web API application that shows how to use the Azure AI Inference reference implementation in the Microsoft.Extensions.AI.AzureAIInference NuGet package. |\n```\n\n----------------------------------------\n\nTITLE: Application Runtime Output\nDESCRIPTION: Console output showing the application startup information\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nBuilding...\ninfo: Microsoft.Hosting.Lifetime[14]\n      Now listening on: http://localhost:<your port>\ninfo: Microsoft.Hosting.Lifetime[0]\n      Application started. Press Ctrl+C to shut down.\ninfo: Microsoft.Hosting.Lifetime[0]\n      Hosting environment: Development\ninfo: Microsoft.Hosting.Lifetime[0]\n      Content root path:<your path>\n```\n\n----------------------------------------\n\nTITLE: Sample Weather Forecast Response\nDESCRIPTION: Example JSON response from the weather forecast endpoint\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"date\": \"2024-06-17\",\n    \"tempratureC\": 4,\n    \"summary\": \"At 4 degrees Celsius, the weather is cool and slightly chilly. It is above freezing, so there is no ice, but it's cold enough that you might want a jacket or sweater when outdoors. This temperature is typical for late autumn or early spring in temperate regions.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Llama 3 Model using Ollama\nDESCRIPTION: Command to install and run the Llama 3 model using Ollama on a local machine.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/local-models/phi3-llama3/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nollama run llama3\n```\n\n----------------------------------------\n\nTITLE: Bypassing PowerShell Execution Policy\nDESCRIPTION: Command to bypass PowerShell execution policy for the current process, allowing the postprovision script to run on Windows systems.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/README.md#2025-04-21_snippet_2\n\nLANGUAGE: powershell\nCODE:\n```\nSet-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass\n```\n\n----------------------------------------\n\nTITLE: Viewing HttpMessageHandler Cleanup Cycle Debug Logs\nDESCRIPTION: Debug logs showing the cleanup cycle pattern for HttpMessageHandler instances managed by DefaultHttpClientFactory. The logs show multiple cleanup cycles each containing 1 item, with each cycle completing quickly (around 0.004ms) but not processing any items.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/06 Modifying Kernel Behavior with Dependency Injection.md#2025-04-21_snippet_8\n\nLANGUAGE: log\nCODE:\n```\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[100]\n            Starting HttpMessageHandler cleanup cycle with 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[101]\n            Ending HttpMessageHandler cleanup cycle after 0.004ms - processed: 0 items - remaining: 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[100]\n            Starting HttpMessageHandler cleanup cycle with 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[101]\n            Ending HttpMessageHandler cleanup cycle after 0.0045ms - processed: 0 items - remaining: 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[100]\n            Starting HttpMessageHandler cleanup cycle with 1 items\ndbug: Microsoft.Extensions.Http.DefaultHttpClientFactory[101]\n            Ending HttpMessageHandler cleanup cycle after 0.0036ms - processed: 0 items - remaining: 1 items\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Azure Storage Examples (Batch)\nDESCRIPTION: Sets environment variables needed to configure examples for using Azure storage providers. These variables specify the Azure storage account endpoint and container name for storing evaluation results and cached LLM responses.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai-evaluation/api/INSTRUCTIONS.md#2025-04-21_snippet_4\n\nLANGUAGE: batch\nCODE:\n```\nset EVAL_SAMPLE_AZURE_STORAGE_ACCOUNT_ENDPOINT=<The endpoint url of the above Azure storage account>\nset EVAL_SAMPLE_AZURE_STORAGE_CONTAINER=<The name of the above Azure storage container>\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Azure AI Content Safety Evaluation (Batch)\nDESCRIPTION: Sets environment variables required to configure examples for using the Azure AI Content Safety service. These variables include the Azure subscription ID, resource group name, and AI project name.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai-evaluation/api/INSTRUCTIONS.md#2025-04-21_snippet_3\n\nLANGUAGE: batch\nCODE:\n```\nset EVAL_SAMPLE_AZURE_SUBSCRIPTION_ID=<The ID of the above Azure subscription>\nset EVAL_SAMPLE_AZURE_RESOURCE_GROUP=<The name of the above Azure resource group>\nset EVAL_SAMPLE_AZURE_AI_PROJECT=<The name of the above Azure AI project>\n```\n\n----------------------------------------\n\nTITLE: Adding Semantic Kernel Namespace\nDESCRIPTION: Adding the required using statement for Semantic Kernel functionality\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.SemanticKernel;\n```\n\n----------------------------------------\n\nTITLE: Installing Semantic Kernel Package\nDESCRIPTION: Command to add the Microsoft.SemanticKernel NuGet package to the project\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/07 Using Semantic Kernel in WebApp.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.SemanticKernel\n```\n\n----------------------------------------\n\nTITLE: Installing Microsoft Extensions Logging Package with .NET CLI\nDESCRIPTION: Command to add the Microsoft.Extensions.Logging NuGet package to the project using the dotnet CLI.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/04 Add Logging.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.Extensions.Logging\n```\n\n----------------------------------------\n\nTITLE: Installing Microsoft Extensions Logging Console Package with .NET CLI\nDESCRIPTION: Command to add the Microsoft.Extensions.Logging.Console NuGet package to the project using the dotnet CLI.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/04 Add Logging.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.Extensions.Logging.Console\n```\n\n----------------------------------------\n\nTITLE: Displaying Hiking Trail Information in Markdown Table\nDESCRIPTION: This markdown table presents data about various hiking trails. It includes columns for trail name, hike date, country, and weather conditions. The table provides a structured view of hiking experiences across different locations and times.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/03-ChattingAboutMyHikes/hikes.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Trail Name      | Hike Date  | Country  | Weather \n| --------------- | ---------- | -------- | --------\n| Cascade Falls   | 2021-07-15 | Canada   | Sunny   \n| Johnston Canyon | 2022-05-10 | Canada   | Cloudy  \n| Lake Louise     | 2020-09-05 | Canada   | Rainy   \n| Angel's Landing | 2023-06-20 | USA      | Sunny   \n| Gros Morne      | 2021-08-25 | Canada   | Foggy   \n| Hocking Hills   | 2022-04-01 | USA      | Sunny   \n| The Chief       | 2020-07-05 | Canada   | Sunny   \n| Skaftafell      | 2022-09-10 | Iceland  | Cloudy\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI API Key with .NET User Secrets\nDESCRIPTION: Commands to initialize user secrets and set the OpenAI API key for the application. These commands must be run from the 05-HikeImages directory to configure the application's authentication with OpenAI services.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/05-HikeImages/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet user-secrets init\ndotnet user-secrets set OpenAIKey <your-openai-key>\n```\n\n----------------------------------------\n\nTITLE: Creating Markdown Table of Hiking Trails\nDESCRIPTION: This markdown table presents a list of hiking trails with their names, dates hiked, countries, and weather conditions. It includes trails from Canada, USA, and Iceland, providing a quick overview of various hiking experiences.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/azure-openai-sdk/03-ChattingAboutMyHikes/hikes.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Trail Name      | Hike Date  | Country  | Weather \n| --------------- | ---------- | -------- | --------\n| Cascade Falls   | 2021-07-15 | Canada   | Sunny   \n| Johnston Canyon | 2022-05-10 | Canada   | Cloudy  \n| Lake Louise     | 2020-09-05 | Canada   | Rainy   \n| Angel's Landing | 2023-06-20 | USA      | Sunny   \n| Gros Morne      | 2021-08-25 | Canada   | Foggy   \n| Hocking Hills   | 2022-04-01 | USA      | Sunny   \n| The Chief       | 2020-07-05 | Canada   | Sunny   \n| Skaftafell      | 2022-09-10 | Iceland  | Cloudy\n```\n\n----------------------------------------\n\nTITLE: Creating Markdown Table for Hiking Trail Data\nDESCRIPTION: This markdown table displays information about various hiking trails, including their names, dates hiked, countries, and weather conditions. The table is formatted with headers and aligned columns for easy readability.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/semantic-kernel/03-ChattingAboutMyHikes/hikes.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Trail Name      | Hike Date  | Country  | Weather \n| --------------- | ---------- | -------- | --------\n| Cascade Falls   | 2021-07-15 | Canada   | Sunny   \n| Johnston Canyon | 2022-05-10 | Canada   | Cloudy  \n| Lake Louise     | 2020-09-05 | Canada   | Rainy   \n| Angel's Landing | 2023-06-20 | USA      | Sunny   \n| Gros Morne      | 2021-08-25 | Canada   | Foggy   \n| Hocking Hills   | 2022-04-01 | USA      | Sunny   \n| The Chief       | 2020-07-05 | Canada   | Sunny   \n| Skaftafell      | 2022-09-10 | Iceland  | Cloudy\n```\n\n----------------------------------------\n\nTITLE: Running the .NET Console Application\nDESCRIPTION: Command to execute the console application that generates hiking images using DALL-E 3.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/05-HikeImages/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running the .NET Console Application\nDESCRIPTION: Command to execute the .NET console application from the 05-HikeImages directory to generate images using Azure OpenAI.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/semantic-kernel/05-HikeImages/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running the .NET Console Application\nDESCRIPTION: This command navigates to the `04-HikerAIPro` directory and executes the .NET console application. The application interacts with the Azure OpenAI service to get hiking recommendations based on AI-assessed weather conditions. Requires .NET 8.0 runtime.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/semantic-kernel/04-HikerAIPro/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running the HikerAI Console Application\nDESCRIPTION: Command to execute the .NET console application that will interact with the OpenAI service to get hiking recommendations.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/02-HikerAI/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for Azure OpenAI - C#\nDESCRIPTION: This snippet provides the commands to set environment variables required for configuring the Azure OpenAI endpoint, including the endpoint URL, model name, and storage path. These are prerequisites for running evaluation examples.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai-evaluation/api/INSTRUCTIONS.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSET EVAL_SAMPLE_AZURE_OPENAI_ENDPOINT=https://<your-endpoint>.openai.azure.com/\nSET EVAL_SAMPLE_AZURE_OPENAI_MODEL=<model-deployment-name>\nSET EVAL_SAMPLE_STORAGE_ROOT_PATH=<full path to a directory under which the examples can store evaluation data>\n```\n\n----------------------------------------\n\nTITLE: Running HikerAI Console Application\nDESCRIPTION: Command to execute the .NET console application from the 02-HikerAI directory. This runs the hiking recommendation AI application that connects to Azure OpenAI Service.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/semantic-kernel/02-HikerAI/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running HikerAI Console Application\nDESCRIPTION: Command to execute the .NET console application from the 02-HikerAI directory. The application connects to Azure OpenAI Service to generate hiking recommendations.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/azure-openai-sdk/02-HikerAI/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Generating Report with aieval Dotnet Tool (Batch)\nDESCRIPTION: Generates an HTML report using the aieval dotnet tool. Requires specifying the storage root path for evaluation results and the output path for the generated report.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai-evaluation/api/INSTRUCTIONS.md#2025-04-21_snippet_6\n\nLANGUAGE: batch\nCODE:\n```\ndotnet aieval report -p <EVAL_SAMPLE_STORAGE_ROOT_PATH> -o <EVAL_SAMPLE_STORAGE_ROOT_PATH>\\report.html\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure Authentication via DefaultAzureCredential - C#\nDESCRIPTION: This snippet outlines the requirement to use DefaultAzureCredential for authenticating with Azure Open AI. It provides links for more information on local development authentication methods.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai-evaluation/api/INSTRUCTIONS.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n[`DefaultAzureCredential`](https://learn.microsoft.com/en-us/dotnet/azure/sdk/authentication/?tabs=command-line#defaultazurecredential)\nto authenticate with Azure Open AI.\n```\n\n----------------------------------------\n\nTITLE: Running .NET Console Application\nDESCRIPTION: This snippet provides the command to execute the .NET console application that interacts with Azure OpenAI service to analyze hiking records. Ensure the Azure OpenAI service is already deployed and configured as per the prerequisites.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/azure-openai-sdk/03-ChattingAboutMyHikes/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running the Application - .NET CLI\nDESCRIPTION: This command initiates the application from the terminal. Make sure to navigate to the *OllamaWebAPI* project directory before executing this command.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/ollama/OllamaWebAPI/README.md#2025-04-21_snippet_2\n\nLANGUAGE: dotnetcli\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Editing the Image Prompt in Program.cs\nDESCRIPTION: This optional step suggests modifying the 'imagePrompt' variable in the Program.cs file to test different prompts for image generation. This allows users to personalize the images produced by the DALL-E 3 model.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/azure-openai-sdk/05-HikeImages/README.md#2025-04-21_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\n// Sample code to edit the image prompt\nstring imagePrompt = \"Your customized prompt here\";\n```\n\n----------------------------------------\n\nTITLE: Running the .NET Console Application\nDESCRIPTION: Command to execute the console application that will process the text file and generate a summary using OpenAI.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/01-HikeBenefitsSummary/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running OllamaExamples Project using .NET CLI\nDESCRIPTION: Command to run the OllamaExamples project using the dotnet CLI in the project directory.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/ollama/OllamaExamples/README.md#2025-04-21_snippet_1\n\nLANGUAGE: dotnetcli\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running Azure AI Inference Web API - .NET CLI\nDESCRIPTION: This command is used to run the Azure AI Inference Web API application from the terminal, enabling the service to be accessed locally for development and testing purposes.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai/azure-ai-inference/AzureAIWebAPI/README.md#2025-04-21_snippet_1\n\nLANGUAGE: dotnetcli\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Restoring aieval Dotnet Tool in Repository (Batch)\nDESCRIPTION: Restores the aieval dotnet tool in a repository where it has been previously installed. This command should be run from the directory where the tool was installed.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/microsoft-extensions-ai-evaluation/api/INSTRUCTIONS.md#2025-04-21_snippet_8\n\nLANGUAGE: batch\nCODE:\n```\ndotnet tool restore\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Azure Resources\nDESCRIPTION: Command to delete Azure resources created using the Azure Developer CLI after experimenting with the samples.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/azure-openai/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nazd down\n```\n\n----------------------------------------\n\nTITLE: Installing PowerShell Using .NET CLI\nDESCRIPTION: This command demonstrates how to update or install PowerShell globally using the .NET CLI, which is necessary if the required version is not present.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/quickstarts/openai/semantic-kernel/README.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```\ndotnet tool update --global PowerShell\n```\n```\n\n----------------------------------------\n\nTITLE: Installing HTTP Resilience Package with .NET CLI\nDESCRIPTION: Command to add the Microsoft.Extensions.Http.Resilience NuGet package to the project for implementing resilient HTTP requests.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/06 Modifying Kernel Behavior with Dependency Injection.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.Extensions.Http.Resilience\n```\n\n----------------------------------------\n\nTITLE: Installing Ollama Embedding Model\nDESCRIPTION: Command to download and install the all-minilm embedding model using Ollama CLI\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/chat/CustomerSupport/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nollama pull all-minilm\n```\n\n----------------------------------------\n\nTITLE: Linking to External Documentation in Markdown\nDESCRIPTION: This snippet demonstrates how to create a hyperlink in Markdown to external documentation. It uses relative path referencing to point to a specific exercise document within the project structure.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/03 - Add Plugin (Function Call)/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\nA complete documentation for this project is [here](../docs/Exercise/03%20Add%20Plugin%20(Function%20Call).md)\n```\n\n----------------------------------------\n\nTITLE: Example Chat Interaction in Console\nDESCRIPTION: This console output illustrates how the application remembers previous interactions.  The AI remembers the user's name and provides contextually relevant responses in subsequent turns.\nSOURCE: https://github.com/dotnet/ai-samples/blob/main/src/build-2024/docs/Exercise/02 Add Chat History.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nQ: Hi my name is Alice\n    Hello Alice! Nice to meet you. How can I assist you today?\n    Q: What is my name?\n    Your name is Alice.\n    Q:\n```"
  }
]