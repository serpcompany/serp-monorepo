[
  {
    "owner": "togethercomputer",
    "repo": "together-python",
    "content": "TITLE: Using Chat Completions API with Text and Multimodal Inputs\nDESCRIPTION: Complete example showing how to use the chat completions API with text-only messages, messages containing images, multiple images, and videos. It demonstrates the multimodal capabilities of various Together API models.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom together import Together\n\nclient = Together()\n\n# Simple text message\nresponse = client.chat.completions.create(\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n    messages=[{\"role\": \"user\", \"content\": \"tell me about new york\"}],\n)\nprint(response.choices[0].message.content)\n\n# Multi-modal message with text and image\nresponse = client.chat.completions.create(\n    model=\"meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo\",\n    messages=[{\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"What's in this image?\"\n            },\n            {\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": \"https://huggingface.co/datasets/patrickvonplaten/random_img/resolve/main/yosemite.png\"\n                }\n            }\n        ]\n    }]\n)\nprint(response.choices[0].message.content)\n\n# Multi-modal message with multiple images\nresponse = client.chat.completions.create(\n    model=\"Qwen/Qwen2.5-VL-72B-Instruct\",\n    messages=[{\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"Compare these two images.\"\n            },\n            {\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": \"https://huggingface.co/datasets/patrickvonplaten/random_img/resolve/main/yosemite.png\"\n                }\n            },\n            {\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": \"https://huggingface.co/datasets/patrickvonplaten/random_img/resolve/main/slack.png\"\n                }\n            }\n        ]\n    }]\n)\nprint(response.choices[0].message.content)\n\n# Multi-modal message with text and video\nresponse = client.chat.completions.create(\n    model=\"Qwen/Qwen2.5-VL-72B-Instruct\",\n    messages=[{\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"What's happening in this video?\"\n            },\n            {\n                \"type\": \"video_url\",\n                \"video_url\": {\n                    \"url\": \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerFun.mp4\"\n                }\n            }\n        ]\n    }]\n)\nprint(response.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Creating and Managing Fine-tuning Jobs with Together Python Client\nDESCRIPTION: Shows how to create and manage fine-tuning jobs using the Together client. This includes creating a job with specific parameters, listing jobs, retrieving information, canceling jobs, and downloading fine-tuned models.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom together import Together\n\nclient = Together()\n\nclient.fine_tuning.create(\n  training_file = 'file-d0d318cb-b7d9-493a-bd70-1cfe089d3815',\n  model = 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n  n_epochs = 3,\n  n_checkpoints = 1,\n  batch_size = \"max\",\n  learning_rate = 1e-5,\n  suffix = 'my-demo-finetune',\n  wandb_api_key = '1a2b3c4d5e.......',\n)\nclient.fine_tuning.list() # lists all fine-tuned jobs\nclient.fine_tuning.retrieve(id=\"ft-c66a5c18-1d6d-43c9-94bd-32d756425b4b\") # retrieves information on finetune event\nclient.fine_tuning.cancel(id=\"ft-c66a5c18-1d6d-43c9-94bd-32d756425b4b\") # Cancels a fine-tuning job\nclient.fine_tuning.list_events(id=\"ft-c66a5c18-1d6d-43c9-94bd-32d756425b4b\") #  Lists events of a fine-tune job\nclient.fine_tuning.download(id=\"ft-c66a5c18-1d6d-43c9-94bd-32d756425b4b\") # downloads compressed fine-tuned model or checkpoint to local disk\n```\n\n----------------------------------------\n\nTITLE: Using Completions API for Code Generation\nDESCRIPTION: Example demonstrating how to use the completions API specifically for code generation with the CodeLlama model. This endpoint is appropriate for non-chat, completion-style models.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom together import Together\n\nclient = Together()\n\nresponse = client.completions.create(\n    model=\"codellama/CodeLlama-34b-Python-hf\",\n    prompt=\"Write a Next.js component with TailwindCSS for a header component.\",\n    max_tokens=200,\n)\nprint(response.choices[0].text)\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Chat Completions with Together API\nDESCRIPTION: Example demonstrating how to use the asynchronous client for chat completions, allowing multiple requests to be processed concurrently using Python's asyncio. This is useful for high-throughput applications.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom together import AsyncTogether\n\nasync_client = AsyncTogether()\nmessages = [\n    \"What are the top things to do in San Francisco?\",\n    \"What country is Paris in?\",\n]\n\nasync def async_chat_completion(messages):\n    async_client = AsyncTogether()\n    tasks = [\n        async_client.chat.completions.create(\n            model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n            messages=[{\"role\": \"user\", \"content\": message}],\n        )\n        for message in messages\n    ]\n    responses = await asyncio.gather(*tasks)\n\n    for response in responses:\n        print(response.choices[0].message.content)\n\nasyncio.run(async_chat_completion(messages))\n```\n\n----------------------------------------\n\nTITLE: Creating Text Embeddings with Together API\nDESCRIPTION: Example demonstrating how to use the embeddings API to convert text inputs into vector representations. These embeddings can be used for semantic search, clustering, and other NLP tasks.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nfrom together import Together\n\nclient = Together()\n\ndef get_embeddings(texts: List[str], model: str) -> List[List[float]]:\n    texts = [text.replace(\"\\n\", \" \") for text in texts]\n    outputs = client.embeddings.create(model=model, input = texts)\n    return [outputs.data[i].embedding for i in range(len(texts))]\n\ninput_texts = ['Our solar system orbits the Milky Way galaxy at about 515,000 mph']\nembeddings = get_embeddings(input_texts, model='togethercomputer/m2-bert-80M-8k-retrieval')\n\nprint(embeddings)\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Completions with Together API\nDESCRIPTION: Example showing how to use the streaming feature of the chat completions API to receive responses incrementally in real-time, which is useful for implementing typewriter-like effects in user interfaces.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom together import Together\n\nclient = Together()\nstream = client.chat.completions.create(\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n    messages=[{\"role\": \"user\", \"content\": \"tell me about new york\"}],\n    stream=True,\n)\n\nfor chunk in stream:\n    print(chunk.choices[0].delta.content or \"\", end=\"\", flush=True)\n```\n\n----------------------------------------\n\nTITLE: Streaming Completions with Together API\nDESCRIPTION: Example showing how to use the streaming feature of the completions API with code generation models. This allows for receiving generated code incrementally in real-time.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom together import Together\n\nclient = Together()\nstream = client.completions.create(\n    model=\"codellama/CodeLlama-34b-Python-hf\",\n    prompt=\"Write a Next.js component with TailwindCSS for a header component.\",\n    stream=True,\n)\n\nfor chunk in stream:\n    print(chunk.choices[0].delta.content or \"\", end=\"\", flush=True)\n```\n\n----------------------------------------\n\nTITLE: Reranking Documents with Together API\nDESCRIPTION: Example showing how to use the reranking API to sort a list of documents based on their relevance to a query. This is useful for improving search results by prioritizing the most relevant documents.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nfrom together import Together\n\nclient = Together()\n\ndef get_reranked_documents(query: str, documents: List[str], model: str, top_n: int = 3) -> List[str]:\n    outputs = client.rerank.create(model=model, query=query, documents=documents, top_n=top_n)\n    # sort by relevance score and returns the original docs\n    return [documents[i] for i in [x.index for x in sorted(outputs.results, key=lambda x: x.relevance_score, reverse=True)]]\n\nquery = \"What is the capital of the United States?\"\ndocuments = [\"New York\",\"Washington, D.C.\", \"Los Angeles\"]\n\nreranked_documents = get_reranked_documents(query, documents, model='Salesforce/Llama-Rank-V1', top_n=1)\n\nprint(reranked_documents)\n```\n\n----------------------------------------\n\nTITLE: Generating Images with Together API\nDESCRIPTION: Example showing how to use the image generation API with the Stable Diffusion XL model. This allows for creating images based on text prompts with specified parameters like steps and number of images.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom together import Together\n\nclient = Together()\n\nresponse = client.images.generate(\n    prompt=\"space robots\",\n    model=\"stabilityai/stable-diffusion-xl-base-1.0\",\n    steps=10,\n    n=4,\n)\nprint(response.data[0].b64_json)\n```\n\n----------------------------------------\n\nTITLE: Managing Fine-tuning via Together CLI\nDESCRIPTION: Shows how to create and manage fine-tuning jobs using the Together CLI. This includes creating jobs, listing existing jobs, retrieving details, monitoring events, canceling jobs, and downloading model weights.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n# Help\ntogether fine-tuning --help\n\n# Create fine-tune job\ntogether fine-tuning create \\\n  --model togethercomputer/llama-2-7b-chat \\\n  --training-file file-711d8724-b3e3-4ae2-b516-94841958117d\n\n# List fine-tune jobs\ntogether fine-tuning list\n\n# Retrieve fine-tune job details\ntogether fine-tuning retrieve ft-c66a5c18-1d6d-43c9-94bd-32d756425b4b\n\n# List fine-tune job events\ntogether fine-tuning list-events ft-c66a5c18-1d6d-43c9-94bd-32d756425b4b\n\n# Cancel running job\ntogether fine-tuning cancel ft-c66a5c18-1d6d-43c9-94bd-32d756425b4b\n\n# Download fine-tuned model weights\ntogether fine-tuning download ft-c66a5c18-1d6d-43c9-94bd-32d756425b4b\n```\n\n----------------------------------------\n\nTITLE: Using Files API with Together Python Client\nDESCRIPTION: Demonstrates how to use the files API for uploading, listing, retrieving, and deleting files for fine-tuning. This API allows management of training data files that can be used in fine-tuning jobs.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom together import Together\n\nclient = Together()\n\nclient.files.upload(file=\"somedata.jsonl\") # uploads a file\nclient.files.list() # lists all uploaded files\nclient.files.retrieve(id=\"file-d0d318cb-b7d9-493a-bd70-1cfe089d3815\") # retrieves a specific file\nclient.files.retrieve_content(id=\"file-d0d318cb-b7d9-493a-bd70-1cfe089d3815\") # retrieves content of a specific file\nclient.files.delete(id=\"file-d0d318cb-b7d9-493a-bd70-1cfe089d3815\") # deletes a file\n```\n\n----------------------------------------\n\nTITLE: Fetching Logprobs with Chat Completions API\nDESCRIPTION: Example showing how to request and process token-level generation probabilities (logprobs) from the chat completions API. Logprobs help estimate the model's confidence in its outputs for quality assessment.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom together import Together\n\nclient = Together()\n\nresponse = client.chat.completions.create(\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n    messages=[{\"role\": \"user\", \"content\": \"tell me about new york\"}],\n    logprobs=1\n)\n\nresponse_lobprobs = response.choices[0].logprobs\n\nprint(dict(zip(response_lobprobs.tokens, response_lobprobs.token_logprobs)))\n# {'New': -2.384e-07, ' York': 0.0, ',': 0.0, ' also': -0.20703125, ' known': -0.20214844, ' as': -8.34465e-07, ... }\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Completions with Together API\nDESCRIPTION: Example demonstrating how to use the asynchronous client for completions API, allowing multiple code generation requests to be processed concurrently using Python's asyncio.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom together import AsyncTogether\n\nasync_client = AsyncTogether()\nprompts = [\n    \"Write a Next.js component with TailwindCSS for a header component.\",\n    \"Write a python function for the fibonacci sequence\",\n]\n\nasync def async_chat_completion(prompts):\n    tasks = [\n        async_client.completions.create(\n            model=\"codellama/CodeLlama-34b-Python-hf\",\n            prompt=prompt,\n        )\n        for prompt in prompts\n    ]\n    responses = await asyncio.gather(*tasks)\n\n    for response in responses:\n        print(response.choices[0].text)\n\nasyncio.run(async_chat_completion(prompts))\n```\n\n----------------------------------------\n\nTITLE: Listing Available Models with Together Python Client\nDESCRIPTION: Demonstrates how to list all the AI models supported by Together's platform. This code retrieves and iterates through the available models.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom together import Together\n\nclient = Together()\n\nmodels = client.models.list()\n\nfor model in models:\n    print(model)\n```\n\n----------------------------------------\n\nTITLE: Installing the Together Python API Client\nDESCRIPTION: Command to install the Together Python API library from PyPI using pip. The library requires Python 3.10+ and has been completely rewritten in v1.0.0 (April 2024).\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install --upgrade together\n```\n\n----------------------------------------\n\nTITLE: Initializing Together API Client with API Key\nDESCRIPTION: Code snippet demonstrating how to initialize the Together API client by providing the API key directly in the constructor rather than using an environment variable.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom together import Together\n\nclient = Together(api_key=\"xxxxx\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Key via Environment Variable\nDESCRIPTION: Command to set the Together API key as an environment variable for authentication. Users need to create an account with Together.ai to obtain an API key from the settings page.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport TOGETHER_API_KEY=xxxxx\n```\n\n----------------------------------------\n\nTITLE: Using Chat Completions via Together CLI\nDESCRIPTION: Shows how to use the Together CLI for chat completions. This command sends a system and user message to create a chat interaction with a specified model.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\ntogether chat.completions \\\n  --message \"system\" \"You are a helpful assistant named Together\" \\\n  --message \"user\" \"What is your name?\" \\\n  --model mistralai/Mixtral-8x7B-Instruct-v0.1\n```\n\n----------------------------------------\n\nTITLE: Using Text Completions via Together CLI\nDESCRIPTION: Demonstrates how to generate text completions using the Together CLI. This command sends a prompt and specifies generation parameters like the model to use, maximum tokens, and stop sequence.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ntogether completions \\\n  \"Large language models are \" \\\n  --model mistralai/Mixtral-8x7B-v0.1 \\\n  --max-tokens 512 \\\n  --stop \".\"\n```\n\n----------------------------------------\n\nTITLE: Generating Images via Together CLI\nDESCRIPTION: Shows how to generate images using the Together CLI. This command creates multiple images based on a text prompt using a specified image generation model.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ntogether images generate \\\n  \"space robots\" \\\n  --model stabilityai/stable-diffusion-xl-base-1.0 \\\n  --n 4\n```\n\n----------------------------------------\n\nTITLE: Managing Files via Together CLI\nDESCRIPTION: Demonstrates various file management operations using the Together CLI. This includes checking, uploading, listing, retrieving, and deleting files that can be used for fine-tuning.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n# Help\ntogether files --help\n\n# Check file\ntogether files check example.jsonl\n\n# Upload file\ntogether files upload example.jsonl\n\n# List files\ntogether files list\n\n# Retrieve file metadata\ntogether files retrieve file-6f50f9d1-5b95-416c-9040-0799b2b4b894\n\n# Retrieve file content\ntogether files retrieve-content file-6f50f9d1-5b95-416c-9040-0799b2b4b894\n\n# Delete remote file\ntogether files delete file-6f50f9d1-5b95-416c-9040-0799b2b4b894\n```\n\n----------------------------------------\n\nTITLE: Listing Models via Together CLI\nDESCRIPTION: Demonstrates how to list available AI models using the Together CLI. This command provides information about all models accessible through the Together platform.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/README.md#2025-04-19_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n# Help\ntogether models --help\n\n# List models\ntogether models list\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests\nDESCRIPTION: Command to run integration tests, requires API key and incurs usage charges.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/CONTRIBUTING.md#2025-04-19_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmake integration_tests\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests\nDESCRIPTION: Command to execute the project's unit test suite.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/CONTRIBUTING.md#2025-04-19_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmake tests\n```\n\n----------------------------------------\n\nTITLE: Installing Development Dependencies with Poetry\nDESCRIPTION: Commands for installing project development dependencies including quality and test requirements using Poetry package manager.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/CONTRIBUTING.md#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry install --with quality,tests\n```\n\n----------------------------------------\n\nTITLE: Setting up Pre-commit Hooks\nDESCRIPTION: Command to install pre-commit hooks for automated formatting and linting checks before commits.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/CONTRIBUTING.md#2025-04-19_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Running Code Formatting\nDESCRIPTION: Command to run code formatting checks locally before submitting a PR.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/CONTRIBUTING.md#2025-04-19_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ make format\n```\n\n----------------------------------------\n\nTITLE: Adding Optional Dependencies with Poetry\nDESCRIPTION: Command to add new optional dependencies to the project using Poetry.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/CONTRIBUTING.md#2025-04-19_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npoetry add --optional [package_name]\n```\n\n----------------------------------------\n\nTITLE: Updating Poetry Lock File\nDESCRIPTION: Command to update the Poetry lock file after adding new dependencies.\nSOURCE: https://github.com/togethercomputer/together-python/blob/main/CONTRIBUTING.md#2025-04-19_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npoetry lock --no-update\n```"
  }
]