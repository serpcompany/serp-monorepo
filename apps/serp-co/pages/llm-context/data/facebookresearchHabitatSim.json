[
  {
    "owner": "facebookresearch",
    "repo": "habitat-sim",
    "content": "TITLE: Adding New Actions in Habitat-Sim (Python)\nDESCRIPTION: This Python snippet is the complete example of how to add new actions to a Habitat-Sim agent. It showcases how to define a custom control functor, register it using `habitat_sim.registry.register_move_fn()`, and integrate it into the agent's action space. This example relies on Habitat-Sim being installed and configured correctly.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/new-actions.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#!/usr/bin/env python3\n\n# Copyright (c) Meta Platforms, Inc. and its affiliates.\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport argparse\nimport os\nimport time\n\nimport habitat_sim\nimport numpy as np\nfrom habitat_sim.utils import common as ut\n\ntry:\n    from PIL import Image\nexcept ImportError:\n    print(\"Please install pillow: pip install pillow\")\n    import sys\n\n    sys.exit(1)\n\nDEFAULT_CFG = \"data/test_assets/configs/plane.yaml\"\n\n\ndef make_simple_cfg(settings, cfg_file=DEFAULT_CFG):\n    cfg = habitat_sim.Configuration()\n    assert os.path.exists(cfg_file), \"{}\" + cfg_file + \" not found\"\n    cfg.merge_from_file(cfg_file)\n    cfg.defrost()\n    cfg.SIMULATOR.RGB_SENSOR.WIDTH = settings[\"width\"]\n    cfg.SIMULATOR.RGB_SENSOR.HEIGHT = settings[\"height\"]\n    cfg.SIMULATOR.RGB_SENSOR.RENDER_TARGET_FRAMEBUFFER = settings[\"rgb_sensor\"]\n    cfg.SIMULATOR.DEPTH_SENSOR.WIDTH = settings[\"width\"]\n    cfg.SIMULATOR.DEPTH_SENSOR.HEIGHT = settings[\"height\"]\n    cfg.SIMULATOR.DEPTH_SENSOR.RENDER_TARGET_FRAMEBUFFER = settings[\"depth_sensor\"]\n    cfg.SIMULATOR.AGENT_0.SENSORS = [\"RGB_SENSOR\", \"DEPTH_SENSOR\"]\n    cfg.SIMULATOR.SCENE = settings[\"scene\"]\n    cfg.freeze()\n    return cfg\n\n\nclass MoveLeft(habitat_sim.agent.SceneNodeControl):\n    def __init__(self, arg):\n        super().__init__()\n        self.move_amount = arg\n\n    def __call__(self, scene_node: habitat_sim.SceneNode, actuation_spec: habitat_sim.ActuationSpec):\n        # scene_node.translate_local(np.array([0.0, 0.0, actuation_spec.amount]))\n        current_location = scene_node.translation\n        scene_node.translation = current_location + np.array([-actuation_spec.amount, 0.0, 0.0])\n\n\nclass MoveRight(habitat_sim.agent.SceneNodeControl):\n    def __init__(self, arg):\n        super().__init__()\n        self.move_amount = arg\n\n    def __call__(self, scene_node: habitat_sim.SceneNode, actuation_spec: habitat_sim.ActuationSpec):\n        # scene_node.translate_local(np.array([0.0, 0.0, actuation_spec.amount]))\n        current_location = scene_node.translation\n        scene_node.translation = current_location + np.array([actuation_spec.amount, 0.0, 0.0])\n\n\n@habitat_sim.registry.register_move_fn(body_action=True)\ndef move_forward(scene_node: habitat_sim.SceneNode, actuation_spec: habitat_sim.ActuationSpec):\n    # scene_node.translate_local(np.array([0.0, 0.0, actuation_spec.amount]))\n    current_location = scene_node.translation\n    scene_node.translation = current_location + np.array([0.0, 0.0, actuation_spec.amount])\n\n\n@habitat_sim.registry.register_move_fn(body_action=True)\ndef move_backward(scene_node: habitat_sim.SceneNode, actuation_spec: habitat_sim.ActuationSpec):\n    # scene_node.translate_local(np.array([0.0, 0.0, actuation_spec.amount]))\n    current_location = scene_node.translation\n    scene_node.translation = current_location + np.array([0.0, 0.0, -actuation_spec.amount])\n\n\n@habitat_sim.registry.register_move_fn(body_action=True)\ndef turn_left(scene_node: habitat_sim.SceneNode, actuation_spec: habitat_sim.ActuationSpec):\n    # scene_node.rotate_local(quat.from_angle_axis(actuation_spec.amount, np.array([0, 1, 0])))\n    current_rotation = scene_node.rotation\n    scene_node.rotation = current_rotation * ut.quat_from_angle_axis(actuation_spec.amount, np.array([0, 1, 0]))\n\n\n@habitat_sim.registry.register_move_fn(body_action=True)\ndef turn_right(scene_node: habitat_sim.SceneNode, actuation_spec: habitat_sim.ActuationSpec):\n    # scene_node.rotate_local(quat.from_angle_axis(actuation_spec.amount, np.array([0, 1, 0])))\n    current_rotation = scene_node.rotation\n    scene_node.rotation = current_rotation * ut.quat_from_angle_axis(-actuation_spec.amount, np.array([0, 1, 0]))\n\n\ndef print_scene(sim):\n    print(\"=====================================================\")\n    print(\"{}\".format(sim.get_scene_graph()))\n    print(\"=====================================================\")\n\n\ndef example(args):\n    settings = {\n        \"width\": 640,\n        \"height\": 480,\n        \"scene\": \"data/scene_datasets/habitat-test-scenes/apartment_1.glb\",\n        \"default_agent\": 0,\n        \"sensor_height\": 1.5,\n        \"rgb_sensor\": True,\n        \"depth_sensor\": True,\n    }\n\n    cfg = make_simple_cfg(settings)\n    # cfg.defrost()\n    # cfg.SIMULATOR.DEBUG_RENDER = True\n    # cfg.freeze()\n\n    sim = habitat_sim.Simulator(cfg)\n    agent = sim.initialize_agent(settings[\"default_agent\"])\n\n    print_scene(sim)\n\n    # Move Left\n    move_left = MoveLeft(0.25)\n    sim.register_action(\"move_left\", move_left)\n    # Move Right\n    move_right = MoveRight(0.25)\n    sim.register_action(\"move_right\", move_right)\n    # Don't do this, actions can also be registered this way but it isn't recommended\n    # sim.register_action(\"move_forward\", move_forward)\n\n    # this is an example of how to get the *names* of the actions\n    # names = list(cfg.SIMULATOR.AGENT_0.ACTION_SPACE.keys())\n    # print(names)\n\n    # this is an example of how to override the *defaults* of pre-existing actions\n    # cfg.SIMULATOR.AGENT_0.ACTION_SPACE[\"move_forward\"] = Config()\n    # cfg.SIMULATOR.AGENT_0.ACTION_SPACE[\"move_forward\"].TYPE = \"MoveForwardAction\"\n    # cfg.SIMULATOR.AGENT_0.ACTION_SPACE[\"move_forward\"].ACTUATION_SETTINGS = Config()\n    # cfg.SIMULATOR.AGENT_0.ACTION_SPACE[\"move_forward\"].ACTUATION_SETTINGS.amount = 2.0\n    # sim.reconfigure(cfg)\n\n    # this shows how to *add new actions* to an agent\n    agent_config = sim.get_agent(0).agent_config\n    agent_config.action_space[\"move_left\"] = habitat_sim.ActionSpec(  # type: ignore\n        \"move_left\", habitat_sim.ActuationSpec(amount=0.25)\n    )\n    agent_config.action_space[\"move_right\"] = habitat_sim.ActionSpec(\n        \"move_right\", habitat_sim.ActuationSpec(amount=0.25)\n    )\n    agent.agent_config = agent_config\n\n    # Get the camera sensor\n    camera = sim.get_sensor(\"rgb_sensor\")\n\n    print(\"Initial agent state: {}\".format(agent.get_state()))\n\n    start_time = time.time()\n    count_frames = 0\n\n    while True:\n        t = time.time() - start_time\n        if t > args.num_seconds:\n            break\n\n        # we are casting actions at probabilities, so you might get\n        # multiple of the same action in a row. To avoid this you can keep\n        # track of the previous action and only cast a new action if it's\n        # different. In the example below the agent should always be moving.\n        # action = np.random.choice(names, p=probability)\n\n        # example of casting existing actions by name\n        # obs = sim.step(action)\n\n        # casting new actions by name\n        action = np.random.choice([\"move_left\", \"move_right\", \"move_forward\", \"move_backward\", \"turn_left\", \"turn_right\"])\n        obs = sim.step(action)\n\n        rgba = sim.get_sensor(\"rgb_sensor\").observations[\"rgba\"]  # type: ignore\n        depth = sim.get_sensor(\"depth_sensor\").observations[\"depth\"]  # type: ignore\n\n        # integer (not floating point) rgba\n        im = Image.fromarray(rgba, mode=\"RGBA\")\n\n        # save some images\n        if count_frames % 50 == 0:\n            im.save(\"rgba_{}.png\".format(count_frames))\n            ut.imwrite(\"depth_{}.png\".format(count_frames), depth)\n\n        count_frames += 1\n\n    print(\"{} frames rendered in {} seconds\".format(count_frames, t))\n\n    print(\"Final agent state: {}\".format(agent.get_state()))\n\n    sim.close()\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--num-seconds\", type=int, default=10)\n    args = parser.parse_args()\n\n    example(args)\n```\n\n----------------------------------------\n\nTITLE: Dynamic Control of Rigid Objects in Habitat-Sim (Python)\nDESCRIPTION: This code demonstrates how to apply forces and torques to rigid objects and manipulate their velocities.  It applies a constant anti-gravity force and torque to boxes, causing them to float and rotate, and then throws a sphere at them using initial velocity manipulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# [dynamic_control]\nnum_objects = 3\ndistance = 0.15\nbox_handles = sim.get_object_template_manager().get_template_handles(\"cube\")\nboxes = []\nfor i in range(num_objects):\n    box = sim.get_rigid_object_manager().add_object_by_template_handle(box_handles[0])\n    boxes.append(box)\n    box.translation = [0.75 + i * distance, 0.7, 0.8]\n\nanti_grav_force = np.array([0, 9.8, 0])\nrotation_speed = 1.0\n\nball_start_pos = np.array([0.25, 1.0, 0.8])\nsphere_object.translation = ball_start_pos\n\n\ndef throw_ball(impulse):\n    sphere_object.linear_velocity = np.array([0, 0, 0])\n    sphere_object.angular_velocity = np.array([0, 0, 0])\n    sphere_object.translation = ball_start_pos\n    sphere_object.apply_impulse(np.array([0, 0, 0]), impulse)\n\n\n# simulate gravity compensation\nfor _ in range(100):\n    for box in boxes:\n        box.apply_force(anti_grav_force, np.array([0, 0, 0]))\n        box.apply_torque(np.array([rotation_speed, rotation_speed, rotation_speed]))\n    sim.step_physics(1 / 60.0)\n\n# throw the ball\nthrow_ball(np.array([8.0, 0, 0]))\n\n# run the simulation after the ball throw\nfor _ in range(150):\n    for box in boxes:\n        box.apply_force(anti_grav_force, np.array([0, 0, 0]))\n        box.apply_torque(np.array([rotation_speed, rotation_speed, rotation_speed]))\n    sim.step_physics(1 / 60.0)\n\n# [/dynamic_control]\n```\n\n----------------------------------------\n\nTITLE: Defining Habitat-sim Simulation Utility Functions\nDESCRIPTION: This snippet defines utility functions for running and controlling simulations within Habitat-sim. It includes a `simulate` function to step the physics simulation for a specified duration and collect sensor observations.  It also includes a `set_object_state_from_agent` function to position an object relative to the agent's location and orientation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# @title Define Simulation Utility Functions { display-mode: \"form\" }\n# @markdown (double click to show code)\n\n# @markdown - remove_all_objects\n# @markdown - simulate\n# @markdown - sample_object_state\n\n\ndef simulate(sim, dt=1.0, get_frames=True):\n    # simulate dt seconds at 60Hz to the nearest fixed timestep\n    print(\"Simulating \" + str(dt) + \" world seconds.\")\n    observations = []\n    start_time = sim.get_world_time()\n    while sim.get_world_time() < start_time + dt:\n        sim.step_physics(1.0 / 60.0)\n        if get_frames:\n            observations.append(sim.get_sensor_observations())\n    return observations\n\n\n# Set an object transform relative to the agent state\ndef set_object_state_from_agent(\n    sim,\n    obj,\n    offset=np.array([0, 2.0, -1.5]),\n    orientation=mn.Quaternion(((0, 0, 0), 1)),\n):\n    agent_transform = sim.agents[0].scene_node.transformation_matrix()\n    ob_translation = agent_transform.transform_point(offset)\n    obj.translation = ob_translation\n    obj.rotation = orientation\n```\n\n----------------------------------------\n\nTITLE: Creating Habitat Simulator Configuration (make_cfg)\nDESCRIPTION: This function creates a Habitat simulator configuration based on provided settings. It configures the GPU device, scene, physics, and sensor specifications including color, depth, and semantic sensors.  It takes a dictionary `settings` as input, which includes parameters like scene ID, sensor resolutions, positions, and types. It returns a `habitat_sim.Configuration` object.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef make_cfg(settings):\n    sim_cfg = habitat_sim.SimulatorConfiguration()\n    sim_cfg.gpu_device_id = 0\n    sim_cfg.scene_id = settings[\"scene\"]\n    sim_cfg.enable_physics = settings[\"enable_physics\"]\n    # Optional; Specify the location of an existing scene dataset configuration\n    # that describes the locations and configurations of all the assets to be used\n    if \"scene_dataset_config\" in settings:\n        sim_cfg.scene_dataset_config_file = settings[\"scene_dataset_config\"]\n\n    # Note: all sensors must have the same resolution\n    sensor_specs = []\n    if settings[\"color_sensor_1st_person\"]:\n        color_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n        color_sensor_1st_person_spec.uuid = \"color_sensor_1st_person\"\n        color_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.COLOR\n        color_sensor_1st_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        color_sensor_1st_person_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n        color_sensor_1st_person_spec.orientation = [\n            settings[\"sensor_pitch\"],\n            0.0,\n            0.0,\n        ]\n        color_sensor_1st_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n        sensor_specs.append(color_sensor_1st_person_spec)\n    if settings[\"depth_sensor_1st_person\"]:\n        depth_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n        depth_sensor_1st_person_spec.uuid = \"depth_sensor_1st_person\"\n        depth_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.DEPTH\n        depth_sensor_1st_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        depth_sensor_1st_person_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n        depth_sensor_1st_person_spec.orientation = [\n            settings[\"sensor_pitch\"],\n            0.0,\n            0.0,\n        ]\n        depth_sensor_1st_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n        sensor_specs.append(depth_sensor_1st_person_spec)\n    if settings[\"semantic_sensor_1st_person\"]:\n        semantic_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n        semantic_sensor_1st_person_spec.uuid = \"semantic_sensor_1st_person\"\n        semantic_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.SEMANTIC\n        semantic_sensor_1st_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        semantic_sensor_1st_person_spec.position = [\n            0.0,\n            settings[\"sensor_height\"],\n            0.0,\n        ]\n        semantic_sensor_1st_person_spec.orientation = [\n            settings[\"sensor_pitch\"],\n            0.0,\n            0.0,\n        ]\n        semantic_sensor_1st_person_spec.sensor_subtype = (\n            habitat_sim.SensorSubType.PINHOLE\n        )\n        sensor_specs.append(semantic_sensor_1st_person_spec)\n    if settings[\"color_sensor_3rd_person\"]:\n        color_sensor_3rd_person_spec = habitat_sim.CameraSensorSpec()\n        color_sensor_3rd_person_spec.uuid = \"color_sensor_3rd_person\"\n        color_sensor_3rd_person_spec.sensor_type = habitat_sim.SensorType.COLOR\n        color_sensor_3rd_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        color_sensor_3rd_person_spec.position = [\n            0.0,\n            settings[\"sensor_height\"] + 0.2,\n            0.2,\n        ]\n        color_sensor_3rd_person_spec.orientation = [-math.pi / 4, 0.0, 0.0]\n        color_sensor_3rd_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n        sensor_specs.append(color_sensor_3rd_person_spec)\n\n    # Here you can specify the amount of displacement in a forward action and the turn angle\n    agent_cfg = habitat_sim.agent.AgentConfiguration()\n    agent_cfg.sensor_specifications = sensor_specs\n\n    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n```\n\n----------------------------------------\n\nTITLE: Local Velocity Control of Kinematic Objects (Python)\nDESCRIPTION: This code demonstrates how to specify velocities in the local space of the object for continuous agent actions. This makes applying velocity control for movement relative to the object's orientation much simpler.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# [local_velocity_control]\nvel_control.linear_velocity = np.array([0, 0, 0.0])\nvel_control.angular_velocity = np.array([0, 0.0, 0])\nvel_control.local_velocity = True\nvel_control.linear_velocity = np.array([0, 0, 1.0])\nvel_control.angular_velocity = np.array([0, 2.0, 0])\n\n# simulate velocity control\nfor _ in range(100):\n    for box in boxes:\n        box.apply_force(anti_grav_force, np.array([0, 0, 0]))\n        box.apply_torque(np.array([rotation_speed, rotation_speed, rotation_speed]))\n    sim.step_physics(1 / 60.0)\n# [/local_velocity_control]\n```\n\n----------------------------------------\n\nTITLE: Configuring Velocity Control and Simulation\nDESCRIPTION: This snippet configures the velocity control parameters for a robot in the Habitat simulator. It sets linear and angular velocities, simulates the robot's movement over time, and records observations for video rendering. The simulation includes forward and turning motions with damping, and settling behavior.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n    vel_control.lin_vel_is_local = True\n    vel_control.ang_vel_is_local = True\n\n    # simulate forward and turn\n    observations += simulate(sim, dt=1.0, get_frames=make_video)\n\n    vel_control.controlling_lin_vel = False\n    vel_control.angular_velocity = [0.0, 1.0, 0.0]\n\n    # simulate turn only\n    observations += simulate(sim, dt=1.5, get_frames=make_video)\n\n    vel_control.angular_velocity = [0.0, 0.0, 0.0]\n    vel_control.controlling_lin_vel = True\n    vel_control.controlling_ang_vel = True\n\n    # simulate forward only with damped angular velocity (reset angular velocity to 0 after each step)\n    observations += simulate(sim, dt=1.0, get_frames=make_video)\n\n    vel_control.angular_velocity = [0.0, -1.25, 0.0]\n\n    # simulate forward and turn\n    observations += simulate(sim, dt=2.0, get_frames=make_video)\n\n    vel_control.controlling_ang_vel = False\n    vel_control.controlling_lin_vel = False\n\n    # simulate settling\n    observations += simulate(sim, dt=3.0, get_frames=make_video)\n```\n\n----------------------------------------\n\nTITLE: Project 3D Point to 2D in Habitat-Sim (Python)\nDESCRIPTION: This function projects a 3D point into 2D image space for a specific sensor in Habitat-Sim. It utilizes the scene render camera and sensor object to transform the point using camera and projection matrices, then converts it to integer pixel space. The function requires the simulator instance (`sim`), the name of the sensor (`sensor_name`), and the 3D point to project (`point_3d`) as input, and returns the 2D point as a `mn.Vector2i` object.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef get_2d_point(sim, sensor_name, point_3d):\n    # get the scene render camera and sensor object\n    render_camera = sim._sensors[sensor_name]._sensor_object.render_camera\n\n    # use the camera and projection matrices to transform the point onto the near plane\n    projected_point_3d = render_camera.projection_matrix.transform_point(\n        render_camera.camera_matrix.transform_point(point_3d)\n    )\n    # convert the 3D near plane point to integer pixel space\n    point_2d = mn.Vector2(projected_point_3d[0], -projected_point_3d[1])\n    point_2d = point_2d / render_camera.projection_size()[0]\n    point_2d += mn.Vector2(0.5)\n    point_2d *= render_camera.viewport\n    return mn.Vector2i(point_2d)\n```\n\n----------------------------------------\n\nTITLE: Kinematic Interactions in Habitat Sim\nDESCRIPTION: This snippet demonstrates kinematic interactions in Habitat Sim by setting an object to kinematic and observing its interaction with dynamic objects. It loads a chefcan template, adds the object to the scene, sets its motion type to kinematic, and then adds several dynamic chefcan objects. The simulation is run, and observations are collected for video generation. Key functions used are `obj_templates_mgr`, `rigid_obj_mgr`, and setting `motion_type`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n    # [kinematic_interactions]\n\n    chefcan_template_handle = obj_templates_mgr.get_template_handles(\n        \"data/objects/example_objects/chefcan\"\n    )[0]\n    chefcan_obj = rigid_obj_mgr.add_object_by_template_handle(chefcan_template_handle)\n    chefcan_obj.translation = [2.4, -0.64, 0.0]\n    # set object to kinematic\n    chefcan_obj.motion_type = habitat_sim.physics.MotionType.KINEMATIC\n\n    # drop some dynamic objects\n    chefcan_obj_2 = rigid_obj_mgr.add_object_by_template_handle(chefcan_template_handle)\n    chefcan_obj_2.translation = [2.4, -0.64, 0.28]\n    chefcan_obj_3 = rigid_obj_mgr.add_object_by_template_handle(chefcan_template_handle)\n    chefcan_obj_3.translation = [2.4, -0.64, -0.28]\n    chefcan_obj_4 = rigid_obj_mgr.add_object_by_template_handle(chefcan_template_handle)\n    chefcan_obj_4.translation = [2.4, -0.3, 0.0]\n\n    # simulate\n    observations = simulate(sim, dt=1.5, get_frames=True)\n\n    if make_video:\n        vut.make_video(\n            observations,\n            \"rgba_camera_1stperson\",\n            \"color\",\n            output_path + \"kinematic_interactions\",\n            open_vid=show_video,\n        )\n\n    # [/kinematic_interactions]\n\n    rigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Initialize Simulator and Load Scene\nDESCRIPTION: This code initializes the Habitat simulator and loads a scene. It defines simulator settings such as the scene path and sensor pitch, creates a simulator instance using these settings, and prepares the environment for further interaction.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nsim_settings = make_default_settings()\nsim_settings[\"scene\"] = os.path.join(\n    data_path, \"scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\"\n)\nsim_settings[\"sensor_pitch\"] = 0.0\n\nmake_simulator_from_settings(sim_settings)\n```\n\n----------------------------------------\n\nTITLE: Embodying an Agent in Habitat-Sim (Python)\nDESCRIPTION: This code demonstrates how to attach an agent to a simulated object, allowing for embodied control. It adds a rigid robot asset and uses VelocityControl to control the robot's actions within the simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# [embodied_agent]\n# remove all objects\nsim.get_rigid_object_manager().remove_all_objects()\n\n# Add the agent/camera\nagent = sim.initialize_agent(cfg.agents[0])\n\n# load the robot template\nrobot_handle = sim.get_object_template_manager().get_template_handles(\"locobot_merged\")[0]\n\n# add the robot\nrobot_object = sim.get_rigid_object_manager().add_object_by_template_handle(robot_handle, agent.scene_node)\n# set the robot transform\ntrans = np.array([0.75, 0.0, 0.8])\nrot = ut.quat_from_angle_axis(np.radians(45), [0, 1, 0])\nrobot_object.translation = trans\nrobot_object.rotation = rot\n\n# get a reference to the velocity control\nvel_control = robot_object.velocity_control\nvel_control.controlling_lin_vel = True\nvel_control.controlling_ang_vel = True\nvel_control.linear_velocity = np.array([0, 0, 1.0])\nvel_control.angular_velocity = np.array([0, 1.0, 0])\nvel_control.local_velocity = True\n\n# simulate robot control\nfor _ in range(100):\n    sim.step_physics(1 / 60.0)\n# [/embodied_agent]\n```\n\n----------------------------------------\n\nTITLE: Path Planning with Habitat-Sim\nDESCRIPTION: This snippet calculates the shortest path between the Locobot and an object, and then between the object and a random navigable point.  It uses the `ShortestPath` class and the `pathfinder` to find valid paths within the environment.  `sample_object_state` ensures the object is placed on the navmesh.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_30\n\nLANGUAGE: Python\nCODE:\n```\nfound_path = False\npath1 = habitat_sim.ShortestPath()\npath2 = habitat_sim.ShortestPath()\nwhile not found_path:\n    if not sample_object_state(\n        sim, obj_1, from_navmesh=True, maintain_object_up=True, max_tries=1000\n    ):\n        print(\"Couldn't find an initial object placement. Aborting.\")\n        break\n    path1.requested_start = locobot_obj.translation\n    path1.requested_end = obj_1.translation\n    path2.requested_start = path1.requested_end\n    path2.requested_end = sim.pathfinder.get_random_navigable_point()\n\n    found_path = sim.pathfinder.find_path(path1) and sim.pathfinder.find_path(path2)\n\nif not found_path:\n    print(\"Could not find path to object, aborting!\")\n```\n\n----------------------------------------\n\nTITLE: Running Habitat Viewer Python\nDESCRIPTION: This command executes the Habitat-Sim interactive viewer in Python, loading a specified scene.  It uses `examples/viewer.py` and requires the `--scene` argument to point to the scene file. The `PYTHONPATH` may need adjustment depending on the installation method.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n#Python\n#NOTE: depending on your choice of installation, you may need to add '/path/to/habitat-sim' to your PYTHONPATH.\n#e.g. from 'habitat-sim/' directory run 'export PYTHONPATH=$(pwd)'\npython examples/viewer.py --scene /path/to/data/scene_datasets/habitat-test-scenes/skokloster-castle.glb\n```\n\n----------------------------------------\n\nTITLE: Playing Gfx Replay Forward (Habitat-Sim, Python)\nDESCRIPTION: Plays a gfx replay forward by iterating through keyframes, setting the keyframe index, and retrieving the user transform for the sensor. The sensor is repositioned at each frame to match the recorded replay. The observations are appended to a list for video creation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nobservations = []\nprint(\"play replay #0...\")\nfor frame in range(player.get_num_keyframes()):\n    player.set_keyframe_index(frame)\n\n    (sensor_node.translation, sensor_node.rotation) = player.get_user_transform(\n        \"sensor\"\n    )\n\n    observations.append(sim.get_sensor_observations())\n\nif make_video:\n    vut.make_video(\n        observations,\n        \"rgba_camera\",\n        \"color\",\n        output_path + \"replay_playback1\",\n        open_vid=show_video,\n    )\n```\n\n----------------------------------------\n\nTITLE: Continuous Control on NavMesh in Habitat-Sim (Python)\nDESCRIPTION: This code demonstrates how to use kinematic state setting and NavMesh to simulate constrained continuous navigation tasks.  The agent is embodied by a robot asset with MotionType.KINEMATIC, and a VelocityControl structure is used to manually integrate a control velocity and snap the resulting state to the NavMesh before running dynamic simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# [embodied_agent_navmesh]\n# remove all objects\nsim.get_rigid_object_manager().remove_all_objects()\n\n# set the navmesh up\nnavmesh_settings = habitat_sim.NavMeshSettings()\nnavmesh_settings.set_defaults()\nnavmesh_settings.agent_height = 1.5\nnavmesh_settings.agent_radius = 0.1\nsim.recompute_navmesh(sim.get_navigable_region(), navmesh_settings)\n\n# Add the agent/camera\nagent = sim.initialize_agent(cfg.agents[0])\n\n# load the robot template\nrobot_handle = sim.get_object_template_manager().get_template_handles(\"locobot_merged\")[0]\n\n# add the robot\nrobot_object = sim.get_rigid_object_manager().add_object_by_template_handle(robot_handle, agent.scene_node)\nrobot_object.motion_type = habitat_sim.physics.MotionType.KINEMATIC\n# set the robot transform\ntrans = np.array([0.75, 0.0, 0.8])\nrot = ut.quat_from_angle_axis(np.radians(45), [0, 1, 0])\nrobot_object.translation = trans\nrobot_object.rotation = rot\n\n# get a reference to the velocity control\nvel_control = robot_object.velocity_control\nvel_control.controlling_lin_vel = True\nvel_control.controlling_ang_vel = True\nvel_control.local_velocity = True\nvel_control.linear_velocity = np.array([0, 0, 1.0])\nvel_control.angular_velocity = np.array([0, 0.0, 0])\n\n# simulate robot control\nfor _ in range(200):\n    current_location = robot_object.translation\n    target_location = current_location + vel_control.linear_velocity * (1 / 60.0)\n    agent_state = habitat_sim.AgentState()\n    agent_state.position = target_location\n    agent_state.rotation = robot_object.rotation\n\n    # option 1: don't let the agent slide\n    agent_state = sim.snap_agent_state(agent_state)\n\n    # option 2: allow the agent to slide\n    # agent_state.position = sim.step_filter(current_location, target_location)\n\n    robot_object.translation = agent_state.position\n    robot_object.rotation = agent_state.rotation\n    sim.step_physics(1 / 60.0)\n\n# [/embodied_agent_navmesh]\n```\n\n----------------------------------------\n\nTITLE: Implement Motion Tracking Camera\nDESCRIPTION: This code implements a motion tracking camera by updating the agent's state to follow the motion of an object during simulation. It removes existing objects, adjusts the sensor's transform to match the agent's, adds a new object, and simulates the scene. During simulation, the agent's rotation is updated to always look at the target object, creating a motion tracking effect.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nrigid_obj_mgr.remove_all_objects()\nvisual_sensor = sim._sensors[\"color_sensor_1st_person\"]\ninitial_sensor_position = np.array(visual_sensor._spec.position)\ninitial_sensor_orientation = np.array(visual_sensor._spec.orientation)\n# set the color sensor transform to be the agent transform\nvisual_sensor._spec.position = mn.Vector3(0.0, 0.0, 0.0)\nvisual_sensor._spec.orientation = mn.Vector3(0.0, 0.0, 0.0)\nvisual_sensor._sensor_object.set_transformation_from_spec()\n\n# boost the agent off the floor\nsim.get_agent(0).scene_node.translation += np.array([0, 1.5, 0])\nobservations = []\n\n# @markdown ---\n# @markdown ### Set example parameters:\nseed = 23  # @param {type:\"integer\"}\nrandom.seed(seed)\nsim.seed(seed)\nnp.random.seed(seed)\n\n# add an object and position the agent\nsel_file_obj = rigid_obj_mgr.add_object_by_template_handle(sel_file_obj_handle)\nrand_position = np.random.uniform(\n    np.array([-0.4, -0.3, -1.0]), np.array([0.4, 0.3, -0.5])\n)\nset_object_state_from_agent(sim, sel_file_obj, rand_position, ut.random_quaternion())\n\n# simulate with updated camera at each frame\nstart_time = sim.get_world_time()\nwhile sim.get_world_time() - start_time < 2.0:\n    sim.step_physics(1.0 / 60.0)\n    # set agent state to look at object\n    camera_position = sim.get_agent(0).scene_node.translation\n    camera_look_at = sel_file_obj.translation\n    sim.get_agent(0).scene_node.rotation = mn.Quaternion.from_matrix(\n        mn.Matrix4.look_at(\n            camera_position, camera_look_at, np.array([0, 1.0, 0])  # up\n        ).rotation()\n    )\n    observations.append(sim.get_sensor_observations())\n\n# video rendering with embedded 1st person view\nvideo_prefix = \"motion tracking\"\nif make_video:\n    vut.make_video(\n        observations,\n        \"color_sensor_1st_person\",\n        \"color\",\n        output_path + video_prefix,\n        open_vid=show_video,\n    )\n\n# reset the sensor state for other examples\nvisual_sensor._spec.position = initial_sensor_position\nvisual_sensor._spec.orientation = initial_sensor_orientation\nvisual_sensor._sensor_object.set_transformation_from_spec()\n# put the agent back\nsim.reset()\nrigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Get NavMesh Bounds Python\nDESCRIPTION: This code snippet retrieves and prints the bounds of the loaded NavMesh using `sim.pathfinder.get_bounds()`. It's part of a larger block that checks if the Pathfinder is initialized before attempting to access its properties.  The output is a tuple containing the minimum and maximum coordinates of the bounding box.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nprint(\"The NavMesh bounds are: \" + str(sim.pathfinder.get_bounds()))\n```\n\n----------------------------------------\n\nTITLE: Creating a Conda Environment for Habitat-Sim\nDESCRIPTION: This snippet demonstrates how to create and activate a Conda environment for Habitat-Sim, specifying Python version 3.9 and CMake version 3.14.0 as dependencies. This environment setup is a prerequisite for installing Habitat-Sim using Conda.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# We require python>=3.9 and cmake>=3.10\nconda create -n habitat python=3.9 cmake=3.14.0\nconda activate habitat\n```\n\n----------------------------------------\n\nTITLE: Kinematic Object Placement in Habitat-Sim (Python)\nDESCRIPTION: This code demonstrates how to place a kinematic object in the scene that doesn't react to physical events such as collisions with dynamic objects, but still acts as a collision object for other scene objects.  It showcases setting the motion type of an object to kinematic.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# [kinematic_interactions]\ncan_handle = sim.get_object_template_manager().get_template_handles(\"small_coke_can\")[0]\ncan_object = sim.get_rigid_object_manager().add_object_by_template_handle(can_handle)\ncan_object.motion_type = habitat_sim.physics.MotionType.KINEMATIC\ncan_object.translation = [0.75, 0.5, 0.5]\n\n# run the simulation after the ball throw\nfor _ in range(100):\n    for box in boxes:\n        box.apply_force(anti_grav_force, np.array([0, 0, 0]))\n        box.apply_torque(np.array([rotation_speed, rotation_speed, rotation_speed]))\n    sim.step_physics(1 / 60.0)\n\n# [/kinematic_interactions]\n```\n\n----------------------------------------\n\nTITLE: Trajectory Prediction Task Setup\nDESCRIPTION: This snippet demonstrates setting up a trajectory prediction task where a sphere is launched to knock boxes off a counter. It initializes random seeds for reproducibility, sets the agent's state manually, and loads target objects using their template handles. It relies on `obj_attr_mgr` and `rigid_obj_mgr` for managing object templates and object instances.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\nrigid_obj_mgr.remove_all_objects()\n\nseed = 2  # @param{type:\"integer\"}\nrandom.seed(seed)\nsim.seed(seed)\nnp.random.seed(seed)\n\n# setup agent state manually to face the bar\nagent_state = sim.agents[0].state\nagent_state.position = np.array([-1.97496, 0.072447, -2.0894])\nagent_state.rotation = ut.quat_from_coeffs([0, -1, 0, 0])\nsim.agents[0].set_state(agent_state)\n\n# load the target objects\ncheezit_handle = obj_attr_mgr.get_template_handles(\"cheezit\")[0]\n```\n\n----------------------------------------\n\nTITLE: Basic Rigid Body Simulation in Habitat-Sim (Python)\nDESCRIPTION: This code demonstrates basic rigid body simulation by loading a sphere object template, instancing it above a table, and simulating its fall due to gravity and collisions with the scene. It illustrates how to add objects to the scene and initiate dynamic simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# [basics]\nsphere_handle = sim.get_object_template_manager().get_template_handles(\"sphere\")[0]\nsphere_object = sim.get_rigid_object_manager().add_object_by_template_handle(sphere_handle)\nsphere_object.translation = [0.75, 1.0, 0.8]\n\nfor _ in range(5):\n    sim.step_physics(1 / 60.0)\n\n# [/basics]\n```\n\n----------------------------------------\n\nTITLE: Downloading Habitat PointNav Dataset with Python\nDESCRIPTION: This code snippet demonstrates how to download the PointNav episodes sampled from Habitat test scenes using the `habitat_sim.utils.datasets_download` module. It uses the `--uids` argument with `habitat_test_pointnav_dataset` to specify the PointNav dataset, and the `--data-path` argument to set the destination directory to `data/`.  This is helpful for setting up PointNav benchmarks using the test scenes.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\npython -m habitat_sim.utils.datasets_download --uids habitat_test_pointnav_dataset --data-path data/\n```\n\n----------------------------------------\n\nTITLE: Set Object State from Agent in Habitat-Sim (Python)\nDESCRIPTION: This snippet demonstrates how to set the state (position and orientation) of an object in the Habitat-Sim environment based on the current agent state.  It relies on a pre-defined `set_object_state_from_agent` function, a simulator instance (`sim`), a rigid object (`sel_file_obj`), a 3D position (`rand_position`), and a quaternion representing the object's orientation (`ut.random_quaternion()`). The snippet is intended for positioning and orienting objects within the simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nrigid_obj_mgr.remove_all_objects()\n\n# add an object and plot the COM on the image\nsel_file_obj = rigid_obj_mgr.add_object_by_template_handle(sel_file_obj_handle)\nrand_position = np.random.uniform(\n    np.array([-0.4, 1.2, -1.0]), np.array([0.4, 1.8, -0.5])\n)\nset_object_state_from_agent(sim, sel_file_obj, rand_position, ut.random_quaternion())\n\nobs = sim.get_sensor_observations()\n\ncom_2d = get_2d_point(\n    sim, sensor_name=\"color_sensor_1st_person\", point_3d=sel_file_obj.translation\n)\nif display:\n    display_sample(obs[\"color_sensor_1st_person\"], key_points=[com_2d])\nrigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Initializing Simulator and Agent in Habitat-Sim (Python)\nDESCRIPTION: This code snippet initializes the Habitat Simulator and Agent. It sets up the simulator configuration, the agent configuration, and the scene dataset configuration. This initialization is crucial for creating a virtual environment where the agent can interact with objects.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport random\n\nimport numpy as np\n\nimport habitat_sim\nfrom habitat_sim.utils import common as ut\nfrom habitat_sim.utils import datasets_download\n\n\ndef safe_makedirs(path):\n    try:\n        os.makedirs(path)\n    except OSError:\n        pass\n\n\ndef make_configuration(scene_id):\n    # simulator configuration\n    sim_cfg = habitat_sim.SimulatorConfiguration()\n    sim_cfg.scene_id = scene_id\n    sim_cfg.enable_physics = True\n\n    # agent configuration\n    agent_cfg = habitat_sim.AgentConfiguration()\n    agent_cfg.height = 0.0\n    agent_cfg.radius = 0.0\n    agent_cfg.sensor_specifications = []\n\n    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n\n\n# [setup]\n```\n\n----------------------------------------\n\nTITLE: Setting User-Defined Object Configurations in Habitat\nDESCRIPTION: This snippet demonstrates how to modify an object's user-defined configurations in the Habitat simulator. It loads a sphere template, adds a sphere to the scene, sets user-defined attributes using a dictionary, and then retrieves and prints these attributes.  It utilizes `obj_templates_mgr`, `rigid_obj_mgr`, and the `user_attributes` property.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n    # [object_user_configurations]\n    # modify an object's user-defined configurations\n\n    # load some object templates from configuration files\n    sphere_template_id = obj_templates_mgr.load_configs(\n        str(os.path.join(data_path, \"test_assets/objects/sphere\"))\n    )[0]\n\n    # add a sphere to the scene, returns the object\n    sphere_obj = rigid_obj_mgr.add_object_by_template_id(sphere_template_id)\n\n    # set user-defined configuration values\n    user_attributes_dict = {\n        \"obj_val_0\": \"This is a sphere object named \" + sphere_obj.handle,\n        \"obj_val_1\": 17,\n        \"obj_val_2\": False,\n        \"obj_val_3\": 19.7,\n        \"obj_val_4\": [2.50, 0.0, 0.2],\n        \"obj_val_5\": mn.Quaternion.rotation(mn.Deg(90.0), [-1.0, 0.0, 0.0]),\n    }\n    for k, v in user_attributes_dict.items():\n        sphere_obj.user_attributes.set(k, v)\n\n    for k, _ in user_attributes_dict.items():\n        print(\n            \"Sphere Object user attribute : {} : {}\".format(\n                k, sphere_obj.user_attributes.get_as_string(k)\n            )\n        )\n\n    # [/object_user_configurations]\n    rigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Embodied Agent with Velocity Control in Habitat\nDESCRIPTION: This snippet demonstrates how to add an embodied agent to the scene and control its velocity in Habitat Sim. It loads a locobot template, adds the robot object to the scene attached to the agent's scene node, sets the initial translation, sets the linear and angular velocities, simulates the environment, and then enables velocity control for the robot. It relies on `obj_templates_mgr`, `rigid_obj_mgr`, `velocity_control`, and `sim.agents[0].scene_node`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n    # [embodied_agent]\n\n    # load the locobot_merged asset\n    locobot_template_id = obj_templates_mgr.load_configs(\n        str(os.path.join(data_path, \"objects/locobot_merged\"))\n    )[0]\n\n    # add robot object to the scene with the agent/camera SceneNode attached\n    locobot = rigid_obj_mgr.add_object_by_template_id(\n        locobot_template_id, sim.agents[0].scene_node\n    )\n    locobot.translation = [1.75, -1.02, 0.4]\n\n    vel_control = locobot.velocity_control\n    vel_control.linear_velocity = [0.0, 0.0, -1.0]\n    vel_control.angular_velocity = [0.0, 2.0, 0.0]\n\n    # simulate robot dropping into place\n    observations = simulate(sim, dt=1.5, get_frames=make_video)\n\n    vel_control.controlling_lin_vel = True\n    vel_control.controlling_ang_vel = True\n```\n\n----------------------------------------\n\nTITLE: Simulator API Usage\nDESCRIPTION: Illustrates how to add the audio sensor to the Habitat simulator and retrieve sensor observations in Python.  `sim.add_sensor()` is used to add the audio sensor based on its specification.  `sim.get_sensor_observations()` is then used to retrieve the impulse response.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/AUDIO.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsim.add_sensor(audio_sensor_spec)\nobs = sim.get_sensor_observations()[\"audio_sensor\"]\n```\n\n----------------------------------------\n\nTITLE: User Defined Object Attributes JSON Example\nDESCRIPTION: This JSON snippet demonstrates how to define user-defined attributes within an object configuration.  The \"user_defined\" tag allows attaching custom metadata to objects, such as object set, affordances, and custom properties. This data can be accessed and modified during simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/attributesJSON.rst#_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n    {\n        \"user_defined\": {\n            \"object_set\": \"kitchen\",\n            \"object_affordances\": [\n                \"can grip\",\n                \"can open\"\n            ],\n            \"custom_object_properties\":{\n                \"is_gripped\": false,\n                \"temperature\": 10.0,\n            },\n        }\n    }\n```\n\n----------------------------------------\n\nTITLE: Scripted vs. Dynamic Motion Simulation\nDESCRIPTION: This snippet simulates the difference between kinematic and dynamic object motion. It adds an object, sets its motion type to either kinematic or dynamic based on `scenario_is_kinematic`, applies a linear velocity if kinematic, and simulates the environment for a specified duration. The resulting observations are then used to generate a video.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nrigid_obj_mgr.remove_all_objects()\n# @markdown Set the scene as dynamic or kinematic:\nscenario_is_kinematic = True  # @param {type:\"boolean\"}\n\n# add the selected object\nobj_1 = rigid_obj_mgr.add_object_by_template_handle(sel_file_obj_handle)\n\n# place the object\nset_object_state_from_agent(\n    sim, obj_1, offset=np.array([0, 2.0, -1.0]), orientation=ut.random_quaternion()\n)\n\nif scenario_is_kinematic:\n    # use the velocity control struct to setup a constant rate kinematic motion\n    obj_1.motion_type = habitat_sim.physics.MotionType.KINEMATIC\n    vel_control = obj_1.velocity_control\n    vel_control.controlling_lin_vel = True\n    vel_control.linear_velocity = np.array([0, -1.0, 0])\n\n# simulate and collect observations\nexample_type = \"kinematic vs dynamic\"\nobservations = simulate(sim, dt=2.0)\nif make_video:\n    vut.make_video(\n        observations,\n        \"color_sensor_1st_person\",\n        \"color\",\n        output_path + example_type,\n        open_vid=show_video,\n    )\n\nrigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Custom Scene Lighting Setup in Habitat-Sim (Python)\nDESCRIPTION: This snippet demonstrates how to reconfigure the Simulator to use a custom lighting setup for the scene. It creates a custom low-light setup with a point light source originating at the window and configures the Simulator to switch the scene's light setup key.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_1\n\nLANGUAGE: py\nCODE:\n```\n# [default scene lighting]\nmy_scene_lighting = habitat_sim.gfx.LightSetup()\n\n# white ambient lighting\nmy_scene_lighting.set_ambient_light([0.1, 0.1, 0.1])\n\n# a single point light\npoint_light = habitat_sim.gfx.LightInfo()\npoint_light.color = np.array([0.6, 0.6, 0.6])\npoint_light.range = 20\npoint_light.intensity = 1.0\n\n# vector describes position\npoint_light.vector = np.array([3, 1.8, 1.5, 0.0])\nmy_scene_lighting.add_light(point_light)\n\nsim.set_light_setup(my_scene_lighting, \"my_scene_lighting\")\n\n# reconfigure the simulator\ncfg.sim_cfg.scene_light_setup = \"my_scene_lighting\"\nsim.reconfigure(cfg)\n# [/default scene lighting]\n```\n\n----------------------------------------\n\nTITLE: Modifying Solid Cylinder Template in Habitat-Sim (Python)\nDESCRIPTION: This code snippet demonstrates how to acquire a default solid cylinder template from the prim_attr_mgr, modify its attributes such as number of rings, segments, half length and whether to use cap ends, texture coordinates and tangents, and then register the modified template. The register_prim_template_if_valid function saves the changes.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_48\n\nLANGUAGE: python\nCODE:\n```\n# Acquire default template\ncylinder_solid_template = prim_attr_mgr.get_default_cylinder_template(False)\n\n\ndef edit_solid_cylinder(edit_template):\n    # @markdown Whether to build with texture coordinate support\n    use_texture_coords = False  # @param {type:\"boolean\"}\n    edit_template.use_texture_coords = use_texture_coords\n    # @markdown Whether to build tangents\n    use_tangents = False  # @param {type:\"boolean\"}\n    edit_template.use_tangents = use_tangents\n    # @markdown Number of (face) rings. Must be larger or equal to 1.\n    num_rings = 4  # @param {type:\"slider\", min:1, max:10, step:1}\n    edit_template.num_rings = num_rings\n    # @markdown Number of (face) segments. Must be larger or equal to 3.\n    num_segments = 14  # @param {type:\"slider\", min:3, max:30, step:1}\n    edit_template.num_segments = num_segments\n    # @markdown Half the cylinder length\n    half_length = 1  # @param {type:\"slider\", min:0.05, max:2.0, step:0.05}\n    edit_template.half_length = half_length\n    # @markdown Whether to cap each end of the cylinder\n    use_cap_ends = True  # @param {type:\"boolean\"}\n    edit_template.use_cap_ends = use_cap_ends\n    # @markdown Do you want to make a solid cylinder using your above modifications?\n    make_modified_solid_cylinder = True  # @param {type:\"boolean\"}\n    # if make is set to true, save modified template.\n    register_prim_template_if_valid(\n        make_modified_solid_cylinder,\n        edit_template,\n        solid_handles_to_use,\n        \"cylinderSolid\",\n    )\n\n\nedit_solid_cylinder(cylinder_solid_template)\n```\n\n----------------------------------------\n\nTITLE: Creating Simulator from Settings (make_simulator_from_settings)\nDESCRIPTION: This function creates a Habitat simulator instance from provided settings. It first calls `make_cfg` to create a configuration object. It then cleans up any existing simulator instance and initializes a new simulator. Additionally, it initializes object, primitive, and stage attribute managers, as well as a rigid object manager. It requires global variables `sim`, `obj_attr_mgr`, `prim_attr_mgr`, `stage_attr_mgr`, and `rigid_obj_mgr` to be properly initialized or handled.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef make_simulator_from_settings(sim_settings):\n    cfg = make_cfg(sim_settings)\n    # clean-up the current simulator instance if it exists\n    global sim\n    global obj_attr_mgr\n    global prim_attr_mgr\n    global stage_attr_mgr\n    global rigid_obj_mgr\n\n    if sim != None:\n        sim.close()\n    # initialize the simulator\n    sim = habitat_sim.Simulator(cfg)\n    # Managers of various Attributes templates\n    obj_attr_mgr = sim.get_object_template_manager()\n    obj_attr_mgr.load_configs(str(os.path.join(data_path, \"objects/example_objects\")))\n    prim_attr_mgr = sim.get_asset_template_manager()\n    stage_attr_mgr = sim.get_stage_template_manager()\n    # Manager providing access to rigid objects\n    rigid_obj_mgr = sim.get_rigid_object_manager()\n\n    # UI-populated handles used in various cells.  Need to initialize to valid\n    # value in case IPyWidgets are not available.\n    # Holds the user's desired file-based object template handle\n    global sel_file_obj_handle\n    sel_file_obj_handle = obj_attr_mgr.get_file_template_handles()[0]\n    # Holds the user's desired primitive-based object template handle\n    global sel_prim_obj_handle\n    sel_prim_obj_handle = obj_attr_mgr.get_synth_template_handles()[0]\n    # Holds the user's desired primitive asset template handle\n    global sel_asset_handle\n    sel_asset_handle = prim_attr_mgr.get_template_handles()[0]\n```\n\n----------------------------------------\n\nTITLE: Clutter Generation Script with NavMesh Integration\nDESCRIPTION: This script generates clutter by placing objects on the NavMesh. It initializes the random seed, positions the agent, scales the selected object based on user input, adds the object to the scene, and places it on the NavMesh.  After placing the objects, the script sets their motion type to STATIC, recomputes the NavMesh to include the static objects and runs a short simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n# @title Clutter Generation Script\n# @markdown Configure some example parameters:\n\nseed = 2  # @param {type:\"integer\"}\nrandom.seed(seed)\nsim.seed(seed)\nnp.random.seed(seed)\n\n# position the agent\nsim.agents[0].scene_node.translation = mn.Vector3(0.5, -1.60025, 6.15)\nprint(sim.agents[0].scene_node.rotation)\nagent_orientation_y = -23  # @param{type:\"integer\"}\nsim.agents[0].scene_node.rotation = mn.Quaternion.rotation(\n    mn.Deg(agent_orientation_y), mn.Vector3(0, 1.0, 0)\n)\n\nnum_objects = 10  # @param {type:\"slider\", min:0, max:20, step:1}\nobject_scale = 5  # @param {type:\"slider\", min:1.0, max:10.0, step:0.1}\n\n# scale up the selected object\nsel_obj_template_cpy = obj_attr_mgr.get_template_by_handle(sel_file_obj_handle)\nsel_obj_template_cpy.scale = mn.Vector3(object_scale)\nobj_attr_mgr.register_template(sel_obj_template_cpy, \"scaled_sel_obj\")\n\n# add the selected object\nsim.navmesh_visualization = True\nrigid_obj_mgr.remove_all_objects()\nfails = 0\nfor _obj in range(num_objects):\n    obj_1 = rigid_obj_mgr.add_object_by_template_handle(\"scaled_sel_obj\")\n\n    # place the object\n    placement_success = sample_object_state(\n        sim, obj_1, from_navmesh=True, maintain_object_up=True, max_tries=100\n    )\n    if not placement_success:\n        fails += 1\n        rigid_obj_mgr.remove_object_by_id(obj_1.object_id)\n    else:\n        # set the objects to STATIC so they can be added to the NavMesh\n        obj_1.motion_type = habitat_sim.physics.MotionType.STATIC\n\nprint(\"Placement fails = \" + str(fails) + \"/\" + str(num_objects))\n\n# recompute the NavMesh with STATIC objects\nnavmesh_settings = habitat_sim.NavMeshSettings()\nnavmesh_settings.set_defaults()\nnavmesh_settings.include_static_objects = True\nnavmesh_success = sim.recompute_navmesh(sim.pathfinder, navmesh_settings)\n\n# simulate and collect observations\nexample_type = \"clutter generation\"\nobservations = simulate(sim, dt=2.0)\nif make_video:\n    vut.make_video(\n        observations,\n        \"color_sensor_1st_person\",\n        \"color\",\n        output_path + example_type,\n        open_vid=show_video,\n    )\nobj_attr_mgr.remove_template_by_handle(\"scaled_sel_obj\")\nrigid_obj_mgr.remove_all_objects()\nsim.navmesh_visualization = False\n```\n\n----------------------------------------\n\nTITLE: Visualize Camera Coordinate Frame\nDESCRIPTION: This snippet visualizes the camera's local coordinate frame and approximate frustum. It draws the camera's local axes (right=red, up=green, forward=blue) at the camera's position and then draws lines representing the edges of the camera's frustum.  Finally, it displays the scene from a slightly offset camera position.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/coordinate_frame_tutorial.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# draw the previous camera's local axes\nlr.push_transform(camera_transform)\ndraw_axes(origin, axis_len=obj_axes_len)\n# draw some approximate edges of the previous camera's frustum\nfx = 2\nfy = 1.5\nfz = 4\nlr.draw_transformed_line(origin, mn.Vector3(-fx, -fy, -fz), white)\nlr.draw_transformed_line(origin, mn.Vector3(fx, -fy, -fz), white)\nlr.draw_transformed_line(origin, mn.Vector3(-fx, fy, -fz), white)\nlr.draw_transformed_line(origin, mn.Vector3(fx, fy, -fz), white)\nlr.pop_transform()\n\n# Show the scene from a position slightly offset from the previous camera.\neye_offset = mn.Vector3(0.5, 0.75, 1.75)\nshow_scene(calc_camera_transform(eye_translation=eye_pos0 + eye_offset, lookat=origin))\n```\n\n----------------------------------------\n\nTITLE: Initialize Agent and Set State\nDESCRIPTION: This snippet initializes the agent within the Habitat-sim environment using `sim.initialize_agent`. It then sets the agent's state, specifically its position in world space, using `agent.set_state`. Finally, it retrieves and prints the agent's updated state, including its position and rotation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# initialize an agent\nagent = sim.initialize_agent(sim_settings[\"default_agent\"])\n\n# Set agent state\nagent_state = habitat_sim.AgentState()\nagent_state.position = np.array([-0.6, 0.0, 0.0])  # in world space\nagent.set_state(agent_state)\n\n# Get agent state\nagent_state = agent.get_state()\nprint(\"agent_state: position\", agent_state.position, \"rotation\", agent_state.rotation)\n```\n\n----------------------------------------\n\nTITLE: Viewing HM3D Semantics with Habitat Viewer (C++)\nDESCRIPTION: This command shows how to view semantic annotations using the Habitat viewer. It requires Habitat-Sim to be compiled locally. The command takes the path to the HM3D annotation config JSON file using the `--dataset` argument and the scene ID as arguments. Ensure the viewer is built correctly (e.g., `./build/viewer`). Replace `<PATH TO HM3D>` with the actual path to your HM3D dataset.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_4\n\nLANGUAGE: C++\nCODE:\n```\n# ./build/viewer if compiled locally\nhabitat-viewer --dataset '<PATH TO HM3D>/hm3d_annotated_basis.scene_dataset_config.json' TEEsavR23oF\n```\n\n----------------------------------------\n\nTITLE: PhysicsManagerAttributes JSON Example\nDESCRIPTION: This JSON snippet shows an example configuration for PhysicsManagerAttributes.  It defines settings such as the physics simulator to use (e.g., \"bullet\" or \"none\"), gravity, timestep, and friction/restitution coefficients. These parameters configure the physics engine used in the simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/attributesJSON.rst#_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n.. include:: ../../data/test_assets/testing.physics_config.json\n    :code: json\n```\n\n----------------------------------------\n\nTITLE: Initializing Habitat Simulator\nDESCRIPTION: This snippet initializes the Habitat simulator with a given configuration. It ensures that any existing simulator instance is closed before creating a new one. It also places the agent in the environment and retrieves managers for primitive assets, physics objects, and rigid objects.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n    # [initialize]\n    # create the simulators AND resets the simulator\n\n    cfg = make_configuration()\n    try:  # Got to make initialization idiot proof\n        sim.close()\n    except NameError:\n        pass\n    sim = habitat_sim.Simulator(cfg)\n    agent_transform = place_agent(sim)\n\n    # get the primitive assets attributes manager\n    prim_templates_mgr = sim.get_asset_template_manager()\n\n    # get the physics object attributes manager\n    obj_templates_mgr = sim.get_object_template_manager()\n\n    # get the rigid object manager\n    rigid_obj_mgr = sim.get_rigid_object_manager()\n    # [/initialize]\n```\n\n----------------------------------------\n\nTITLE: Loading HM3D Semantics in Habitat-Sim with Python\nDESCRIPTION: This code snippet demonstrates how to load semantic annotations for HM3D in Habitat-Sim. It initializes a `SimulatorConfiguration`, sets the `scene_id` to the GLB file, and `scene_dataset_config_file` to the HM3D annotation config JSON file. It also configures a semantic sensor and adds it to the agent configuration.  Replace `<PATH TO HM3D>` with the actual path to your HM3D dataset.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nimport habitat_sim\n\nbackend_cfg = habitat_sim.SimulatorConfiguration()\nbackend_cfg.scene_id = \"<PATH TO HM3D>/minival/00800-TEEsavR23oF/TEEsavR23oF.basis.glb\"\nbackend_cfg.scene_dataset_config_file = \"<PATH TO HM3D>/hm3d_annotated_basis.scene_dataset_config.json\"\n\nsem_cfg = habitat_sim.CameraSensorSpec()\nsem_cfg.uuid = \"semantic\"\nsem_cfg.sensor_type = habitat_sim.SensorType.SEMANTIC\n\nagent_cfg = habitat_sim.agent.AgentConfiguration()\nagent_cfg.sensor_specifications = [sem_cfg]\n\nsim_cfg = habitat_sim.Configuration(backend_cfg, [agent_cfg])\nsim = habitat_sim.Simulator(sim_cfg)\n```\n\n----------------------------------------\n\nTITLE: Simulating with Camera Tracking (camera_track_simulate)\nDESCRIPTION: This function simulates the Habitat scene while having the camera track the center of mass (COM) of specified objects. It takes the simulator instance `sim`, a list of objects to track `objects`, simulation time `dt`, a flag to get frames `get_frames`, and the agent ID `agent_ID` as input.  It calculates the COM of the objects and adjusts the agent's rotation to look at the COM at each physics step. It returns a list of sensor observations during the simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# Simulate scene while having camera track COM of objects of interest\ndef camera_track_simulate(sim, objects, dt=2.0, get_frames=True, agent_ID=0):\n    start_time = sim.get_world_time()\n    observations = []\n    num_objs = len(objects)\n    if num_objs == 0:\n        print(\"camera_track_simulate : Aborting, no objects sent to track\")\n        return observations\n    agent = sim.get_agent(agent_ID)\n    # define up vector for tracking calc\n    up_vec = np.array([0, 1.0, 0])\n    # partition to speed up\n    time_step = 1.0 / 60.0\n    # process for multiple objects\n    while sim.get_world_time() - start_time < dt:\n        sim.step_physics(time_step)\n        # set agent state to look at object\n        camera_position = agent.scene_node.translation\n        camera_look_at = objects[0].translation\n        for i in range(1, num_objs):\n            camera_look_at += objects[i].translation\n        camera_look_at /= len(objects)\n        agent.scene_node.rotation = mn.Quaternion.from_matrix(\n            mn.Matrix4.look_at(camera_position, camera_look_at, up_vec).rotation()  # up\n        )\n        if get_frames:\n            observations.append(sim.get_sensor_observations())\n\n    return observations\n```\n\n----------------------------------------\n\nTITLE: Install Habitat-Sim (Headless)\nDESCRIPTION: This snippet shows how to install Habitat-Sim in headless mode, which is suitable for systems without an attached display, such as clusters.  This is achieved by passing the `--headless` flag to the `setup.py` script.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython setup.py install --headless\n```\n\n----------------------------------------\n\nTITLE: Loading Gfx Replay Keyframes (Habitat-Sim, Python)\nDESCRIPTION: Loads keyframes from a gfx replay file into a player object using Habitat-Sim's gfx_replay_manager.  The assert statement confirms successful loading. This is a crucial first step before playback.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nplayer = sim.gfx_replay_manager.read_keyframes_from_file(replay_filepath)\nassert player\n```\n\n----------------------------------------\n\nTITLE: Simulating Physics (simulate)\nDESCRIPTION: This function simulates the physics of a Habitat scene for a specified duration. It takes the simulator instance `sim` and simulation time `dt` as input. The function steps the physics simulation at a fixed rate (60Hz) and optionally captures sensor observations at each step if `get_frames` is True. It returns a list of sensor observations made during the simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef simulate(sim, dt=1.0, get_frames=True):\n    # simulate dt seconds at 60Hz to the nearest fixed timestep\n    print(\"Simulating \" + str(dt) + \" world seconds.\")\n    observations = []\n    start_time = sim.get_world_time()\n    while sim.get_world_time() < start_time + dt:\n        sim.step_physics(1.0 / 60.0)\n        if get_frames:\n            observations.append(sim.get_sensor_observations())\n    return observations\n```\n\n----------------------------------------\n\nTITLE: Visualize Rigid Object Coordinate Frame\nDESCRIPTION: This snippet adds two chair objects to the scene and visualizes their local coordinate frames.  It loads a chair object template, adds two instances of the chair to the scene, sets their poses (translation and rotation), and then uses `DebugLineRender` to draw the local axes of each object at their respective origins. The camera transform is saved for reuse.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/coordinate_frame_tutorial.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nrigid_obj_mgr = sim.get_rigid_object_manager()\nobj_template = os.path.join(\n    data_path, \"replica_cad/configs/objects/frl_apartment_chair_01.object_config.json\"\n)\n\n# add two chair objects to the scene\nobj0 = rigid_obj_mgr.add_object_by_template_handle(obj_template)\nobj1 = rigid_obj_mgr.add_object_by_template_handle(obj_template)\n\n# pose the first chair at the origin with identity rotation\nobj0.translation = mn.Vector3(0.0, 0.0, 0.0)\nobj0.rotation = mn.Quaternion()\n\n# pose the second chair with an arbitrary translation and rotation\nobj1.translation = mn.Vector3(1.1, 0.4, 1.2)\nup_axis = mn.Vector3(0, 1, 0)\nobj1.rotation = mn.Quaternion.rotation(mn.Deg(-60.0), up_axis) * mn.Quaternion.rotation(\n    mn.Deg(20.0), mn.Vector3(0, 0, 1)\n)\n\nfor obj in [obj0, obj1]:\n    # use DebugLineRender's push_transform to draw axes in each object's local coordinate frame.\n    lr.push_transform(obj.transformation)\n    draw_axes(origin, axis_len=obj_axes_len)\n    lr.pop_transform()\n\n# save the camera transform for use in the next block\ncamera_transform = calc_camera_transform(eye_translation=eye_pos0, lookat=origin)\nshow_scene(camera_transform)\n```\n\n----------------------------------------\n\nTITLE: Local Velocity Control in Habitat\nDESCRIPTION: This snippet demonstrates how to control an object's local velocity in Habitat Sim. It sets the linear and angular velocities in the object's local frame, enables local velocity control, simulates the environment, and generates a video. It utilizes the `velocity_control` property and sets `lin_vel_is_local` and `ang_vel_is_local` to True.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n    # [local_velocity_control]\n\n    vel_control.linear_velocity = [0.0, 0.0, 2.3]\n    vel_control.angular_velocity = [-4.3, 0.0, 0.0]\n    vel_control.lin_vel_is_local = True\n    vel_control.ang_vel_is_local = True\n\n    observations = simulate(sim, dt=1.5, get_frames=True)\n\n    # video rendering\n    if make_video:\n        vut.make_video(\n            observations,\n            \"rgba_camera_1stperson\",\n            \"color\",\n            output_path + \"local_velocity_control\",\n            open_vid=show_video,\n        )\n\n    # [/local_velocity_control]\n    rigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Adding Object with Specific Light Setup (Python)\nDESCRIPTION: This snippet demonstrates how to add an object to the scene using a specific light setup by passing the setup's name as a parameter to `Simulator.add_object`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_9\n\nLANGUAGE: py\nCODE:\n```\n# [example 6]\ncube_handle_3 = sim.load_object(\n    os.path.join(habitat_sim.sim.kTestAssetsDir, \"objects/cube.glb\"), \"my_second_lighting_setup\"\n)\n\ntrans = habitat_sim.utils.common.quat_from_coeffs([1, 0, 0, 0])\nsim.set_translation(np.array([3.5, 0.0, 0.5]), cube_handle_3)\nsim.set_rotation(trans, cube_handle_3)\n# [/example 6]\n```\n\n----------------------------------------\n\nTITLE: Retrieving Light Setup (Python)\nDESCRIPTION: This snippet demonstrates how to retrieve a copy of an existing light setup using `Simulator.get_light_setup`. This is useful for querying light properties or making small changes to an existing setup.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_10\n\nLANGUAGE: py\nCODE:\n```\n# [example 7]\nretrieved_lighting = sim.get_light_setup(\"my_second_lighting_setup\")\n\nprint(f\"The number of lights in this light setup is {len(retrieved_lighting.lights)}\")\n# [/example 7]\n```\n\n----------------------------------------\n\nTITLE: Recomputing NavMesh with Configuration\nDESCRIPTION: This code snippet demonstrates how to recompute the NavMesh at runtime using Habitat-Sim. It allows customization of NavMesh settings, including voxelization, agent parameters, filtering options, and detail mesh generation. The code also includes logic to update the agent state and display sensor observations and a top-down map.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n# @markdown ## Recompute NavMesh:\n\n# @markdown Take a moment to edit some parameters and visualize the resulting NavMesh. Consider agent_radius and agent_height as the most impactful starting point. Note that large variations from the defaults for these parameters (e.g. in the case of very small agents) may be better supported by additional changes to cell_size and cell_height.\nnavmesh_settings = habitat_sim.NavMeshSettings()\n\n# @markdown Choose Habitat-sim defaults (e.g. for point-nav tasks), or custom settings.\nuse_custom_settings = False  # @param {type:\"boolean\"}\nsim.navmesh_visualization = True  # @param {type:\"boolean\"}\nnavmesh_settings.set_defaults()\nif use_custom_settings:\n    # fmt: off\n    #@markdown ---\n    #@markdown ## Configure custom settings (if use_custom_settings):\n    #@markdown Configure the following NavMeshSettings for customized NavMesh recomputation.\n    #@markdown **Voxelization parameters**:\n    navmesh_settings.cell_size = 0.05 #@param {type:\"slider\", min:0.01, max:0.2, step:0.01}\n    #default = 0.05\n    navmesh_settings.cell_height = 0.2 #@param {type:\"slider\", min:0.01, max:0.4, step:0.01}\n    #default = 0.2\n\n    #@markdown **Agent parameters**:\n    navmesh_settings.agent_height = 1.5 #@param {type:\"slider\", min:0.01, max:3.0, step:0.01}\n    #default = 1.5\n    navmesh_settings.agent_radius = 0.1 #@param {type:\"slider\", min:0.01, max:0.5, step:0.01}\n    #default = 0.1\n    navmesh_settings.agent_max_climb = 0.2 #@param {type:\"slider\", min:0.01, max:0.5, step:0.01}\n    #default = 0.2\n    navmesh_settings.agent_max_slope = 45 #@param {type:\"slider\", min:0, max:85, step:1.0}\n    # default = 45.0\n    # fmt: on\n    # @markdown **Navigable area filtering options**:\n    navmesh_settings.filter_low_hanging_obstacles = True  # @param {type:\"boolean\"}\n    # default = True\n    navmesh_settings.filter_ledge_spans = True  # @param {type:\"boolean\"}\n    # default = True\n    navmesh_settings.filter_walkable_low_height_spans = True  # @param {type:\"boolean\"}\n    # default = True\n\n    # fmt: off\n    #@markdown **Detail mesh generation parameters**:\n    #@markdown For more details on the effects\n    navmesh_settings.region_min_size = 20 #@param {type:\"slider\", min:0, max:50, step:1}\n    #default = 20\n    navmesh_settings.region_merge_size = 20 #@param {type:\"slider\", min:0, max:50, step:1}\n    #default = 20\n    navmesh_settings.edge_max_len = 12.0 #@param {type:\"slider\", min:0, max:50, step:1}\n    #default = 12.0\n    navmesh_settings.edge_max_error = 1.3 #@param {type:\"slider\", min:0, max:5, step:0.1}\n    #default = 1.3\n    navmesh_settings.verts_per_poly = 6.0 #@param {type:\"slider\", min:3, max:6, step:1}\n    #default = 6.0\n    navmesh_settings.detail_sample_dist = 6.0 #@param {type:\"slider\", min:0, max:10.0, step:0.1}\n    #default = 6.0\n    navmesh_settings.detail_sample_max_error = 1.0 #@param {type:\"slider\", min:0, max:10.0, step:0.1}\n    # default = 1.0\n    # fmt: on\n\n    # @markdown **Include STATIC Objects**:\n    # @markdown Optionally include all instanced RigidObjects with STATIC MotionType as NavMesh constraints.\n    navmesh_settings.include_static_objects = True  # @param {type:\"boolean\"}\n    # default = False\n\nnavmesh_success = sim.recompute_navmesh(sim.pathfinder, navmesh_settings)\n\nif not navmesh_success:\n    print(\"Failed to build the navmesh! Try different parameters?\")\nelse:\n    # @markdown ---\n    # @markdown **Agent parameters**:\n\n    agent_state = sim.agents[0].get_state()\n    set_random_valid_state = False  # @param {type:\"boolean\"}\n    seed = 5  # @param {type:\"integer\"}\n    sim.seed(seed)\n    orientation = 0\n    if set_random_valid_state:\n        agent_state.position = sim.pathfinder.get_random_navigable_point()\n        orientation = random.random() * math.pi * 2.0\n    # @markdown Optionally configure the agent state (overrides random state):\n    set_agent_state = True  # @param {type:\"boolean\"}\n    try_to_make_valid = True  # @param {type:\"boolean\"}\n    if set_agent_state:\n        pos_x = 0  # @param {type:\"number\"}\n        pos_y = 0  # @param {type:\"number\"}\n        pos_z = 0.0  # @param {type:\"number\"}\n        # @markdown Y axis rotation (radians):\n        orientation = 1.56  # @param {type:\"number\"}\n        agent_state.position = np.array([pos_x, pos_y, pos_z])\n        if try_to_make_valid:\n            snapped_point = np.array(sim.pathfinder.snap_point(agent_state.position))\n            if not np.isnan(np.sum(snapped_point)):\n                print(\"Successfully snapped point to: \" + str(snapped_point))\n                agent_state.position = snapped_point\n    if set_agent_state or set_random_valid_state:\n        agent_state.rotation = utils.quat_from_magnum(\n            mn.Quaternion.rotation(-mn.Rad(orientation), mn.Vector3(0, 1.0, 0))\n        )\n        sim.agents[0].set_state(agent_state)\n\n    agent_state = sim.agents[0].get_state()\n    print(\"Agent state: \" + str(agent_state))\n    print(\" position = \" + str(agent_state.position))\n    print(\" rotation = \" + str(agent_state.rotation))\n    print(\" orientation (about Y) = \" + str(orientation))\n\n    observations = sim.get_sensor_observations()\n    rgb = observations[\"color_sensor\"]\n    semantic = observations[\"semantic_sensor\"]\n    depth = observations[\"depth_sensor\"]\n\n    if display:\n        display_sample(rgb, semantic, depth)\n        # @markdown **Map parameters**:\n        # fmt: off\n        meters_per_pixel = 0.025  # @param {type:\"slider\", min:0.01, max:0.1, step:0.005}\n        # fmt: on\n        agent_pos = agent_state.position\n        # topdown map at agent position\n        top_down_map = maps.get_topdown_map(\n            sim.pathfinder, height=agent_pos[1], meters_per_pixel=meters_per_pixel\n        )\n        recolor_map = np.array(\n            [[255, 255, 255], [128, 128, 128], [0, 0, 0]], dtype=np.uint8\n        )\n        top_down_map = recolor_map[top_down_map]\n        grid_dimensions = (top_down_map.shape[0], top_down_map.shape[1])\n        # convert world agent position to maps module grid point\n        agent_grid_pos = maps.to_grid(\n            agent_pos[2], agent_pos[0], grid_dimensions, pathfinder=sim.pathfinder\n        )\n        agent_forward = utils.quat_to_magnum(\n            sim.agents[0].get_state().rotation\n        ).transform_vector(mn.Vector3(0, 0, -1.0))\n        agent_orientation = math.atan2(agent_forward[0], agent_forward[2])\n        # draw the agent and trajectory on the map\n        maps.draw_agent(\n            top_down_map, agent_grid_pos, agent_orientation, agent_radius_px=8\n        )\n        print(\"\\nDisplay topdown map with agent:\")\n        display_map(top_down_map)\n```\n\n----------------------------------------\n\nTITLE: Converting 3D points to 2D topdown coordinates (Python)\nDESCRIPTION: This function, `convert_points_to_topdown`, converts 3D coordinates to 2D topdown coordinates for NavMesh visualization. It requires a `pathfinder` object and the `meters_per_pixel` resolution. It takes 3D points as input and returns a list of corresponding 2D topdown points.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# convert 3d points to 2d topdown coordinates\ndef convert_points_to_topdown(pathfinder, points, meters_per_pixel):\n    points_topdown = []\n    bounds = pathfinder.get_bounds()\n    for point in points:\n        # convert 3D x,z to topdown x,y\n        px = (point[0] - bounds[0][0]) / meters_per_pixel\n        py = (point[2] - bounds[0][2]) / meters_per_pixel\n        points_topdown.append(np.array([px, py]))\n    return points_topdown\n```\n\n----------------------------------------\n\nTITLE: Stepping Simulation and Retrieving Observations in Habitat-Sim (Python)\nDESCRIPTION: This snippet performs simulation steps by randomly choosing actions from the agent's action space and retrieves observations from the sensors (color, semantic, depth). It limits the total number of frames to `max_frames` and optionally displays the sensor data using `display_sample` if the `display` flag is set. It requires `habitat_sim` and a pre-configured simulator instance.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntotal_frames = 0\naction_names = list(cfg.agents[sim_settings[\"default_agent\"]].action_space.keys())\n\nmax_frames = 5\n\nwhile total_frames < max_frames:\n    action = random.choice(action_names)\n    print(\"action\", action)\n    observations = sim.step(action)\n    rgb = observations[\"color_sensor\"]\n    semantic = observations[\"semantic_sensor\"]\n    depth = observations[\"depth_sensor\"]\n\n    if display:\n        display_sample(rgb, semantic, depth)\n\n    total_frames += 1\n```\n\n----------------------------------------\n\nTITLE: SceneInstanceAttributes JSON configuration\nDESCRIPTION: This JSON snippet illustrates the structure of a SceneInstanceAttributes configuration file, defining a scene composed of a stage and multiple object instances with specific transformations and properties. It showcases how to specify the template name, motion type, translation, rotation, and other relevant attributes for objects and articulated objects within the scene.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/attributesJSON.rst#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"stage_instance\": {\n        \"template_name\": \"stages/frl_apartment_stage\"\n    },\n    \"default_lighting\": \"lighting/frl_apartment_stage\",\n    \"object_instances\": [\n        {\n            \"template_name\": \"objects/frl_apartment_basket\",\n            \"motion_type\": \"DYNAMIC\",\n            \"translation\": [\n                -1.9956579525706273,\n                1.0839370509764081,\n                0.057981376432922185\n            ],\n            \"rotation\": [\n                0.9846951961517334,\n                -5.20254616276361e-07,\n                0.17428532242774963,\n                3.540688453540497e-07\n            ]\n        },\n        ...\n    ],\n    \"articulated_object_instances\": [\n        {\n            \"template_name\": \"fridge\",\n            \"translation_origin\": \"COM\",\n            \"fixed_base\": true,\n            \"translation\": [\n                -2.1782121658325195,\n                0.9755649566650391,\n                3.2299728393554688\n            ],\n            \"rotation\": [\n                1,\n                0,\n                0,\n                0\n            ],\n            \"motion_type\": \"DYNAMIC\"\n        },\n        ...\n    ],\n    \"navmesh_instance\": \"empty_stage_navmesh\"\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying Wireframe Cylinder Template in Habitat-Sim (Python)\nDESCRIPTION: This code shows how to acquire and modify a default wireframe cylinder template. Attributes modified include the number of rings, segments, and half length.  The modifications are then registered using register_prim_template_if_valid.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_49\n\nLANGUAGE: python\nCODE:\n```\n# @title ####2.3.2 Wireframe Cylinder : { display-mode: \"form\" }\n# Acquire default template\ncylinder_wireframe_template = prim_attr_mgr.get_default_cylinder_template(True)\n\n\ndef edit_wireframe_cylinder(edit_template):\n    # @markdown Number of (face) rings. Must be larger or equal to 1.\n    num_rings = 1  # @param {type:\"slider\", min:1, max:10, step:1}\n    edit_template.num_rings = num_rings\n    # @markdown Number of (line) segments. Must be larger or equal to 4 and multiple of 4.\n    num_segments = 28  # @param {type:\"slider\", min:4, max:64, step:4}\n    edit_template.num_segments = num_segments\n    # @markdown Half the cylinder length\n    half_length = 0.7  # @param {type:\"slider\", min:0.05, max:2.0, step:0.05}\n    edit_template.half_length = half_length\n    # @markdown Do you want to make a wireframe cylinder using your above modifications?\n    make_modified_wireframe_cylinder = True  # @param {type:\"boolean\"}\n    # if make is set to true, save modified template.\n    register_prim_template_if_valid(\n        make_modified_wireframe_cylinder,\n        edit_template,\n        wireframe_handles_to_use,\n        \"cylinderWireframe\",\n    )\n\n\nedit_wireframe_cylinder(cylinder_wireframe_template)\n```\n\n----------------------------------------\n\nTITLE: PathFinder Closest Obstacle Point\nDESCRIPTION: Details the `habitat_sim.nav.PathFinder.closest_obstacle_surface_point` function. This function returns the hit position, hit normal, and hit distance of the surface point on the closest obstacle.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.nav.PathFinder.closest_obstacle_surface_point\n```\n\n----------------------------------------\n\nTITLE: Write Gfx Replay to File\nDESCRIPTION: Writes the saved gfx replay keyframes to a file and cleans up objects from the scene. Uses `sim.gfx_replay_manager.write_saved_keyframes_to_file` to write the replay data to a JSON file, and `rigid_obj_mgr.remove_all_objects()` to clear all objects.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsim.gfx_replay_manager.write_saved_keyframes_to_file(replay_filepath)\nassert os.path.exists(replay_filepath)\n\nrigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Build Options\nDESCRIPTION: This snippet defines several build options to control which features are included in the build. These options allow users to enable or disable features like Assimp support, Python bindings, GUI viewers, Bullet physics, background renderer, and tests.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\noption(BUILD_ASSIMP_SUPPORT \"Whether to build assimp import library support\" ON)\noption(BUILD_PYTHON_BINDINGS \"Whether to build python bindings\" ON)\noption(BUILD_GUI_VIEWERS \"Whether to build GUI viewer utility binary\" OFF)\noption(BUILD_WITH_BULLET\n       \"Build Habitat-Sim with Bullet physics enabled -- Requires Bullet\" OFF\n)\noption(BUILD_WITH_BACKGROUND_RENDERER \"Build Habitat-Sim with async rendering support.\"\n       ON\n)\noption(BUILD_TEST \"Build test binaries\" OFF)\noption(REL_BUILD_RPATH \"Use a relative build rpath\" OFF)\noption(USE_SYSTEM_ASSIMP \"Use system Assimp instead of a bundled submodule\" OFF)\noption(USE_SYSTEM_OPENEXR \"Use system OpenEXR instead of a bundled submodule\" OFF)\noption(USE_SYSTEM_EIGEN \"Use system Eigen instead of a bundled submodule\" OFF)\noption(USE_SYSTEM_GLFW \"Use system GLFW instead of a bundled submodule\" OFF)\noption(USE_SYSTEM_MAGNUM \"Use system Magnum instead of a bundled submodule\" OFF)\noption(USE_SYSTEM_PYBIND11 \"Use system Pybind11 instead of a bundled submodule\" OFF)\noption(USE_SYSTEM_RAPIDJSON \"Use system RapidJSON instead of a bundled submodule\" OFF)\noption(USE_SYSTEM_BULLET \"Use system Bullet instead of a bundled submodule\" OFF)\n# Zstd is used only by the BasisImporter plugin, if external Magnum is used it\n# doesn't need to be built at all.\ninclude(CMakeDependentOption)\ncmake_dependent_option(\n  USE_SYSTEM_ZSTD \"Use system zstd instead of a bundled submodule\" OFF\n  \"NOT USE_SYSTEM_MAGNUM\" ON\n)\noption(\n  BUILD_BASIS_COMPRESSOR\n  \"Wether or not to build the basis compressor.  Loading basis compressed meshes does NOT require this.\"\n  OFF\n)\noption(BUILD_WITH_AUDIO \"Build Habitat-Sim with Audio sensor\" OFF)\n```\n\n----------------------------------------\n\nTITLE: Object Configuration for Flat Shading (JSON)\nDESCRIPTION: This JSON configuration shows how to force flat shading for an object by setting the `force_flat_shading` property to true in the object's configuration file. This is useful for objects with baked-in illumination.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"render_asset\": \"my_object.glb\",\n    \"force_flat_shading\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Sampling Object State in Habitat-Sim (Python)\nDESCRIPTION: This function `sample_object_state` attempts to sample a random valid state (position and orientation) for a given object within a Habitat-Sim scene. It checks if the object is static and uses either the navmesh or a provided bounding box to sample a location. It also includes collision checks and ensures the object is placed above the navmesh if applicable. The function returns True if a valid placement is found, False otherwise.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef sample_object_state(\n    sim, obj, from_navmesh=True, maintain_object_up=True, max_tries=100, bb=None\n):\n    # check that the object is not STATIC\n    if obj.motion_type is habitat_sim.physics.MotionType.STATIC:\n        print(\"sample_object_state : Object is STATIC, aborting.\")\n    if from_navmesh:\n        if not sim.pathfinder.is_loaded:\n            print(\"sample_object_state : No pathfinder, aborting.\")\n            return False\n    elif not bb:\n        print(\n            \"sample_object_state : from_navmesh not specified and no bounding box provided, aborting.\"\n        )\n        return False\n    tries = 0\n    valid_placement = False\n    # Note: following assumes sim was not reconfigured without close\n    scene_collision_margin = stage_attr_mgr.get_template_by_id(0).margin\n    while not valid_placement and tries < max_tries:\n        tries += 1\n        # initialize sample location to random point in scene bounding box\n        sample_location = np.array([0, 0, 0])\n        if from_navmesh:\n            # query random navigable point\n            sample_location = sim.pathfinder.get_random_navigable_point()\n        else:\n            sample_location = np.random.uniform(bb.min, bb.max)\n        # set the test state\n        obj.translation = sample_location\n        if maintain_object_up:\n            # random rotation only on the Y axis\n            y_rotation = mn.Quaternion.rotation(\n                mn.Rad(random.random() * 2 * math.pi), mn.Vector3(0, 1.0, 0)\n            )\n            obj.rotation = y_rotation * obj.rotation\n        else:\n            # unconstrained random rotation\n            obj.rotation = ut.random_quaternion()\n\n        # raise object such that lowest bounding box corner is above the navmesh sample point.\n        if from_navmesh:\n            xform_bb = habitat_sim.geo.get_transformed_bb(obj.aabb, obj.transformation)\n            # also account for collision margin of the scene\n            obj.translation += mn.Vector3(\n                0, xform_bb.size_y() / 2.0 + scene_collision_margin, 0\n            )\n\n        # test for penetration with the environment\n        if not obj.contact_test():\n            valid_placement = True\n\n    if not valid_placement:\n        return False\n    return True\n```\n\n----------------------------------------\n\nTITLE: Loading YCB Assets in Python\nDESCRIPTION: This snippet shows how to load the YCB dataset into Habitat-Sim's `MetadataMediator` and then instance objects from the `ObjectAttributesManager`.  It requires setting the `active_dataset` property with the path to the YCB scene dataset configuration file. It depends on an initialized `sim` object representing the Habitat-Sim environment.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n#load the full YCB dataset into the MetadataMediator\nsim.metadata_mediator.active_dataset = \"/path/to/data/objects/ycb/ycb.scene_dataset_config.json\"\n\n#then instance objects from the ObjectAttributesManager:\nchef_can_key = sim.get_object_template_manager().get_file_template_handles(\"002_master_chef_can\")[0]\nchef_can_object = sim.get_rigid_object_manager().add_object_by_template_handle(chef_can_key)\n```\n\n----------------------------------------\n\nTITLE: Configure Semantic IDs in Habitat-Sim (Python)\nDESCRIPTION: This snippet configures and modifies semantic IDs for objects in Habitat-Sim using different methods. It demonstrates setting a default semantic ID via an object template, overriding it using the Simulator API, and directly modifying the semantic ID of specific SceneNodes. It relies on the `habitat_sim` library, object and scene node managers, and functions for creating a default settings and a simulator.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n# @markdown ###Configuring Object Semantic IDs:\n\nsim_settings = make_default_settings()\nsim_settings[\"scene\"] = os.path.join(\n    data_path, \"scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\"\n)\nsim_settings[\"sensor_pitch\"] = 0.0\nsim_settings[\"semantic_sensor_1st_person\"] = True\n\nmake_simulator_from_settings(sim_settings)\n\n# fmt: off\n# @markdown In this example, we load a box asset with each face as a separate component with its own SceneNode. We demonstrate the result of modiyfing the associated semantic ids via object templates, the Simulator API, and the SceneNode property.\n# fmt: on\n\nrigid_obj_mgr.remove_all_objects()\nobservations = []\n\n# @markdown Set the initial object orientation via local Euler angle (degrees):\norientation_x = 45  # @param {type:\"slider\", min:-180, max:180, step:1}\norientation_y = 45  # @param {type:\"slider\", min:-180, max:180, step:1}\norientation_z = 45  # @param {type:\"slider\", min:-180, max:180, step:1}\n\n\n# compose the rotations\nrotation_x = mn.Quaternion.rotation(mn.Deg(orientation_x), mn.Vector3(1.0, 0, 0))\nrotation_y = mn.Quaternion.rotation(mn.Deg(orientation_y), mn.Vector3(0, 1.0, 0))\nrotation_z = mn.Quaternion.rotation(mn.Deg(orientation_z), mn.Vector3(0, 0, 1.0))\nobject_orientation = rotation_z * rotation_y * rotation_x\nprint(object_orientation)\n\n# fmt: off\n# @markdown We can configure the semantic id in the object template. This id will be applied to the object (instead of the default 0) upon instantiation:\n# fmt: on\n\n# add a box with default semanticId configured in the template\n# Note: each face of this box asset is a separate component\nbox_template = habitat_sim.attributes.ObjectAttributes()\nbox_template.render_asset_handle = str(\n    os.path.join(data_path, \"test_assets/objects/transform_box.glb\")\n)\nbox_template.scale = np.array([0.2, 0.2, 0.2])\n# set the default semantic id for this object template\nbox_template.semantic_id = 10  # @param{type:\"integer\"}\nbox_template_id = obj_attr_mgr.register_template(box_template, \"box\")\n\nbox_obj = rigid_obj_mgr.add_object_by_template_id(box_template_id)\nset_object_state_from_agent(\n    sim, box_obj, mn.Vector3(0.0, 1.5, -0.75), orientation=object_orientation\n)\nobservations.append(sim.get_sensor_observations())\n# fmt: off\n# @markdown We can set the semantic id for all components of the object via the Simulator API at any time:\n# fmt: on\n# override the configured id with a new id\nbox_semantic_id_override = 20  # @param{type:\"integer\"}\nbox_obj.semantic_id = box_semantic_id_override\nobservations.append(sim.get_sensor_observations())\n\n# @markdown We can also set the semantic id for any single SceneNode directly:\n# set semantic id for specific SceneNode components of the box object\nbox_visual_nodes = box_obj.visual_scene_nodes\nbox_visual_nodes[6].semantic_id = 3  # @param{type:\"integer\"}\nbox_visual_nodes[7].semantic_id = 4  # @param{type:\"integer\"}\nobservations.append(sim.get_sensor_observations())\n\n# display the resulting observations:\nif display:\n    for obs in observations:\n        display_sample(\n            obs[\"color_sensor_1st_person\"],\n            semantic_obs=obs[\"semantic_sensor_1st_person\"],\n        )\nrigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Creating pybind11 Module\nDESCRIPTION: This snippet uses `pybind11_add_module` to create a Python module named `habitat_sim_bindings`. It specifies the source files (Bindings.h, Bindings.cpp, etc.) that will be used to generate the module. This module provides Python bindings for the C++ habitat-sim library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/bindings/CMakeLists.txt#_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\npybind11_add_module(\n  habitat_sim_bindings\n  Bindings.h\n  Bindings.cpp\n  AttributesBindings.cpp\n  AttributesManagersBindings.cpp\n  ConfigBindings.cpp\n  CoreBindings.cpp\n  GeoBindings.cpp\n  GfxBindings.cpp\n  MetadataMediatorBindings.cpp\n  GfxReplayBindings.cpp\n  OpaqueTypes.h\n  PhysicsBindings.cpp\n  PhysicsObjectBindings.cpp\n  PhysicsWrapperManagerBindings.cpp\n  SceneBindings.cpp\n  SensorBindings.cpp\n  ShortestPathBindings.cpp\n  SimBindings.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Habitat-Sim Agent Module\nDESCRIPTION: Provides an overview of the `habitat_sim.agent` module, including actions and references to `AgentConfiguration`, `AgentState`, and `SixDOFPose`. Mentions default and noisy actions, linking to relevant source code.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.agent\n```\n\n----------------------------------------\n\nTITLE: Scaling Object Template and Instantiating Objects\nDESCRIPTION: This snippet demonstrates how to scale an object template iteratively and instantiate multiple objects from the modified templates. It registers the modified templates with new handles and adds new objects to the scene at different offsets. Finally, it cleans up by removing the modified templates.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nobjs = [file_obj]\nfor i in range(5):\n    # Increase the template scale value (object size)\n    obj_template.scale *= 1.5\n    # Make a new handle for the modified template, so we don't overwrite\n    new_obj_template_handle = obj_template_handle + \"_new_\" + str(i)\n    # Register modified template with new handle, returns template ID\n    new_tmplt_id = obj_attr_mgr.register_template(obj_template, new_obj_template_handle)\n    # Object creation can occur using template ID or handle\n    if i % 2 == 0:\n        # Add another object instantiated by modified template using handle\n        new_obj = rigid_obj_mgr.add_object_by_template_id(new_tmplt_id)\n    else:\n        # Add another object instantiated by modified template using handle\n        new_obj = rigid_obj_mgr.add_object_by_template_handle(new_obj_template_handle)\n    # Move object to the right of previous object\n    offset[0] += 0.4\n    objs.append(new_obj)\n    set_object_state_from_agent(sim, new_obj, offset=offset)\n\n# Clean-up - remove modified templates from template library\n# Get all modified template handles through keyword search\nmod_template_handles = obj_attr_mgr.get_template_handles(\"_new_\")\n# Show number of modified templates\nprint(\n    \"Before delete, there are {} modified templates.\".format(len(mod_template_handles))\n)\n# Display modified template handles\nprint(*mod_template_handles, sep=\"\\n\")\n# Remove modified templates\nfor handle in mod_template_handles:\n    obj_attr_mgr.remove_template_by_handle(handle)\n# Verify removal - get template handles through keyword search\nmod_template_handles = obj_attr_mgr.get_template_handles(\"_new_\")\n# Show number of modified templates now\nprint(\n    \"After deleting added templates, there are {} modified templates.\".format(\n        len(mod_template_handles)\n    )\n)\n# Display modified template handles after delete\nprint(*mod_template_handles, sep=\"\\n\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Simulator and Loading Scene in Habitat Sim (Python)\nDESCRIPTION: This snippet initializes the Habitat simulator with default settings, loads the 'apartment_1' scene, sets the sensor pitch, and retrieves the object attributes manager. This sets the stage for object and primitive asset customization.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nsim_settings = make_default_settings()\nsim_settings[\"scene\"] = os.path.join(\n    data_path, \"scene_datasets/habitat-test-scenes/apartment_1.glb\"\n)\nsim_settings[\"sensor_pitch\"] = 0.0\n\nmake_simulator_from_settings(sim_settings)\n\n# Object Attributes Manager\nobj_attr_mgr = sim.get_object_template_manager()\n```\n\n----------------------------------------\n\nTITLE: Initializing Simulator for Object Retrieval Task in Python\nDESCRIPTION: This set of code initializes the Habitat-Sim simulator for an object retrieval task. It configures the simulator with a 3rd person camera view, modifies the 1st person sensor placement, and sets the scene. It also recomputes the navmesh with inflated agent parameters for collision avoidance.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_28\n\nLANGUAGE: python\nCODE:\n```\n# @title Embodied Continuous Navigation Example { display-mode: \"form\" }\n# @markdown This example cell runs the object retrieval task.\n\n# @markdown First the Simulator is re-initialized with:\n# @markdown - a 3rd person camera view\n# @markdown - modified 1st person sensor placement\nsim_settings = make_default_settings()\n# fmt: off\nsim_settings[\"scene\"] = os.path.join(data_path, \"scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\")  # @param{type:\"string\"}\n# fmt: on\nsim_settings[\"sensor_pitch\"] = 0.0\nsim_settings[\"sensor_height\"] = 0.6\nsim_settings[\"color_sensor_3rd_person\"] = True\nsim_settings[\"depth_sensor_1st_person\"] = True\nsim_settings[\"semantic_sensor_1st_person\"] = True\n\nmake_simulator_from_settings(sim_settings)\n\ndefault_nav_mesh_settings = habitat_sim.NavMeshSettings()\ndefault_nav_mesh_settings.set_defaults()\ninflated_nav_mesh_settings = habitat_sim.NavMeshSettings()\ninflated_nav_mesh_settings.set_defaults()\ninflated_nav_mesh_settings.agent_radius = 0.2\ninflated_nav_mesh_settings.agent_height = 1.5\nrecompute_successful = sim.recompute_navmesh(sim.pathfinder, inflated_nav_mesh_settings)\nif not recompute_successful:\n    print(\"Failed to recompute navmesh!\")\n```\n\n----------------------------------------\n\nTITLE: Setting Data Directories\nDESCRIPTION: This snippet sets variables for the data directory, scene datasets directory, and test assets directory. These variables are used to locate the project's data files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nset(DATA_DIR ${CMAKE_CURRENT_SOURCE_DIR}/../data)\nset(SCENE_DATASETS ${CMAKE_CURRENT_SOURCE_DIR}/../data/scene_datasets)\nset(TEST_ASSETS ${CMAKE_CURRENT_SOURCE_DIR}/../data/test_assets)\n```\n\n----------------------------------------\n\nTITLE: Define GUI Utility Functions\nDESCRIPTION: This code defines utility functions for building and managing IPyWidget interactive components. It includes event handlers for dropdowns displaying file-based object handles, prim-based object handles, and asset handles.  It also provides functions to create dropdown lists, buttons, simulate and make videos, and clear objects from the scene.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef on_file_obj_ddl_change(ddl_values):\n    global sel_file_obj_handle\n    sel_file_obj_handle = ddl_values[\"new\"]\n    return sel_file_obj_handle\n\n\ndef on_prim_obj_ddl_change(ddl_values):\n    global sel_prim_obj_handle\n    sel_prim_obj_handle = ddl_values[\"new\"]\n    return sel_prim_obj_handle\n\n\ndef on_prim_ddl_change(ddl_values):\n    global sel_asset_handle\n    sel_asset_handle = ddl_values[\"new\"]\n    return sel_asset_handle\n\n\ndef set_handle_ddl_widget(obj_handles, handle_types, sel_handle, on_change):\n    sel_handle = obj_handles[0]\n    descStr = handle_types + \" Template Handles:\"\n    style = {\"description_width\": \"300px\"}\n    obj_ddl = widgets.Dropdown(\n        options=obj_handles,\n        value=sel_handle,\n        description=descStr,\n        style=style,\n        disabled=False,\n        layout={\"width\": \"max-content\"},\n    )\n\n    obj_ddl.observe(on_change, names=\"value\")\n    return obj_ddl, sel_handle\n\n\ndef set_button_launcher(desc):\n    button = widgets.Button(\n        description=desc,\n        layout={\"width\": \"max-content\"},\n    )\n    return button\n\n\ndef make_sim_and_vid_button(prefix, dt=1.0):\n    if not HAS_WIDGETS:\n        return\n\n    def on_sim_click(b):\n        observations = simulate(sim, dt=dt)\n        vut.make_video(\n            observations,\n            \"color_sensor_1st_person\",\n            \"color\",\n            output_path + prefix,\n            open_vid=show_video,\n        )\n\n    sim_and_vid_btn = set_button_launcher(\"Simulate and Make Video\")\n    sim_and_vid_btn.on_click(on_sim_click)\n    ipydisplay(sim_and_vid_btn)\n\n\ndef make_clear_all_objects_button():\n    if not HAS_WIDGETS:\n        return\n\n    def on_clear_click(b):\n        rigid_obj_mgr.remove_all_objects()\n\n    clear_objs_button = set_button_launcher(\"Clear all objects\")\n    clear_objs_button.on_click(on_clear_click)\n    ipydisplay(clear_objs_button)\n\n\n# Builds widget-based UI components\ndef build_widget_ui(obj_attr_mgr, prim_attr_mgr):\n    # Holds the user's desired file-based object template handle\n    global sel_file_obj_handle\n    sel_file_obj_handle = \"\"\n\n    # Holds the user's desired primitive-based object template handle\n    global sel_prim_obj_handle\n    sel_prim_obj_handle = \"\"\n\n    # Holds the user's desired primitive asset template handle\n    global sel_asset_handle\n    sel_asset_handle = \"\"\n\n    # Construct DDLs and assign event handlers\n    # All file-based object template handles\n    file_obj_handles = obj_attr_mgr.get_file_template_handles()\n    # All primitive asset-based object template handles\n    prim_obj_handles = obj_attr_mgr.get_synth_template_handles()\n    # All primitive asset handles template handles\n    prim_asset_handles = prim_attr_mgr.get_template_handles()\n    # If not using widgets, set as first available handle\n    if not HAS_WIDGETS:\n        sel_file_obj_handle = file_obj_handles[0]\n        sel_prim_obj_handle = prim_obj_handles[0]\n        sel_asset_handle = prim_asset_handles[0]\n        return\n\n    # Build widgets\n    file_obj_ddl, sel_file_obj_handle = set_handle_ddl_widget(\n        file_obj_handles,\n        \"File-based Object\",\n        sel_file_obj_handle,\n        on_file_obj_ddl_change,\n    )\n    prim_obj_ddl, sel_prim_obj_handle = set_handle_ddl_widget(\n        prim_obj_handles,\n        \"Primitive-based Object\",\n        sel_prim_obj_handle,\n        on_prim_obj_ddl_change,\n    )\n    prim_asset_ddl, sel_asset_handle = set_handle_ddl_widget(\n        prim_asset_handles, \"Primitive Asset\", sel_asset_handle, on_prim_ddl_change\n    )\n    # Display DDLs\n    ipydisplay(file_obj_ddl)\n    ipydisplay(prim_obj_ddl)\n    ipydisplay(prim_asset_ddl)\n```\n\n----------------------------------------\n\nTITLE: Initializing Habitat Simulator and Loading Scene (Python)\nDESCRIPTION: This code initializes the Habitat simulator using default settings defined by `make_default_settings()` and then sets global simulation variables through `make_simulator_from_settings()`. This sets up the simulator environment for further interaction and simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# convenience functions defined in Utility cell manage global variables\nsim_settings = make_default_settings()\n# set globals: sim,\nmake_simulator_from_settings(sim_settings)\n```\n\n----------------------------------------\n\nTITLE: LightLayoutAttributes JSON Structure\nDESCRIPTION: This code snippet illustrates the structure of a LightLayoutAttributes JSON file used in Habitat-Sim for configuring light setups.  The 'lights' cell contains key-value pairs representing light IDs and their properties. Each property defines characteristics such as position, direction, color, intensity, and light type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/attributesJSON.rst#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"lights\": {\n    \"light_id_1\": {\n      \"position\": [1.0, 2.0, 3.0],\n      \"direction\": [0.0, -1.0, 0.0],\n      \"color\": [1.0, 1.0, 1.0],\n      \"intensity\": 2.0,\n      \"type\": \"point\",\n      \"position_model\": \"global\"\n    },\n    \"light_id_2\": {\n      \"position\": [4.0, 5.0, 6.0],\n      \"direction\": [0.0, -1.0, 0.0],\n      \"color\": [0.5, 0.5, 0.5],\n      \"intensity\": 1.5,\n      \"type\": \"directional\",\n      \"position_model\": \"camera\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Audio Sensor Spec\nDESCRIPTION: Demonstrates how to access the AudioSensorSpec within the habitat_sim module in Python. This spec is used to configure and add the audio sensor to the simulator. The acoustic sensor spec is part of habitat_sim.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/AUDIO.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport habitat_sim\n\nhabitat_sim.AudioSensorSpec()\n```\n\n----------------------------------------\n\nTITLE: Agent ObjectControls Constructor\nDESCRIPTION: Describes the constructor for the `habitat_sim.agent.ObjectControls` class, highlighting the `move_filter_fn` parameter. This function is applied after actions to handle collisions, typically using `nav.PathFinder.try_step`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.agent.ObjectControls.__init__\n```\n\n----------------------------------------\n\nTITLE: Physical Plausibility Experiment\nDESCRIPTION: This snippet simulates a physical plausibility experiment where a sphere is dropped onto a couch. Optionally, an invisible plane is introduced to create non-physical motion. It adds a sphere and optionally adds an invisible surface (cube) with a specific scale and visibility configuration. It then simulates the environment to observe the sphere's behavior.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\nintroduce_surface = True  # @param{type:\"boolean\"}\n\nrigid_obj_mgr.remove_all_objects()\n\n# add a rolling object\nobj_attr_mgr = sim.get_object_template_manager()\nsphere_handle = obj_attr_mgr.get_template_handles(\"uvSphereSolid\")[0]\nobj_1 = rigid_obj_mgr.add_object_by_template_handle(sphere_handle)\nset_object_state_from_agent(sim, obj_1, offset=np.array([1.0, 1.6, -1.95]))\n\nif introduce_surface:\n    # optionally add invisible surface\n    cube_handle = obj_attr_mgr.get_template_handles(\"cube\")[0]\n    cube_template_cpy = obj_attr_mgr.get_template_by_handle(cube_handle)\n    # Modify the template.\n    cube_template_cpy.scale = np.array([1.0, 0.04, 1.0])\n    surface_is_visible = False  # @param{type:\"boolean\"}\n    cube_template_cpy.is_visibile = surface_is_visible\n    # Register the modified template under a new name.\n    obj_attr_mgr.register_template(cube_template_cpy, \"invisible_surface\")\n\n    # Instance and place the surface object from the template.\n    surface_obj = rigid_obj_mgr.add_object_by_template_handle(\"invisible_surface\")\n    set_object_state_from_agent(sim, surface_obj, offset=np.array([0.4, 0.88, -1.6]))\n    surface_obj.motion_type = habitat_sim.physics.MotionType.STATIC\n\n\nexample_type = \"physical plausibility\"\nobservations = simulate(sim, dt=3.0)\nif make_video:\n    vut.make_video(\n        observations,\n        \"color_sensor_1st_person\",\n        \"color\",\n        output_path + example_type,\n        open_vid=show_video,\n    )\nrigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Object Placement Configuration\nDESCRIPTION: This code snippet configures the initial location and orientation of an object within the simulation environment. It uses slider widgets to define the object's offset from the agent and its orientation via Euler angles. It calculates the final orientation by composing rotations around the X, Y, and Z axes using quaternions.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\n# @markdown Configure the initial object location (local offset from the agent body node):\n# default : offset=np.array([0,2.0,-1.5]), orientation=np.quaternion(1,0,0,0)\noffset_x = 0.5  # @param {type:\"slider\", min:-2, max:2, step:0.1}\noffset_y = 1.4  # @param {type:\"slider\", min:0, max:3.0, step:0.1}\noffset_z = -1.5  # @param {type:\"slider\", min:-3, max:0, step:0.1}\noffset = np.array([offset_x, offset_y, offset_z])\n\n# @markdown Configure the initial object orientation via local Euler angle (degrees):\norientation_x = 0  # @param {type:\"slider\", min:-180, max:180, step:1}\norientation_y = 0  # @param {type:\"slider\", min:-180, max:180, step:1}\norientation_z = 0  # @param {type:\"slider\", min:-180, max:180, step:1}\n\n# compose the rotations\nrotation_x = mn.Quaternion.rotation(mn.Deg(orientation_x), mn.Vector3(1.0, 0, 0))\nrotation_y = mn.Quaternion.rotation(mn.Deg(orientation_y), mn.Vector3(1.0, 0, 0))\nrotation_z = mn.Quaternion.rotation(mn.Deg(orientation_z), mn.Vector3(1.0, 0, 0))\norientation = rotation_z * rotation_y * rotation_x\n```\n\n----------------------------------------\n\nTITLE: Initializing Habitat-Sim Simulator (Python)\nDESCRIPTION: This snippet initializes the Habitat-Sim simulator using the configuration created by `make_cfg`. It handles potential errors from out-of-order cell runs in Jupyter notebooks by attempting to close an existing simulator instance before creating a new one. It requires the `habitat_sim` library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ncfg = make_cfg(sim_settings)\n# Needed to handle out of order cell run in Jupyter\ntry:  # Got to make initialization idiot proof\n    sim.close()\nexcept NameError:\n    pass\nsim = habitat_sim.Simulator(cfg)\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for the io Module\nDESCRIPTION: This snippet defines a CMake variable `io_SOURCES` and assigns it a list of source files related to input/output operations. These files handle functionalities such as file reading/writing and JSON serialization/deserialization within the Habitat-Sim project. The listed files include C++ source and header files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_11\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  io_SOURCES\n  io/Io.cpp\n  io/Io.h\n  io/Json.cpp\n  io/Json.h\n  io/JsonAllTypes.h\n  io/JsonBuiltinTypes.h\n  io/JsonEspTypes.cpp\n  io/JsonEspTypes.h\n  io/JsonMagnumTypes.cpp\n  io/JsonMagnumTypes.h\n  io/JsonStlTypes.cpp\n  io/JsonStlTypes.h\n  io/JsonUtils.h\n)\n```\n\n----------------------------------------\n\nTITLE: Building Icosphere Attributes Dictionary in Python\nDESCRIPTION: This function builds a dictionary of attributes for an Icosphere primitive in Habitat-Sim. It takes an `icosphere_template` as input, retrieves the base attributes using `build_dict_of_prim_attrs`, and adds the `subdivisions` attribute to the dictionary. The function returns a dictionary where each attribute is mapped to a tuple containing its value, editability (True), and type (\"int\").\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Icosphere_prim_attrs(icosphere_template):\n    res_dict = build_dict_of_prim_attrs(icosphere_template)\n    res_dict[\"subdivisions\"] = (icosphere_template.subdivisions, True, \"int\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Initializing Simulator and Agent in Habitat-Sim (Python)\nDESCRIPTION: This snippet demonstrates the setup process, importing necessary modules, defining helper functions, and initializing the Simulator and Agent within Habitat-Sim. It's the initial step for setting up the environment and agent for subsequent lighting manipulations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_0\n\nLANGUAGE: py\nCODE:\n```\n # [setup]\nimport os\nimport random\n\nimport numpy as np\n\nimport habitat_sim\nfrom habitat_sim.utils.common import quat_from_two_vectors, quat_to_coeffs\n\ntry:\n    from PIL import Image  # type: ignore\nexcept ImportError:\n    print(\"Please install Pillow: pip install Pillow\")\n\ndef make_configuration():\n    # simulator configuration\n    backend_cfg = habitat_sim.SimulatorConfiguration()\n    backend_cfg.scene_id = os.path.join(\n        habitat_sim.sim.kTestAssetsDir, \"scenes/simple_apartment.glb\"\n    )\n    backend_cfg.enable_physics = True\n\n    # agent configuration\n    agent_cfg = habitat_sim.AgentConfiguration()\n\n    return habitat_sim.Configuration(backend_cfg, [agent_cfg])\n\n\ncfg = make_configuration()\nsim = habitat_sim.Simulator(cfg)\nagent = sim.initialize_agent(0)\n# [/setup]\n```\n\n----------------------------------------\n\nTITLE: Initializing Habitat-sim and dependencies\nDESCRIPTION: This snippet sets up the necessary paths and imports required libraries for Habitat-sim, including magnum, numpy, matplotlib, PIL, and habitat_sim itself. It also initializes global variables for the simulator and various managers, and handles widget dependencies.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Path Setup and Imports { display-mode: \"form\" }\n# @markdown (double click to show code).\n\n## [setup]\nimport math\nimport os\nimport random\n\nimport git\nimport magnum as mn\nimport numpy as np\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n\nimport habitat_sim\nfrom habitat_sim.utils import common as ut\nfrom habitat_sim.utils import viz_utils as vut\n\ntry:\n    import ipywidgets as widgets\n    from IPython.display import display as ipydisplay\n\n    # For using jupyter/ipywidget IO components\n\n    HAS_WIDGETS = True\nexcept ImportError:\n    HAS_WIDGETS = False\n\nrepo = git.Repo(\".\", search_parent_directories=True)\ndir_path = repo.working_tree_dir\ndata_path = os.path.join(dir_path, \"data\")\noutput_directory = \"examples/tutorials/interactivity_output/\"  # @param {type:\"string\"}\noutput_path = os.path.join(dir_path, output_directory)\nos.makedirs(output_path, exist_ok=True)\n\n# define some globals the first time we run.\nif \"sim\" not in globals():\n    global sim\n    sim = None\n    global obj_attr_mgr\n    obj_attr_mgr = None\n    global prim_attr_mgr\n    obj_attr_mgr = None\n    global stage_attr_mgr\n    stage_attr_mgr = None\n    global rigid_obj_mgr\n    rigid_obj_mgr = None\n```\n\n----------------------------------------\n\nTITLE: Loading and Configuring Robot with Navmesh Integration\nDESCRIPTION: This snippet shows how to load a robot asset (locobot), add it to the Habitat scene, and configure it for navigation using a navmesh. It involves loading the robot's template, setting its motion type to kinematic, and creating a `VelocityControl` object for manual control. It also showcases how to step the simulation while integrating the robot's movement with the navmesh, including collision detection and velocity randomization.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n    # [embodied_agent_navmesh]\n\n    # load the locobot_merged asset\n    locobot_template_id = obj_templates_mgr.load_configs(\n        str(os.path.join(data_path, \"objects/locobot_merged\"))\n    )[0]\n    # add robot object to the scene with the agent/camera SceneNode attached\n    locobot = rigid_obj_mgr.add_object_by_template_id(\n        locobot_template_id, sim.agents[0].scene_node\n    )\n    initial_rotation = locobot.rotation\n\n    # set the agent's body to kinematic since we will be updating position manually\n    locobot.motion_type = habitat_sim.physics.MotionType.KINEMATIC\n\n    # create and configure a new VelocityControl structure\n    # Note: this is NOT the object's VelocityControl, so it will not be consumed automatically in sim.step_physics\n    vel_control = habitat_sim.physics.VelocityControl()\n    vel_control.controlling_lin_vel = True\n    vel_control.lin_vel_is_local = True\n    vel_control.controlling_ang_vel = True\n    vel_control.ang_vel_is_local = True\n    vel_control.linear_velocity = [0.0, 0.0, -1.0]\n\n    # try 2 variations of the control experiment\n    for iteration in range(2):\n        # reset observations and robot state\n        observations = []\n        locobot.translation = [1.75, -1.02, 0.4]\n        locobot.rotation = initial_rotation\n        vel_control.angular_velocity = [0.0, 0.0, 0.0]\n\n        video_prefix = \"robot_control_sliding\"\n        # turn sliding off for the 2nd pass\n        if iteration == 1:\n            sim.config.sim_cfg.allow_sliding = False\n            video_prefix = \"robot_control_no_sliding\"\n\n        # manually control the object's kinematic state via velocity integration\n        start_time = sim.get_world_time()\n        last_velocity_set = 0\n        dt = 6.0\n        time_step = 1.0 / 60.0\n        while sim.get_world_time() < start_time + dt:\n            previous_rigid_state = locobot.rigid_state\n\n            # manually integrate the rigid state\n            target_rigid_state = vel_control.integrate_transform(\n                time_step, previous_rigid_state\n            )\n\n            # snap rigid state to navmesh and set state to object/agent\n            end_pos = sim.step_filter(\n                previous_rigid_state.translation, target_rigid_state.translation\n            )\n            locobot.translation = end_pos\n            locobot.rotation = target_rigid_state.rotation\n\n            # Check if a collision occurred\n            dist_moved_before_filter = (\n                target_rigid_state.translation - previous_rigid_state.translation\n            ).dot()\n            dist_moved_after_filter = (end_pos - previous_rigid_state.translation).dot()\n\n            # NB: There are some cases where ||filter_end - end_pos|| > 0 when a\n            # collision _didn't_ happen. One such case is going up stairs.  Instead,\n            # we check to see if the the amount moved after the application of the filter\n            # is _less_ than the amount moved before the application of the filter\n            EPS = 1e-5\n            collided = (dist_moved_after_filter + EPS) < dist_moved_before_filter\n\n            # run any dynamics simulation\n            sim.step_physics(time_step)\n\n            # render observation\n            observations.append(sim.get_sensor_observations())\n\n            # randomize angular velocity\n            last_velocity_set += time_step\n            if last_velocity_set >= 1.0:\n                vel_control.angular_velocity = [0.0, (random.random() - 0.5) * 2.0, 0.0]\n                last_velocity_set = 0\n\n        # video rendering with embedded 1st person views\n        if make_video:\n            sensor_dims = (\n                sim.get_agent(0).agent_config.sensor_specifications[0].resolution\n            )\n            overlay_dims = (int(sensor_dims[1] / 4), int(sensor_dims[0] / 4))\n            overlay_settings = [\n                {\n                    \"obs\": \"rgba_camera_1stperson\",\n                    \"type\": \"color\",\n                    \"dims\": overlay_dims,\n                    \"pos\": (10, 10),\n                    \"border\": 2,\n                },\n                {\n                    \"obs\": \"depth_camera_1stperson\",\n                    \"type\": \"depth\",\n                    \"dims\": overlay_dims,\n                    \"pos\": (10, 30 + overlay_dims[1]),\n                    \"border\": 2,\n                },\n            ]\n\n            vut.make_video(\n                observations=observations,\n                primary_obs=\"rgba_camera_3rdperson\",\n                primary_obs_type=\"color\",\n                video_file=output_path + video_prefix,\n                fps=60,\n                open_vid=show_video,\n                overlay_settings=overlay_settings,\n                depth_clip=10.0,\n            )\n\n    # [/embodied_agent_navmesh]\n```\n\n----------------------------------------\n\nTITLE: PbrShaderAttributes JSON Structure\nDESCRIPTION: This snippet showcases the structure of a PbrShaderAttributes JSON file used to configure PBR shader parameters in Habitat-Sim. It includes parameters for direct and indirect lighting, controlling aspects like intensity, texture mapping, tonemapping, and diffuse/specular scale. The configuration allows fine-tuning of the PBR shader for realistic rendering.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/attributesJSON.rst#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"enable_direct_lights\": true,\n  \"direct_light_intensity\": 1.0,\n  \"map_mat_txtr_to_linear\": true,\n  \"use_direct_tonemap\": false,\n  \"use_burley_diffuse\": true,\n  \"enable_ibl\": true,\n  \"ibl_blut_filename\": \"brdflut_ldr_512x512.png\",\n  \"ibl_envmap_filename\": \"brown_photostudio_02_1k.hdr\",\n  \"map_ibl_txtr_to_linear\": true,\n  \"use_ibl_tonemap\": true,\n  \"direct_diffuse_scale\": 0.5,\n  \"direct_specular_scale\": 0.5,\n  \"ibl_diffuse_scale\": 0.5,\n  \"ibl_specular_scale\": 0.5\n}\n```\n\n----------------------------------------\n\nTITLE: CUDA Build Option\nDESCRIPTION: This snippet defines a build option to enable CUDA support. If `BUILD_WITH_CUDA` is ON, it sets up the project to use CUDA and finds the CUDA runtime library. Otherwise, it configures the project without CUDA support.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\noption(BUILD_WITH_CUDA \"Build Habitat-Sim with CUDA features enabled -- Requires CUDA\"\n       OFF\n)\n\nif(BUILD_WITH_CUDA)\n  project(esp LANGUAGES C CXX CUDA)\n  find_library(CUDART_LIBRARY cudart ${CMAKE_CUDA_IMPLICIT_LINK_DIRECTORIES})\nelse()\n  project(esp LANGUAGES C CXX)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Building UVSphere Attributes Dictionary in Python\nDESCRIPTION: This function builds a dictionary of attributes for a UVSphere primitive in Habitat-Sim. It takes a `uvsphere_template` as input and retrieves the base attributes using `build_dict_of_prim_attrs`. It returns a dictionary where each attribute is mapped to a tuple containing its value, editability (True), and type (obtained from the base attributes).\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_UVSphere_prim_attrs(uvsphere_template):\n    res_dict = build_dict_of_prim_attrs(uvsphere_template)\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Defining Default Simulation Settings (make_default_settings)\nDESCRIPTION: This function defines default settings for the Habitat simulation. It sets the width, height, scene path, sensor height, sensor pitch, and enables/disables various sensors (color, depth, semantic). It returns a dictionary containing these settings, which can be used as input to `make_cfg` to configure the simulator. The function uses `os.path.join` and `data_path` which need to be available in the global scope.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef make_default_settings():\n    settings = {\n        \"width\": 720,  # Spatial resolution of the observations\n        \"height\": 544,\n        \"scene\": os.path.join(\n            data_path, \"scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\"\n        ),  # Scene path\n        \"scene_dataset\": os.path.join(\n            data_path, \"scene_datasets/mp3d_example/mp3d.scene_dataset_config.json\"\n        ),  # mp3d scene dataset\n        \"default_agent\": 0,\n        \"sensor_height\": 1.5,  # Height of sensors in meters\n        \"sensor_pitch\": -math.pi / 8.0,  # sensor pitch (x rotation in rads)\n        \"color_sensor_1st_person\": True,  # RGB sensor\n        \"color_sensor_3rd_person\": False,  # RGB sensor 3rd person\n        \"depth_sensor_1st_person\": False,  # Depth sensor\n        \"semantic_sensor_1st_person\": False,  # Semantic sensor\n        \"seed\": 1,\n        \"enable_physics\": True,  # enable dynamics simulation\n    }\n    return settings\n```\n\n----------------------------------------\n\nTITLE: Creating Stereo Agent in Habitat-Sim with Python\nDESCRIPTION: This code snippet demonstrates how to create a stereo agent in Habitat-Sim. It involves defining two sensors (RGB, depth, or semantic) with different positions and unique UUIDs, which are then attached to the agent configuration. This setup allows for simulating a stereo vision system.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/stereo-agent.rst#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport argparse\nimport os\nimport random\nimport sys\n\nimport numpy as np\n\nimport habitat_sim\nfrom habitat_sim.agent.agent_utils import (  # noqa: F401 is needed for string eval\n    AgentConfiguration,  # noqa: F401 is needed for string eval\n    get_agent_config,  # noqa: F401 is needed for string eval\n)\nfrom habitat_sim.sensors import SensorSpec, SensorType\n\ntry:\n    from PIL import Image\n\n    HAS_PIL = True\nexcept ImportError:\n    HAS_PIL = False\n\nDEFAULT_CFG = \"data/scene_datasets/habitat-test-scenes/apartment_1_debug.glb\"\n\ndef make_configuration(scene_file):\n    # Build the SensorSpec(s) that specify the sensor(s) to be used by the agent\n    # Create the left RGB sensor\n    left_rgb_sensor_spec = SensorSpec()\n    left_rgb_sensor_spec.uuid = \"left_eye_rgb\"\n    left_rgb_sensor_spec.sensor_type = SensorType.COLOR\n    left_rgb_sensor_spec.resolution = [640, 480]\n    left_rgb_sensor_spec.position = [0, 1.5, 0.2]\n    left_rgb_sensor_spec.orientation = [0.0, 0.0, 0.0]\n\n    # Create the right RGB sensor\n    right_rgb_sensor_spec = SensorSpec()\n    right_rgb_sensor_spec.uuid = \"right_eye_rgb\"\n    right_rgb_sensor_spec.sensor_type = SensorType.COLOR\n    right_rgb_sensor_spec.resolution = [640, 480]\n    right_rgb_sensor_spec.position = [0, 1.5, -0.2]\n    right_rgb_sensor_spec.orientation = [0.0, 0.0, 0.0]\n\n    agent_cfg = AgentConfiguration()\n    agent_cfg.sensor_specifications = [left_rgb_sensor_spec, right_rgb_sensor_spec]\n\n    return habitat_sim.Configuration(\n        [agent_cfg],\n        habitat_sim.SimulatorConfiguration()  # SimulatorConfiguration() {scene_id: ...}\n        # SimulatorConfiguration() {scene_dataset_config_file:..., scene_id: ...}\n        if scene_file == \"\" or scene_file is None\n        else habitat_sim.SimulatorConfiguration({\"scene_id\": scene_file})\n        if scene_file == \"\" or scene_file is None\n        else habitat_sim.SimulatorConfiguration(\n            {\"scene_dataset_config_file\": \"default\", \"scene_id\": scene_file}\n        ),\n    )\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--scene\",\n        default=DEFAULT_CFG,\n        help=\"Path to scene file or dataset defaults.scene_dataset_config_file\",\n    )\n    parser.add_argument(\n        \"--gfx-replay-prefix\",\n        type=str,\n        default=None,\n        help=\"Graphics replay output prefix. Default None\",\n    )\n\n    args = parser.parse_args()\n\n    if not habitat_sim.gfx.gfx_gl_initialized:\n        habitat_sim.gfx.gfx_gl_init()\n\n    cfg = make_configuration(args.scene)\n    sim = habitat_sim.Simulator(cfg)\n    sim.initialize_agent(0)  # Set initial state of agent 0.\n\n    # Reset the agent to a random valid state\n    sim.sample_navigable_location(sim.get_agent(0).get_state().position)\n\n    # Get stereo observations at the current position\n    observations = sim.get_sensor_observations()\n\n    # Show the left and right eye image\n    if HAS_PIL:\n        left_img = Image.fromarray(observations[\"left_eye_rgb\"])\n        right_img = Image.fromarray(observations[\"right_eye_rgb\"])\n\n        left_img.save(\"left_eye.png\")\n        right_img.save(\"right_eye.png\")\n        print(\"Saved left and right eye views to left_eye.png and right_eye.png\")\n    else:\n        print(\"Can't output images, PIL not installed.\")\n\n    if args.gfx_replay_prefix is not None:\n        # Dump the replayable state of the Simulator instance to a file.\n        print(f\"Dumping gfx replayable to {args.gfx_replay_prefix}.\")\n        sim.dump_state_gfx_replayable(args.gfx_replay_prefix)\n\n    sim.close()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Simulator Initialization and Configuration\nDESCRIPTION: Initializes the simulator with the configured settings, including enabling gfx replay. Configures lighting, initializes the agent, and sets the initial agent state.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--no-show-video\", dest=\"show_video\", action=\"store_false\")\n    parser.add_argument(\"--no-make-video\", dest=\"make_video\", action=\"store_false\")\n    parser.set_defaults(show_video=True, make_video=True)\n    args, _ = parser.parse_known_args()\n    show_video = args.show_video\n    make_video = args.make_video\n    make_video_during_sim = False\nelse:\n    show_video = False\n    make_video = False\n\nif make_video and not os.path.exists(output_path):\n    os.mkdir(output_path)\n\ncfg = make_configuration({\"make_video_during_sim\": make_video_during_sim})\nsim = None\nreplay_filepath = os.path.join(output_path, \"replay.json\")\n\nif not sim:\n    sim = habitat_sim.Simulator(cfg)\nelse:\n    sim.reconfigure(cfg)\n\nconfigure_lighting(sim)\n\nagent_state = habitat_sim.AgentState()\nagent = sim.initialize_agent(0, agent_state)\n```\n\n----------------------------------------\n\nTITLE: Building Cone Attributes Dictionary in Python\nDESCRIPTION: This function builds a dictionary of attributes for a Cone primitive in Habitat-Sim. It takes a `cone_template` as input, retrieves the base attributes using `build_dict_of_prim_attrs`, and adds the `use_cap_end` attribute to the dictionary. The function returns a dictionary where each attribute is mapped to a tuple containing its value, editability (True), and type (\"boolean\").\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Cone_prim_attrs(cone_template):\n    res_dict = build_dict_of_prim_attrs(cone_template)\n    res_dict[\"use_cap_end\"] = (cone_template.use_cap_end, True, \"boolean\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: habitat_sim.gfx.RenderTarget class documentation\nDESCRIPTION: This snippet documents the `habitat_sim.gfx.RenderTarget` class. This class represents a render target and exposes functionalities for rendering scenes to off-screen buffers. Refer to the C++ documentation for `esp::gfx::RenderTarget` for further details.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/gfx.rst#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. py:class:: habitat_sim.gfx.RenderTarget\n    :summary: Render target\n\n    See :dox:`esp::gfx::RenderTarget` for more information.\n```\n\n----------------------------------------\n\nTITLE: Initializing Habitat-sim and Dependencies (Python)\nDESCRIPTION: This snippet initializes necessary Python libraries, including Habitat-sim, Magnum, NumPy, and Matplotlib. It also sets up paths for data and output directories, and defines global variables related to the simulator and attribute managers. It checks for ipywidgets and sets a flag accordingly. It relies on the git library to locate the repository root.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport math\nimport os\nimport random\n\nimport git\nimport magnum as mn\nimport numpy as np\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n\nimport habitat_sim\nfrom habitat_sim.utils import common as ut\nfrom habitat_sim.utils import viz_utils as vut\n\ntry:\n    import ipywidgets as widgets\n    from IPython.display import display as ipydisplay\n\n    # For using jupyter/ipywidget IO components\n\n    HAS_WIDGETS = True\nexcept ImportError:\n    HAS_WIDGETS = False\n\nrepo = git.Repo(\".\", search_parent_directories=True)\ndir_path = repo.working_tree_dir\ndata_path = os.path.join(dir_path, \"data\")\n# fmt: off\noutput_directory = \"examples/tutorials/advanced_features_output/\"  # @param {type:\"string\"}\n# fmt: on\noutput_path = os.path.join(dir_path, output_directory)\nos.makedirs(output_path, exist_ok=True)\n\n# define some globals the first time we run.\nif \"sim\" not in globals():\n    global sim\n    sim = None\n    global obj_attr_mgr\n    obj_attr_mgr = None\n    global prim_attr_mgr\n    obj_attr_mgr = None\n    global stage_attr_mgr\n    stage_attr_mgr = None\n    global rigid_obj_mgr\n    rigid_obj_mgr = None\n```\n\n----------------------------------------\n\nTITLE: Initializing Simulator and Loading Scene\nDESCRIPTION: This snippet initializes the Habitat simulator with specified settings. It creates a default settings dictionary, sets the scene path to \"apartment_1.glb\", and sets the sensor pitch. Finally, it creates a simulator instance using the configured settings.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# @title Initialize Simulator and Load Scene { display-mode: \"form\" }\n# @markdown (load the apartment_1 scene for clutter generation in an open space)\nsim_settings = make_default_settings()\nsim_settings[\"scene\"] = os.path.join(\n    data_path, \"scene_datasets/habitat-test-scenes/apartment_1.glb\"\n)\nsim_settings[\"sensor_pitch\"] = 0.0\n\nmake_simulator_from_settings(sim_settings)\n```\n\n----------------------------------------\n\nTITLE: Building PhyObj Attributes Dictionary in Habitat-Sim\nDESCRIPTION: This function `build_dict_of_PhyObj_attrs` constructs a dictionary of attribute properties for a given physical object template (`phys_obj_template`). The dictionary includes attributes like scale, margin, friction coefficient, and asset handles. Each value is a tuple containing the attribute's value, a boolean indicating if it's editable, and the attribute's type (e.g., \"vector\", \"double\", \"string\", \"boolean\", \"int\"). It also builds from a base dictionary from `build_dict_of_Default_attrs`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_PhyObj_attrs(phys_obj_template):\n    res_dict = build_dict_of_Default_attrs(phys_obj_template)\n    res_dict[\"scale\"] = (phys_obj_template.scale, True, \"vector\")\n    res_dict[\"margin\"] = (phys_obj_template.margin, True, \"double\")\n    res_dict[\"friction_coefficient\"] = (\n        phys_obj_template.friction_coefficient,\n        True,\n        \"double\",\n    )\n    res_dict[\"restitution_coefficient\"] = (\n        phys_obj_template.restitution_coefficient,\n        True,\n        \"double\",\n    )\n    res_dict[\"render_asset_handle\"] = (\n        phys_obj_template.render_asset_handle,\n        True,\n        \"string\",\n    )\n    res_dict[\"collision_asset_handle\"] = (\n        phys_obj_template.collision_asset_handle,\n        True,\n        \"string\",\n    )\n    res_dict[\"force_flat_shading\"] = (\n        phys_obj_template.force_flat_shading,\n        True,\n        \"boolean\",\n    )\n    res_dict[\"shader_type\"] = (phys_obj_template.shader_type, True, \"int\")\n    res_dict[\"up\"] = (phys_obj_template.orient_up, True, \"vector\")\n    res_dict[\"front\"] = (phys_obj_template.orient_front, True, \"vector\")\n    res_dict[\"units_to_meters\"] = (phys_obj_template.units_to_meters, True, \"double\")\n    res_dict[\"render_asset_type\"] = (phys_obj_template.render_asset_type, True, \"int\")\n    res_dict[\"collision_asset_type\"] = (\n        phys_obj_template.collision_asset_type,\n        True,\n        \"int\",\n    )\n    # Read-only values\n    res_dict[\"render_asset_is_primitive\"] = (\n        phys_obj_template.render_asset_is_primitive,\n        False,\n        \"boolean\",\n    )\n    res_dict[\"collision_asset_is_primitive\"] = (\n        phys_obj_template.collision_asset_is_primitive,\n        False,\n        \"boolean\",\n    )\n    res_dict[\"use_mesh_for_collision\"] = (\n        phys_obj_template.use_mesh_for_collision,\n        False,\n        \"boolean\",\n    )\n    res_dict[\"is_collidable\"] = (phys_obj_template.is_collidable, True, \"boolean\")\n    res_dict[\"filenames_are_dirty\"] = (\n        phys_obj_template.filenames_are_dirty,\n        False,\n        \"boolean\",\n    )\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Building Cylinder Attributes Dictionary in Python\nDESCRIPTION: This function builds a dictionary of attributes for a Cylinder primitive in Habitat-Sim. It takes a `cylinder_template` as input, retrieves the base attributes using `build_dict_of_prim_attrs`, and adds the `use_cap_ends` attribute to the dictionary. The function returns a dictionary where each attribute is mapped to a tuple containing its value, editability (True), and type (\"boolean\").\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Cylinder_prim_attrs(cylinder_template):\n    res_dict = build_dict_of_prim_attrs(cylinder_template)\n    res_dict[\"use_cap_ends\"] = (cylinder_template.use_cap_ends, True, \"boolean\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Conditional Linking of OpenMP Library\nDESCRIPTION: This snippet conditionally links the OpenMP C++ library to the `habitat_sim` target if OpenMP is found.  It uses the `OpenMP_CXX_FOUND` variable to determine if OpenMP is available and links the `OpenMP::OpenMP_CXX` target.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_26\n\nLANGUAGE: cmake\nCODE:\n```\nif(OpenMP_CXX_FOUND)\n  target_link_libraries(habitat_sim PUBLIC OpenMP::OpenMP_CXX)\nendif()\n```\n\n----------------------------------------\n\nTITLE: RenderTarget RGBA Frame Read\nDESCRIPTION: Explains the `habitat_sim.gfx.RenderTarget.read_frame_rgba` function, which reads an RGBA frame into a provided `numpy.ndarray` in uint8 byte format. The function expects a pre-allocated array of the correct size.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.gfx.RenderTarget.read_frame_rgba\n```\n\n----------------------------------------\n\nTITLE: Object Configuration JSON Example\nDESCRIPTION: This snippet provides an example of an ObjectAttributes configuration file in JSON format. It shows how to define properties for rigid objects, such as their render asset. This is used for instancing rigid objects into Habitat-Sim.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/attributesJSON.rst#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n.. include:: ../../data/test_assets/objects/donut.object_config.json\n    :code: json\n```\n\n----------------------------------------\n\nTITLE: Configure Lighting\nDESCRIPTION: Defines a function to configure the lighting setup in the simulator. It sets up three global lights with specified vectors, colors, and models.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef configure_lighting(sim):\n    light_setup = [\n        LightInfo(\n            vector=[1.0, 1.0, 0.0, 1.0],\n            color=[18.0, 18.0, 18.0],\n            model=LightPositionModel.Global,\n        ),\n        LightInfo(\n            vector=[0.0, -1.0, 0.0, 1.0],\n            color=[5.0, 5.0, 5.0],\n            model=LightPositionModel.Global,\n        ),\n        LightInfo(\n            vector=[-1.0, 1.0, 1.0, 1.0],\n            color=[18.0, 18.0, 18.0],\n            model=LightPositionModel.Global,\n        ),\n    ]\n    sim.set_light_setup(light_setup)\n```\n\n----------------------------------------\n\nTITLE: Dynamic Control with Forces and Torques in Habitat\nDESCRIPTION: This snippet demonstrates dynamic control of objects in the Habitat simulator by applying forces and torques. It loads object templates, places multiple boxes in the scene, applies an anti-gravity force and torque to each box, and throws a sphere at the boxes. The simulation is stepped, and observations are collected for video generation. The code leverages `obj_templates_mgr`, `rigid_obj_mgr`, `apply_force`, and `apply_torque`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n    # [dynamic_control]\n\n    observations = []\n    obj_templates_mgr.load_configs(\n        str(os.path.join(data_path, \"objects/example_objects/\"))\n    )\n    # search for an object template by key sub-string\n    cheezit_template_handle = obj_templates_mgr.get_template_handles(\n        \"data/objects/example_objects/cheezit\"\n    )[0]\n    # build multiple object initial positions\n    box_positions = [\n        [2.39, -0.37, 0.0],\n        [2.39, -0.64, 0.0],\n        [2.39, -0.91, 0.0],\n        [2.39, -0.64, -0.22],\n        [2.39, -0.64, 0.22],\n    ]\n    box_orientation = mn.Quaternion.rotation(mn.Deg(90.0), [-1.0, 0.0, 0.0])\n    # instance and place the boxes\n    boxes = []\n    for b in range(len(box_positions)):\n        boxes.append(\n            rigid_obj_mgr.add_object_by_template_handle(cheezit_template_handle)\n        )\n        boxes[b].translation = box_positions[b]\n        boxes[b].rotation = box_orientation\n\n    # anti-gravity force f=m(-g) using first object's mass (all objects have the same mass)\n    anti_grav_force = -1.0 * sim.get_gravity() * boxes[0].mass\n\n    # throw a sphere at the boxes from the agent position\n    sphere_template = obj_templates_mgr.get_template_by_id(sphere_template_id)\n    sphere_template.scale = [0.5, 0.5, 0.5]\n\n    obj_templates_mgr.register_template(sphere_template)\n\n    # create sphere\n    sphere_obj = rigid_obj_mgr.add_object_by_template_id(sphere_template_id)\n\n    sphere_obj.translation = sim.agents[0].get_state().position + [0.0, 1.0, 0.0]\n    # get the vector from the sphere to a box\n    target_direction = boxes[0].translation - sphere_obj.translation\n    # apply an initial velocity for one step\n    sphere_obj.linear_velocity = target_direction * 5\n    sphere_obj.angular_velocity = [0.0, -1.0, 0.0]\n\n    start_time = sim.get_world_time()\n    dt = 3.0\n    while sim.get_world_time() < start_time + dt:\n        # set forces/torques before stepping the world\n        for box in boxes:\n            box.apply_force(anti_grav_force, [0.0, 0.0, 0.0])\n            box.apply_torque([0.0, 0.01, 0.0])\n        sim.step_physics(1.0 / 60.0)\n        observations.append(sim.get_sensor_observations())\n\n    if make_video:\n        vut.make_video(\n            observations,\n            \"rgba_camera_1stperson\",\n            \"color\",\n            output_path + \"dynamic_control\",\n            open_vid=show_video,\n        )\n\n    # [/dynamic_control]\n    rigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Modifying Default Light Setup in Habitat-Sim (Python)\nDESCRIPTION: This snippet modifies the default light setup by calling `Simulator.set_light_setup` with an empty key. This allows for achieving a desired illumination effect for newly added objects.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_6\n\nLANGUAGE: py\nCODE:\n```\n# [example 3]\ndefault_lighting = habitat_sim.gfx.LightSetup()\n\npoint_light_1 = habitat_sim.gfx.LightInfo()\npoint_light_1.color = np.array([0.5, 0.5, 0.5])\npoint_light_1.vector = np.array([0, 1, 0, 0.0])\npoint_light_1.range = 10\npoint_light_1.intensity = 1.0\ndefault_lighting.add_light(point_light_1)\n\npoint_light_2 = habitat_sim.gfx.LightInfo()\npoint_light_2.color = np.array([0.5, 0.0, 0.0])\npoint_light_2.vector = np.array([1, 1, 0, 0.0])\npoint_light_2.range = 10\npoint_light_2.intensity = 1.0\ndefault_lighting.add_light(point_light_2)\n\nsim.set_light_setup(default_lighting, \"\")\n\n# [/example 3]\n```\n\n----------------------------------------\n\nTITLE: Configure Habitat-Sim Logging Subsystems\nDESCRIPTION: Defines the grammar for configuring logging levels for individual Habitat-Sim subsystems via the HABITAT_SIM_LOG environment variable.  Allows setting different verbosity levels for different parts of the system, such as 'gfx', 'physics', or 'sim'.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/logging.rst#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nFilterString: SetLevelCommand (COLON SetLevelCommand)*\nSetLevelCommand: (SUBSYSTEM (COMMA SUBSYSTEM)* EQUALS)? LOGGING_LEVEL\n```\n\n----------------------------------------\n\nTITLE: Simulation Utility Function for Habitat-sim\nDESCRIPTION: This snippet defines a utility function called `simulate` that simulates the environment for a specified duration. It steps the physics simulation at a fixed timestep and collects sensor observations, returning a list of observations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ReplicaCAD_quickstart.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef simulate(sim, dt=1.0, get_frames=True):\n    # simulate dt seconds at 60Hz to the nearest fixed timestep\n    print(\"Simulating {:.3f} world seconds.\".format(dt))\n    observations = []\n    start_time = sim.get_world_time()\n    while sim.get_world_time() < start_time + dt:\n        sim.step_physics(1.0 / 60.0)\n        if get_frames:\n            observations.append(sim.get_sensor_observations())\n    return observations\n```\n\n----------------------------------------\n\nTITLE: Configuring Habitat Simulator\nDESCRIPTION: This function configures the Habitat simulator by defining backend settings (scene ID), and sensor specifications (camera resolution, position, orientation). It sets up two RGB cameras (1st and 3rd person) and a depth camera.  The scene ID specifies the environment to load. The agent configuration uses the defined sensor specifications.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef make_configuration():\n    # simulator configuration\n    backend_cfg = habitat_sim.SimulatorConfiguration()\n    backend_cfg.scene_id = os.path.join(\n        data_path, \"scene_datasets/habitat-test-scenes/apartment_1.glb\"\n    )\n    assert os.path.exists(backend_cfg.scene_id)\n\n    # sensor configurations\n    # Note: all sensors must have the same resolution\n    # setup 2 rgb sensors for 1st and 3rd person views\n    camera_resolution = [544, 720]\n    sensor_specs = []\n\n    rgba_camera_1stperson_spec = habitat_sim.CameraSensorSpec()\n    rgba_camera_1stperson_spec.uuid = \"rgba_camera_1stperson\"\n    rgba_camera_1stperson_spec.sensor_type = habitat_sim.SensorType.COLOR\n    rgba_camera_1stperson_spec.resolution = camera_resolution\n    rgba_camera_1stperson_spec.position = [0.0, 0.6, 0.0]\n    rgba_camera_1stperson_spec.orientation = [0.0, 0.0, 0.0]\n    rgba_camera_1stperson_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n    sensor_specs.append(rgba_camera_1stperson_spec)\n\n    depth_camera_1stperson_spec = habitat_sim.CameraSensorSpec()\n    depth_camera_1stperson_spec.uuid = \"depth_camera_1stperson\"\n    depth_camera_1stperson_spec.sensor_type = habitat_sim.SensorType.DEPTH\n    depth_camera_1stperson_spec.resolution = camera_resolution\n    depth_camera_1stperson_spec.position = [0.0, 0.6, 0.0]\n    depth_camera_1stperson_spec.orientation = [0.0, 0.0, 0.0]\n    depth_camera_1stperson_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n    sensor_specs.append(depth_camera_1stperson_spec)\n\n    rgba_camera_3rdperson_spec = habitat_sim.CameraSensorSpec()\n    rgba_camera_3rdperson_spec.uuid = \"rgba_camera_3rdperson\"\n    rgba_camera_3rdperson_spec.sensor_type = habitat_sim.SensorType.COLOR\n    rgba_camera_3rdperson_spec.resolution = camera_resolution\n    rgba_camera_3rdperson_spec.position = [0.0, 1.0, 0.3]\n    rgba_camera_3rdperson_spec.orientation = [-45.0, 0.0, 0.0]\n    rgba_camera_3rdperson_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n    sensor_specs.append(rgba_camera_3rdperson_spec)\n\n    # agent configuration\n    agent_cfg = habitat_sim.agent.AgentConfiguration()\n    agent_cfg.sensor_specifications = sensor_specs\n\n    return habitat_sim.Configuration(backend_cfg, [agent_cfg])\n```\n\n----------------------------------------\n\nTITLE: Define Observation Display Utility Function\nDESCRIPTION: This snippet defines a utility function `display_sample` that displays sensor observations using matplotlib. It takes RGB, semantic, and depth observations as input and displays them in a 1x3 grid. The function uses `PIL` for image manipulation and `habitat_sim.utils.common.d3_40_colors_rgb` for semantic image coloring. It includes an `if __name__ == '__main__'` block to handle command-line arguments for disabling display and video creation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef display_sample(rgb_obs, semantic_obs=np.array([]), depth_obs=np.array([])):\n    from habitat_sim.utils.common import d3_40_colors_rgb\n\n    rgb_img = Image.fromarray(rgb_obs, mode=\"RGBA\")\n\n    arr = [rgb_img]\n    titles = [\"rgb\"]\n    if semantic_obs.size != 0:\n        semantic_img = Image.new(\"P\", (semantic_obs.shape[1], semantic_obs.shape[0]))\n        semantic_img.putpalette(d3_40_colors_rgb.flatten())\n        semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n        semantic_img = semantic_img.convert(\"RGBA\")\n        arr.append(semantic_img)\n        titles.append(\"semantic\")\n\n    if depth_obs.size != 0:\n        depth_img = Image.fromarray((depth_obs / 10 * 255).astype(np.uint8), mode=\"L\")\n        arr.append(depth_img)\n        titles.append(\"depth\")\n\n    plt.figure(figsize=(12, 8))\n    for i, data in enumerate(arr):\n        ax = plt.subplot(1, 3, i + 1)\n        ax.axis(\"off\")\n        ax.set_title(titles[i])\n        plt.imshow(data)\n    plt.show(block=False)\n\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--no-display\", dest=\"display\", action=\"store_false\")\n    parser.add_argument(\"--no-make-video\", dest=\"make_video\", action=\"store_false\")\n    parser.set_defaults(show_video=True, make_video=True)\n    args, _ = parser.parse_known_args()\n    show_video = args.display\n    display = args.display\n    do_make_video = args.make_video\nelse:\n    show_video = False\n    do_make_video = False\n    display = False\n\n# import the maps module alone for topdown mapping\nif display:\n    from habitat.utils.visualizations import maps\n```\n\n----------------------------------------\n\nTITLE: Object Template Modification in Detail\nDESCRIPTION: This snippet demonstrates detailed modification of object template attributes such as mass, scale, center of mass (COM), collision margin, friction, restitution, shading, inertia, damping, and collision mesh settings. It clears existing objects, saves the initial camera state, and uses sliders to set the attribute values before registering the modified template and creating an object instance.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_36\n\nLANGUAGE: python\nCODE:\n```\n# clear all objects and observations\nrigid_obj_mgr.remove_all_objects()\nobservations = []\n# save initial camera state for tracking\ninit_config = init_camera_track_config(sim)\n\n# @markdown ###Editable fields in Object Templates :\n# Get a new template\nnew_template = obj_attr_mgr.get_template_by_handle(sel_file_obj_handle)\n\n# These are all the available attributes and their values for this object\nshow_template_properties(new_template)\n\n# @markdown The desired mass of the object\nmass = 1.0  # @param {type:\"slider\", min:0.1, max:50, step:0.1}\nnew_template.mass = mass\n\n# @markdown The x,y,z components for the scale of the object.\nscale_X = 2  # @param {type:\"slider\", min:0.1, max:10, step:0.1}\nscale_Y = 8  # @param {type:\"slider\", min:0.1, max:10, step:0.1}\nscale_Z = 2  # @param {type:\"slider\", min:0.1, max:10, step:0.1}\nnew_template.scale = mn.Vector3(scale_X, scale_Y, scale_Z)\n\n# @markdown The x,y,z components for the desired location of the center of mass.\ncom_X = 0  # @param {type:\"slider\", min:-1.0, max:1, step:0.1}\ncom_Y = 0  # @param {type:\"slider\", min:-1.0, max:1, step:0.1}\ncom_Z = 0  # @param {type:\"slider\", min:-1.0, max:1, step:0.1}\nnew_template.com = mn.Vector3(com_X, com_Y, com_Z)\n\n# @markdown If true, simulator sets COM as center of bounding box, and ignores any specified COM.\ncompute_COM_from_shape = False  # @param {type:\"boolean\"}\nnew_template.compute_COM_from_shape = compute_COM_from_shape\n\n# @markdown Sets the collision margin\nmargin = 0.4  # @param {type:\"slider\", min:0.0, max:10, step:0.1}\nnew_template.margin = margin\n\n# @markdown Friction for object contact\nfriction_coefficient = 0.5  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\nnew_template.friction_coefficient = friction_coefficient\n\n# @markdown Fraction of original relative velocity retained by an object after contact.  1 is perfectly elastic contact.\nrestitution_coefficient = 0.3  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\nnew_template.restitution_coefficient = restitution_coefficient\n\n# @markdown Whether the object should be lit via Phong shading.\nforce_flat_shading = True  # @param {type:\"boolean\"}\nnew_template.force_flat_shading = force_flat_shading\n\n# @markdown The x,y,z components of the intertia matrix diagonal\n\ninertia_X = 1.0  # @param {type:\"slider\", min:0.1, max:10, step:0.1}\ninertia_Y = 1  # @param {type:\"slider\", min:0.1, max:10, step:0.1}\ninertia_Z = 1.0  # @param {type:\"slider\", min:0.1, max:10, step:0.1}\nnew_template.inertia = mn.Vector3(inertia_X, inertia_Y, inertia_Z)\n\n# @markdown Rate of linear momentum dissipation\nlinear_damping = 0.1  # @param {type:\"slider\", min:0.0, max:5.0, step:0.1}\nnew_template.linear_damping = linear_damping\n\n# @markdown Rate of angular momentum dissipation\nangular_damping = 0.2  # @param {type:\"slider\", min:0.0, max:5.0, step:0.1}\n\nnew_template.angular_damping = angular_damping\n\n# @markdown Use bounding box for collision instead of collision mesh.\nbounding_box_collisions = False  # @param {type:\"boolean\"}\nnew_template.bounding_box_collisions = bounding_box_collisions\n\n# @markdown Whether compound collision meshes should be merged into a single convex hull.\njoin_collision_meshes = False  # @param {type:\"boolean\"}\nnew_template.join_collision_meshes = join_collision_meshes\n\n# Construct a new handle to save this template with\nnew_template_handle = sel_file_obj_handle + \"_new\"\n\n\n# register new template and get its new id\nnew_template_id = obj_attr_mgr.register_template(new_template, new_template_handle)\n\n\n# Add object instantiated by original template using template handle\noriginal_template = obj_attr_mgr.get_template_by_handle(sel_file_obj_handle)\norig_obj = rigid_obj_mgr.add_object_by_template_handle(original_template.handle)\n\n# Set desired offset from agent location to place object\noffset = np.array([-0.5, 0.3, -1.5])\n# Move object to be in front of the agent\nset_object_state_from_agent(sim, orig_obj, offset=offset)\n\n# Add new object instantiated by desired template using template handle\nnew_obj = rigid_obj_mgr.add_object_by_template_id(new_template_id)\n\n# Set desired offset from agent location to place object\noffset[0] += 1.0\n# Move object to be in front of the agent\nset_object_state_from_agent(sim, new_obj, offset=offset)\n```\n\n----------------------------------------\n\nTITLE: Object Permanence Task Simulation\nDESCRIPTION: This snippet sets up an object permanence task where two objects are dropped behind an occluder, and one object is removed while occluded. It adds two objects, places them in the environment, creates an occluder using a scaled cube primitive, and simulates the environment. During simulation, it checks if the second object has passed the occluder's center and removes it if it has.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nrigid_obj_mgr.remove_all_objects()\n\n# @markdown 1. Add the two dynamic objects.\n# add the selected objects\nobj_1 = rigid_obj_mgr.add_object_by_template_handle(sel_file_obj_handle)\nobj_2 = rigid_obj_mgr.add_object_by_template_handle(sel_file_obj_handle)\n\n# place the objects\nset_object_state_from_agent(\n    sim, obj_1, offset=np.array([0.5, 2.0, -1.0]), orientation=ut.random_quaternion()\n)\nset_object_state_from_agent(\n    sim,\n    obj_2,\n    offset=np.array([-0.5, 2.0, -1.0]),\n    orientation=ut.random_quaternion(),\n)\n\n# @markdown 2. Configure and add an occluder from a scaled cube primitive.\n# Get a default cube primitive template\ncube_handle = obj_attr_mgr.get_template_handles(\"cube\")[0]\ncube_template_cpy = obj_attr_mgr.get_template_by_handle(cube_handle)\n# Modify the template's configured scale.\ncube_template_cpy.scale = np.array([0.32, 0.075, 0.01])\n# Register the modified template under a new name.\nobj_attr_mgr.register_template(cube_template_cpy, \"occluder_cube\")\n# Instance and place the occluder object from the template.\noccluder_obj = rigid_obj_mgr.add_object_by_template_handle(\"occluder_cube\")\nset_object_state_from_agent(sim, occluder_obj, offset=np.array([0.0, 1.4, -0.4]))\noccluder_obj.motion_type = habitat_sim.physics.MotionType.KINEMATIC\n# fmt off\n# @markdown 3. Simulate at 60Hz, removing one object when it's center of mass drops below that of the occluder.\n# fmt on\n# Simulate and remove object when it passes the midpoint of the occluder\ndt = 2.0\nprint(\"Simulating \" + str(dt) + \" world seconds.\")\nobservations = []\n# simulate at 60Hz to the nearest fixed timestep\nstart_time = sim.get_world_time()\n\nwhile sim.get_world_time() < start_time + dt:\n    sim.step_physics(1.0 / 60.0)\n    # remove the object once it passes the occluder center and it still exists/hasn't already been removed\n    if obj_2.is_alive and obj_2.translation[1] <= occluder_obj.translation[1]:\n        rigid_obj_mgr.remove_object_by_id(obj_2.object_id)\n    observations.append(sim.get_sensor_observations())\n\nexample_type = \"object permanence\"\nif make_video:\n    vut.make_video(\n        observations,\n        \"color_sensor_1st_person\",\n        \"color\",\n        output_path + example_type,\n        open_vid=show_video,\n    )\nrigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Default Simulator Settings\nDESCRIPTION: Documents `habitat_sim.utils.settings.default_sim_settings`, a quickstart settings dictionary that can be passed to `settings.make_cfg()` to create a default configuration for an empty scene. The settings can be edited for customization.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_16\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.utils.settings.default_sim_settings\n```\n\n----------------------------------------\n\nTITLE: Linking Magnum Windowless Application\nDESCRIPTION: Links the Magnum WindowlessApplication library to the habitat_sim target. This library provides an application class that does not require a window, making it suitable for headless rendering or simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_27\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_link_libraries(\n  habitat_sim\n  PUBLIC Magnum::WindowlessApplication\n)\n```\n\n----------------------------------------\n\nTITLE: Stage Configuration JSON Example\nDESCRIPTION: This snippet provides an example of a StageAttributes configuration file in JSON format. It defines the render and collision assets, frame of reference, and physical properties of a stage object.  It shows an example of configuring static mesh components making up the backdrop of a Scene within Habitat-Sim.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/attributesJSON.rst#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n.. include:: ../../data/test_assets/scenes/stage_floor1.stage_config.json\n    :code: json\n```\n\n----------------------------------------\n\nTITLE: Running Habitat Viewer with Physics C++\nDESCRIPTION: This command starts the Habitat-Sim viewer with physics enabled, loading a ReplicaCAD scene. It requires the `--enable-physics` flag, the `--dataset` argument pointing to the scene dataset config JSON, and the `--scene` argument specifying the scene to load (e.g., `apt_1`).\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n#C++\n# ./build/viewer if compiling locally\nhabitat-viewer --enable-physics --dataset data/replica_cad/replicaCAD.scene_dataset_config.json -- apt_1\n```\n\n----------------------------------------\n\nTITLE: Building PhysicsSim Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_PhysicsSim_attrs` constructs a dictionary of attribute properties for a given physics manager template (`physics_template`). This includes attributes like gravity, timestep, and substep settings. It extends the base attributes using `build_dict_of_Default_attrs`.  Each attribute value is a tuple containing the attribute's value, whether it's editable, and its type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_PhysicsSim_attrs(physics_template):\n    res_dict = build_dict_of_Default_attrs(physics_template)\n    res_dict[\"gravity\"] = (physics_template.gravity, True, \"vector\")\n    res_dict[\"timestep\"] = (physics_template.timestep, True, \"double\")\n    res_dict[\"max_substeps\"] = (physics_template.max_substeps, True, \"int\")\n    res_dict[\"friction_coefficient\"] = (\n        physics_template.friction_coefficient,\n        True,\n        \"double\",\n    )\n    res_dict[\"restitution_coefficient\"] = (\n        physics_template.restitution_coefficient,\n        True,\n        \"double\",\n    )\n    # Read-only values\n    res_dict[\"simulator\"] = (physics_template.simulator, False, \"string\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Setting RPATH\nDESCRIPTION: This snippet configures the rpath (runtime search path) for the built binaries. It sets the appropriate rpath based on whether it's an Apple platform and whether a relative rpath is requested. The rpath is used to locate shared libraries at runtime.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_8\n\nLANGUAGE: cmake\nCODE:\n```\n# Properly set the rpath in a cross-platform way\nif(APPLE)\n  set(CMAKE_MACOSX_RPATH ON)\n  set(_rpath_portable_origin \"@loader_path\")\nelse()\n  set(_rpath_portable_origin $ORIGIN)\nendif(APPLE)\nset(CMAKE_SKIP_BUILD_RPATH FALSE)\nif(REL_BUILD_RPATH)\n  message(\"Using relative rpath\")\n  set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE)\n  set(CMAKE_INSTALL_RPATH_USE_LINK_PATH TRUE)\n  #_magnum.so needs to look at habitat_sim/_ext for its corrade dependencies\n  set(CMAKE_INSTALL_RPATH \"${_rpath_portable_origin}\"\n                          \"${_rpath_portable_origin}/habitat_sim/_ext/\"\n  )\nelse()\n  message(\"Using absolute rpath\")\n  # Set to defaults\n  set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE)\n  set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE)\n  set(CMAKE_INSTALL_RPATH \"\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Turn off non-critical logging (Habitat-Sim >= 0.2.2)\nDESCRIPTION: Sets environment variables to suppress non-critical logging in Habitat-Sim versions 0.2.2 and later. It configures both Magnum and Habitat-Sim logging to the 'quiet' level.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/logging.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nexport MAGNUM_LOG=quiet HABITAT_SIM_LOG=quiet\n```\n\n----------------------------------------\n\nTITLE: Define Template Dictionary Utility Functions (Python)\nDESCRIPTION: These utility functions build dictionaries of attribute property names and values for various Habitat-sim template types (Default, PhyObj, Object, Stage, PhysicsSim, prim, Capsule_prim). The values in the dictionary are tuples containing the value, editability status, and type of the property. These dictionaries expose Attribute template object properties for examination and potential modification.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# This method builds a dictionary of k-v pairs of attribute property names and\n# values shared by all attribute template types.  The values are tuples with the\n# first entry being the value and the second being whether the property is\n# editable and the third being the type.\ndef build_dict_of_Default_attrs(template):\n    res_dict = {\n        \"handle\": (template.handle, True, \"string\"),\n        # Read-only values\n        \"template_id\": (template.template_id, False, \"int\"),\n        \"template_class\": (template.template_class, False, \"string\"),\n        \"file_directory\": (template.file_directory, False, \"string\"),\n    }\n    return res_dict\n\n\n# This method builds a dictionary of k-v pairs of attribute property names and\n# values shared by templates of physically modeled constructs (scenes and\n# objects). The values are tuples with the first entry being the value and the\n# second being whether the property is editable and the third being the type.\ndef build_dict_of_PhyObj_attrs(phys_obj_template):\n    res_dict = build_dict_of_Default_attrs(phys_obj_template)\n    res_dict[\"scale\"] = (phys_obj_template.scale, True, \"vector\")\n    res_dict[\"margin\"] = (phys_obj_template.margin, True, \"double\")\n    res_dict[\"friction_coefficient\"] = (\n        phys_obj_template.friction_coefficient,\n        True,\n        \"double\",\n    )\n    res_dict[\"restitution_coefficient\"] = (\n        phys_obj_template.restitution_coefficient,\n        True,\n        \"double\",\n    )\n    res_dict[\"render_asset_handle\"] = (\n        phys_obj_template.render_asset_handle,\n        True,\n        \"string\",\n    )\n    res_dict[\"collision_asset_handle\"] = (\n        phys_obj_template.collision_asset_handle,\n        True,\n        \"string\",\n    )\n    res_dict[\"force_flat_shading\"] = (\n        phys_obj_template.force_flat_shading,\n        True,\n        \"boolean\",\n    )\n    # New fields, uncomment upon updating conda 8/4/20\n    res_dict[\"up\"] = (phys_obj_template.orient_up, True, \"vector\")\n    res_dict[\"front\"] = (phys_obj_template.orient_front, True, \"vector\")\n    res_dict[\"units_to_meters\"] = (phys_obj_template.units_to_meters, True, \"double\")\n    res_dict[\"render_asset_type\"] = (phys_obj_template.render_asset_type, True, \"int\")\n    res_dict[\"collision_asset_type\"] = (\n        phys_obj_template.collision_asset_type,\n        True,\n        \"int\",\n    )\n    # Read-only values\n    res_dict[\"render_asset_is_primitive\"] = (\n        phys_obj_template.render_asset_is_primitive,\n        False,\n        \"boolean\",\n    )\n    res_dict[\"collision_asset_is_primitive\"] = (\n        phys_obj_template.collision_asset_is_primitive,\n        False,\n        \"boolean\",\n    )\n    res_dict[\"use_mesh_for_collision\"] = (\n        phys_obj_template.use_mesh_for_collision,\n        False,\n        \"boolean\",\n    )\n    res_dict[\"filenames_are_dirty\"] = (\n        phys_obj_template.filenames_are_dirty,\n        False,\n        \"boolean\",\n    )\n    return res_dict\n\n\n# This method will build a dict containing k-v pairs of attribute property names\n# and values for the passed object template. The values are tuples with the first\n# entry being the value,the second being whether the property is editable and\n# the third being the type.\ndef build_dict_of_Object_attrs(obj_template):\n    res_dict = build_dict_of_PhyObj_attrs(obj_template)\n    res_dict[\"com\"] = (obj_template.com, True, \"vector\")\n    res_dict[\"compute_COM_from_shape\"] = (\n        obj_template.compute_COM_from_shape,\n        True,\n        \"boolean\",\n    )\n    res_dict[\"mass\"] = (obj_template.mass, True, \"double\")\n    res_dict[\"inertia\"] = (obj_template.inertia, True, \"vector\")\n    res_dict[\"linear_damping\"] = (obj_template.linear_damping, True, \"double\")\n    res_dict[\"angular_damping\"] = (obj_template.angular_damping, True, \"double\")\n    res_dict[\"bounding_box_collisions\"] = (\n        obj_template.bounding_box_collisions,\n        True,\n        \"boolean\",\n    )\n    res_dict[\"join_collision_meshes\"] = (\n        obj_template.join_collision_meshes,\n        True,\n        \"boolean\",\n    )\n    # res_dict[\"is_visible\"] = (obj_template.is_visible, True, \"boolean\")\n    # res_dict[\"is_collidable\"] = (obj_template.is_collidable, True, \"boolean\")\n    res_dict[\"semantic_id\"] = (obj_template.semantic_id, True, \"int\")\n    return res_dict\n\n\n# This method will build a dict containing k-v pairs of attribute property names\n# and values for the passed scene template. The values are tuples with the first\n# entry being the value,the second being whether the property is editable and\n# the third being the type.\ndef build_dict_of_Stage_attrs(scene_template):\n    res_dict = build_dict_of_PhyObj_attrs(scene_template)\n    res_dict[\"gravity\"] = (scene_template.gravity, True, \"vector\")\n    res_dict[\"origin\"] = (scene_template.origin, True, \"vector\")\n    res_dict[\"semantic_asset_handle\"] = (\n        scene_template.semantic_asset_handle,\n        True,\n        \"string\",\n    )\n    res_dict[\"semantic_asset_type\"] = (scene_template.semantic_asset_type, True, \"int\")\n    res_dict[\"navmesh_asset_handle\"] = (\n        scene_template.navmesh_asset_handle,\n        True,\n        \"string\",\n    )\n    res_dict[\"house_filename\"] = (scene_template.house_filename, True, \"string\")\n    # res_dict[\"light_setup\"] = (scene_template.light_setup, True, \"string\")\n    # res_dict[\"frustum_culling\"] = (scene_template.frustum_culling, True, \"boolean\")\n    return res_dict\n\n\n# This method will build a dict containing k-v pairs of attribute property names\n# and values for the passed physics manager template. The values are tuples with\n# the first entry being the value,the second being whether the property is\n# editable and the third being the type.\ndef build_dict_of_PhysicsSim_attrs(physics_template):\n    res_dict = build_dict_of_Default_attrs(physics_template)\n    res_dict[\"gravity\"] = (physics_template.gravity, True, \"vector\")\n    res_dict[\"timestep\"] = (physics_template.timestep, True, \"double\")\n    res_dict[\"max_substeps\"] = (physics_template.max_substeps, True, \"int\")\n    res_dict[\"friction_coefficient\"] = (\n        physics_template.friction_coefficient,\n        True,\n        \"double\",\n    )\n    res_dict[\"restitution_coefficient\"] = (\n        physics_template.restitution_coefficient,\n        True,\n        \"double\",\n    )\n    # Read-only values\n    res_dict[\"simulator\"] = (physics_template.simulator, False, \"string\")\n    return res_dict\n\n\n# This method will build a dict containing k-v pairs of attribute property names\n# and values that are shared among all primitive asset attributes templates.\n# The values are tuples with the first entry being the value,the second being\n# whether the property is editable and the third being the type.\ndef build_dict_of_prim_attrs(prim_template):\n    res_dict = build_dict_of_Default_attrs(prim_template)\n    res_dict[\"use_texture_coords\"] = (prim_template.use_texture_coords, True, \"boolean\")\n    res_dict[\"use_tangents\"] = (prim_template.use_tangents, True, \"boolean\")\n    res_dict[\"num_rings\"] = (prim_template.num_rings, True, \"int\")\n    res_dict[\"num_segments\"] = (prim_template.num_segments, True, \"int\")\n    res_dict[\"half_length\"] = (prim_template.half_length, True)\n    # Read-only values\n    res_dict[\"prim_obj_class_name\"] = (\n        prim_template.prim_obj_class_name,\n        False,\n        \"string\",\n    )\n    res_dict[\"prim_obj_type\"] = (prim_template.prim_obj_type, False, \"int\")\n    res_dict[\"is_valid_template\"] = (prim_template.is_valid_template, False, \"boolean\")\n    return res_dict\n\n\n# This method will build a dict containing k-v pairs of attribute property names\n# and values for the passed capsule primitive template. The values are tuples with\n# the first entry being the value,the second being whether the property is\n# editable and the third being the type.\ndef build_dict_of_Capsule_prim_attrs(capsule_template):\n    res_dict = build_dict_of_prim_attrs(capsule_template)\n    res_dict[\"hemisphere_rings\"] = (capsule_template.hemisphere_rings, True, \"int\")\n    res_dict[\"cylinder_rings\"] = (capsule_template.cylinder_rings, True, \"int\")\n    return res_dict\n\n\n# This method will build a dict containing k-v pairs of attribute property names\n# and values for the passed cone primitive template. The values are tuples with\n```\n\n----------------------------------------\n\nTITLE: Visualize Multiple Object Coordinate Frames\nDESCRIPTION: This code iterates through all rigid objects in the scene and visualizes their local coordinate frames.  It retrieves a dictionary of all rigid objects, then for each object, pushes the object's transformation onto the `DebugLineRender`, draws the axes at the origin of the object's local frame, and pops the transformation.  Finally, it shows the scene from a new camera position.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/coordinate_frame_tutorial.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nobj_dict = rigid_obj_mgr.get_objects_by_handle_substring()\nfor _, obj in obj_dict.items():\n    lr.push_transform(obj.transformation)\n    draw_axes(origin, axis_len=obj_axes_len)\n    lr.pop_transform()\n\nshow_scene(calc_camera_transform(eye_translation=eye_pos1, lookat=origin))\n```\n\n----------------------------------------\n\nTITLE: Discrete and Continuous Navigation in Habitat-Sim (Python)\nDESCRIPTION: This code snippet demonstrates how to control an agent in Habitat-Sim using both discrete and continuous action spaces. It sets up the simulation, defines action sequences, applies actions to the agent, and integrates the agent's velocity over time. It also includes logic to handle collisions and render the agent's observations. It depends on the `habitat_sim` library and `numpy` for velocity control.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n# @title Discrete and Continuous Navigation:\n\n# @markdown Take moment to run this cell a couple times and note the differences between discrete and continuous navigation with and without sliding.\n\n# @markdown ---\n# @markdown ### Set example parameters:\nseed = 7  # @param {type:\"integer\"}\n# @markdown Optionally navigate on the currently configured scene and NavMesh instead of re-loading with defaults:\nuse_current_scene = False  # @param {type:\"boolean\"}\n\n\nsim_settings[\"seed\"] = seed\nif not use_current_scene:\n    # reload a default nav scene\n    sim_settings[\"scene\"] = os.path.join(\n        data_path, \"scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\"\n    )\n    cfg = make_cfg(sim_settings)\n    try:  # make initialization Colab cell order proof\n        sim.close()\n    except NameError:\n        pass\n    sim = habitat_sim.Simulator(cfg)\nrandom.seed(sim_settings[\"seed\"])\nsim.seed(sim_settings[\"seed\"])\n# set new initial state\nsim.initialize_agent(agent_id=0)\nagent = sim.agents[0]\n\n# @markdown Seconds to simulate:\nsim_time = 10  # @param {type:\"integer\"}\n\n# @markdown Optional continuous action space parameters:\ncontinuous_nav = True  # @param {type:\"boolean\"}\n\n# defaults for discrete control\n# control frequency (actions/sec):\ncontrol_frequency = 3\n# observation/integration frames per action\nframe_skip = 1\nif continuous_nav:\n    control_frequency = 5  # @param {type:\"slider\", min:1, max:30, step:1}\n    frame_skip = 12  # @param {type:\"slider\", min:1, max:30, step:1}\n\n\nfps = control_frequency * frame_skip\nprint(\"fps = \" + str(fps))\ncontrol_sequence = []\nfor _action in range(int(sim_time * control_frequency)):\n    if continuous_nav:\n        # allow forward velocity and y rotation to vary\n        control_sequence.append(\n            {\n                \"forward_velocity\": random.random() * 2.0,  # [0,2)\n                \"rotation_velocity\": (random.random() - 0.5) * 2.0,  # [-1,1)\n            }\n        )\n    else:\n        control_sequence.append(random.choice(action_names))\n\n# create and configure a new VelocityControl structure\nvel_control = habitat_sim.physics.VelocityControl()\nvel_control.controlling_lin_vel = True\nvel_control.lin_vel_is_local = True\nvel_control.controlling_ang_vel = True\nvel_control.ang_vel_is_local = True\n\n# try 2 variations of the control experiment\nfor iteration in range(2):\n    # reset observations and robot state\n    observations = []\n\n    video_prefix = \"nav_sliding\"\n    sim.config.sim_cfg.allow_sliding = True\n    # turn sliding off for the 2nd pass\n    if iteration == 1:\n        sim.config.sim_cfg.allow_sliding = False\n        video_prefix = \"nav_no_sliding\"\n\n    print(video_prefix)\n\n    # manually control the object's kinematic state via velocity integration\n    time_step = 1.0 / (frame_skip * control_frequency)\n    print(\"time_step = \" + str(time_step))\n    for action in control_sequence:\n        # apply actions\n        if continuous_nav:\n            # update the velocity control\n            # local forward is -z\n            vel_control.linear_velocity = np.array([0, 0, -action[\"forward_velocity\"]])\n            # local up is y\n            vel_control.angular_velocity = np.array([0, action[\"rotation_velocity\"], 0])\n\n        else:  # discrete action navigation\n            discrete_action = agent.agent_config.action_space[action]\n\n            did_collide = False\n            if agent.controls.is_body_action(discrete_action.name):\n                did_collide = agent.controls.action(\n                    agent.scene_node,\n                    discrete_action.name,\n                    discrete_action.actuation,\n                    apply_filter=True,\n                )\n            else:\n                for _, v in agent._sensors.items():\n                    habitat_sim.errors.assert_obj_valid(v)\n                    agent.controls.action(\n                        v.object,\n                        discrete_action.name,\n                        discrete_action.actuation,\n                        apply_filter=False,\n                    )\n\n        # simulate and collect frames\n        for _frame in range(frame_skip):\n            if continuous_nav:\n                # Integrate the velocity and apply the transform.\n                # Note: this can be done at a higher frequency for more accuracy\n                agent_state = agent.state\n                previous_rigid_state = habitat_sim.RigidState(\n                    utils.quat_to_magnum(agent_state.rotation), agent_state.position\n                )\n\n                # manually integrate the rigid state\n                target_rigid_state = vel_control.integrate_transform(\n                    time_step, previous_rigid_state\n                )\n\n                # snap rigid state to navmesh and set state to object/agent\n                # calls pathfinder.try_step or self.pathfinder.try_step_no_sliding\n                end_pos = sim.step_filter(\n                    previous_rigid_state.translation, target_rigid_state.translation\n                )\n\n                # set the computed state\n                agent_state.position = end_pos\n                agent_state.rotation = utils.quat_from_magnum(\n                    target_rigid_state.rotation\n                )\n                agent.set_state(agent_state)\n\n                # Check if a collision occurred\n                dist_moved_before_filter = (\n                    target_rigid_state.translation - previous_rigid_state.translation\n                ).dot()\n                dist_moved_after_filter = (\n                    end_pos - previous_rigid_state.translation\n                ).dot()\n\n                # NB: There are some cases where ||filter_end - end_pos|| > 0 when a\n                # collision _didn't_ happen. One such case is going up stairs.  Instead,\n                # we check to see if the the amount moved after the application of the filter\n                # is _less_ than the amount moved before the application of the filter\n                EPS = 1e-5\n                collided = (dist_moved_after_filter + EPS) < dist_moved_before_filter\n\n            # run any dynamics simulation\n            sim.step_physics(time_step)\n\n            # render observation\n            observations.append(sim.get_sensor_observations())\n\n    print(\"frames = \" + str(len(observations)))\n    # video rendering with embedded 1st person view\n    if do_make_video:\n        # use the video utility to render the observations\n        vut.make_video(\n            observations=observations,\n            primary_obs=\"color_sensor\",\n            primary_obs_type=\"color\",\n            video_file=output_directory + \"continuous_nav\",\n            fps=fps,\n            open_vid=show_video,\n        )\n\n    sim.reset()\n```\n\n----------------------------------------\n\nTITLE: Instancing Modified Primitives in Habitat-Sim (Python)\nDESCRIPTION: This code demonstrates how to instantiate modified primitive objects (both solid and wireframe) in the Habitat-Sim environment. It iterates through the handles of registered solid and wireframe primitives, creates object templates from them, and then adds the objects to the scene. The objects are placed relative to the agent, and the simulation is run to capture camera observations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_53\n\nLANGUAGE: python\nCODE:\n```\n# @title ####Using the modifications set in the previous cells, instantiate examples of all available solid and wireframe primitives.{ display-mode: \"form\" }\n# clear all objects and observations\nrigid_obj_mgr.remove_all_objects()\nobservations = []\n# save initial camera state for tracking\ninit_config = init_camera_track_config(sim)\n# Previous cells configured solid_handles_to_use and wireframe_handles_to_use\n\n# Set desired offset from agent location to place object\noffset_solid = np.array([-1.1, 0.6, -1.8])\nobjs_to_sim = []\n# Create primitive-attributes based object templates for solid and wireframe objects\nfor solidHandle in solid_handles_to_use.values():\n    # Create object template with passed handle\n    obj_template = obj_attr_mgr.create_template(solidHandle)\n    # Create object from object template handle\n    print(\"Solid Object being made using handle :{}\".format(solidHandle))\n    obj_solid = rigid_obj_mgr.add_object_by_template_handle(solidHandle)\n    objs_to_sim.append(obj_solid)\n    # Place object in scene relative to agent\n    set_object_state_from_agent(sim, obj_solid, offset=offset_solid)\n    # Move offset for next object\n    offset_solid[0] += 0.4\n\noffset_wf = np.array([-1.1, 0.6, -1.0])\n\nfor wireframeHandle in wireframe_handles_to_use.values():\n    # Create object template with passed handle\n    obj_template = obj_attr_mgr.create_template(wireframeHandle)\n    # Create object from object template handle\n    print(\"Wireframe Object being made using handle :{}\".format(wireframeHandle))\n    obj_wf = rigid_obj_mgr.add_object_by_template_handle(wireframeHandle)\n    objs_to_sim.append(obj_wf)\n    # Place object in scene relative to agent\n    set_object_state_from_agent(sim, obj_wf, offset=offset_wf)\n    # Move offset for next object\n    offset_wf[0] += 0.4\n\nexample_type = \"Adding customized primitive-based objects\"\nobservations = camera_track_simulate(sim, objs_to_sim, dt=2.0)\nif make_video:\n    vut.make_video(\n        observations,\n        \"color_sensor_1st_person\",\n        \"color\",\n        output_path + example_type,\n        open_vid=show_video,\n    )\n\n# restore camera tracking position\nrestore_camera_track_config(sim, init_config)\nmake_clear_all_objects_button()\n```\n\n----------------------------------------\n\nTITLE: Playing Gfx Replay with Visualization (Habitat-Sim, Python)\nDESCRIPTION: Plays a gfx replay from a different camera view, visualizing the agent and sensor using primitives. It calculates the agent's trajectory, draws boxes around the agent and sensor, and draws a line indicating the sensor's look direction. DebugLineRenderer is used to draw the primitives. Depends on mn (Magnum) for vector and matrix operations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nobservations = []\nprint(\"play from a different camera view, with agent/sensor visualization...\")\n\n# place a third-person camera\nsensor_node.translation = [-1.1, -0.9, -0.2]\nsensor_node.rotation = mn.Quaternion.rotation(mn.Deg(-115), mn.Vector3(0.0, 1.0, 0))\n\n# gather the agent trajectory for later visualization\nagent_trajectory_points = []\nfor frame in range(player.get_num_keyframes()):\n    player.set_keyframe_index(frame)\n    (agent_translation, _) = player.get_user_transform(\"agent\")\n    agent_trajectory_points.append(agent_translation)\n\ndebug_line_render = sim.get_debug_line_render()\ndebug_line_render.set_line_width(2.0)\nagent_viz_box = mn.Range3D(mn.Vector3(-0.1, 0.0, -0.1), mn.Vector3(0.1, 0.4, 0.1))\nsensor_viz_box = mn.Range3D(mn.Vector3(-0.1, -0.1, -0.1), mn.Vector3(0.1, 0.1, 0.1))\n\nfor frame in range(player.get_num_keyframes()):\n    player.set_keyframe_index(frame)\n\n    (agent_translation, agent_rotation) = player.get_user_transform(\"agent\")\n\n    rot_mat = agent_rotation.to_matrix()\n    full_mat = mn.Matrix4.from_(rot_mat, agent_translation)\n\n    # draw a box in the agent body's local space\n    debug_line_render.push_transform(full_mat)\n    debug_line_render.draw_box(\n        agent_viz_box.min, agent_viz_box.max, mn.Color4(1.0, 0.0, 0.0, 1.0)\n    )\n    debug_line_render.pop_transform()\n\n    for radius, opacity in [(0.2, 0.6), (0.25, 0.4), (0.3, 0.2)]:\n        debug_line_render.draw_circle(\n            agent_translation, radius, mn.Color4(0.0, 1.0, 1.0, opacity)\n        )\n\n    # draw a box in the sensor's local space\n    (sensor_translation, sensor_rotation) = player.get_user_transform(\"sensor\")\n    debug_line_render.push_transform(\n        mn.Matrix4.from_(sensor_rotation.to_matrix(), sensor_translation)\n    )\n    debug_line_render.draw_box(\n        sensor_viz_box.min, sensor_viz_box.max, mn.Color4(1.0, 0.0, 0.0, 1.0)\n    )\n    # draw a line in the sensor look direction (-z in local space)\n    debug_line_render.draw_transformed_line(\n        mn.Vector3.zero_init(),\n        mn.Vector3(0.0, 0.0, -0.5),\n        mn.Color4(1.0, 0.0, 0.0, 1.0),\n        mn.Color4(1.0, 1.0, 1.0, 1.0),\n    )\n    debug_line_render.pop_transform()\n\n    # draw the agent trajectory\n    debug_line_render.draw_path_with_endpoint_circles(\n        agent_trajectory_points, 0.07, mn.Color4(1.0, 1.0, 1.0, 1.0)\n    )\n\n    observations.append(sim.get_sensor_observations())\n\nif make_video:\n    vut.make_video(\n        observations,\n        \"rgba_camera\",\n        \"color\",\n        output_path + \"replay_playback3\",\n        open_vid=show_video,\n    )\n```\n\n----------------------------------------\n\nTITLE: CCache Configuration\nDESCRIPTION: This snippet checks if ccache is found on the system. If found, it sets ccache as the compiler and linker wrapper, speeding up the build process by caching compiler outputs.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nfind_program(CCACHE_FOUND ccache)\nif(CCACHE_FOUND)\n  set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE ccache)\n  set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK ccache)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Turn off non-critical logging (Habitat-Sim < 0.2.2)\nDESCRIPTION: Sets environment variables to suppress non-critical logging in Habitat-Sim versions prior to 0.2.2.  It configures Magnum logging to 'quiet' and sets the minimum GLOG level to 2.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/logging.rst#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport MAGNUM_LOG=quiet GLOG_minloglevel=2\n```\n\n----------------------------------------\n\nTITLE: Displaying topdown map of Habitat-Sim NavMesh using Matplotlib (Python)\nDESCRIPTION: This function, `display_map`, displays a topdown map using Matplotlib, with an optional overlay of key points. It takes the `topdown_map` (a NumPy array) and an optional list of `key_points` as input.  It visualizes the NavMesh and any specified points on the map.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# display a topdown map with matplotlib\ndef display_map(topdown_map, key_points=None):\n    plt.figure(figsize=(12, 8))\n    ax = plt.subplot(1, 1, 1)\n    ax.axis(\"off\")\n    plt.imshow(topdown_map)\n    # plot points on map\n    if key_points is not None:\n        for point in key_points:\n            plt.plot(point[0], point[1], marker=\"o\", markersize=10, alpha=0.8)\n    plt.show(block=False)\n```\n\n----------------------------------------\n\nTITLE: Setting Template Properties from Dictionary in Python\nDESCRIPTION: This function sets the attributes of a template based on the key-value pairs in a dictionary. It iterates through the dictionary, using the keys as attribute names and the first element of the corresponding value tuple (v[0]) as the attribute value. It uses the `setattr` function to assign the values to the template's attributes.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef set_template_properties_from_dict(template, template_dict):\n    for k, v in template_dict.items():\n        setattr(template, k, v[0])\n    return template\n```\n\n----------------------------------------\n\nTITLE: Adding and Simulating Objects\nDESCRIPTION: Adds dynamic objects (chefcan) to the scene and continues the simulation with these objects present.  Loads object templates, adds objects to the scene, and then simulates agent movement using the `simulate_with_moving_agent` function.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nobj_templates_mgr = sim.get_object_template_manager()\n# get the rigid object manager, which provides direct\n# access to objects\nrigid_obj_mgr = sim.get_rigid_object_manager()\n\nobj_templates_mgr.load_configs(str(os.path.join(data_path, \"objects/example_objects\")))\nchefcan_template_handle = obj_templates_mgr.get_template_handles(\n    \"data/objects/example_objects/chefcan\"\n)[0]\n\n# drop some dynamic objects\nchefcan_1 = rigid_obj_mgr.add_object_by_template_handle(chefcan_template_handle)\nchefcan_1.translation = [2.4, -0.64, 0.0]\nchefcan_2 = rigid_obj_mgr.add_object_by_template_handle(chefcan_template_handle)\nchefcan_2.translation = [2.4, -0.64, 0.28]\nchefcan_3 = rigid_obj_mgr.add_object_by_template_handle(chefcan_template_handle)\nchefcan_3.translation = [2.4, -0.64, -0.28]\n\nobservations += simulate_with_moving_agent(\n    sim,\n    duration=2.0,\n    agent_vel=np.array([0.0, 0.0, -0.4]),\n    look_rotation_vel=-5.0,\n    get_frames=make_video_during_sim,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Habitat-sim Simulator\nDESCRIPTION: This snippet defines utility functions to configure and initialize the Habitat-Sim simulator. It provides functions to create simulator configurations, define default settings, and create a simulator instance from the settings. The `make_cfg` function takes settings as input and returns a `habitat_sim.Configuration` object.  It supports configuring various sensors and agents.  `make_default_settings` returns a dictionary of default settings. `make_simulator_from_settings` initializes the simulator and its managers.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef make_cfg(settings):\n    sim_cfg = habitat_sim.SimulatorConfiguration()\n    sim_cfg.gpu_device_id = 0\n    sim_cfg.scene_id = settings[\"scene\"]\n    sim_cfg.enable_physics = settings[\"enable_physics\"]\n    # Optional; Specify the location of an existing scene dataset configuration\n    # that describes the locations and configurations of all the assets to be used\n    if \"scene_dataset_config\" in settings:\n        sim_cfg.scene_dataset_config_file = settings[\"scene_dataset_config\"]\n    if \"override_scene_light_defaults\" in settings:\n        sim_cfg.override_scene_light_defaults = settings[\n            \"override_scene_light_defaults\"\n        ]\n    if \"scene_light_setup\" in settings:\n        sim_cfg.scene_light_setup = settings[\"scene_light_setup\"]\n\n    # Note: all sensors must have the same resolution\n    sensor_specs = []\n    if settings[\"color_sensor_1st_person\"]:\n        color_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n        color_sensor_1st_person_spec.uuid = \"color_sensor_1st_person\"\n        color_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.COLOR\n        color_sensor_1st_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        color_sensor_1st_person_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n        color_sensor_1st_person_spec.orientation = [\n            settings[\"sensor_pitch\"],\n            0.0,\n            0.0,\n        ]\n        color_sensor_1st_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n        sensor_specs.append(color_sensor_1st_person_spec)\n    if settings[\"depth_sensor_1st_person\"]:\n        depth_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n        depth_sensor_1st_person_spec.uuid = \"depth_sensor_1st_person\"\n        depth_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.DEPTH\n        depth_sensor_1st_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        depth_sensor_1st_person_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n        depth_sensor_1st_person_spec.orientation = [\n            settings[\"sensor_pitch\"],\n            0.0,\n            0.0,\n        ]\n        depth_sensor_1st_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n        sensor_specs.append(depth_sensor_1st_person_spec)\n    if settings[\"semantic_sensor_1st_person\"]:\n        semantic_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n        semantic_sensor_1st_person_spec.uuid = \"semantic_sensor_1st_person\"\n        semantic_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.SEMANTIC\n        semantic_sensor_1st_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        semantic_sensor_1st_person_spec.position = [\n            0.0,\n            settings[\"sensor_height\"],\n            0.0,\n        ]\n        semantic_sensor_1st_person_spec.orientation = [\n            settings[\"sensor_pitch\"],\n            0.0,\n            0.0,\n        ]\n        semantic_sensor_1st_person_spec.sensor_subtype = (\n            habitat_sim.SensorSubType.PINHOLE\n        )\n        sensor_specs.append(semantic_sensor_1st_person_spec)\n    if settings[\"color_sensor_3rd_person\"]:\n        color_sensor_3rd_person_spec = habitat_sim.CameraSensorSpec()\n        color_sensor_3rd_person_spec.uuid = \"color_sensor_3rd_person\"\n        color_sensor_3rd_person_spec.sensor_type = habitat_sim.SensorType.COLOR\n        color_sensor_3rd_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        color_sensor_3rd_person_spec.position = [\n            0.0,\n            settings[\"sensor_height\"] + 0.2,\n            0.2,\n        ]\n        color_sensor_3rd_person_spec.orientation = [-math.pi / 4, 0.0, 0.0]\n        color_sensor_3rd_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n        sensor_specs.append(color_sensor_3rd_person_spec)\n\n    # Here you can specify the amount of displacement in a forward action and the turn angle\n    agent_cfg = habitat_sim.agent.AgentConfiguration()\n    agent_cfg.sensor_specifications = sensor_specs\n\n    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n\n\ndef make_default_settings():\n    settings = {\n        \"width\": 1280,  # Spatial resolution of the observations\n        \"height\": 720,\n        \"scene\": os.path.join(\n            data_path, \"scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\"\n        ),  # Scene path\n        \"default_agent\": 0,\n        \"sensor_height\": 1.5,  # Height of sensors in meters\n        \"sensor_pitch\": -math.pi / 8.0,  # sensor pitch (x rotation in rads)\n        \"color_sensor_1st_person\": True,  # RGB sensor\n        \"color_sensor_3rd_person\": False,  # RGB sensor 3rd person\n        \"depth_sensor_1st_person\": False,  # Depth sensor\n        \"semantic_sensor_1st_person\": False,  # Semantic sensor\n        \"seed\": 1,\n        \"enable_physics\": built_with_bullet,  # enable dynamics simulation if bullet is present\n    }\n    return settings\n\n\ndef make_simulator_from_settings(sim_settings):\n    cfg = make_cfg(sim_settings)\n    # clean-up the current simulator instance if it exists\n    global sim\n    global obj_attr_mgr\n    global prim_attr_mgr\n    global stage_attr_mgr\n    global rigid_obj_mgr\n    global metadata_mediator\n\n    if sim != None:\n        sim.close()\n    # initialize the simulator\n    sim = habitat_sim.Simulator(cfg)\n    # Managers of various Attributes templates\n    obj_attr_mgr = sim.get_object_template_manager()\n    obj_attr_mgr.load_configs(str(os.path.join(data_path, \"objects/example_objects\")))\n    prim_attr_mgr = sim.get_asset_template_manager()\n    stage_attr_mgr = sim.get_stage_template_manager()\n    # Manager providing access to rigid objects\n    rigid_obj_mgr = sim.get_rigid_object_manager()\n    # get metadata_mediator\n    metadata_mediator = sim.metadata_mediator\n\n    # UI-populated handles used in various cells.  Need to initialize to valid\n    # value in case IPyWidgets are not available.\n    # Holds the user's desired file-based object template handle\n    global sel_file_obj_handle\n    sel_file_obj_handle = obj_attr_mgr.get_file_template_handles()[0]\n    # Holds the user's desired primitive-based object template handle\n    global sel_prim_obj_handle\n    sel_prim_obj_handle = obj_attr_mgr.get_synth_template_handles()[0]\n    # Holds the user's desired primitive asset template handle\n    global sel_asset_handle\n    sel_asset_handle = prim_attr_mgr.get_template_handles()[0]\n```\n\n----------------------------------------\n\nTITLE: Utility Functions for Habitat Simulation\nDESCRIPTION: This code defines utility functions to streamline common tasks in Habitat simulation.  `create_sim_helper` sets up the simulator with a specified scene. `show_img` displays or saves RGB images. `show_scene` renders the scene from a given camera transform. `draw_axes` draws coordinate axes. `calc_camera_transform` calculates a camera transformation matrix.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/coordinate_frame_tutorial.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef create_sim_helper(scene_id):\n    global sim\n    global sensor_node\n    global lr\n\n    # clean-up the current simulator instance if it exists\n    if sim != None:\n        sim.close()\n\n    sim_cfg = habitat_sim.SimulatorConfiguration()\n    sim_cfg.scene_dataset_config_file = os.path.join(\n        data_path, \"replica_cad/replicaCAD.scene_dataset_config.json\"\n    )\n    sim_cfg.scene_id = scene_id\n    sim_cfg.enable_physics = True  # for ReplicaCAD articulated furniture\n\n    agent_cfg = habitat_sim.agent.AgentConfiguration()\n    rgb_sensor_spec = habitat_sim.CameraSensorSpec()\n    rgb_sensor_spec.uuid = \"color_sensor\"\n    rgb_sensor_spec.sensor_type = habitat_sim.SensorType.COLOR\n    rgb_sensor_spec.resolution = [768, 1024]\n    rgb_sensor_spec.position = [0.0, 0.0, 0.0]\n    agent_cfg.sensor_specifications = [rgb_sensor_spec]\n\n    cfg = habitat_sim.Configuration(sim_cfg, [agent_cfg])\n    sim = habitat_sim.Simulator(cfg)\n\n    # This tutorial doesn't involve agent concepts. We want to directly set\n    # camera transforms in world-space (the world's coordinate frame). We set\n    # the agent transform to identify and then return the sensor node.\n    sim.initialize_agent(0)\n    agent_node = sim.get_agent(0).body.object\n    agent_node.translation = [0.0, 0.0, 0.0]\n    agent_node.rotation = mn.Quaternion()\n    sensor_node = sim._sensors[\"color_sensor\"]._sensor_object.object\n\n    lr = sim.get_debug_line_render()\n    lr.set_line_width(3)\n\n\ndef show_img(rgb_obs):\n    global image_counter\n\n    colors = []\n    for row in rgb_obs:\n        for rgba in row:\n            colors.extend([rgba[0], rgba[1], rgba[2]])\n\n    resolution_x = len(rgb_obs[0])\n    resolution_y = len(rgb_obs)\n\n    colors = bytes(colors)\n    img = Image.frombytes(\"RGB\", (resolution_x, resolution_y), colors)\n    if IS_NOTEBOOK:\n        IPython.display.display(img)\n    else:\n        filepath = f\"{output_directory}/{image_counter}.png\"\n        img.save(filepath)\n        print(f\"Saved image: {filepath}\")\n        image_counter += 1\n\n\ndef show_scene(camera_transform):\n    sensor_node.transformation = camera_transform\n    observations = sim.get_sensor_observations()\n    show_img(observations[\"color_sensor\"])\n\n\ndef draw_axes(translation, axis_len=1.0):\n    lr = sim.get_debug_line_render()\n    # draw axes with x+ = red, y+ = green, z+ = blue\n    lr.draw_transformed_line(translation, mn.Vector3(axis_len, 0, 0), red)\n    lr.draw_transformed_line(translation, mn.Vector3(0, axis_len, 0), green)\n    lr.draw_transformed_line(translation, mn.Vector3(0, 0, axis_len), blue)\n\n\ndef calc_camera_transform(\n    eye_translation=mn.Vector3(1, 1, 1), lookat=mn.Vector3(0, 0, 0)\n):\n    # choose y-up to match Habitat's y-up convention\n    camera_up = mn.Vector3(0.0, 1.0, 0.0)\n    return mn.Matrix4.look_at(eye_translation, lookat, camera_up)\n```\n\n----------------------------------------\n\nTITLE: Conditional Logic and String Manipulation (JavaScript)\nDESCRIPTION: This snippet contains a large chain of conditional statements combined with string manipulation. It appears to be validating some kind of user input or browser state, potentially related to bot detection or fraud prevention. The final outcome depends on the evaluation of multiple nested conditions.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_30\n\nLANGUAGE: javascript\nCODE:\n```\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\n```\n\n----------------------------------------\n\nTITLE: Linking dependencies to gfx_batch library\nDESCRIPTION: This snippet uses `target_link_libraries` to link the necessary Magnum libraries to the gfx_batch library. It includes Magnum::GL, Magnum::Magnum, Magnum::SceneTools, Magnum::Shaders, Magnum::Trade, and Magnum::WindowlessApplication. The comment emphasizes that the gfx_batch library should only depend on Magnum libraries, avoiding dependencies on other Habitat libraries to maintain its modularity.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/gfx_batch/CMakeLists.txt#_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_link_libraries(\n  gfx_batch\n  # Important: this library *deliberately* doesn't depend on any other Habitat\n  # libraries, and it should be kept as such. Only Magnum libraries are an\n  # allowed dependency. See the original PR for discussion:\n  # https://github.com/facebookresearch/habitat-sim/pull/1798#discussion_r911398937\n  PUBLIC Magnum::GL\n         Magnum::Magnum\n         Magnum::SceneTools\n         Magnum::Shaders\n         Magnum::Trade\n         Magnum::WindowlessApplication\n  # Not linking any plugins here, as the renderer itself doesn't directly rely\n  # on any of them. That also makes the plugins implicitly registered in\n  # *every* target that links to gfx_batch, which is far from ideal. Only the\n  # leaf executable links to them, and only to those that are actually used\n  # in that scenario -- i.e., a test only needs a tiny subset of plugins for\n  # data it uses, not everything to handle general file formats.\n)\n```\n\n----------------------------------------\n\nTITLE: Restoring Camera Tracking Configuration (restore_camera_track_config)\nDESCRIPTION: This function restores the camera and agent state to the values saved by `init_camera_track_config`. It takes the simulator instance `sim` and the initial state dictionary `init_state` as input. It resets the sensor's position and orientation, and restores the agent's state, effectively undoing the changes made for camera tracking.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Reset sensor and agent state using dictionary built in init_camera_track_config\n# Used at end of cell that directly modifies camera (i.e. tracking an object)\ndef restore_camera_track_config(sim, init_state):\n    visual_sensor = init_state[\"visual_sensor\"]\n    agent_ID = init_state[\"agent_ID\"]\n    # reset the sensor state for other examples\n    visual_sensor._spec.position = init_state[\"position\"]\n    visual_sensor._spec.orientation = init_state[\"orientation\"]\n    visual_sensor._sensor_object.set_transformation_from_spec()\n    # restore the agent's state to what was savedd in init_camera_track_config\n    sim.get_agent(agent_ID).set_state(init_state[\"agent_state\"])\n```\n\n----------------------------------------\n\nTITLE: Building Object Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_Object_attrs` generates a dictionary of attribute properties for a given object template (`obj_template`). It inherits attributes from the `PhyObj` template using `build_dict_of_PhyObj_attrs` and adds object-specific attributes like center of mass (com), mass, inertia, and damping coefficients. Each attribute's value is a tuple containing the value, editability status, and type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Object_attrs(obj_template):\n    res_dict = build_dict_of_PhyObj_attrs(obj_template)\n    res_dict[\"com\"] = (obj_template.com, True, \"vector\")\n    res_dict[\"compute_COM_from_shape\"] = (\n        obj_template.compute_COM_from_shape,\n        True,\n        \"boolean\",\n    )\n    res_dict[\"mass\"] = (obj_template.mass, True, \"double\")\n    res_dict[\"inertia\"] = (obj_template.inertia, True, \"vector\")\n    res_dict[\"linear_damping\"] = (obj_template.linear_damping, True, \"double\")\n    res_dict[\"angular_damping\"] = (obj_template.angular_damping, True, \"double\")\n    res_dict[\"bounding_box_collisions\"] = (\n        obj_template.bounding_box_collisions,\n        True,\n        \"boolean\",\n    )\n    res_dict[\"join_collision_meshes\"] = (\n        obj_template.join_collision_meshes,\n        True,\n        \"boolean\",\n    )\n    res_dict[\"is_visible\"] = (obj_template.is_visible, True, \"boolean\")\n    res_dict[\"semantic_id\"] = (obj_template.semantic_id, True, \"int\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Building Carousel View for Asset\nDESCRIPTION: This Python code snippet creates a carousel view of an asset, generating a video showing the asset rotating.  It takes the simulator object, asset ID, output path, video length, and optional orientation correction as input.  The orientation_correction parameter addresses common issues with asset orientations. Depends on cv2 (optional).\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/asset-viewer-tutorial.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# [build_carousel_view]\ndef build_carousel_view(\n    sim,\n    object_id:\n    str,\n    output_path: str,\n    video_len: int = 360,\n    orientation_correction: bool = False,\n    camera_params=None,\n):\n    assert video_len > 1 and output_path\n\n    if not has_cv2:\n        print(\"Error: OpenCV must be installed.\")\n        return\n\n    if camera_params is None:\n        camera_params = get_default_asset_viewer_camera_params()\n\n    cam_dist = camera_params[\"distance\"]\n    cam_latitude = camera_params[\"latitude\"]\n    cam_longitude = camera_params[\"longitude\"]\n    cam_height = camera_params[\"height\"]\n\n    # look at origin\n    target_position = mn.Vector3(np.array([0, cam_height, 0]))\n\n    video = []\n\n    for i in range(video_len):\n        rads = i / video_len * 2 * np.pi\n        # orbit around origin\n        cam_position = mn.Vector3(\n            np.array(\n                [\n                    cam_dist * np.cos(rads),\n                    cam_height,\n                    cam_dist * np.sin(rads),\n                ]\n            )\n        )\n\n        direction_vector = target_position - cam_position\n        direction_vector = direction_vector / np.linalg.norm(direction_vector)\n\n        # default k = [0,1,0] (y axis)\n        k = mn.Vector3(np.array([0, 1, 0]))\n\n        # when direction_vector is parallel to k, the rotation is ill-defined, so pick a different k\n        if abs(np.dot(direction_vector, k)) > 0.99:\n            k = mn.Vector3(np.array([0, 0, 1]))\n\n        rotation = quat_from_two_vectors(mn.Vector3(np.array([0, 0, -1])), direction_vector, k)\n\n        sim.agents[0].scene_node.rotation = rotation\n        sim.agents[0].scene_node.translation = cam_position\n\n        rgb = sim.render(False)  # non-blocking\n        video.append(rgb)\n\n    # concat frames\n    output = np.concatenate([frame for frame in video], axis=1)\n    frame_height, frame_width, _ = video[0].shape\n    output_height, _, _ = output.shape\n    output_video = cv2.VideoWriter(\n        output_path,\n        cv2.VideoWriter_fourcc(*\"mp4v\"),\n        30,\n        (frame_width, frame_height),\n    )\n    for frame in video:\n        output_video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n\n    output_video.release()\n    # cv2.imwrite(output_path, cv2.cvtColor(output, cv2.COLOR_RGB2BGR))\n\n\n# [/build_carousel_view]\n```\n\n----------------------------------------\n\nTITLE: Simulating Agent Movement with Replay Recording\nDESCRIPTION: Defines a function to simulate agent movement, step physics, and record replay keyframes.  It takes the simulator instance, duration, agent velocity, and look rotation velocity as input. It adds user transforms for the agent and sensor nodes using `gfx_replay_utils.add_node_user_transform` and saves keyframes using `sim.gfx_replay_manager.save_keyframe` after each physics step. Returns a list of observations if `get_frames` is True.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef simulate_with_moving_agent(\n    sim,\n    duration=1.0,\n    agent_vel=np.array([0, 0, 0]),\n    look_rotation_vel=0.0,\n    get_frames=True,\n):\n    sensor_node = sim._sensors[\"rgba_camera\"]._sensor_object.object\n    agent_node = sim.get_agent(0).body.object\n\n    # simulate dt seconds at 60Hz to the nearest fixed timestep\n    time_step = 1.0 / 60.0\n\n    rotation_x = mn.Quaternion.rotation(\n        mn.Deg(look_rotation_vel) * time_step, mn.Vector3(1.0, 0, 0)\n    )\n\n    print(\"Simulating \" + str(duration) + \" world seconds.\")\n    observations = []\n    start_time = sim.get_world_time()\n    while sim.get_world_time() < start_time + duration:\n        # move agent\n        agent_node.translation += agent_vel * time_step\n\n        # rotate sensor\n        sensor_node.rotation *= rotation_x\n\n        # Add user transforms for the agent and sensor. We'll use these later during\n        # replay playback.\n        gfx_replay_utils.add_node_user_transform(sim, agent_node, \"agent\")\n        gfx_replay_utils.add_node_user_transform(sim, sensor_node, \"sensor\")\n\n        sim.step_physics(time_step)\n\n        # save a replay keyframe after every physics step\n        sim.gfx_replay_manager.save_keyframe()\n\n        if get_frames:\n            observations.append(sim.get_sensor_observations())\n\n    return observations\n```\n\n----------------------------------------\n\nTITLE: Habitat-Sim Simulator Module\nDESCRIPTION: Describes the `habitat_sim.simulator` module, covering core classes like `Simulator` and `Configuration`. Highlights the Semantic Scene and its availability depending on the dataset.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.simulator\n```\n\n----------------------------------------\n\nTITLE: Finding Magnum Packages\nDESCRIPTION: This snippet uses the `find_package` command to locate and load required Magnum packages such as MagnumBindings and various MagnumPlugins (BasisImporter, GltfImporter, etc.). The `REQUIRED` keyword ensures that the build fails if these packages are not found.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/bindings/CMakeLists.txt#_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(MagnumBindings REQUIRED Python)\n\nfind_package(\n  MagnumPlugins\n  REQUIRED\n  BasisImporter\n  GltfImporter\n  KtxImporter\n  PrimitiveImporter\n  StanfordImporter\n  StbImageImporter\n  StbImageConverter\n  UfbxImporter\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Audio Sensor Object\nDESCRIPTION: Shows how to access the audio sensor object from the Habitat simulator in Python and perform actions like setting audio source transform and resetting the sensor.  The audio sensor object is obtained from the simulator's agent.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/AUDIO.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\naudio_sensor = sim.get_agent(0)._sensors[\"audio_sensor\"]\naudio_sensor.setAudioSourceTransform(np.array([x, y, z]))\naudio_sensor.reset()\n```\n\n----------------------------------------\n\nTITLE: Downloading ReplicaCAD Dataset Bash\nDESCRIPTION: This command downloads the ReplicaCAD dataset for Habitat-Sim using the `habitat_sim.utils.datasets_download` utility. It leverages the `replica_cad_dataset` UID.  The default download location is `habitat-sim/data/`, but can be overridden with `--data-path`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n#NOTE: by default, data will be downloaded into habitat-sim/data/. Optionally modify the data path by adding:  `--data-path /path/to/data/`\n# with conda install\npython -m habitat_sim.utils.datasets_download --uids replica_cad_dataset\n\n# with source (from inside habitat_sim/)\npython src_python/habitat_sim/utils/datasets_download.py --uids replica_cad_dataset\n```\n\n----------------------------------------\n\nTITLE: Instantiating Primitive-based Objects\nDESCRIPTION: This snippet demonstrates how to instantiate objects based on pre-defined primitive shapes (Capsule, Cone, Cube, Cylinder, Icosphere, UVSphere). It retrieves template handles for both solid and wireframe primitives, creates instances of each, places them in the scene relative to the agent, and then performs camera tracking simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_38\n\nLANGUAGE: python\nCODE:\n```\n# clear all objects and observations\nrigid_obj_mgr.remove_all_objects()\nobservations = []\n# save initial camera state for tracking\ninit_config = init_camera_track_config(sim)\n# Get Primitive-based solid object template handles\nprim_solid_obj_handles = obj_attr_mgr.get_synth_template_handles(\"solid\")\n# Get Primitive-based wireframe object template handles\nprim_wf_obj_handles = obj_attr_mgr.get_synth_template_handles(\"wireframe\")\n\n# Set desired offset from agent location to place object\noffset_solid = np.array([-1.1, 0.6, -1.8])\noffset_wf = np.array([-1.1, 0.6, -1.0])\nobjs_to_sim = []\nfor i in range(6):\n    # Create object from template handle\n    obj_solid = rigid_obj_mgr.add_object_by_template_handle(prim_solid_obj_handles[i])\n    obj_wf = rigid_obj_mgr.add_object_by_template_handle(prim_wf_obj_handles[i])\n    objs_to_sim.append(obj_solid)\n    objs_to_sim.append(obj_wf)\n\n    # Place object in scene relative to agent\n    set_object_state_from_agent(sim, obj_solid, offset=offset_solid)\n    set_object_state_from_agent(sim, obj_wf, offset=offset_wf)\n\n    # Move offset for next object\n    offset_solid[0] += 0.4\n    offset_wf[0] += 0.4\n```\n\n----------------------------------------\n\nTITLE: Creating Simulator Configuration in Habitat-Sim (Python)\nDESCRIPTION: This function `make_cfg` creates a Habitat-Sim configuration object from the provided settings. It defines the simulator configuration, sensor specifications (color, depth, semantic), and agent configuration, including action space definitions (move forward, turn left, turn right). It requires the `habitat_sim` library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef make_cfg(settings):\n    sim_cfg = habitat_sim.SimulatorConfiguration()\n    sim_cfg.gpu_device_id = 0\n    sim_cfg.scene_id = settings[\"scene\"]\n    sim_cfg.scene_dataset_config_file = settings[\"scene_dataset\"]\n    sim_cfg.enable_physics = settings[\"enable_physics\"]\n\n    # Note: all sensors must have the same resolution\n    sensor_specs = []\n\n    color_sensor_spec = habitat_sim.CameraSensorSpec()\n    color_sensor_spec.uuid = \"color_sensor\"\n    color_sensor_spec.sensor_type = habitat_sim.SensorType.COLOR\n    color_sensor_spec.resolution = [settings[\"height\"], settings[\"width\"]]\n    color_sensor_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n    color_sensor_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n    sensor_specs.append(color_sensor_spec)\n\n    depth_sensor_spec = habitat_sim.CameraSensorSpec()\n    depth_sensor_spec.uuid = \"depth_sensor\"\n    depth_sensor_spec.sensor_type = habitat_sim.SensorType.DEPTH\n    depth_sensor_spec.resolution = [settings[\"height\"], settings[\"width\"]]\n    depth_sensor_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n    depth_sensor_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n    sensor_specs.append(depth_sensor_spec)\n\n    semantic_sensor_spec = habitat_sim.CameraSensorSpec()\n    semantic_sensor_spec.uuid = \"semantic_sensor\"\n    semantic_sensor_spec.sensor_type = habitat_sim.SensorType.SEMANTIC\n    semantic_sensor_spec.resolution = [settings[\"height\"], settings[\"width\"]]\n    semantic_sensor_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n    semantic_sensor_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n    sensor_specs.append(semantic_sensor_spec)\n\n    # Here you can specify the amount of displacement in a forward action and the turn angle\n    agent_cfg = habitat_sim.agent.AgentConfiguration()\n    agent_cfg.sensor_specifications = sensor_specs\n    agent_cfg.action_space = {\n        \"move_forward\": habitat_sim.agent.ActionSpec(\n            \"move_forward\", habitat_sim.agent.ActuationSpec(amount=0.25)\n        ),\n        \"turn_left\": habitat_sim.agent.ActionSpec(\n            \"turn_left\", habitat_sim.agent.ActuationSpec(amount=30.0)\n        ),\n        \"turn_right\": habitat_sim.agent.ActionSpec(\n            \"turn_right\", habitat_sim.agent.ActuationSpec(amount=30.0)\n        ),\n    }\n\n    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n```\n\n----------------------------------------\n\nTITLE: Conda Package Installation with Headless Feature\nDESCRIPTION: This command installs the Habitat-Sim package with the `headless` feature from the `aihabitat` and `conda-forge` conda channels.  This is specific to linux builds, where the package can be built with or without a graphical interface.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nconda install -c aihabitat -c conda-forge habitat-sim headless\n```\n\n----------------------------------------\n\nTITLE: Creating and Linking CUDA Noise Model Library\nDESCRIPTION: This snippet conditionally creates a static library for CUDA noise model kernels if `BUILD_WITH_CUDA` is enabled. It sets target properties, links CUDA runtime libraries, and defines include directories for the CUDA toolkit.  It also links this noise_model_kernels library with the habitat_sim library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_22\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_WITH_CUDA)\n  add_library(noise_model_kernels STATIC ${noise_model_SOURCES})\n  # Use this until this change in Corrade is included in Habitat\n  # https://github.com/mosra/corrade/commit/280e6b6874e0902086e321d733ce0e90e0c52920\n  set_target_properties(noise_model_kernels PROPERTIES CORRADE_USE_PEDANTIC_FLAGS OFF)\n  target_link_libraries(noise_model_kernels PUBLIC ${CUDART_LIBRARY})\n  target_include_directories(\n    noise_model_kernels PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES}\n  )\n  target_compile_features(noise_model_kernels PUBLIC cxx_std_11)\n\n  target_link_libraries(habitat_sim PUBLIC noise_model_kernels ${CUDART_LIBRARY})\n\n  target_include_directories(\n    habitat_sim PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES}\n  )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Object Existence Check and Initialization\nDESCRIPTION: This snippet checks if the specified object file exists and is a valid file. If it exists, it proceeds to acquire the visual sensor, load the object template, and create an object instance using the Habitat-Sim rigid object manager.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nif os.path.exists(object_to_view_path) and os.path.isfile(object_to_view_path):\n    # Acquire the sensor being used\n    visual_sensor = sim._sensors[\"color_sensor_3rd_person\"]\n    initial_sensor_position = np.array(visual_sensor._spec.position)\n    initial_sensor_orientation = np.array(visual_sensor._spec.orientation)\n\n    # load an object template and instantiate an object to view\n    object_template = obj_attr_mgr.create_new_template(str(object_to_view_path), False)\n    # if using a stage and it displays sideways, you may need to reorient it via its attributes for it to display properly.\n```\n\n----------------------------------------\n\nTITLE: Setup Habitat-Sim Environment (Python)\nDESCRIPTION: This code initializes the Habitat-Sim environment, including downloading necessary datasets, creating a configuration, and initializing the simulator.  It ensures that the simulation environment is properly set up for further object interaction and manipulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nDATA_PATH = os.path.abspath(\"data/\")\nEXAMPLE_OBJECTS = os.path.join(DATA_PATH, \"objects/example_objects\")\nHABITAT_SCENE_DATASETS = os.path.join(DATA_PATH, \"scene_datasets/\")\nTEST_SCENE = os.path.join(HABITAT_SCENE_DATASETS, \"mp3d_example/v1/scans/17DRP5sb8fy/17DRP5sb8fy.glb\")\n\ndatasets_download.main(argv=[\n    \"--uids\",\n    \"habitat_example_objects\",\n    \"locobot_merged\",\n    \"--data-path\",\n    DATA_PATH,\n])\n\n\ncfg = make_configuration(TEST_SCENE)\nsim = habitat_sim.Simulator(cfg)\n\ntable_handle = sim.get_object_template_manager().get_template_handles(\"table\")[0]\n\ntable_object = sim.get_rigid_object_manager().add_object_by_template_handle(table_handle)\ntable_object.translation = [0.75, 0.0, 0.8]\n\n# [/setup]\n```\n\n----------------------------------------\n\nTITLE: Locobot Object Manipulation with Gripper and Path Following\nDESCRIPTION: This code controls the Locobot to pick up an object and move it to a new location. It uses `ObjectGripper` to grasp and release objects.  `ContinuousPathFollower` guides the Locobot along a pre-calculated path. The path follower's progress is monitored, and velocities are set to track waypoints.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_32\n\nLANGUAGE: Python\nCODE:\n```\ngripper = ObjectGripper(sim, locobot_obj.root_scene_node, np.array([0.0, 0.6, 0.0]))\ncontinuous_path_follower = ContinuousPathFollower(\n    sim, path1, locobot_obj.root_scene_node, waypoint_threshold=0.4\n)\n\nshow_waypoint_indicators = False  # @param {type:\"boolean\"}\ntime_step = 1.0 / 30.0\nfor i in range(2):\n    if i == 1:\n        gripper.grip(obj_1)\n        continuous_path_follower = ContinuousPathFollower(\n            sim, path2, locobot_obj.root_scene_node, waypoint_threshold=0.4\n        )\n\n    if show_waypoint_indicators:\n        for vis_obj in vis_objs:\n            rigid_obj_mgr.remove_object_by_id(vis_obj.object_id)\n        vis_objs = setup_path_visualization(continuous_path_follower)\n\n    # manually control the object's kinematic state via velocity integration\n    start_time = sim.get_world_time()\n    max_time = 30.0\n    while (\n        continuous_path_follower.progress < 1.0\n        and sim.get_world_time() - start_time < max_time\n    ):\n        continuous_path_follower.update_waypoint()\n        if show_waypoint_indicators:\n            vis_objs[0].translation = continuous_path_follower.waypoint\n\n        if locobot_obj.object_id < 0:\n            print(\"locobot_id \" + str(locobot_obj.object_id))\n            break\n\n        previous_rigid_state = locobot_obj.rigid_state\n\n        # set velocities based on relative waypoint position/direction\n        track_waypoint(\n            continuous_path_follower.waypoint,\n            previous_rigid_state,\n            vel_control,\n            dt=time_step,\n        )\n\n        # manually integrate the rigid state\n        target_rigid_state = vel_control.integrate_transform(\n            time_step, previous_rigid_state\n        )\n\n        # snap rigid state to navmesh and set state to object/agent\n        end_pos = sim.step_filter(\n            previous_rigid_state.translation, target_rigid_state.translation\n        )\n        locobot_obj.translation = end_pos\n        locobot_obj.rotation = target_rigid_state.rotation\n\n        # Check if a collision occurred\n        dist_moved_before_filter = (\n            target_rigid_state.translation - previous_rigid_state.translation\n        ).dot()\n        dist_moved_after_filter = (end_pos - previous_rigid_state.translation).dot()\n\n        # NB: There are some cases where ||filter_end - end_pos|| > 0 when a\n        # collision _didn't_ happen. One such case is going up stairs.  Instead,\n        # we check to see if the the amount moved after the application of the filter\n        # is _less_ than the amount moved before the application of the filter\n        EPS = 1e-5\n        collided = (dist_moved_after_filter + EPS) < dist_moved_before_filter\n\n        gripper.sync_states()\n        # run any dynamics simulation\n        sim.step_physics(time_step)\n\n        # render observation\n        observations.append(sim.get_sensor_observations())\n\n# release\ngripper.release()\nstart_time = sim.get_world_time()\nwhile sim.get_world_time() - start_time < 2.0:\n    sim.step_physics(time_step)\n    observations.append(sim.get_sensor_observations())\n```\n\n----------------------------------------\n\nTITLE: Loading and Rendering Font with Magnum (Python)\nDESCRIPTION: This code snippet demonstrates how to load a TrueType font (ProggyClean.ttf) using the Magnum graphics engine in Python. It initializes the font, creates a glyph cache, renders text using the font, and configures blending for transparency.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/data/fonts/README.txt#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport string\nimport magnum as mn\nfrom magnum import shaders, text\n\n.\n.\n.\n\nDISPLAY_FONT_SIZE = 16.0\nviewport_size: mn.Vector2i = mn.gl.default_framebuffer.viewport.size()\n\n# how much to displace window text relative to the center of the\n# app window\nTEXT_DELTA_FROM_CENTER = 0.5\n\n# the maximum number of chars displayable in the app window\n# using the magnum text module.\nMAX_DISPLAY_TEXT_CHARS = 256\n\n# Load a TrueTypeFont plugin and open the font file\ndisplay_font = text.FontManager().load_and_instantiate(\"TrueTypeFont\")\nrelative_path_to_font = \"../data/fonts/ProggyClean.ttf\"\ndisplay_font.open_file(\n    os.path.join(os.path.dirname(__file__), relative_path_to_font),\n    13,\n)\n\n# Glyphs we need to render everything\nglyph_cache = text.GlyphCache(mn.Vector2i(256))\ndisplay_font.fill_glyph_cache(\n    glyph_cache,\n    string.ascii_lowercase\n    + string.ascii_uppercase\n    + string.digits\n    + \":-_+,.! %µ\",\n)\n\n# magnum text object that displays CPU/GPU usage data in the app window\nwindow_text = text.Renderer2D(\n    display_font,\n    glyph_cache,\n    DISPLAY_FONT_SIZE,\n    text.Alignment.TOP_LEFT,\n)\nwindow_text.reserve(MAX_DISPLAY_TEXT_CHARS)\n\n# text object transform in window space is Projection matrix times Translation Matrix\nwindow_text_transform = mn.Matrix3.projection(\n    mn.Vector2(viewport_size)\n) @ mn.Matrix3.translation(\n    mn.Vector2(\n        viewport_size[0]\n        * -TEXT_DELTA_FROM_CENTER,\n        viewport_size[1]\n        * TEXT_DELTA_FROM_CENTER,\n    )\n)\nshader = shaders.VectorGL2D()\n\n# make magnum text background transparent\nmn.gl.Renderer.enable(mn.gl.Renderer.Feature.BLENDING)\nmn.gl.Renderer.set_blend_function(\n    mn.gl.Renderer.BlendFunction.ONE,\n    mn.gl.Renderer.BlendFunction.ONE_MINUS_SOURCE_ALPHA,\n)\nmn.gl.Renderer.set_blend_equation(\n    mn.gl.Renderer.BlendEquation.ADD, mn.gl.Renderer.BlendEquation.ADD\n)\n\n# draw text\nshader.bind_vector_texture(glyph_cache.texture)\nshader.transformation_projection_matrix = window_text_transform\nshader.color = [1.0, 1.0, 1.0]\nwindow_text.render(\n    f\"\"\"\nHello World\n    \"\"\"\n)\nshader.draw(window_text.mesh)\n```\n\n----------------------------------------\n\nTITLE: PathFinder Navigability Check\nDESCRIPTION: Explains `habitat_sim.nav.PathFinder.is_navigable`, which checks if an agent can stand at a specified point.  It snaps the point to the nearest polygon and compares the snapped point to the original.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.nav.PathFinder.is_navigable\n```\n\n----------------------------------------\n\nTITLE: Visibility Flags\nDESCRIPTION: This snippet sets the `-fvisibility=hidden` flag to control symbol visibility, improving build times and reducing library size.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fvisibility=hidden\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Simulator for Asset Viewer\nDESCRIPTION: This Python snippet initializes the Habitat-Sim simulator with specific configurations for asset viewing. It overrides default settings to use an empty scene and a 3rd person camera, suitable for examining individual assets.  Dependencies include the habitat_sim package.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/asset-viewer-tutorial.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# [initialize]\nimport argparse\nimport math\nimport os\nimport random\nimport sys\nfrom typing import Optional, Tuple\n\nimport attr\nimport magnum as mn\nimport numpy as np\n\nimport habitat_sim\nfrom habitat_sim.gfx import LightInfo, LightPositionModel, LightType\nfrom habitat_sim.utils.common import quat_from_two_vectors\n\ntry:\n    import cv2\n\n    has_cv2 = True\nexcept ImportError:\n    has_cv2 = False\n\nDEFAULT_CAMERA_ELEVATION = -mn.Rad(math.pi / 4)\n\n\ndef make_configuration(scene_filepath, render_gpu_device_id=0, camera_height=1.5):\n    settings = habitat_sim.SimulatorConfiguration()\n    settings.gpu_device_id = render_gpu_device_id\n    settings.scene_id = scene_filepath\n    settings.enable_physics = False\n\n    agent_0_config = habitat_sim.AgentConfiguration()\n\n    # Note: all sensors must have unique names\n    sensors = {\n        \"depth_sensor\": habitat_sim.SensorSpec(\n            uuid=\"depth_sensor\",\n            sensor_type=habitat_sim.SensorType.DEPTH,\n            resolution=[512, 512],\n            parameters={\n                \"hfov\": str(90),\n                \"near\": str(0.05),\n                \"far\": str(10.0),\n            },\n        ),\n        \"color_sensor\": habitat_sim.SensorSpec(\n            uuid=\"color_sensor\",\n            sensor_type=habitat_sim.SensorType.COLOR,\n            resolution=[512, 512],\n            parameters={\n                \"hfov\": str(90),\n            },\n        ),\n    }\n\n    agent_0_config.sensor_specifications = list(sensors.values())\n    agent_0_config.action_space = {\n        \"move_forward\": habitat_sim.ActionSpec(\"move_forward\", {}),\n        \"turn_left\": habitat_sim.ActionSpec(\"turn_left\", {}),\n        \"turn_right\": habitat_sim.ActionSpec(\"turn_right\", {}),\n    }\n\n    return habitat_sim.Configuration(settings, [agent_0_config])\n\n\n\ndef get_default_asset_viewer_camera_params():\n    return {\n        \"distance\": 3.0,\n        \"latitude\": 0.0,\n        \"longitude\": 0.0,\n        \"height\": 1.5,\n    }\n\n\n# [/initialize]\n```\n\n----------------------------------------\n\nTITLE: Display Object and Asset Attributes using UI\nDESCRIPTION: This snippet displays available file-based and primitive-based object and asset attributes using a widget-based user interface. It depends on functions `build_widget_ui`, `obj_attr_mgr`, and `prim_attr_mgr`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nbuild_widget_ui(obj_attr_mgr, prim_attr_mgr)\n```\n\n----------------------------------------\n\nTITLE: Finding Magnum Packages\nDESCRIPTION: This snippet uses the `find_package` command to locate the Magnum graphics library and its dependencies, including DebugTools, GlfwApplication, and Text. The `REQUIRED` keyword ensures that the build fails if these packages are not found.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/viewer/CMakeLists.txt#_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(Magnum REQUIRED DebugTools GlfwApplication Text)\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for Gfx Module\nDESCRIPTION: This snippet defines a list of source files (`gfx_SOURCES`) for the `gfx` module using the `set` command. The list includes both `.cpp` and `.h` files, and shaders.  It also conditionally appends source files for the background renderer if `BUILD_WITH_BACKGROUND_RENDERER` is enabled, and appends GfxShaderResources.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_8\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  gfx_SOURCES\n  gfx/CubeMap.cpp\n  gfx/CubeMap.h\n  gfx/Drawable.cpp\n  gfx/Drawable.h\n  gfx/DrawableConfiguration.cpp\n  gfx/DrawableConfiguration.h\n  gfx/DrawableGroup.cpp\n  gfx/DrawableGroup.h\n  gfx/GenericDrawable.cpp\n  gfx/GenericDrawable.h\n  gfx/SkinData.h\n  gfx/MeshVisualizerDrawable.cpp\n  gfx/MeshVisualizerDrawable.h\n  gfx/LightSetup.cpp\n  gfx/LightSetup.h\n  gfx/magnum.h\n  gfx/RenderCamera.cpp\n  gfx/RenderCamera.h\n  gfx/CubeMapCamera.cpp\n  gfx/CubeMapCamera.h\n  gfx/CubeMap.cpp\n  gfx/CubeMap.h\n  gfx/DebugLineRender.cpp\n  gfx/DebugLineRender.h\n  gfx/Renderer.cpp\n  gfx/Renderer.h\n  gfx/replay/Keyframe.h\n  gfx/replay/Player.cpp\n  gfx/replay/Player.h\n  gfx/replay/Recorder.cpp\n  gfx/replay/Recorder.h\n  gfx/replay/ReplayManager.h\n  gfx/replay/ReplayManager.cpp\n  gfx/WindowlessContext.cpp\n  gfx/WindowlessContext.h\n  gfx/RenderTarget.cpp\n  gfx/RenderTarget.h\n  gfx/ShaderManager.cpp\n  gfx/ShaderManager.h\n  gfx/PbrShader.cpp\n  gfx/PbrShader.h\n  gfx/PbrDrawable.cpp\n  gfx/PbrDrawable.h\n  gfx/TextureVisualizerShader.cpp\n  gfx/TextureVisualizerShader.h\n  gfx/CubeMapShaderBase.cpp\n  gfx/CubeMapShaderBase.h\n  gfx/DoubleSphereCameraShader.cpp\n  gfx/DoubleSphereCameraShader.h\n  gfx/EquirectangularShader.cpp\n  gfx/EquirectangularShader.h\n  gfx/PbrIBLHelper.cpp\n  gfx/PbrIBLHelper.h\n  gfx/PbrEquiRectangularToCubeMapShader.cpp\n  gfx/PbrEquiRectangularToCubeMapShader.h\n  gfx/PbrPrecomputedMapShader.cpp\n  gfx/PbrPrecomputedMapShader.h\n  gfx/PbrTextureUnit.h\n  gfx/GaussianFilterShader.h\n  gfx/GaussianFilterShader.cpp\n)\n\nif(BUILD_WITH_BACKGROUND_RENDERER)\n  list(APPEND gfx_SOURCES gfx/BackgroundRenderer.h gfx/BackgroundRenderer.cpp)\nendif()\n\nlist(APPEND gfx_SOURCES ${GfxShaderResources})\n```\n\n----------------------------------------\n\nTITLE: GUI Utility Functions for Habitat-sim\nDESCRIPTION: This snippet provides utility functions for building and managing interactive IPyWidget components for user interaction within the Habitat-sim environment.  It includes functions for creating dropdown lists of scene handles, event handling, and building the widget-based UI. It handles cases where IPyWidgets are not available.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ReplicaCAD_quickstart.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Event handler for dropdowns displaying file-based object handles\ndef on_scene_ddl_change(ddl_values):\n    global selected_scene\n    selected_scene = ddl_values[\"new\"]\n    return selected_scene\n\n\n# Build a dropdown list holding obj_handles and set its event handler\ndef set_handle_ddl_widget(scene_handles, sel_handle, on_change):\n    descStr = \"Available Scenes:\"\n    style = {\"description_width\": \"300px\"}\n    obj_ddl = widgets.Dropdown(\n        options=scene_handles,\n        value=sel_handle,\n        description=descStr,\n        style=style,\n        disabled=False,\n        layout={\"width\": \"max-content\"},\n    )\n\n    obj_ddl.observe(on_change, names=\"value\")\n    return obj_ddl, sel_handle\n\n\ndef set_button_launcher(desc):\n    button = widgets.Button(\n        description=desc,\n        layout={\"width\": \"max-content\"},\n    )\n    return button\n\n\n# Builds widget-based UI components\ndef build_widget_ui(metadata_mediator):\n    # Holds the user's desired scene\n    global selected_scene\n\n    # All file-based object template handles\n    scene_handles = metadata_mediator.get_scene_handles()\n    # Set default as first available valid handle, or NONE scene if none are available\n    if len(scene_handles) == 0:\n        selected_scene = \"NONE\"\n    else:\n        # Set default selection to be first valid non-NONE scene (for python consumers)\n        for scene_handle in scene_handles:\n            if \"NONE\" not in scene_handle:\n                selected_scene = scene_handle\n                break\n\n    if not HAS_WIDGETS:\n        # If no widgets present, return, using default\n        return\n\n    # Construct DDLs and assign event handlers\n    # Build widgets\n    scene_obj_ddl, selected_scene = set_handle_ddl_widget(\n        scene_handles,\n        selected_scene,\n        on_scene_ddl_change,\n    )\n\n    # Display DDLs\n    ipydisplay(scene_obj_ddl)\n\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--no-display\", dest=\"display\", action=\"store_false\")\n    parser.add_argument(\"--no-make-video\", dest=\"make_video\", action=\"store_false\")\n    parser.set_defaults(show_video=True, make_video=True)\n    args, _ = parser.parse_known_args()\n    show_video = args.display\n    display = args.display\n    make_video = args.make_video\nelse:\n    show_video = False\n    make_video = False\n    display = False\n```\n\n----------------------------------------\n\nTITLE: Registering Multiple Light Setups (Python)\nDESCRIPTION: This snippet shows how to register a new light setup with a specific name for later use. It demonstrates the creation and registration of a second lighting setup.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_8\n\nLANGUAGE: py\nCODE:\n```\n# [example 5]\nnew_lighting = habitat_sim.gfx.LightSetup()\n\npoint_light_1 = habitat_sim.gfx.LightInfo()\npoint_light_1.color = np.array([0.0, 0.5, 0.5])\npoint_light_1.vector = np.array([0, 1, 0, 0.0])\npoint_light_1.range = 10\npoint_light_1.intensity = 1.0\nnew_lighting.add_light(point_light_1)\n\nsim.set_light_setup(new_lighting, \"my_second_lighting_setup\")\n# [/example 5]\n```\n\n----------------------------------------\n\nTITLE: Continuous Path Follower Class in Python\nDESCRIPTION: This class implements a continuous path follower, allowing an agent to navigate along a predefined path in the Habitat-Sim environment. It initializes with a path, simulator instance, agent scene node, and waypoint threshold. The class calculates progress along the path and provides methods to update the agent's waypoint.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nclass ContinuousPathFollower:\n    def __init__(self, sim, path, agent_scene_node, waypoint_threshold):\n        self._sim = sim\n        self._points = path.points[:]\n        assert len(self._points) > 0\n        self._length = path.geodesic_distance\n        self._node = agent_scene_node\n        self._threshold = waypoint_threshold\n        self._step_size = 0.01\n        self.progress = 0  # geodesic distance -> [0,1]\n        self.waypoint = path.points[0]\n\n        # setup progress waypoints\n        _point_progress = [0]\n        _segment_tangents = []\n        _length = self._length\n        for ix, point in enumerate(self._points):\n            if ix > 0:\n                segment = point - self._points[ix - 1]\n                segment_length = np.linalg.norm(segment)\n                segment_tangent = segment / segment_length\n                _point_progress.append(\n                    segment_length / _length + _point_progress[ix - 1]\n                )\n                # t-1 -> t\n                _segment_tangents.append(segment_tangent)\n        self._point_progress = _point_progress\n        self._segment_tangents = _segment_tangents\n        # final tangent is duplicated\n        self._segment_tangents.append(self._segment_tangents[-1])\n\n        print(\"self._length = \" + str(self._length))\n        print(\"num points = \" + str(len(self._points)))\n        print(\"self._point_progress = \" + str(self._point_progress))\n        print(\"self._segment_tangents = \" + str(self._segment_tangents))\n\n    def pos_at(self, progress):\n        if progress <= 0:\n            return self._points[0]\n        elif progress >= 1.0:\n            return self._points[-1]\n\n        path_ix = 0\n        for ix, prog in enumerate(self._point_progress):\n            if prog > progress:\n                path_ix = ix\n                break\n\n        segment_distance = self._length * (progress - self._point_progress[path_ix - 1])\n        return (\n            self._points[path_ix - 1]\n            + self._segment_tangents[path_ix - 1] * segment_distance\n        )\n\n    def update_waypoint(self):\n        if self.progress < 1.0:\n            wp_disp = self.waypoint - self._node.absolute_translation\n            wp_dist = np.linalg.norm(wp_disp)\n            node_pos = self._node.absolute_translation\n            step_size = self._step_size\n            threshold = self._threshold\n            while wp_dist < threshold:\n                self.progress += step_size\n                self.waypoint = self.pos_at(self.progress)\n                if self.progress >= 1.0:\n                    break\n                wp_disp = self.waypoint - node_pos\n                wp_dist = np.linalg.norm(wp_disp)\n```\n\n----------------------------------------\n\nTITLE: Defining Habitat-sim Configuration Utility Functions\nDESCRIPTION: This snippet defines utility functions for configuring and initializing the Habitat-sim simulator. It includes functions to create the simulator configuration (`make_cfg`), set default settings (`make_default_settings`), and initialize the simulator from settings (`make_simulator_from_settings`). The configuration includes sensor specifications, agent configuration, and physics settings.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# @title Define Configuration Utility Functions { display-mode: \"form\" }\n# @markdown (double click to show code)\n\n# @markdown This cell defines a number of utility functions used throughout the tutorial to make simulator reconstruction easy:\n# @markdown - make_cfg\n# @markdown - make_default_settings\n# @markdown - make_simulator_from_settings\n\n\ndef make_cfg(settings):\n    sim_cfg = habitat_sim.SimulatorConfiguration()\n    sim_cfg.gpu_device_id = 0\n    sim_cfg.scene_id = settings[\"scene\"]\n    sim_cfg.enable_physics = settings[\"enable_physics\"]\n    # Optional; Specify the location of an existing scene dataset configuration\n    # that describes the locations and configurations of all the assets to be used\n    if \"scene_dataset_config\" in settings:\n        sim_cfg.scene_dataset_config_file = settings[\"scene_dataset_config\"]\n\n    # Note: all sensors must have the same resolution\n    sensor_specs = []\n    if settings[\"color_sensor_1st_person\"]:\n        color_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n        color_sensor_1st_person_spec.uuid = \"color_sensor_1st_person\"\n        color_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.COLOR\n        color_sensor_1st_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        color_sensor_1st_person_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n        color_sensor_1st_person_spec.orientation = [\n            settings[\"sensor_pitch\"],\n            0.0,\n            0.0,\n        ]\n        color_sensor_1st_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n        sensor_specs.append(color_sensor_1st_person_spec)\n    if settings[\"depth_sensor_1st_person\"]:\n        depth_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n        depth_sensor_1st_person_spec.uuid = \"depth_sensor_1st_person\"\n        depth_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.DEPTH\n        depth_sensor_1st_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        depth_sensor_1st_person_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n        depth_sensor_1st_person_spec.orientation = [\n            settings[\"sensor_pitch\"],\n            0.0,\n            0.0,\n        ]\n        depth_sensor_1st_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n        sensor_specs.append(depth_sensor_1st_person_spec)\n    if settings[\"semantic_sensor_1st_person\"]:\n        semantic_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n        semantic_sensor_1st_person_spec.uuid = \"semantic_sensor_1st_person\"\n        semantic_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.SEMANTIC\n        semantic_sensor_1st_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        semantic_sensor_1st_person_spec.position = [\n            0.0,\n            settings[\"sensor_height\"],\n            0.0,\n        ]\n        semantic_sensor_1st_person_spec.orientation = [\n            settings[\"sensor_pitch\"],\n            0.0,\n            0.0,\n        ]\n        semantic_sensor_1st_person_spec.sensor_subtype = (\n            habitat_sim.SensorSubType.PINHOLE\n        )\n        sensor_specs.append(semantic_sensor_1st_person_spec)\n    if settings[\"color_sensor_3rd_person\"]:\n        color_sensor_3rd_person_spec = habitat_sim.CameraSensorSpec()\n        color_sensor_3rd_person_spec.uuid = \"color_sensor_3rd_person\"\n        color_sensor_3rd_person_spec.sensor_type = habitat_sim.SensorType.COLOR\n        color_sensor_3rd_person_spec.resolution = [\n            settings[\"height\"],\n            settings[\"width\"],\n        ]\n        color_sensor_3rd_person_spec.position = [\n            0.0,\n            settings[\"sensor_height\"] + 0.2,\n            0.2,\n        ]\n        color_sensor_3rd_person_spec.orientation = [-math.pi / 4, 0.0, 0.0]\n        color_sensor_3rd_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n        sensor_specs.append(color_sensor_3rd_person_spec)\n\n    # Here you can specify the amount of displacement in a forward action and the turn angle\n    agent_cfg = habitat_sim.agent.AgentConfiguration()\n    agent_cfg.sensor_specifications = sensor_specs\n    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n\n\ndef make_default_settings():\n    settings = {\n        \"width\": 720,  # Spatial resolution of the observations\n        \"height\": 544,\n        \"scene\": os.path.join(\n            data_path, \"scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\"\n        ),  # Scene path\n        \"scene_dataset_config\": os.path.join(\n            data_path, \"scene_datasets/mp3d_example/mp3d.scene_dataset_config.json\"\n        ),  # MP3D scene dataset\n        \"default_agent\": 0,\n        \"sensor_height\": 1.5,  # Height of sensors in meters\n        \"sensor_pitch\": -math.pi / 8.0,  # sensor pitch (x rotation in rads)\n        \"color_sensor_1st_person\": True,  # RGB sensor\n        \"color_sensor_3rd_person\": False,  # RGB sensor 3rd person\n        \"depth_sensor_1st_person\": False,  # Depth sensor\n        \"semantic_sensor_1st_person\": False,  # Semantic sensor\n        \"seed\": 1,\n        \"enable_physics\": True,  # enable dynamics simulation\n    }\n    return settings\n\n\ndef make_simulator_from_settings(sim_settings):\n    cfg = make_cfg(sim_settings)\n    # clean-up the current simulator instance if it exists\n    global sim\n    global obj_attr_mgr\n    global prim_attr_mgr\n    global stage_attr_mgr\n    global rigid_obj_mgr\n    if sim != None:\n        sim.close()\n    # initialize the simulator\n    sim = habitat_sim.Simulator(cfg)\n    # Managers of various Attributes templates\n    obj_attr_mgr = sim.get_object_template_manager()\n    obj_attr_mgr.load_configs(str(os.path.join(data_path, \"objects/example_objects\")))\n    obj_attr_mgr.load_configs(str(os.path.join(data_path, \"objects/locobot_merged\")))\n    prim_attr_mgr = sim.get_asset_template_manager()\n    stage_attr_mgr = sim.get_stage_template_manager()\n    # Manager providing access to rigid objects\n    rigid_obj_mgr = sim.get_rigid_object_manager()\n```\n\n----------------------------------------\n\nTITLE: Configuration Utility Functions for Habitat-sim\nDESCRIPTION: This snippet defines utility functions for configuring the Habitat-sim simulator. It includes functions to create configurations, define default settings, and initialize the simulator based on these settings. The functions `make_cfg`, `make_default_settings`, and `make_simulator_from_settings` are defined to simplify the simulator setup process.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ReplicaCAD_quickstart.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef make_cfg(settings):\n    sim_cfg = habitat_sim.SimulatorConfiguration()\n    sim_cfg.gpu_device_id = 0\n    sim_cfg.scene_dataset_config_file = settings[\"scene_dataset\"]\n    sim_cfg.scene_id = settings[\"scene\"]\n    sim_cfg.enable_physics = settings[\"enable_physics\"]\n    # Specify the location of the scene dataset\n    if \"scene_dataset_config\" in settings:\n        sim_cfg.scene_dataset_config_file = settings[\"scene_dataset_config\"]\n    if \"override_scene_light_defaults\" in settings:\n        sim_cfg.override_scene_light_defaults = settings[\n            \"override_scene_light_defaults\"\n        ]\n    if \"scene_light_setup\" in settings:\n        sim_cfg.scene_light_setup = settings[\"scene_light_setup\"]\n\n    # Note: all sensors must have the same resolution\n    sensor_specs = []\n    color_sensor_1st_person_spec = habitat_sim.CameraSensorSpec()\n    color_sensor_1st_person_spec.uuid = \"color_sensor_1st_person\"\n    color_sensor_1st_person_spec.sensor_type = habitat_sim.SensorType.COLOR\n    color_sensor_1st_person_spec.resolution = [\n        settings[\"height\"],\n        settings[\"width\"],\n    ]\n    color_sensor_1st_person_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n    color_sensor_1st_person_spec.orientation = [\n        settings[\"sensor_pitch\"],\n        0.0,\n        0.0,\n    ]\n    color_sensor_1st_person_spec.sensor_subtype = habitat_sim.SensorSubType.PINHOLE\n    sensor_specs.append(color_sensor_1st_person_spec)\n\n    # Here you can specify the amount of displacement in a forward action and the turn angle\n    agent_cfg = habitat_sim.agent.AgentConfiguration()\n    agent_cfg.sensor_specifications = sensor_specs\n\n    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n\n\ndef make_default_settings():\n    settings = {\n        \"width\": 1280,  # Spatial resolution of the observations\n        \"height\": 720,\n        \"scene_dataset\": os.path.join(\n            data_path, \"replica_cad/replicaCAD.scene_dataset_config.json\"\n        ),  # dataset path\n        \"scene\": \"NONE\",  # Scene path\n        \"default_agent\": 0,\n        \"sensor_height\": 1.5,  # Height of sensors in meters\n        \"sensor_pitch\": 0.0,  # sensor pitch (x rotation in rads)\n        \"seed\": 1,\n        \"enable_physics\": True,  # enable dynamics simulation\n    }\n    return settings\n\n\ndef make_simulator_from_settings(sim_settings):\n    cfg = make_cfg(sim_settings)\n    # clean-up the current simulator instance if it exists\n    global sim\n    global obj_attr_mgr\n    global prim_attr_mgr\n    global stage_attr_mgr\n    global rigid_obj_mgr\n    global metadata_mediator\n\n    if sim != None:\n        sim.close()\n    # initialize the simulator\n    sim = habitat_sim.Simulator(cfg)\n    # Managers of various Attributes templates\n    obj_attr_mgr = sim.get_object_template_manager()\n    obj_attr_mgr.load_configs(str(os.path.join(data_path, \"objects/example_objects\")))\n    prim_attr_mgr = sim.get_asset_template_manager()\n    stage_attr_mgr = sim.get_stage_template_manager()\n    # Manager providing access to rigid objects\n    rigid_obj_mgr = sim.get_rigid_object_manager()\n    # get metadata_mediator\n    metadata_mediator = sim.metadata_mediator\n\n    # UI-populated handles used in various cells.  Need to initialize to valid\n    # value in case IPyWidgets are not available.\n    # Holds the user's desired scene handle\n    global selected_scene\n    selected_scene = \"NONE\"\n```\n\n----------------------------------------\n\nTITLE: Setting Default Configuration Paths\nDESCRIPTION: This snippet defines default paths for PBR shader and physics manager configuration files using `set`.  It defines relative paths (`ESP_DEFAULT_PBRSHADER_CONFIG_REL_PATH`, `ESP_DEFAULT_PHYSICS_CONFIG_REL_PATH`) and then constructs absolute paths based on the `PROJECT_SOURCE_DIR`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\n# Set PBR configuration default path. Used in gfx/configure.h\nset(ESP_DEFAULT_PBRSHADER_CONFIG_REL_PATH ./data/default.pbr_config.json)\nset(ESP_DEFAULT_PBRSHADER_CONFIG\n    ${PROJECT_SOURCE_DIR}/.${ESP_DEFAULT_PBRSHADER_CONFIG_REL_PATH}\n)\n\n# Set Physics Manager configuration default path. Used in physics/configure.h\nset(ESP_DEFAULT_PHYSICS_CONFIG_REL_PATH ./data/default.physics_config.json)\nset(ESP_DEFAULT_PHYSICS_CONFIG\n    ${PROJECT_SOURCE_DIR}/.${ESP_DEFAULT_PHYSICS_CONFIG_REL_PATH}\n)\n```\n\n----------------------------------------\n\nTITLE: Find Magnum Packages\nDESCRIPTION: This snippet uses the find_package command to locate the Magnum graphics engine and its related plugins. REQUIRED ensures that the build will fail if these packages are not found. DebugTools, AnyImageConverter, AnySceneImporter, and AnyImageImporter are specific Magnum components. BasisImporter, GltfImporter, KtxImporter, OpenExrImporter, OpenExrImageConverter, StanfordImporter, StbImageImporter, StbImageConverter, UfbxImporter are Magnum plugins used for importing different file formats.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(\n  Magnum\n  REQUIRED\n  DebugTools\n  AnyImageConverter\n  AnySceneImporter\n  AnyImageImporter\n)\nfind_package(\n  MagnumPlugins\n  REQUIRED\n  BasisImporter\n  GltfImporter\n  KtxImporter\n  OpenExrImporter\n  OpenExrImageConverter\n  StanfordImporter\n  StbImageImporter\n  StbImageConverter\n  UfbxImporter\n  OPTIONAL_COMPONENTS GltfSceneConverter KtxImageConverter\n)\n```\n\n----------------------------------------\n\nTITLE: Building Widget UI (Habitat-Sim)\nDESCRIPTION: The `build_widget_ui` function constructs the widget-based user interface for Habitat-Sim, allowing users to select object templates. It retrieves lists of file-based, primitive-based object handles, and primitive asset handles, constructs dropdown widgets using these handles, assigns event handlers to the dropdowns, and displays these dropdowns in the UI.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndef build_widget_ui(obj_attr_mgr, prim_attr_mgr):\n    # Holds the user's desired file-based object template handle\n    global sel_file_obj_handle\n    sel_file_obj_handle = \"\"\n\n    # Holds the user's desired primitive-based object template handle\n    global sel_prim_obj_handle\n    sel_prim_obj_handle = \"\"\n\n    # Holds the user's desired primitive asset template handle\n    global sel_asset_handle\n    sel_asset_handle = \"\"\n\n    # Construct DDLs and assign event handlers\n    # All file-based object template handles\n    file_obj_handles = obj_attr_mgr.get_file_template_handles()\n    # All primitive asset-based object template handles\n    prim_obj_handles = obj_attr_mgr.get_synth_template_handles()\n    # All primitive asset handles template handles\n    prim_asset_handles = prim_attr_mgr.get_template_handles()\n    # If not using widgets, set as first available handle\n    if not HAS_WIDGETS:\n        sel_file_obj_handle = file_obj_handles[0]\n        sel_prim_obj_handle = prim_obj_handles[0]\n        sel_prim_obj_handle = prim_asset_handles[0]\n        return\n\n    # Build widgets\n    file_obj_ddl, sel_file_obj_handle = set_handle_ddl_widget(\n        file_obj_handles,\n        \"File-based Object\",\n        sel_file_obj_handle,\n        on_file_obj_ddl_change,\n    )\n    prim_obj_ddl, sel_prim_obj_handle = set_handle_ddl_widget(\n        prim_obj_handles,\n        \"Primitive-based Object\",\n        sel_prim_obj_handle,\n        on_prim_obj_ddl_change,\n    )\n    prim_asset_ddl, sel_asset_handle = set_handle_ddl_widget(\n        prim_asset_handles, \"Primitive Asset\", sel_asset_handle, on_prim_ddl_change\n    )\n    # Display DDLs\n    ipydisplay(file_obj_ddl)\n    ipydisplay(prim_obj_ddl)\n    ipydisplay(prim_asset_ddl)\n```\n\n----------------------------------------\n\nTITLE: Build Widget UI for object and primitive assets (Python)\nDESCRIPTION: This code snippet creates a GUI to select a target object and primitive asset. It depends on `obj_attr_mgr` and `prim_attr_mgr` and calls the `build_widget_ui` function to create the UI.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nbuild_widget_ui(obj_attr_mgr, prim_attr_mgr)\n```\n\n----------------------------------------\n\nTITLE: Editing Solid Capsule Template\nDESCRIPTION: Acquires the default solid capsule template and allows for modification of its properties such as texture coordinates, tangents, hemisphere rings, cylinder rings, number of segments, and half-length. The modified template can then be registered.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_44\n\nLANGUAGE: Python\nCODE:\n```\n# Acquire default template\ncapsule_solid_template = prim_attr_mgr.get_default_capsule_template(False)\n\n\ndef edit_solid_capsule(edit_template):\n    # @markdown Whether to build with texture coordinate support\n    use_texture_coords = False  # @param {type:\"boolean\"}\n    edit_template.use_texture_coords = use_texture_coords\n    # @markdown Whether to build tangents\n    use_tangents = False  # @param {type:\"boolean\"}\n    edit_template.use_tangents = use_tangents\n    # @markdown  Number of (face) rings for each hemisphere. Must be larger or equal to 1\n    hemisphere_rings = 6  # @param {type:\"slider\", min:1, max:10, step:1}\n    edit_template.hemisphere_rings = hemisphere_rings\n    # @markdown Number of (face) rings for cylinder. Must be larger or equal to 1.\n    cylinder_rings = 1  # @param {type:\"slider\", min:1, max:10, step:1}\n    edit_template.cylinder_rings = cylinder_rings\n    # @markdown  Number of (face) segments. Must be larger or equal to 3.\n    num_segments = 16  # @param {type:\"slider\", min:3, max:30, step:1}\n    edit_template.num_segments = num_segments\n    # @markdown Half the length of cylinder part.\n    half_length = 0.95  # @param {type:\"slider\", min:0.05, max:2.0, step:0.05}\n    edit_template.half_length = half_length\n    # @markdown Do you want to make a solid capsule using your above modifications?\n    make_modified_solid_capsule = True  # @param {type:\"boolean\"}\n    # if make is set to true, save modified template.\n    register_prim_template_if_valid(\n        make_modified_solid_capsule,\n        edit_template,\n        solid_handles_to_use,\n        \"capsule3DSolid\",\n    )\n\n\nedit_solid_capsule(capsule_solid_template)\n```\n\n----------------------------------------\n\nTITLE: Kinematic Object Update in Habitat\nDESCRIPTION: This snippet shows how to manually update the kinematic state of an object in Habitat. It loads a clamp object, sets its motion type to kinematic, and then iteratively updates its translation and rotation over time. The simulation is stepped, and observations are collected for video generation. It utilizes `obj_templates_mgr`, `rigid_obj_mgr`, and direct manipulation of `translation` and `rotation` properties.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n    # [kinematic_update]\n    observations = []\n\n    clamp_template_handle = obj_templates_mgr.get_template_handles(\n        \"data/objects/example_objects/largeclamp\"\n    )[0]\n    clamp_obj = rigid_obj_mgr.add_object_by_template_handle(clamp_template_handle)\n    clamp_obj.motion_type = habitat_sim.physics.MotionType.KINEMATIC\n    clamp_obj.translation = [0.8, 0.2, 0.5]\n\n    start_time = sim.get_world_time()\n    dt = 1.0\n    while sim.get_world_time() < start_time + dt:\n        # manually control the object's kinematic state\n        clamp_obj.translation += [0.0, 0.0, 0.01]\n        clamp_obj.rotation = (\n            mn.Quaternion.rotation(mn.Rad(0.05), [-1.0, 0.0, 0.0]) * clamp_obj.rotation\n        )\n        sim.step_physics(1.0 / 60.0)\n        observations.append(sim.get_sensor_observations())\n\n    if make_video:\n        vut.make_video(\n            observations,\n            \"rgba_camera_1stperson\",\n            \"color\",\n            output_path + \"kinematic_update\",\n            open_vid=show_video,\n        )\n\n    # [/kinematic_update]\n```\n\n----------------------------------------\n\nTITLE: Linking Replayer Libraries\nDESCRIPTION: This snippet uses the `target_link_libraries` command to link the replayer executable with the necessary libraries. The `PRIVATE` keyword specifies that these libraries are only required for building the replayer executable and are not exposed to other targets. The libraries linked include habitat_sim, gfx_batch, Magnum, GlfwApplication, and the Magnum plugins found earlier.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/replayer/CMakeLists.txt#_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(\n  replayer\n  PRIVATE habitat_sim\n          gfx_batch\n          Magnum::Application\n          Magnum::GlfwApplication\n          MagnumPlugins::BasisImporter\n          MagnumPlugins::GltfImporter\n          MagnumPlugins::KtxImporter\n          MagnumPlugins::StanfordImporter\n          MagnumPlugins::StbImageImporter\n          MagnumPlugins::StbImageConverter\n          MagnumPlugins::UfbxImporter\n)\n```\n\n----------------------------------------\n\nTITLE: Conditional Linking of Bullet Physics Libraries\nDESCRIPTION: This snippet conditionally links the Bullet physics libraries (MagnumIntegration::Bullet and Bullet::Dynamics) to the `habitat_sim` target if the `BUILD_WITH_BULLET` flag is enabled. This enables physics simulation using the Bullet physics engine.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_28\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_WITH_BULLET)\n  target_link_libraries(habitat_sim PUBLIC MagnumIntegration::Bullet Bullet::Dynamics)\nendif() #BUILD_WITH_BULLET\n```\n\n----------------------------------------\n\nTITLE: Select Target Object from GUI\nDESCRIPTION: This snippet calls the `build_widget_ui` function to construct the GUI elements related to object selection.  The object attribute manager and primitive attribute manager are passed as arguments to allow the GUI to dynamically populate selection options based on available objects and assets.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nbuild_widget_ui(obj_attr_mgr, prim_attr_mgr)\n```\n\n----------------------------------------\n\nTITLE: Waypoint Tracking Implementation in Python\nDESCRIPTION: This function implements waypoint tracking by adjusting the agent's linear and angular velocities to move towards a given waypoint. It calculates the angle error between the agent's forward direction and the direction to the waypoint, and adjusts the velocities accordingly.  The function leverages `habitat_sim`'s math libraries for vector operations and angle calculations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ndef track_waypoint(waypoint, rs, vc, dt=1.0 / 60.0):\n    angular_error_threshold = 0.5\n    max_linear_speed = 1.0\n    max_turn_speed = 1.0\n    glob_forward = rs.rotation.transform_vector(mn.Vector3(0, 0, -1.0)).normalized()\n    glob_right = rs.rotation.transform_vector(mn.Vector3(-1.0, 0, 0)).normalized()\n    to_waypoint = mn.Vector3(waypoint) - rs.translation\n    u_to_waypoint = to_waypoint.normalized()\n    angle_error = float(mn.math.angle(glob_forward, u_to_waypoint))\n\n    new_velocity = 0\n    if angle_error < angular_error_threshold:\n        # speed up to max\n        new_velocity = (vc.linear_velocity[2] - max_linear_speed) / 2.0\n    else:\n        # slow down to 0\n        new_velocity = (vc.linear_velocity[2]) / 2.0\n    vc.linear_velocity = mn.Vector3(0, 0, new_velocity)\n\n    # angular part\n    rot_dir = 1.0\n    if mn.math.dot(glob_right, u_to_waypoint) < 0:\n        rot_dir = -1.0\n    angular_correction = 0.0\n    if angle_error > (max_turn_speed * 10.0 * dt):\n        angular_correction = max_turn_speed\n    else:\n        angular_correction = angle_error / 2.0\n\n    vc.angular_velocity = mn.Vector3(\n        0, np.clip(rot_dir * angular_correction, -max_turn_speed, max_turn_speed), 0\n    )\n```\n\n----------------------------------------\n\nTITLE: Setting Ball Properties and Initial State\nDESCRIPTION: This snippet loads a sphere template, sets its mass based on a slider input, registers it as \"ball\", adds it to the scene, and sets its initial position based on the agent's position with an offset. Initial linear and angular velocities are also set based on slider inputs.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# @markdown ###Ball properties:\n# load the ball\nsphere_handle = obj_attr_mgr.get_template_handles(\"uvSphereSolid\")[0]\nsphere_template_cpy = obj_attr_mgr.get_template_by_handle(sphere_handle)\n# @markdown Mass:\nball_mass = 5.01  # @param {type:\"slider\", min:0.01, max:50.0, step:0.01}\nsphere_template_cpy.mass = ball_mass\nobj_attr_mgr.register_template(sphere_template_cpy, \"ball\")\n\nball_obj = rigid_obj_mgr.add_object_by_template_handle(\"ball\")\nset_object_state_from_agent(sim, ball_obj, offset=np.array([0, 1.4, 0]))\n\n# @markdown Initial linear velocity (m/sec):\nlin_vel_x = 0  # @param {type:\"slider\", min:-10, max:10, step:0.1}\nlin_vel_y = 1  # @param {type:\"slider\", min:-10, max:10, step:0.1}\nlin_vel_z = 5  # @param {type:\"slider\", min:0, max:10, step:0.1}\nball_obj.linear_velocity = mn.Vector3(lin_vel_x, lin_vel_y, lin_vel_z)\n\n# @markdown Initial angular velocity (rad/sec):\nang_vel_x = 0  # @param {type:\"slider\", min:-100, max:100, step:0.1}\nang_vel_y = 0  # @param {type:\"slider\", min:-100, max:100, step:0.1}\nang_vel_z = 0  # @param {type:\"slider\", min:-100, max:100, step:0.1}\nball_obj.angular_velocity = mn.Vector3(ang_vel_x, ang_vel_y, ang_vel_z)\n```\n\n----------------------------------------\n\nTITLE: Add Batched Replay Renderer Test (Conditional)\nDESCRIPTION: This snippet adds a test named BatchReplayRendererTest conditionally based on the BUILD_WITH_BACKGROUND_RENDERER option.  It links the test against habitat_sim, gfx_batch, and several Magnum plugins used for importing various file formats. target_include_directories adds the binary directory to the include path for the test.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_WITH_BACKGROUND_RENDERER)\n  corrade_add_test(\n    BatchReplayRendererTest\n    BatchReplayRendererTest.cpp\n    LIBRARIES\n    habitat_sim\n    gfx_batch\n    MagnumPlugins::GltfImporter\n    MagnumPlugins::OpenExrImageConverter\n    MagnumPlugins::OpenExrImporter\n    MagnumPlugins::StbImageImporter\n    MagnumPlugins::StbImageConverter\n    MagnumPlugins::UfbxImporter\n  )\n  target_include_directories(\n    BatchReplayRendererTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR}\n  )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for the Scene Module\nDESCRIPTION: This snippet defines a CMake variable `scene_SOURCES` and assigns it a list of source files related to scene representation and management.  These files handle different scene formats (Gibson, HM3D, MP3D, Replica), scene graphs, scene managers, and semantic information. The listed files include C++ source and header files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_12\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  scene_SOURCES\n  scene/GibsonSemanticScene.cpp\n  scene/GibsonSemanticScene.h\n  scene/HM3DSemanticScene.cpp\n  scene/HM3DSemanticScene.h\n  scene/Mp3dSemanticScene.cpp\n  scene/Mp3dSemanticScene.h\n  scene/ReplicaSemanticScene.cpp\n  scene/ReplicaSemanticScene.h\n  scene/SceneGraph.cpp\n  scene/SceneGraph.h\n  scene/SceneManager.cpp\n  scene/SceneManager.h\n  scene/SceneNode.cpp\n  scene/SceneNode.h\n  scene/SemanticScene.cpp\n  scene/SemanticScene.h\n)\n```\n\n----------------------------------------\n\nTITLE: Registering Primitive Template\nDESCRIPTION: This function checks if a primitive template is valid and registers it using the Asset Template Manager. If the template is valid, it's registered, and its handle is added to a dictionary. If invalid, an error message is printed. If no modification is requested, it fetches and uses the default template.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_40\n\nLANGUAGE: Python\nCODE:\n```\ndef register_prim_template_if_valid(\n    make_modified, template, dict_of_handles, handle_key\n):\n    if make_modified:\n        if template.is_valid_template:\n            prim_attr_mgr.register_template(template)\n            dict_of_handles[handle_key] = template.handle\n            print(\n                \"Primitive Template named {} is registered for {}.\".format(\n                    template.handle, handle_key\n                )\n            )\n        else:\n            print(\n                \"Primitive Template configuration is invalid for {}, so unable to register.\".format(\n                    handle_key\n                )\n            )\n    else:\n        dict_of_handles[handle_key] = prim_attr_mgr.get_template_handles(handle_key)[0]\n        print(\"Default Primitive Template used at key {}.\".format(handle_key))\n```\n\n----------------------------------------\n\nTITLE: Configuring Object Template Handles (GUI)\nDESCRIPTION: This snippet uses the `build_widget_ui` function to create a GUI for selecting object templates from the `obj_attr_mgr` and `prim_attr_mgr`. It allows users to interactively choose object templates for use in the simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nbuild_widget_ui(obj_attr_mgr, prim_attr_mgr)\n```\n\n----------------------------------------\n\nTITLE: Query NavMesh Properties Python\nDESCRIPTION: This code demonstrates how to query various properties of the NavMesh, including its area, bounds, random navigable points, island radius, and distance to the closest obstacle.  It requires an initialized Pathfinder and leverages methods such as `navigable_area`, `get_bounds`, `get_random_navigable_point`, `island_radius`, and `distance_to_closest_obstacle`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nprint(\"NavMesh area = \" + str(sim.pathfinder.navigable_area))\nprint(\"Bounds = \" + str(sim.pathfinder.get_bounds()))\n\npathfinder_seed = 1  # @param {type:\"integer\"}\nsim.pathfinder.seed(pathfinder_seed)\nnav_point = sim.pathfinder.get_random_navigable_point()\nprint(\"Random navigable point : \" + str(nav_point))\nprint(\"Is point navigable? \" + str(sim.pathfinder.is_navigable(nav_point)))\n\nprint(\"Nav island radius : \" + str(sim.pathfinder.island_radius(nav_point)))\n\nmax_search_radius = 2.0  # @param {type:\"number\"}\nprint(\n    \"Distance to obstacle: \"\n    + str(sim.pathfinder.distance_to_closest_obstacle(nav_point, max_search_radius))\n)\nhit_record = sim.pathfinder.closest_obstacle_surface_point(\n    nav_point, max_search_radius\n)\nprint(\"Closest obstacle HitRecord:\")\nprint(\" point: \" + str(hit_record.hit_pos))\nprint(\" normal: \" + str(hit_record.hit_normal))\nprint(\" distance: \" + str(hit_record.hit_dist))\n\nvis_points = [nav_point]\n\nif math.isinf(hit_record.hit_dist):\n    print(\"No obstacle found within search radius.\")\nelse:\n    perturbed_point = hit_record.hit_pos - hit_record.hit_normal * 0.2\n    print(\"Perturbed point : \" + str(perturbed_point))\n    print(\n        \"Is point navigable? \" + str(sim.pathfinder.is_navigable(perturbed_point))\n    )\n    snapped_point = sim.pathfinder.snap_point(perturbed_point)\n    print(\"Snapped point : \" + str(snapped_point))\n    print(\"Is point navigable? \" + str(sim.pathfinder.is_navigable(snapped_point)))\n    vis_points.append(snapped_point)\n```\n\n----------------------------------------\n\nTITLE: Load and Sequence Multiple Gfx Replays (Habitat-Sim, Python)\nDESCRIPTION: Loads multiple copies of a gfx replay and sets each to a different keyframe index to create a sequence image.  The agent's camera is moved to a third-person perspective. The resulting observations are then used to create a video, effectively showing a still image multiple times as a workaround for missing make_image functionality. It depends on os module to delete replay file.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nobservations = []\nnum_copies = 30\nother_players = []\nfor i in range(num_copies):\n    other_player = sim.gfx_replay_manager.read_keyframes_from_file(replay_filepath)\n    assert other_player\n    other_player.set_keyframe_index(\n        other_player.get_num_keyframes() // (num_copies - 1) * i\n    )\n    other_players.append(other_player)\n\n# place a third-person camera\nsensor_node.translation = [1.0, -0.9, -0.3]\nsensor_node.rotation = mn.Quaternion.rotation(mn.Deg(-115), mn.Vector3(0.0, 1.0, 0))\n\n# Create a video by repeating this image a few times. This is a workaround because\n# we don't have make_image available in viz_utils. TODO: add make_image to\n# viz_utils.\nobs = sim.get_sensor_observations()\nfor _ in range(10):\n    observations.append(obs)\n\nif make_video:\n    vut.make_video(\n        observations,\n        \"rgba_camera\",\n        \"color\",\n        output_path + \"replay_playback4\",\n        open_vid=show_video,\n    )\n\n# clean up the players\nfor other_player in other_players:\n    other_player.close()\n\n# clean up replay file\nos.remove(replay_filepath)\n```\n\n----------------------------------------\n\nTITLE: Modifying Object Template from File in Habitat Sim (Python)\nDESCRIPTION: This code snippet demonstrates how to modify an object template from a file by iteratively changing its scale. It clears existing objects, saves the initial camera state, retrieves an object template by its handle, instantiates an object using the template, sets an offset for the object's position relative to the agent, and prepares for iterative modification of the template.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_33\n\nLANGUAGE: python\nCODE:\n```\n# @title 1 Simple File-based Object Template modification. { display-mode: \"form\" }\n# @markdown Running this will demonstrate how to create objects of varying size from a file-based template by iteratively modifying the template's scale value.  This will also demonstrate how to delete unwanted templates from the library.\n\n# clear all objects and observations\nrigid_obj_mgr.remove_all_objects()\nobservations = []\n# save initial camera state\ninit_config = init_camera_track_config(sim)\n\n# Use selected handle as object handle\nobj_template_handle = sel_file_obj_handle\n# Get File-based template for object using its handle - retrieves\n# a copy of this object's attributes template.\nobj_template = obj_attr_mgr.get_template_by_handle(obj_template_handle)\n\n# Add object instantiated by desired template using template handle.\nfile_obj = rigid_obj_mgr.add_object_by_template_handle(obj_template_handle)\n\n# Set desired offset from agent location to place object\noffset = np.array([-1.2, 0.1, -1.5])\n# Move object to be in front of the agent\nset_object_state_from_agent(sim, file_obj, offset=offset)\n\n# Templates have editable fields that will directly affect the instanced\n# objects built from them.  Here we iteratively modify and re-register the\n# template, instancing a new object each time.\n```\n\n----------------------------------------\n\nTITLE: Editing Solid Cone Template\nDESCRIPTION: Acquires the default solid cone template and allows for modification of its properties such as texture coordinates, tangents, number of rings, number of segments, half-length, and whether to cap the base. The modified template can then be registered.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_46\n\nLANGUAGE: Python\nCODE:\n```\n# Acquire default template\ncone_solid_template = prim_attr_mgr.get_default_cone_template(False)\n\n\ndef edit_solid_cone(edit_template):\n    # @markdown Whether to build with texture coordinate support\n    use_texture_coords = False  # @param {type:\"boolean\"}\n    edit_template.use_texture_coords = use_texture_coords\n    # @markdown Whether to build tangents\n    use_tangents = False  # @param {type:\"boolean\"}\n    edit_template.use_tangents = use_tangents\n    # @markdown Number of (face) rings. Must be larger or equal to 1.\n    num_rings = 6  # @param {type:\"slider\", min:1, max:10, step:1}\n    edit_template.num_rings = num_rings\n    # @markdown Number of (face) segments. Must be larger or equal to 3.\n    num_segments = 20  # @param {type:\"slider\", min:3, max:40, step:1}\n    edit_template.num_segments = num_segments\n    # @markdown Half the cone length\n    half_length = 1.25  # @param {type:\"slider\", min:0.05, max:2.0, step:0.05}\n    edit_template.half_length = half_length\n    # @markdown Whether to cap the base of the cone\n    use_cap_end = True  # @param {type:\"boolean\"}\n    edit_template.use_cap_end = use_cap_end\n    # @markdown Do you want to make a solid cone using your above modifications?\n    make_modified_solid_cone = True  # @param {type:\"boolean\"}\n    # if make is set to true, save modified template.\n    register_prim_template_if_valid(\n        make_modified_solid_cone, edit_template, solid_handles_to_use, \"coneSolid\"\n    )\n\n\nedit_solid_cone(cone_solid_template)\n```\n\n----------------------------------------\n\nTITLE: Setting Target Properties\nDESCRIPTION: This snippet sets the `RUNTIME_OUTPUT_DIRECTORY` property for the `magnum-imageconverter` target. It specifies that the output executable should be placed in the `${CMAKE_CURRENT_BINARY_DIR}` directory, which is the current binary directory of the CMake project.  This helps organize the build output.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/imageconverter/CMakeLists.txt#_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nset_target_properties(\n  magnum-imageconverter PROPERTIES RUNTIME_OUTPUT_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Linking Viewer Libraries\nDESCRIPTION: This snippet uses the `target_link_libraries` command to link the necessary libraries to the viewer executable. It links against habitat_sim, Magnum::DebugTools, Magnum::GlfwApplication, Magnum::Text, and several Magnum plugin libraries. The `PRIVATE` keyword indicates that these libraries are only required for the viewer and not for other targets that might link against it.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/viewer/CMakeLists.txt#_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(\n  viewer\n  PRIVATE habitat_sim\n          Magnum::DebugTools\n          Magnum::GlfwApplication\n          Magnum::Text\n          MagnumPlugins::BasisImporter\n          MagnumPlugins::GltfImporter\n          MagnumPlugins::KtxImporter\n          MagnumPlugins::StanfordImporter\n          MagnumPlugins::StbImageImporter\n          MagnumPlugins::StbImageConverter\n          MagnumPlugins::StbTrueTypeFont\n          MagnumPlugins::UfbxImporter\n)\n```\n\n----------------------------------------\n\nTITLE: Downloading MP3D Example Scene with Python\nDESCRIPTION: This code snippet demonstrates how to download the MP3D example scene using the `habitat_sim.utils.datasets_download` module. It uses the `--uids` argument to specify `mp3d_example_scene` and the `--data-path` argument to set the destination directory to `data/`. This is useful for quickly testing Habitat-Sim with a sample MP3D scene.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\npython -m habitat_sim.utils.datasets_download --uids mp3d_example_scene --data-path data/\n```\n\n----------------------------------------\n\nTITLE: Scene Shader Swap in Habitat-Sim (Python)\nDESCRIPTION: This snippet demonstrates how to swap the scene shader by reconfiguring the simulator. This is necessary when switching between Flat and PBR (or Phong) shading setups.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_2\n\nLANGUAGE: py\nCODE:\n```\n# [scene swap shader]\n# setup up scene shader here, FLAT or PBR\ncfg.sim_cfg.override_scene_light_defaults = True\nsim.close()\nsim = habitat_sim.Simulator(cfg)\nagent = sim.initialize_agent(0)\n\n# NOTE: asset loading specifics mean the simulator must be closed and\n# re-initialized to swap between Flat and PBR shading setups.\n# [/scene swap shader]\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for the Physics Module\nDESCRIPTION: This snippet defines a CMake variable `physics_SOURCES` and assigns it a list of source files related to physics simulation. It includes headers and source files for articulated objects, collision handling, object managers, and physics managers. It also contains source files for the URDF importer, which is used to import robot models.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_13\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  physics_SOURCES\n  physics/ArticulatedLink.h\n  physics/ArticulatedObject.h\n  physics/CollisionGroupHelper.cpp\n  physics/CollisionGroupHelper.h\n  physics/objectManagers/ArticulatedObjectManager.cpp\n  physics/objectManagers/ArticulatedObjectManager.h\n  physics/objectManagers/PhysicsObjectBaseManager.h\n  physics/objectManagers/RigidObjectManager.cpp\n  physics/objectManagers/RigidObjectManager.h\n  physics/objectWrappers/ManagedArticulatedObject.h\n  physics/objectWrappers/ManagedPhysicsObjectBase.h\n  physics/objectWrappers/ManagedRigidBase.h\n  physics/objectWrappers/ManagedRigidObject.h\n  physics/PhysicsManager.cpp\n  physics/PhysicsManager.h\n  physics/PhysicsObjectBase.h\n  physics/RigidBase.h\n  physics/RigidObject.cpp\n  physics/RigidObject.h\n  physics/RigidStage.cpp\n  physics/RigidStage.h\n  physics/URDFImporter.cpp\n  physics/URDFImporter.h\n)\n```\n\n----------------------------------------\n\nTITLE: Define Visualization Utility Function\nDESCRIPTION: This function `display_sample` visualizes RGB, semantic, and depth observations. It takes RGB, semantic, and depth observations as NumPy arrays and key_points. It converts the arrays into image objects and displays them using Matplotlib. Semantic observations are colorized using a predefined color palette. Depth observations are scaled and converted to grayscale images.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef display_sample(\n    rgb_obs, semantic_obs=np.array([]), depth_obs=np.array([]), key_points=None\n):\n    from habitat_sim.utils.common import d3_40_colors_rgb\n\n    rgb_img = Image.fromarray(rgb_obs, mode=\"RGBA\")\n\n    arr = [rgb_img]\n    titles = [\"rgb\"]\n    if semantic_obs.size != 0:\n        semantic_img = Image.new(\"P\", (semantic_obs.shape[1], semantic_obs.shape[0]))\n        semantic_img.putpalette(d3_40_colors_rgb.flatten())\n        semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n        semantic_img = semantic_img.convert(\"RGBA\")\n        arr.append(semantic_img)\n        titles.append(\"semantic\")\n\n    if depth_obs.size != 0:\n        depth_img = Image.fromarray((depth_obs / 10 * 255).astype(np.uint8), mode=\"L\")\n        arr.append(depth_img)\n        titles.append(\"depth\")\n\n    plt.figure(figsize=(12, 8))\n    for i, data in enumerate(arr):\n        ax = plt.subplot(1, 3, i + 1)\n        ax.axis(\"off\")\n        ax.set_title(titles[i])\n        # plot points on images\n        if key_points is not None:\n            for point in key_points:\n                plt.plot(point[0], point[1], marker=\"o\", markersize=10, alpha=0.8)\n        plt.imshow(data)\n\n    plt.show(block=False)\n```\n\n----------------------------------------\n\nTITLE: Configuring compiler flags and adding resources\nDESCRIPTION: This snippet sets directory properties to enable pedantic compiler flags for Corrade, promoting stricter code checking. It also uses `corrade_add_resource` to add a shader resource file (Shaders.conf) to the gfx_batch library, which likely contains configurations for shaders used in the rendering process.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/gfx_batch/CMakeLists.txt#_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nset_directory_properties(PROPERTIES CORRADE_USE_PEDANTIC_FLAGS ON)\ncorrade_add_resource(GfxBatchShaderResources ../../shaders/gfx_batch/Shaders.conf)\nlist(APPEND gfx_batch_SOURCES ${GfxBatchShaderResources})\n```\n\n----------------------------------------\n\nTITLE: Finding Assimp Plugin\nDESCRIPTION: This snippet conditionally finds the AssimpImporter plugin for Magnum, based on the `BUILD_ASSIMP_SUPPORT` variable. This allows enabling or disabling Assimp support at build time.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/bindings/CMakeLists.txt#_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_ASSIMP_SUPPORT)\n  find_package(MagnumPlugins REQUIRED AssimpImporter)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Semantic Sensor in Habitat-Lab\nDESCRIPTION: This code shows how to configure the semantic sensor within habitat-lab's configuration. It adds `SEMANTIC_SENSOR` to the list of agent sensors and specifies the path to the HM3D annotated basis scene dataset configuration file. These lines need to be added to the habitat-lab configuration file.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nSIMULATOR.AGENT_0.SENSORS = [\"RGB_SENSOR\", \"SEMANTIC_SENSOR\"]\nSIMULATOR.SCENE_DATASET = \"<PATH TO HM3D>/hm3d_annotated_basis.scene_dataset_config.json\"\n```\n\n----------------------------------------\n\nTITLE: Event Handler for Primitive Object Dropdown Change (Habitat-Sim)\nDESCRIPTION: The `on_prim_obj_ddl_change` function acts as an event handler for dropdowns displaying primitive-based object handles. It updates the global variable `sel_prim_obj_handle` with the newly selected value from the dropdown (`ddl_values[\"new\"]`) and returns the updated value.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndef on_prim_obj_ddl_change(ddl_values):\n    global sel_prim_obj_handle\n    sel_prim_obj_handle = ddl_values[\"new\"]\n    return sel_prim_obj_handle\n```\n\n----------------------------------------\n\nTITLE: Modifying Solid UVSphere Template in Habitat-Sim (Python)\nDESCRIPTION: This code shows how to acquire and modify a default solid UV sphere template. Attributes modified include whether to use texture coordinates, use tangents, the number of rings, and the number of segments.  The modifications are then registered using register_prim_template_if_valid.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_51\n\nLANGUAGE: python\nCODE:\n```\n# @title ####2.5.1 Solid UVSphere : { display-mode: \"form\" }\n# Acquire default template\nUVSphere_solid_template = prim_attr_mgr.get_default_UVsphere_template(False)\n\n\ndef edit_solid_UVSphere(edit_template):\n    # @markdown Whether to build with texture coordinate support\n    use_texture_coords = False  # @param {type:\"boolean\"}\n    edit_template.use_texture_coords = use_texture_coords\n    # @markdown Whether to build tangents\n    use_tangents = False  # @param {type:\"boolean\"}\n    edit_template.use_tangents = use_tangents\n    # @markdown Number of (face) rings. Must be larger or equal to 2.\n    num_rings = 13  # @param {type:\"slider\", min:2, max:30, step:1}\n    edit_template.num_rings = num_rings\n    # @markdown Number of (face) segments. Must be larger or equal to 3.\n    num_segments = 8  # @param {type:\"slider\", min:3, max:30, step:1}\n    edit_template.num_segments = num_segments\n\n    # @markdown Do you want to make a solid UVSphere using your above modifications?\n    make_modified_solid_UVSphere = True  # @param {type:\"boolean\"}\n    # if make is set to true, save modified template.\n    register_prim_template_if_valid(\n        make_modified_solid_UVSphere,\n        edit_template,\n        solid_handles_to_use,\n        \"uvSphereSolid\",\n    )\n\n\nedit_solid_UVSphere(UVSphere_solid_template)\n```\n\n----------------------------------------\n\nTITLE: Object Gripper Class in Python\nDESCRIPTION: This class implements an object gripper, allowing an agent to grip and release objects in the Habitat-Sim environment. It initializes with a simulator instance, agent scene node, and end-effector offset. The class provides methods to grip, release, and synchronize the state of a gripped object.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nclass ObjectGripper:\n    def __init__(\n        self,\n        sim,\n        agent_scene_node,\n        end_effector_offset,\n    ):\n        self._sim = sim\n        self._node = agent_scene_node\n        self._offset = end_effector_offset\n        self._gripped_obj = None\n        self._gripped_obj_buffer = 0  # bounding box y dimension offset of the offset\n\n    def sync_states(self):\n        if self._gripped_obj is not None:\n            agent_t = self._node.absolute_transformation_matrix()\n            agent_t.translation += self._offset + mn.Vector3(\n                0, self._gripped_obj_buffer, 0.0\n            )\n            self._gripped_obj.transformation = agent_t\n\n    def grip(self, obj):\n        if self._gripped_obj is not None:\n            print(\"Oops, can't carry more than one item.\")\n            return\n        self._gripped_obj = obj\n        obj.motion_type = habitat_sim.physics.MotionType.KINEMATIC\n        self._gripped_obj_buffer = obj.aabb.size_y() / 2.0\n        self.sync_states()\n\n    def release(self):\n        if self._gripped_obj is None:\n            print(\"Oops, can't release nothing.\")\n            return\n        self._gripped_obj.motion_type = habitat_sim.physics.MotionType.DYNAMIC\n        self._gripped_obj.linear_velocity = (\n            self._node.absolute_transformation_matrix().transform_vector(\n                mn.Vector3(0, 0, -1.0)\n            )\n            + mn.Vector3(0, 2.0, 0)\n        )\n        self._gripped_obj = None\n```\n\n----------------------------------------\n\nTITLE: Add GfxReplay Test Target\nDESCRIPTION: Adds a test executable GfxReplayTest, links it with habitat_sim and Magnum importers (Gltf and Ufbx). The target_include_directories command sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_10\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  GfxReplayTest\n  GfxReplayTest.cpp\n  LIBRARIES\n  habitat_sim\n  MagnumPlugins::GltfImporter\n  MagnumPlugins::UfbxImporter\n)\ntarget_include_directories(GfxReplayTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Finding Magnum Plugin Packages\nDESCRIPTION: This snippet uses the `find_package` command to locate various Magnum plugin packages required for importing different file formats. The `REQUIRED` keyword ensures the build process stops if any of these packages are missing. The plugins include BasisImporter, GltfImporter, KtxImporter, StanfordImporter, StbImageImporter, StbImageConverter, StbTrueTypeFont, and UfbxImporter.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/viewer/CMakeLists.txt#_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(\n  MagnumPlugins\n  REQUIRED\n  BasisImporter\n  GltfImporter\n  KtxImporter\n  StanfordImporter\n  StbImageImporter\n  StbImageConverter\n  StbTrueTypeFont\n  UfbxImporter\n)\n```\n\n----------------------------------------\n\nTITLE: Previewing Assets using the Python Viewer\nDESCRIPTION: This snippet shows how to use the Python viewer to preview datasets with scene dataset configuration support. It requires specifying both the dataset configuration file and the scene file as command-line arguments. The user needs to run this command from the Habitat-Sim source directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\npython examples/viewer.py --dataset '<path to desired dataset config>/<desired dataset>.scene_dataset_config.json' --scene '<scene to show>'\n```\n\n----------------------------------------\n\nTITLE: Building Capsule Primitive Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_Capsule_prim_attrs` creates a dictionary for the capsule primitive template (`capsule_template`).  It extends the base primitive attributes using `build_dict_of_prim_attrs` and adds capsule-specific properties, such as hemisphere and cylinder ring counts.  Each value in the dictionary is a tuple consisting of the attribute's value, its editability, and data type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Capsule_prim_attrs(capsule_template):\n    res_dict = build_dict_of_prim_attrs(capsule_template)\n    res_dict[\"hemisphere_rings\"] = (capsule_template.hemisphere_rings, True, \"int\")\n    res_dict[\"cylinder_rings\"] = (capsule_template.cylinder_rings, True, \"int\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Setting Seed and Loading Objects in Python\nDESCRIPTION: This code snippet sets the random seed for reproducibility and loads a selected target object onto the NavMesh. It also loads the locobot asset, adds the robot object to the scene, sets the agent's body to kinematic, and configures a new VelocityControl structure. It resets observations and robot state.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_29\n\nLANGUAGE: python\nCODE:\n```\n# @markdown ---\n# @markdown ### Set other example parameters:\nseed = 24  # @param {type:\"integer\"}\nrandom.seed(seed)\nsim.seed(seed)\nnp.random.seed(seed)\n\nsim.config.sim_cfg.allow_sliding = True  # @param {type:\"boolean\"}\n\nprint(sel_file_obj_handle)\n# load a selected target object and place it on the NavMesh\nobj_1 = rigid_obj_mgr.add_object_by_template_handle(sel_file_obj_handle)\n\n# load the locobot_merged asset\nlocobot_template_handle = obj_attr_mgr.get_file_template_handles(\"locobot\")[0]\n\n# add robot object to the scene with the agent/camera SceneNode attached\nlocobot_obj = rigid_obj_mgr.add_object_by_template_handle(\n    locobot_template_handle, sim.agents[0].scene_node\n)\n\n# set the agent's body to kinematic since we will be updating position manually\nlocobot_obj.motion_type = habitat_sim.physics.MotionType.KINEMATIC\n\n# create and configure a new VelocityControl structure\n# Note: this is NOT the object's VelocityControl, so it will not be consumed automatically in sim.step_physics\nvel_control = habitat_sim.physics.VelocityControl()\nvel_control.controlling_lin_vel = True\nvel_control.lin_vel_is_local = True\nvel_control.controlling_ang_vel = True\nvel_control.ang_vel_is_local = True\n\n# reset observations and robot state\nlocobot_obj.translation = sim.pathfinder.get_random_navigable_point()\nobservations = []\n```\n\n----------------------------------------\n\nTITLE: Finding Required Packages\nDESCRIPTION: This section uses the `find_package` command to locate required dependencies like Magnum, Bullet, MagnumIntegration, Eigen, and Corrade.  The `REQUIRED` keyword ensures that the build fails if a package is not found. It also conditionally finds Magnum windowless applications based on the target platform.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(\n  Magnum\n  REQUIRED\n  AnyImageImporter\n  AnySceneImporter\n  GL\n  MaterialTools\n  MeshTools\n  DebugTools\n  SceneGraph\n  SceneTools\n  Shaders\n  Trade\n  Primitives\n  AnyImageConverter\n)\n\nif(BUILD_WITH_BULLET)\n  find_package(MagnumIntegration REQUIRED Bullet)\n  find_package(Bullet REQUIRED Dynamics)\nendif()\n\nfind_package(MagnumPlugins REQUIRED PrimitiveImporter)\n\nfind_package(MagnumIntegration REQUIRED Eigen)\n\nfind_package(Corrade REQUIRED Utility)\n\n# Link appropriate windowless library - gfx and gfx_batch\nif(MAGNUM_TARGET_EGL)\n  find_package(Magnum REQUIRED WindowlessEglApplication)\nelif(CORRADE_TARGET_APPLE)\n  find_package(Magnum REQUIRED WindowlessCglApplication)\nelif(CORRADE_TARGET_UNIX)\n  # Mainly for builds with external Magnum that might not have TARGET_EGL\n  # enabled\n  find_package(Magnum REQUIRED WindowlessGlxApplication)\nelif(CORRADE_TARGET_WINDOWS)\n  find_package(Magnum REQUIRED WindowlessWglApplication)\nelse()\n  message(FATAL_ERROR \"Unsupported platform\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Installing ninja on Linux\nDESCRIPTION: Installs ninja build system on Linux using apt package manager. Ninja is used to improve build speed.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nsudo apt install ninja-build\n```\n\n----------------------------------------\n\nTITLE: Setting Build Warnings as Errors\nDESCRIPTION: This snippet sets the `BUILD_WARNINGS_AS_ERRORS` option. If enabled, it configures the compiler to treat warnings as errors.  For MSVC, it uses the `/WX` flag. For other compilers, it adds `-Wall` and `-Werror` flags. The TODO comment suggests future integration with `CORRADE_USE_PEDANTIC`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\noption(BUILD_WARNINGS_AS_ERRORS \"Build with warnings as errors\" OFF)\nif(BUILD_WARNINGS_AS_ERRORS)\n  if(MSVC)\n    add_compile_options(/WX)\n  else()\n    # TODO(msb) remove -Wall once we enable CORRADE_USE_PEDANTIC\n    add_compile_options(-Wall)\n    add_compile_options(-Werror)\n  endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Building Cylinder Primitive Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_Cylinder_prim_attrs` creates a dictionary for the cylinder primitive template (`cylinder_template`). It extends the base primitive attributes defined in `build_dict_of_prim_attrs` and includes the `use_cap_ends` property. The values in the dictionary are tuples including the attribute's value, its editability, and its type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Cylinder_prim_attrs(cylinder_template):\n    res_dict = build_dict_of_prim_attrs(cylinder_template)\n    res_dict[\"use_cap_ends\"] = (cylinder_template.use_cap_ends, True, \"boolean\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Install Habitat-Sim (CUDA)\nDESCRIPTION: This snippet demonstrates how to install Habitat-Sim with CUDA support. This is done by passing the `--with-cuda` flag to `setup.py` which enables the compilation of CUDA features within the simulator.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython setup.py install --with-cuda\n```\n\n----------------------------------------\n\nTITLE: Video Rendering with Sensor Overlays in Habitat-Sim\nDESCRIPTION: This snippet generates a video from the collected observations with overlays of sensor data such as color, depth, and semantic segmentation from a first-person perspective. It uses the `vut.make_video` function with specified overlay settings and depth clipping. Requires the `observations` list to be populated with sensor data.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_33\n\nLANGUAGE: Python\nCODE:\n```\n# video rendering with embedded 1st person view\nvideo_prefix = \"fetch\"\nif make_video:\n    overlay_dims = (int(sim_settings[\"width\"] / 5), int(sim_settings[\"height\"] / 5))\n    print(\"overlay_dims = \" + str(overlay_dims))\n    overlay_settings = [\n        {\n            \"obs\": \"color_sensor_1st_person\",\n            \"type\": \"color\",\n            \"dims\": overlay_dims,\n            \"pos\": (10, 10),\n            \"border\": 2,\n        },\n        {\n            \"obs\": \"depth_sensor_1st_person\",\n            \"type\": \"depth\",\n            \"dims\": overlay_dims,\n            \"pos\": (10, 30 + overlay_dims[1]),\n            \"border\": 2,\n        },\n        {\n            \"obs\": \"semantic_sensor_1st_person\",\n            \"type\": \"semantic\",\n            \"dims\": overlay_dims,\n            \"pos\": (10, 50 + overlay_dims[1] * 2),\n            \"border\": 2,\n        },\n    ]\n    print(\"overlay_settings = \" + str(overlay_settings))\n\n    vut.make_video(\n        observations=observations,\n        primary_obs=\"color_sensor_3rd_person\",\n        primary_obs_type=\"color\",\n        video_file=output_path + video_prefix,\n        fps=int(1.0 / time_step),\n        open_vid=show_video,\n        overlay_settings=overlay_settings,\n        depth_clip=10.0,\n    )\n```\n\n----------------------------------------\n\nTITLE: Add Depth Unprojection Test\nDESCRIPTION: Adds a test executable named DepthUnprojectionTest and links it against gfx_batch, Magnum::MeshTools, Magnum::OpenGLTester, Magnum::Trade, and Magnum::Primitives.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  DepthUnprojectionTest\n  DepthUnprojectionTest.cpp\n  LIBRARIES\n  gfx_batch\n  Magnum::MeshTools\n  Magnum::OpenGLTester\n  Magnum::Trade\n  Magnum::Primitives\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Configuration Header Files\nDESCRIPTION: This section generates C++ header files (`configure.h`) for different modules (core, gfx, physics, sensor) using the `configure_file` command.  It takes a `.cmake` template file as input and generates a `.h` file in the binary directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\n# core\nconfigure_file(\n  ${CMAKE_CURRENT_SOURCE_DIR}/core/configure.h.cmake\n  ${CMAKE_CURRENT_BINARY_DIR}/core/configure.h\n)\n# gfx\nconfigure_file(\n  ${CMAKE_CURRENT_SOURCE_DIR}/gfx/configure.h.cmake\n  ${CMAKE_CURRENT_BINARY_DIR}/gfx/configure.h\n)\n# physics\nconfigure_file(\n  ${CMAKE_CURRENT_SOURCE_DIR}/physics/configure.h.cmake\n  ${CMAKE_CURRENT_BINARY_DIR}/physics/configure.h\n)\n# sensor\nconfigure_file(\n  ${CMAKE_CURRENT_SOURCE_DIR}/sensor/configure.h.cmake\n  ${CMAKE_CURRENT_BINARY_DIR}/sensor/configure.h\n)\n```\n\n----------------------------------------\n\nTITLE: Running Example with Physics Enabled Bash\nDESCRIPTION: This command executes the `example.py` script with physics enabled.  It requires the `--scene` argument to specify the scene file and the `--enable_physics` flag.  The agent will be frozen and oriented towards the spawned physical objects.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npython examples/example.py --scene /path/to/data/scene_datasets/habitat-test-scenes/skokloster-castle.glb --enable_physics\n```\n\n----------------------------------------\n\nTITLE: Displaying Template Properties (Habitat-Sim)\nDESCRIPTION: The `show_template_properties` function displays all properties of a given attributes template.  It first builds a dictionary from the template using `build_dict_from_template`.  Then it iterates through this dictionary and prints each property's name, value, type, and editability status.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef show_template_properties(template):\n    template_dict = build_dict_from_template(template)\n    print(\"Template {} has : \".format(template.handle))\n    for k, v in template_dict.items():\n        print(\n            \"\\tProperty {} has value {} of type {} that is editable : {}\".format(\n                k, v[0], v[2], v[1]\n            )\n        )\n```\n\n----------------------------------------\n\nTITLE: Linking Libraries to Module\nDESCRIPTION: This snippet uses `target_link_libraries` to link necessary libraries to the `habitat_sim_bindings` target. It links against MagnumBindings::Python, various MagnumPlugins, and the core habitat_sim library.  The `PRIVATE` and `PUBLIC` keywords control the visibility of the linked libraries.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/bindings/CMakeLists.txt#_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_link_libraries(\n  habitat_sim_bindings\n  PRIVATE MagnumBindings::Python\n          MagnumPlugins::BasisImporter\n          MagnumPlugins::GltfImporter\n          MagnumPlugins::KtxImporter\n          MagnumPlugins::StanfordImporter\n          MagnumPlugins::StbImageImporter\n          MagnumPlugins::StbImageConverter\n          MagnumPlugins::UfbxImporter\n  PUBLIC habitat_sim\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Minimum CMake Version\nDESCRIPTION: This snippet sets the minimum required CMake version for the project. It ensures that the CMake version used to build the project is at least 3.12.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.12)\n```\n\n----------------------------------------\n\nTITLE: Generating GLTF and Converting Images using Magnum and ImageMagick\nDESCRIPTION: This shell script uses Magnum's `magnum-imageconverter` to process GLTF files and convert images. It also uses ImageMagick's `convert` tool to resize images with nearest-neighbor interpolation.  The script assumes that the `magnum-imageconverter` and `convert` commands are available in the system's PATH. The resulting `*.dxt.ktx2` files are the final output.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/data/test_assets/scenes/README.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nmagnum-imageconverter -I GltfImporter -i experimentalKhrTextureKtx,ignoreRequiredExtensions --image 0 --layer 0 batch-four-squares.{gltf,0.0.png} -D3\nmagnum-imageconverter -I GltfImporter -i experimentalKhrTextureKtx,ignoreRequiredExtensions --image 0 --layer 1 batch-four-squares.{gltf,0.1.png} -D3\nmagnum-imageconverter -I GltfImporter -i experimentalKhrTextureKtx,ignoreRequiredExtensions --image 0 batch-square-circle-triangle.{gltf,0.png}\n\nconvert batch-four-squares.0.0.png -interpolate Nearest -filter point -resize 400% batch-four-squares.0.0.4x.png\nconvert batch-four-squares.0.1.png -interpolate Nearest -filter point -resize 400% batch-four-squares.0.1.4x.png\nconvert batch-square-circle-triangle.0.png -interpolate Nearest -filter point -resize 200% batch-square-circle-triangle.0.2x.png\n\nmagnum-imageconverter --array --layers batch-four-squares.0.{0,1}.4x.png batch-four-squares.0.4x.dxt.ktx2 -C StbDxtImageConverter\nmagnum-imageconverter batch-square-circle-triangle.0.2x.png batch-square-circle-triangle.0.2x.dxt.ktx2 -C StbDxtImageConverter\n```\n\n----------------------------------------\n\nTITLE: Visualizing Target Zone with Wireframe Cube\nDESCRIPTION: This snippet creates a wireframe cube to visualize the target zone. It retrieves the \"cubeWireframe\" template, scales it to the target zone's size, disables collision, registers it under a new name (\"target_zone\"), and instances it at the target zone's center.  The motion type is set to STATIC.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nshow_target_zone = False  # @param{type:\"boolean\"}\nif show_target_zone:\n    # Get and modify the wire cube template from the range\n    cube_handle = obj_attr_mgr.get_template_handles(\"cubeWireframe\")[0]\n    cube_template_cpy = obj_attr_mgr.get_template_by_handle(cube_handle)\n    cube_template_cpy.scale = target_zone.size()\n    cube_template_cpy.is_collidable = False\n    # Register the modified template under a new name.\n    obj_attr_mgr.register_template(cube_template_cpy, \"target_zone\")\n    # instance and place the object from the template\n    target_zone_obj = rigid_obj_mgr.add_object_by_template_handle(\"target_zone\")\n    target_zone_obj.translation = target_zone.center()\n    target_zone_obj.motion_type = habitat_sim.physics.MotionType.STATIC\n```\n\n----------------------------------------\n\nTITLE: Clone Habitat-Sim Repository\nDESCRIPTION: This snippet demonstrates how to clone the Habitat-Sim repository from GitHub, specifically checking out the latest stable release. It then changes the current directory to the cloned repository.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Checkout the latest stable release\ngit clone --branch stable https://github.com/facebookresearch/habitat-sim.git\ncd habitat-sim\n```\n\n----------------------------------------\n\nTITLE: Visualizing Observations in Habitat-Sim (Python)\nDESCRIPTION: This function `display_sample` visualizes RGB, semantic, and depth observations from a Habitat-Sim environment using Matplotlib. It takes observation arrays as input and displays them as images in a single plot. The function can also plot key points on the images.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef display_sample(\n    rgb_obs, semantic_obs=np.array([]), depth_obs=np.array([]), key_points=None\n):\n    from habitat_sim.utils.common import d3_40_colors_rgb\n\n    rgb_img = Image.fromarray(rgb_obs, mode=\"RGBA\")\n\n    arr = [rgb_img]\n    titles = [\"rgb\"]\n    if semantic_obs.size != 0:\n        semantic_img = Image.new(\"P\", (semantic_obs.shape[1], semantic_obs.shape[0]))\n        semantic_img.putpalette(d3_40_colors_rgb.flatten())\n        semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n        semantic_img = semantic_img.convert(\"RGBA\")\n        arr.append(semantic_img)\n        titles.append(\"semantic\")\n\n    if depth_obs.size != 0:\n        depth_img = Image.fromarray((depth_obs / 10 * 255).astype(np.uint8), mode=\"L\")\n        arr.append(depth_img)\n        titles.append(\"depth\")\n\n    plt.figure(figsize=(12, 8))\n    for i, data in enumerate(arr):\n        ax = plt.subplot(1, 3, i + 1)\n        ax.axis(\"off\")\n        ax.set_title(titles[i])\n        # plot points on images\n        if key_points is not None:\n            for point in key_points:\n                plt.plot(point[0], point[1], marker=\"o\", markersize=10, alpha=0.8)\n        plt.imshow(data)\n\n    plt.show(block=False)\n```\n\n----------------------------------------\n\nTITLE: Add Semantic Test Target\nDESCRIPTION: This snippet adds a test executable SemanticTest and links it against the habitat_sim library. target_include_directories adds the binary directory to the include path for the test.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_23\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(SemanticTest SemanticTest.cpp LIBRARIES habitat_sim)\ntarget_include_directories(SemanticTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Remove Build Folder\nDESCRIPTION: This command removes the `build` directory. It is crucial when building from a development clone to prevent CMake errors, as the builder copies the folder.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nrm -r ../build\n```\n\n----------------------------------------\n\nTITLE: Installing black and isort for Python\nDESCRIPTION: This snippet installs `black` and `isort` for Python code formatting and linting using `pip`. `black` automatically formats code according to PEP 8, and `isort` sorts imports.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npip install -U black isort\n```\n\n----------------------------------------\n\nTITLE: GUI Utility Functions for Habitat-Sim (Python)\nDESCRIPTION: These functions provide GUI utilities for interacting with a Habitat-Sim environment using widgets. They include event handlers for dropdown menus that allow the user to select object and asset handles. Functions are included to create and manage buttons that trigger simulation and object clearing.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef on_file_obj_ddl_change(ddl_values):\n    global sel_file_obj_handle\n    sel_file_obj_handle = ddl_values[\"new\"]\n    return sel_file_obj_handle\n\n\ndef on_prim_obj_ddl_change(ddl_values):\n    global sel_prim_obj_handle\n    sel_prim_obj_handle = ddl_values[\"new\"]\n    return sel_prim_obj_handle\n\n\ndef on_prim_ddl_change(ddl_values):\n    global sel_asset_handle\n    sel_asset_handle = ddl_values[\"new\"]\n    return sel_asset_handle\n\n\ndef set_handle_ddl_widget(obj_handles, handle_types, sel_handle, on_change):\n    sel_handle = obj_handles[0]\n    descStr = handle_types + \" Template Handles:\"\n    style = {\"description_width\": \"300px\"}\n    obj_ddl = widgets.Dropdown(\n        options=obj_handles,\n        value=sel_handle,\n        description=descStr,\n        style=style,\n        disabled=False,\n        layout={\"width\": \"max-content\"},\n    )\n\n    obj_ddl.observe(on_change, names=\"value\")\n    return obj_ddl, sel_handle\n\n\ndef set_button_launcher(desc):\n    button = widgets.Button(\n        description=desc,\n        layout={\"width\": \"max-content\"},\n    )\n    return button\n\n\ndef make_sim_and_vid_button(prefix, dt=1.0):\n    if not HAS_WIDGETS:\n        return\n\n    def on_sim_click(b):\n        observations = simulate(sim, dt=dt)\n        vut.make_video(\n            observations, \"color_sensor_1st_person\", \"color\", output_path + prefix\n        )\n\n    sim_and_vid_btn = set_button_launcher(\"Simulate and Make Video\")\n    sim_and_vid_btn.on_click(on_sim_click)\n    ipydisplay(sim_and_vid_btn)\n\n\ndef make_clear_all_objects_button():\n    if not HAS_WIDGETS:\n        return\n\n    def on_clear_click(b):\n        rigid_obj_mgr.remove_all_objects()\n\n    clear_objs_button = set_button_launcher(\"Clear all objects\")\n    clear_objs_button.on_click(on_clear_click)\n    ipydisplay(clear_objs_button)\n\n\ndef build_widget_ui(obj_attr_mgr, prim_attr_mgr):\n    # Holds the user's desired file-based object template handle\n    global sel_file_obj_handle\n    sel_file_obj_handle = \"\"\n\n    # Holds the user's desired primitive-based object template handle\n    global sel_prim_obj_handle\n    sel_prim_obj_handle = \"\"\n\n    # Holds the user's desired primitive asset template handle\n    global sel_asset_handle\n    sel_asset_handle = \"\"\n\n    # Construct DDLs and assign event handlers\n    # All file-based object template handles\n    file_obj_handles = obj_attr_mgr.get_file_template_handles()\n    prim_obj_handles = obj_attr_mgr.get_synth_template_handles()\n    prim_asset_handles = prim_attr_mgr.get_template_handles()\n    if not HAS_WIDGETS:\n        sel_file_obj_handle = file_obj_handles[0]\n        sel_prim_obj_handle = prim_obj_handles[0]\n        sel_asset_handle = prim_asset_handles[0]\n        return\n    file_obj_ddl, sel_file_obj_handle = set_handle_ddl_widget(\n        file_obj_handles,\n        \"File-based Object\",\n        sel_file_obj_handle,\n        on_file_obj_ddl_change,\n    )\n    # All primitive asset-based object template handles\n    prim_obj_ddl, sel_prim_obj_handle = set_handle_ddl_widget(\n        prim_obj_handles,\n        \"Primitive-based Object\",\n        sel_prim_obj_handle,\n        on_prim_obj_ddl_change,\n    )\n    # All primitive asset handles template handles\n    prim_asset_ddl, sel_asset_handle = set_handle_ddl_widget(\n        prim_asset_handles, \"Primitive Asset\", sel_asset_handle, on_prim_ddl_change\n    )\n    # Display DDLs\n    ipydisplay(file_obj_ddl)\n    ipydisplay(prim_obj_ddl)\n    ipydisplay(prim_asset_ddl)\n```\n\n----------------------------------------\n\nTITLE: Building Stage Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_Stage_attrs` creates a dictionary of attribute properties for a given scene template (`scene_template`). It includes scene-specific attributes such as gravity, origin, semantic asset handle, and house filename. It inherits attributes from `PhyObj` using `build_dict_of_PhyObj_attrs`. Each value is a tuple that contains the attribute's value, a boolean indicating its editability, and its data type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Stage_attrs(scene_template):\n    res_dict = build_dict_of_PhyObj_attrs(scene_template)\n    res_dict[\"gravity\"] = (scene_template.gravity, True, \"vector\")\n    res_dict[\"origin\"] = (scene_template.origin, True, \"vector\")\n    res_dict[\"semantic_asset_handle\"] = (\n        scene_template.semantic_asset_handle,\n        True,\n        \"string\",\n    )\n    res_dict[\"semantic_asset_type\"] = (scene_template.semantic_asset_type, True, \"int\")\n    res_dict[\"navmesh_asset_handle\"] = (\n        scene_template.navmesh_asset_handle,\n        True,\n        \"string\",\n    )\n    res_dict[\"house_filename\"] = (scene_template.house_filename, True, \"string\")\n    res_dict[\"frustum_culling\"] = (scene_template.frustum_culling, True, \"boolean\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Setting Include Directories for Habitat-Sim\nDESCRIPTION: This code sets the include directories for the `habitat_sim` target, making header files from these directories available during compilation. It includes the project binary directory, tinyxml2, and recastnavigation headers. It specifies public and private include directories using `target_include_directories`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_21\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_include_directories(\n  habitat_sim PUBLIC ${PROJECT_BINARY_DIR}\n  PRIVATE \"${DEPS_DIR}/tinyxml2\" \"${DEPS_DIR}/recastnavigation/Detour/Include\"\n          \"${DEPS_DIR}/recastnavigation/Recast/Include\"\n)\n```\n\n----------------------------------------\n\nTITLE: Installing clang-format on macOS\nDESCRIPTION: This snippet shows how to install `clang-format-12` on macOS using the `brew` package manager. `clang-format` is used for C++ code style enforcement and linting.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbrew install clang-format\n```\n\n----------------------------------------\n\nTITLE: Finding Magnum Packages\nDESCRIPTION: This snippet uses the `find_package` command to locate the Magnum library and its required components: AnyImageImporter, AnyImageConverter, and Trade.  The `REQUIRED` keyword ensures that the build process fails if these packages are not found.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/imageconverter/CMakeLists.txt#_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(Magnum REQUIRED AnyImageImporter AnyImageConverter Trade)\n```\n\n----------------------------------------\n\nTITLE: Set PYTHONPATH for Habitat-Sim\nDESCRIPTION: This snippet adds the path to the Habitat-Sim installation to the `PYTHONPATH` environment variable.  This ensures that Python can find the Habitat-Sim modules when importing them in other projects like Habitat-Lab.  This is commonly added to `.bashrc` or `.bash_profile`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nexport PYTHONPATH=$PYTHONPATH:/path/to/habitat-sim/\n```\n\n----------------------------------------\n\nTITLE: Install Habitat-Sim (Default)\nDESCRIPTION: This snippet shows how to install Habitat-Sim using `setup.py` with the default options. This assumes the machine has a display attached.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Assuming we're still within habitat conda environment\npython setup.py install\n```\n\n----------------------------------------\n\nTITLE: Printing Semantic Scene Information in Habitat-Sim (Python)\nDESCRIPTION: This function `print_scene_recur` prints semantic annotation information (id, category, bounding box details) about levels, regions, and objects in a hierarchical fashion within the Habitat-Sim scene. It takes a `scene` object and an optional `limit_output` parameter to control the amount of output. It utilizes the `sim.semantic_scene` attribute to access the scene's semantic information.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef print_scene_recur(scene, limit_output=10):\n    print(\n        f\"House has {len(scene.levels)} levels, {len(scene.regions)} regions and {len(scene.objects)} objects\"\n    )\n    print(f\"House center:{scene.aabb.center} dims:{scene.aabb.size}\")\n\n    count = 0\n    for level in scene.levels:\n        print(\n            f\"Level id:{level.id}, center:{level.aabb.center},\"\n            f\" dims:{level.aabb.size}\"\n        )\n        for region in level.regions:\n            print(\n                f\"Region id:{region.id}, category:{region.category.name()},\"\n                f\" center:{region.aabb.center}, dims:{region.aabb.size}\"\n            )\n            for obj in region.objects:\n                print(\n                    f\"Object id:{obj.id}, category:{obj.category.name()},\"\n                    f\" center:{obj.aabb.center}, dims:{obj.aabb.size}\"\n                )\n                count += 1\n                if count >= limit_output:\n                    return\n\n\n# Print semantic annotation information (id, category, bounding box details)\n# about levels, regions and objects in a hierarchical fashion\nscene = sim.semantic_scene\nprint_scene_recur(scene)\n```\n\n----------------------------------------\n\nTITLE: Building Primitive Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_prim_attrs` builds a dictionary of attribute properties for a general primitive asset template (`prim_template`). It includes properties common to all primitives, such as whether to use texture coordinates, the number of rings and segments.  The function relies on `build_dict_of_Default_attrs`. Each value is a tuple comprising the attribute's value, its editability, and data type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_prim_attrs(prim_template):\n    res_dict = build_dict_of_Default_attrs(prim_template)\n    res_dict[\"use_texture_coords\"] = (prim_template.use_texture_coords, True, \"boolean\")\n    res_dict[\"use_tangents\"] = (prim_template.use_tangents, True, \"boolean\")\n    res_dict[\"num_rings\"] = (prim_template.num_rings, True, \"int\")\n    res_dict[\"num_segments\"] = (prim_template.num_segments, True, \"int\")\n    res_dict[\"half_length\"] = (prim_template.half_length, True)\n    # Read-only values\n    res_dict[\"prim_obj_class_name\"] = (\n        prim_template.prim_obj_class_name,\n        False,\n        \"string\",\n    )\n    res_dict[\"prim_obj_type\"] = (prim_template.prim_obj_type, False, \"int\")\n    res_dict[\"is_valid_template\"] = (prim_template.is_valid_template, False, \"boolean\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Navigate and See\nDESCRIPTION: This snippet defines a `navigateAndSee` function which takes an action name as input, performs that action using `sim.step`, and then displays the resulting observation from the color sensor using the `display_sample` function.  It also prints the action that was taken. The snippet then demonstrates how to use this function to navigate the agent by taking a series of actions (turn_right, move_forward, turn_left).\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# obtain the default, discrete actions that an agent can perform\n# default action space contains 3 actions: move_forward, turn_left, and turn_right\naction_names = list(cfg.agents[sim_settings[\"default_agent\"]].action_space.keys())\nprint(\"Discrete action space: \", action_names)\n\n\ndef navigateAndSee(action=\"\"):\n    if action in action_names:\n        observations = sim.step(action)\n        print(\"action: \", action)\n        if display:\n            display_sample(observations[\"color_sensor\"])\n\n\naction = \"turn_right\"\nnavigateAndSee(action)\n\naction = \"turn_right\"\nnavigateAndSee(action)\n\naction = \"move_forward\"\nnavigateAndSee(action)\n\naction = \"turn_left\"\nnavigateAndSee(action)\n\n# action = \"move_backward\"   // #illegal, no such action in the default action space\n# navigateAndSee(action)\n```\n\n----------------------------------------\n\nTITLE: Path Visualization Setup in Python\nDESCRIPTION: This function sets up the visualization of a path by adding sphere objects at waypoints and along the path. It uses the object attribute manager to create sphere templates and the rigid object manager to add the objects to the scene. The function returns a list of the added objects.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndef setup_path_visualization(path_follower, vis_samples=100):\n    vis_objs = []\n    sphere_handle = obj_attr_mgr.get_template_handles(\"uvSphereSolid\")[0]\n    sphere_template_cpy = obj_attr_mgr.get_template_by_handle(sphere_handle)\n    sphere_template_cpy.scale *= 0.2\n    template_id = obj_attr_mgr.register_template(sphere_template_cpy, \"mini-sphere\")\n    print(\"template_id = \" + str(template_id))\n    if template_id < 0:\n        return None\n    vis_objs.append(rigid_obj_mgr.add_object_by_template_handle(sphere_handle))\n\n    for point in path_follower._points:\n        cp_obj = rigid_obj_mgr.add_object_by_template_handle(sphere_handle)\n        if cp_obj.object_id < 0:\n            print(cp_obj.object_id)\n            return None\n        cp_obj.translation = point\n        vis_objs.append(cp_obj)\n\n    for i in range(vis_samples):\n        cp_obj = rigid_obj_mgr.add_object_by_template_handle(\"mini-sphere\")\n        if cp_obj.object_id < 0:\n            print(cp_obj.object_id)\n            return None\n        cp_obj.translation = path_follower.pos_at(float(i / vis_samples))\n        vis_objs.append(cp_obj)\n\n    for obj in vis_objs:\n        if obj.object_id < 0:\n            print(obj.object_id)\n            return None\n\n    for obj in vis_objs:\n        obj.motion_type = habitat_sim.physics.MotionType.KINEMATIC\n\n    return vis_objs\n```\n\n----------------------------------------\n\nTITLE: Add Geo Test Target\nDESCRIPTION: This snippet adds a test executable GeoTest and links it against the habitat_sim library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(GeoTest GeoTest.cpp LIBRARIES habitat_sim)\n```\n\n----------------------------------------\n\nTITLE: Add Physics Test Target\nDESCRIPTION: Adds a test executable PhysicsTest, links it with habitat_sim and Magnum importers (Gltf, Stb, and Ufbx). The target_include_directories command sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_19\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  PhysicsTest\n  PhysicsTest.cpp\n  LIBRARIES\n  habitat_sim\n  MagnumPlugins::GltfImporter\n  MagnumPlugins::StbImageImporter\n  MagnumPlugins::StbImageConverter\n  MagnumPlugins::UfbxImporter\n)\ntarget_include_directories(PhysicsTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Running black and isort\nDESCRIPTION: These commands run `black` and `isort` on the current directory to format and sort python code. Black enforces a consistent code style, and isort organizes imports.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nblack .\n```\n\nLANGUAGE: shell\nCODE:\n```\nisort .\n```\n\n----------------------------------------\n\nTITLE: Setting C++ Standard and Flags\nDESCRIPTION: This snippet sets the C++ standard to C++14, enables position-independent code, and enables compile command export. It also sets the default build type if it's not already set and configures interprocedural optimization (IPO) if enabled.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CXX_STANDARD 14)\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON)\nif(NOT CMAKE_BUILD_TYPE)\n  set(\n    CMAKE_BUILD_TYPE\n    RelWithDebInfo\n    CACHE STRING\n          \"Choose build, options are: None Debug Release RelWithDebInfo MinSizeRel\"\n          FORCE\n  )\nendif()\nif(CMAKE_INTERPROCEDURAL_OPTIMIZATION)\n  # Policy that enables INTERPROCEDURAL_OPTIMIZATION\n  set(CMAKE_POLICY_DEFAULT_CMP0069 NEW)\n  cmake_policy(SET CMP0069 NEW)\n\n  if(CMAKE_CXX_COMPILER_ID STREQUAL \"AppleClang\"\n     OR (CMAKE_CXX_COMPILER_ID MATCHES \"Clang\" AND CMAKE_CXX_COMPILER_VERSION\n                                                   VERSION_LESS 13.0)\n  )\n    message(\"-- Forcing full LTO for compatibility: ThinLTO requires LLVM Clang>=13.0\")\n    # Clang has some issues with thinLTO (segfaults on final linking)\n    # This enables full LTO through CMake\n    # FullLTO is slow, but may yield performance improvements.\n    #set(CMAKE_{lang}_COMPILE_OPTIONS_IPO ${CMAKE_CXX_COMPILE_OPTIONS_IPO} -flto)\n    add_compile_options(\"-flto=full\") # alternate way of forcing FAT LTO.\n  endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Linking Libraries to Habitat-Sim\nDESCRIPTION: This snippet links various libraries to the `habitat_sim` target, including Magnum graphics libraries, Corrade utility libraries, tinyxml2, Detour, and Recast.  It distinguishes between public and private linking using the PUBLIC and PRIVATE keywords. It also links to the gfx_batch library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_24\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_link_libraries(\n  habitat_sim\n  PUBLIC gfx_batch\n         Magnum::AnyImageImporter\n         Magnum::AnySceneImporter\n         Magnum::GL\n         Magnum::Magnum\n         Magnum::MaterialTools\n         Magnum::MeshTools\n         Magnum::DebugTools\n         Magnum::SceneGraph\n         Magnum::SceneTools\n         Magnum::Shaders\n         Magnum::Trade\n         Magnum::Primitives\n         MagnumPlugins::PrimitiveImporter\n         MagnumIntegration::Eigen\n         Corrade::Utility\n         Magnum::AnyImageConverter\n  PRIVATE tinyxml2 Detour Recast\n)\n```\n\n----------------------------------------\n\nTITLE: Add IOTest Test Target\nDESCRIPTION: This snippet adds a test executable IOTest and links it against the habitat_sim library. target_include_directories adds the binary directory to the include path for the test.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_13\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(IOTest IOTest.cpp LIBRARIES habitat_sim)\ntarget_include_directories(IOTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Add Nav Test Target\nDESCRIPTION: This snippet adds a test executable NavTest and links it against the habitat_sim library. target_include_directories adds the binary directory to the include path for the test.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_17\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(NavTest NavTest.cpp LIBRARIES habitat_sim)\ntarget_include_directories(NavTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Making Clear All Objects Button (Habitat-Sim)\nDESCRIPTION: The `make_clear_all_objects_button` function creates a button which, when clicked, removes all objects from the Habitat simulation environment using the `rigid_obj_mgr.remove_all_objects()` function. This function is skipped if HAS_WIDGETS is false.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndef make_clear_all_objects_button():\n    if not HAS_WIDGETS:\n        return\n\n    def on_clear_click(b):\n        rigid_obj_mgr.remove_all_objects()\n\n    clear_objs_button = set_button_launcher(\"Clear all objects\")\n    clear_objs_button.on_click(on_clear_click)\n    ipydisplay(clear_objs_button)\n```\n\n----------------------------------------\n\nTITLE: Run Matrix Builder Script\nDESCRIPTION: This command executes the `matrix_builder.py` Python script, which initiates the build process for Habitat-Sim.  The script configures environment variables and calls `conda build` based on the `meta.yaml` configuration file.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npython matrix_builder.py\n```\n\n----------------------------------------\n\nTITLE: Setup Habitat Simulation Environment\nDESCRIPTION: This snippet sets up the Habitat simulation environment by defining paths to data directories, configuring logging, and defining constants like colors and initial camera positions.  It also initializes global variables for the simulator and sensor node if they haven't already been created.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/coordinate_frame_tutorial.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"HABITAT_SIM_LOG\"] = \"quiet\"\n\n# define path to data directory\nrepo = git.Repo(\".\", search_parent_directories=True)\ndir_path = repo.working_tree_dir\ndata_path = os.path.join(dir_path, \"data\")\n\n# images will be either displayed in the notebook or saved as image files\nif not IS_NOTEBOOK:\n    output_directory = \"examples/tutorials/coordinate_system_tutorial_output/\"\n    output_path = os.path.join(dir_path, output_directory)\n    os.makedirs(output_path, exist_ok=True)\n\n# define some constants and globals the first time we run:\nopacity = 1.0\nred = mn.Color4(1.0, 0.0, 0.0, opacity)\ngreen = mn.Color4(0.0, 1.0, 0.0, opacity)\nblue = mn.Color4(0.0, 0.0, 1.0, opacity)\nwhite = mn.Color4(1.0, 1.0, 1.0, opacity)\n\norigin = mn.Vector3(0.0, 0.0, 0.0)\neye_pos0 = mn.Vector3(2.5, 1.3, 1)\neye_pos1 = mn.Vector3(3.5, 3.0, 4.5)\nobj_axes_len = 0.4\n\nif \"sim\" not in globals():\n    global sim\n    sim = None\n    global sensor_node\n    sensor_node = None\n    global lr\n    lr = None\n    global image_counter\n    image_counter = 0\n```\n\n----------------------------------------\n\nTITLE: Render Path with Agent Python\nDESCRIPTION: This snippet places an agent and renders images at trajectory points along a calculated path. It iterates through path points, sets the agent's position and orientation, gets sensor observations, and displays the RGB, semantic, and depth images. It depends on `numpy` and Habitat-Sim's agent and sensor APIs.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndisplay_path_agent_renders = True  # @param{type:\"boolean\"}\nif display_path_agent_renders:\n    print(\"Rendering observations at path points:\")\n    tangent = path_points[1] - path_points[0]\n    agent_state = habitat_sim.AgentState()\n    for ix, point in enumerate(path_points):\n        if ix < len(path_points) - 1:\n            tangent = path_points[ix + 1] - point\n            agent_state.position = point\n            tangent_orientation_matrix = mn.Matrix4.look_at(\n                point, point + tangent, np.array([0, 1.0, 0])\n            )\n            tangent_orientation_q = mn.Quaternion.from_matrix(\n                tangent_orientation_matrix.rotation()\n            )\n            agent_state.rotation = utils.quat_from_magnum(tangent_orientation_q)\n            agent.set_state(agent_state)\n\n            observations = sim.get_sensor_observations()\n            rgb = observations[\"color_sensor\"]\n            semantic = observations[\"semantic_sensor\"]\n            depth = observations[\"depth_sensor\"]\n\n            if display:\n                display_sample(rgb, semantic, depth)\n```\n\n----------------------------------------\n\nTITLE: Get Topdown Map from NavMesh Python\nDESCRIPTION: This snippet retrieves a top-down map from the Habitat-sim API using `sim.pathfinder.get_topdown_view()`. It takes `meters_per_pixel` and `height` as parameters. It then optionally processes and displays the map using the `maps` module from Habitat-Lab, and saves the map to a file using the `imageio` library.  It depends on `numpy`, `imageio`, and the Habitat-Lab `maps` module.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nsim_topdown_map = sim.pathfinder.get_topdown_view(meters_per_pixel, height)\n\nif display:\n    hablab_topdown_map = maps.get_topdown_map(\n        sim.pathfinder, height, meters_per_pixel=meters_per_pixel\n    )\n    recolor_map = np.array(\n        [[255, 255, 255], [128, 128, 128], [0, 0, 0]], dtype=np.uint8\n    )\n    hablab_topdown_map = recolor_map[hablab_topdown_map]\n    print(\"Displaying the raw map from get_topdown_view:\")\n    display_map(sim_topdown_map)\n    print(\"Displaying the map from the Habitat-Lab maps module:\")\n    display_map(hablab_topdown_map)\n\n    map_filename = os.path.join(output_path, \"top_down_map.png\")\n    imageio.imsave(map_filename, hablab_topdown_map)\n```\n\n----------------------------------------\n\nTITLE: Modifying Wireframe UVSphere Template in Habitat-Sim (Python)\nDESCRIPTION: This code shows how to acquire and modify a default wireframe UV sphere template. Attributes modified include the number of rings and the number of segments.  The modifications are then registered using register_prim_template_if_valid.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_52\n\nLANGUAGE: python\nCODE:\n```\n# @title ####2.5.2 Wireframe UVSphere : { display-mode: \"form\" }\n# Acquire default template\nUVSphere_wireframe_template = prim_attr_mgr.get_default_UVsphere_template(True)\n\n\ndef edit_wireframe_UVSphere(edit_template):\n    # @markdown Number of (line) rings. Must be larger or equal to 2 and multiple of 2.\n    num_rings = 16  # @param {type:\"slider\", min:2, max:64, step:2}\n    edit_template.num_rings = num_rings\n    # @markdown Number of (line) segments. Must be larger or equal to 4 and multiple of 4.\n    num_segments = 40  # @param {type:\"slider\", min:4, max:64, step:4}\n    edit_template.num_segments = num_segments\n    # @markdown Do you want to make a UVSphere cylinder using your above modifications?\n    make_modified_wireframe_UVSphere = True  # @param {type:\"boolean\"}\n    # if make is set to true, save modified template.\n    register_prim_template_if_valid(\n        make_modified_wireframe_UVSphere,\n        edit_template,\n        wireframe_handles_to_use,\n        \"uvSphereWireframe\",\n    )\n\n\nedit_wireframe_UVSphere(UVSphere_wireframe_template)\n```\n\n----------------------------------------\n\nTITLE: Running Example Script Bash\nDESCRIPTION: This command executes the `example.py` script in Habitat-Sim. It needs the `--scene` argument to specify the scene file. The agent will traverse a predefined path, and performance statistics will be printed upon completion.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npython /path/to/habitat-sim/examples/example.py --scene /path/to/data/scene_datasets/habitat-test-scenes/skokloster-castle.glb\n```\n\n----------------------------------------\n\nTITLE: Add Drawable Test Target\nDESCRIPTION: Adds a test executable DrawableTest, links it with habitat_sim and Magnum importers (Gltf and Ufbx). The target_include_directories command sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  DrawableTest\n  DrawableTest.cpp\n  LIBRARIES\n  habitat_sim\n  MagnumPlugins::GltfImporter\n  MagnumPlugins::UfbxImporter\n)\ntarget_include_directories(DrawableTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Installing ccache on Linux\nDESCRIPTION: Installs ccache on Linux using apt package manager. ccache is used to improve build speed with caching.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nsudo apt install ccache\n```\n\n----------------------------------------\n\nTITLE: Removing Robot Object\nDESCRIPTION: This code removes the agent's rigid body from the scene while preserving its SceneNode, and then verifies the object no longer exists. It demonstrates how to manage objects in the Habitat simulator and handle their lifecycle.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n    # remove the agent's body while preserving the SceneNode\n    rigid_obj_mgr.remove_object_by_id(locobot.object_id, delete_object_node=False)\n\n    # demonstrate that the locobot object does not now exist'\n    print(\"Locobot is still alive : {}\".format(locobot.is_alive))\n```\n\n----------------------------------------\n\nTITLE: Place Dummy Agent for Playback\nDESCRIPTION: Places a dummy agent at the origin with an identity transform for replay playback.  This is done to use the sensor user transforms stored in the replay.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nagent_node.translation = [0.0, 0.0, 0.0]\nagent_node.rotation = mn.Quaternion()\n```\n\n----------------------------------------\n\nTITLE: habitat_sim.gfx module documentation\nDESCRIPTION: This snippet documents the `habitat_sim.gfx` module, which provides Python bindings for the C++ `esp::gfx` library. It enables access to graphics functionalities within the habitat-sim environment.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/gfx.rst#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. py:module:: habitat_sim.gfx\n    :summary: GFX library\n\n    Python bindings for :dox:`esp::gfx`. See the C++ docs for more information.\n```\n\n----------------------------------------\n\nTITLE: Running the New Actions Example in Habitat-Sim (Shell)\nDESCRIPTION: This shell command executes the `new_actions.py` example script, demonstrating the usage of custom actions within Habitat-Sim. It assumes that the script is located in the `examples/tutorials/` directory relative to the project root.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/new-actions.rst#_snippet_1\n\nLANGUAGE: shell-session\nCODE:\n```\n$ python examples/tutorials/new_actions.py\n```\n\n----------------------------------------\n\nTITLE: Create and Activate Conda Environment\nDESCRIPTION: This snippet shows how to create a new conda environment named 'habitat' with Python 3.9 and CMake 3.14.0, and then activate the environment. Conda is used to manage project dependencies.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# We require python>=3.9 and cmake>=3.10\nconda create -n habitat python=3.9 cmake=3.14.0\nconda activate habitat\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Docker Container Run\nDESCRIPTION: This command runs the Docker container `hsim_condabuild_dcontainer` in interactive mode with a bash shell.  It mounts the parent directory of the current working directory (`../`) to `/remote` inside the container, enables inter-process communication (`--ipc=host`), and removes the container after it exits (`--rm`).\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ndocker run -it --ipc=host --rm -v $(pwd)/../:/remote hsim_condabuild_dcontainer bash\n```\n\n----------------------------------------\n\nTITLE: Configuring Simulator Settings in Habitat-Sim (Python)\nDESCRIPTION: This snippet defines simulator settings, including scene paths, sensor configurations (RGB, depth, semantic), sensor height, and enabling/disabling physics. These settings are used to configure the simulation environment before initialization.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntest_scene = os.path.join(\n    data_path, \"scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\"\n)\nmp3d_scene_dataset = os.path.join(\n    data_path, \"scene_datasets/mp3d_example/mp3d.scene_dataset_config.json\"\n)\n\nrgb_sensor = True  # @param {type:\"boolean\"}\ndepth_sensor = True  # @param {type:\"boolean\"}\nsemantic_sensor = True  # @param {type:\"boolean\"}\n\nsim_settings = {\n    \"width\": 256,  # Spatial resolution of the observations\n    \"height\": 256,\n    \"scene\": test_scene,  # Scene path\n    \"scene_dataset\": mp3d_scene_dataset,  # the scene dataset configuration files\n    \"default_agent\": 0,\n    \"sensor_height\": 1.5,  # Height of sensors in meters\n    \"color_sensor\": rgb_sensor,  # RGB sensor\n    \"depth_sensor\": depth_sensor,  # Depth sensor\n    \"semantic_sensor\": semantic_sensor,  # Semantic sensor\n    \"seed\": 1,  # used in the random navigation\n    \"enable_physics\": False,  # kinematics only\n}\n```\n\n----------------------------------------\n\nTITLE: MSVC Definitions\nDESCRIPTION: This snippet adds a preprocessor definition `/DNOMINMAX` when using the MSVC compiler. This definition prevents conflicts with the Windows API's `min` and `max` macros.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nif(MSVC)\n  add_definitions(/DNOMINMAX)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Minimum CMake Version\nDESCRIPTION: This snippet sets the minimum required CMake version to 3.13. This ensures that the project is built with a compatible CMake version, preventing potential build errors or unexpected behavior due to older CMake features.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/imageconverter/CMakeLists.txt#_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.13)\n```\n\n----------------------------------------\n\nTITLE: Navigate to Conda Build Directory\nDESCRIPTION: This command navigates to the `/remote/conda-build` directory within the Docker container. This is where the Habitat-Sim source code has been mounted via the docker run command.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncd /remote/conda-build\n```\n\n----------------------------------------\n\nTITLE: Editing Wireframe Capsule Template\nDESCRIPTION: Acquires the default wireframe capsule template and allows for modification of its properties such as hemisphere rings, cylinder rings, number of segments, and half-length. The modified template can then be registered.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_45\n\nLANGUAGE: Python\nCODE:\n```\n# Acquire default template\ncapsule_wireframe_template = prim_attr_mgr.get_default_capsule_template(True)\n\n\ndef edit_wf_capsule(edit_template):\n    # @markdown Number of (line) rings for each hemisphere. Must be larger or equal to 1\n    hemisphere_rings = 7  # @param {type:\"slider\", min:1, max:10, step:1}\n    edit_template.hemisphere_rings = hemisphere_rings\n\n    # @markdown Number of (line) rings for cylinder. Must be larger or equal to 1.\n    cylinder_rings = 10  # @param {type:\"slider\", min:1, max:10, step:1}\n    edit_template.cylinder_rings = cylinder_rings\n\n    # @markdown Number of line segments. Must be larger or equal to 4 and multiple of 4\n    num_segments = 16  # @param {type:\"slider\", min:4, max:40, step:4}\n    edit_template.num_segments = num_segments\n\n    # @markdown Half the length of cylinder part.\n    half_length = 0.85  # @param {type:\"slider\", min:0.05, max:2.0, step:0.05}\n    edit_template.half_length = half_length\n\n    # @markdown Do you want to make a wireframe capsule using your above modifications?\n    make_modified_wireframe_capsule = True  # @param {type:\"boolean\"}\n    # if make is set to true, save modified template.\n    register_prim_template_if_valid(\n        make_modified_wireframe_capsule,\n        edit_template,\n        wireframe_handles_to_use,\n        \"capsule3DWireframe\",\n    )\n\n\nedit_wf_capsule(capsule_wireframe_template)\n```\n\n----------------------------------------\n\nTITLE: Velocity Control in Habitat Sim\nDESCRIPTION: This snippet demonstrates how to control an object's velocity in Habitat Sim using the `velocity_control` interface. It gets the object's velocity control structure, sets the linear and angular velocities, enables the velocity control, simulates the environment, reverses the linear velocity, and simulates again. It relies on `rigid_obj_mgr` and the `velocity_control` property.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n    # [velocity_control]\n\n    # get object VelocityControl structure and setup control\n    vel_control = clamp_obj.velocity_control\n    vel_control.linear_velocity = [0.0, 0.0, -1.0]\n    vel_control.angular_velocity = [4.0, 0.0, 0.0]\n    vel_control.controlling_lin_vel = True\n    vel_control.controlling_ang_vel = True\n\n    observations = simulate(sim, dt=1.0, get_frames=True)\n\n    # reverse linear direction\n    vel_control.linear_velocity = [0.0, 0.0, 1.0]\n\n    observations += simulate(sim, dt=1.0, get_frames=True)\n\n    if make_video:\n        vut.make_video(\n            observations,\n            \"rgba_camera_1stperson\",\n            \"color\",\n            output_path + \"velocity_control\",\n            open_vid=show_video,\n        )\n\n    # [/velocity_control]\n```\n\n----------------------------------------\n\nTITLE: Create Simulator Configuration\nDESCRIPTION: This snippet defines the `make_simple_cfg` function, which generates a configuration for the Habitat-sim simulator. It creates a `SimulatorConfiguration` object and an `AgentConfiguration` object, attaching a single RGB visual sensor to the agent. The sensor's UUID, type, resolution, and position are specified.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# This function generates a config for the simulator.\n# It contains two parts:\n# one for the simulator backend\n# one for the agent, where you can attach a bunch of sensors\ndef make_simple_cfg(settings):\n    # simulator backend\n    sim_cfg = habitat_sim.SimulatorConfiguration()\n    sim_cfg.scene_id = settings[\"scene\"]\n\n    # agent\n    agent_cfg = habitat_sim.agent.AgentConfiguration()\n\n    # In the 1st example, we attach only one sensor,\n    # a RGB visual sensor, to the agent\n    rgb_sensor_spec = habitat_sim.CameraSensorSpec()\n    rgb_sensor_spec.uuid = \"color_sensor\"\n    rgb_sensor_spec.sensor_type = habitat_sim.SensorType.COLOR\n    rgb_sensor_spec.resolution = [settings[\"height\"], settings[\"width\"]]\n    rgb_sensor_spec.position = [0.0, settings[\"sensor_height\"], 0.0]\n\n    agent_cfg.sensor_specifications = [rgb_sensor_spec]\n\n    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n\n\ncfg = make_simple_cfg(sim_settings)\n```\n\n----------------------------------------\n\nTITLE: Calculate Shortest Path on NavMesh Python\nDESCRIPTION: This code snippet demonstrates how to compute the shortest path between two points on the NavMesh using the `habitat_sim.ShortestPath` module. It samples two random navigable points, initializes a `ShortestPath` object, sets the start and end points, and then calls `sim.pathfinder.find_path` to find the path. The geodesic distance and path points are then printed.  It requires an initialized Pathfinder.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nsample1 = sim.pathfinder.get_random_navigable_point()\nsample2 = sim.pathfinder.get_random_navigable_point()\n\npath = habitat_sim.ShortestPath()\npath.requested_start = sample1\npath.requested_end = sample2\nfound_path = sim.pathfinder.find_path(path)\ngeodesic_distance = path.geodesic_distance\npath_points = path.points\nprint(\"found_path : \" + str(found_path))\nprint(\"geodesic_distance : \" + str(geodesic_distance))\nprint(\"path_points : \" + str(path_points))\n```\n\n----------------------------------------\n\nTITLE: Object Placement and Sensor Positioning\nDESCRIPTION: This snippet adds the object to the scene, centers it, and positions the sensor relative to the object's size. It also sets the object's motion type to STATIC to prevent it from moving during the simulation.  It initializes an agent and sets its initial state.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_30\n\nLANGUAGE: python\nCODE:\n```\n    # create object\n    obj = rigid_obj_mgr.add_object_by_template_id(obj_temp_id)\n    # place object in center - must be done before setting to static\n    # get bb of object\n    obj_bbox = obj.aabb\n    # find center of bb and move to scene origin - this centers object\n    obj.translation = -obj_bbox.center()\n    # get max dim to use as scale for sensor placement\n    bb_scale = max(obj_bbox.max)\n    # determine sensor placement based on size of object\n    sensor_pos = bb_scale * mn.Vector3(0.0, 1.0, 2.0)\n    # set object to be static\n    obj.motion_type = habitat_sim.physics.MotionType.STATIC\n\n    # initialize an agent and set its initial state\n    agent = sim.initialize_agent(sim_settings[\"default_agent\"])\n    agent_state = habitat_sim.AgentState()\n    agent_state.position = mn.Vector3(0.0, 0.0, 0.0)  # in world space\n    agent.set_state(agent_state)\n```\n\n----------------------------------------\n\nTITLE: Conditional Inclusion of Bullet Physics Sources\nDESCRIPTION: This snippet conditionally appends Bullet physics-related source files to the `physics_SOURCES` variable if the `BUILD_WITH_BULLET` flag is enabled. It uses `list(APPEND)` to add the files and includes headers and source files specific to the Bullet physics engine.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_14\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_WITH_BULLET)\n\n  # Add bullet sources\n  list(\n    APPEND\n    physics_SOURCES\n    physics/bullet/BulletArticulatedLink.h\n    physics/bullet/BulletArticulatedObject.cpp\n    physics/bullet/BulletArticulatedObject.h\n    physics/bullet/BulletBase.cpp\n    physics/bullet/BulletBase.h\n    physics/bullet/BulletCollisionHelper.cpp\n    physics/bullet/BulletCollisionHelper.h\n    physics/bullet/BulletPhysicsManager.cpp\n    physics/bullet/BulletPhysicsManager.h\n    physics/bullet/BulletRigidObject.cpp\n    physics/bullet/BulletRigidObject.h\n    physics/bullet/BulletRigidStage.cpp\n    physics/bullet/BulletRigidStage.h\n    physics/bullet/BulletURDFImporter.cpp\n    physics/bullet/BulletURDFImporter.h\n    physics/bullet/objectWrappers/ManagedBulletArticulatedObject.h\n    physics/bullet/objectWrappers/ManagedBulletRigidObject.h\n  )\n\n  ## Enable physics profiling\n  #add_compile_definitions(BT_ENABLE_PROFILE=0)\n  #add_definitions(-DBT_ENABLE_PROFILE)\n\nendif() #BUILD_WITH_BULLET\n```\n\n----------------------------------------\n\nTITLE: Testing YCB Assets in the Viewer Application\nDESCRIPTION: This snippet demonstrates how to launch the Habitat-Sim viewer application to test the loaded YCB assets.  It requires specifying the object directory and the dataset configuration file. It utilizes command-line arguments to configure the viewer. Assumes the user is in the habitat-sim directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n#from the habitat-sim directory\n# C++\n# ./build/viewer if compiling locally\nhabitat-viewer --use-default-lighting --enable-physics --object-dir \"\"  --dataset data/objects/ycb/ycb.scene_dataset_config.json -- data/test_assets/scenes/simple_room.glb\n```\n\n----------------------------------------\n\nTITLE: Building Dictionary from Template in Python\nDESCRIPTION: This function determines the appropriate template type and builds a corresponding dictionary of attributes. It takes a `template` as input and uses the `template_class` attribute to determine which `build_dict_of_*_attrs` function to call. It returns the resulting dictionary, or `None` if the template type is unknown.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_from_template(template):\n    template_class = template.template_class\n    if \"ObjectAttributes\" in template_class:\n        return build_dict_of_Object_attrs(template)\n    if \"StageAttributes\" in template_class:\n        return build_dict_of_Stage_attrs(template)\n    if \"PhysicsManagerAttributes\" in template_class:\n        return build_dict_of_PhysicsSim_attrs(template)\n    if \"CapsulePrimitiveAttributes\" in template_class:\n        return build_dict_of_Capsule_prim_attrs(template)\n    if \"ConePrimitiveAttributes\" in template_class:\n        return build_dict_of_Cone_prim_attrs(template)\n    if \"CubePrimitiveAttributes\" in template_class:\n        return build_dict_of_Cube_prim_attrs(template)\n    if \"CylinderPrimitiveAttributes\" in template_class:\n        return build_dict_of_Cylinder_prim_attrs(template)\n    if \"IcospherePrimitiveAttributes\" in template_class:\n        return build_dict_of_Icosphere_prim_attrs(template)\n    if \"UVSpherePrimitiveAttributes\" in template_class:\n        return build_dict_of_UVSphere_prim_attrs(template)\n    print(\"Unknown template type : %s \" % template_class)\n    return None\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for Metadata Module\nDESCRIPTION: This snippet defines a list of source files (`metadata_SOURCES`) for the `metadata` module using the `set` command. The list includes both `.cpp` and `.h` files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_10\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  metadata_SOURCES\n  metadata/attributes/AbstractAttributes.h\n  metadata/attributes/AbstractAttributes.cpp\n  metadata/attributes/AttributesEnumMaps.h\n  metadata/attributes/AttributesEnumMaps.cpp\n  metadata/attributes/AbstractObjectAttributes.h\n  metadata/attributes/AbstractObjectAttributes.cpp\n  metadata/attributes/AbstractSensorAttributes.h\n  metadata/attributes/AbstractSensorAttributes.cpp\n  metadata/attributes/AbstractVisualSensorAttributes.h\n  metadata/attributes/AbstractVisualSensorAttributes.cpp\n  metadata/attributes/ArticulatedObjectAttributes.h\n  metadata/attributes/ArticulatedObjectAttributes.cpp\n  metadata/attributes/AudioSensorAttributes.h\n  metadata/attributes/AudioSensorAttributes.cpp\n  metadata/attributes/CameraSensorAttributes.h\n  metadata/attributes/CameraSensorAttributes.cpp\n  metadata/attributes/CustomSensorAttributes.h\n  metadata/attributes/CustomSensorAttributes.cpp\n  metadata/attributes/CubeMapSensorAttributes.h\n  metadata/attributes/CubeMapSensorAttributes.cpp\n  metadata/attributes/LightLayoutAttributes.h\n  metadata/attributes/LightLayoutAttributes.cpp\n  metadata/attributes/MarkerSets.h\n  metadata/attributes/ObjectAttributes.h\n  metadata/attributes/ObjectAttributes.cpp\n  metadata/attributes/PhysicsManagerAttributes.h\n  metadata/attributes/PhysicsManagerAttributes.cpp\n  metadata/attributes/PbrShaderAttributes.h\n  metadata/attributes/PbrShaderAttributes.cpp\n  metadata/attributes/PrimitiveAssetAttributes.h\n  metadata/attributes/PrimitiveAssetAttributes.cpp\n  metadata/attributes/SceneInstanceAttributes.h\n  metadata/attributes/SceneInstanceAttributes.cpp\n  metadata/attributes/SceneDatasetAttributes.h\n  metadata/attributes/SceneDatasetAttributes.cpp\n  metadata/attributes/SemanticAttributes.h\n  metadata/attributes/SemanticAttributes.cpp\n  metadata/attributes/StageAttributes.h\n  metadata/attributes/StageAttributes.cpp\n  metadata/managers/AbstractAttributesManager.h\n  metadata/managers/AbstractObjectAttributesManager.h\n  metadata/managers/AOAttributesManager.h\n  metadata/managers/AOAttributesManager.cpp\n  metadata/managers/AssetAttributesManager.h\n  metadata/managers/AssetAttributesManager.cpp\n  metadata/managers/LightLayoutAttributesManager.h\n  metadata/managers/LightLayoutAttributesManager.cpp\n  metadata/managers/ObjectAttributesManager.h\n  metadata/managers/ObjectAttributesManager.cpp\n  metadata/managers/PbrShaderAttributesManager.h\n  metadata/managers/PbrShaderAttributesManager.cpp\n  metadata/managers/PhysicsAttributesManager.h\n  metadata/managers/PhysicsAttributesManager.cpp\n  metadata/managers/SceneInstanceAttributesManager.h\n  metadata/managers/SceneInstanceAttributesManager.cpp\n  metadata/managers/SceneDatasetAttributesManager.h\n  metadata/managers/SceneDatasetAttributesManager.cpp\n  metadata/managers/SemanticAttributesManager.h\n  metadata/managers/SemanticAttributesManager.cpp\n  metadata/managers/SensorAttributesManager.h\n  metadata/managers/SensorAttributesManager.cpp\n  metadata/managers/StageAttributesManager.h\n  metadata/managers/StageAttributesManager.cpp\n  metadata/MetadataMediator.h\n  metadata/MetadataMediator.cpp\n  metadata/URDFParser.cpp\n  metadata/URDFParser.h\n)\n```\n\n----------------------------------------\n\nTITLE: Editing Wireframe Cone Template\nDESCRIPTION: Acquires the default wireframe cone template and allows for modification of its properties such as the number of segments and half-length. The modified template can then be registered.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_47\n\nLANGUAGE: Python\nCODE:\n```\n# Acquire default template\ncone_wireframe_template = prim_attr_mgr.get_default_cone_template(True)\n\n\ndef edit_wireframe_cone(edit_template):\n    # @markdown Number of (line) segments. Must be larger or equal to 4 and multiple of 4.\n    num_segments = 32  # @param {type:\"slider\", min:4, max:40, step:4}\n    edit_template.num_segments = num_segments\n    # @markdown Half the cone length\n    half_length = 1.25  # @param {type:\"slider\", min:0.05, max:2.0, step:0.05}\n    edit_template.half_length = half_length\n    # @markdown Do you want to make a wireframe cone using your above modifications?\n    make_modified_wireframe_cone = True  # @param {type:\"boolean\"}\n    # if make is set to true, save modified template.\n    register_prim_template_if_valid(\n        make_modified_wireframe_cone,\n        edit_template,\n        wireframe_handles_to_use,\n        \"coneWireframe\",\n    )\n\n\nedit_wireframe_cone(cone_wireframe_template)\n```\n\n----------------------------------------\n\nTITLE: Removing Locobot Object from Scene\nDESCRIPTION: This snippet removes the Locobot object from the scene, optionally preserving the agent node for later use. It then removes all other objects from the scene. It utilizes the `rigid_obj_mgr` to manage object removal.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_34\n\nLANGUAGE: Python\nCODE:\n```\n# remove locobot while leaving the agent node for later use\nrigid_obj_mgr.remove_object_by_id(locobot_obj.object_id, delete_object_node=False)\nrigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Building Cube Primitive Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_Cube_prim_attrs` builds a dictionary of attribute properties for a cube primitive template (`cube_template`). It relies on the base primitive attributes dictionary provided by `build_dict_of_prim_attrs`. The returned dictionary represents the attributes of the cube.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Cube_prim_attrs(cube_template):\n    res_dict = build_dict_of_prim_attrs(cube_template)\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Simulation and Object Rotation\nDESCRIPTION: This snippet simulates the environment for a specified video length, rotating the agent at each step to achieve the carousel view. It appends the sensor observations to the observations list. The rotation amount is calculated based on the desired video length and the simulation time step.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_32\n\nLANGUAGE: python\nCODE:\n```\n    # @markdown Set how long the resultant video should be, in seconds.  The object will make 1 full revolution during this time.\n    video_length = 4.8  # @param {type:\"slider\", min:1.0, max:20.0, step:0.1}\n    # Sim time step\n    time_step = 1.0 / 60.0\n    # Amount to rotate per frame to make 1 full rotation\n    rot_amount = 2 * math.pi / (video_length / time_step)\n\n    # simulate with updated camera at each frame\n    start_time = sim.get_world_time()\n    while sim.get_world_time() - start_time < video_length:\n        sim.step_physics(time_step)\n        # rotate the agent to rotate the camera\n        agent_state.rotation *= ut.quat_from_angle_axis(\n            rot_amount, np.array([0.0, 1.0, 0.0])\n        )\n        agent.set_state(agent_state)\n\n        observations.append(sim.get_sensor_observations())\n```\n\n----------------------------------------\n\nTITLE: Load NavMesh from File Python\nDESCRIPTION: This code snippet shows how to load a NavMesh from a file, either automatically when initializing the simulator with a scene (if the `.navmesh` file has the same name as the scene) or explicitly using `sim.pathfinder.load_nav_mesh()`.  The code assumes that the scene file (`apartment_1.glb`) and the NavMesh file (`apartment_1.navmesh`) are located in the specified directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# initialize a new simulator with the apartment_1 scene\n# this will automatically load the accompanying .navmesh file\nsim_settings[\"scene\"] = os.path.join(\n    data_path, \"scene_datasets/habitat-test-scenes/apartment_1.glb\"\n)\ncfg = make_cfg(sim_settings)\ntry:  # Got to make initialization idiot proof\n    sim.close()\nexcept NameError:\n    pass\nsim = habitat_sim.Simulator(cfg)\n\n# the navmesh can also be explicitly loaded\nsim.pathfinder.load_nav_mesh(\n    os.path.join(data_path, \"scene_datasets/habitat-test-scenes/apartment_1.navmesh\")\n)\n```\n\n----------------------------------------\n\nTITLE: Basic Object Manipulation in Habitat\nDESCRIPTION: This snippet demonstrates basic object manipulation in the Habitat simulator. It loads a sphere template from a configuration file, adds a sphere object to the scene, moves the sphere, simulates the environment, and generates a video if enabled. It depends on the `obj_templates_mgr`, `rigid_obj_mgr`, and `simulate` functions.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n    # [basics]\n\n    # load some object templates from configuration files\n    sphere_template_id = obj_templates_mgr.load_configs(\n        str(os.path.join(data_path, \"test_assets/objects/sphere\"))\n    )[0]\n\n    # add a sphere to the scene, returns the object\n    sphere_obj = rigid_obj_mgr.add_object_by_template_id(sphere_template_id)\n    # move sphere\n    sphere_obj.translation = [2.50, 0.0, 0.2]\n\n    # simulate\n    observations = simulate(sim, dt=1.5, get_frames=make_video)\n\n    if make_video:\n        vut.make_video(\n            observations,\n            \"rgba_camera_1stperson\",\n            \"color\",\n            output_path + \"sim_basics\",\n            open_vid=show_video,\n        )\n\n    # [/basics]\n    rigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Initializing Wireframe Cube Handle\nDESCRIPTION: Initializes the handle for a wireframe cube primitive from the asset template manager. Wireframe cube has no customizable attributes.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_42\n\nLANGUAGE: Python\nCODE:\n```\nwireframe_handles_to_use = {\n    \"cubeWireframe\": prim_attr_mgr.get_template_handles(\"cubeWireframe\")[0]\n}\n```\n\n----------------------------------------\n\nTITLE: Finding windowless application library based on platform\nDESCRIPTION: This snippet determines the appropriate windowless application library to use based on the target platform. It uses a series of `if` and `elseif` statements to check the platform (EGL, Apple, Unix, or Windows) and then uses `find_package` to locate the corresponding Magnum WindowlessApplication library (WindowlessEglApplication, WindowlessCglApplication, WindowlessGlxApplication, or WindowlessWglApplication). If none of the supported platforms are found, it issues a fatal error.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/gfx_batch/CMakeLists.txt#_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nif(MAGNUM_TARGET_EGL)\n  find_package(Magnum REQUIRED WindowlessEglApplication)\nelif(CORRADE_TARGET_APPLE)\n  find_package(Magnum REQUIRED WindowlessCglApplication)\nelif(CORRADE_TARGET_UNIX)\n  # Mainly for builds with external Magnum that might not have TARGET_EGL\n  # enabled\n  find_package(Magnum REQUIRED WindowlessGlxApplication)\nelif(CORRADE_TARGET_WINDOWS)\n  find_package(Magnum REQUIRED WindowlessWglApplication)\nelse()\n  message(FATAL_ERROR \"Unsupported platform\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Building UVSphere Primitive Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_UVSphere_prim_attrs` builds a dictionary for the UV-Sphere primitive template (`uvsphere_template`).  It calls `build_dict_of_prim_attrs` to get the base primitive attributes, and the resulting dictionary represents the set of attributes for the UV-Sphere.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_UVSphere_prim_attrs(uvsphere_template):\n    res_dict = build_dict_of_prim_attrs(uvsphere_template)\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Loading and Simulating a Scene in Habitat-sim\nDESCRIPTION: This snippet loads the selected scene into the Habitat-sim simulator, simulates the environment, and generates a video of the simulation. The agent's scene node is rotated, and the simulation is stepped forward in time.  Sensor observations are captured and used to generate a video if `make_video` is enabled.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ReplicaCAD_quickstart.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nglobal selected_scene\nif sim_settings[\"scene\"] != selected_scene:\n    sim_settings[\"scene\"] = selected_scene\n    make_simulator_from_settings(sim_settings)\n\nobservations = []\nstart_time = sim.get_world_time()\nwhile sim.get_world_time() < start_time + 4.0:\n    sim.agents[0].scene_node.rotate(mn.Rad(mn.math.pi_half / 60.0), mn.Vector3(0, 1, 0))\n    sim.step_physics(1.0 / 60.0)\n    if make_video:\n        observations.append(sim.get_sensor_observations())\n\n# video rendering of carousel view\nvideo_prefix = \"ReplicaCAD_scene_view\"\nif make_video:\n    vut.make_video(\n        observations,\n        \"color_sensor_1st_person\",\n        \"color\",\n        output_path + video_prefix,\n        open_vid=show_video,\n        video_dims=[1280, 720],\n    )\n```\n\n----------------------------------------\n\nTITLE: Path Setup and Imports in Habitat-sim\nDESCRIPTION: This snippet sets up the necessary paths and imports required libraries for using Habitat-sim, including os, git, magnum, habitat_sim, and habitat_sim.utils.viz_utils. It also checks for the presence of ipywidgets for interactive components in a Jupyter environment.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ReplicaCAD_quickstart.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport git\nimport magnum as mn\n\nimport habitat_sim\nfrom habitat_sim.utils import viz_utils as vut\n\ntry:\n    import ipywidgets as widgets\n    from IPython.display import display as ipydisplay\n\n    # For using jupyter/ipywidget IO components\n\n    HAS_WIDGETS = True\nexcept ImportError:\n    HAS_WIDGETS = False\n\nrepo = git.Repo(\".\", search_parent_directories=True)\ndir_path = repo.working_tree_dir\ndata_path = os.path.join(dir_path, \"data\")\noutput_path = os.path.join(\n    dir_path, \"examples/tutorials/replica_cad_output/\"\n)  # @param {type:\"string\"}\nos.makedirs(output_path, exist_ok=True)\n\n# define some globals the first time we run.\nif \"sim\" not in globals():\n    global sim\n    sim = None\n    global obj_attr_mgr\n    obj_attr_mgr = None\n    global stage_attr_mgr\n    stage_attr_mgr = None\n    global rigid_obj_mgr\n    rigid_obj_mgr = None\n```\n\n----------------------------------------\n\nTITLE: Initializing Habitat-sim and Dependencies\nDESCRIPTION: This snippet initializes the required paths and imports necessary for using the Habitat-Sim engine. It also checks for optional dependencies like `ipywidgets` and sets up global variables for the simulator and managers.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport math\nimport os\n\nimport git\nimport magnum as mn\nimport numpy as np\n\nimport habitat_sim\nfrom habitat_sim.bindings import built_with_bullet\nfrom habitat_sim.utils import common as ut\nfrom habitat_sim.utils import viz_utils as vut\n\ntry:\n    import ipywidgets as widgets\n    from IPython.display import display as ipydisplay\n\n    # For using jupyter/ipywidget IO components\n\n    HAS_WIDGETS = True\nexcept ImportError:\n    HAS_WIDGETS = False\n\nrepo = git.Repo(\".\", search_parent_directories=True)\ndir_path = repo.working_tree_dir\ndata_path = os.path.join(dir_path, \"data\")\n# fmt: off\noutput_directory = \"examples/tutorials/asset_viewer_output/\"  # @param {type:\"string\"}\n# fmt: on\noutput_path = os.path.join(dir_path, output_directory)\nos.makedirs(output_path, exist_ok=True)\n\n# define some globals the first time we run.\nif \"sim\" not in globals():\n    global sim\n    sim = None\n    global obj_attr_mgr\n    obj_attr_mgr = None\n    global prim_attr_mgr\n    obj_attr_mgr = None\n    global stage_attr_mgr\n    stage_attr_mgr = None\n    global rigid_obj_mgr\n    rigid_obj_mgr = None\n```\n\n----------------------------------------\n\nTITLE: Configuring User-Defined Object Values in Habitat-Sim (Python)\nDESCRIPTION: This snippet retrieves and modifies user-defined configuration values for a rigid object. It demonstrates how to access and change parameters within the object's attributes, allowing for customized object behavior within the simulation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# [object_user_configurations]\nprint(f\"sphere_object.user_attributes[int_slider]: {sphere_object.user_attributes['int_slider']}\")\nsphere_object.user_attributes['int_slider'] = 2\nprint(f\"sphere_object.user_attributes[int_slider]: {sphere_object.user_attributes['int_slider']}\")\n\nprint(f\"sphere_object.user_attributes[float_slider]: {sphere_object.user_attributes['float_slider']}\")\nsphere_object.user_attributes['float_slider'] = 1.5\nprint(f\"sphere_object.user_attributes[float_slider]: {sphere_object.user_attributes['float_slider']}\")\n\nprint(f\"sphere_object.user_attributes[string_text]: {sphere_object.user_attributes['string_text']}\")\nsphere_object.user_attributes['string_text'] = 'new string'\nprint(f\"sphere_object.user_attributes[string_text]: {sphere_object.user_attributes['string_text']}\")\n\nprint(f\"sphere_object.user_attributes[color]: {sphere_object.user_attributes['color']}\")\nsphere_object.user_attributes['color'] = [0, 1, 0]\nprint(f\"sphere_object.user_attributes[color]: {sphere_object.user_attributes['color']}\")\n\n# [/object_user_configurations]\n```\n\n----------------------------------------\n\nTITLE: Visualize GLB Scene Coordinate Frame (Incorrect Method)\nDESCRIPTION: This snippet demonstrates the issues with loading a GLB file directly as a scene.  It loads a chair GLB file as the scene, draws the world axes, and displays the scene.  It's crucial to note that this is a legacy codepath and that the loaded model will be rotated by 90 degrees, which is not the intended behavior. It highlights an incorrect method of loading scenes and showcases potential pitfalls.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/coordinate_frame_tutorial.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ncreate_sim_helper(\n    scene_id=os.path.join(data_path, \"replica_cad/objects/frl_apartment_chair_01.glb\")\n)\ndraw_axes(origin)\nshow_scene(calc_camera_transform(eye_translation=eye_pos0, lookat=origin))\n```\n\n----------------------------------------\n\nTITLE: Argument Parsing with argparse in Habitat Sim\nDESCRIPTION: This snippet uses the `argparse` module to handle command-line arguments for controlling video output. It defines arguments to enable or disable video display (`--no-show-video`) and video creation (`--no-make-video`), defaulting to both being enabled.  The parsed arguments are then used to control the video generation process.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--no-show-video\", dest=\"show_video\", action=\"store_false\")\n    parser.add_argument(\"--no-make-video\", dest=\"make_video\", action=\"store_false\")\n    parser.set_defaults(show_video=True, make_video=True)\n    args, _ = parser.parse_known_args()\n    show_video = args.show_video\n    make_video = args.make_video\n    if make_video and not os.path.exists(output_path):\n        os.mkdir(output_path)\n```\n\n----------------------------------------\n\nTITLE: Configuration: Enable Gfx Replay Save\nDESCRIPTION: Defines a function to create a simulator configuration, enabling the `enable_gfx_replay_save` flag. This is essential for using the gfx replay recording API. It also sets up the scene, enables physics, and configures the camera sensor.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef make_configuration(settings):\n    make_video_during_sim = False\n    if \"make_video_during_sim\" in settings:\n        make_video_during_sim = settings[\"make_video_during_sim\"]\n\n    # simulator configuration\n    backend_cfg = habitat_sim.SimulatorConfiguration()\n    backend_cfg.scene_id = os.path.join(\n        data_path, \"scene_datasets/habitat-test-scenes/apartment_1.glb\"\n    )\n    assert os.path.exists(backend_cfg.scene_id)\n    backend_cfg.enable_physics = built_with_bullet\n\n    # Enable gfx replay save. See also our call to sim.gfx_replay_manager.save_keyframe()\n    # below.\n    backend_cfg.enable_gfx_replay_save = True\n    backend_cfg.create_renderer = make_video_during_sim\n\n    sensor_cfg = habitat_sim.CameraSensorSpec()\n    sensor_cfg.resolution = [544, 720]\n    agent_cfg = habitat_sim.agent.AgentConfiguration()\n    agent_cfg.sensor_specifications = [sensor_cfg]\n\n    return habitat_sim.Configuration(backend_cfg, [agent_cfg])\n```\n\n----------------------------------------\n\nTITLE: Accessing Audio Sensor Structs/Enums via Pybind11\nDESCRIPTION: Demonstrates how to import and access the audio sensor structs and enums via pybind11 in Python.  This is necessary to configure the audio simulation using the C++ backend.  The structs and enums are part of the `hsim_bindings` module.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/AUDIO.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport habitat_sim\nimport habitat_sim._ext.habitat_sim_bindings as hsim_bindings\nimport habitat_sim.sensor\nimport habitat_sim.sim\n\nhsim_bindings.RLRAudioPropagationConfiguration()\nhsim_bindings.RLRAudioPropagationChannelLayout()\nhsim_bindings.RLRAudioPropagationChannelLayoutType.Binaural\n```\n\n----------------------------------------\n\nTITLE: Install Linux Dependencies\nDESCRIPTION: This snippet updates the package list and installs several essential packages for EGL support on Linux systems. These packages are required for OpenGL rendering and related functionalities within Habitat-Sim.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get update || true\n# These are fairly ubiquitous packages and your system likely has them already,\n# but if not, let's get the essentials for EGL support:\nsudo apt-get install -y --no-install-recommends \\\n     libjpeg-dev libglm-dev libgl1-mesa-glx libegl1-mesa-dev mesa-utils xorg-dev freeglut3-dev\n```\n\n----------------------------------------\n\nTITLE: Setup and Imports\nDESCRIPTION: This snippet imports necessary libraries for Habitat-sim, including `math`, `os`, `random`, `git`, `imageio`, `magnum`, `numpy`, `matplotlib`, `PIL`, `habitat_sim` and `habitat_sim.utils`. It also configures the data path and output directory for video output.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport math\nimport os\nimport random\n\nimport git\nimport imageio\nimport magnum as mn\nimport numpy as np\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\n# function to display the topdown map\nfrom PIL import Image\n\nimport habitat_sim\nfrom habitat_sim.utils import common as utils\nfrom habitat_sim.utils import viz_utils as vut\n\nrepo = git.Repo(\".\", search_parent_directories=True)\ndir_path = repo.working_tree_dir\ndata_path = os.path.join(dir_path, \"data\")\nprint(f\"data_path = {data_path}\")\n# @markdown Optionally configure the save path for video output:\noutput_directory = os.path.join(\n    dir_path, \"examples/tutorials/nav_output/\"\n)  # @param {type:\"string\"}\noutput_path = os.path.join(dir_path, output_directory)\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\n```\n\n----------------------------------------\n\nTITLE: Building Dictionary from Template (Habitat-Sim)\nDESCRIPTION: This function `build_dict_from_template` constructs a dictionary from a given template. It determines the template's class and calls specific helper functions (e.g., `build_dict_of_Object_attrs`) based on the class name. If the template type is unknown, it prints an error message and returns None.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_from_template(template):\n    template_class = template.template_class\n    if \"ObjectAttributes\" in template_class:\n        return build_dict_of_Object_attrs(template)\n    if \"StageAttributes\" in template_class:\n        return build_dict_of_Stage_attrs(template)\n    if \"PhysicsManagerAttributes\" in template_class:\n        return build_dict_of_PhysicsSim_attrs(template)\n    if \"CapsulePrimitiveAttributes\" in template_class:\n        return build_dict_of_Capsule_prim_attrs(template)\n    if \"ConePrimitiveAttributes\" in template_class:\n        return build_dict_of_Cone_prim_attrs(template)\n    if \"CubePrimitiveAttributes\" in template_class:\n        return build_dict_of_Cube_prim_attrs(template)\n    if \"CylinderPrimitiveAttributes\" in template_class:\n        return build_dict_of_Cylinder_prim_attrs(template)\n    if \"IcospherePrimitiveAttributes\" in template_class:\n        return build_dict_of_Icosphere_prim_attrs(template)\n    if \"UVSpherePrimitiveAttributes\" in template_class:\n        return build_dict_of_UVSphere_prim_attrs(template)\n    print(\"Unknown template type : %s \" % template_class)\n    return None\n```\n\n----------------------------------------\n\nTITLE: PathFinder Obstacle Distance\nDESCRIPTION: Describes the `habitat_sim.nav.PathFinder.distance_to_closest_obstacle` function. It returns the distance to the closest obstacle, or `max_search_radius` if no obstacle is found within that radius.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.nav.PathFinder.distance_to_closest_obstacle\n```\n\n----------------------------------------\n\nTITLE: Creating Habitat-Sim Static Library\nDESCRIPTION: This code defines a static library called `habitat_sim` and assigns all the defined module source files to it, including core, geo, gfx, assets, metadata, io, scene, physics, nav, sensor and sim sources. These modules define different functionalities within the habitat simulator.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_20\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  habsim_SOURCES\n  ${core_SOURCES}\n  ${geo_SOURCES}\n  ${gfx_SOURCES}\n  ${assets_SOURCES}\n  ${metadata_SOURCES}\n  ${io_SOURCES}\n  ${scene_SOURCES}\n  ${physics_SOURCES}\n  ${nav_SOURCES}\n  ${sensor_SOURCES}\n  ${sim_SOURCES}\n)\n\nadd_library(\n  habitat_sim STATIC\n  ${habsim_SOURCES}\n)\n```\n\n----------------------------------------\n\nTITLE: Downloading HSSD with Python\nDESCRIPTION: This code snippet demonstrates how to download the HSSD dataset using the `habitat_sim.utils.datasets_download` module. It requires a Hugging Face username and password, passed as `--username` and `--password` arguments respectively. The `--uids` argument specifies `hssd-hab`, and the `--data-path` argument sets the destination directory to `data/`. Replace `<huggingface-username>` and `<huggingface-password>` with your actual Hugging Face credentials.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\npython -m habitat_sim.utils.datasets_download --username <huggingface-username> --password <huggingface-password> --uids hssd-hab --data-path data/\n```\n\n----------------------------------------\n\nTITLE: Event Handler for File Object Dropdown Change (Habitat-Sim)\nDESCRIPTION: The `on_file_obj_ddl_change` function serves as an event handler for dropdowns that display file-based object handles. When the selected value in the dropdown changes, this function updates the global variable `sel_file_obj_handle` with the new value and returns it.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef on_file_obj_ddl_change(ddl_values):\n    global sel_file_obj_handle\n    sel_file_obj_handle = ddl_values[\"new\"]\n    return sel_file_obj_handle\n```\n\n----------------------------------------\n\nTITLE: Modifying Solid Icosphere Template in Habitat-Sim (Python)\nDESCRIPTION: This code shows how to acquire and modify a default solid icosphere template. The attribute modified is the subdivisions level. The modifications are then registered using register_prim_template_if_valid.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_50\n\nLANGUAGE: python\nCODE:\n```\n# @title ####2.4.1 Solid Icosphere : { display-mode: \"form\" }\n# Acquire default template\nicosphere_solid_template = prim_attr_mgr.get_default_icosphere_template(False)\n\n\ndef edit_solid_icosphere(edit_template):\n    # @markdown Describes the depth of recursive subdivision for each icosphere triangle.\n    subdivisions = 3  # @param {type:\"slider\", min:1, max:10, step:1}\n    edit_template.subdivisions = subdivisions\n    # @markdown Do you want to make a solid icosphere using your above modifications?\n    make_modified_solid_icosphere = True  # @param {type:\"boolean\"}\n    # if make is set to true, save modified template.\n    register_prim_template_if_valid(\n        make_modified_solid_icosphere,\n        edit_template,\n        solid_handles_to_use,\n        \"icosphereSolid\",\n    )\n\n\nedit_solid_icosphere(icosphere_solid_template)\n```\n\n----------------------------------------\n\nTITLE: Downloading HM3D Minival Split with Python\nDESCRIPTION: This code snippet demonstrates how to download the HM3D minival split using the `habitat_sim.utils.datasets_download` module. It requires a Matterport API token ID and secret, which are passed as `--username` and `--password` arguments respectively. The `--uids` argument specifies the `hm3d_minival_v0.2` dataset.  Replace `<api-token-id>` and `<api-token-secret>` with your actual API credentials.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\npython -m habitat_sim.utils.datasets_download --username <api-token-id> --password <api-token-secret> --uids hm3d_minival_v0.2\n```\n\n----------------------------------------\n\nTITLE: PathFinder Snap Point Function\nDESCRIPTION: Describes the `habitat_sim.nav.PathFinder.snap_point` function which snaps a given point to the closest navigable location within a 4x8x4 cube. Returns ``{NAN, NAN, NAN}`` if no navigable point exists within the cube.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.nav.PathFinder.snap_point\n```\n\n----------------------------------------\n\nTITLE: Adding Replayer Executable\nDESCRIPTION: This snippet uses the `add_executable` command to define the replayer executable, specifying `replayer.cpp` as the source file. This command creates the executable target within the CMake build system, and compiles `replayer.cpp` to generate the output.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/replayer/CMakeLists.txt#_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(replayer replayer.cpp)\n```\n\n----------------------------------------\n\nTITLE: Building Habitat-sim Template Dictionary\nDESCRIPTION: This code defines a utility function for extracting attribute information from Habitat-sim template objects. The `build_dict_of_Default_attrs` function takes a template object as input and returns a dictionary containing key-value pairs representing the attribute properties. Each value is a tuple containing the value, a boolean indicating editability, and the data type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Default_attrs(template):\n    res_dict = {\n        \"handle\": (template.handle, True, \"string\"),\n        # Read-only values\n        \"template_id\": (template.template_id, False, \"int\"),\n        \"template_class\": (template.template_class, False, \"string\"),\n        \"file_directory\": (template.file_directory, False, \"string\"),\n        \"num_user_configs\": (template.num_user_configs, False, \"int\"),\n    }\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Finding Magnum and Corrade packages with CMake\nDESCRIPTION: This snippet uses CMake's `find_package` command to locate the Magnum and Corrade libraries, which are required dependencies for the gfx_batch library. It specifically requests the GL, SceneTools, Shaders, and Trade components of Magnum, and the Utility component of Corrade. The `REQUIRED` keyword ensures that the configuration fails if these packages are not found.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/gfx_batch/CMakeLists.txt#_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(\n  Magnum\n  REQUIRED\n  GL\n  SceneTools\n  Shaders\n  Trade\n)\nfind_package(Corrade REQUIRED Utility)\n```\n\n----------------------------------------\n\nTITLE: Set Object State Relative to Agent\nDESCRIPTION: This function sets the object's position and orientation relative to the agent's current transform in the simulation. It takes the simulator instance, the object to be manipulated, an offset vector, and an orientation quaternion as inputs. The object's new translation is calculated by transforming the offset vector by the agent's transform, and the object's rotation is set to the provided orientation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef set_object_state_from_agent(\n    sim,\n    obj,\n    offset=np.array([0, 2.0, -1.5]),\n    orientation=mn.Quaternion(((0, 0, 0), 1)),\n):\n    agent_transform = sim.agents[0].scene_node.transformation_matrix()\n    ob_translation = agent_transform.transform_point(offset)\n    obj.translation = ob_translation\n    obj.rotation = orientation\n```\n\n----------------------------------------\n\nTITLE: Initialize Camera Tracking (init_camera_track_config)\nDESCRIPTION: This function initializes the camera tracking configuration.  It saves the initial state of the specified sensor and agent, allowing for later restoration.  It modifies the sensor's position and orientation, and boosts the agent off the floor for better visibility. It takes the simulator instance `sim`, sensor name `sensor_name`, and agent ID `agent_ID` as input. It returns a dictionary containing the initial state of the sensor and agent.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Save sensor and agent state to a dictionary, so that initial values can be reset\n# Used at beginning of cell that directly modifies camera (i.e. tracking an object)\ndef init_camera_track_config(sim, sensor_name=\"color_sensor_1st_person\", agent_ID=0):\n    init_state = {}\n    visual_sensor = sim._sensors[sensor_name]\n    # save ref to sensor being used\n    init_state[\"visual_sensor\"] = visual_sensor\n    init_state[\"position\"] = np.array(visual_sensor._spec.position)\n    init_state[\"orientation\"] = np.array(visual_sensor._spec.orientation)\n    # set the color sensor transform to be the agent transform\n    visual_sensor._spec.position = mn.Vector3(0.0, 0.0, 0.0)\n    visual_sensor._spec.orientation = mn.Vector3(0.0, 0.0, 0.0)\n    visual_sensor._sensor_object.set_transformation_from_spec()\n    # save ID of agent being modified\n    init_state[\"agent_ID\"] = agent_ID\n    # save agent initial state\n    init_state[\"agent_state\"] = sim.get_agent(agent_ID).get_state()\n    # boost the agent off the floor\n    sim.get_agent(agent_ID).scene_node.translation += np.array([0, 1.5, 0])\n    return init_state\n```\n\n----------------------------------------\n\nTITLE: Adding and Rotating Objects in Target Zone\nDESCRIPTION: This snippet adds multiple objects to the scene, rotates them, and samples their states from a defined target zone using `sample_object_state`. If the sampling fails, the object is removed. It utilizes the rigid object manager to add, remove, and manipulate objects.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nnum_targets = 9  # @param{type:\"integer\"}\nfor _target in range(num_targets):\n    obj = rigid_obj_mgr.add_object_by_template_handle(cheezit_handle)\n    # rotate boxes off of their sides\n    obj.rotation = mn.Quaternion.rotation(\n        mn.Rad(-mn.math.pi_half), mn.Vector3(1.0, 0, 0)\n    )\n    # sample state from the target zone\n    if not sample_object_state(sim, obj, False, True, 100, target_zone):\n        rigid_obj_mgr.remove_object_by_id(obj.object_id)\n```\n\n----------------------------------------\n\nTITLE: Simulating Physics in Habitat Sim\nDESCRIPTION: This function simulates the physics within the Habitat environment for a specified duration (dt) at a fixed timestep of 1/60 seconds. It steps the physics engine and collects sensor observations at each step, storing them in a list. It returns the list of sensor observations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef simulate(sim, dt=1.0, get_frames=True):\n    # simulate dt seconds at 60Hz to the nearest fixed timestep\n    print(\"Simulating \" + str(dt) + \" world seconds.\")\n    observations = []\n    start_time = sim.get_world_time()\n    while sim.get_world_time() < start_time + dt:\n        sim.step_physics(1.0 / 60.0)\n        if get_frames:\n            observations.append(sim.get_sensor_observations())\n\n    return observations\n```\n\n----------------------------------------\n\nTITLE: Define Simulator Settings\nDESCRIPTION: This snippet defines the basic settings for the Habitat-sim simulator, including the scene path, default agent index, sensor height, and observation resolution (width and height).  The `test_scene` variable specifies the path to the scene file.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# This is the scene we are going to load.\n# we support a variety of mesh formats, such as .glb, .gltf, .obj, .ply\ntest_scene = os.path.join(\n    data_path, \"scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\"\n)\n\nsim_settings = {\n    \"scene\": test_scene,  # Scene path\n    \"default_agent\": 0,  # Index of the default agent\n    \"sensor_height\": 1.5,  # Height of sensors in meters, relative to the agent\n    \"width\": 256,  # Spatial resolution of the observations\n    \"height\": 256,\n}\n```\n\n----------------------------------------\n\nTITLE: Velocity Control of Kinematic Objects in Habitat-Sim (Python)\nDESCRIPTION: This code demonstrates how to use the VelocityControl structure to specify a constant linear and angular velocity for a kinematic object. This allows for easier programmatic control of the object's movement without manual state setting.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# [velocity_control]\n# get a reference to the object's velocity control\nvel_control = can_object.velocity_control\nvel_control.linear_velocity = np.array([0, 0, 1.0])\nvel_control.angular_velocity = np.array([0, 2.0, 0])\n\n# simulate velocity control\nfor _ in range(100):\n    for box in boxes:\n        box.apply_force(anti_grav_force, np.array([0, 0, 0]))\n        box.apply_torque(np.array([rotation_speed, rotation_speed, rotation_speed]))\n    sim.step_physics(1 / 60.0)\n# [/velocity_control]\n```\n\n----------------------------------------\n\nTITLE: Making Simulate and Video Button (Habitat-Sim)\nDESCRIPTION: The `make_sim_and_vid_button` function creates a button that, when clicked, simulates the Habitat environment and generates a video of the simulation. The function takes a prefix for the output video file name and a simulation time `dt` as arguments.  The function is skipped if HAS_WIDGETS is false.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndef make_sim_and_vid_button(prefix, dt=1.0):\n    if not HAS_WIDGETS:\n        return\n\n    def on_sim_click(b):\n        observations = simulate(sim, dt=dt)\n        vut.make_video(\n            observations,\n            \"color_sensor_1st_person\",\n            \"color\",\n            output_path + prefix,\n            open_vid=show_video,\n        )\n\n    sim_and_vid_btn = set_button_launcher(\"Simulate and Make Video\")\n    sim_and_vid_btn.on_click(on_sim_click)\n    ipydisplay(sim_and_vid_btn)\n```\n\n----------------------------------------\n\nTITLE: Creating Video with Embedded 1st Person View\nDESCRIPTION: This snippet demonstrates how to create a video from a sequence of observations using the `vut.make_video` function. It specifically focuses on creating videos with embedded first-person views and utilizes the rgba_camera sensor.  It shows how to display the agent's point of view within the larger video.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n    # video rendering with embedded 1st person view\n    if make_video:\n        vut.make_video(\n            observations,\n            \"rgba_camera_1stperson\",\n            \"color\",\n            output_path + \"robot_control\",\n            open_vid=show_video,\n        )\n```\n\n----------------------------------------\n\nTITLE: Building Icosphere Primitive Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_Icosphere_prim_attrs` generates a dictionary of attribute properties for the icosphere primitive template (`icosphere_template`).  It builds upon the base primitive attributes from `build_dict_of_prim_attrs` and adds the `subdivisions` property specific to icospheres. Each attribute's value is a tuple containing the attribute's actual value, its editability status, and its type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Icosphere_prim_attrs(icosphere_template):\n    res_dict = build_dict_of_prim_attrs(icosphere_template)\n    res_dict[\"subdivisions\"] = (icosphere_template.subdivisions, True, \"int\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Object Template Handle Selection\nDESCRIPTION: This code snippet allows the user to choose between a file-based or primitive-based object template handle. Based on user selection, the correct object handle will be used. If the selection is invalid, it defaults to file-based. The handles are stored in the variables `obj_template_handle` and `asset_template_handle`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\n# @markdown Choose either the primitive or file-based template recently selected in the dropdown:\nobj_template_handle = sel_file_obj_handle\nasset_template_handle = sel_asset_handle\nobject_type = \"File-based\"  # @param [\"File-based\",\"Primitive-based\"]\nif \"File\" in object_type:\n    # Handle File-based object handle\n    obj_template_handle = sel_file_obj_handle\nelif \"Primitive\" in object_type:\n    # Handle Primitive-based object handle\n    obj_template_handle = sel_prim_obj_handle\nelse:\n    # Unknown - defaults to file-based\n    pass\n```\n\n----------------------------------------\n\nTITLE: Upload All Binaries\nDESCRIPTION: This command uploads all `.tar.bz2` files in the current directory to Anaconda Cloud. It finds all files with the `.tar.bz2` extension and uses `xargs` to pass them to the `anaconda upload` command.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nfind . -name \"*.tar.bz2\" | xargs -I {} anaconda upload {}\n```\n\n----------------------------------------\n\nTITLE: Playing Gfx Replay in Reverse (Habitat-Sim, Python)\nDESCRIPTION: Plays a gfx replay in reverse at a specified speed (skipping frames) by iterating through keyframes in reverse order.  The keyframe index is set, the sensor's transform is retrieved, and observations are collected. The observations can then be used to create a video.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nobservations = []\nprint(\"play in reverse at 3x...\")\nfor frame in range(player.get_num_keyframes() - 2, -1, -3):\n    player.set_keyframe_index(frame)\n    (sensor_node.translation, sensor_node.rotation) = player.get_user_transform(\n        \"sensor\"\n    )\n    observations.append(sim.get_sensor_observations())\n\nif make_video:\n    vut.make_video(\n        observations,\n        \"rgba_camera\",\n        \"color\",\n        output_path + \"replay_playback2\",\n        open_vid=show_video,\n    )\n```\n\n----------------------------------------\n\nTITLE: Configure Test Properties\nDESCRIPTION: This snippet sets the ENVIRONMENT property for several tests (GfxReplayTest, HM3DSceneTest, MetadataMediatorTest, Mp3dTest, NavTest, PhysicsTest, ReplicaSceneTest, ResourceManagerTest, SimTest) to control logging verbosity. It sets HABITAT_SIM_LOG and MAGNUM_LOG to \"quiet\" or \"QUIET\" to reduce output.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_26\n\nLANGUAGE: cmake\nCODE:\n```\nset_tests_properties(\n  GfxReplayTest\n  HM3DSceneTest\n  MetadataMediatorTest\n  Mp3dTest\n  NavTest\n  PhysicsTest\n  ReplicaSceneTest\n  ResourceManagerTest\n  SimTest\n  PROPERTIES ENVIRONMENT \"HABITAT_SIM_LOG=quiet;MAGNUM_LOG=QUIET\"\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Dropdown Widget (Habitat-Sim)\nDESCRIPTION: The `set_handle_ddl_widget` function creates a dropdown widget (`widgets.Dropdown`) with the provided object handles as options. It sets the initial selected handle, a description string, and a style. It also attaches an event handler (`on_change`) to the dropdown. Returns the dropdown and the selected handle.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ndef set_handle_ddl_widget(obj_handles, handle_types, sel_handle, on_change):\n    sel_handle = obj_handles[0]\n    descStr = handle_types + \" Template Handles:\"\n    style = {\"description_width\": \"300px\"}\n    obj_ddl = widgets.Dropdown(\n        options=obj_handles,\n        value=sel_handle,\n        description=descStr,\n        style=style,\n        disabled=False,\n        layout={\"width\": \"max-content\"},\n    )\n\n    obj_ddl.observe(on_change, names=\"value\")\n    return obj_ddl, sel_handle\n```\n\n----------------------------------------\n\nTITLE: Simulator Initialization (Habitat-Sim)\nDESCRIPTION: This snippet initializes the Habitat-Sim simulator with specified settings.  It sets scene to \"none\", sensor pitch to 0.0, override scene light defaults to True, scene_light_setup to empty string. Also, it enables 3rd person camera view. It then calls `make_simulator_from_settings` to create the simulator instance.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nsim_settings = make_default_settings()\nsim_settings[\"scene\"] = \"none\"\nsim_settings[\"sensor_pitch\"] = 0.0\nsim_settings[\"override_scene_light_defaults\"] = True\nsim_settings[\"scene_light_setup\"] = \"\"\n\n# use 3rd person camera\nsim_settings[\"color_sensor_3rd_person\"] = True\n\nmake_simulator_from_settings(sim_settings)\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for Sensor Module\nDESCRIPTION: This CMake snippet sets the source files for the sensor module, including camera, cubemap, generic sensors, and specialized sensors like fisheye and equirectangular sensors, as well as audio sensors. It defines the `sensor_SOURCES` CMake variable.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_16\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  sensor_SOURCES\n  sensor/CameraSensor.cpp\n  sensor/CameraSensor.h\n  sensor/CubeMapSensorBase.cpp\n  sensor/CubeMapSensorBase.h\n  sensor/Sensor.cpp\n  sensor/Sensor.h\n  sensor/SensorFactory.cpp\n  sensor/SensorFactory.h\n  sensor/VisualSensor.cpp\n  sensor/VisualSensor.h\n  sensor/FisheyeSensor.cpp\n  sensor/FisheyeSensor.h\n  sensor/EquirectangularSensor.cpp\n  sensor/EquirectangularSensor.h\n  sensor/AudioSensor.cpp\n  sensor/AudioSensor.h\n  sensor/AudioSensorStubs.h\n)\n```\n\n----------------------------------------\n\nTITLE: Kinematic Object Update in Habitat-Sim (Python)\nDESCRIPTION: This code demonstrates how to directly update the state (translation) of a kinematic object before each simulation step.  This allows for synchronizing the object's state to external data such as a dataset trajectory or motion capture data.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/managed-rigid-object-tutorial.rst#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# [kinematic_update]\nnew_can_pos = [0.75, 0.5, 0.5]\n\nfor _ in range(100):\n    new_can_pos[2] += 0.001\n    can_object.translation = new_can_pos\n    for box in boxes:\n        box.apply_force(anti_grav_force, np.array([0, 0, 0]))\n        box.apply_torque(np.array([rotation_speed, rotation_speed, rotation_speed]))\n    sim.step_physics(1 / 60.0)\n# [/kinematic_update]\n```\n\n----------------------------------------\n\nTITLE: Camera Tracking Simulation and Video Creation\nDESCRIPTION: This snippet executes a camera-tracking simulation, displaying the modified objects, and optionally creates a video of the simulation. It uses `camera_track_simulate` to generate observations, `vut.make_video` to create the video, and `restore_camera_track_config` to reset the camera position. It depends on the `vut` module for video creation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nexample_type = \"Adding edited objects\"\n# Run camera-tracking simulation displaying modified objects\nobservations = camera_track_simulate(sim, objs, dt=3.0)\n\nif make_video:\n    vut.make_video(\n        observations,\n        \"color_sensor_1st_person\",\n        \"color\",\n        output_path + example_type,\n        open_vid=show_video,\n    )\n\n# restore camera tracking position for future cells\nrestore_camera_track_config(sim, init_config)\nmake_clear_all_objects_button()\n```\n\n----------------------------------------\n\nTITLE: Simulating Physics Steps (Habitat-Sim)\nDESCRIPTION: The `simulate` function simulates the physics of a Habitat-Sim environment for a specified duration. It takes the simulator instance `sim`, the simulation time `dt`, and a flag `get_frames` as input. It simulates at 60Hz and appends sensor observations to a list, which is returned.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef simulate(sim, dt=1.0, get_frames=True):\n    # simulate dt seconds at 60Hz to the nearest fixed timestep\n    print(\"Simulating {:.3f} world seconds.\".format(dt))\n    observations = []\n    start_time = sim.get_world_time()\n    while sim.get_world_time() < start_time + dt:\n        sim.step_physics(1.0 / 60.0)\n        if get_frames:\n            observations.append(sim.get_sensor_observations())\n    return observations\n```\n\n----------------------------------------\n\nTITLE: Finding Magnum Plugins\nDESCRIPTION: This snippet uses the `find_package` command to locate several Magnum plugins required for importing various 3D file formats. The `REQUIRED` keyword ensures that the build process will fail if these plugins are not found.  These plugins are crucial for loading different types of assets into the replayer application.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/replayer/CMakeLists.txt#_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(\n  MagnumPlugins\n  REQUIRED\n  BasisImporter\n  GltfImporter\n  KtxImporter\n  StanfordImporter\n  StbImageImporter\n  StbImageConverter\n  UfbxImporter\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Template Properties from Dictionary (Habitat-Sim)\nDESCRIPTION: The `set_template_properties_from_dict` function sets the attributes of a template object based on a provided dictionary. It iterates through the dictionary's key-value pairs and uses `setattr` to assign the value (first element of the value which assumed to be a list or tuple) to the corresponding attribute of the template. The modified template is then returned.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef set_template_properties_from_dict(template, template_dict):\n    for k, v in template_dict.items():\n        setattr(template, k, v[0])\n    return template\n```\n\n----------------------------------------\n\nTITLE: Setting Conditional Build Variables\nDESCRIPTION: This section conditionally sets build variables based on other CMake options. For example, if `BUILD_ASSIMP_SUPPORT` is enabled, `ESP_BUILD_ASSIMP_SUPPORT` is set to `ON`. This pattern is repeated for other features like audio, background renderer, Bullet physics, and CUDA.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_ASSIMP_SUPPORT)\n  set(ESP_BUILD_ASSIMP_SUPPORT ON)\nendif()\n\nif(BUILD_WITH_AUDIO)\n  set(ESP_BUILD_WITH_AUDIO ON)\nendif()\n\nif(BUILD_WITH_BACKGROUND_RENDERER)\n  set(ESP_BUILD_WITH_BACKGROUND_RENDERER ON)\nendif()\n\nif(BUILD_WITH_BULLET)\n  set(ESP_BUILD_WITH_BULLET ON)\nendif()\n\nif(BUILD_WITH_CUDA)\n  set(ESP_BUILD_WITH_CUDA ON)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Displaying Template Properties in Python\nDESCRIPTION: This function displays the properties of a given template. It first builds a dictionary of the template's attributes using `build_dict_from_template`. It then iterates through the dictionary and prints each attribute's name, value, type, and editability status.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef show_template_properties(template):\n    template_dict = build_dict_from_template(template)\n    print(\"Template {} has : \".format(template.handle))\n    for k, v in template_dict.items():\n        print(\n            \"\\tProperty {} has value {} of type {} that is editable : {}\".format(\n                k, v[0], v[2], v[1]\n            )\n        )\n```\n\n----------------------------------------\n\nTITLE: Add Subdirectories\nDESCRIPTION: These snippets add subdirectories to the build process. They specify which parts of the project to build based on the enabled build options, such as the core `esp` library, Python bindings, image converter, tests, GUI viewer, and replayer.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_13\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(esp)\n\nif(BUILD_PYTHON_BINDINGS)\n  message(\"Building Python bindings\")\n  add_subdirectory(esp/bindings)\nendif()\n\n# Build the following with the build RPath\nset(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE)\n\nif(BUILD_BASIS_COMPRESSOR)\n  add_subdirectory(utils/imageconverter)\nendif()\n\nif(BUILD_TEST)\n  add_subdirectory(tests)\nendif()\n\n# pybind bindings\nif(BUILD_GUI_VIEWERS)\n  message(\"Building GUI viewer\")\n  add_subdirectory(utils/viewer)\n  add_subdirectory(utils/replayer)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for Assets Module\nDESCRIPTION: This snippet defines a list of source files (`assets_SOURCES`) for the `assets` module using the `set` command. The list includes both `.cpp` and `.h` files. It also appends the PbrIBlImageResources.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_9\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  assets_SOURCES\n  assets/Asset.cpp\n  assets/Asset.h\n  assets/BaseMesh.cpp\n  assets/BaseMesh.h\n  assets/CollisionMeshData.h\n  assets/GenericSemanticMeshData.cpp\n  assets/GenericSemanticMeshData.h\n  assets/GenericMeshData.cpp\n  assets/GenericMeshData.h\n  assets/MeshData.h\n  assets/MeshMetaData.h\n  assets/RenderAssetInstanceCreationInfo.cpp\n  assets/RenderAssetInstanceCreationInfo.h\n  assets/ResourceManager.cpp\n  assets/ResourceManager.h\n  assets/RigManager.cpp\n  assets/RigManager.h\n  ${PbrIBlImageResources}\n)\n```\n\n----------------------------------------\n\nTITLE: Building Cone Primitive Attributes Dictionary in Habitat-Sim\nDESCRIPTION: The function `build_dict_of_Cone_prim_attrs` generates a dictionary of attribute properties for the cone primitive template (`cone_template`). It extends the base primitive attributes using `build_dict_of_prim_attrs` and includes the property to enable or disable the cap end.  The values are tuples containing the value, editability, and data type.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Cone_prim_attrs(cone_template):\n    res_dict = build_dict_of_prim_attrs(cone_template)\n    res_dict[\"use_cap_end\"] = (cone_template.use_cap_end, True, \"boolean\")\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Building Cube Attributes Dictionary in Python\nDESCRIPTION: This function builds a dictionary of attributes for a Cube primitive in Habitat-Sim. It takes a `cube_template` as input and retrieves the base attributes using `build_dict_of_prim_attrs`. It returns a dictionary where each attribute is mapped to a tuple containing its value, editability (True), and type (obtained from the base attributes).\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef build_dict_of_Cube_prim_attrs(cube_template):\n    res_dict = build_dict_of_prim_attrs(cube_template)\n    return res_dict\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading NavMesh in Habitat-Sim (Python)\nDESCRIPTION: This code snippet shows how to save an existing NavMesh to a file using `Pathfinder.save_nav_mesh(filename)` and then load it back using `Pathfinder.load_nav_mesh(filename)`. It requires an initialized `sim` object and a valid path to save the NavMesh.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# @markdown An existing NavMesh can be saved with *Pathfinder.save_nav_mesh(filename)*\nif sim.pathfinder.is_loaded:\n    navmesh_save_path = os.path.join(data_path, \"test_saving.navmesh\") #@param {type:\"string\"}\n    sim.pathfinder.save_nav_mesh(navmesh_save_path)\n    print('Saved NavMesh to \"' + navmesh_save_path + '\"')\n    sim.pathfinder.load_nav_mesh(navmesh_save_path)\n```\n\n----------------------------------------\n\nTITLE: Articulated Object Configuration JSON Example\nDESCRIPTION: This snippet provides an example of an ArticulatedObjectAttributes configuration file in JSON format.  It demonstrates how to specify the URDF filepath, render asset, scaling factors, and other rendering and physical properties for an articulated object. It is used for instancing articulated objects into Habitat-Sim via URDF files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/attributesJSON.rst#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n.. include:: ../../data/test_assets/urdf/skinned_prism.ao_config.json\n    :code: json\n```\n\n----------------------------------------\n\nTITLE: Copying Audio Library (Post-Build)\nDESCRIPTION: This snippet adds a custom command to copy the audio propagation library after the `habitat_sim_bindings` target is built. This ensures that the audio library is available in the same directory as the bindings. This command is conditional on `BUILD_WITH_AUDIO`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/bindings/CMakeLists.txt#_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_WITH_AUDIO)\n  add_custom_command(\n    TARGET habitat_sim_bindings POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different ${RLRAudioPropagation_LIBRARY}\n            $<TARGET_FILE_DIR:habitat_sim_bindings>\n  )\nendif()\n```\n\n----------------------------------------\n\nTITLE: PathFinder Try Step Function\nDESCRIPTION: Describes the `habitat_sim.nav.PathFinder.try_step` function, which attempts to move an agent from a start to an end location and returns the closest navigable point reachable from the start. If no such location exists, it returns ``{NAN, NAN, NAN}``.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.nav.PathFinder.try_step\n```\n\n----------------------------------------\n\nTITLE: Downloading Habitat Test Scenes with Python\nDESCRIPTION: This code snippet demonstrates how to download Habitat test scenes using the `habitat_sim.utils.datasets_download` module. It utilizes the `--uids` argument to specify the `habitat_test_scenes` dataset and the `--data-path` argument to specify the destination directory as `data/`. This is useful for downloading minimal test scenes for fast experimentation and unit testing.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\npython -m habitat_sim.utils.datasets_download --uids habitat_test_scenes --data-path data/\n```\n\n----------------------------------------\n\nTITLE: Applying RedwoodDepthNoiseModel to Sensor\nDESCRIPTION: This snippet demonstrates how to apply the `RedwoodDepthNoiseModel` to a sensor in habitat-sim. It sets the `noise_model` field of the `sensor.SensorSpec` to \"RedwoodDepthNoiseModel\" and provides a `noise_multiplier` of 5 as a keyword argument to the noise model constructor via the `sensor.SensorSpec.noise_model_kwargs` field. This configuration adjusts the amount of noise applied by the model.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/noise_models.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nsensor_spec.noise_model = \"RedwoodDepthNoiseModel\"\nsensor_spec.noise_model_kwargs = dict(noise_multiplier=5)\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for Core Module\nDESCRIPTION: This snippet defines a list of source files (`core_SOURCES`) for the `core` module using the `set` command. The list includes both `.cpp` and `.h` files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  core_SOURCES\n  core/Buffer.cpp\n  core/Buffer.h\n  core/Check.cpp\n  core/Check.h\n  core/Configuration.cpp\n  core/Configuration.h\n  core/Esp.cpp\n  core/Esp.h\n  core/Logging.cpp\n  core/Logging.h\n  core/managedContainers/AbstractFileBasedManagedObject.h\n  core/managedContainers/AbstractManagedObject.h\n  core/managedContainers/ManagedContainer.h\n  core/managedContainers/ManagedContainerBase.cpp\n  core/managedContainers/ManagedContainerBase.h\n  core/managedContainers/ManagedFileBasedContainer.h\n  core/Random.h\n  core/Spimpl.h\n  core/Utility.h\n)\n```\n\n----------------------------------------\n\nTITLE: Simulating and Creating Video\nDESCRIPTION: This snippet simulates the environment for a specified duration (dt=3.0), collects observations, and optionally creates a video from the observations using the `vut.make_video` function if `make_video` is True. Finally, all objects are removed from the scene.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nexample_type = \"trajectory prediction\"\nobservations = simulate(sim, dt=3.0)\nif make_video:\n    vut.make_video(\n        observations,\n        \"color_sensor_1st_person\",\n        \"color\",\n        output_path + example_type,\n        open_vid=show_video,\n    )\nrigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Video Rendering and Cleanup\nDESCRIPTION: This snippet renders the video from the captured observations and resets the sensor to its initial state.  It also removes all added objects from the scene to clean up the environment.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_33\n\nLANGUAGE: python\nCODE:\n```\n    # video rendering of carousel view\n    video_prefix = clip_short_name + \"_scene_view\"\n    if make_video:\n        vut.make_video(\n            observations,\n            \"color_sensor_3rd_person\",\n            \"color\",\n            output_path + video_prefix,\n            open_vid=show_video,\n            video_dims=[1280, 720],\n        )\n\n    # reset the sensor state for other examples\n    visual_sensor._spec.position = initial_sensor_position\n    visual_sensor._spec.orientation = initial_sensor_orientation\n    visual_sensor._sensor_object.set_transformation_from_spec()\n\n    # remove added objects\n    rigid_obj_mgr.remove_all_objects()\n```\n\n----------------------------------------\n\nTITLE: Visualize ReplicaCAD Scene Coordinate Frame\nDESCRIPTION: This code loads a ReplicaCAD scene into the Habitat simulator and visualizes the world coordinate frame. It initializes the simulator with a specific ReplicaCAD scene file, draws the world axes at the origin, and renders the scene from a set camera position, reinforcing the world coordinate frame's location and orientation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/coordinate_frame_tutorial.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncreate_sim_helper(\n    scene_id=os.path.join(\n        data_path, \"replica_cad/configs/scenes/v3_sc0_staging_00.scene_instance.json\"\n    )\n)\ndraw_axes(origin)\nshow_scene(calc_camera_transform(eye_translation=eye_pos0, lookat=origin))\n```\n\n----------------------------------------\n\nTITLE: Building Widget UI for Target Object Selection\nDESCRIPTION: This snippet calls the function `build_widget_ui` to create a user interface for selecting a target object. It utilizes the object attribute manager (`obj_attr_mgr`) and the primitive attribute manager (`prim_attr_mgr`) to build the UI elements for object selection. This allows users to interactively choose a target object for the navigation task.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n# @title Select target object from the GUI: { display-mode: \"form\" }\n\nbuild_widget_ui(obj_attr_mgr, prim_attr_mgr)\n```\n\n----------------------------------------\n\nTITLE: Downloading YCB Dataset using dataset_downloader utility\nDESCRIPTION: This snippet demonstrates how to download the YCB dataset using the `dataset_downloader` utility provided with Habitat-Sim.  The `--uids ycb` flag specifies the YCB dataset, and `--data-path` specifies the directory where the data should be downloaded. Two methods are shown: one for conda installations and one for source installations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# with conda install\npython -m habitat_sim.utils.datasets_download --uids ycb --data-path /path/to/data/\n\n# with source\npython /path/to/habitat_sim/src_python/habitat_sim/utils/datasets_download.py --uids ycb --data-path /path/to/data/\n```\n\n----------------------------------------\n\nTITLE: Setting source files for gfx_batch library\nDESCRIPTION: This snippet defines the source files that will be compiled into the gfx_batch library. It includes both C++ source files (.cpp) and header files (.h) related to depth unprojection, rendering, and HBAO (Horizon-Based Ambient Occlusion).\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/gfx_batch/CMakeLists.txt#_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  gfx_batch_SOURCES\n  DepthUnprojection.cpp\n  DepthUnprojection.h\n  Renderer.cpp\n  Renderer.h\n  RendererStandalone.cpp\n  RendererStandalone.h\n  Hbao.cpp\n  Hbao.h\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for Simulation Module\nDESCRIPTION: Defines the source files for the `sim` module, including classes for replay rendering, batch players, and the core simulator.  It sets the CMake variable `sim_SOURCES` to the list of files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_18\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  sim_SOURCES\n  sim/AbstractReplayRenderer.cpp\n  sim/AbstractReplayRenderer.h\n  sim/BatchPlayerImplementation.cpp\n  sim/BatchPlayerImplementation.h\n  sim/BatchReplayRenderer.cpp\n  sim/BatchReplayRenderer.h\n  sim/ClassicReplayRenderer.cpp\n  sim/ClassicReplayRenderer.h\n  sim/Simulator.cpp\n  sim/Simulator.h\n  sim/SimulatorConfiguration.cpp\n  sim/SimulatorConfiguration.h\n  sim/RenderInstanceHelper.cpp\n  sim/RenderInstanceHelper.h\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Range from Center and Half-Extent\nDESCRIPTION: This snippet creates a 3D range (bounding box) using the Magnum library (mn). It defines the center and half-extent vectors to specify the dimensions and position of the range in the scene. This range is later used for sampling object states within its boundaries.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ntarget_zone = mn.Range3D.from_center(\n    mn.Vector3(-2.07496, 1.07245, -0.2894), mn.Vector3(0.5, 0.05, 0.1)\n)\n```\n\n----------------------------------------\n\nTITLE: Orientation Correction and Template Registration\nDESCRIPTION: This snippet handles optional orientation correction for the loaded object and registers the object template with the object attribute manager. The orientation correction is useful if the asset is displayed sideways, and the registration makes the template available for object instantiation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_29\n\nLANGUAGE: python\nCODE:\n```\n    # @markdown If the asset being displayed is on its side, enable orientation_correction below :\n    orientation_correction = False  # @param {type: \"boolean\"}\n    # This will correct the orientation (Dependent on PR : )\n    if orientation_correction:\n        object_template.orient_up = (0.0, 0.0, 1.0)\n        object_template.orient_front = (0.0, 1.0, 0.0)\n\n    # modify template here if desired and then register it\n    obj_temp_id = obj_attr_mgr.register_template(object_template)\n```\n\n----------------------------------------\n\nTITLE: Setting Agent State in Habitat-Sim (Python)\nDESCRIPTION: This snippet initializes the agent and sets its initial state (position) within the Habitat-Sim environment. It uses the `sim_settings` for the seed and agent information. It requires the `habitat_sim` and `numpy` libraries.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# the randomness is needed when choosing the actions\nrandom.seed(sim_settings[\"seed\"])\nsim.seed(sim_settings[\"seed\"])\n\n# Set agent state\nagent = sim.initialize_agent(sim_settings[\"default_agent\"])\nagent_state = habitat_sim.AgentState()\nagent_state.position = np.array([-0.6, 0.0, 0.0])  # world space\nagent.set_state(agent_state)\n\n# Get agent state\nagent_state = agent.get_state()\nprint(\"agent_state: position\", agent_state.position, \"rotation\", agent_state.rotation)\n```\n\n----------------------------------------\n\nTITLE: Adding and Setting Object State\nDESCRIPTION: This code snippet adds an object to the scene using a template handle and then sets its state (position and orientation) relative to the agent. It uses `rigid_obj_mgr.add_object_by_template_handle` to instantiate the object and `set_object_state_from_agent` to place it in the environment.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\n# Add object instantiated by desired template using template handle\nobj_1 = rigid_obj_mgr.add_object_by_template_handle(obj_template_handle)\n\n# @markdown Note: agent local coordinate system is Y up and -Z forward.\n# Move object to be in front of the agent\nset_object_state_from_agent(sim, obj_1, offset=offset, orientation=orientation)\n```\n\n----------------------------------------\n\nTITLE: Registering a Control Functor as Body Action in Habitat-Sim (Python)\nDESCRIPTION: This snippet demonstrates how to register a custom control functor `MyNewControl` as a body action in Habitat-Sim using the `@habitat_sim.registry.register_move_fn` decorator. The `body_action=True` argument specifies that this action moves the entire agent body. This control requires the `habitat_sim` library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/new-actions.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport habitat_sim\n\n@habitat_sim.registry.register_move_fn(body_action=True)\nclass MyNewControl(habitat_sim.SceneNodeControl):\n    pass\n```\n\n----------------------------------------\n\nTITLE: Placing the Agent in Habitat Sim\nDESCRIPTION: This function places the agent within the simulation environment at a specified position and rotation. It initializes the agent's state, sets the position and rotation, and then initializes the agent within the simulator. It returns the agent's transformation matrix.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef place_agent(sim):\n    # place our agent in the scene\n    agent_state = habitat_sim.AgentState()\n    agent_state.position = [-0.15, -0.7, 1.0]\n    agent_state.rotation = np.quaternion(-0.83147, 0, 0.55557, 0)\n    agent = sim.initialize_agent(0, agent_state)\n    return agent.scene_node.transformation_matrix()\n```\n\n----------------------------------------\n\nTITLE: Removing Objects and Simulating\nDESCRIPTION: Removes specified objects (chefcan) from the scene and continues the simulation after their removal. Removes objects using the rigid object manager and then simulates agent movement using the `simulate_with_moving_agent` function.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nrigid_obj_mgr.remove_object_by_id(chefcan_1.object_id)\nrigid_obj_mgr.remove_object_by_id(chefcan_2.object_id)\n\nobservations += simulate_with_moving_agent(\n    sim,\n    duration=2.0,\n    agent_vel=np.array([0.4, 0.0, 0.0]),\n    look_rotation_vel=-10.0,\n    get_frames=make_video_during_sim,\n)\n```\n\n----------------------------------------\n\nTITLE: Sensor Adjustment and Observation Creation\nDESCRIPTION: This snippet adjusts the sensor position and orientation based on the agent's state and object size. It then creates an empty list to store observations that will be captured during the simulation loop.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_31\n\nLANGUAGE: python\nCODE:\n```\n    # set the sensor to be behind and above the agent's initial loc\n    # distance is scaled by size of largest object dimension\n    visual_sensor._spec.position = agent_state.position + sensor_pos\n    visual_sensor._spec.orientation = mn.Vector3(-0.5, 0.0, 0.0)\n    visual_sensor._sensor_object.set_transformation_from_spec()\n\n    # Create observations array\n    observations = []\n```\n\n----------------------------------------\n\nTITLE: Specifying Object Path (Habitat-Sim)\nDESCRIPTION: This snippet defines the path to the object to be viewed in the simulator. It retrieves the path from a `object_to_view_path` variable, which is set using a notebook parameter (indicated by `# @param {type:\"string\"}`). The short name of the clip is derived from the provided object path.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nobject_to_view_path = os.path.join(data_path, \"test_assets/scenes/simple_room.glb\")  # @param {type:\"string\"}\n\n# this is the name to save the resultant video with\nclip_short_name = object_to_view_path.split(\"/\")[-1].split(\".\")[0]\n```\n\n----------------------------------------\n\nTITLE: Converting 3DSceneGraph to Gibson Semantics with Bash\nDESCRIPTION: This bash script converts semantic information from the 3DSceneGraph dataset to a format compatible with the Gibson dataset. It requires specifying the paths to the 3DSceneGraph data, the Gibson dataset, and the output directory.  The output of this script will be semantic information that can be used in Habitat.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_8\n\nLANGUAGE: Bash\nCODE:\n```\ntools/gen_gibson_semantics.sh /path/to/3DSceneGraph_medium/automated_graph /path/to/GibsonDataset /path/to/output\n```\n\n----------------------------------------\n\nTITLE: Conditional Inclusion of Audio Propagation Library\nDESCRIPTION: This snippet conditionally includes the audio propagation library based on the `BUILD_WITH_AUDIO` flag. If the flag is set, it includes the necessary header directories and links the `RLRAudioPropagation_LIBRARY` to the `habitat_sim` target.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_23\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_WITH_AUDIO)\n  include_directories(${DEPS_DIR}/rlr-audio-propagation/RLRAudioPropagationPkg/headers)\n  target_link_libraries(habitat_sim PUBLIC ${RLRAudioPropagation_LIBRARY})\nendif()\n```\n\n----------------------------------------\n\nTITLE: Finding Magnum and GlfwApplication Packages\nDESCRIPTION: This snippet uses the `find_package` command in CMake to locate the Magnum graphics engine and the GlfwApplication package. The `REQUIRED` keyword ensures that the build process will fail if these packages are not found. It is a prerequisite for using Magnum functionalities.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/replayer/CMakeLists.txt#_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(Magnum REQUIRED GlfwApplication)\n```\n\n----------------------------------------\n\nTITLE: GLSL Shader Code Fragment\nDESCRIPTION: This is a fragment of GLSL shader code. It is difficult to determine its exact functionality without more context, but it appears to be manipulating values and performing calculations within a shader program.  The code is likely incomplete and depends on other parts of the shader for complete functionality.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_26\n\nLANGUAGE: GLSL\nCODE:\n```\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\n```\n\n----------------------------------------\n\nTITLE: Visualize Empty Scene Coordinate Frame\nDESCRIPTION: This snippet demonstrates the world coordinate frame in an empty Habitat scene. It initializes the simulator with no scene, draws the world axes at the origin (x=red, y=green, z=blue), and displays the scene from a specified camera position. This highlights Habitat's y-up and right-handed coordinate system.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/coordinate_frame_tutorial.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ncreate_sim_helper(scene_id=\"NONE\")\ndraw_axes(origin)\nshow_scene(calc_camera_transform(eye_translation=eye_pos0, lookat=origin))\n```\n\n----------------------------------------\n\nTITLE: Conditional Inclusion of CUDA Noise Model Sources\nDESCRIPTION: Conditionally appends Redwood noise model related source files to `sensor_SOURCES` and creates a separate CUDA target, `noise_model_SOURCES`, when `BUILD_WITH_CUDA` is enabled.  It also configures compile features and links CUDA runtime libraries.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_17\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_WITH_CUDA)\n  list(APPEND sensor_SOURCES sensor/RedwoodNoiseModel.cpp sensor/RedwoodNoiseModel.h)\n  # CUDA kernel sources\n  set(noise_model_SOURCES sensor/RedwoodNoiseModel.cu sensor/RedwoodNoiseModel.cuh)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Agent and Sensor Placement\nDESCRIPTION: Sets the initial translation and rotation for the agent and sensor nodes within the simulation environment.  Defines the initial position and orientation of the agent and camera.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nagent_node = sim.get_agent(0).body.object\nsensor_node = sim._sensors[\"rgba_camera\"]._sensor_object.object\n\n# initial agent transform\nagent_node.translation = [-0.15, -1.5, 1.0]\nagent_node.rotation = mn.Quaternion.rotation(mn.Deg(-75), mn.Vector3(0.0, 1.0, 0))\n\n# initial sensor local transform (relative to agent)\nsensor_node.translation = [0.0, 0.6, 0.0]\nsensor_node.rotation = mn.Quaternion.rotation(mn.Deg(-15), mn.Vector3(1.0, 0.0, 0))\n```\n\n----------------------------------------\n\nTITLE: Add Sim Test Target\nDESCRIPTION: Adds a test executable SimTest, links it with habitat_sim, Magnum and several Magnum importers (Gltf, Stb, and Ufbx). The target_include_directories command sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_25\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  SimTest\n  SimTest.cpp\n  LIBRARIES\n  habitat_sim\n  Magnum::DebugTools\n  Magnum::AnyImageConverter\n  MagnumPlugins::GltfImporter\n  MagnumPlugins::StbImageImporter\n  MagnumPlugins::StbImageConverter\n  MagnumPlugins::UfbxImporter\n)\ntarget_include_directories(SimTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Import Libraries for Habitat Simulation\nDESCRIPTION: This snippet imports necessary libraries for Habitat simulation, including `os`, `git`, `magnum`, `PIL`, and `habitat_sim`. It also checks if the code is running within a Jupyter Notebook environment to conditionally import `IPython.display`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/coordinate_frame_tutorial.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport git\nimport magnum as mn\nfrom PIL import Image\n\nimport habitat_sim\n\ntry:\n    # For using jupyter IO components\n    import IPython.display\n\n    IS_NOTEBOOK = True\n\nexcept ImportError:\n    IS_NOTEBOOK = False\n```\n\n----------------------------------------\n\nTITLE: Building Widget UI for Object Selection\nDESCRIPTION: This snippet calls the function `build_widget_ui` to create a user interface for selecting objects, using the object attribute manager (`obj_attr_mgr`) and the primitive attribute manager (`prim_attr_mgr`). This allows users to interactively choose objects to be placed in the scene.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n# @title Select clutter object from the GUI: { display-mode: \"form\" }\n\nbuild_widget_ui(obj_attr_mgr, prim_attr_mgr)\n```\n\n----------------------------------------\n\nTITLE: Add ResourceManager Test Target\nDESCRIPTION: Adds a test executable ResourceManagerTest, links it with habitat_sim and Magnum importers (Basis, Gltf, and Ufbx). The target_include_directories command sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_21\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  ResourceManagerTest\n  ResourceManagerTest.cpp\n  LIBRARIES\n  habitat_sim\n  MagnumPlugins::BasisImporter\n  MagnumPlugins::GltfImporter\n  MagnumPlugins::UfbxImporter\n)\ntarget_include_directories(ResourceManagerTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Setting Viewer Source Files\nDESCRIPTION: This snippet sets the source files for the viewer executable. It defines the `viewer_SOURCES` variable to include the main viewer.cpp file, ObjectPickingHelper.cpp, and ObjectPickingHelper.h.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/viewer/CMakeLists.txt#_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nset(viewer_SOURCES viewer.cpp ObjectPickingHelper.cpp ObjectPickingHelper.h)\n```\n\n----------------------------------------\n\nTITLE: Simulate Agent Movement and Capture Observations\nDESCRIPTION: Simulates the agent's movement within the scene for a specified duration, capturing observations during the simulation.  Uses the `simulate_with_moving_agent` function to move the agent and record the resulting frames.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nobservations = []\n\n# simulate with empty scene\nobservations += simulate_with_moving_agent(\n    sim,\n    duration=1.0,\n    agent_vel=np.array([0.5, 0.0, 0.0]),\n    look_rotation_vel=25.0,\n    get_frames=make_video_during_sim,\n)\n```\n\n----------------------------------------\n\nTITLE: Running Habitat Viewer C++\nDESCRIPTION: This command runs the Habitat-Sim interactive viewer in C++ to visualize a specified scene. It requires the path to the scene file (`/path/to/data/scene_datasets/habitat-test-scenes/skokloster-castle.glb`) and assumes the viewer executable is located at `./build/viewer` or `habitat-viewer`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n#C++\n# ./build/viewer if compiling locally\nhabitat-viewer /path/to/data/scene_datasets/habitat-test-scenes/skokloster-castle.glb\n```\n\n----------------------------------------\n\nTITLE: Adding tinyxml2 Static Library using CMake\nDESCRIPTION: This CMake command defines a static library named 'tinyxml2'. It specifies the header file 'tinyxml2.h' and the source file 'tinyxml2.cpp' as inputs for building the library. The library will be statically linked into any target that depends on it.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/deps/tinyxml2/CMakeLists.txt#_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_library(tinyxml2 STATIC\n  tinyxml2.h\n  tinyxml2.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Object with Default Lighting in Habitat-Sim (Python)\nDESCRIPTION: This snippet adds a new object to the scene using the default lighting setup. The object is loaded from a glTF file and positioned in the scene.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_5\n\nLANGUAGE: py\nCODE:\n```\n# [example 2]\ncube_handle = sim.load_object(os.path.join(habitat_sim.sim.kTestAssetsDir, \"objects/cube.glb\"))\n\ntrans = habitat_sim.utils.common.quat_from_coeffs([1, 0, 0, 0])\nsim.set_translation(np.array([1.5, 0.0, 0.5]), cube_handle)\nsim.set_rotation(trans, cube_handle)\n# [/example 2]\n```\n\n----------------------------------------\n\nTITLE: Reconfigure Simulator for Playback\nDESCRIPTION: Reconfigures the simulator for gfx replay playback. Closes the current simulator instance, then reconfigures it using `gfx_replay_utils.make_backend_configuration_for_playback`. Initializes the agent.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nsim.close()\n\n# use same agents/sensors from earlier, with different backend config\nplayback_cfg = habitat_sim.Configuration(\n    gfx_replay_utils.make_backend_configuration_for_playback(\n        need_separate_semantic_scene_graph=False\n    ),\n    cfg.agents,\n)\n\nif not sim:\n    sim = habitat_sim.Simulator(playback_cfg)\nelse:\n    sim.reconfigure(playback_cfg)\n\nconfigure_lighting(sim)\n\nagent_state = habitat_sim.AgentState()\nsim.initialize_agent(0, agent_state)\n\nagent_node = sim.get_agent(0).body.object\nsensor_node = sim._sensors[\"rgba_camera\"]._sensor_object.object\n```\n\n----------------------------------------\n\nTITLE: Installing Doxygen and Docutils\nDESCRIPTION: This command installs Doxygen (version 1.8.16), Jinja2, Pygments, and Docutils using conda. Doxygen is used for generating documentation from code comments, while Jinja2, Pygments, and Docutils are used for styling and formatting the documentation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c conda-forge doxygen==1.8.16\nconda install jinja2 pygments docutils\n```\n\n----------------------------------------\n\nTITLE: PIP Install Habitat-Sim\nDESCRIPTION: This snippet demonstrates how to install Habitat-Sim using PIP. It clones the repository, navigates into the directory, and then uses pip to install the package. This method is automated but less recommended for active development due to caching limitations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone --branch stable https://github.com/facebookresearch/habitat-sim.git\ncd habitat-sim\npip install . -v\n```\n\n----------------------------------------\n\nTITLE: JavaScript Data Processing/Manipulation\nDESCRIPTION: This snippet contains JavaScript code that manipulates data, possibly for use in updating the SVG graphic. It involves mathematical operations and assignments to variables, suggesting the calculation or transformation of data points to be rendered or animated within the SVG.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_29\n\nLANGUAGE: JavaScript\nCODE:\n```\ne = (e + 1) % 256\n```\n\n----------------------------------------\n\nTITLE: Converting PLY to GLB with assimp\nDESCRIPTION: This snippet shows how to convert a ScanNet scene from PLY format to GLB format using the assimp tool.  The GLB format is required for use with Habitat-Sim versions >= 2.0. It assumes assimp is installed and accessible in the command line.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nassimp export <PLY FILE> <GLB PATH>\n```\n\n----------------------------------------\n\nTITLE: Install Habitat-Sim (Audio Sensor)\nDESCRIPTION: This snippet installs Habitat-Sim with audio sensor support by passing the `--audio` flag to `setup.py`.  This enables audio sensor capabilities within the simulator, and is only available on Linux.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython setup.py install --audio    # build habitat with audio sensor\n```\n\n----------------------------------------\n\nTITLE: Create Simulator Instance\nDESCRIPTION: This snippet creates an instance of the Habitat-sim simulator using the configuration generated by `make_simple_cfg`. It handles potential `NameError` exceptions that may occur in Jupyter notebooks due to out-of-order cell execution by closing the simulator if it exists.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntry:  # Needed to handle out of order cell run in Jupyter\n    sim.close()\nexcept NameError:\n    pass\nsim = habitat_sim.Simulator(cfg)\n```\n\n----------------------------------------\n\nTITLE: Add Culling Test Target\nDESCRIPTION: This snippet adds a test executable CullingTest, links it with habitat_sim and Magnum importers (Gltf and Ufbx). The target_include_directories command sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  CullingTest\n  CullingTest.cpp\n  LIBRARIES\n  habitat_sim\n  MagnumPlugins::GltfImporter\n  MagnumPlugins::UfbxImporter\n)\ntarget_include_directories(CullingTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Downloading Testing 3D Scenes Bash\nDESCRIPTION: This command downloads the testing 3D scenes for Habitat-Sim using the `habitat_sim.utils.datasets_download` utility. It requires the `habitat_test_scenes` UID and specifies the `/path/to/data/` as the destination. Note that these scenes lack semantic annotations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython -m habitat_sim.utils.datasets_download --uids habitat_test_scenes --data-path /path/to/data/\n```\n\n----------------------------------------\n\nTITLE: Add SceneGraph Test Target\nDESCRIPTION: This snippet adds a test executable SceneGraphTest and links it against the habitat_sim library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_22\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(SceneGraphTest SceneGraphTest.cpp LIBRARIES habitat_sim)\n```\n\n----------------------------------------\n\nTITLE: Import dependencies\nDESCRIPTION: Imports necessary modules for the Habitat-Sim Gfx Replay tutorial, including os, git, magnum, numpy, habitat_sim, and utility functions for gfx replay and visualization. Defines paths for data and output.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport git\nimport magnum as mn\nimport numpy as np\n\nimport habitat_sim\nfrom habitat_sim.bindings import built_with_bullet\nfrom habitat_sim.gfx import LightInfo, LightPositionModel\nfrom habitat_sim.utils import gfx_replay_utils\nfrom habitat_sim.utils import viz_utils as vut\n\nrepo = git.Repo(\".\", search_parent_directories=True)\ndir_path = repo.working_tree_dir\ndata_path = os.path.join(dir_path, \"data\")\noutput_path = os.path.join(dir_path, \"examples/tutorials/replay_tutorial_output/\")\nos.makedirs(output_path, exist_ok=True)\n```\n\n----------------------------------------\n\nTITLE: Navmesh Recomputation in Habitat-Sim\nDESCRIPTION: This snippet recomputes the navigation mesh using the `recompute_navmesh` function.  It is important for updating the navigable space if the environment changes. It depends on `default_nav_mesh_settings` which specifies how the navmesh should be recomputed.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Interactivity.ipynb#_snippet_31\n\nLANGUAGE: Python\nCODE:\n```\nrecompute_successful = sim.recompute_navmesh(sim.pathfinder, default_nav_mesh_settings)\nif not recompute_successful:\n    print(\"Failed to recompute navmesh 2!\")\n```\n\n----------------------------------------\n\nTITLE: Updating Existing Light Setups (Python)\nDESCRIPTION: This snippet demonstrates how updates to existing light setups will update all objects using that setup, allowing control over groups of objects with consistent lighting.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_11\n\nLANGUAGE: py\nCODE:\n```\n# [example 8]\nretrieved_lighting.lights[0].color = np.array([0.9, 0.0, 0.9])\nsim.set_light_setup(retrieved_lighting, \"my_second_lighting_setup\")\n# [/example 8]\n```\n\n----------------------------------------\n\nTITLE: Event Handler for Asset Handle Dropdown Change (Habitat-Sim)\nDESCRIPTION: The `on_prim_ddl_change` function is the event handler for dropdowns displaying asset handles in Habitat-Sim. It updates the global variable `sel_asset_handle` with the new value selected in the dropdown menu, then returns the new value.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndef on_prim_ddl_change(ddl_values):\n    global sel_asset_handle\n    sel_asset_handle = ddl_values[\"new\"]\n    return sel_asset_handle\n```\n\n----------------------------------------\n\nTITLE: Docker Image Build\nDESCRIPTION: This command builds a Docker image named `hsim_condabuild_dcontainer` using the provided `Dockerfile`. The `-t` flag specifies the image name, and the `-f` flag specifies the Dockerfile path.  The `.` indicates the build context is the current directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ndocker build -t hsim_condabuild_dcontainer -f Dockerfile .\n```\n\n----------------------------------------\n\nTITLE: File Not Found Error Handling\nDESCRIPTION: This snippet handles the case where the specified object file does not exist or cannot be found. It prints an error message to the console indicating that the file is missing and aborting the process.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nelse:\n    print(\n        \"\\nChosen File : '{}' does not exist or cannot be found. Aborting.\\n\".format(\n            object_to_view_path\n        )\n    )\n```\n\n----------------------------------------\n\nTITLE: Selecting a Scene Instance in Habitat-sim\nDESCRIPTION: This snippet builds the widget UI to allow the user to select a scene. It calls the `build_widget_ui` function to create and display the interactive scene selection dropdown.  This relies on the `sim` simulator object having been initialized.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ReplicaCAD_quickstart.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nbuild_widget_ui(sim.metadata_mediator)\n```\n\n----------------------------------------\n\nTITLE: Adding Object with Current Default Lighting (Python)\nDESCRIPTION: This snippet adds another cube to the scene, demonstrating that newly added objects will use the current default lighting setup unless otherwise specified.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_7\n\nLANGUAGE: py\nCODE:\n```\n# [example 4]\ncube_handle_2 = sim.load_object(os.path.join(habitat_sim.sim.kTestAssetsDir, \"objects/cube.glb\"))\n\ntrans = habitat_sim.utils.common.quat_from_coeffs([1, 0, 0, 0])\nsim.set_translation(np.array([2.5, 0.0, 0.5]), cube_handle_2)\nsim.set_rotation(trans, cube_handle_2)\n# [/example 4]\n```\n\n----------------------------------------\n\nTITLE: Running Habitat Viewer with Physics Python\nDESCRIPTION: This command launches the Habitat-Sim viewer in Python with physics enabled, using a ReplicaCAD scene. It needs the `--dataset` argument pointing to the scene dataset config JSON and the `--scene` argument specifying the scene to load. `PYTHONPATH` needs to include the path to `habitat-sim`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n#python\n#NOTE: habitat-sim/ directory must be on your `PYTHONPATH`\npython examples/viewer.py --dataset data/replica_cad/replicaCAD.scene_dataset_config.json --scene apt_1\n```\n\n----------------------------------------\n\nTITLE: Cleaning up Simulator in Habitat-Sim (Python)\nDESCRIPTION: This snippet demonstrates the final cleanup by closing the simulator to release resources. It is typically done at the end of a simulation or tutorial.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_3\n\nLANGUAGE: py\nCODE:\n```\n# [scene]\nsim.close()\n# [/scene]\n```\n\n----------------------------------------\n\nTITLE: Creating the gfx_batch static library\nDESCRIPTION: This snippet uses `add_library` to create a static library named gfx_batch from the source files defined in the `gfx_batch_SOURCES` variable.  It also sets include directories for esp/core/configure.h and, if CUDA is enabled, includes CUDA toolkit directories and links the CUDA runtime library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/gfx_batch/CMakeLists.txt#_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nadd_library(\n  gfx_batch STATIC\n  ${gfx_batch_SOURCES}\n)\n# For esp/core/configure.h\n# TODO move configure.h directly to esp/\ntarget_include_directories(gfx_batch PUBLIC ${PROJECT_BINARY_DIR})\nif(BUILD_WITH_CUDA)\n  target_include_directories(\n    gfx_batch PUBLIC ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES}\n                     ${CMAKE_CURRENT_LIST_DIR}/cuda_helpers\n  )\n\n  target_link_libraries(gfx_batch PUBLIC ${CUDART_LIBRARY})\nendif()\n```\n\n----------------------------------------\n\nTITLE: Downloading Example Objects Bash\nDESCRIPTION: This command downloads example objects for Habitat-Sim using the `habitat_sim.utils.datasets_download` utility. It utilizes the `habitat_example_objects` UID and specifies the `/path/to/data/` as the destination directory for the downloaded assets.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython -m habitat_sim.utils.datasets_download --uids habitat_example_objects --data-path /path/to/data/\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for Navigation Module\nDESCRIPTION: Defines the source files for the navigation module, which includes path planning and navigation functionalities like greedy following and path finding. The source files are assigned to the `nav_SOURCES` CMake variable.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_15\n\nLANGUAGE: cmake\nCODE:\n```\nset(nav_SOURCES\n  nav/GreedyFollower.cpp\n  nav/GreedyFollower.h\n  nav/PathFinder.cpp\n  nav/PathFinder.h\n)\n```\n\n----------------------------------------\n\nTITLE: Render Observations to Video\nDESCRIPTION: Renders the collected observations into a video file, if the `make_video_during_sim` flag is enabled. Uses `vut.make_video` to generate the video from the observations.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nif make_video_during_sim:\n    vut.make_video(\n        observations,\n        \"rgba_camera\",\n        \"color\",\n        output_path + \"episode\",\n        open_vid=show_video,\n    )\n```\n\n----------------------------------------\n\nTITLE: Serialize Habitat-Sim Build Process\nDESCRIPTION: This snippet serializes the Habitat-Sim build process to prevent running out of memory on virtual machines. It achieves this by using the `--parallel 1` flag during the build_ext phase, which limits the build to using a single core.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npython setup.py build_ext --parallel 1 install\n```\n\n----------------------------------------\n\nTITLE: Writing Python Path File (Commented Out)\nDESCRIPTION: This commented-out snippet shows how to write a Python file that defines the library path. This is used to help Python find the compiled library. This functionality is currently disabled.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/bindings/CMakeLists.txt#_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\n# file(WRITE ${PYTHON_ROOT}/libpath.py \"LIB_PATH='${CMAKE_CURRENT_BINARY_DIR}'\\n\")\n```\n\n----------------------------------------\n\nTITLE: Setting Button Launcher (Habitat-Sim)\nDESCRIPTION: The `set_button_launcher` function creates a `widgets.Button` with the given description and layout settings (specifically, setting the width to 'max-content'). It simply constructs the button and returns it.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/asset_viewer.ipynb#_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndef set_button_launcher(desc):\n    button = widgets.Button(\n        description=desc,\n        layout={\"width\": \"max-content\"},\n    )\n    return button\n```\n\n----------------------------------------\n\nTITLE: Add GibsonScene Test Target\nDESCRIPTION: This snippet adds a test executable GibsonSceneTest and links it against the habitat_sim library. target_include_directories adds the binary directory to the include path for the test.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_11\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(GibsonSceneTest GibsonSceneTest.cpp LIBRARIES habitat_sim)\ntarget_include_directories(GibsonSceneTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Linking Assimp Library Conditionally\nDESCRIPTION: This snippet conditionally links the AssimpImporter library to the `habitat_sim_bindings` target if `BUILD_ASSIMP_SUPPORT` is enabled.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/bindings/CMakeLists.txt#_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_ASSIMP_SUPPORT)\n  target_link_libraries(habitat_sim_bindings PUBLIC MagnumPlugins::AssimpImporter)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Physics Definition\nDESCRIPTION: Adds a preprocessor definition `-DBT_ENABLE_PROFILE` for enabling profiling in Bullet Physics.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_12\n\nLANGUAGE: cmake\nCODE:\n```\nadd_definitions(-DBT_ENABLE_PROFILE)\n```\n\n----------------------------------------\n\nTITLE: Test Configuration\nDESCRIPTION: This snippet configures the test suite if `BUILD_TEST` is enabled. It enables testing, finds the Corrade and Magnum packages, and adds the necessary dependencies for running tests.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_10\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_TEST)\n  message(\"Building TESTS\")\n  enable_testing()\n  find_package(Corrade REQUIRED TestSuite)\n  find_package(Magnum REQUIRED OpenGLTester)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Changing Object's Light Setup (Python)\nDESCRIPTION: This snippet demonstrates how to change the lighting setup for a specific object already instanced into the scene using `Simulator.set_object_light_setup`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/lighting-setups.rst#_snippet_12\n\nLANGUAGE: py\nCODE:\n```\n# [example 9]\nsim.set_object_light_setup(cube_handle_3, \"\")\n# [/example 9]\n```\n\n----------------------------------------\n\nTITLE: Adding Viewer Resources\nDESCRIPTION: This snippet uses the `corrade_add_resource` command to add resource files to the viewer executable. It includes the resources.conf file, which likely contains configuration data for the viewer application.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/viewer/CMakeLists.txt#_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ncorrade_add_resource(viewer_RESOURCES resources.conf)\n```\n\n----------------------------------------\n\nTITLE: Initializing Habitat-sim\nDESCRIPTION: This snippet initializes the Habitat-sim simulator using the default settings. It calls the `make_default_settings` function to retrieve the default settings and then uses the `make_simulator_from_settings` function to create and initialize the simulator instance.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ReplicaCAD_quickstart.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsim_settings = make_default_settings()\nmake_simulator_from_settings(sim_settings)\n```\n\n----------------------------------------\n\nTITLE: Installing Habitat-Sim with Conda\nDESCRIPTION: These snippets demonstrate how to install Habitat-Sim using Conda.  Different installation options are presented for machines with an attached display, headless machines, and machines using bullet physics.  The headless version relies on EGL and does not work on MacOS.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nconda install habitat-sim -c conda-forge -c aihabitat\n```\n\nLANGUAGE: bash\nCODE:\n```\nconda install habitat-sim headless -c conda-forge -c aihabitat\n```\n\nLANGUAGE: bash\nCODE:\n```\nconda install habitat-sim withbullet -c conda-forge -c aihabitat\n```\n\nLANGUAGE: bash\nCODE:\n```\nconda install habitat-sim withbullet headless -c conda-forge -c aihabitat\n```\n\n----------------------------------------\n\nTITLE: Enable GPU Context Debugging\nDESCRIPTION: Sets environment variables to enable verbose logging and GPU validation for debugging GPU-related issues in Habitat-Sim. This is achieved by setting MAGNUM_LOG to 'verbose' and MAGNUM_GPU_VALIDATION to 'ON'.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/logging.rst#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nexport MAGNUM_LOG=verbose MAGNUM_GPU_VALIDATION=ON\n```\n\n----------------------------------------\n\nTITLE: Creating Viewer Executable\nDESCRIPTION: This snippet uses the `add_executable` command to create the viewer executable. It specifies the source files and resources that should be compiled and linked into the executable.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/viewer/CMakeLists.txt#_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(viewer ${viewer_SOURCES} ${viewer_RESOURCES})\n```\n\n----------------------------------------\n\nTITLE: Setting Directory Properties\nDESCRIPTION: This CMake command sets directory properties for the current directory. Specifically, it enables pedantic flags using the CORRADE_USE_PEDANTIC_FLAGS property. The command is commented as potentially slowing compilation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_29\n\nLANGUAGE: cmake\nCODE:\n```\nset_directory_properties(PROPERTIES CORRADE_USE_PEDANTIC_FLAGS ON)\n```\n\n----------------------------------------\n\nTITLE: Conditional Linking of atomic_wait Library\nDESCRIPTION: This snippet conditionally links the `atomic_wait` library to the `habitat_sim` target if the `BUILD_WITH_BACKGROUND_RENDERER` flag is enabled. This library is required for background rendering tasks.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_25\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_WITH_BACKGROUND_RENDERER)\n  target_link_libraries(habitat_sim PUBLIC atomic_wait)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding gfx_batch as a Subdirectory\nDESCRIPTION: This snippet includes the `gfx_batch` directory as a subdirectory in the CMake build process. This creates a separate library for graphics batching functionality.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_19\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(gfx_batch)\n```\n\n----------------------------------------\n\nTITLE: Registering Corrade Resources\nDESCRIPTION: This section registers shader and image resources using the `corrade_add_resource` command. It registers a configuration file for gfx shaders (`Shaders.conf`) and a configuration file for PBR IBL image resources (`PbrImages.conf`).\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\n# gfx shaders configuration\ncorrade_add_resource(GfxShaderResources ../shaders/gfx/Shaders.conf)\n\n# pbr IBL image resources configuration\ncorrade_add_resource(PbrIBlImageResources ../../data/pbr/PbrImages.conf)\n```\n\n----------------------------------------\n\nTITLE: Conda Package Installation\nDESCRIPTION: This command installs the Habitat-Sim package from the `aihabitat` and `conda-forge` conda channels. The `-c` flag specifies the channels to search for the package.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nconda install -c aihabitat -c conda-forge habitat-sim\n```\n\n----------------------------------------\n\nTITLE: Closing the Replay Player (Habitat-Sim, Python)\nDESCRIPTION: Closes the replay player to release resources. This is essential for proper cleanup after playback. It closes a single player and the multiple players.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/replay_tutorial.ipynb#_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# clean up the player\nplayer.close()\n```\n\nLANGUAGE: python\nCODE:\n```\n# clean up the players\nfor other_player in other_players:\n    other_player.close()\n```\n\n----------------------------------------\n\nTITLE: Install Habitat-Sim (Bullet Physics)\nDESCRIPTION: This snippet installs Habitat-Sim with Bullet physics support by passing the `--bullet` flag to `setup.py`.  This enables physics simulation capabilities within the simulator.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/BUILD_FROM_SOURCE.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython setup.py install --bullet    # build habitat with bullet physics\n```\n\n----------------------------------------\n\nTITLE: Importing Habitat Sim and Dependencies\nDESCRIPTION: This snippet imports necessary libraries including os, random, git, magnum, numpy, and habitat_sim modules. It also initializes paths for data and output directories based on the git repository root. These imports are essential for setting up the simulation environment and handling data.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/managed_rigid_object_tutorial.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport random\n\nimport git\nimport magnum as mn\nimport numpy as np\n\nimport habitat_sim\nfrom habitat_sim.utils import viz_utils as vut\n\nrepo = git.Repo(\".\", search_parent_directories=True)\ndir_path = repo.working_tree_dir\ndata_path = os.path.join(dir_path, \"data\")\noutput_path = os.path.join(\n    dir_path, \"examples/tutorials/managed_rigid_object_tutorial_output/\"\n)\n```\n\n----------------------------------------\n\nTITLE: PathFinder Random Navigable Point\nDESCRIPTION: Explains the `habitat_sim.nav.PathFinder.get_random_navigable_point` function, which samples a navigable point uniformly at random from the navmesh. Returns ``{NAN, NAN, NAN}`` if the point is invalid.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.nav.PathFinder.get_random_navigable_point\n```\n\n----------------------------------------\n\nTITLE: Accessing AssetAttributesTemplates\nDESCRIPTION: This snippet shows how to get an instance of the Asset Template Manager from the simulator object. The Asset Template Manager is used to get access to AssetAttributeTemplates.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_39\n\nLANGUAGE: Python\nCODE:\n```\nprim_attr_mgr = sim.get_asset_template_manager()\n```\n\n----------------------------------------\n\nTITLE: SemanticCategory Base Class\nDESCRIPTION: Defines the base class `habitat_sim.scene.SemanticCategory` for all semantic categories. Specific implementations such as `Mp3dObjectCategory` and `Mp3dRegionCategory` contain dataset-specific information.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.scene.SemanticCategory\n```\n\n----------------------------------------\n\nTITLE: Add Corrade Test Target\nDESCRIPTION: This snippet uses the corrade_add_test macro to create a test executable named AttributesConfigsTest from AttributesConfigsTest.cpp and links it against the habitat_sim library. target_include_directories adds the binary directory to the include path, allowing the test to access generated header files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(AttributesConfigsTest AttributesConfigsTest.cpp LIBRARIES habitat_sim)\ntarget_include_directories(AttributesConfigsTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Initializing Wireframe Icosphere Handle\nDESCRIPTION: Initializes the handle for a wireframe icosphere primitive from the asset template manager.  Wireframe icosphere has no customizable attributes.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_43\n\nLANGUAGE: Python\nCODE:\n```\nwireframe_handles_to_use[\"icosphereWireframe\"] = prim_attr_mgr.get_template_handles(\n    \"icosphereWireframe\"\n)[0]\n```\n\n----------------------------------------\n\nTITLE: Installing pre-commit hooks\nDESCRIPTION: This snippet installs and sets up pre-commit hooks to automatically run linters and formatters before committing code. It ensures consistent code style across the project.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\npip install pre-commit && pre-commit install\n```\n\n----------------------------------------\n\nTITLE: Running Asset Viewer\nDESCRIPTION: This shell command shows how to execute the Asset Viewer utility from the command line using Python. It assumes the user is in a shell environment.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/pages/asset-viewer-tutorial.rst#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ python path/to/habitat-sim/examples/tutorials/nb_python/asset_viewer.py\n```\n\n----------------------------------------\n\nTITLE: SemanticObject ID Property\nDESCRIPTION: Describes the `id` property of `habitat_sim.scene.SemanticObject`. For some datasets, the region ID is globally unique, while in others, it's unique per level.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.scene.SemanticObject.id\n```\n\n----------------------------------------\n\nTITLE: Previewing Assets using the C++ Viewer\nDESCRIPTION: This snippet shows how to use the C++ viewer to preview datasets with scene dataset configuration support. It requires specifying both the dataset configuration file and the scene file as command-line arguments.  It assumes the user is in the Habitat-Sim source directory and that the viewer has been built.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# ./build/viewer if compiled locally\nhabitat-viewer --dataset '<path to desired dataset config>/<desired dataset>.scene_dataset_config.json' '<scene to show>'\n```\n\n----------------------------------------\n\nTITLE: Vim integration for clang-format\nDESCRIPTION: This snippet configures vim to use clang-format by adding a mapping in the `.vimrc` file.  Ctrl+K will format the entire file.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_2\n\nLANGUAGE: vim\nCODE:\n```\nmap <C-K> :%!clang-format<cr>\n```\n\n----------------------------------------\n\nTITLE: Initializing Solid Cube Handle\nDESCRIPTION: Initializes the handle for a solid cube primitive from the asset template manager.  Solid cube has no customizable attributes.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_41\n\nLANGUAGE: Python\nCODE:\n```\nsolid_handles_to_use = {\"cubeSolid\": prim_attr_mgr.get_template_handles(\"cubeSolid\")[0]}\n```\n\n----------------------------------------\n\nTITLE: Add Mp3d Test Target\nDESCRIPTION: This snippet adds a test executable Mp3dTest and links it against the habitat_sim library. target_include_directories adds the binary directory to the include path for the test.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_16\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(Mp3dTest Mp3dTest.cpp LIBRARIES habitat_sim)\ntarget_include_directories(Mp3dTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Configure Header File\nDESCRIPTION: This snippet uses configure_file to copy and configure a header file from the source directory to the binary directory. This allows CMake variables to be used within the header file, providing configuration information to the C++ code.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nconfigure_file(\n  ${CMAKE_CURRENT_SOURCE_DIR}/configure.h.cmake ${CMAKE_CURRENT_BINARY_DIR}/configure.h\n)\n```\n\n----------------------------------------\n\nTITLE: Semantic ID Color Map (Hex)\nDESCRIPTION: Describes the `habitat_sim.utils.common.d3_40_colors_hex` data, a color map for semantic ID rendering in hexadecimal format, similar to `d3_40_colors_rgb`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.utils.common.d3_40_colors_hex\n```\n\n----------------------------------------\n\nTITLE: Habitat-Sim Common Utils Module\nDESCRIPTION: Explains the `habitat_sim.utils.common` module, focusing on quaternion math helper functions and misc utilities like `colorize_ids()`. Lists available quaternion functions.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.utils.common\n```\n\n----------------------------------------\n\nTITLE: Include Dependencies File\nDESCRIPTION: This snippet includes a separate CMake file (`cmake/dependencies.cmake`) that handles finding and configuring project dependencies.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_9\n\nLANGUAGE: cmake\nCODE:\n```\ninclude(cmake/dependencies.cmake)\n```\n\n----------------------------------------\n\nTITLE: Include Directories\nDESCRIPTION: This snippet includes the project's source directory in the include path, allowing the compiler to find header files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/CMakeLists.txt#_snippet_11\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(${PROJECT_SOURCE_DIR})\n```\n\n----------------------------------------\n\nTITLE: Add Sensor Test Target\nDESCRIPTION: This snippet adds a test executable SensorTest and links it against the habitat_sim library.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_24\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(SensorTest SensorTest.cpp LIBRARIES habitat_sim)\n```\n\n----------------------------------------\n\nTITLE: Linking Target Libraries\nDESCRIPTION: This snippet links the `magnum-imageconverter` target against the necessary Magnum libraries and plugins.  It includes core Magnum libraries like `AnyImageImporter` and `AnyImageConverter`, as well as plugin libraries like `StbImageImporter`, `StbImageConverter`, and `BasisImageConverter`. The `PRIVATE` keyword indicates that these libraries are only needed during the build process of `magnum-imageconverter`.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/imageconverter/CMakeLists.txt#_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_link_libraries(\n  magnum-imageconverter\n  PRIVATE Magnum::AnyImageImporter Magnum::AnyImageConverter\n          MagnumPlugins::StbImageImporter MagnumPlugins::StbImageConverter\n          MagnumPlugins::BasisImageConverter\n)\n```\n\n----------------------------------------\n\nTITLE: Conda Environment Activation\nDESCRIPTION: This command creates a new conda environment named 'py39' with Python version 3.9 and then activates it. This ensures the correct Python version and package dependencies are used for the build process.  The `-y` flag automatically confirms any prompts during environment creation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nconda create --name py39 python=3.9 -y;conda activate py39\n```\n\n----------------------------------------\n\nTITLE: Setting Source Files for Geo Module\nDESCRIPTION: This snippet defines a list of source files (`geo_SOURCES`) for the `geo` module using the `set` command. The list includes both `.cpp` and `.h` files.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/CMakeLists.txt#_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\nset(\n  geo_SOURCES\n  geo/CoordinateFrame.cpp\n  geo/CoordinateFrame.h\n  geo/Geo.cpp\n  geo/Geo.h\n  geo/OBB.cpp\n  geo/OBB.h\n)\n```\n\n----------------------------------------\n\nTITLE: Semantic ID Color Map (RGB)\nDESCRIPTION: Describes the `habitat_sim.utils.common.d3_40_colors_rgb` data, a color map for semantic ID rendering.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.utils.common.d3_40_colors_rgb\n```\n\n----------------------------------------\n\nTITLE: Add LoggingTest Test Target\nDESCRIPTION: Adds a test target LoggingTest linked to the habitat_sim library.  Also sets the HABITAT_SIM_LOG environment variable to an empty string for this test.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_14\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(LoggingTest LoggingTest.cpp LIBRARIES habitat_sim)\nset_tests_properties(LoggingTest PROPERTIES ENVIRONMENT HABITAT_SIM_LOG=\"\")\n```\n\n----------------------------------------\n\nTITLE: Saving the NavMesh\nDESCRIPTION: This is a placeholder for the code to save the NavMesh.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Navigation.ipynb#_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n# @markdown ##Saving the NavMesh\n\n# fmt: off\n```\n\n----------------------------------------\n\nTITLE: Installing clang-format via conda\nDESCRIPTION: This snippet shows how to install `clang-format-12` using `conda`. `clang-format` is used for C++ code style enforcement and linting.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nconda install clangdev -c conda-forge\n```\n\n----------------------------------------\n\nTITLE: Add MetadataMediator Test Target\nDESCRIPTION: This snippet adds a test executable MetadataMediatorTest and links it against the habitat_sim library. target_include_directories adds the binary directory to the include path for the test.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_15\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(MetadataMediatorTest MetadataMediatorTest.cpp LIBRARIES habitat_sim)\ntarget_include_directories(MetadataMediatorTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for RedwoodDepthNoiseModel\nDESCRIPTION: This snippet provides the BibTeX entry for the research paper associated with the RedwoodDepthNoiseModel. Citing this paper is important when using the noise model in research, as it acknowledges the original work that developed the model. The citation includes the title, authors, booktitle, pages, and year of publication.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/noise_models.rst#_snippet_1\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{choi2015robust,\n  title={Robust reconstruction of indoor scenes},\n  author={Choi, Sungjoon and Zhou, Qian-Yi and Koltun, Vladlen},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and\n    Pattern Recognition}, pages={5556--5565}, year={2015}\n}\n```\n\n----------------------------------------\n\nTITLE: Add PathFinder Test Target\nDESCRIPTION: This snippet adds a test executable PathFinderTest and links it against the habitat_sim and Corrade::Utility libraries. target_include_directories adds the binary directory to the include path for the test.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_18\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  PathFinderTest PathFinderTest.cpp LIBRARIES habitat_sim Corrade::Utility\n)\ntarget_include_directories(PathFinderTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Installing ninja on macOS\nDESCRIPTION: Installs ninja build system on macOS using brew package manager. Ninja is used to improve build speed.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nbrew install ninja\n```\n\n----------------------------------------\n\nTITLE: Building Bullet Tag File\nDESCRIPTION: This set of commands clones the bullet3 repository, checks out version 2.88, modifies the Doxyfile to generate a tagfile, runs doxygen to generate the tagfile, and copies the tagfile to the docs directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/README.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/bulletphysics/bullet3\ncd bullet3\ngit checkout 2.88\nnano Doxyfile # modify it to have GENERATE_TAGFILE = bullet.tag\ndoxygen # it'll complain about some CHM file, ignore that\ncp bullet.tag ../habitat-sim/docs/\n```\n\n----------------------------------------\n\nTITLE: Installing MacTex on OSX\nDESCRIPTION: This command installs MacTex on OSX using brew. MacTex is a comprehensive TeX distribution for macOS, providing all the necessary tools for typesetting documents.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nbrew install --cask mactex\n```\n\n----------------------------------------\n\nTITLE: Building Habitat-Sim Docs\nDESCRIPTION: This script executes the build process for the Habitat-Sim documentation. It first builds the C++ extensions in place, then updates the git submodules in the docs directory, and finally runs the build script to generate the documentation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython setup.py build_ext --inplace\ncd docs\ngit submodule update --init\n./build.sh # or ./build-public.sh when deploying to aihabitat.org\n```\n\n----------------------------------------\n\nTITLE: Exporting TeX Binary Path\nDESCRIPTION: This command exports the path to the TeX binaries. This may be required for the documentation build process to correctly find and execute the TeX binaries for mathematical typesetting.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nexport PATH=$PATH:/Library/TeX/Distributions/.DefaultTeX/Contents/Programs/texbin\n```\n\n----------------------------------------\n\nTITLE: Add GfxBatchHbao Test Target\nDESCRIPTION: Adds a test target named GfxBatchHbaoTest and links it against gfx_batch, Magnum and several Magnum plugins. The target_include_directories command sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_8\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  GfxBatchHbaoTest\n  GfxBatchHbaoTest.cpp\n  LIBRARIES\n  gfx_batch\n  Magnum::DebugTools\n  Magnum::OpenGLTester\n  Magnum::MeshTools\n  Magnum::AnyImageConverter\n  Magnum::AnyImageImporter\n  Magnum::AnySceneImporter\n  MagnumPlugins::OpenExrImageConverter\n  MagnumPlugins::OpenExrImporter\n  MagnumPlugins::StanfordImporter\n  MagnumPlugins::StbImageImporter\n  MagnumPlugins::StbImageConverter\n)\ntarget_include_directories(GfxBatchHbaoTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Anaconda Package Upload\nDESCRIPTION: This command uploads the built conda package to Anaconda Cloud.  It makes the package available for others to download and install.  The path should be replaced with the actual location of the `.tar.bz2` file created by the build process.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/conda-build/README.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nanaconda upload <path to the tarball file that conda build created>\n```\n\nLANGUAGE: shell\nCODE:\n```\nanaconda upload hsim-macos/osx-64/habitat-sim-1.3.2-py3.9_osx.tar.bz2\n```\n\n----------------------------------------\n\nTITLE: Add GfxBatchRenderer Test Target\nDESCRIPTION: This snippet adds a test target named GfxBatchRendererTest and links it against gfx_batch, Magnum, and several Magnum plugins. It also conditionally adds include directories for CUDA and links against Magnum plugins depending on their availability. target_include_directories sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_9\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  GfxBatchRendererTest\n  GfxBatchRendererTest.cpp\n  LIBRARIES\n  gfx_batch\n  Magnum::DebugTools\n  Magnum::AnyImageConverter\n  Magnum::AnySceneImporter\n  MagnumPlugins::GltfImporter\n  MagnumPlugins::KtxImporter\n  MagnumPlugins::StbImageImporter\n  MagnumPlugins::StbImageConverter\n)\ntarget_include_directories(GfxBatchRendererTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\nif(BUILD_WITH_CUDA)\n  target_include_directories(\n    GfxBatchRendererTest PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES}\n  )\nendif()\nif(MagnumPlugins_GltfSceneConverter_FOUND)\n  target_link_libraries(GfxBatchRendererTest PRIVATE MagnumPlugins::GltfSceneConverter)\nendif()\nif(MagnumPlugins_KtxImageConverter_FOUND)\n  target_link_libraries(GfxBatchRendererTest PRIVATE MagnumPlugins::KtxImageConverter)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Installing ccache on macOS\nDESCRIPTION: Installs ccache on macOS using brew package manager. ccache is used to improve build speed with caching.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/CONTRIBUTING.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nbrew install ccache\n```\n\n----------------------------------------\n\nTITLE: Add HM3DScene Test Target\nDESCRIPTION: Adds a test executable HM3DSceneTest, links it with habitat_sim and Magnum importers (Basis, Gltf, Stb, and Ufbx). The target_include_directories command sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_12\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  HM3DSceneTest\n  HM3DSceneTest.cpp\n  LIBRARIES\n  habitat_sim\n  MagnumPlugins::BasisImporter\n  MagnumPlugins::GltfImporter\n  MagnumPlugins::StbImageImporter\n  MagnumPlugins::StbImageConverter\n  MagnumPlugins::UfbxImporter\n)\ntarget_include_directories(HM3DSceneTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages on Linux\nDESCRIPTION: This command installs required TeX Live packages on Linux using apt. These packages are needed for rendering mathematical formulas and other special characters in the documentation.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install --allow-change-held-packages \\\n                  texlive-base \\\n                  texlive-latex-extra \\\n                  texlive-fonts-extra \\\n                  texlive-fonts-recommended\n```\n\n----------------------------------------\n\nTITLE: Citing Habitat Papers in BibTeX Format\nDESCRIPTION: This snippet contains BibTeX entries for citing Habitat 3.0, Habitat 2.0, and Habitat 1.0 papers. These citations should be used when Habitat platform is used in research.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/README.md#_snippet_0\n\nLANGUAGE: BibTeX\nCODE:\n```\n@misc{puig2023habitat3,\n      title  = {Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots},\n      author = {Xavi Puig and Eric Undersander and Andrew Szot and Mikael Dallaire Cote and Ruslan Partsey and Jimmy Yang and Ruta Desai and Alexander William Clegg and Michal Hlavac and Tiffany Min and Theo Gervet and Vladimír Vondruš and Vincent-Pierre Berges and John Turner and Oleksandr Maksymets and Zsolt Kira and Mrinal Kalakrishnan and Jitendra Malik and Devendra Singh Chaplot and Unnat Jain and Dhruv Batra and Akshara Rai and Roozbeh Mottaghi},\n      year={2023},\n      archivePrefix={arXiv},\n}\n\n@inproceedings{szot2021habitat,\n  title     =     {Habitat 2.0: Training Home Assistants to Rearrange their Habitat},\n  author    =     {Andrew Szot and Alex Clegg and Eric Undersander and Erik Wijmans and Yili Zhao and John Turner and Noah Maestre and Mustafa Mukadam and Devendra Chaplot and Oleksandr Maksymets and Aaron Gokaslan and Vladimir Vondrus and Sameer Dharur and Franziska Meier and Wojciech Galuba and Angel Chang and Zsolt Kira and Vladlen Koltun and Jitendra Malik and Manolis Savva and Dhruv Batra},\n  booktitle =     {Advances in Neural Information Processing Systems (NeurIPS)},\n  year      =     {2021}\n}\n\n@inproceedings{habitat19iccv,\n  title     =     {Habitat: {A} {P}latform for {E}mbodied {AI} {R}esearch},\n  author    =     {Manolis Savva and Abhishek Kadian and Oleksandr Maksymets and Yili Zhao and Erik Wijmans and Bhavana Jain and Julian Straub and Jia Liu and Vladlen Koltun and Jitendra Malik and Devi Parikh and Dhruv Batra},\n  booktitle =     {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},\n  year      =     {2019}\n}\n```\n\n----------------------------------------\n\nTITLE: JavaScript Animation/Update Function\nDESCRIPTION: This snippet contains JavaScript code that appears to be responsible for dynamically updating or animating the SVG graphic. It uses variables like 'n', 'm', 'x', and 'y' which might represent coordinates or properties of SVG elements. The calculations within suggest transformations or data-driven updates.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_28\n\nLANGUAGE: JavaScript\nCODE:\n```\nz.toString(16)\n```\n\n----------------------------------------\n\nTITLE: Add ReplicaScene Test Target\nDESCRIPTION: Adds a test executable ReplicaSceneTest, links it with habitat_sim and Magnum importers (Gltf, Stanford, Stb, and Ufbx). The target_include_directories command sets the include path to the build directory.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/tests/CMakeLists.txt#_snippet_20\n\nLANGUAGE: cmake\nCODE:\n```\ncorrade_add_test(\n  ReplicaSceneTest\n  ReplicaSceneTest.cpp\n  LIBRARIES\n  habitat_sim\n  MagnumPlugins::GltfImporter\n  MagnumPlugins::StanfordImporter\n  MagnumPlugins::StbImageImporter\n  MagnumPlugins::StbImageConverter\n  MagnumPlugins::UfbxImporter\n)\ntarget_include_directories(ReplicaSceneTest PRIVATE ${CMAKE_CURRENT_BINARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: SVG Element Definition\nDESCRIPTION: This snippet likely defines an SVG element. The surrounding code consists primarily of obfuscated SVG path data and style attributes. The element's content is likely used to render a part of the overall graphic and is potentially manipulated by the JavaScript code.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/examples/tutorials/notebooks/ECCV_2020_Advanced_Features.ipynb#_snippet_27\n\nLANGUAGE: SVG\nCODE:\n```\n<svg width=\"0\" height=\"0\"></svg>\n```\n\n----------------------------------------\n\nTITLE: SemanticRegion ID Property\nDESCRIPTION: Explains the `id` property of `habitat_sim.scene.SemanticRegion`. In some datasets, the region ID is globally unique, while in others it is only unique per level.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/docs.rst#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nhabitat_sim.scene.SemanticRegion.id\n```\n\n----------------------------------------\n\nTITLE: Checking CMake Version\nDESCRIPTION: This snippet checks if the CMake version is less than 3.13. If it is, it prints a message indicating that a newer version of CMake is required and suggests using pip to install it. This ensures that the build process can proceed with a compatible CMake version.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/utils/imageconverter/CMakeLists.txt#_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nif(CMAKE_VERSION VERSION_LESS \"3.13\")\n  message(\"Build imageconverter requires a newer version of cmake.\")\n  message(\"You can get one with pip install cmake\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Checking Doxygen Version\nDESCRIPTION: This command checks the installed version of Doxygen. The documentation recommends using Doxygen version 1.8.16.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/docs/README.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndoxygen -v\n```\n\n----------------------------------------\n\nTITLE: Setting Include Directories (Commented Out)\nDESCRIPTION: This commented-out snippet shows how to add include directories for the `environment` target, making header files available during compilation. This functionality is currently disabled.\nSOURCE: https://github.com/facebookresearch/habitat-sim/blob/main/src/esp/bindings/CMakeLists.txt#_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\n# target_include_directories(environment\n#   PUBLIC\n#     ${CMAKE_CURRENT_LIST_DIR}\n# )\n```"
  }
]